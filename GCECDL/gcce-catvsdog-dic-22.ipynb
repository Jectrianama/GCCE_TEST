{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jenntm/gcce-catvsdog-dic-22?scriptVersionId=118378191\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"807bdcbe","metadata":{"id":"oAuRT75GdLFw","papermill":{"duration":0.006621,"end_time":"2023-02-06T14:27:13.637677","exception":false,"start_time":"2023-02-06T14:27:13.631056","status":"completed"},"tags":[]},"source":["# Cats vs. Dogs Class dataset for multiple annotators\n"]},{"cell_type":"markdown","id":"e77c06fc","metadata":{"id":"9rK94t33nwDC","papermill":{"duration":0.005052,"end_time":"2023-02-06T14:27:13.648647","exception":false,"start_time":"2023-02-06T14:27:13.643595","status":"completed"},"tags":[]},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"id":"23b23247","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:13.662422Z","iopub.status.busy":"2023-02-06T14:27:13.661495Z","iopub.status.idle":"2023-02-06T14:27:20.063738Z","shell.execute_reply":"2023-02-06T14:27:20.062726Z"},"id":"zSyMHuCVys-O","papermill":{"duration":6.412103,"end_time":"2023-02-06T14:27:20.066248","exception":false,"start_time":"2023-02-06T14:27:13.654145","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n","from keras.utils.vis_utils import plot_model\n","from tensorflow.keras import regularizers\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy as sp\n","import cv2\n","import os\n","import time\n","import sys"]},{"cell_type":"code","execution_count":2,"id":"f2b808b4","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:20.080077Z","iopub.status.busy":"2023-02-06T14:27:20.078871Z","iopub.status.idle":"2023-02-06T14:27:20.083432Z","shell.execute_reply":"2023-02-06T14:27:20.082559Z"},"id":"-E1MJt8cxlwg","outputId":"ea43c1c9-075f-44de-d2d8-e135799b6630","papermill":{"duration":0.013442,"end_time":"2023-02-06T14:27:20.085452","exception":false,"start_time":"2023-02-06T14:27:20.07201","status":"completed"},"tags":[]},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"5bb4cc31","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:20.097418Z","iopub.status.busy":"2023-02-06T14:27:20.097136Z","iopub.status.idle":"2023-02-06T14:27:20.101124Z","shell.execute_reply":"2023-02-06T14:27:20.100034Z"},"id":"QJPvjdZ-f8ca","papermill":{"duration":0.012242,"end_time":"2023-02-06T14:27:20.103041","exception":false,"start_time":"2023-02-06T14:27:20.090799","status":"completed"},"tags":[]},"outputs":[],"source":["# os.chdir('/content/drive/Shareddrives/Multiple Anotators/CrowdLayer/Notebooks')\n","# cwd = os.getcwd()\n","# sys.path.append(\"../Models\")\n","\n","\n","# from Multiple_Annotators_C import MultipleAnnotators_Classification\n","\n","#import sys\n","#sys.path.insert(1, '../input/multiple-annotators-c/')\n","#os.chdir('/Multiple Anotators-c/')\n","#cwd = os.getcwd()\n","#sys.path.append('/input/multiple-annotators-c')\n","#from Multiple_Annotators_C import MultipleAnnotators_Classification\n","\n","# seed_value= 12321 \n","# from numpy.random import seed\n","# seed(seed_value)\n","# tf.random.set_seed(seed_value)"]},{"cell_type":"markdown","id":"c1b9aec8","metadata":{"id":"6Un5nFWgnyem","papermill":{"duration":0.005274,"end_time":"2023-02-06T14:27:20.113601","exception":false,"start_time":"2023-02-06T14:27:20.108327","status":"completed"},"tags":[]},"source":["## Download and Prepare the Dataset\n","\n","We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset and we can load it via Tensorflow Datasets. The images are labeled 0 for cats and 1 for dogs."]},{"cell_type":"markdown","id":"4afa2697","metadata":{"id":"Gw6K2Uey06kh","papermill":{"duration":0.005363,"end_time":"2023-02-06T14:27:20.124218","exception":false,"start_time":"2023-02-06T14:27:20.118855","status":"completed"},"tags":[]},"source":["# Multiple annotators model"]},{"cell_type":"code","execution_count":4,"id":"24820a77","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:20.136385Z","iopub.status.busy":"2023-02-06T14:27:20.135606Z","iopub.status.idle":"2023-02-06T14:27:22.93427Z","shell.execute_reply":"2023-02-06T14:27:22.933345Z"},"id":"xam4REp209Sd","papermill":{"duration":2.807116,"end_time":"2023-02-06T14:27:22.936546","exception":false,"start_time":"2023-02-06T14:27:20.12943","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-06 14:27:20.232166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:20.373332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:20.374074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:20.375594: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-06 14:27:20.382340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:20.383020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:20.383698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:22.527969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:22.528833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:22.529543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-06 14:27:22.530205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["\n","validation_data = tf.data.experimental.load('/kaggle/input/catsvsdog-ma/cats_dogs_Te')\n","train_data_MA = tf.data.experimental.load('/kaggle/input/catsvsdog-ma/cats_dogs_MA_Tr_1')\n","\n"]},{"cell_type":"code","execution_count":5,"id":"a97f3779","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:22.949361Z","iopub.status.busy":"2023-02-06T14:27:22.949048Z","iopub.status.idle":"2023-02-06T14:27:22.959196Z","shell.execute_reply":"2023-02-06T14:27:22.958335Z"},"id":"D_S0EJ3mFdfK","outputId":"9ed3c2c7-50b4-4445-a01e-c9a3d780c403","papermill":{"duration":0.018936,"end_time":"2023-02-06T14:27:22.961539","exception":false,"start_time":"2023-02-06T14:27:22.942603","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["18610"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["image_count = tf.data.experimental.cardinality(train_data_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count"]},{"cell_type":"code","execution_count":6,"id":"9591f53c","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:22.974788Z","iopub.status.busy":"2023-02-06T14:27:22.97415Z","iopub.status.idle":"2023-02-06T14:27:22.980886Z","shell.execute_reply":"2023-02-06T14:27:22.979812Z"},"id":"ctjLei0TxcVh","outputId":"6f578b73-ebdf-4465-91c7-2adb7d127174","papermill":{"duration":0.015906,"end_time":"2023-02-06T14:27:22.982997","exception":false,"start_time":"2023-02-06T14:27:22.967091","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["4652"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["image_count1 = tf.data.experimental.cardinality(validation_data).numpy() # los datos de training son 18610\n","image_count1"]},{"cell_type":"code","execution_count":7,"id":"23c1b357","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:22.996254Z","iopub.status.busy":"2023-02-06T14:27:22.995529Z","iopub.status.idle":"2023-02-06T14:27:22.999715Z","shell.execute_reply":"2023-02-06T14:27:22.998758Z"},"id":"opk5MXl4IwjC","papermill":{"duration":0.013243,"end_time":"2023-02-06T14:27:23.001892","exception":false,"start_time":"2023-02-06T14:27:22.988649","status":"completed"},"tags":[]},"outputs":[],"source":["#X_test = [validation_data[i][0] for i in range(image_count1)]\n","#Y_true_test = [validation_data[i][1] for i in range(image_count1)]\n","#Y_true_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n","#X_test = np.asarray([aux[0].numpy() for aux  in validation_data])"]},{"cell_type":"code","execution_count":8,"id":"88be70f3","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:23.015829Z","iopub.status.busy":"2023-02-06T14:27:23.014993Z","iopub.status.idle":"2023-02-06T14:27:23.021639Z","shell.execute_reply":"2023-02-06T14:27:23.020579Z"},"id":"-BydcVOQxcVh","outputId":"8c1b4ed2-7c43-4675-f055-f9e4e3f5b3dd","papermill":{"duration":0.016221,"end_time":"2023-02-06T14:27:23.02357","exception":false,"start_time":"2023-02-06T14:27:23.007349","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["18610"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["image_count"]},{"cell_type":"code","execution_count":9,"id":"1e9b35de","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:23.038667Z","iopub.status.busy":"2023-02-06T14:27:23.037894Z","iopub.status.idle":"2023-02-06T14:27:23.051994Z","shell.execute_reply":"2023-02-06T14:27:23.04953Z"},"id":"HdFme6fdxcVh","papermill":{"duration":0.025993,"end_time":"2023-02-06T14:27:23.055074","exception":false,"start_time":"2023-02-06T14:27:23.029081","status":"completed"},"tags":[]},"outputs":[],"source":["val_size = int(image_count * 0.2)\n","train_ds_MA = train_data_MA.skip(val_size)\n","val_ds_MA = train_data_MA.take(val_size)"]},{"cell_type":"code","execution_count":10,"id":"0d7f4076","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:23.083922Z","iopub.status.busy":"2023-02-06T14:27:23.083437Z","iopub.status.idle":"2023-02-06T14:27:23.101597Z","shell.execute_reply":"2023-02-06T14:27:23.10035Z"},"id":"aVHIlFpgxcVi","papermill":{"duration":0.035402,"end_time":"2023-02-06T14:27:23.104657","exception":false,"start_time":"2023-02-06T14:27:23.069255","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 100\n","train_batches_MA = train_ds_MA.shuffle(1024).batch(batch_size)\n","val_batches_MA = val_ds_MA.shuffle(1024).batch(batch_size)\n","test_batches_MA = validation_data.shuffle(1024).batch(batch_size)"]},{"cell_type":"code","execution_count":11,"id":"a50008e0","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:23.123787Z","iopub.status.busy":"2023-02-06T14:27:23.123065Z","iopub.status.idle":"2023-02-06T14:27:23.133029Z","shell.execute_reply":"2023-02-06T14:27:23.132131Z"},"id":"GsB4EA2-xcVi","outputId":"2d45809e-a9cc-408f-9a8b-745e8fe850e9","papermill":{"duration":0.021957,"end_time":"2023-02-06T14:27:23.13532","exception":false,"start_time":"2023-02-06T14:27:23.113363","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["14888"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["image_count = tf.data.experimental.cardinality(train_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count"]},{"cell_type":"code","execution_count":12,"id":"1dc61ffd","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:23.154104Z","iopub.status.busy":"2023-02-06T14:27:23.153813Z","iopub.status.idle":"2023-02-06T14:27:23.164839Z","shell.execute_reply":"2023-02-06T14:27:23.164199Z"},"id":"Hk33DzwkxcVi","outputId":"aad91eec-842c-4995-de90-5bb715539b6a","papermill":{"duration":0.022418,"end_time":"2023-02-06T14:27:23.166634","exception":false,"start_time":"2023-02-06T14:27:23.144216","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["3722"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["image_count_val = tf.data.experimental.cardinality(val_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count_val"]},{"cell_type":"code","execution_count":null,"id":"96a4b02f","metadata":{"id":"UMeK3NG3xcVi","papermill":{"duration":0.012987,"end_time":"2023-02-06T14:27:23.185571","exception":false,"start_time":"2023-02-06T14:27:23.172584","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"id":"3b4773f5","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:23.202316Z","iopub.status.busy":"2023-02-06T14:27:23.202014Z","iopub.status.idle":"2023-02-06T14:27:41.680768Z","shell.execute_reply":"2023-02-06T14:27:41.679808Z"},"id":"uvwc7eixxcVi","outputId":"d7766078-8c40-41ed-fb01-66b5f62a07f1","papermill":{"duration":18.488903,"end_time":"2023-02-06T14:27:41.683326","exception":false,"start_time":"2023-02-06T14:27:23.194423","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-06 14:27:23.833989: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2023-02-06 14:27:36.230144: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n","2023-02-06 14:27:39.935262: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.71      0.75        62\n","           1       0.59      0.68      0.63        38\n","\n","    accuracy                           0.70       100\n","   macro avg       0.69      0.70      0.69       100\n","weighted avg       0.71      0.70      0.70       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.85      0.88        62\n","           1       0.79      0.87      0.82        38\n","\n","    accuracy                           0.86       100\n","   macro avg       0.85      0.86      0.85       100\n","weighted avg       0.87      0.86      0.86       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.50      0.62        62\n","           1       0.50      0.82      0.62        38\n","\n","    accuracy                           0.62       100\n","   macro avg       0.66      0.66      0.62       100\n","weighted avg       0.70      0.62      0.62       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.24      0.38        62\n","           1       0.43      0.95      0.60        38\n","\n","    accuracy                           0.51       100\n","   macro avg       0.66      0.59      0.49       100\n","weighted avg       0.71      0.51      0.46       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.84      0.87        62\n","           1       0.76      0.84      0.80        38\n","\n","    accuracy                           0.84       100\n","   macro avg       0.83      0.84      0.83       100\n","weighted avg       0.85      0.84      0.84       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.75      0.71        48\n","           1       0.74      0.67      0.71        52\n","\n","    accuracy                           0.71       100\n","   macro avg       0.71      0.71      0.71       100\n","weighted avg       0.71      0.71      0.71       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.85      0.89        48\n","           1       0.88      0.94      0.91        52\n","\n","    accuracy                           0.90       100\n","   macro avg       0.90      0.90      0.90       100\n","weighted avg       0.90      0.90      0.90       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.42      0.51        48\n","           1       0.59      0.79      0.68        52\n","\n","    accuracy                           0.61       100\n","   macro avg       0.62      0.60      0.59       100\n","weighted avg       0.62      0.61      0.60       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.15      0.25        48\n","           1       0.55      0.98      0.71        52\n","\n","    accuracy                           0.58       100\n","   macro avg       0.71      0.56      0.48       100\n","weighted avg       0.71      0.58      0.49       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.83      0.88        48\n","           1       0.86      0.94      0.90        52\n","\n","    accuracy                           0.89       100\n","   macro avg       0.89      0.89      0.89       100\n","weighted avg       0.89      0.89      0.89       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.74      0.76        57\n","           1       0.67      0.72      0.70        43\n","\n","    accuracy                           0.73       100\n","   macro avg       0.73      0.73      0.73       100\n","weighted avg       0.73      0.73      0.73       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.75      0.81        57\n","           1       0.73      0.86      0.79        43\n","\n","    accuracy                           0.80       100\n","   macro avg       0.80      0.81      0.80       100\n","weighted avg       0.81      0.80      0.80       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.60      0.66        57\n","           1       0.57      0.72      0.64        43\n","\n","    accuracy                           0.65       100\n","   macro avg       0.66      0.66      0.65       100\n","weighted avg       0.67      0.65      0.65       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.26      0.41        57\n","           1       0.49      0.95      0.65        43\n","\n","    accuracy                           0.56       100\n","   macro avg       0.69      0.61      0.53       100\n","weighted avg       0.72      0.56      0.51       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.95        57\n","           1       0.91      0.95      0.93        43\n","\n","    accuracy                           0.94       100\n","   macro avg       0.94      0.94      0.94       100\n","weighted avg       0.94      0.94      0.94       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.70      0.70        54\n","           1       0.65      0.65      0.65        46\n","\n","    accuracy                           0.68       100\n","   macro avg       0.68      0.68      0.68       100\n","weighted avg       0.68      0.68      0.68       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.74      0.82        54\n","           1       0.75      0.91      0.82        46\n","\n","    accuracy                           0.82       100\n","   macro avg       0.83      0.83      0.82       100\n","weighted avg       0.84      0.82      0.82       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.48      0.55        54\n","           1       0.53      0.70      0.60        46\n","\n","    accuracy                           0.58       100\n","   macro avg       0.59      0.59      0.58       100\n","weighted avg       0.60      0.58      0.58       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.31      0.48        54\n","           1       0.55      1.00      0.71        46\n","\n","    accuracy                           0.63       100\n","   macro avg       0.78      0.66      0.60       100\n","weighted avg       0.79      0.63      0.59       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.85      0.88        54\n","           1       0.84      0.91      0.87        46\n","\n","    accuracy                           0.88       100\n","   macro avg       0.88      0.88      0.88       100\n","weighted avg       0.88      0.88      0.88       100\n","\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from sklearn.metrics import classification_report\n","i = 0\n","fig, ax = plt.subplots(1, 4)\n","for image, label, label2 in train_batches_MA.take(4):\n","   # predictedLabel = int(predictions[i] >= 0.5)\n","   # print(label2)\n","    ax[i].axis('off')\n","   # ax[i].set_title(classNames[label[i]])\n","    ax[i].imshow(image[0])\n","    i += 1\n","    for j in range(label2.shape[1]):\n","      print('annotator',j+1)\n","      print(classification_report(label ,label2[:,j]))\n","plt.show()"]},{"cell_type":"markdown","id":"98622f5e","metadata":{"id":"9AgOHREc1bmd","papermill":{"duration":0.007174,"end_time":"2023-02-06T14:27:41.697996","exception":false,"start_time":"2023-02-06T14:27:41.690822","status":"completed"},"tags":[]},"source":["## Build the classifier from multiple annotators"]},{"cell_type":"code","execution_count":14,"id":"615b777f","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:41.713995Z","iopub.status.busy":"2023-02-06T14:27:41.713697Z","iopub.status.idle":"2023-02-06T14:27:41.739236Z","shell.execute_reply":"2023-02-06T14:27:41.738336Z"},"id":"k-ePr0-fxcVi","papermill":{"duration":0.036031,"end_time":"2023-02-06T14:27:41.741199","exception":false,"start_time":"2023-02-06T14:27:41.705168","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import time\n","from tensorflow.keras import regularizers\n","\n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n","from keras.utils.vis_utils import plot_model\n","\n","class MultipleAnnotators_Classification():\n","    def __init__(self, output_dim, num_annotators, q= 0.0001):\n","        self.K = output_dim\n","        self.R = num_annotators\n","        self.q = q\n","        #self.callbacks #=callbacks\n","        #self.l1_param=l1_param \n","        #self.l2_param=l1_param\n","\n","    def CrowdLayer(self, input):\n","       #x = keras.layers.Dense(self.R + self.K,  ,  activation='tanh')(input)\n","        output_cla = keras.layers.Dense(self.K,    activation='softmax')(input)\n","        output_ann = keras.layers.Dense(self.R, activation='sigmoid')(input)\n","        output = keras.layers.Concatenate()([output_cla, output_ann])\n","        \n","        return output\n","#RCDNN   \n","#     def loss(self):\n","#         def custom_loss(y_true, y_pred):\n","#             # print(y_true,y_pred)\n","#             pred = y_pred[:, :self.K]\n","#             pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1-1e-9) #estabilidad numerica de la funcion de costo\n","#             ann_ = y_pred[:, self.K:]\n","#             Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n","#             Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n","#             p_logreg = tf.math.reduce_prod(tf.math.pow(Y_hat, Y_true), axis=1)\n","#             temp1 = ann_*tf.math.log(p_logreg)  \n","#             temp2 = (1 - ann_)*tf.math.log(1/self.K)*tf.reduce_sum(Y_true,axis=1)\n","#             # temp2 = (tf.ones(tf.shape(ann_)) - ann_)*tf.math.log(1/K)\n","#             # print(tf.reduce_mean(Y_true,axis=1).numpy())\n","#             return -tf.math.reduce_sum((temp1 + temp2))\n","#         return custom_loss\n","    \n","    def loss(self):\n","        def custom_loss(y_true, y_pred):\n","               # print(y_true,y_pred)\n","           # q = 0.1\n","            pred = y_pred[:, :self.K]\n","            pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n","            ann_ = y_pred[:, self.K:]\n","            # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n","            Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n","            Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n","\n","            p_gcce = Y_true*(1 - Y_hat**self.q)/self.q\n","            temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n","            temp2 = (1 - ann_)*(1-(1/self.K)**self.q)/self.q*tf.reduce_sum(Y_true,axis=1)\n","            return tf.math.reduce_sum((temp1 + temp2))\n","        return custom_loss\n","\n","    @tf.function\n","    def train_step(self, x, Y, y):\n","        with tf.GradientTape() as tape:\n","            logits = self.model(x, training=True)\n","            loss_value = self.loss_fn(Y, logits)\n","        grads = tape.gradient(loss_value, self.model.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n","        self.train_acc_metric.update_state(y, logits[:, :self.K])\n","        return loss_value\n","\n","    @tf.function\n","    def test_step(self, x, y):\n","        val_logits = self.model(x, training=False)\n","        self.val_acc_metric.update_state(y, val_logits[:,:self.K])\n","\n","    def fit(self, model, Data_tr, Data_Val, epochs):\n","        self.model = model\n","        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        # Instantiate an optimizer.\n","        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n","        #self.optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n","        #self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, clipnorm=1.0)\n","        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        # Instantiate a loss function.\n","        self.loss_fn = self.loss()\n","        self.train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","        train_loss = np.zeros(epochs)\n","        train_accur = np.zeros(epochs)\n","        val_accur = np.zeros(epochs)\n","        val_loss = np.zeros(epochs)\n","\n","        for epoch in range(epochs):\n","            print(\"\\nStart of epoch %d\" % (epoch,))\n","            start_time = time.time()\n","\n","            # Iterate over the batches of the dataset.\n","            for step, (x_batch_train, y_batch_train, Y_batch_train) in enumerate(Data_tr):\n","                # print(y_batch_train, Y_batch_train)\n","                loss_value = self.train_step(x_batch_train, Y_batch_train, y_batch_train)\n","\n","                # Log every 200 batches.\n","                if step % 10 == 0:\n","                    train_acc = self.train_acc_metric.result()\n","                    print(\n","                      \"Training loss (for one batch) at step %d: %.4f, Accuracy: %.4f\"\n","                      % (step, float(loss_value), float(train_acc))\n","                            )\n","                # print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n","\n","\n","\n","            # Run a validation loop at the end of each epoch.\n","            for x_batch_val, y_batch_val,Y_batch_val in Data_Val:\n","\n","                val_logits = model(x_batch_val, training=False)\n","\n","                val_loss_value = self.loss_fn(Y_batch_val, val_logits)\n","\n","                self.val_acc_metric.update_state(y_batch_val, val_logits[:,:self.K])\n","                \n","               # np.round(np.mean([model(x_batch_val, training= True) for sample in range(100)]), 2)\n","\n","\n","             # Display metrics at the end of each epoch.\n","            train_acc = self.train_acc_metric.result()\n","            val_acc = self.val_acc_metric.result()\n","\n","\n","            print('---- Training ----')\n","            print(\"Training loss: %.4f\" % (float(loss_value),))\n","            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","            # Reset training metrics at the end of each epoch\n","            self.train_acc_metric.reset_states()\n","            self.val_acc_metric.reset_states()\n","\n","\n","            train_loss[epoch] = float(loss_value)\n","            train_accur[epoch] = float(train_acc)\n","\n","            val_accur[epoch] = float(val_acc)\n","            val_loss[epoch] = float(val_loss_value) \n","\n","\n","            print('---- Validation ----')\n","            print(\"Validation loss: %.4f\" % (float(val_loss_value),))\n","            print(\"Validation acc: %.4f\" % (float(val_acc),))\n","\n","            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n","\n","        fig, (ax1, ax2) = plt.subplots(1, 2)\n","        fig.suptitle('Loss and accuracy')\n","        ax1.plot(range(1,epochs+1),train_loss)\n","        ax1.plot(range(1,epochs+1), val_loss)\n","        ax2.plot(range(1,epochs+1),train_accur)\n","        ax2.plot(range(1,epochs+1),val_accur)\n","        #plt.figure(figsize=(16,9))\n","        ax1.set(xlabel= 'Epoch', ylabel=\"Loss\")\n","        ax2.set(xlabel= 'Epoch',ylabel=\"Accuracy\")\n","        ax1.legend(['Training_loss', 'Validation_loss'])\n","        ax2.legend(['Training', 'Validation'])\n","        ax1.grid()\n","        ax2.grid()\n","        plt.show()\n","        return self.model\n","\n","    def eval_model(self, Data):\n","        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","        for x_batch_val, y_batch_val in Data:\n","            self.test_step(x_batch_val, y_batch_val)\n","\n","        val_acc = self.val_acc_metric.result()\n","        self.val_acc_metric.reset_states()\n","        return val_acc\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":15,"id":"37008c2a","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:41.756645Z","iopub.status.busy":"2023-02-06T14:27:41.756366Z","iopub.status.idle":"2023-02-06T14:27:41.76434Z","shell.execute_reply":"2023-02-06T14:27:41.763517Z"},"id":"4l-_pkpaBkSv","papermill":{"duration":0.017905,"end_time":"2023-02-06T14:27:41.766324","exception":false,"start_time":"2023-02-06T14:27:41.748419","status":"completed"},"tags":[]},"outputs":[],"source":["def custom_loss(y_true, y_pred):\n","  # print(y_true,y_pred)\n","  K = 2 #len(np.unique(y_true))\n","  R = 5\n","  q = 0.1\n","  pred = y_pred[:, K]\n","  pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n","  ann_ = y_pred[:,  K:]\n","  # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n","  Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=K, axis=1)\n","  Y_hat = tf.repeat(tf.expand_dims(pred,-1), R, axis = -1)\n","\n","  p_gcce = Y_true*(1 - Y_hat**q)/q\n","  temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n","  temp2 = (1 - ann_)*(1-(1/K)**q)/q*tf.reduce_sum(Y_true,axis=1)\n","  return tf.math.reduce_sum((temp1 + temp2))\n","\n"]},{"cell_type":"code","execution_count":16,"id":"1e228afc","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:41.781463Z","iopub.status.busy":"2023-02-06T14:27:41.781147Z","iopub.status.idle":"2023-02-06T14:27:41.792664Z","shell.execute_reply":"2023-02-06T14:27:41.791537Z"},"id":"Z-fV95n3GEqa","papermill":{"duration":0.021496,"end_time":"2023-02-06T14:27:41.794914","exception":false,"start_time":"2023-02-06T14:27:41.773418","status":"completed"},"tags":[]},"outputs":[],"source":["MA = MultipleAnnotators_Classification(2, 5, 0.001)\n"," \n","def create_model():\n","   \n","    l1 = 1e-2\n","    # Block 1\n","    inputs = keras.layers.Input(shape=(150, 150, 3), name='entrada')\n","    x = keras.layers.BatchNormalization()(inputs)\n","    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\" , name=\"block1_conv1\")(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n","\n","\n","    # Block 2\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", name=\"block2_conv1\")(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    #x = keras.layers.Dropout(0.2)(x)\n","    \n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n","\n","    # Block 3\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block3_conv1\" )(x)             \n","    x = keras.layers.BatchNormalization()(x)\n","   # x = keras.layers.Dropout(0.2)(x)\n","   \n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n","    \n","    # Block 4\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block4_conv1\")(x)            \n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n","    #x = keras.layers.Dropout(0.2)(x)\n","    \n","    #x = keras.layers.GlobalAveragePooling2D()(x)\n","   \n","    x = keras.layers.Flatten()(x)\n","    #x = keras.layers.Dropout(0.5)(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Dense(128, activation='relu')(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Dropout(0.5)(x)\n","    output = MA.CrowdLayer(x)\n","    model = keras.Model(inputs=inputs,outputs=output)\n","\n","    return model\n","  \n","  "]},{"cell_type":"code","execution_count":17,"id":"cd329b6c","metadata":{"execution":{"iopub.execute_input":"2023-02-06T14:27:41.810073Z","iopub.status.busy":"2023-02-06T14:27:41.809814Z","iopub.status.idle":"2023-02-06T16:58:40.639906Z","shell.execute_reply":"2023-02-06T16:58:40.63544Z"},"papermill":{"duration":9059.059655,"end_time":"2023-02-06T16:58:40.861582","exception":false,"start_time":"2023-02-06T14:27:41.801927","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-06 14:27:45.878071: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 499.8174, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 417.3527, Accuracy: 0.5709\n","Training loss (for one batch) at step 20: 495.1985, Accuracy: 0.5562\n","Training loss (for one batch) at step 30: 517.4245, Accuracy: 0.5565\n","Training loss (for one batch) at step 40: 436.8000, Accuracy: 0.5532\n","Training loss (for one batch) at step 50: 433.8491, Accuracy: 0.5480\n","Training loss (for one batch) at step 60: 427.1490, Accuracy: 0.5551\n","Training loss (for one batch) at step 70: 437.3154, Accuracy: 0.5549\n","Training loss (for one batch) at step 80: 434.5520, Accuracy: 0.5537\n","Training loss (for one batch) at step 90: 485.1485, Accuracy: 0.5529\n","Training loss (for one batch) at step 100: 423.8014, Accuracy: 0.5553\n","Training loss (for one batch) at step 110: 421.6901, Accuracy: 0.5586\n","Training loss (for one batch) at step 120: 448.2731, Accuracy: 0.5621\n","Training loss (for one batch) at step 130: 414.9524, Accuracy: 0.5627\n","Training loss (for one batch) at step 140: 440.5935, Accuracy: 0.5621\n","---- Training ----\n","Training loss: 380.4025\n","Training acc over epoch: 0.5629\n","---- Validation ----\n","Validation loss: 89.3483\n","Validation acc: 0.5134\n","Time taken: 61.68s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 401.6354, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 412.0300, Accuracy: 0.5864\n","Training loss (for one batch) at step 20: 412.2226, Accuracy: 0.5876\n","Training loss (for one batch) at step 30: 416.1606, Accuracy: 0.5945\n","Training loss (for one batch) at step 40: 396.6981, Accuracy: 0.5988\n","Training loss (for one batch) at step 50: 433.8810, Accuracy: 0.5951\n","Training loss (for one batch) at step 60: 413.0230, Accuracy: 0.6000\n","Training loss (for one batch) at step 70: 423.7108, Accuracy: 0.5972\n","Training loss (for one batch) at step 80: 377.0972, Accuracy: 0.6004\n","Training loss (for one batch) at step 90: 399.9095, Accuracy: 0.6011\n","Training loss (for one batch) at step 100: 421.8521, Accuracy: 0.6001\n","Training loss (for one batch) at step 110: 379.4671, Accuracy: 0.6019\n","Training loss (for one batch) at step 120: 411.5949, Accuracy: 0.6043\n","Training loss (for one batch) at step 130: 416.0682, Accuracy: 0.6044\n","Training loss (for one batch) at step 140: 390.5247, Accuracy: 0.6046\n","---- Training ----\n","Training loss: 349.9677\n","Training acc over epoch: 0.6056\n","---- Validation ----\n","Validation loss: 93.7645\n","Validation acc: 0.5322\n","Time taken: 9.84s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 380.3620, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 371.3869, Accuracy: 0.6445\n","Training loss (for one batch) at step 20: 365.6732, Accuracy: 0.6433\n","Training loss (for one batch) at step 30: 358.6793, Accuracy: 0.6406\n","Training loss (for one batch) at step 40: 358.8151, Accuracy: 0.6393\n","Training loss (for one batch) at step 50: 395.9088, Accuracy: 0.6390\n","Training loss (for one batch) at step 60: 365.2747, Accuracy: 0.6370\n","Training loss (for one batch) at step 70: 360.3681, Accuracy: 0.6368\n","Training loss (for one batch) at step 80: 380.7638, Accuracy: 0.6315\n","Training loss (for one batch) at step 90: 382.4431, Accuracy: 0.6308\n","Training loss (for one batch) at step 100: 386.9939, Accuracy: 0.6318\n","Training loss (for one batch) at step 110: 363.6733, Accuracy: 0.6322\n","Training loss (for one batch) at step 120: 396.8258, Accuracy: 0.6317\n","Training loss (for one batch) at step 130: 358.3638, Accuracy: 0.6328\n","Training loss (for one batch) at step 140: 383.1042, Accuracy: 0.6329\n","---- Training ----\n","Training loss: 342.5185\n","Training acc over epoch: 0.6329\n","---- Validation ----\n","Validation loss: 75.1523\n","Validation acc: 0.6300\n","Time taken: 9.74s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 380.2181, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 377.2034, Accuracy: 0.6618\n","Training loss (for one batch) at step 20: 365.9045, Accuracy: 0.6557\n","Training loss (for one batch) at step 30: 364.8375, Accuracy: 0.6523\n","Training loss (for one batch) at step 40: 365.6963, Accuracy: 0.6546\n","Training loss (for one batch) at step 50: 358.2010, Accuracy: 0.6543\n","Training loss (for one batch) at step 60: 375.7340, Accuracy: 0.6518\n","Training loss (for one batch) at step 70: 363.8657, Accuracy: 0.6524\n","Training loss (for one batch) at step 80: 380.1952, Accuracy: 0.6500\n","Training loss (for one batch) at step 90: 377.3872, Accuracy: 0.6478\n","Training loss (for one batch) at step 100: 343.0252, Accuracy: 0.6482\n","Training loss (for one batch) at step 110: 354.4338, Accuracy: 0.6497\n","Training loss (for one batch) at step 120: 349.0388, Accuracy: 0.6530\n","Training loss (for one batch) at step 130: 358.7388, Accuracy: 0.6529\n","Training loss (for one batch) at step 140: 352.7457, Accuracy: 0.6530\n","---- Training ----\n","Training loss: 312.1616\n","Training acc over epoch: 0.6537\n","---- Validation ----\n","Validation loss: 73.7726\n","Validation acc: 0.6967\n","Time taken: 10.48s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 322.2693, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 338.6504, Accuracy: 0.6791\n","Training loss (for one batch) at step 20: 347.1219, Accuracy: 0.6757\n","Training loss (for one batch) at step 30: 352.9778, Accuracy: 0.6729\n","Training loss (for one batch) at step 40: 345.0679, Accuracy: 0.6688\n","Training loss (for one batch) at step 50: 346.8672, Accuracy: 0.6724\n","Training loss (for one batch) at step 60: 329.1732, Accuracy: 0.6708\n","Training loss (for one batch) at step 70: 353.5898, Accuracy: 0.6699\n","Training loss (for one batch) at step 80: 339.3427, Accuracy: 0.6712\n","Training loss (for one batch) at step 90: 358.8564, Accuracy: 0.6723\n","Training loss (for one batch) at step 100: 350.8319, Accuracy: 0.6720\n","Training loss (for one batch) at step 110: 345.4066, Accuracy: 0.6721\n","Training loss (for one batch) at step 120: 321.7917, Accuracy: 0.6721\n","Training loss (for one batch) at step 130: 347.6348, Accuracy: 0.6714\n","Training loss (for one batch) at step 140: 343.9502, Accuracy: 0.6726\n","---- Training ----\n","Training loss: 302.4982\n","Training acc over epoch: 0.6728\n","---- Validation ----\n","Validation loss: 72.7400\n","Validation acc: 0.7058\n","Time taken: 9.92s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 316.9156, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 367.7045, Accuracy: 0.7073\n","Training loss (for one batch) at step 20: 345.0109, Accuracy: 0.6890\n","Training loss (for one batch) at step 30: 353.2136, Accuracy: 0.6826\n","Training loss (for one batch) at step 40: 331.6494, Accuracy: 0.6807\n","Training loss (for one batch) at step 50: 354.0005, Accuracy: 0.6857\n","Training loss (for one batch) at step 60: 320.7467, Accuracy: 0.6874\n","Training loss (for one batch) at step 70: 306.6889, Accuracy: 0.6879\n","Training loss (for one batch) at step 80: 346.7151, Accuracy: 0.6846\n","Training loss (for one batch) at step 90: 333.0264, Accuracy: 0.6814\n","Training loss (for one batch) at step 100: 312.8938, Accuracy: 0.6826\n","Training loss (for one batch) at step 110: 339.9150, Accuracy: 0.6836\n","Training loss (for one batch) at step 120: 348.0907, Accuracy: 0.6847\n","Training loss (for one batch) at step 130: 344.8629, Accuracy: 0.6848\n","Training loss (for one batch) at step 140: 341.6884, Accuracy: 0.6862\n","---- Training ----\n","Training loss: 327.8758\n","Training acc over epoch: 0.6865\n","---- Validation ----\n","Validation loss: 72.3500\n","Validation acc: 0.7155\n","Time taken: 9.67s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 326.7017, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 329.0497, Accuracy: 0.7000\n","Training loss (for one batch) at step 20: 311.5078, Accuracy: 0.6971\n","Training loss (for one batch) at step 30: 308.3211, Accuracy: 0.6997\n","Training loss (for one batch) at step 40: 334.9770, Accuracy: 0.6941\n","Training loss (for one batch) at step 50: 333.8188, Accuracy: 0.7010\n","Training loss (for one batch) at step 60: 320.7678, Accuracy: 0.7054\n","Training loss (for one batch) at step 70: 330.9243, Accuracy: 0.7038\n","Training loss (for one batch) at step 80: 333.6037, Accuracy: 0.7046\n","Training loss (for one batch) at step 90: 352.0060, Accuracy: 0.7037\n","Training loss (for one batch) at step 100: 327.5163, Accuracy: 0.7033\n","Training loss (for one batch) at step 110: 335.0466, Accuracy: 0.7017\n","Training loss (for one batch) at step 120: 314.6845, Accuracy: 0.7011\n","Training loss (for one batch) at step 130: 321.7050, Accuracy: 0.7001\n","Training loss (for one batch) at step 140: 327.0804, Accuracy: 0.6996\n","---- Training ----\n","Training loss: 288.6072\n","Training acc over epoch: 0.7004\n","---- Validation ----\n","Validation loss: 71.3272\n","Validation acc: 0.7163\n","Time taken: 9.79s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 307.7511, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 307.9276, Accuracy: 0.7209\n","Training loss (for one batch) at step 20: 339.2914, Accuracy: 0.7148\n","Training loss (for one batch) at step 30: 335.8093, Accuracy: 0.7174\n","Training loss (for one batch) at step 40: 320.4383, Accuracy: 0.7193\n","Training loss (for one batch) at step 50: 313.6727, Accuracy: 0.7186\n","Training loss (for one batch) at step 60: 332.4274, Accuracy: 0.7164\n","Training loss (for one batch) at step 70: 325.6904, Accuracy: 0.7155\n","Training loss (for one batch) at step 80: 337.0674, Accuracy: 0.7138\n","Training loss (for one batch) at step 90: 323.5823, Accuracy: 0.7118\n","Training loss (for one batch) at step 100: 326.5217, Accuracy: 0.7137\n","Training loss (for one batch) at step 110: 317.8847, Accuracy: 0.7148\n","Training loss (for one batch) at step 120: 305.6598, Accuracy: 0.7140\n","Training loss (for one batch) at step 130: 302.9687, Accuracy: 0.7134\n","Training loss (for one batch) at step 140: 312.5416, Accuracy: 0.7142\n","---- Training ----\n","Training loss: 279.7455\n","Training acc over epoch: 0.7153\n","---- Validation ----\n","Validation loss: 77.6288\n","Validation acc: 0.6937\n","Time taken: 9.57s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 315.0819, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 318.2516, Accuracy: 0.7373\n","Training loss (for one batch) at step 20: 313.8016, Accuracy: 0.7348\n","Training loss (for one batch) at step 30: 333.9250, Accuracy: 0.7323\n","Training loss (for one batch) at step 40: 314.5671, Accuracy: 0.7300\n","Training loss (for one batch) at step 50: 329.6407, Accuracy: 0.7314\n","Training loss (for one batch) at step 60: 298.0911, Accuracy: 0.7320\n","Training loss (for one batch) at step 70: 325.5587, Accuracy: 0.7269\n","Training loss (for one batch) at step 80: 322.5449, Accuracy: 0.7235\n","Training loss (for one batch) at step 90: 321.7443, Accuracy: 0.7210\n","Training loss (for one batch) at step 100: 322.4958, Accuracy: 0.7207\n","Training loss (for one batch) at step 110: 314.2064, Accuracy: 0.7197\n","Training loss (for one batch) at step 120: 303.6586, Accuracy: 0.7197\n","Training loss (for one batch) at step 130: 312.0672, Accuracy: 0.7211\n","Training loss (for one batch) at step 140: 316.9904, Accuracy: 0.7221\n","---- Training ----\n","Training loss: 270.5768\n","Training acc over epoch: 0.7228\n","---- Validation ----\n","Validation loss: 73.0060\n","Validation acc: 0.6985\n","Time taken: 9.67s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 310.3579, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 321.3575, Accuracy: 0.7327\n","Training loss (for one batch) at step 20: 306.7059, Accuracy: 0.7314\n","Training loss (for one batch) at step 30: 313.8938, Accuracy: 0.7306\n","Training loss (for one batch) at step 40: 321.4273, Accuracy: 0.7295\n","Training loss (for one batch) at step 50: 308.3231, Accuracy: 0.7337\n","Training loss (for one batch) at step 60: 310.2330, Accuracy: 0.7339\n","Training loss (for one batch) at step 70: 302.6532, Accuracy: 0.7366\n","Training loss (for one batch) at step 80: 318.8044, Accuracy: 0.7340\n","Training loss (for one batch) at step 90: 318.4057, Accuracy: 0.7323\n","Training loss (for one batch) at step 100: 311.9531, Accuracy: 0.7311\n","Training loss (for one batch) at step 110: 307.5638, Accuracy: 0.7314\n","Training loss (for one batch) at step 120: 294.8524, Accuracy: 0.7335\n","Training loss (for one batch) at step 130: 296.3249, Accuracy: 0.7337\n","Training loss (for one batch) at step 140: 320.0692, Accuracy: 0.7328\n","---- Training ----\n","Training loss: 274.9137\n","Training acc over epoch: 0.7334\n","---- Validation ----\n","Validation loss: 78.5865\n","Validation acc: 0.7319\n","Time taken: 10.47s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 311.8062, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 325.0893, Accuracy: 0.7318\n","Training loss (for one batch) at step 20: 313.7551, Accuracy: 0.7362\n","Training loss (for one batch) at step 30: 304.2447, Accuracy: 0.7384\n","Training loss (for one batch) at step 40: 310.5277, Accuracy: 0.7378\n","Training loss (for one batch) at step 50: 293.7604, Accuracy: 0.7473\n","Training loss (for one batch) at step 60: 311.4313, Accuracy: 0.7461\n","Training loss (for one batch) at step 70: 300.1535, Accuracy: 0.7439\n","Training loss (for one batch) at step 80: 309.6306, Accuracy: 0.7412\n","Training loss (for one batch) at step 90: 303.9570, Accuracy: 0.7401\n","Training loss (for one batch) at step 100: 309.2512, Accuracy: 0.7422\n","Training loss (for one batch) at step 110: 308.0401, Accuracy: 0.7433\n","Training loss (for one batch) at step 120: 295.8338, Accuracy: 0.7443\n","Training loss (for one batch) at step 130: 302.6317, Accuracy: 0.7448\n","Training loss (for one batch) at step 140: 286.8918, Accuracy: 0.7452\n","---- Training ----\n","Training loss: 262.3422\n","Training acc over epoch: 0.7448\n","---- Validation ----\n","Validation loss: 75.2734\n","Validation acc: 0.7192\n","Time taken: 9.71s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 296.9203, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 301.3925, Accuracy: 0.7709\n","Training loss (for one batch) at step 20: 286.4999, Accuracy: 0.7614\n","Training loss (for one batch) at step 30: 296.4302, Accuracy: 0.7597\n","Training loss (for one batch) at step 40: 308.1405, Accuracy: 0.7615\n","Training loss (for one batch) at step 50: 292.6508, Accuracy: 0.7600\n","Training loss (for one batch) at step 60: 296.5093, Accuracy: 0.7611\n","Training loss (for one batch) at step 70: 296.3571, Accuracy: 0.7630\n","Training loss (for one batch) at step 80: 316.2054, Accuracy: 0.7609\n","Training loss (for one batch) at step 90: 293.2539, Accuracy: 0.7584\n","Training loss (for one batch) at step 100: 295.7631, Accuracy: 0.7565\n","Training loss (for one batch) at step 110: 302.4059, Accuracy: 0.7568\n","Training loss (for one batch) at step 120: 288.8061, Accuracy: 0.7565\n","Training loss (for one batch) at step 130: 318.7933, Accuracy: 0.7550\n","Training loss (for one batch) at step 140: 319.1435, Accuracy: 0.7533\n","---- Training ----\n","Training loss: 271.9563\n","Training acc over epoch: 0.7558\n","---- Validation ----\n","Validation loss: 66.8496\n","Validation acc: 0.7174\n","Time taken: 9.53s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 304.4655, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 293.6890, Accuracy: 0.7573\n","Training loss (for one batch) at step 20: 299.8173, Accuracy: 0.7533\n","Training loss (for one batch) at step 30: 295.4745, Accuracy: 0.7606\n","Training loss (for one batch) at step 40: 285.8755, Accuracy: 0.7639\n","Training loss (for one batch) at step 50: 294.9932, Accuracy: 0.7682\n","Training loss (for one batch) at step 60: 298.0158, Accuracy: 0.7685\n","Training loss (for one batch) at step 70: 301.7595, Accuracy: 0.7675\n","Training loss (for one batch) at step 80: 298.7753, Accuracy: 0.7640\n","Training loss (for one batch) at step 90: 294.5325, Accuracy: 0.7642\n","Training loss (for one batch) at step 100: 294.0314, Accuracy: 0.7645\n","Training loss (for one batch) at step 110: 288.1186, Accuracy: 0.7650\n","Training loss (for one batch) at step 120: 307.4528, Accuracy: 0.7655\n","Training loss (for one batch) at step 130: 307.7210, Accuracy: 0.7655\n","Training loss (for one batch) at step 140: 289.5885, Accuracy: 0.7662\n","---- Training ----\n","Training loss: 250.2145\n","Training acc over epoch: 0.7653\n","---- Validation ----\n","Validation loss: 69.5144\n","Validation acc: 0.7141\n","Time taken: 9.63s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 308.6454, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 283.0355, Accuracy: 0.7655\n","Training loss (for one batch) at step 20: 300.7612, Accuracy: 0.7571\n","Training loss (for one batch) at step 30: 281.2237, Accuracy: 0.7610\n","Training loss (for one batch) at step 40: 280.1538, Accuracy: 0.7624\n","Training loss (for one batch) at step 50: 289.5826, Accuracy: 0.7635\n","Training loss (for one batch) at step 60: 281.9497, Accuracy: 0.7662\n","Training loss (for one batch) at step 70: 304.7301, Accuracy: 0.7627\n","Training loss (for one batch) at step 80: 295.5024, Accuracy: 0.7610\n","Training loss (for one batch) at step 90: 286.5792, Accuracy: 0.7621\n","Training loss (for one batch) at step 100: 282.8946, Accuracy: 0.7619\n","Training loss (for one batch) at step 110: 299.0194, Accuracy: 0.7654\n","Training loss (for one batch) at step 120: 309.9044, Accuracy: 0.7650\n","Training loss (for one batch) at step 130: 308.8960, Accuracy: 0.7647\n","Training loss (for one batch) at step 140: 302.1743, Accuracy: 0.7665\n","---- Training ----\n","Training loss: 251.6555\n","Training acc over epoch: 0.7676\n","---- Validation ----\n","Validation loss: 83.1796\n","Validation acc: 0.7144\n","Time taken: 9.77s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 284.3557, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 283.7570, Accuracy: 0.7818\n","Training loss (for one batch) at step 20: 290.1455, Accuracy: 0.7819\n","Training loss (for one batch) at step 30: 273.0179, Accuracy: 0.7739\n","Training loss (for one batch) at step 40: 292.2597, Accuracy: 0.7732\n","Training loss (for one batch) at step 50: 289.5660, Accuracy: 0.7773\n","Training loss (for one batch) at step 60: 282.5360, Accuracy: 0.7789\n","Training loss (for one batch) at step 70: 304.2601, Accuracy: 0.7775\n","Training loss (for one batch) at step 80: 269.3367, Accuracy: 0.7751\n","Training loss (for one batch) at step 90: 302.4066, Accuracy: 0.7749\n","Training loss (for one batch) at step 100: 284.0547, Accuracy: 0.7760\n","Training loss (for one batch) at step 110: 288.6634, Accuracy: 0.7766\n","Training loss (for one batch) at step 120: 279.5899, Accuracy: 0.7757\n","Training loss (for one batch) at step 130: 301.1478, Accuracy: 0.7751\n","Training loss (for one batch) at step 140: 287.5948, Accuracy: 0.7745\n","---- Training ----\n","Training loss: 247.3041\n","Training acc over epoch: 0.7740\n","---- Validation ----\n","Validation loss: 63.1833\n","Validation acc: 0.7125\n","Time taken: 9.71s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 275.4424, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 266.8047, Accuracy: 0.7973\n","Training loss (for one batch) at step 20: 286.5469, Accuracy: 0.7843\n","Training loss (for one batch) at step 30: 304.8398, Accuracy: 0.7810\n","Training loss (for one batch) at step 40: 288.8718, Accuracy: 0.7822\n","Training loss (for one batch) at step 50: 292.6041, Accuracy: 0.7849\n","Training loss (for one batch) at step 60: 296.2888, Accuracy: 0.7833\n","Training loss (for one batch) at step 70: 298.6552, Accuracy: 0.7813\n","Training loss (for one batch) at step 80: 271.6941, Accuracy: 0.7790\n","Training loss (for one batch) at step 90: 285.7315, Accuracy: 0.7775\n","Training loss (for one batch) at step 100: 271.7017, Accuracy: 0.7797\n","Training loss (for one batch) at step 110: 277.5394, Accuracy: 0.7793\n","Training loss (for one batch) at step 120: 281.1851, Accuracy: 0.7802\n","Training loss (for one batch) at step 130: 299.5507, Accuracy: 0.7792\n","Training loss (for one batch) at step 140: 281.7928, Accuracy: 0.7787\n","---- Training ----\n","Training loss: 254.1168\n","Training acc over epoch: 0.7789\n","---- Validation ----\n","Validation loss: 70.0762\n","Validation acc: 0.7152\n","Time taken: 9.56s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 283.1644, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 269.3552, Accuracy: 0.7882\n","Training loss (for one batch) at step 20: 270.5990, Accuracy: 0.7962\n","Training loss (for one batch) at step 30: 276.8746, Accuracy: 0.7913\n","Training loss (for one batch) at step 40: 278.8081, Accuracy: 0.7849\n","Training loss (for one batch) at step 50: 287.4105, Accuracy: 0.7886\n","Training loss (for one batch) at step 60: 261.0534, Accuracy: 0.7916\n","Training loss (for one batch) at step 70: 280.5903, Accuracy: 0.7914\n","Training loss (for one batch) at step 80: 305.7946, Accuracy: 0.7874\n","Training loss (for one batch) at step 90: 282.0331, Accuracy: 0.7854\n","Training loss (for one batch) at step 100: 288.3315, Accuracy: 0.7842\n","Training loss (for one batch) at step 110: 272.1946, Accuracy: 0.7842\n","Training loss (for one batch) at step 120: 288.0819, Accuracy: 0.7845\n","Training loss (for one batch) at step 130: 285.1228, Accuracy: 0.7844\n","Training loss (for one batch) at step 140: 264.4659, Accuracy: 0.7847\n","---- Training ----\n","Training loss: 236.3416\n","Training acc over epoch: 0.7848\n","---- Validation ----\n","Validation loss: 61.4192\n","Validation acc: 0.7195\n","Time taken: 9.77s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 286.4347, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 274.0612, Accuracy: 0.7918\n","Training loss (for one batch) at step 20: 275.7314, Accuracy: 0.7829\n","Training loss (for one batch) at step 30: 281.0282, Accuracy: 0.7839\n","Training loss (for one batch) at step 40: 278.9643, Accuracy: 0.7863\n","Training loss (for one batch) at step 50: 263.8884, Accuracy: 0.7873\n","Training loss (for one batch) at step 60: 281.7768, Accuracy: 0.7892\n","Training loss (for one batch) at step 70: 280.1490, Accuracy: 0.7886\n","Training loss (for one batch) at step 80: 278.0842, Accuracy: 0.7880\n","Training loss (for one batch) at step 90: 274.9206, Accuracy: 0.7853\n","Training loss (for one batch) at step 100: 284.6377, Accuracy: 0.7827\n","Training loss (for one batch) at step 110: 272.9237, Accuracy: 0.7844\n","Training loss (for one batch) at step 120: 271.3307, Accuracy: 0.7860\n","Training loss (for one batch) at step 130: 270.3390, Accuracy: 0.7867\n","Training loss (for one batch) at step 140: 275.4255, Accuracy: 0.7867\n","---- Training ----\n","Training loss: 244.8389\n","Training acc over epoch: 0.7861\n","---- Validation ----\n","Validation loss: 62.3679\n","Validation acc: 0.7163\n","Time taken: 9.62s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 261.1313, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 273.1465, Accuracy: 0.7955\n","Training loss (for one batch) at step 20: 280.3771, Accuracy: 0.7890\n","Training loss (for one batch) at step 30: 268.2046, Accuracy: 0.7877\n","Training loss (for one batch) at step 40: 264.5122, Accuracy: 0.7893\n","Training loss (for one batch) at step 50: 270.5028, Accuracy: 0.7941\n","Training loss (for one batch) at step 60: 271.2436, Accuracy: 0.7943\n","Training loss (for one batch) at step 70: 270.0958, Accuracy: 0.7942\n","Training loss (for one batch) at step 80: 289.6936, Accuracy: 0.7931\n","Training loss (for one batch) at step 90: 285.4735, Accuracy: 0.7905\n","Training loss (for one batch) at step 100: 273.9890, Accuracy: 0.7911\n","Training loss (for one batch) at step 110: 257.4946, Accuracy: 0.7927\n","Training loss (for one batch) at step 120: 276.7903, Accuracy: 0.7913\n","Training loss (for one batch) at step 130: 268.9029, Accuracy: 0.7911\n","Training loss (for one batch) at step 140: 278.3646, Accuracy: 0.7915\n","---- Training ----\n","Training loss: 221.7372\n","Training acc over epoch: 0.7902\n","---- Validation ----\n","Validation loss: 71.5296\n","Validation acc: 0.7018\n","Time taken: 9.70s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 287.0661, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 270.3215, Accuracy: 0.8000\n","Training loss (for one batch) at step 20: 280.5371, Accuracy: 0.7952\n","Training loss (for one batch) at step 30: 273.3058, Accuracy: 0.8013\n","Training loss (for one batch) at step 40: 283.5128, Accuracy: 0.7973\n","Training loss (for one batch) at step 50: 261.2220, Accuracy: 0.8002\n","Training loss (for one batch) at step 60: 257.5144, Accuracy: 0.8016\n","Training loss (for one batch) at step 70: 273.5475, Accuracy: 0.7989\n","Training loss (for one batch) at step 80: 290.9027, Accuracy: 0.7979\n","Training loss (for one batch) at step 90: 277.7750, Accuracy: 0.7978\n","Training loss (for one batch) at step 100: 268.0762, Accuracy: 0.7960\n","Training loss (for one batch) at step 110: 258.9614, Accuracy: 0.7967\n","Training loss (for one batch) at step 120: 261.8503, Accuracy: 0.7972\n","Training loss (for one batch) at step 130: 258.4286, Accuracy: 0.7975\n","Training loss (for one batch) at step 140: 279.1687, Accuracy: 0.7978\n","---- Training ----\n","Training loss: 225.3756\n","Training acc over epoch: 0.7981\n","---- Validation ----\n","Validation loss: 78.4458\n","Validation acc: 0.7069\n","Time taken: 9.70s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 269.2266, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 271.6802, Accuracy: 0.8027\n","Training loss (for one batch) at step 20: 270.7282, Accuracy: 0.8090\n","Training loss (for one batch) at step 30: 260.9411, Accuracy: 0.8055\n","Training loss (for one batch) at step 40: 269.2730, Accuracy: 0.7995\n","Training loss (for one batch) at step 50: 252.4012, Accuracy: 0.8008\n","Training loss (for one batch) at step 60: 265.4134, Accuracy: 0.7993\n","Training loss (for one batch) at step 70: 259.1840, Accuracy: 0.7959\n","Training loss (for one batch) at step 80: 247.7363, Accuracy: 0.7942\n","Training loss (for one batch) at step 90: 289.5043, Accuracy: 0.7918\n","Training loss (for one batch) at step 100: 282.3046, Accuracy: 0.7902\n","Training loss (for one batch) at step 110: 272.0268, Accuracy: 0.7916\n","Training loss (for one batch) at step 120: 266.9478, Accuracy: 0.7921\n","Training loss (for one batch) at step 130: 272.3166, Accuracy: 0.7934\n","Training loss (for one batch) at step 140: 271.9189, Accuracy: 0.7933\n","---- Training ----\n","Training loss: 234.5761\n","Training acc over epoch: 0.7931\n","---- Validation ----\n","Validation loss: 76.0012\n","Validation acc: 0.7096\n","Time taken: 9.82s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 249.2544, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 270.9263, Accuracy: 0.8055\n","Training loss (for one batch) at step 20: 266.8354, Accuracy: 0.8071\n","Training loss (for one batch) at step 30: 273.0071, Accuracy: 0.7987\n","Training loss (for one batch) at step 40: 264.7624, Accuracy: 0.7946\n","Training loss (for one batch) at step 50: 277.7350, Accuracy: 0.8006\n","Training loss (for one batch) at step 60: 258.1729, Accuracy: 0.8026\n","Training loss (for one batch) at step 70: 276.9637, Accuracy: 0.8015\n","Training loss (for one batch) at step 80: 273.6439, Accuracy: 0.7957\n","Training loss (for one batch) at step 90: 256.7590, Accuracy: 0.7960\n","Training loss (for one batch) at step 100: 250.7914, Accuracy: 0.7968\n","Training loss (for one batch) at step 110: 257.3471, Accuracy: 0.7973\n","Training loss (for one batch) at step 120: 253.1193, Accuracy: 0.7971\n","Training loss (for one batch) at step 130: 248.7319, Accuracy: 0.7981\n","Training loss (for one batch) at step 140: 276.4878, Accuracy: 0.7974\n","---- Training ----\n","Training loss: 222.2799\n","Training acc over epoch: 0.7976\n","---- Validation ----\n","Validation loss: 76.9122\n","Validation acc: 0.6994\n","Time taken: 9.63s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 251.8392, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 273.1373, Accuracy: 0.8036\n","Training loss (for one batch) at step 20: 245.7420, Accuracy: 0.8000\n","Training loss (for one batch) at step 30: 269.2325, Accuracy: 0.7919\n","Training loss (for one batch) at step 40: 254.3063, Accuracy: 0.7934\n","Training loss (for one batch) at step 50: 259.6668, Accuracy: 0.7976\n","Training loss (for one batch) at step 60: 254.2091, Accuracy: 0.7979\n","Training loss (for one batch) at step 70: 267.9905, Accuracy: 0.7963\n","Training loss (for one batch) at step 80: 274.9420, Accuracy: 0.7947\n","Training loss (for one batch) at step 90: 258.6869, Accuracy: 0.7943\n","Training loss (for one batch) at step 100: 259.7324, Accuracy: 0.7943\n","Training loss (for one batch) at step 110: 258.8749, Accuracy: 0.7949\n","Training loss (for one batch) at step 120: 258.7508, Accuracy: 0.7977\n","Training loss (for one batch) at step 130: 238.9721, Accuracy: 0.7979\n","Training loss (for one batch) at step 140: 262.4558, Accuracy: 0.7991\n","---- Training ----\n","Training loss: 214.7170\n","Training acc over epoch: 0.7986\n","---- Validation ----\n","Validation loss: 74.3114\n","Validation acc: 0.7063\n","Time taken: 9.74s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 254.7822, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 249.1060, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 252.3150, Accuracy: 0.8076\n","Training loss (for one batch) at step 30: 267.9487, Accuracy: 0.8074\n","Training loss (for one batch) at step 40: 258.9608, Accuracy: 0.8100\n","Training loss (for one batch) at step 50: 233.1359, Accuracy: 0.8096\n","Training loss (for one batch) at step 60: 244.7977, Accuracy: 0.8041\n","Training loss (for one batch) at step 70: 260.3236, Accuracy: 0.8063\n","Training loss (for one batch) at step 80: 259.5628, Accuracy: 0.8004\n","Training loss (for one batch) at step 90: 268.0031, Accuracy: 0.8013\n","Training loss (for one batch) at step 100: 255.4855, Accuracy: 0.8015\n","Training loss (for one batch) at step 110: 271.7265, Accuracy: 0.8017\n","Training loss (for one batch) at step 120: 252.3615, Accuracy: 0.8018\n","Training loss (for one batch) at step 130: 258.2191, Accuracy: 0.8008\n","Training loss (for one batch) at step 140: 244.7858, Accuracy: 0.8004\n","---- Training ----\n","Training loss: 228.0107\n","Training acc over epoch: 0.8007\n","---- Validation ----\n","Validation loss: 82.9267\n","Validation acc: 0.7018\n","Time taken: 9.59s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 243.6529, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 245.8385, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 261.0462, Accuracy: 0.8019\n","Training loss (for one batch) at step 30: 271.5121, Accuracy: 0.8087\n","Training loss (for one batch) at step 40: 265.4540, Accuracy: 0.8029\n","Training loss (for one batch) at step 50: 252.9068, Accuracy: 0.8080\n","Training loss (for one batch) at step 60: 239.6669, Accuracy: 0.8095\n","Training loss (for one batch) at step 70: 269.3980, Accuracy: 0.8099\n","Training loss (for one batch) at step 80: 269.4832, Accuracy: 0.8049\n","Training loss (for one batch) at step 90: 260.5720, Accuracy: 0.8040\n","Training loss (for one batch) at step 100: 266.2416, Accuracy: 0.8055\n","Training loss (for one batch) at step 110: 252.7767, Accuracy: 0.8059\n","Training loss (for one batch) at step 120: 250.1666, Accuracy: 0.8060\n","Training loss (for one batch) at step 130: 235.9562, Accuracy: 0.8066\n","Training loss (for one batch) at step 140: 267.7930, Accuracy: 0.8055\n","---- Training ----\n","Training loss: 217.4878\n","Training acc over epoch: 0.8054\n","---- Validation ----\n","Validation loss: 70.8800\n","Validation acc: 0.7109\n","Time taken: 9.66s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 254.5559, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 242.6177, Accuracy: 0.8055\n","Training loss (for one batch) at step 20: 232.8304, Accuracy: 0.8100\n","Training loss (for one batch) at step 30: 254.0927, Accuracy: 0.8074\n","Training loss (for one batch) at step 40: 267.5963, Accuracy: 0.8120\n","Training loss (for one batch) at step 50: 237.1525, Accuracy: 0.8165\n","Training loss (for one batch) at step 60: 256.7430, Accuracy: 0.8161\n","Training loss (for one batch) at step 70: 282.0675, Accuracy: 0.8154\n","Training loss (for one batch) at step 80: 258.3649, Accuracy: 0.8122\n","Training loss (for one batch) at step 90: 266.4422, Accuracy: 0.8115\n","Training loss (for one batch) at step 100: 244.6179, Accuracy: 0.8100\n","Training loss (for one batch) at step 110: 245.9238, Accuracy: 0.8116\n","Training loss (for one batch) at step 120: 265.3755, Accuracy: 0.8124\n","Training loss (for one batch) at step 130: 259.0764, Accuracy: 0.8115\n","Training loss (for one batch) at step 140: 254.0219, Accuracy: 0.8109\n","---- Training ----\n","Training loss: 208.3311\n","Training acc over epoch: 0.8115\n","---- Validation ----\n","Validation loss: 82.3697\n","Validation acc: 0.7088\n","Time taken: 9.58s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 246.2280, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 250.3651, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 248.3431, Accuracy: 0.8257\n","Training loss (for one batch) at step 30: 242.5679, Accuracy: 0.8135\n","Training loss (for one batch) at step 40: 259.2390, Accuracy: 0.8166\n","Training loss (for one batch) at step 50: 243.9961, Accuracy: 0.8182\n","Training loss (for one batch) at step 60: 231.0233, Accuracy: 0.8170\n","Training loss (for one batch) at step 70: 248.7681, Accuracy: 0.8163\n","Training loss (for one batch) at step 80: 269.8913, Accuracy: 0.8125\n","Training loss (for one batch) at step 90: 249.8314, Accuracy: 0.8114\n","Training loss (for one batch) at step 100: 249.5396, Accuracy: 0.8094\n","Training loss (for one batch) at step 110: 247.4394, Accuracy: 0.8109\n","Training loss (for one batch) at step 120: 244.0094, Accuracy: 0.8123\n","Training loss (for one batch) at step 130: 259.7657, Accuracy: 0.8115\n","Training loss (for one batch) at step 140: 258.7309, Accuracy: 0.8108\n","---- Training ----\n","Training loss: 220.7126\n","Training acc over epoch: 0.8111\n","---- Validation ----\n","Validation loss: 67.2159\n","Validation acc: 0.6999\n","Time taken: 9.89s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 248.3405, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 264.6301, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 243.9135, Accuracy: 0.8257\n","Training loss (for one batch) at step 30: 264.5132, Accuracy: 0.8245\n","Training loss (for one batch) at step 40: 256.7426, Accuracy: 0.8205\n","Training loss (for one batch) at step 50: 251.1747, Accuracy: 0.8255\n","Training loss (for one batch) at step 60: 245.6319, Accuracy: 0.8241\n","Training loss (for one batch) at step 70: 242.0225, Accuracy: 0.8208\n","Training loss (for one batch) at step 80: 238.8710, Accuracy: 0.8174\n","Training loss (for one batch) at step 90: 247.3784, Accuracy: 0.8171\n","Training loss (for one batch) at step 100: 260.3456, Accuracy: 0.8160\n","Training loss (for one batch) at step 110: 247.5206, Accuracy: 0.8159\n","Training loss (for one batch) at step 120: 249.3836, Accuracy: 0.8160\n","Training loss (for one batch) at step 130: 236.1893, Accuracy: 0.8167\n","Training loss (for one batch) at step 140: 268.8261, Accuracy: 0.8165\n","---- Training ----\n","Training loss: 232.2924\n","Training acc over epoch: 0.8160\n","---- Validation ----\n","Validation loss: 74.1511\n","Validation acc: 0.7163\n","Time taken: 10.37s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 241.7523, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 256.1203, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 247.3249, Accuracy: 0.8114\n","Training loss (for one batch) at step 30: 244.8572, Accuracy: 0.8184\n","Training loss (for one batch) at step 40: 234.6306, Accuracy: 0.8159\n","Training loss (for one batch) at step 50: 241.9037, Accuracy: 0.8192\n","Training loss (for one batch) at step 60: 241.7030, Accuracy: 0.8189\n","Training loss (for one batch) at step 70: 241.4403, Accuracy: 0.8190\n","Training loss (for one batch) at step 80: 235.2543, Accuracy: 0.8181\n","Training loss (for one batch) at step 90: 255.4001, Accuracy: 0.8164\n","Training loss (for one batch) at step 100: 255.9400, Accuracy: 0.8137\n","Training loss (for one batch) at step 110: 248.9530, Accuracy: 0.8152\n","Training loss (for one batch) at step 120: 237.8143, Accuracy: 0.8168\n","Training loss (for one batch) at step 130: 250.8102, Accuracy: 0.8168\n","Training loss (for one batch) at step 140: 234.0806, Accuracy: 0.8146\n","---- Training ----\n","Training loss: 221.2499\n","Training acc over epoch: 0.8157\n","---- Validation ----\n","Validation loss: 73.6398\n","Validation acc: 0.6985\n","Time taken: 9.58s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 250.4451, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 248.9943, Accuracy: 0.8045\n","Training loss (for one batch) at step 20: 220.1432, Accuracy: 0.8181\n","Training loss (for one batch) at step 30: 252.9929, Accuracy: 0.8097\n","Training loss (for one batch) at step 40: 221.7041, Accuracy: 0.8144\n","Training loss (for one batch) at step 50: 233.3668, Accuracy: 0.8155\n","Training loss (for one batch) at step 60: 228.8225, Accuracy: 0.8154\n","Training loss (for one batch) at step 70: 247.6233, Accuracy: 0.8152\n","Training loss (for one batch) at step 80: 242.3249, Accuracy: 0.8141\n","Training loss (for one batch) at step 90: 266.7362, Accuracy: 0.8132\n","Training loss (for one batch) at step 100: 244.2534, Accuracy: 0.8122\n","Training loss (for one batch) at step 110: 226.5349, Accuracy: 0.8116\n","Training loss (for one batch) at step 120: 241.0284, Accuracy: 0.8131\n","Training loss (for one batch) at step 130: 236.7581, Accuracy: 0.8147\n","Training loss (for one batch) at step 140: 256.9763, Accuracy: 0.8145\n","---- Training ----\n","Training loss: 220.2234\n","Training acc over epoch: 0.8145\n","---- Validation ----\n","Validation loss: 70.9833\n","Validation acc: 0.6961\n","Time taken: 9.69s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 240.2110, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 257.1552, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 241.6981, Accuracy: 0.8062\n","Training loss (for one batch) at step 30: 239.4058, Accuracy: 0.8081\n","Training loss (for one batch) at step 40: 255.5287, Accuracy: 0.8093\n","Training loss (for one batch) at step 50: 234.3710, Accuracy: 0.8184\n","Training loss (for one batch) at step 60: 222.2800, Accuracy: 0.8215\n","Training loss (for one batch) at step 70: 249.7809, Accuracy: 0.8187\n","Training loss (for one batch) at step 80: 247.4206, Accuracy: 0.8183\n","Training loss (for one batch) at step 90: 240.8690, Accuracy: 0.8170\n","Training loss (for one batch) at step 100: 231.3708, Accuracy: 0.8182\n","Training loss (for one batch) at step 110: 248.3986, Accuracy: 0.8188\n","Training loss (for one batch) at step 120: 253.7074, Accuracy: 0.8199\n","Training loss (for one batch) at step 130: 246.8803, Accuracy: 0.8194\n","Training loss (for one batch) at step 140: 240.5248, Accuracy: 0.8196\n","---- Training ----\n","Training loss: 201.1444\n","Training acc over epoch: 0.8205\n","---- Validation ----\n","Validation loss: 70.8598\n","Validation acc: 0.7152\n","Time taken: 9.57s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 235.3650, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 238.8591, Accuracy: 0.8218\n","Training loss (for one batch) at step 20: 250.4523, Accuracy: 0.8205\n","Training loss (for one batch) at step 30: 221.2367, Accuracy: 0.8181\n","Training loss (for one batch) at step 40: 218.5978, Accuracy: 0.8171\n","Training loss (for one batch) at step 50: 240.5612, Accuracy: 0.8204\n","Training loss (for one batch) at step 60: 246.1829, Accuracy: 0.8234\n","Training loss (for one batch) at step 70: 232.1558, Accuracy: 0.8208\n","Training loss (for one batch) at step 80: 272.6910, Accuracy: 0.8193\n","Training loss (for one batch) at step 90: 243.2771, Accuracy: 0.8197\n","Training loss (for one batch) at step 100: 251.9560, Accuracy: 0.8179\n","Training loss (for one batch) at step 110: 236.7314, Accuracy: 0.8197\n","Training loss (for one batch) at step 120: 243.7774, Accuracy: 0.8191\n","Training loss (for one batch) at step 130: 241.8370, Accuracy: 0.8201\n","Training loss (for one batch) at step 140: 255.8399, Accuracy: 0.8199\n","---- Training ----\n","Training loss: 219.0495\n","Training acc over epoch: 0.8209\n","---- Validation ----\n","Validation loss: 78.2174\n","Validation acc: 0.6945\n","Time taken: 9.62s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 261.8496, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 250.9485, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 233.3438, Accuracy: 0.8205\n","Training loss (for one batch) at step 30: 230.8369, Accuracy: 0.8213\n","Training loss (for one batch) at step 40: 240.8082, Accuracy: 0.8207\n","Training loss (for one batch) at step 50: 232.5352, Accuracy: 0.8218\n","Training loss (for one batch) at step 60: 228.8831, Accuracy: 0.8221\n","Training loss (for one batch) at step 70: 241.4626, Accuracy: 0.8225\n","Training loss (for one batch) at step 80: 220.2527, Accuracy: 0.8211\n","Training loss (for one batch) at step 90: 258.6848, Accuracy: 0.8185\n","Training loss (for one batch) at step 100: 240.8549, Accuracy: 0.8186\n","Training loss (for one batch) at step 110: 227.5682, Accuracy: 0.8205\n","Training loss (for one batch) at step 120: 235.9788, Accuracy: 0.8204\n","Training loss (for one batch) at step 130: 228.3001, Accuracy: 0.8217\n","Training loss (for one batch) at step 140: 248.5804, Accuracy: 0.8219\n","---- Training ----\n","Training loss: 211.1579\n","Training acc over epoch: 0.8221\n","---- Validation ----\n","Validation loss: 82.6062\n","Validation acc: 0.7045\n","Time taken: 9.75s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 239.1549, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 223.3627, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 231.2509, Accuracy: 0.8152\n","Training loss (for one batch) at step 30: 232.1986, Accuracy: 0.8168\n","Training loss (for one batch) at step 40: 221.4433, Accuracy: 0.8183\n","Training loss (for one batch) at step 50: 230.2722, Accuracy: 0.8216\n","Training loss (for one batch) at step 60: 253.3837, Accuracy: 0.8246\n","Training loss (for one batch) at step 70: 218.9214, Accuracy: 0.8217\n","Training loss (for one batch) at step 80: 241.2599, Accuracy: 0.8200\n","Training loss (for one batch) at step 90: 227.8666, Accuracy: 0.8207\n","Training loss (for one batch) at step 100: 208.4311, Accuracy: 0.8206\n","Training loss (for one batch) at step 110: 243.3914, Accuracy: 0.8224\n","Training loss (for one batch) at step 120: 235.5283, Accuracy: 0.8229\n","Training loss (for one batch) at step 130: 246.2702, Accuracy: 0.8224\n","Training loss (for one batch) at step 140: 237.1437, Accuracy: 0.8216\n","---- Training ----\n","Training loss: 199.3507\n","Training acc over epoch: 0.8229\n","---- Validation ----\n","Validation loss: 96.8237\n","Validation acc: 0.7058\n","Time taken: 9.58s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 245.0250, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 220.6778, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 234.6695, Accuracy: 0.8248\n","Training loss (for one batch) at step 30: 223.5953, Accuracy: 0.8203\n","Training loss (for one batch) at step 40: 225.2344, Accuracy: 0.8188\n","Training loss (for one batch) at step 50: 221.8347, Accuracy: 0.8241\n","Training loss (for one batch) at step 60: 254.2512, Accuracy: 0.8234\n","Training loss (for one batch) at step 70: 237.4907, Accuracy: 0.8223\n","Training loss (for one batch) at step 80: 238.8491, Accuracy: 0.8236\n","Training loss (for one batch) at step 90: 221.0038, Accuracy: 0.8212\n","Training loss (for one batch) at step 100: 227.0986, Accuracy: 0.8214\n","Training loss (for one batch) at step 110: 229.2064, Accuracy: 0.8233\n","Training loss (for one batch) at step 120: 232.0025, Accuracy: 0.8219\n","Training loss (for one batch) at step 130: 217.4268, Accuracy: 0.8226\n","Training loss (for one batch) at step 140: 245.5939, Accuracy: 0.8233\n","---- Training ----\n","Training loss: 220.5328\n","Training acc over epoch: 0.8244\n","---- Validation ----\n","Validation loss: 76.9408\n","Validation acc: 0.7182\n","Time taken: 9.60s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 221.6432, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 206.2493, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 208.5780, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 217.9269, Accuracy: 0.8381\n","Training loss (for one batch) at step 40: 224.9034, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 218.2380, Accuracy: 0.8359\n","Training loss (for one batch) at step 60: 244.2475, Accuracy: 0.8346\n","Training loss (for one batch) at step 70: 233.2775, Accuracy: 0.8323\n","Training loss (for one batch) at step 80: 244.2184, Accuracy: 0.8298\n","Training loss (for one batch) at step 90: 238.5244, Accuracy: 0.8278\n","Training loss (for one batch) at step 100: 221.5307, Accuracy: 0.8264\n","Training loss (for one batch) at step 110: 220.5214, Accuracy: 0.8275\n","Training loss (for one batch) at step 120: 230.8710, Accuracy: 0.8265\n","Training loss (for one batch) at step 130: 229.7900, Accuracy: 0.8260\n","Training loss (for one batch) at step 140: 227.1769, Accuracy: 0.8257\n","---- Training ----\n","Training loss: 228.4571\n","Training acc over epoch: 0.8267\n","---- Validation ----\n","Validation loss: 85.4932\n","Validation acc: 0.7031\n","Time taken: 9.77s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 234.8074, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 243.7492, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 216.2917, Accuracy: 0.8243\n","Training loss (for one batch) at step 30: 244.5337, Accuracy: 0.8200\n","Training loss (for one batch) at step 40: 220.1456, Accuracy: 0.8217\n","Training loss (for one batch) at step 50: 207.7800, Accuracy: 0.8251\n","Training loss (for one batch) at step 60: 229.1524, Accuracy: 0.8261\n","Training loss (for one batch) at step 70: 240.0051, Accuracy: 0.8249\n","Training loss (for one batch) at step 80: 248.0614, Accuracy: 0.8231\n","Training loss (for one batch) at step 90: 234.5938, Accuracy: 0.8234\n","Training loss (for one batch) at step 100: 233.2736, Accuracy: 0.8231\n","Training loss (for one batch) at step 110: 215.3956, Accuracy: 0.8229\n","Training loss (for one batch) at step 120: 212.0039, Accuracy: 0.8233\n","Training loss (for one batch) at step 130: 198.5090, Accuracy: 0.8227\n","Training loss (for one batch) at step 140: 215.0432, Accuracy: 0.8218\n","---- Training ----\n","Training loss: 239.2356\n","Training acc over epoch: 0.8225\n","---- Validation ----\n","Validation loss: 76.5270\n","Validation acc: 0.7104\n","Time taken: 9.56s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 214.0967, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 216.6006, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 236.1078, Accuracy: 0.8300\n","Training loss (for one batch) at step 30: 234.1485, Accuracy: 0.8242\n","Training loss (for one batch) at step 40: 206.7434, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 216.8272, Accuracy: 0.8306\n","Training loss (for one batch) at step 60: 230.6901, Accuracy: 0.8302\n","Training loss (for one batch) at step 70: 226.9344, Accuracy: 0.8283\n","Training loss (for one batch) at step 80: 220.3894, Accuracy: 0.8293\n","Training loss (for one batch) at step 90: 237.9218, Accuracy: 0.8273\n","Training loss (for one batch) at step 100: 210.0191, Accuracy: 0.8270\n","Training loss (for one batch) at step 110: 228.4105, Accuracy: 0.8273\n","Training loss (for one batch) at step 120: 227.5029, Accuracy: 0.8272\n","Training loss (for one batch) at step 130: 239.7544, Accuracy: 0.8285\n","Training loss (for one batch) at step 140: 223.7988, Accuracy: 0.8289\n","---- Training ----\n","Training loss: 207.9358\n","Training acc over epoch: 0.8283\n","---- Validation ----\n","Validation loss: 72.1625\n","Validation acc: 0.7166\n","Time taken: 9.65s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 223.7174, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 222.1842, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 237.0414, Accuracy: 0.8286\n","Training loss (for one batch) at step 30: 233.8603, Accuracy: 0.8294\n","Training loss (for one batch) at step 40: 244.7388, Accuracy: 0.8283\n","Training loss (for one batch) at step 50: 224.9032, Accuracy: 0.8310\n","Training loss (for one batch) at step 60: 248.0059, Accuracy: 0.8323\n","Training loss (for one batch) at step 70: 248.6875, Accuracy: 0.8296\n","Training loss (for one batch) at step 80: 236.6255, Accuracy: 0.8293\n","Training loss (for one batch) at step 90: 227.7181, Accuracy: 0.8276\n","Training loss (for one batch) at step 100: 226.0479, Accuracy: 0.8276\n","Training loss (for one batch) at step 110: 223.1125, Accuracy: 0.8294\n","Training loss (for one batch) at step 120: 200.9487, Accuracy: 0.8294\n","Training loss (for one batch) at step 130: 226.1448, Accuracy: 0.8298\n","Training loss (for one batch) at step 140: 214.7541, Accuracy: 0.8309\n","---- Training ----\n","Training loss: 200.7714\n","Training acc over epoch: 0.8299\n","---- Validation ----\n","Validation loss: 92.8842\n","Validation acc: 0.7106\n","Time taken: 9.75s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 223.9993, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 196.5800, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 219.1623, Accuracy: 0.8319\n","Training loss (for one batch) at step 30: 219.0320, Accuracy: 0.8297\n","Training loss (for one batch) at step 40: 236.9446, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 202.3056, Accuracy: 0.8353\n","Training loss (for one batch) at step 60: 210.3218, Accuracy: 0.8374\n","Training loss (for one batch) at step 70: 216.2662, Accuracy: 0.8352\n","Training loss (for one batch) at step 80: 250.4698, Accuracy: 0.8322\n","Training loss (for one batch) at step 90: 237.9304, Accuracy: 0.8322\n","Training loss (for one batch) at step 100: 219.7745, Accuracy: 0.8320\n","Training loss (for one batch) at step 110: 217.1269, Accuracy: 0.8307\n","Training loss (for one batch) at step 120: 236.2024, Accuracy: 0.8309\n","Training loss (for one batch) at step 130: 239.3029, Accuracy: 0.8308\n","Training loss (for one batch) at step 140: 221.6471, Accuracy: 0.8306\n","---- Training ----\n","Training loss: 203.0618\n","Training acc over epoch: 0.8305\n","---- Validation ----\n","Validation loss: 71.7685\n","Validation acc: 0.7136\n","Time taken: 9.59s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 209.1858, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 207.8594, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 202.0844, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 207.3480, Accuracy: 0.8277\n","Training loss (for one batch) at step 40: 237.2653, Accuracy: 0.8324\n","Training loss (for one batch) at step 50: 242.6984, Accuracy: 0.8318\n","Training loss (for one batch) at step 60: 234.5340, Accuracy: 0.8336\n","Training loss (for one batch) at step 70: 227.6132, Accuracy: 0.8337\n","Training loss (for one batch) at step 80: 230.9316, Accuracy: 0.8316\n","Training loss (for one batch) at step 90: 221.2841, Accuracy: 0.8321\n","Training loss (for one batch) at step 100: 208.3921, Accuracy: 0.8319\n","Training loss (for one batch) at step 110: 242.2288, Accuracy: 0.8318\n","Training loss (for one batch) at step 120: 201.3129, Accuracy: 0.8312\n","Training loss (for one batch) at step 130: 228.2354, Accuracy: 0.8319\n","Training loss (for one batch) at step 140: 223.5803, Accuracy: 0.8313\n","---- Training ----\n","Training loss: 194.1138\n","Training acc over epoch: 0.8300\n","---- Validation ----\n","Validation loss: 69.8497\n","Validation acc: 0.7053\n","Time taken: 9.58s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 215.5904, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 206.5195, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 213.7240, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 222.6592, Accuracy: 0.8290\n","Training loss (for one batch) at step 40: 219.6306, Accuracy: 0.8295\n","Training loss (for one batch) at step 50: 226.3649, Accuracy: 0.8351\n","Training loss (for one batch) at step 60: 220.7243, Accuracy: 0.8372\n","Training loss (for one batch) at step 70: 217.1813, Accuracy: 0.8335\n","Training loss (for one batch) at step 80: 226.2806, Accuracy: 0.8325\n","Training loss (for one batch) at step 90: 229.3942, Accuracy: 0.8320\n","Training loss (for one batch) at step 100: 212.4511, Accuracy: 0.8321\n","Training loss (for one batch) at step 110: 237.0356, Accuracy: 0.8314\n","Training loss (for one batch) at step 120: 205.4695, Accuracy: 0.8328\n","Training loss (for one batch) at step 130: 250.6389, Accuracy: 0.8329\n","Training loss (for one batch) at step 140: 219.8384, Accuracy: 0.8324\n","---- Training ----\n","Training loss: 211.8098\n","Training acc over epoch: 0.8322\n","---- Validation ----\n","Validation loss: 77.5305\n","Validation acc: 0.7112\n","Time taken: 9.56s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 208.9044, Accuracy: 0.9200\n","Training loss (for one batch) at step 10: 212.7299, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 217.1583, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 211.0278, Accuracy: 0.8381\n","Training loss (for one batch) at step 40: 214.5446, Accuracy: 0.8410\n","Training loss (for one batch) at step 50: 219.4484, Accuracy: 0.8410\n","Training loss (for one batch) at step 60: 215.7365, Accuracy: 0.8393\n","Training loss (for one batch) at step 70: 225.8362, Accuracy: 0.8390\n","Training loss (for one batch) at step 80: 213.6684, Accuracy: 0.8379\n","Training loss (for one batch) at step 90: 228.7104, Accuracy: 0.8362\n","Training loss (for one batch) at step 100: 212.2047, Accuracy: 0.8351\n","Training loss (for one batch) at step 110: 212.8658, Accuracy: 0.8350\n","Training loss (for one batch) at step 120: 212.3029, Accuracy: 0.8360\n","Training loss (for one batch) at step 130: 194.5359, Accuracy: 0.8345\n","Training loss (for one batch) at step 140: 227.8154, Accuracy: 0.8347\n","---- Training ----\n","Training loss: 185.9583\n","Training acc over epoch: 0.8339\n","---- Validation ----\n","Validation loss: 93.9932\n","Validation acc: 0.6956\n","Time taken: 19.22s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 228.8535, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 226.4486, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 207.5004, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 212.4405, Accuracy: 0.8358\n","Training loss (for one batch) at step 40: 210.4387, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 245.2902, Accuracy: 0.8314\n","Training loss (for one batch) at step 60: 209.0607, Accuracy: 0.8352\n","Training loss (for one batch) at step 70: 207.3609, Accuracy: 0.8344\n","Training loss (for one batch) at step 80: 210.8991, Accuracy: 0.8325\n","Training loss (for one batch) at step 90: 238.9788, Accuracy: 0.8316\n","Training loss (for one batch) at step 100: 212.1125, Accuracy: 0.8309\n","Training loss (for one batch) at step 110: 216.6277, Accuracy: 0.8329\n","Training loss (for one batch) at step 120: 213.8141, Accuracy: 0.8312\n","Training loss (for one batch) at step 130: 218.3577, Accuracy: 0.8316\n","Training loss (for one batch) at step 140: 209.7258, Accuracy: 0.8314\n","---- Training ----\n","Training loss: 195.4649\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 73.9086\n","Validation acc: 0.6967\n","Time taken: 13.28s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 210.6085, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 201.7401, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 211.8245, Accuracy: 0.8376\n","Training loss (for one batch) at step 30: 204.8664, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 233.0979, Accuracy: 0.8402\n","Training loss (for one batch) at step 50: 202.9729, Accuracy: 0.8427\n","Training loss (for one batch) at step 60: 192.3502, Accuracy: 0.8413\n","Training loss (for one batch) at step 70: 228.6195, Accuracy: 0.8396\n","Training loss (for one batch) at step 80: 212.2207, Accuracy: 0.8358\n","Training loss (for one batch) at step 90: 227.7310, Accuracy: 0.8333\n","Training loss (for one batch) at step 100: 213.8422, Accuracy: 0.8339\n","Training loss (for one batch) at step 110: 213.7059, Accuracy: 0.8339\n","Training loss (for one batch) at step 120: 222.2202, Accuracy: 0.8342\n","Training loss (for one batch) at step 130: 204.3745, Accuracy: 0.8350\n","Training loss (for one batch) at step 140: 217.3221, Accuracy: 0.8340\n","---- Training ----\n","Training loss: 181.5528\n","Training acc over epoch: 0.8339\n","---- Validation ----\n","Validation loss: 89.4893\n","Validation acc: 0.7182\n","Time taken: 9.81s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 213.1630, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 217.8937, Accuracy: 0.8627\n","Training loss (for one batch) at step 20: 224.1081, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 220.2220, Accuracy: 0.8432\n","Training loss (for one batch) at step 40: 195.8871, Accuracy: 0.8432\n","Training loss (for one batch) at step 50: 209.1792, Accuracy: 0.8451\n","Training loss (for one batch) at step 60: 223.5687, Accuracy: 0.8430\n","Training loss (for one batch) at step 70: 208.3980, Accuracy: 0.8435\n","Training loss (for one batch) at step 80: 214.9637, Accuracy: 0.8420\n","Training loss (for one batch) at step 90: 221.4601, Accuracy: 0.8413\n","Training loss (for one batch) at step 100: 207.2704, Accuracy: 0.8411\n","Training loss (for one batch) at step 110: 204.9501, Accuracy: 0.8410\n","Training loss (for one batch) at step 120: 232.6051, Accuracy: 0.8410\n","Training loss (for one batch) at step 130: 233.1870, Accuracy: 0.8407\n","Training loss (for one batch) at step 140: 223.7559, Accuracy: 0.8412\n","---- Training ----\n","Training loss: 197.2923\n","Training acc over epoch: 0.8405\n","---- Validation ----\n","Validation loss: 66.3047\n","Validation acc: 0.6983\n","Time taken: 9.65s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 212.0699, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 237.7320, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 211.9771, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 194.7521, Accuracy: 0.8374\n","Training loss (for one batch) at step 40: 197.1711, Accuracy: 0.8388\n","Training loss (for one batch) at step 50: 201.8455, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 214.0741, Accuracy: 0.8341\n","Training loss (for one batch) at step 70: 215.1934, Accuracy: 0.8323\n","Training loss (for one batch) at step 80: 207.0825, Accuracy: 0.8331\n","Training loss (for one batch) at step 90: 205.9198, Accuracy: 0.8338\n","Training loss (for one batch) at step 100: 201.0440, Accuracy: 0.8328\n","Training loss (for one batch) at step 110: 204.3562, Accuracy: 0.8338\n","Training loss (for one batch) at step 120: 218.6438, Accuracy: 0.8346\n","Training loss (for one batch) at step 130: 198.1359, Accuracy: 0.8351\n","Training loss (for one batch) at step 140: 223.0361, Accuracy: 0.8341\n","---- Training ----\n","Training loss: 178.7750\n","Training acc over epoch: 0.8358\n","---- Validation ----\n","Validation loss: 85.7257\n","Validation acc: 0.7163\n","Time taken: 9.58s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 208.0161, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 225.4704, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 204.5640, Accuracy: 0.8429\n","Training loss (for one batch) at step 30: 205.0370, Accuracy: 0.8439\n","Training loss (for one batch) at step 40: 241.7812, Accuracy: 0.8417\n","Training loss (for one batch) at step 50: 210.3588, Accuracy: 0.8431\n","Training loss (for one batch) at step 60: 215.4566, Accuracy: 0.8446\n","Training loss (for one batch) at step 70: 206.3390, Accuracy: 0.8413\n","Training loss (for one batch) at step 80: 235.0339, Accuracy: 0.8401\n","Training loss (for one batch) at step 90: 213.2674, Accuracy: 0.8400\n","Training loss (for one batch) at step 100: 182.4996, Accuracy: 0.8389\n","Training loss (for one batch) at step 110: 216.0347, Accuracy: 0.8399\n","Training loss (for one batch) at step 120: 212.9646, Accuracy: 0.8383\n","Training loss (for one batch) at step 130: 194.5529, Accuracy: 0.8392\n","Training loss (for one batch) at step 140: 193.5678, Accuracy: 0.8401\n","---- Training ----\n","Training loss: 172.1738\n","Training acc over epoch: 0.8395\n","---- Validation ----\n","Validation loss: 69.3348\n","Validation acc: 0.7071\n","Time taken: 9.75s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 217.7331, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 190.9162, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 222.2691, Accuracy: 0.8371\n","Training loss (for one batch) at step 30: 195.5429, Accuracy: 0.8348\n","Training loss (for one batch) at step 40: 194.6698, Accuracy: 0.8412\n","Training loss (for one batch) at step 50: 198.4827, Accuracy: 0.8453\n","Training loss (for one batch) at step 60: 223.3607, Accuracy: 0.8449\n","Training loss (for one batch) at step 70: 218.2011, Accuracy: 0.8445\n","Training loss (for one batch) at step 80: 199.3458, Accuracy: 0.8411\n","Training loss (for one batch) at step 90: 198.4548, Accuracy: 0.8404\n","Training loss (for one batch) at step 100: 197.4250, Accuracy: 0.8408\n","Training loss (for one batch) at step 110: 196.3456, Accuracy: 0.8413\n","Training loss (for one batch) at step 120: 209.2120, Accuracy: 0.8413\n","Training loss (for one batch) at step 130: 226.9843, Accuracy: 0.8398\n","Training loss (for one batch) at step 140: 200.0687, Accuracy: 0.8391\n","---- Training ----\n","Training loss: 187.2924\n","Training acc over epoch: 0.8403\n","---- Validation ----\n","Validation loss: 73.6109\n","Validation acc: 0.6983\n","Time taken: 9.56s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 236.2391, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 203.9991, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 214.6414, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 207.1248, Accuracy: 0.8371\n","Training loss (for one batch) at step 40: 188.4485, Accuracy: 0.8441\n","Training loss (for one batch) at step 50: 202.5773, Accuracy: 0.8439\n","Training loss (for one batch) at step 60: 180.2544, Accuracy: 0.8459\n","Training loss (for one batch) at step 70: 234.1096, Accuracy: 0.8451\n","Training loss (for one batch) at step 80: 211.8907, Accuracy: 0.8421\n","Training loss (for one batch) at step 90: 223.1905, Accuracy: 0.8408\n","Training loss (for one batch) at step 100: 201.6539, Accuracy: 0.8394\n","Training loss (for one batch) at step 110: 211.5441, Accuracy: 0.8423\n","Training loss (for one batch) at step 120: 229.8951, Accuracy: 0.8422\n","Training loss (for one batch) at step 130: 200.7299, Accuracy: 0.8420\n","Training loss (for one batch) at step 140: 197.2450, Accuracy: 0.8406\n","---- Training ----\n","Training loss: 192.2186\n","Training acc over epoch: 0.8414\n","---- Validation ----\n","Validation loss: 86.3682\n","Validation acc: 0.7063\n","Time taken: 9.58s\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABrfElEQVR4nO2dd3xVRfbAvye9kkASQkkgofcaugXEgopiQ0FXQXctrKLgrq66roXV37rq2is2RBHsFEVRkQhK7yX0ECAhBAipkP7m98fcJC8hCQm8l5c85vv5vM+7d8q9Z15u7pk5c+aMKKUwGAwGgwHAw9UCGAwGg6HhYJSCwWAwGMowSsFgMBgMZRilYDAYDIYyjFIwGAwGQxlGKRgMBoOhDKMUDIY6ICLDRSTZ1XIYDM7CKAVDvSEiSSJysavlMBgM1WOUgsHgJoiIl6tlMDR+jFIwuBwR8RWRV0TkkPV5RUR8rbxwEflORDJF5LiILBMRDyvvHyKSIiI5IrJTREZWc/0rRWSDiGSLyEERecouL0ZElIhMEJEDInJMRP5pl+8vIjNEJENEEoABp2nLq9Y9skVknYicb5fnKSKPicheS+Z1IhJt5XUXkZ+tNqaJyGNW+gwRecbuGhXMV9bo6x8ishk4ISJeIvKI3T0SROTaSjLeKSLb7fL7ichDIvJ1pXKvicirNbXX4IYopczHfOrlAyQBF1eRPg1YCTQHIoDlwL+tvP8A7wDe1ud8QIDOwEGglVUuBmhfzX2HAz3RnaBeQBpwjV09BbwH+AO9gQKgq5X/HLAMaAZEA1uB5Bra+CcgDPAC/gYcBvysvIeALZbsYt0rDAgGUq3yftb5IKvODOCZSm1JrvSbbrRk87fSxgKtrPbeBJwAWtrlpaCVmwAdgLZAS6tcqFXOCzgC9Hf1c2M+9ftxuQDmc+58alAKe4Er7M4vA5Ks42nAPKBDpTodrJfWxYB3HeV4BXjZOi5VClF2+auBcdZxIjDKLu+umpRCFffKAHpbxzuBMVWUGQ9sqKZ+bZTCHaeRYWPpfYFFwAPVlPsBuNM6Hg0kuPqZMZ/6/xjzkaEh0ArYb3e+30oDeAHYA/wkIoki8giAUmoPMAV4CjgiInNEpBVVICKDRGSJiBwVkSzgHiC8UrHDdscngSA72Q5Wkq1aROTvlmkmS0QygRC7e0WjFWBlqkuvLfbyISK3ichGy+SWCfSohQwAH6NHOljfn5yFTIZGilEKhobAIbQJo5Q2VhpKqRyl1N+UUu2Aq4EHS+cOlFKfKaXOs+oq4L/VXP8zYD4QrZQKQZujpJaypaJfpPayVYk1f/AwcCPQVCkVCmTZ3esg0L6KqgeBdtVc9gQQYHfeoooyZaGORaQt2hR2HxBmybC1FjIAzAV6iUgP9EhhVjXlDG6MUQqG+sZbRPzsPl7AbOBxEYkQkXDgCeBTABEZLSIdRETQL9gSwCYinUXkImtCOh/IA2zV3DMYOK6UyheRgcDNdZD3C+BREWkqIlHA5BrKBgPFwFHAS0SeAJrY5b8P/FtEOoqml4iEAd8BLUVkijXpHiwig6w6G4ErRKSZiLRAj45qIhCtJI4CiMjt6JGCvQx/F5H+lgwdLEWCUiof+AqtRFcrpQ6c5l4GN8QoBUN9sxD9Ai/9PAU8A6wFNqMnYtdbaQAdgV+AXGAF8JZSagngi54EPoY2/TQHHq3mnn8FpolIDlrhfFEHeZ9Gm4z2AT9Rs0llEfAjsMuqk09F085L1r1/ArKBD9CTwznAJcBVVlt2AyOsOp8Am9BzBz8Bn9ckrFIqAfgf+rdKQ0+w/2GX/yXwLPrFn4MeHTSzu8THVh1jOjpHEaXMJjsGg0EjIm2AHUALpVS2q+Ux1D9mpGAwGACw1n88CMwxCuHcxayANBgMiEgg2ty0HxjlYnEMLsSYjwwGg8FQhjEfGQwGg6EMoxQMBoPBUIZRCgaDwWAowygFg8FgMJRhlILBYDAYyjBKwWAwGAxlGKVgMBgMhjKMUjAYDAZDGUYpGAwGg6EMoxQMBoPBUIZRCgaDwWAowygFg8FgMJRhlILBYDAYyjBKwWAwGAxlNOr9FMLDw1VMTEzZ+YkTJwgMDHSdQPWAu7exIbVv3bp1x5RSEa6497n2bLt7+6BhtbGmZ7tRK4WYmBjWrl1bdh4fH8/w4cNdJ1A94O5tbEjtE5H9rrr3ufZsu3v7oGG1saZn25iPDIZaICKjRGSniOwRkUeqyG8jIktEZIOIbBaRK6z0GBHJE5GN1ued+pfeYKg9jXqkYDDUByLiCbwJXAIkA2tEZL5SKsGu2OPAF0qpt0WkG7AQiLHy9iql+tSjyAbDGWNGCgbD6RkI7FFKJSqlCoE5wJhKZRTQxDoOAQ7Vo3wGg8MwIwUHU1RURHJyMvn5+U65fkhICNu3b3fKtRsCrmifn58fUVFReHt7V1ekNXDQ7jwZGFSpzFPATyIyGQgELrbLixWRDUA28LhSallVNxGRu4C7ACIjI4mPjy/Ly83NrXDubrh7+6DxtNEoBQeTnJxMcHAwMTExiIjDr5+Tk0NwcLDDr9tQqO/2KaVIT08nOTmZ2NjYs7nUeGCGUup/IjIE+EREegCpQBulVLqI9Afmikh3pVR2FbJMB6YDxMXFKftJyYY0SekM3L190HjaaMxHDiY/P5+wsDCnKASD4xERwsLCTjeySwGi7c6jrDR7/gx8AaCUWgH4AeFKqQKlVLqVvg7YC3RykPgGg8MxSsEJGIXQuKjF32sN0FFEYkXEBxgHzK9U5gAw0rpeV7RSOCoiEdZENSLSDugIJDpQfIPBobil+ejHrYdJzjjJX85v52pRDG6AUqpYRO4DFgGewIdKqW0iMg1Yq5SaD/wNeE9EpqInnScqpZSIXABME5EiwAbco5Q67qKmGNwcm02x52gua5MyKCwuYeKwuptE3VIpxO88ws8JaUYpGByGUmoh2s3UPu0Ju+MEYFgV9b4Gvna6gAa3JregmNs/Ws2QdmFMvaRT2ei2oLiEH7ceZmtKFgmp2WxNySYrrwiATpFBRimU0i4ikPQThWSdLCIkoFqPErckPT2dkSNHAnD48GE8PT2JiNCr2VevXo2Pj0+1ddeuXcvMmTN57bXXarzH0KFDWb58ucNknjFjBmvXruWNN95w2DUNBnfiyXnbWJOUwZqkDApKbDwyqgtp2QVMmrWODQcy8fHyoEuLYK7o2YJ+bZoSF9OMmLCAM7qXWyqF2PAgABKP5dK3TVMXS1O/hIWFsXHjRgCeeuopgoKC+Pvf/16WX1xcjJdX1X/2uLg44uLiTnsPRyoEg8FQMws2HeLr9clMvqgDGScLefe3RI7mFLB011HyCkt4fXxfLu/RAi9Px0wRu6lS0EGn9h074VKl8PSCbSQcOsXz8KzoGO7PM9f3qVOdiRMn4ufnx4YNGxg2bBjjxo3jgQceID8/H39/fz766CM6d+5MfHw8L774It999x1PPfUUBw4cIDExkQMHDjBlyhTuv/9+AIKCgsp8rp966inCw8PZunUr/fv359NPP0VEWLhwIQ8++CCBgYEMGzaMxMREvvvuu9PKun//fu6//36OHTtGREQEH330EW3atOHLL7/k6aefxtPTk5CQEJYuXcq2bdu4/fbbKSwsxGaz8fXXX9OxY8cz+VkNhgZJSmYe//x2C32iQ7l/ZEe8PLTZ6NOVB2gXHsjsOwfTMdKxLtxuqRTaNAvA00PYd+yEq0VpMCQnJ7N8+XI8PT3Jzs5m2bJleHl58csvv/DYY4/x9denmr137NjBkiVLyMnJoXPnzkyaNOmUBV4bNmxg27ZttGrVimHDhvHHH38QFxfH3XffzdKlS4mNjWX8+PG1lvOhhx5iwoQJTJgwgQ8//JD777+fuXPnMm3aNBYtWkTr1q3JzMwE4J133uGBBx7glltuobCwkJKSkrP6jQyG+iYnv4hF29KYuyGFHYdzGNI+jIu7NqdpgA+/7jjCj1sPU2JTvDquD97WSGDa1T24qEtzBsQ0I9jP8eZxt1QKPl4eRDf1J/Goa5XCk1d1d/g1c3Jyzqje2LFj8fT0BCArK4sJEyawe/duRISioqIq61x55ZX4+vri6+tL8+bNSUtLIyoqqkKZgQMHlqX16dOHpKQkgoKCaNeuXdlisPHjxzN9+vRaybl69Wrmz9fenrfeeisPP/wwAMOGDWPixInceOONXHfddQAMGTKEZ599luTkZK677jozSjA0GlIy83hvaSJz1hwgv8hGdDN/Brdrxoq9x1iwSUdI8fXyYFiHcP5yfixtw8pDbnt4CBd1iXSabG6pFECbkBLNSKEM+zju//rXvxgxYgTffvstSUlJ1a6y9PX1LTv29PSkuLj4jMo4gnfeeYdVq1bx/fff079/f9atW8fNN9/MoEGD+P7777niiit49913ueiii5xyf4OhLhzJzmf+pkNsScniUGYeqVn5FBfkE7NrBf7enizbfQyAa/q2ZvzANvRrE4qIYLMpNiZnkpVXxODYMPx9POtddrdVCu0igliZeBybTeHhYRaT2ZOVlUXr1q0B7fnjaDp37kxiYiJJSUnExMTw+eef17ruoEGDmDNnDrfeeiuzZs3i/PPPB2Dv3r0MGjSIQYMG8cMPP3Dw4EGysrJo164d999/PwcOHGDz5s1GKRhcypbkLJ5ftIM/9hzDpqB1qD+tm/oT17Yphw6nUWJTHDh+kluHtOXO89vRKtS/Qn0PD6Gfi51j3FYpxIYHkldUwuHs/FN++HOdhx9+mAkTJvDMM89w5ZVXOvz6/v7+vPXWW4waNYrAwEAGDBhQ67ovvPACkydP5oUXXiibaAY917B7926UUowcOZLevXvz3//+l08++QRvb29atGjBY4895vC2GAxVseFABvM2HmLi0BhiLMeW5IyTTPhoNV4ewn0jOjCmb2vaRwSV1dGxj4a6SuTao5RqtJ/+/fsre5YsWVJ2/Mfuo6rtP75Tv+8+quqThIQEp14/Ozvbqdd3FDk5OUoppWw2m5o0aZJ66aWXalXPVe2r6u+GXq3c4J5td6QxtK+4xKb+2H1U3fLeStX2H9+ptv/4TvWd9pPacCBD5eYXqcte/k31ePJHtfdITpX1G1Iba3q23XekEKG1d+KxEwzrEO5iac493nvvPT7++GMKCwvp27cvd999t6tFMhjqRKmpZ0dqNkt3H+XnhDSO5RYSHuTDo5d3YViHcCbNWsf46Svp0boJu9Jy+Oj2gbSzGx00RtxWKbRo4oe/tyf7XOyBdK4ydepUpk6dWiHto48+4tVXX62QNmzYMN588836FM1gOIWiEhvHTxSy92guK/ems3xvOltSsigotgEQ5OvF8M4RXNq9BZd0jSybAP5m0jDumLGGNUkZPH5lVy7sFOHKZjgEt1UKImJ5IOW6WhSDxe23387tt9/uajEMhjL+2HOMB7/YSFp2QVmah0DPqFD+NLgtnVsE0zkymC4tg/H1OtUTKCLYl8/vHszGg5kMaRdWn6I7DbdVCqBNSFtTslwthsFgaIAkZ5zkvs/W0zTAhykXtyE8yJfWof70j2lKkzosCgvw8WJoe/cxUbu1UmgfHsgPW1IpLLbh42W2jjAYzjVyC4pJycijaYA3IQHeZb39/KIS/jprPcUlig8mDigLjWNwc6UQGxGITcGB4yfo0Nx9t7A0GAyncvD4SW54Z3kF01BMWACDYsPIOFnI5uQs3rstziiESjhNKYiIH7AU8LXu85VS6kkRmQFcCJTadSYqpTaKDhD+KnAFcNJKX382MpRFSz1qlILBcC5xOCufm99fSUGxjedv6EVhsZ5I3pycxY/bDpOVV8TkizpwSTfnhYtorDhzpFAAXKSUyhURb+B3EfnByntIKfVVpfKXo7cq7AgMAt62vs8Y+2ip5wojRozgkUce4bLLLitLe+WVV9i5cydvv/32KeWHDx/Oiy++SFxcHFdccQWfffYZoaGhFcpUFYK7MnPnzqVTp05069YNgCeeeIILLriAiy++2CHtMnsuGGriaE4B8zcdItjPi/AgH/6zcAfHcwv57M7B9I4OrVDWZlOkZOYR1dQsaq0KpykFa4FEqeuPt/VRNVQZA8y06q0UkVARaamUSj1TGUL8vQkP8mHv0XPHA2n8+PHMmTOnglKYM2cOzz///GnrLly48LRlqmPu3LmMHj26TClMmzbtjK9lMNSFguIS/vLxGjYllzuV+Hp5MOP2gacoBNChJKKbndkGNOcCTp1TsDYsXwd0AN5USq0SkUnAsyLyBLAYeEQpVQC0Bg7aVU+20lIrXfMu4C6AyMhI4uPjy/JKY/zbExtUwrwNyQwKTCfM3/mTzSEhIWWRTH2XPInHkW0Ovb5PeDdyRlb/wr3sssv45z//SXp6Oj4+Puzfv5+UlBRmzpzJlClTyMvLY8yYMfzzn/8EoKSkhBMnTpCTk0OPHj347bffCAsL44UXXuCzzz4jIiKC1q1b07dvX3JycpgxYwYfffQRRUVFtGvXjunTp7NlyxbmzZtHfHw806ZN45NPPuH5559n1KhRXHPNNcTHx/P4449TXFxMv379ePnll/H19aVHjx6MHz+eH3/8kaKiImbOnEn79u2rjASbn59PYWEhOTk57N+/n3vvvZf09HTCw8N56623iI6O5ttvv+W5557D09OTJk2a8OOPP7J9+3YmTZpEUVERNpuNTz75hA4dOlR5/crPjqFx8Oz329mUnMUbN/eld1Qoadn5RDbxMy/+M8SpSkEpVQL0EZFQ4FsR6QE8ChwGfIDpwD+AWncrlVLTrXrExcUp+wifOrbI8Arl2/c6ySUv/8Yv6SG8/af+Z9OcWrF9+3aCg635C28f8HTsT2zzkPLrV0FwcDCDBg3i999/Z8yYMXz33XfcdNNNPPbYYzRr1oySkhJGjhzJvn376NWrF56engQGBhIcHIyIEBQUxK5du/j222/ZvHlz2Yt88ODBBAcHc/PNNzN58mQAHn/8cb744gsmT57MmDFjGD16NDfccINuurc3/v7+eHt789e//pXFixfTqVMnbrvtNj799FOmTJmCiNC6dWs2btzIW2+9xdtvv83LL79cZfv8/Pzw8fEhODiYRx99lDvuuKNsz4XHHnuMuXPn8sILL/Dzzz+X7bkQHBzMJ598woMPPlhhzwV//1PNBn5+fvTt29dBfyVDfTFvYwozV+znzvNjGd2rFYBRBmdJvXgfKaUyRWQJMEop9aKVXCAiHwGlhuoUINquWpSVdlZENwtg8kUdeWHRTpbsPMKIzs3P9pK15/LnHH7Jgpwcqt9lWVNqQhozZgxz5szhgw8+4IsvvmD69OkUFxeTmppKQkICvXr1qrL+smXLuPbaawkI0P9cV199dVne1q1befzxx8nMzCQ3N7eCmaoqdu7cSWxsLJ06dQJgwoQJvPnmm0yZMgWgbG+E/v37880339TiF4AVK1aUlTV7Lpy7bE3J4tFvthDXtikPj+rianHcBqfZU0QkwhohICL+wCXADhFpaaUJcA2w1aoyH7hNNIOBrLOZT7DnzvPb0T4ikCfnbSO/yP135xozZgyLFy9m/fr1nDx5kmbNmvHiiy+yePFiNm/ezJVXXkl+fv4ZXXvixIm88cYbbNmyhSeffPKMr1NK6X4MjtiL4Z133uGZZ57h4MGD9O/fn/T0dG6++Wbmz5+Pv78/V1xxBb/++usZXVtERonIThHZIyKPVJHfRkSWiMgGEdksIlfY5T1q1dspIjVrUUOt2JqSxS3vr6JpgA9v3NyvbFcyw9njzF+yJbBERDYDa4CflVLfAbNEZAuwBQgHnrHKLwQSgT3Ae8BfHSWIj5cH/76mBweOn2TWqgOOumyDJSgoiBEjRnDHHXcwfvx4srOzCQwMJCQkhLS0NH744Yca619wwQXMnTuXvLw8cnJyWLBgQVleTk4OLVu2pKioiFmzZpWlBwcHVzkX0LlzZ5KSktizZw8An3zyCRdeeOFZtW/o0KHMmTMHoMo9F6ZNm0ZERAQHDx4kMTGxbM+FMWPGsHnz5jrfz5obexPtIdcNGC8i3SoVexz4QinVFxgHvGXV7WaddwdGAW9Z1zOcIaUKIcjXizl3DaZFiJ+rRXIrnOl9tBk4xUirlKpyFxTL6+heZ8kztH04rUP92ZKc6axbNCjGjx/Ptddey5w5c+jSpQt9+/alS5cuREdHM2zYsBrr9uvXj5tuuonevXvTvHnzCvsh/Pvf/2bQoEFEREQwaNCgMkUwbtw47rzzTl577TW++qrc29jPz4+PPvqIsWPHUlxczIABA7jnnnvOqm2vv/46t99+e33uuTAQ2KOUSgQQkTlob7kEuzIKaGIdhwCHrOMxwBzLmWKfiOyxrrfiTAQ5lzmclc/MFUl8smI/Tfy9mXPXYDN/4AREv4sbJ3FxcWrt2rVl51VNNNtz6weryM4rYt595zlNpu3bt9O1a1enXT8nJ6fGiebGjqvaV9XfTUTWKaXiROQG9HzYX6z0W4FBSqn77Mq2BH4CmgKBwMVKqXUi8gawUin1qVXuA+CHKtbpVPas6186GgLtWRcU1LhDMldHYYli06ETxEUFoq3KmhKb4kCOjd0ZNnZmlLDxSAk2Bf0iPRnX2YeIgMZlMmpIf8MRI0asU0rFVZXn1mEuKhMbHsi361NQSlV4+AwGBzAemKGU+p+IDAE+sbztak1dPevchX/N3con205yZ7NIHruiKyJCem4Bt89Yw2Zr7UHrUH9uGxrJ7UNjaRPWOEcHjeVveM4phZyCYo7lFhIR7Hv6CoZ659NPP+Xdd9+tkNYA9lyojWfcn9FzBiilVlhhXsJrWfecJeFQNrNW7SfMT3hv2T6C/by5aUA0t7y/ioPHT/Kf63oyvHMELUPM6uP64pxSCqU7Iu07dsKpSsGMRM6cP/3pT0yaNKle71kLE+oaoKOIxKJf6OOAmyuVOQCMBGaISFfADziK9qr7TEReAlqhw7isdpz0jRelFE/O30pogA9PD/JiSWYzXvp5FzOWJ1FQVMLHdwxksJvsUdCYaFxGubOknRULKdGJYS/8/PxIT0+vzYvG0ABQSpGeno6fX/UeLEqpYuA+YBGwHe1ltE1EpolI6SKOvwF3isgmYDY6oKNSSm0DvkBPSv8I3Gst6jznmbfxEGuSMnj4ss4E+Qj/vb4nV/ZsiVKKWXcONgrBRZxTI4VWof74eHk4NUBeVFQUycnJHD161CnXz8/Pr/EF1thxRfv8/PyIioqqsYxSaiHabdo+7Qm74wSgSrcupdSzwLNnL6n7cCy3gP9buJ1eUSHcGBfN0qWJeHl68MbNfSkssVW5y5mhfjinlIKnhxATFsBeJ+7b7O3tTWxsrNOuHx8f79bhGNy9fQY9Up/40Rqy84t477Y4PDzKTa0iYhSCizmnzEcA7cKD2FfNvs3zNx3ipndXGNOPweAkVu87znVvL+dEQTGzqwhrbXA959RIAfRubIt3pFFcYsOr0tL4n7YdZtW+42TlFREacLoIQwaDoTZsOpjJtxtSWLr7KIlHTxAbHsiM2wfQNszseNYQOfeUQnggRSWK5Iw8Yiptw7fjsF6dm5KZZ5SCweAAtqZkceO7KxCBwe3CuHlgG8b2jyYkwNvVohmq4ZxTCu0jyndjs1cK+UUlZV5JhzLz6d4qxCXyGQzuQnpuAXd/so6wQB/mTz6P8CCzNqgxcM7NKZTu21x5N7Y9R3KxWVMJqVl59S2WweBWFJXYuPez9RzLLeDdW+OMQmhEnHMjhWaBPoQGeJ/ilro9NbvsOCXTKAWD4UxRSvHU/G2sTDzOyzf1pmeUGXU3Js45pQB6XqGyUthxOAc/bw/Cg3w5lHl2ewQYDOcyLyzayaxVB7jnwvZc27fm9R+Ghsc5Zz4CrRQSj1ZWCtl0jgwmqqk/qWakYDCcEW/H7+Wt+L2MH9iGf4zq7GpxDGfAOakU2kcEcTg7nxMFeqcvpRTbU3Po0qIJrUL9OWSUgsFQZ75al8x/f9zBmD6teOaaHib+VyPlnFQKseHlHkgAR3MLOH6ikC4tg2kd6s/h7HyKS2yuFNFgaFTsOZLD43O3MLR9GC+O7Y2nh1EIjZVzUil0bK49kNYfyABgR6pen9ClRRNahvhjU5CWU+Ay+QyGxkR+UQn3fbaBQB8vXrmpj9kvuZFzTv71OjQPondUCB/8vo/iEhs7DmvPoy4tgmkVqoOxmXkFg6F2PPN9AjsO5/C/G3vTvIn7Bms8VzgnlYKIMGl4B/ann2Th1sPsSM2hRRM/mgb60DpUb+Zh3FINhprZlZbD/bM38OnKA9x9QTuGd27uapEMDuCcdEkFuLRbJB2aB/F2/F6UUnRpqfcFbmkpBeOWajBUTUFxCQ99uZn5mw4R4OPJpOHtmXpxJ1eLZXAQ56xS8PAQ7rmwPX//chNAWS8nyNeLJn5eZlWzwVANn685yPxNh7j7gnbcc2F7mgaaOGHuhNPMRyLiJyKrRWSTiGwTkaet9FgRWSUie0TkcxHxsdJ9rfM9Vn6Ms2Qr5ererWgVom2gXa2RAmDcUg2GaigoLuHt+L3EtW3KI5d3MQrBDXHmnEIBcJFSqjfQBxglIoOB/wIvK6U6ABnoDc+xvjOs9Jetck7Fx8uDuy9sD0CP1uVL8VuF+pNizEcGwyl8uTaZ1Kx8Hri4o1mH4KY4TSlY+9OWRp3ztj4KuAj4ykr/GLjGOh5jnWPlj5R6eOpuG9KWXx68gPYRQWVprUL9zEjBYKhEYbGNt+P30rdNKOd1CHe1OAYn4dQ5BRHxBNYBHYA3gb1AprUROkAy0No6bg0cBL1RuohkAWHAsUrXvAu4CyAyMpL4+PiyvNzc3ArndSE5ofw4/3ghWXlF/PjLEvy8GlZv6Gza2Bhw9/Y1Zr5al0xKZh7PXmtWK7szTlUKSqkSoI+IhALfAl0ccM3pwHSAuLg4NXz48LK8+Ph47M/PlKzQFL7atZEOveLo0Dz49BXqEUe1saHi7u1rrBSX2Hgrfg+9o0O5sFOEq8UxOJF6WaeglMoElgBDgFARKVVGUUCKdZwCRANY+SFAen3IV5mWIaVrFcy8gkEjIqNEZKflCPFIFfkvi8hG67NLRDLt8krs8ubXq+AOYvGOIyRn5DHpwnZmlODmOG2kICIRQJFSKlNE/IFL0JPHS4AbgDnABGCeVWW+db7Cyv9VKaWcJV9NmFXNBnssM+ib6Gc4GVgjIvOVUmVGR6XUVLvyk4G+dpfIU0r1qSdxncLMFUm0CvHj4q6RrhbF4GScOVJoCSwRkc3AGuBnpdR3wD+AB0VkD3rO4AOr/AdAmJX+IHBKb6y+iGzih4dgJpsNpQwE9iilEpVShegOzZgayo8HZteLZPXA7rQc/tiTzi2D2+Jl4hq5PU4bKSilNlOxt1Sanoj+J6ucng+MdZY8dcHb04PmwX7GfGQopcwJwiIZGFRVQRFpC8QCv9ol+4nIWqAYeE4pNbeauk5xojhbZiYU4OUB0UUHiY9Pdso9zgUHg8bSxnN2RfPpaBXqR0rmSVeLYWh8jAO+spwsSmmrlEoRkXbAryKyRSm1t3LF+nCiqCvZ+UX89dfFjOkTxdWX9nbafc4FB4PG0kYzFqyGXlGhrNufQXKGUQyGcicIC3sHicqMo5LpSCmVYn0nAvFUMYJuqHyzLpmThSVMGNrW1aIY6gmjFKrhrgvaIQhv/LrH1aIYXM8aoKMVosUH/eI/xYtIRLoATdHOEqVpTUXE1zoOB4YBCZXrNkSUUsxcuZ8+0aH0igp1tTiGesIohWpoFerPzYPa8OW6ZJKOnTh9BYPbYi22vA9YBGwHvlBKbRORaSJytV3RccCcSl5zXYG1IrIJ7Xn3nL3XUkNmxd50Eo+e4LYhZpRwLmHmFGrgr8PbM2fNAV5bvJuXburjanEMLkQptRBYWCntiUrnT1VRbznQ06nCOYlPVu6naYA3V/Rs6WpRDPWIGSnUQPMmfkwYEsO3G1PYnZbjanEMhnojLTufnxLSuDEuGj9vT1eLY6hHjFI4DXdf2J4Ab09eWbzb1aIYDPXG7NUHsCnFzYPauFoUQz1jlMJpaBbow4ShMSzckmpGC4ZzgqISG7NXH+CCjhG0DQt0tTiGesYohVrwl/Pb4e/tyWuVPJHyi0qqqWEwNF4Wb08jLbuAWwebCeZzEaMUakGzQB9uGxLDd5sPlY0W3l+WSI8nF7Fir0ti9hkMTmPhb8u5Ong3I7o0d7UoBhdglEItufP8WPy8PHn91z28+stunvl+O8U2xezVByqUy8kvYp9xYTU0UramZDHi8Ae8VPIsngWZrhbH4AKMUqglYUG+3Da0LfM3HeLlX3Zxfb8oxg+M5qeEw+QWFJeV+/uXm7j2rT+w2VwS4NVgOCs+/H0f7T0O42UrhG3fulocgwswSqEO3HV+O1qG+DFxaAwv3NCLG/pHkV9k48ethwHYlZbDom1pZJ4sIvFY7mmuZjA0LI5k57Ng8yE6eh3RCRvdJtCroQ4YpVAHwoJ8Wf7IRTx1dXc8PIR+bZrSplkA327QkSPfid+Lp4fegGTjwSxXimow1JmZK/YTaMvBvyQHmkRB8mo4ZsK8nGsYpVBH7HedEhGu6dua5XvTWZt0nHmbDnHr4LYE+Xqx6WCm64Q0GOpIflEJs1btZ2xskU44/0EQD9hkRgvnGkYpnCXX9m2NUnD3J+vwELj7wnb0bB3C5uRMV4tmMNSaz1YdIONkETe2K9QJbYdC+4tg8+dgs7lWOEO9YpTCWRIbHkjfNqGknyjkur5RtAzxp1d0CAmp2RQUm3UMhoZPWnY+L/28i/M6hNOhdD6haQz0Hg9ZByFp2dndwDW76hrOEKMUHMC4AdH4eHlw94XtAOgTFUpRiWJHqlkBbWj4TFuQQGGJjWeu6YEc3wdNWoO3P3S5EnybwE//hO0LoKSo7hfPPABvDYYPLoP0U/YVanxkHzqz3+FMycuA/Oz6ux9GKTiEG+OiWfPYxbSLCAKgd3QoAJuMCcnQECkq33t8yY4jfL8llckjOhATHgjHE6GZ7tzg7Q9X/g9OHofP/wQv94A179e+539kO3xwKWSnwtHt8M55davvCGw2x5m/ThyD1/rB769UX6a4UCsORzH7ZvjmrlPTnaiYjFJwACJCSIB32XnLED/Cg3zZaCabDQ2FdR/DzDHwYid4tgVs+Yq8whL+NW8r7SMCucsa5ZKxD5rFltfrdSM8sBnGz4GwDvD93+DT607/4tu3DD4cpRXA7QvhryuhzWBdf9W7zmtnZT67EebeU31+cSEkzKudotr8ORTnVb9+w1YCn42F1/rCoY1nJG4FCk9qD7CkZVBSvhaK7EPwXBvY8tXZ36MKjFJwAiJCn+gQNicbt1RDA+DIdlhwP2SlQIeLwTcE9i7hh62pJGfk8dTV3fH18tRmihNHy0cKpXh6QefLYeJ3euRwYCW8OQhe7w8vdITn28N3UyF1M2Qlw1d/ho9HQ0AzuONHaNEDmrSCP30Drfrql2t9cPI47F0MOxZW37Pe8gV8cRvsX17ztZSCDbMAgSPb4Pi+U8v89jwkxoOnjx5ZnbBC4NhssH0B/ifrOIJI3QS2YijMhbQt5el7FkPRSVg8zSkjBqMUnETvqFD2Hs0lO7/6P5pSisSjZpGbwcksewm8A+GORXDNWxA9EA6tZ9G2w0Q28WVY+3BdLsN60VVWCqWIwIC/wD2/ayXRoqf+bnchbPwM3j0fXukFO76DCx6Gu5dVHHWIQLcxcGg9ZB50bpsBEpeAskFhDqSsr7pM0u/6++DKmq+VulErg6GT9fnOhRXz9/4Kv/0Xet8Mt82D3CPw1e2QlgAzroTP/0T3bc/p0URtSVlbfnzATr59v4GHN2Tuhw2f1v56tcRpSkFEokVkiYgkiMg2EXnASn9KRFJEZKP1ucKuzqMiskdEdorIZc6SrT7oFR2KUrC1htHCR38kcdH/fmP9gYx6lMxwTpG+F7Z+BQPugMAwnda6H+roDlbvOsil3VrgYS245Hii/q5OKZQS1h6umw5jZ8DVr8ENH8LfdsCo/8Kge+C+NXDRP8E36NS6Xa3dS7cvqP76tZ1zSN+rTVTLXoK8zFPzd/+iR0WI7sFXRdIf+vvg6prvtWEWePnB+X+D5t1hx/fledmp8PWd0LyrHkm17gejX9Iv77eHwJEE6D+RoBP7YcMnFeV7vp0eyVVF8hrtBRbSpnwkoxTsW6qVa9QAWPoCFOXXLHsdceZIoRj4m1KqGzAYuFdEull5Lyul+lifhQBW3jigOzAKeEtEGu2WT72jQgBYvjed+ZsO8dCXm/h+c2pZ/r5jJ3h+0Q4Alu466hIZz0UWLFiA7Vzyu//jFd2rHDK5PK1VP0TZ6FCcyGXdW5SnlyqFprHUGf+mMPgeGPV/EFrDxjxh7SGyB2yff2pe6iaYMRreGFC7F92vz+iX+eKn4eXu2pxS+re12WDPz9DxEmjZW7+gK5N5ALIOgJc/HFxVvTIqyoctX0KX0eAfqr2yDqzQ5iGl4LspUHgCxn4MPgG6Tt8/wYWPQN9btZIc/QpZTbpqmQtytEL7+g44mQ5bv6n6vslr9Yu/7RA9UlAKju6E3DQ9OhvxT8hOgfUfn/63qgNOUwpKqVSl1HrrOAe94XnrGqqMQW96XqCU2gfsAQY6Sz5nExrgQ0xYAG8s2cP9szcwb9Mh7v1sPZ+sSKLEpnjoy034eHoQGx7IchN+u974/PPP6dixIw8//DA7duxwtTjOJfOgjl/UfwIER5ant+4HwEDfJAa1a1aefjwRgiKr7uE7kq5X6ZdcTpo+z8+i08434N0L9QRt+u5T5x2KCyu+tA9vhW3fwHlT4O6leqHdsv/B9nlW/iY9P9LxEmg3XCuPgkqm2tJRQv8J2vUzvZqQHju/h/xM6HuLPu9yhTZL7foRtn6tvy96HCI6Vaw34lEY8wYENQcR9nS4Q8v067Pw+a16xXhEV9j1w6n3zErRL/zWcXqC/sQR/fcpVW6xF+h2tR2m2114smL97NSqR0+1wOuMatUREYkB+gKrgGHAfSJyG7AWPZrIQCsMe8NeMlUoERG5C7gLIDIykvj4+LK83NzcCueu5vKoEpKaeNOvuSdtmnjw9sYC/jVvG3N+3862dBt39vQhObeQn5NOsGjxEnw95bTXbGhtdDTObt9f/vIXxo8fz+LFi7nuuusQEUaNGsXIkSMJCAhw2n1dwh+v6u+h91dILvYP5wjhjGySjLenXb/w+L7Tm44cQderIf4/eu6h93iYdSMtDq+BIffCBQ/Bx1fB8td1L9vDQ7/cpl8IzdrDTZ/q3nj8f7RpaOhkPUoZOwPeHqZfuF2u0qYZgPYj9Uv5j1d0777jJeVy7P8d/EKh/+2w6h09WgjvWJ6feVCPNla+rWNBxV6o01v20Ws5Nn4GR3dAq34weNJpm53TpBP0vBFWva0Vwi1fweEt8MuTeoI+JKq8cOl8QtSA8tHHgZWQ+BuEttVmJdDK6KPLYfV0rSBL+W6KHlXct1Y7CtQBpysFEQkCvgamKKWyReRt4N+Asr7/B9xR2+sppaYD0wHi4uLU8OHDy/Li4+OxP3c1wyudXzTcxtTPN/Ld5lRGdmnOYzfH8duuo/zw0RoC2/TkvI7hp71mQ2ujo6mv9g0ePJg2bdrwyiuvkJCQwPz587n//vuZPHlyleVFZBTwKuAJvK+Ueq5S/svACOs0AGiulAq18iYAj1t5zyilHDver4rMg9qs0OdmCI2ukLV633EyS9pxYUmlnvHxRN3jdjbNu2r31m3fwq5FcHAV27s9RPfL/qnzhz0AX/9Z96C7XAk/Pqrbk3lAu5gOf1QrlOGPaYUA4OGpX5Cf3wKbPtMv81Z9ISgCfIeAp6+eV7BXCkl/6HAe4Z30dQ6u0mYfgJ+f1IoEtE3/smf1PUBPmHe5Ur+IPbxgzPzyvNMx8gk9uT3kXugwUiuCX57Uo40Bfykvl7xGy9yip76Hf1NdL+l36HZ1ebm2Q6HDJfD7y9B/ojZv7f5FX+/ip+usEMDJ3kci4o1WCLOUUt8AKKXSlFIlSikb8B7lJqIUwP7pjbLS3AZvTw9eHdeXV8f14aUb+yAiDIhphpeHsHzvsbJyOw5ns2y3mWdwBvPnz+faa69l+PDhFBUVsXr1an744Qc2bdrE//73vyrrWHNbbwKXA92A8XbzYwAopaaWzpMBrwPfWHWbAU8Cg9DP+pMi0tRZ7Stj2Yv6+4KHTsn6KSGNBNoTeOKAdtsEbRPPSa3oLeQsRLQJKWkZ7F4EV/6Po82Hled3u0a/iP94DXb+oF/y5z8I172nJ1xnXm3NYVTqnXe5Uptbfn1Wv1Q7WArA2x/aDNK97FKyD2lvq7bD9GgkamD5ZHNWCqx4U8t472qYshm6X1PxXl2v0t/nPQiR3Wvf9tBomLoNht6nz8M76TmcnT9WLJe8Ts+FePlo+aIHa3NZQZY2G9kz8l/avLX8dW1m+/ERPeKrxeilKpzpfSTAB8B2pdRLdukt7YpdC2y1jucD40TEV0RigY7AaVwCGh+eHsKYPq3LFrsF+nrROzqUFYl6XqGoxMY9n6xj8uwNKBMzxuF8/fXXTJ06lS1btvDQQw/RvLnecjIgIIAPPvigumoDgT1KqUSlVCEwBz0HVh3jgdLwopcBPyuljltm0p/RjhTO4/g+7arYb8IpowSlFD9tOwyt++uEQ5arZkaS/q4P8xFAjxt0T3jE4zDgzxXzPL10T/rgSr2at3l37eLa8wYY+xEgWtn5NalYT0T3xHMPa5u//agg9kLt63/C6nyVevPEWMooeqA2BeVlaIWgbHDpsxDRWV+3MjHnw8Tv4cJ/1L3tHnavXRHt1rtvqVbMoNceHNoAUXHl5doOgWJr8j32gorXa9kbelwPK9+CJc/qOZnL/gNevnWXDeeaj4YBtwJbRGSjlfYYupfVB20+SgLuBlBKbRORL4AEtOfSvUqpcyKi3JB2Ybz9215yC4r5dkMKSel60ig5I4/oZm5m53YxTz31FC1blvdL8vLySEtLIyYmhpEjR1ZXrTVg71ifjO75n4KItAVigV9rqFulw4Wj5ss673iV5niwymsIhZXq7M0s4VBWPqp1BAD7fv+G/clehB9dQQ9g7b4Mco/V7j5ni8fQmdiUH8THn9I+j5IYhngF41l4gvXRfyb399LFZSF4Dp1JSUEAVPN79Grah6DcfSzfkwN7dZng7Cb0B7YveJ20FiPotPMLmnsG8PvO47ArntAMX/oA2+e9SqddH3C0+fns2LQPqGKRmj2l6xxqQXV/w9C8lvQpKWDrvNc5FjGYoJy9xBXnsS07gKNW+SZZvvQDTgS0Yc3aBPRrshz/gIsZWPQt8scrpDfrx5ZDvpBa9e9zOpymFJRSvwNVzZwurCKttM6zwLPOkqmhMrR9GG8s2cNvO4/y2uLdtGjix+HsfLamZBml4GDGjh3L8uXlq1c9PT0ZO3Ysa9ascdQtxgFfnUmHxiHzZcd2w2/xMPivDL3s+lOyf/8uAW/PJO4aeyW835FY3wxiB/WGjx8H7wDiLr0JfIPrKvpZU2X72n4MRXnEdR1dt4sNmgf5mQwvnYwFsJ0Pe1+j687X6ep/DPJ3QrvzGD7C6ggUDoDNT9L1wEyw5dPi+udo0bzr2TTpFKr9G5YMgx0v0sPnoB55LN8EQPdLJ5S79xYPhYT/I7DPmOqfA9ta2PAJYePfZXhlT6g6YFY0NwD6tW2Kj5cHT8zbytGcAl66qTdeHsLWQ+4TJiO/qISLXoznizX1sJK1BoqLi/Hx8Sk79/HxobCw8HTV6jLfNY5y01Fd6549G2eBeMKwKadk2WyKhVtSuaBjBCH+3to1NXkNfHKd9lS58ROXKIRq6TAS6qoQQE+22isE0BPBd/4Kg+6GzV9qc1lbu3kMn0A9qXsyHTpfoSfD6wtPb93Wrd/ACx3g5ye0d1OI3WPj5QOT/tBrE6rjihfggU2nusbWEaMUGgB+3p70s/ZkuKRbJEPbh9MxMpgtKfUbMteZzN94iMRjJ1iZ6No1GREREcyfX75wat68eYSHn9braw3QUURiRcQH/eI/ZfWViHQBmgIr7JIXAZeKSFNrgvlSK8055B7Raw2CIk7J2nAwk0NZ+YzubZnPWvXTfvOHN+uFVx0vdppYDYKg5jDqP3D/Brhkml6fYE+0ZRE8b2r9y9Z/ona57XgJjH5Fx4yqPJcRGq0nzavDw1PHmDpL6mWdguH0XNApgjVJGTx8WWcAerRqwq87jqCUqrAFaCk5+UUE+3mfkt4QUUoxY3kSAPvST7hUlnfeeYdbbrmF++67D6UU0dHRzJw5s8Y6SqliEbkP/TL3BD605sCmAWuVUqUKYhx6Aaayq3tcRP6NViwA05RSxx3esFLyMsrdNCvx3eZD+Hh5cHFXayFb+xEQEKZDM3S5oso6bklIa+32Wpmhk/XoKdoFa2bbXQiTaj8/4UyMUmgg/Pm8WK7o0VLHtAd6RoXw5bpkUrPyaRVasXewNSWLa978gzdv6VcxTEEDZf2BDBJSswnx9ybpmGuVQvv27Vm5ciW5uXp1a1BQ7VbvWuFYFlZKe6LS+VPV1P0Q+PAMxK07eRnafFKJUtPRhZ0iyjsTEZ3hob1Ve9eci4RGQ+g4V0vhcmqlFEQkEMhTStlEpBPQBfhBKVWPWxC5N75enmUKAaB7Kx07aWtK1ilK4ZVfdlFsU3y26oBDlMLutBw+/GNfeQhlBzNj+X6C/by4fVgMr/yym8yThYQG+Jy+opP4/vvv2bZtG/n55fF1nnjiiRpqNCLyMrTveyXWHcggLbuA0b1aVswwCsFQidrOKSwF/ESkNfAT2tV0hrOEMkC3lk3wEK0U7EnKKuGX7UeIbOLLst1HScs++wiJbyzZw+zVB/lhy+GzvlZljmTn88OWVG6Miy5TdPtcOFq45557+Pzzz3n99ddRSvHll1+yf/9+l8njcKoxH3236RC+Xh6MLDUdGQzVUFulIEqpk8B1wFtKqbHoaKYGJ+Hv40mH5kFsPVRxsnn+3iKa+Hkx/dY4bArmbazakUUphc12+sVvmScL+WGrVgafrnT8y/Gz1QcotiluHdyW2HDtXpvkwnmF5cuXM3PmTJo2bcqTTz7JihUr2LVrl8vkcShKVakUSmyKhVsPM6Jzc4J8jcXYUDO1VgoiMgS4BSgNJN5ow1o3Fnq0CmGL3Ugh4VA264+UcMd5sfSODqVvm1C+XpdS5crnv3+5mfHvrTztquhv1qdQWGzj+n5RrN2fQcIhx3k8ZZ0s4uPlSYzoHEFMeCDRzQLwENh37OTpKzsJPz8/QK9gPnToEN7e3qSmpp6mViOh6CSUFJ6iFFbtS+doTkG515HBUAO1VQpTgEeBby2vi3bAEqdJZQCgR+sQjuYUcCQ7H6UUr/yyC38vuH2Yjk9zfb8odqblsK3Sizwnv4gFmw+xat/xGjfwUUrx+ZqD9I4K4V+ju+Lr5cGnqxw3Wnh18W6y8op46LIugJ43ad3U36WTzVdddRWZmZk89NBD9OvXj5iYGG6++WaXyeNQ8qy/dSWl8N3mVAJ8PLmoS3MXCGVobNRKKSilflNKXa2U+q+IeADHlFL3n7ai4azo0Vrb4NckZTD18438lJDG5bHeeuERcFWvVvh4efDVuuQK9X5OSKOw2IaXh/DhH0nVXn/DwUx2puUwbmAbQgN8uLp3K+ZuSCGnhi1Ea8ueI7nMXJHEuIFt6NaqPEZNTFigy8xHNpuNkSNHEhoayvXXX8/+/fvZsWMH06ZNc4k8DqcKpVBUYuOHLamM7BpJgI8xHRlOT62Ugoh8JiJNLC+krUCCiJwaftHgULq1aoIITP1iI/M2HeKhyzozul352oSQAG8u6RrJ/E2HKCwu301swaZDtA71Z+LQGH7cepjUrLwqrz9n9QECfDy5qrde8PKnwW05WVjCtxvOfsHtM98n4O/jyd8uqegJExseyL6jJ1wS7M/Dw4N777237NzX15eQkJB6l8NpVKEUlu9NJ+NkEVdV9joyGKqhtuajbkqpbOAa4Ad0wK9bnSWUQRPk60XnyGB8vTz4cMIA7h3RAY9KLoTjBkZz/EQhM1ckAZBxopBlu48xuldLJgyNQSnFJytONQnl5BexYFMqV/VqVTb52Ds6lF5RIbz88y4e+XozX6w9yLHcgjrLvWTnEeJ3HuWBkR0JC6oYqTEmLJCcgmLST5w2tIRTGDlyJF9//bV7RqCtQiks2HSIYF8vLux86gpng6EqaqsUvK29Ea4B5lvrE9zwv6rh8eHEAfz6t+GMqMYefF6HcC7q0pxXftlNWnY+i7YdptimuKp3K6KbBXBJt0hmrz5AflHF+GwLt6SSV1TCTQMrhlZ+5poe9IoKZeGWVB7+ajP3zlpfIV8pxezVB0ivQVnMWrmf1qH+3DYk5pS8WGsthqvmFd59913Gjh2Lr68vTZo0ITg4mCZNmpy+YmOgklIoKC5h0bbDXNq9hVPWnxjck9oqhXfRYa4DgaVWeGD3CczTgGkV6k9EcPVx0UWEJ6/qRmGJjWe/386CzYeIDQ+ku2XHv31YLBkni5hbyST09foU2kUE0jc6tEJ6r6hQPr5jIBufuJQJQ9qy4UBmBYWyNSWbR7/ZwhPzt1Upj1KKDQcyGdwuDB+vUx+vUqXgqrUKOTk52Gw2CgsLyc7OJicnh+xsN3mUKymFpbuOkZNfzFXG68hQB2o186SUeg14zS5pv4iMqK68oX5pGxbIpAvb8+ri3YjA5BEdyuIlDYptRo/WTXh3aSI39I/Cy9ODg8dPsnrfcR66rHOVcZUAPDyE8zpG8PGK/Ww6mMmgdmEAZTvEfb85ldsGp5ell5KckUf6iUL6tAmt8rpRTf3x8hCXKYWlS5dWmX7BBRdUmd6oyMvQG9dYQdO+33yIpgHeDOtw+m1eDYZSahvmIgS9pWDpf85vwDTAfWI7N3ImDW/PNxuSOXg8j9G9yyMligj3jejIPZ+uY8HmQ1zbN6psIvmavlXu9VLGgBjd41y973jZy39FYjptwwIoKrbx9IIEFkw+D0+PcsWy4WAmwCkjkFK8PD2IbhbgMg+kF154oew4Pz+f1atX079/f3799dcaajUSSheuiaCU4vc96VzQKQJvTxMM2VB7auuj9iHa6+hG6/xW4CP0CmdDA8DP25NXx/Vl6a6jdIqsGBP/0m6RdG3ZhNcX7+GqXq34Zn0yQ9qF0Tq0hjC8QGiAD50jg1mdpIN6FpXYWLPvONf2a82g2DAmz97AF2sPMn5gm7I6Gw9k4uvlQecW1cfljwkLcNkCtgULFlQ4P3jwIFOmTHGJLA7HbjVz4rETHMstYFBs2GkqGQwVqW0Xor1S6klrj9pEpdTTQD1t5mqoLf3aNGXKxacGQ/PwEB4Y2YHEYyd4ekECSeknua5fzaOEUgbENmX9/gyKS2xsScniRGEJQ9uHM7pXSwbENOXFRTvJtlvXsPFgBj1bh9TYO40JD2R/eu3dUsdPX8krvzgnFEVUVBTbt293yrXrnbzMMqWwep9W5IPaNXOhQIbGSG1HCnkicp61xSYiMgyo2vnd0CC5tFsLurQI5pOV+/H39uTynrWbfBwQ04xPVx5ge2oOK/bqDXIGtwtDRHjsiq5c+9Zy5m5I4bYhMRQW29h6KJvbBret8ZrtwgM5WVjCkZwCIpv41Vg2LTufFYnp5BeXVKnw6srkyZPL5lFsNhsbN26kX79+Z33dBkFeBoTq335VYjrhQb60s4u8azDUhtoqhXuAmdbcAkAGMKGG8oYGhh4tdGTSrPWM6tGi1oHRBsbqnubqpOOsTEynS4tgmgXqsNd92zSlW8smfLH2ILcNiWHH4WwKi23VTjKXUhoifO/R3NMqhVJFtOtwDjabwsOj6onx2hIXF1d27OXlxfjx4xk2bFgNNRoReRnQsg9KKVbtO86gds2qdSQwGKqjtt5Hm4DeItLEOs8WkSnAZifKZnAwl3VvwYOXdDo1pn4NtAzxJ6qpP3/sOcaapOOMG9CmQv5NA6J5cv42th3KYmPpJHObqnf+KqVHqxACfDyZvjSRIdaoozpKvZ1OFJaQkplHdLOAWsteFTfccAN+fn54emq//ZKSEk6ePElAwNldt0FgbbBz8HgeqVn5DI41piND3amTW4JSKtta2QzwoBPkMTgRDw/h/pEdaRdRu93GShkY04wlO4+QX2RjSPuKE5dj+uj4S1+sOcjGA5lEBPvSKqTm3n/TQB/+fmln4nceZf6mQzWWXb43vex6Ow7n1Enuqhg5ciR5eeWWz7y8PC6+2A32Ji7K11FS/Zuycp8eXVV2FzYYasPZ+KrVOC4VkWgRWSIiCSKyTUQesNKbicjPIrLb+m5qpYuIvCYie0Rks4i4iaG38TMwthlK6U26BlfyZgkN8OGy7i2Yu/EQa/Yfp090aK1MFhOGxtA7OpRpCxLIOFGIzab4fnMqi5LKJ60PHj9JckYefxqi7eQ7D5/9IrP8/PwKW3AGBQVx8qTrQnk7jPxM/e3flFWJx2ka4E2HOip/gwHOTimcznWkGPibUqobMBi4V0S6AY8Ai5VSHYHF1jnA5UBH63MX8PZZyGZwIAMsM0S3lk0ICfA+Jf+muGiy8oo4eDyPPtWsT6iMp4fw3HU9ycorYvLsDVz+6jLu/Ww9s3cUlpmMSr8v7RZJVFN/tjtgpBAYGMj69eWhO9atW4e/f82uuY0Cu9XMq/alMzC22VnPvxjOTWpUCiKSIyLZVXxygFY11VVKpSql1lvHOcB2oDUwBvjYKvYxOp4SVvpMpVkJhIqIWZ/fAGgXHkj7iEBGVbMf9ND25Wseqlu0VhVdWzbhrgva8fueYxTbbLx8U2+a+gov/7wLpRTL96YTEexL+4ggurQIZqcDlMIrr7zC2LFjOf/88znvvPO46aabeOONN876ui7HUgrHbIEkZ+SZ9QmGM6bGiWalVPUrkOqAiMQAfYFVQKRSqnSrq8NA6aaxrYGDdtWSrbQK22KJyF3okQSRkZHEx8eX5eXm5lY4d0dc1cbH+ykgmfj4qsNqD2lezHc5kJW0hfjk2vdQ43wV/xzkR/tQhUfWHi6NsvH53gze/Hox8dsL6drMg99++w2/gkISjxbx869L8D7LHvC7777LwYP6UYuOjiYnJ+e0v6mIjAJeRe84+L5S6rkqytwIPIUeRW9SSt1spZcAW6xiB5RSV59VA6rCUgqb063wJmZ9guEMcfquGyISBHwNTLG8lsrylFJKROoUbVUpNR2YDhAXF6eGDx9elhcfH4/9uTvSUNt4wQWKR04WEh5UffC+6rjI7rjItoTf0xWz90BWgeKaId0YPrAN2U0P8V3iBlp16Uf3VtXvgfDmkj0s2naYefcOq3Ju48033+SWW24pm1zOyMhg9uzZ/PWvf632miLiCbwJXILurKwRkflKqQS7Mh3RuxMOU0pliIh9WNs8pVSfWvwUZ46lFNakQbCfF11auEnkV0O949SgKFa47a+BWUqpb6zktFKzkPV9xEpPAezjOEdZaYZGgIeHnJFCqIy3h3DfRR1IydQeQkPb62BuXa2wGaUmpKRjJxj9+jL2Hs2tUP+b9clsTs7iwPGqJ4/fe+89QkNDy86bNm3Ke++9dzqxBgJ7rNX8hcActLnTnjuBN5VSGQBKqSPUJ5ZSWHmohH5tmlaIR2Uw1AWnKQXR3bQPgO1KqZfssuZTvvBtAjDPLv02ywtpMJBlZ2YynEPc0D+K6Gb+tA71J7qZnquICQ/Ex9OjTCm8/usetqZkV9iK9ED6SfYe1YH2ViUer/LaJSUlFcJr5OQVUFh42g1/qjNt2tMJ6CQif4jISsvcVIqfiKy10q853c3OiLwMlHiy8ahWCgbDmeJM89EwdOC8LSKy0Up7DHgO+EJE/gzspzzI3kLgCmAPcBK43YmyGRow3p56p7n8IluZCcjb04P2zYPYcTiHg8dPMndjCiLww5ZUHrZCgMfv0p1zP28PVu5L58YB0adce9SoUdx0003cfffdbE3J4unnX+Wq8y46pdwZ4IX2nBuOHuUuFZGeSqlMoK1SKkVE2gG/isgWpdTeyhc4m/myjnu30cwjEKUEr8wD1c79NFTMfGDDwWlKwYqTVN0YdmQV5RVwbxVlDecgHSNP9XHo0iKYFXvTmb40EQ+Be4d34LVf97DjcA5dWzZhyY4jxIQF0LVlk2pHCv/973+ZPn06z730Oqv2pdO8bSe8KaqyrB21MW0mA6usXQn3icgutJJYo5RKAVBKJYpIPNrp4hSlcFbzZUdncPx4KB4Ct42+gGC/U12HGzINda7MkTSWNppA64ZGQ+cWwRzOzufzNQe5vl8Utw2NwcMaLeQXlbB8bzrDOzdnUGwzUjLzSM44dV7Bw8ODlh17sCnTm8LUXUSe2EOfnj1Od+s1QEcRiRURH2Ac2txpz1z0KAERCUebkxJFpKmI+NqlDwMScDR5GaTbAukUGdzoFIKhYeF07yODwVGU7tFQbLNxz4XtCQ/yZWBsMxZuPUzftk0pKLYxoktzIqwJ71WJx4nqr2Ma7dq1i9mzZzPrs9kcLvAitMdwvIN8+WPpb6e9r1KqWETuAxahXVI/VEptE5FpwFql1Hwr71IRSQBKgIeUUukiMhR4V0Rs6E7Yc/ZeS45C5WWQWuBH/65mPsFwdhilYGg0dLXcLK/q3aos0uoVPVvyxLxtvLc0EX9vTwbFNsPH04MQf29W7Uvn+v5RAHTp0oXzzz+ff7z0If9elsHHdwzk9lELa31vpdRC9LyXfdoTdscKHQ/swUpllgM9z6S9daEo9zjHbG3p39YoBcPZYcxHhkZDixA/Xh/fl3+N7laWdln3FojowHnDOoTh5+2Jh4cwIKYZq/aVzyt88803tGzZkikTriPn5zcoSNpY601+GgV5GWSpQON5ZDhrjFIwNCqu6t2qwnqIyCZ+xFm94+Gdy9eLDW7XjP3pJzmclQ/ANddcw6zPZtNu0nQGDD2f119/jSNHjjBp0iR++umn+m2Eoykpwqc4lwLvENqGuUEIcINLMUrB0Oi5uk9rvD2FEV3KlUJp7J9VVhhp0FuFZhV58te/TGTBggUkJyfTt29f/vvf/9a7zA4lPwuAJk2bm011DGeNUQqGRs8tA9vw20MjyoLyAXRr1YRgXy9WJpYrhV+2H8HLQ7iwUwSgVzPfddddLF68uN5ldiSZx/X6jOaRVQcsNBjqglEKhkaPh4fQKrRi+GtPD+Girs35Zn0Ke47oUBiLt6cxIKYZIf7u5bK5e98BAKJbVV5kbTDUHaMUDG7LP6/sSoCPJw9+sZHEo7nsSsvl4m6Rp6/YyDicpqPBtGldYzR7g6FWGKVgcFuaB/vxf9f2ZHNyFnfOXAvAxV2bn6ZW4+N4ehoA/k3CXSyJwR0wSsHg1lzesyXX9m3N3qMn6NA8iLZhga4WyeFkZ1q7rvk6ZPsTwzmOUQoGt+epq7vTLjyQ6/tFuVoUh1NYbONkrvY+wtfsyWw4e8yKZoPbE+LvzeK/XeiW7pr7jp3Aj3wUgni5wV7TBpdjRgqGcwJ3VAgAu9JyCCIfm3cAeJh/Z8PZY54ig6ERsysthyDJx8OYjgwOwigFg6ERs/NwDhG+xYiPUQoGx2CUgsHQiNmVlkOEbxH4uJ9XlcE1GKVgMDRS8gpL2H/8JE09C8GMFAwOwigFg6GRsudILkpBsEeBcUc1OAyjFAyGRsqutBwA/Mk35iODwzBKwWBopOxKy8HHywPvkjyjFAwOwygFg6GRsjMthw4RQUhhrplTMDgMpykFEflQRI6IyFa7tKdEJEVENlqfK+zyHhWRPSKyU0Quc5ZcBoO7sOtwDp0jg8AoBYMDceZIYQYwqor0l5VSfazPQgAR6QaMA7pbdd4SEU8nymYwNGqy84s4lJVPlwhvUDZjPjI4DKcpBaXUUuD4aQtqxgBzlFIFSql9wB5goLNkMxjqioiMskaxe0TkkWrK3CgiCSKyTUQ+s0ufICK7rc8ER8iTePQEAJ2aWv/CZqRgcBCuCIh3n4jcBqwF/qaUygBaAyvtyiRbaacgIncBdwFERkYSHx9flpebm1vh3B1x9zY2xPZZo9Y3gUvQz+YaEZmvlEqwK9MReBQYppTKEJHmVnoz4EkgDlDAOqtuxtnIdDgrD4DWAcU6wYwUDA6ivpXC28C/0f8c/wb+B9xRlwsopaYD0wHi4uLU8OHDy/Li4+OxP3dH3L2NDbR9A4E9SqlEABGZgx7dJtiVuRN4s/Rlr5Q6YqVfBvyslDpu1f0ZbSKdfTYCpWblAxDpW6ITzDoFg4OoV+8jpVSaUqpEKWUD3qPcRJQCRNsVjbLSDIaGQGvgoN15VSPZTkAnEflDRFaKyKg61K0zh7Py8fHyoIlngU4wIwWDg6jXkYKItFRKpVqn1wKlnknzgc9E5CWgFdARWF2fshkMZ4kX+rkdju7ULBWRnnW5QF1Moxt35RPqo9i8dgW9gfXbdpOd3Hi3R2mIZkNH01ja6LSnSERmo/9BwkUkGW1XHS4ifdDmoyTgbgCl1DYR+QI9HC8G7lVKlThLNoOhjtRmJJsMrFJKFQH7RGQXWkmkoP8P7OvGV3WTuphG39yxnHYBQu8u7WAz9Bt0HrSokw5qUDRQs6FDaSxtdJpSUEqNryL5gxrKPws86yx5DIazYA3QUURi0S/5ccDNlcrMBcYDH4lIONqclAjsBf5PRJpa5S5FT0ifFalZ+QyIaQaF2gvJeB8ZHEXjHW8aDPWEUqpYRO4DFgGewIfW6HYasFYpNd/Ku1REEoAS4CGlVDqAiPwbrVgAppVOOp8pNpsiLTufFiF+RikYHI5RCgZDLbAWWi6slPaE3bECHrQ+let+CHzoKFnSTxRSVKJoGeIHBToonploNjgKE/vIYGhkHLbcUVs0sUYK4gHe/i6WyuAuGKVgMDQyUq2Fay1D/LVS8AkCERdLZXAXjFIwGBoZpQvX9JxCrjEdGRyKUQoGQyMjNSsfb08hLNDHKAWDwzFKwWBoZBzOyiOyiR8eHlJuPjIYHIRRCgZDIyM1K59WIdbEslEKBgdjlILB0Mg4XLpGAYz5yOBwjFIwGBoRSilSs/L1GgWAAqMUDI7FKAWDoRGRcbKIwmKb3UjhhAmbbXAoRikYDI2IQ5mlaxTslIKZUzA4EKMUDIZGRNlq5hB/UMrMKRgcjlEKBkMjIjVbK4WWIX5QdBJQRikYHIpRCgZDI+JwVh6eHkJ4kK+JkGpwCkYpGAyNiNSsfCKDffH0EG06AqMUDA7FKAWDoRFxOCuflqF2C9fAmI8MDsUoBYOhEXE4y27hWoE1UjAuqQYHYpSCwdBIUEpxKCuPlk3s3FHBmI8MDsUoBYOhkZBXVEK78CDaRVhKoGxOwZiPDI7DbMdpMDQSAny8WPjA+eUJRikYnIBRCgZDY6XMfBTsWjkcRFFREcnJyeTn57taFKcQEhLC9u3b6/Wefn5+REVF4e3tXes6TlMKIvIhMBo4opTqYaU1Az4HYoAk4EalVIaICPAqcAVwEpiolFrvLNkMBrfAzUYKycnJBAcHExMTg7jh9qI5OTkEB9efAldKkZ6eTnJyMrGxsbWu58w5hRnAqEppjwCLlVIdgcXWOcDlQEfrcxfwthPlMhjcg8ITIJ7g5etqSRxCfn4+YWFhbqkQXIGIEBYWVueRl9OUglJqKXC8UvIY4GPr+GPgGrv0mUqzEggVkZbOks1gqCsiMkpEdorIHhF5pIr8iSJyVEQ2Wp+/2OWV2KXPd5hQBbna88iNXqJGITiWM/k963tOIVIplWodHwYirePWwEG7cslWWiqVEJG70KMJIiMjiY+PL8vLzc2tcO6OuHsbG2L7RMQTeBO4BP1srhGR+UqphEpFP1dK3VfFJfKUUn0cLpgJm+1Q0tPTGTlyJACHDx/G09OTiIgIAFavXo2Pj0+1ddeuXcvMmTN57bXXarzH0KFDWb58ueOEdgIum2hWSikRUWdQbzowHSAuLk4NHz68LC8+Ph77c3ekwbbx4BpYNwOufg08PM/4Mg20fQOBPUqpRAARmYMe3VZWCvWLiZDqUMLCwti4cSMATz31FEFBQfz9738vyy8uLsbLq+pXZlxcHHFxcae9R0NXCFD/SiFNRFoqpVIt89ARKz0FiLYrF2WlGRoLK16HhHkw5K8Q2d3V0jiaqkayg6ood72IXADsAqYqpUrr+InIWqAYeE4pNbeqm9R1FNzz8EG8i2ysb2AjqzMhNzeXkJAQcnJyXC0KAAUFBXh7e3PLLbfg5+fHpk2bGDx4MNdffz3/+Mc/KCgowM/Pj7fffpuOHTuybNkyXnvtNb788kv+7//+j+TkZJKSkkhOTmbSpElMmjSJkpISgoKCSE1NZdmyZfznP/8hLCyMhIQE+vTpw/vvv4+IsGjRIh577DECAwMZNGgQSUlJfPnll2fclvz8/DqNvutbKcwHJgDPWd/z7NLvs3pgg4AsOzPTmVN4Er5/EFr00i8rg3MoyoPdP+vjAyvrphRsJXBoA0SdvpdF4Ql4awhc8jR0v/bMZHUeC4DZSqkCEbkbPWd2kZXXVimVIiLtgF9FZItSam/lC9R5FJz4HHi0bIgjqzoTHx+Pn59fmXfO0wu2kXAo26H36NaqCU9eVbtn09fXF19fX7y9vUlLS2PVqlV4enqSnZ3N8uXL8fLy4pdffuHZZ5/l66+/JiAgAC8vL4KDg/H19WXv3r0sWbKEnJwcOnfuzNSpU8smfIODgwkICGDz5s1s27aNVq1aMWzYMDZv3kxcXBxTp05l6dKlxMbGMn78+LLrnil+fn707du31uWdNtEsIrOBFUBnEUkWkT+jlcElIrIbuNg6B1gIJAJ7gPeAs3+DF+TCZzfCptmw+t2zvpyhBvb+asX2Fzi4qm51t3wF74+Ew1tPX3bfMsjcDzu+PyMxz4LTjmSVUulKqQLr9H2gv11eivWdCMQDtf8PrYnCXBPioh4YO3Ysnp7aJJqVlcXYsWPp0aMHU6dOZdu2bVXWufLKK/H19SU8PJzmzZuTlpZ2SpmBAwcSFRWFh4cHffr0ISkpiR07dtCuXbsyF9Lx48c7r2HV4LSRglKqutaMrKKsAu512M3zs2HWWEheA+0v0i+trBQIae2wWxjs2L4A/EKhzZC6K4X9f+jvgyuhRY+ay+791Spb6R42G2SnQGj0qXUcwxqgo4jEopXBOOBm+wKlZlHr9Gpgu5XeFDhpjSDCgWHA8w6RqvCE284p1LZHXx8EBpb/xv/6178YMWIE3377LUlJSdWO0nx9y92EPT09KS4uPqMyrsA9Yx/NnQQpa+GGD+Hip3Ra6cvH4FhKimDnQuh8BcQMg4wkyDm1V1QtyWut73WnL7t3MSCQeQCy7ayL6z+G1/rW7b51QClVDNwHLEK/7L9QSm0TkWkicrVV7H4R2SYim4D7gYlWeldgrZW+BD2n4JgJajdWCg2VrKwsWrfWncsZM2Y4/PqdO3cmMTGRpKQkAD7//HOH3+N0uKdSGPkkjPsMul8DkT3AN8QoBWeRtAzys6DrVRA9WKcdXFm7ugU5cMR6P6asrblsxn5I3wM9rtfnyavL87bPB1sRHKrjIvjCE7DtWz0nchqUUguVUp2UUu2VUs9aaU8opeZbx48qpborpXorpUYopXZY6cuVUj2t9J5KqQ/qJmQNFOSCr3uEuGgsPPzwwzz66KP07dvXKT17f39/3nrrLUaNGkX//v0JDg4mJCTE4fepCfeMfRTRSX9Au0e2GQxJRik4he0LwDsQ2o+wVtf6wcHV0G2Mzl/6IgQ1h363nVo3ZR2goM1QOLAc8jKrv8/exfr7vCn6nqX3KMiFpN913qGN0Pny8jqL/62/R/6r6mvuWAjf/AUmLtSjnMaEzQZFZqTgLJ566qkq04cMGcKuXbvKzp955hkAhg8fXmZKqlx361Y9X5aTk0Nubu4p5QHeeOONsuMRI0awY8cOlFLce++9tXJ1dSTuOVKoTMwwSN/tNPNCrTi2u+aXnqMpyi8PmOYsbCWw/TvoeAl4+4OXD7Tqpz2QAFI3wa//hh8egRPHTq2fvEZ/D7pLf9fU09+zGJpE6ZFf637l8wr7foOSQvDw1vcrk80Gaz+A1e9BSTU9ui1f6Gu2GVK3djcEik7qb6MU3I733nuPPn360L17d7Kysrj77rvr9f7nhlJoe57+PuCihSOFJ2H6CFj8dP3cTymYfRN8dIU+LqW4EL64DfY76HfY/DmcOKJNR6VED9Qv56I8+OVp8G0CxXnwx6un1k9eC+Gdod2I8vOqKCmCfUuhw0U6pEP0QD0qKMqH3T/pKKFdR1dUCsd2QV4GFGRVbZo6cUwrml5jwaMR/huYrTjdlqlTp7Jx40YSEhKYNWsWAQEB9Xr/RvjfcAa07KVNHK4yIe3+CQpz6u/+exdDYjykbtRrAErZ+b1eYLb6vbO/x4ZZMO9ebfrpMro8vc1gbd//4zUtxwUPQc8b9T1zj5SXU0qPFKIHgH+oVg7VKYXktVCQDe0tx7XoQdYcwga9PqL9CIgaADmHyu9xYEV5/T2LT73m1m9AlWjZGiNlEVLNnILBsZwbSsHTG9oMcuxkc3GBfjHmZZy+7LZv9fexnXCycozAOrB/Bb75R2ouY7PB4mkQEq3t+xs/K89bN0N/71mse99nypoPYN5fIfZC+NNX4O1Xnhc1UH/H/weatIaBd8KFD2sTz++vlJc7nggn0/XLHPTitZS1FUc2pez9FcQD2l1Y8R5rP9SuqJ0ug5a9dVrpaOHASghsrq+/twqlsOULbYqK7HbGP4NLKX2OzESzwcGcG0oBoO0w7elyIr1u9UqK4as79KRl6QtLKVgwRb8Y3zm/3IZeFYUn9Ughoqs+r643fDr2r4CPLmfQqknw46O6HSeP6xf8pjn6PgAJc/WL8aLHdQ9+y5fazHJ8nx49tOqnTSpnakJK+kOvEu80CsbPOdV8ERgGYR0BBcMf0XMNYe2h9zht4y91JS39HUqVQuv+cDIdv/xK8z5Kwa4fdb5/U50WFAHN2um2AXS4BFr01MepG/X3gRV61NLhYkhZX1EZp+/Vo5RejXSUAOVzKq0csw7OYCjl3FIKALsXVd0brY6lL8DWr2HZi7Don7ruyrdg02fao8bDCz66HH57oerr7v5JTwpe/JT2zqmtu6Y9hSe1qSY0mrTI4bDqHfhfZ3g+Fj69Dr69G96I08rh12egeTfoORb63gL5mXodwfqZurd93XTw9NUv2rpSXAjfTYXQNnDDRxVHCPZ0uRJa9oHeduu7LngIbMXwzZ3aYyh5tTZ9RHTR+ZZyaJK9s+K1tn0LhzdD70prIaMHAUq/FIMjwS8EmrXXCjH7kF753GaIZXJSkLikvO6WrwCBHjfU/TdoKCT9rtvbxESYNziWc0cptO4HQZF6Ydvr/eDHx7RLYlVeMaXsXw5Ln9cvpEH3wMo34fM/wU+PQ9erYfSrcPdSHYdnyTOwa9Gp19j2LQRG6B5ry17albKuLHkWju+Fq99gZ5fJMGmFNstc/DTcNk9/AiO0cji+Fy76l3bFjb1Qm3DWfwwbZ0HHSyG8I8ReADt/KFdiqZtg9s0w/36I/69uR1UKbvlr2gR2xf/Ap4bJr0uehrviwdPO47lZLFzzjv5NP7lWh6xo3a88omrzbuAdQJPscnc/Ck/o37pFT+g/seI9oi0TUsfLytNa9oZDm8rnE9oM1vfwCy2fV1BKT5DHnNd4V7jbSvTvGHOeqyVxK0aMGMGiRRX/h1955RUmTZpUZfnhw4ezdq0e8V5xxRVkZmaeUuapp57ixRdfrPG+c+fOJSGhfD3jE088wS+//FJH6R2He65TqAovX/0C375A95LXvKdf8gChbaFJKwgM1y6KUXHQvCt8fSc0jYErXtAxZmzFsOZ9aN4drnlbe634NYFr39XeML88pd0zS190paaj3uP0CzJ6kO6xlxTpeY7acHCNHpn0v13b1A/EQ/MuMOo/FcvduQQ2z9Erikt99T08tUJbZj2UpS/WzqPg+79pD53Qtrqd2Yd0z//EUV2m7Xlw+XPlZpnj+/SoqdsY6HTp6eWuanOPXmP1Pb68XU8U23steXpByz40ybAbKSz7n54zuOHDU8Nxd7xUzwn0HFue1rI3bPtGK3vvQB0I0cMT2g3X8xK2Em36Or5Xj1waK2lbtQkw5nxXS+JWjB8/njlz5nDZZeUdjTlz5vD886ePSrJw4cIzvu/cuXMZPXo03brp+a1p06ad8bUcwbkzUgAIbqF72H/6Gh45ALf/oHvbrftrM9Cx3bpX/fWf4e2hkJsG13+gJ/NE4PIX4Lr3dX37zU08vWHkE3B0uzbhlFJqOup2jT6PHqjPD28pL1PTxLPNBt9NgeBWcMlpHhQPD+hzM4x4rOILuY9lwgluqW3voOcDQI8Wlj6ve/9jZ8BDe+CfaTD6FT3/8u4F8OEo3bP/9Hr9G416jrOi61UwfraeCO9yRcW8mPNokrMb3r8YVr4Dy1+HXuN0j78yIVEw6Q8I71Ce1qqP/k6YqxV76Uilw0jISYWZY/Rk+/l/04q6sVK6WK+xLbhr4Nxwww18//33FBYWApCUlMShQ4eYPXs2cXFxdO/enSeffLLKujExMRw7pq0Ozz77LJ06deK8885j587yTs6MGTMYMGAAvXv35vrrr+fkyZMsX76c+fPn89BDD9GnTx/27t3LxIkT+eqrrwBYvHgxffv2pWfPntxxxx0UFBSU3e/JJ5+kX79+9OzZkx07djjsdzh3RgqV8faHtkP1x56SYt0TS16jbeet+5XneXjo3m5VdBujlcuSZ6HHdZBzWPvmB0aUz2eUhYFYra+77mP90r/5S+h48anX3LFAy3Lde3pEciaEtYch9+ledelLMiRKjwDWfghZydDnlvL7e/tB3O06RMjSF7XbZ362VowXPa5HVGdLx0tgahVRUc//G7sPHafj8SXw4z/0nMMldVjb0aKX/rYVV1yQVurKmrRMdwLOm3LGojcIkn7XE+2O+Fs0VH54pGLnyRG06KlHv9XQrFkzBg4cyA8//MCYMWOYM2cON954I4899hjNmjWjpKSEkSNHsnnzZnr16lXlNdatW8ecOXPYuHEjxcXF9OvXj/79dcDcq666ismTJwPw+OOP88EHHzB58mSuvvpqRo8ezQ03VJzjys/PZ+LEiSxevJhOnTpx22238fbbbzNlyhQAwsPDWb9+PW+99RYvvvgi77//vgN+pHNZKVSHp5fucZb2OmuLiO7Nz7hSR2g9uFqbLq58ye5l3Fqbpw6u0pOxi/4JyqbNTu0vqriIymbT9v2wDuXxfs6Uy549Na3T5XqUENSi6nz/plWnOxNvP1KirqLjzS/olcq+wXp0V1sCmmlFnnmg4ugipLUeHYR1hD71H4rYodhsej6h29WnL2uoM6UmpFKl8MEHH/DFF18wffp0iouLSU1NJSEhoVqlsGzZMq699tqyBWdXX13+d9q+fTu33normZmZ5ObmVjBTVcXOnTuJjY2lUycdsmfChAm8+eabZUrhuuuuA6B///588803Z9v0MoxScCQx5+mJz92LtK374qdPncyMHqiVwoIHtEIY8biepE74tuLLf8d3cGQbXDv9rLa3rJbu12rzzFWvlrt6NhQ8PPSCtDOhZW8dJr3ypj0jnzh7uRoCaVu1R5m7zyfU0KN3JmPGjGHq1KmsX7+ekydP0qxZM1588UXWrFlD06ZNmThxYtlmOXVl0qRJzJs3j969ezNjxoyz3ou8NPS2o8Nun1tzCvXB9e/DX1fp76q8W9oM1pOnexdr08j5D2rPm1+fLV9QZrPBb887ZpRQHZHd4NFkPensTgyboh0D3HVRV+l8Qlszn+AMgoKCGDFiBHfccQfjx48nOzubwMBAQkJCSEtL44cffqix/gUXXMDcuXPJy8sjJyeHBQsWlOXl5OTQsmVLioqKmDVrVll6cHBwlduQdu7cmaSkJPbs2QPAJ598woUXXuigllaPUQqOxq+J9g6qjlJXyrbnQdyf9Sjgon9pj5iNs7QX0Mo3IW2L9pDxdOJgzpnXdhVRcTDgz66Wwnkk/Q5NYxuvO20jYPz48WzatInx48fTu3dv+vbtS5cuXbj55psZNqxmZdyvXz9uuukmevfuzeWXX86AAQPK8h5//HEGDRrEsGHD6NKl/B0xbtw4XnjhBfr27cveveW7tPr5+fHRRx8xduxYevbsiYeHB/fcc4/jG1wJUXVZyNXAiIuLU6V+wlDNPrYNDZtNv/S7X1f+j60UfHCpFTXU+nu06Al3xp/y4m4UbTwLGlL7RGSdUqp+4xZbVPlsX3CBXrDY9SoY80YNtRsf8fHxREZG0rVrV1eL4jRycnLOaq/lM2X79u2n/K41Pdtu2FVs4Hh4wNDJFdNEYPRLsOrd8tDQLXu7Z0/ecOYU5ug1KPZ7RhgMDsa8dRoKLXq6Xe/P4GD8QuDad1wthcHNMXMKBoPBYCjDKAWDwdBgaMxznA2RM/k9XaIURCRJRLaIyEYRWWulNRORn0Vkt/XdwJznDQaDM/Hz8yM9Pd0oBgehlCI9PR0/v2qiGVeDK+cURiil7EOUPgIsVko9JyKPWOf/cI1oBkNFRGQU8CrgCbyvlHquUv5E4AUgxUp6Qyn1vpU3AXjcSn9GKfVxvQjdyIiKiiI5OZmjR4+6WhSnkJ+fX+cX9Nni5+dHVFRUneo0pInmMcBw6/hjIB6jFAwNABHxBN4ELgGSgTUiMl8plVCp6OdKqfsq1W0GPAnEof2N11l1a7Fl37mFt7c3sbGxrhbDacTHx9O3b8PfFMlVSkEBP4mIAt5VSk0HIpVS1rZcHAYiq6ooIncBdwFERkZWWCqem5t71kvHGzru3sYG2r6BwB6lVCKAiMxBd2IqK4WquAz4WSl13Kr7MzAKmO0kWQ2Gs8JVSuE8pVSKiDQHfhaRCnFflVLKUhinYCmQ6aAX+NgvdGpIC5+chbu3sYG2rzVw0O48GRhURbnrReQCYBcwVSl1sJq6VS5HPpc7PO7ePmg8bXSJUlBKpVjfR0TkW3RPLE1EWiqlUkWkJXCaHeoNhgbFAmC2UqpARO5Gm0AvqssFzuUOj7u3DxpPG+tdKYhIIOChlMqxji8FpgHzgQnAc9b3vNNda926dcdEZL9dUjhQw/6aboG7t7Ehta+t9Z0CRNulR1E+oQyAUird7vR9oHS7rhTK58pK68af7sbn4LPt7u2DhtXGttVl1HvsIxFpB3xrnXoBnymlnhWRMOALoA2wH7ix1A5bh2uvdVWsmvrC3dvYENsnIl5ok9BI9Et+DXCzUmqbXZmWpXNiInIt8A+l1GBronkdULpb03qgv3m2K+Lu7YPG08Z6HylYk3W9q0hPR//TGQwNCqVUsYjcByxCu6R+qJTaJiLTgLVKqfnA/SJyNVAMHAcmWnWPi8i/0YoEYFpdFYLBUJ806iiplWksmvhscPc2unv7zhR3/13cvX3QeNrobmEuprtagHrA3dvo7u07U9z9d3H39kEjaaNbjRQMBoPBcHa420jBYDAYDGeB2ygFERklIjtFZI8VO6lRIyLRIrJERBJEZJuIPGClu1XgQBHxFJENIvKddR4rIqusv+PnIuLjahldibs912Ce7Yb+bLuFUrCLTXM50A0YLyLdXCvVWVMM/E0p1Q0YDNxrtak0cGBHYLF13ph5ANhud/5f4GWlVAcgA3DjDZdrxk2fazDPdoN+tt1CKWAXm0YpVQiUxqZptCilUpVS663jHPTD1RrdrtIomx8D17hEQAcgIlHAlejFXoiIoFcBf2UVadTtcwBu91yDebatIg22fe6iFGodX6YxIiIxQF9gFbUMHNhIeAV4GLBZ52FAplKq2Dp3q7/jGeDWzzWYZ9sFcp0Wd1EKbouIBAFfA1OUUtn2eUq7jjVK9zERGQ0cUUqtc7UsBtdgnu2GSUPaT+FsOG1smsaIiHij/2lmKaW+sZLdJXDgMOBqEbkC8AOaoDexCRURL6tH5RZ/x7PALZ9rMM82Dfhv6S4jhTVAR2t23wcYhw6w12ixbJAfANuVUi/ZZZUGDoRaBg5siCilHlVKRSmlYtB/r1+VUrcAS4AbrGKNtn0Owu2eazDPtlWswbbPLZSCpXlLY9NsB76wD1bWSBkG3ApcJHov641Wz+M54BIR2Q1cbJ27E/8AHhSRPWg77AculsdluOlzDebZbtDPtlnRbDAYDIYy3GKkYDAYDAbHYJSCwWAwGMowSsFgMBgMZRilYDAYDIYyjFIwGAwGQxlGKTRCRKTEzpVvoyOjZ4pIjIhsddT1DIa6YJ5t1+MuK5rPNfKUUn1cLYTB4ATMs+1izEjBjRCRJBF5XkS2iMhqEelgpceIyK8isllEFotIGys9UkS+FZFN1meodSlPEXnPinX/k4j4u6xRBgPm2a5PjFJonPhXGmLfZJeXpZTqCbyBjtQI8DrwsVKqFzALeM1Kfw34TSnVG+gHlK6W7Qi8qZTqDmQC1zu1NQZDOebZdjFmRXMjRERylVJBVaQnARcppRKtgGOHlVJhInIMaKmUKrLSU5VS4SJyFIhSShXYXSMG+Nna6AQR+QfgrZR6ph6aZjjHMc+26zEjBfdDVXNcFwrsjkswc0+GhoF5tusBoxTcj5vsvldYx8vR0RoBbgGWWceLgUlQtp9sSH0JaTCcAebZrgeMlmyc+IvIRrvzH5VSpa57TUVkM7pHNN5Kmwx8JCIPAUeB2630B4DpIvJndK9pEpCKweA6zLPtYsycghth2V3jlFLHXC2LweBIzLNdfxjzkcFgMBjKMCMFg8FgMJRhRgoGg8FgKMMoBYPBYDCUYZSCwWAwGMowSsFgMBgMZRilYDAYDIYyjFIwGAwGQxn/D5DVFh3uPtorAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7395\n","Validation AUC: 0.7363\n","Validation Balanced_ACC: 0.4715\n","Validation MI: 0.1398\n","Validation Normalized MI: 0.2118\n","Validation Adjusted MI: 0.2118\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 505.7479, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 447.0490, Accuracy: 0.5209\n","Training loss (for one batch) at step 20: 451.4684, Accuracy: 0.5319\n","Training loss (for one batch) at step 30: 446.2194, Accuracy: 0.5390\n","Training loss (for one batch) at step 40: 465.4218, Accuracy: 0.5424\n","Training loss (for one batch) at step 50: 433.5737, Accuracy: 0.5516\n","Training loss (for one batch) at step 60: 414.4743, Accuracy: 0.5607\n","Training loss (for one batch) at step 70: 417.3436, Accuracy: 0.5624\n","Training loss (for one batch) at step 80: 393.9321, Accuracy: 0.5642\n","Training loss (for one batch) at step 90: 431.9925, Accuracy: 0.5688\n","Training loss (for one batch) at step 100: 429.0975, Accuracy: 0.5686\n","Training loss (for one batch) at step 110: 397.5590, Accuracy: 0.5730\n","Training loss (for one batch) at step 120: 418.4052, Accuracy: 0.5752\n","Training loss (for one batch) at step 130: 406.1350, Accuracy: 0.5759\n","Training loss (for one batch) at step 140: 381.8127, Accuracy: 0.5766\n","---- Training ----\n","Training loss: 360.1847\n","Training acc over epoch: 0.5775\n","---- Validation ----\n","Validation loss: 95.1625\n","Validation acc: 0.5134\n","Time taken: 25.46s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 375.9430, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 366.0421, Accuracy: 0.6445\n","Training loss (for one batch) at step 20: 396.4454, Accuracy: 0.6276\n","Training loss (for one batch) at step 30: 367.7935, Accuracy: 0.6213\n","Training loss (for one batch) at step 40: 400.5780, Accuracy: 0.6193\n","Training loss (for one batch) at step 50: 375.4491, Accuracy: 0.6175\n","Training loss (for one batch) at step 60: 403.3240, Accuracy: 0.6169\n","Training loss (for one batch) at step 70: 370.4282, Accuracy: 0.6172\n","Training loss (for one batch) at step 80: 376.1950, Accuracy: 0.6172\n","Training loss (for one batch) at step 90: 383.0567, Accuracy: 0.6196\n","Training loss (for one batch) at step 100: 366.3389, Accuracy: 0.6200\n","Training loss (for one batch) at step 110: 362.8410, Accuracy: 0.6199\n","Training loss (for one batch) at step 120: 361.6058, Accuracy: 0.6198\n","Training loss (for one batch) at step 130: 381.6435, Accuracy: 0.6219\n","Training loss (for one batch) at step 140: 358.9826, Accuracy: 0.6219\n","---- Training ----\n","Training loss: 327.1513\n","Training acc over epoch: 0.6210\n","---- Validation ----\n","Validation loss: 84.2533\n","Validation acc: 0.5180\n","Time taken: 12.63s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 362.5213, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 367.8340, Accuracy: 0.6282\n","Training loss (for one batch) at step 20: 341.3913, Accuracy: 0.6505\n","Training loss (for one batch) at step 30: 362.1333, Accuracy: 0.6461\n","Training loss (for one batch) at step 40: 369.2815, Accuracy: 0.6441\n","Training loss (for one batch) at step 50: 381.8395, Accuracy: 0.6424\n","Training loss (for one batch) at step 60: 362.3724, Accuracy: 0.6438\n","Training loss (for one batch) at step 70: 340.7473, Accuracy: 0.6408\n","Training loss (for one batch) at step 80: 328.1923, Accuracy: 0.6401\n","Training loss (for one batch) at step 90: 365.7192, Accuracy: 0.6381\n","Training loss (for one batch) at step 100: 356.2336, Accuracy: 0.6404\n","Training loss (for one batch) at step 110: 375.1975, Accuracy: 0.6414\n","Training loss (for one batch) at step 120: 359.2396, Accuracy: 0.6413\n","Training loss (for one batch) at step 130: 367.4986, Accuracy: 0.6416\n","Training loss (for one batch) at step 140: 352.4538, Accuracy: 0.6413\n","---- Training ----\n","Training loss: 301.4972\n","Training acc over epoch: 0.6413\n","---- Validation ----\n","Validation loss: 76.3605\n","Validation acc: 0.6714\n","Time taken: 10.72s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 355.4755, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 333.4222, Accuracy: 0.6736\n","Training loss (for one batch) at step 20: 363.0529, Accuracy: 0.6557\n","Training loss (for one batch) at step 30: 348.0221, Accuracy: 0.6594\n","Training loss (for one batch) at step 40: 362.1293, Accuracy: 0.6527\n","Training loss (for one batch) at step 50: 354.4961, Accuracy: 0.6576\n","Training loss (for one batch) at step 60: 331.8196, Accuracy: 0.6610\n","Training loss (for one batch) at step 70: 339.8966, Accuracy: 0.6632\n","Training loss (for one batch) at step 80: 336.1597, Accuracy: 0.6619\n","Training loss (for one batch) at step 90: 352.3458, Accuracy: 0.6610\n","Training loss (for one batch) at step 100: 342.4937, Accuracy: 0.6597\n","Training loss (for one batch) at step 110: 346.3434, Accuracy: 0.6600\n","Training loss (for one batch) at step 120: 341.3229, Accuracy: 0.6603\n","Training loss (for one batch) at step 130: 330.9433, Accuracy: 0.6602\n","Training loss (for one batch) at step 140: 355.9293, Accuracy: 0.6619\n","---- Training ----\n","Training loss: 285.1752\n","Training acc over epoch: 0.6621\n","---- Validation ----\n","Validation loss: 69.5334\n","Validation acc: 0.7144\n","Time taken: 11.27s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 338.8942, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 318.1559, Accuracy: 0.6873\n","Training loss (for one batch) at step 20: 334.5628, Accuracy: 0.6910\n","Training loss (for one batch) at step 30: 339.5991, Accuracy: 0.6894\n","Training loss (for one batch) at step 40: 319.0349, Accuracy: 0.6851\n","Training loss (for one batch) at step 50: 339.6900, Accuracy: 0.6861\n","Training loss (for one batch) at step 60: 336.0117, Accuracy: 0.6833\n","Training loss (for one batch) at step 70: 338.4647, Accuracy: 0.6844\n","Training loss (for one batch) at step 80: 344.4948, Accuracy: 0.6825\n","Training loss (for one batch) at step 90: 342.3159, Accuracy: 0.6805\n","Training loss (for one batch) at step 100: 316.0325, Accuracy: 0.6801\n","Training loss (for one batch) at step 110: 343.1810, Accuracy: 0.6791\n","Training loss (for one batch) at step 120: 349.5577, Accuracy: 0.6808\n","Training loss (for one batch) at step 130: 322.2242, Accuracy: 0.6796\n","Training loss (for one batch) at step 140: 339.4850, Accuracy: 0.6802\n","---- Training ----\n","Training loss: 296.8806\n","Training acc over epoch: 0.6796\n","---- Validation ----\n","Validation loss: 70.3681\n","Validation acc: 0.6983\n","Time taken: 10.96s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 337.2212, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 318.1101, Accuracy: 0.6918\n","Training loss (for one batch) at step 20: 332.8084, Accuracy: 0.6857\n","Training loss (for one batch) at step 30: 329.2864, Accuracy: 0.6903\n","Training loss (for one batch) at step 40: 352.5554, Accuracy: 0.6815\n","Training loss (for one batch) at step 50: 314.0512, Accuracy: 0.6875\n","Training loss (for one batch) at step 60: 328.0562, Accuracy: 0.6874\n","Training loss (for one batch) at step 70: 341.6897, Accuracy: 0.6910\n","Training loss (for one batch) at step 80: 344.1531, Accuracy: 0.6878\n","Training loss (for one batch) at step 90: 339.2658, Accuracy: 0.6918\n","Training loss (for one batch) at step 100: 318.7071, Accuracy: 0.6937\n","Training loss (for one batch) at step 110: 316.2639, Accuracy: 0.6945\n","Training loss (for one batch) at step 120: 319.1281, Accuracy: 0.6942\n","Training loss (for one batch) at step 130: 331.5127, Accuracy: 0.6934\n","Training loss (for one batch) at step 140: 317.0984, Accuracy: 0.6950\n","---- Training ----\n","Training loss: 296.4150\n","Training acc over epoch: 0.6963\n","---- Validation ----\n","Validation loss: 75.9394\n","Validation acc: 0.7190\n","Time taken: 11.37s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 333.2641, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 308.2968, Accuracy: 0.7136\n","Training loss (for one batch) at step 20: 308.5182, Accuracy: 0.7043\n","Training loss (for one batch) at step 30: 319.6080, Accuracy: 0.7016\n","Training loss (for one batch) at step 40: 311.1789, Accuracy: 0.7061\n","Training loss (for one batch) at step 50: 316.8433, Accuracy: 0.7063\n","Training loss (for one batch) at step 60: 325.4386, Accuracy: 0.7089\n","Training loss (for one batch) at step 70: 302.1039, Accuracy: 0.7123\n","Training loss (for one batch) at step 80: 318.6925, Accuracy: 0.7075\n","Training loss (for one batch) at step 90: 313.1141, Accuracy: 0.7055\n","Training loss (for one batch) at step 100: 324.4827, Accuracy: 0.7050\n","Training loss (for one batch) at step 110: 312.3599, Accuracy: 0.7066\n","Training loss (for one batch) at step 120: 322.3994, Accuracy: 0.7059\n","Training loss (for one batch) at step 130: 319.5196, Accuracy: 0.7071\n","Training loss (for one batch) at step 140: 321.6414, Accuracy: 0.7067\n","---- Training ----\n","Training loss: 263.9602\n","Training acc over epoch: 0.7082\n","---- Validation ----\n","Validation loss: 65.1166\n","Validation acc: 0.7128\n","Time taken: 13.01s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 321.3201, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 328.4919, Accuracy: 0.7236\n","Training loss (for one batch) at step 20: 298.6317, Accuracy: 0.7233\n","Training loss (for one batch) at step 30: 322.9443, Accuracy: 0.7184\n","Training loss (for one batch) at step 40: 311.8343, Accuracy: 0.7224\n","Training loss (for one batch) at step 50: 323.8883, Accuracy: 0.7241\n","Training loss (for one batch) at step 60: 313.2386, Accuracy: 0.7216\n","Training loss (for one batch) at step 70: 314.4420, Accuracy: 0.7211\n","Training loss (for one batch) at step 80: 309.2715, Accuracy: 0.7230\n","Training loss (for one batch) at step 90: 310.4165, Accuracy: 0.7257\n","Training loss (for one batch) at step 100: 317.1065, Accuracy: 0.7250\n","Training loss (for one batch) at step 110: 326.0794, Accuracy: 0.7253\n","Training loss (for one batch) at step 120: 304.4872, Accuracy: 0.7274\n","Training loss (for one batch) at step 130: 327.9365, Accuracy: 0.7279\n","Training loss (for one batch) at step 140: 307.4597, Accuracy: 0.7278\n","---- Training ----\n","Training loss: 263.6531\n","Training acc over epoch: 0.7288\n","---- Validation ----\n","Validation loss: 60.1039\n","Validation acc: 0.7082\n","Time taken: 12.85s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 295.3627, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 301.3909, Accuracy: 0.7300\n","Training loss (for one batch) at step 20: 308.7578, Accuracy: 0.7252\n","Training loss (for one batch) at step 30: 314.3296, Accuracy: 0.7268\n","Training loss (for one batch) at step 40: 302.4211, Accuracy: 0.7317\n","Training loss (for one batch) at step 50: 316.4544, Accuracy: 0.7353\n","Training loss (for one batch) at step 60: 310.1462, Accuracy: 0.7362\n","Training loss (for one batch) at step 70: 307.2719, Accuracy: 0.7375\n","Training loss (for one batch) at step 80: 323.1379, Accuracy: 0.7375\n","Training loss (for one batch) at step 90: 314.8786, Accuracy: 0.7371\n","Training loss (for one batch) at step 100: 298.2223, Accuracy: 0.7384\n","Training loss (for one batch) at step 110: 304.0044, Accuracy: 0.7382\n","Training loss (for one batch) at step 120: 318.3654, Accuracy: 0.7391\n","Training loss (for one batch) at step 130: 315.8106, Accuracy: 0.7386\n","Training loss (for one batch) at step 140: 297.2430, Accuracy: 0.7399\n","---- Training ----\n","Training loss: 259.9349\n","Training acc over epoch: 0.7410\n","---- Validation ----\n","Validation loss: 74.5205\n","Validation acc: 0.7208\n","Time taken: 11.27s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 291.0724, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 296.5955, Accuracy: 0.7491\n","Training loss (for one batch) at step 20: 290.5693, Accuracy: 0.7533\n","Training loss (for one batch) at step 30: 288.2244, Accuracy: 0.7526\n","Training loss (for one batch) at step 40: 304.6689, Accuracy: 0.7483\n","Training loss (for one batch) at step 50: 302.8081, Accuracy: 0.7494\n","Training loss (for one batch) at step 60: 299.1040, Accuracy: 0.7525\n","Training loss (for one batch) at step 70: 292.2798, Accuracy: 0.7525\n","Training loss (for one batch) at step 80: 299.7027, Accuracy: 0.7516\n","Training loss (for one batch) at step 90: 292.3237, Accuracy: 0.7510\n","Training loss (for one batch) at step 100: 315.6925, Accuracy: 0.7492\n","Training loss (for one batch) at step 110: 292.4157, Accuracy: 0.7505\n","Training loss (for one batch) at step 120: 304.0314, Accuracy: 0.7507\n","Training loss (for one batch) at step 130: 306.0441, Accuracy: 0.7505\n","Training loss (for one batch) at step 140: 295.5231, Accuracy: 0.7511\n","---- Training ----\n","Training loss: 277.7402\n","Training acc over epoch: 0.7518\n","---- Validation ----\n","Validation loss: 74.5532\n","Validation acc: 0.7399\n","Time taken: 10.98s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 299.2159, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 293.5230, Accuracy: 0.7591\n","Training loss (for one batch) at step 20: 308.6039, Accuracy: 0.7505\n","Training loss (for one batch) at step 30: 296.1248, Accuracy: 0.7590\n","Training loss (for one batch) at step 40: 309.9251, Accuracy: 0.7622\n","Training loss (for one batch) at step 50: 303.4523, Accuracy: 0.7639\n","Training loss (for one batch) at step 60: 300.5195, Accuracy: 0.7661\n","Training loss (for one batch) at step 70: 276.3600, Accuracy: 0.7679\n","Training loss (for one batch) at step 80: 285.6808, Accuracy: 0.7653\n","Training loss (for one batch) at step 90: 319.4261, Accuracy: 0.7632\n","Training loss (for one batch) at step 100: 286.6819, Accuracy: 0.7638\n","Training loss (for one batch) at step 110: 301.6789, Accuracy: 0.7653\n","Training loss (for one batch) at step 120: 307.9443, Accuracy: 0.7649\n","Training loss (for one batch) at step 130: 296.6432, Accuracy: 0.7635\n","Training loss (for one batch) at step 140: 298.7863, Accuracy: 0.7643\n","---- Training ----\n","Training loss: 251.8987\n","Training acc over epoch: 0.7641\n","---- Validation ----\n","Validation loss: 70.2375\n","Validation acc: 0.7337\n","Time taken: 11.28s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 268.7806, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 296.7429, Accuracy: 0.7518\n","Training loss (for one batch) at step 20: 297.8770, Accuracy: 0.7543\n","Training loss (for one batch) at step 30: 305.9904, Accuracy: 0.7535\n","Training loss (for one batch) at step 40: 268.5856, Accuracy: 0.7639\n","Training loss (for one batch) at step 50: 303.3166, Accuracy: 0.7655\n","Training loss (for one batch) at step 60: 301.1732, Accuracy: 0.7672\n","Training loss (for one batch) at step 70: 287.1773, Accuracy: 0.7672\n","Training loss (for one batch) at step 80: 292.7417, Accuracy: 0.7651\n","Training loss (for one batch) at step 90: 287.3630, Accuracy: 0.7657\n","Training loss (for one batch) at step 100: 304.4905, Accuracy: 0.7639\n","Training loss (for one batch) at step 110: 292.2924, Accuracy: 0.7657\n","Training loss (for one batch) at step 120: 309.2312, Accuracy: 0.7669\n","Training loss (for one batch) at step 130: 284.6317, Accuracy: 0.7669\n","Training loss (for one batch) at step 140: 292.5260, Accuracy: 0.7670\n","---- Training ----\n","Training loss: 254.1886\n","Training acc over epoch: 0.7673\n","---- Validation ----\n","Validation loss: 68.0717\n","Validation acc: 0.7362\n","Time taken: 10.30s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 307.4944, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 277.7292, Accuracy: 0.7945\n","Training loss (for one batch) at step 20: 294.7672, Accuracy: 0.7819\n","Training loss (for one batch) at step 30: 292.6246, Accuracy: 0.7787\n","Training loss (for one batch) at step 40: 287.5689, Accuracy: 0.7810\n","Training loss (for one batch) at step 50: 283.9417, Accuracy: 0.7825\n","Training loss (for one batch) at step 60: 281.4204, Accuracy: 0.7803\n","Training loss (for one batch) at step 70: 324.6819, Accuracy: 0.7815\n","Training loss (for one batch) at step 80: 297.3210, Accuracy: 0.7804\n","Training loss (for one batch) at step 90: 291.2896, Accuracy: 0.7775\n","Training loss (for one batch) at step 100: 290.1831, Accuracy: 0.7759\n","Training loss (for one batch) at step 110: 270.8722, Accuracy: 0.7773\n","Training loss (for one batch) at step 120: 272.3774, Accuracy: 0.7800\n","Training loss (for one batch) at step 130: 281.1711, Accuracy: 0.7796\n","Training loss (for one batch) at step 140: 290.6362, Accuracy: 0.7809\n","---- Training ----\n","Training loss: 255.4049\n","Training acc over epoch: 0.7808\n","---- Validation ----\n","Validation loss: 64.7171\n","Validation acc: 0.7372\n","Time taken: 9.59s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 277.0561, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 273.2881, Accuracy: 0.7864\n","Training loss (for one batch) at step 20: 296.6604, Accuracy: 0.7771\n","Training loss (for one batch) at step 30: 279.7600, Accuracy: 0.7748\n","Training loss (for one batch) at step 40: 278.7093, Accuracy: 0.7800\n","Training loss (for one batch) at step 50: 303.5544, Accuracy: 0.7849\n","Training loss (for one batch) at step 60: 298.6024, Accuracy: 0.7867\n","Training loss (for one batch) at step 70: 289.3492, Accuracy: 0.7904\n","Training loss (for one batch) at step 80: 280.6289, Accuracy: 0.7898\n","Training loss (for one batch) at step 90: 292.8898, Accuracy: 0.7870\n","Training loss (for one batch) at step 100: 280.7176, Accuracy: 0.7863\n","Training loss (for one batch) at step 110: 277.3491, Accuracy: 0.7869\n","Training loss (for one batch) at step 120: 294.3686, Accuracy: 0.7853\n","Training loss (for one batch) at step 130: 269.2896, Accuracy: 0.7858\n","Training loss (for one batch) at step 140: 286.3923, Accuracy: 0.7862\n","---- Training ----\n","Training loss: 244.1207\n","Training acc over epoch: 0.7863\n","---- Validation ----\n","Validation loss: 68.9201\n","Validation acc: 0.7458\n","Time taken: 9.90s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 269.8148, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 285.3218, Accuracy: 0.8055\n","Training loss (for one batch) at step 20: 271.8728, Accuracy: 0.7948\n","Training loss (for one batch) at step 30: 309.6854, Accuracy: 0.7906\n","Training loss (for one batch) at step 40: 271.5883, Accuracy: 0.7905\n","Training loss (for one batch) at step 50: 270.2053, Accuracy: 0.7955\n","Training loss (for one batch) at step 60: 270.7924, Accuracy: 0.7944\n","Training loss (for one batch) at step 70: 288.2145, Accuracy: 0.7945\n","Training loss (for one batch) at step 80: 280.0001, Accuracy: 0.7936\n","Training loss (for one batch) at step 90: 273.9040, Accuracy: 0.7945\n","Training loss (for one batch) at step 100: 290.3657, Accuracy: 0.7951\n","Training loss (for one batch) at step 110: 268.0042, Accuracy: 0.7942\n","Training loss (for one batch) at step 120: 277.2168, Accuracy: 0.7942\n","Training loss (for one batch) at step 130: 276.7352, Accuracy: 0.7944\n","Training loss (for one batch) at step 140: 256.9728, Accuracy: 0.7960\n","---- Training ----\n","Training loss: 237.1262\n","Training acc over epoch: 0.7959\n","---- Validation ----\n","Validation loss: 69.6636\n","Validation acc: 0.7480\n","Time taken: 9.80s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 264.4987, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 278.0785, Accuracy: 0.7973\n","Training loss (for one batch) at step 20: 294.5446, Accuracy: 0.7995\n","Training loss (for one batch) at step 30: 262.3807, Accuracy: 0.8003\n","Training loss (for one batch) at step 40: 268.0933, Accuracy: 0.8022\n","Training loss (for one batch) at step 50: 284.0923, Accuracy: 0.8004\n","Training loss (for one batch) at step 60: 277.4748, Accuracy: 0.7974\n","Training loss (for one batch) at step 70: 288.1228, Accuracy: 0.8021\n","Training loss (for one batch) at step 80: 263.1868, Accuracy: 0.8011\n","Training loss (for one batch) at step 90: 274.7823, Accuracy: 0.8000\n","Training loss (for one batch) at step 100: 280.4817, Accuracy: 0.8004\n","Training loss (for one batch) at step 110: 277.5749, Accuracy: 0.8003\n","Training loss (for one batch) at step 120: 281.2541, Accuracy: 0.7998\n","Training loss (for one batch) at step 130: 281.0193, Accuracy: 0.7992\n","Training loss (for one batch) at step 140: 258.4727, Accuracy: 0.7987\n","---- Training ----\n","Training loss: 230.1223\n","Training acc over epoch: 0.7995\n","---- Validation ----\n","Validation loss: 83.0033\n","Validation acc: 0.7335\n","Time taken: 9.77s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 286.8574, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 279.6346, Accuracy: 0.7936\n","Training loss (for one batch) at step 20: 273.8136, Accuracy: 0.7976\n","Training loss (for one batch) at step 30: 277.8340, Accuracy: 0.7997\n","Training loss (for one batch) at step 40: 279.2336, Accuracy: 0.8061\n","Training loss (for one batch) at step 50: 267.8282, Accuracy: 0.8082\n","Training loss (for one batch) at step 60: 296.6985, Accuracy: 0.8095\n","Training loss (for one batch) at step 70: 259.4114, Accuracy: 0.8052\n","Training loss (for one batch) at step 80: 285.8021, Accuracy: 0.8036\n","Training loss (for one batch) at step 90: 287.3031, Accuracy: 0.8015\n","Training loss (for one batch) at step 100: 292.4879, Accuracy: 0.8005\n","Training loss (for one batch) at step 110: 261.6482, Accuracy: 0.8004\n","Training loss (for one batch) at step 120: 280.7043, Accuracy: 0.7999\n","Training loss (for one batch) at step 130: 283.3046, Accuracy: 0.7995\n","Training loss (for one batch) at step 140: 282.7703, Accuracy: 0.8002\n","---- Training ----\n","Training loss: 263.2161\n","Training acc over epoch: 0.8004\n","---- Validation ----\n","Validation loss: 70.5569\n","Validation acc: 0.7386\n","Time taken: 9.76s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 283.9086, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 257.6488, Accuracy: 0.8118\n","Training loss (for one batch) at step 20: 287.9340, Accuracy: 0.8114\n","Training loss (for one batch) at step 30: 281.3402, Accuracy: 0.8061\n","Training loss (for one batch) at step 40: 246.1188, Accuracy: 0.8056\n","Training loss (for one batch) at step 50: 273.5889, Accuracy: 0.8084\n","Training loss (for one batch) at step 60: 286.8968, Accuracy: 0.8097\n","Training loss (for one batch) at step 70: 276.1590, Accuracy: 0.8073\n","Training loss (for one batch) at step 80: 266.7623, Accuracy: 0.8056\n","Training loss (for one batch) at step 90: 260.3531, Accuracy: 0.8060\n","Training loss (for one batch) at step 100: 265.5763, Accuracy: 0.8033\n","Training loss (for one batch) at step 110: 262.7481, Accuracy: 0.8058\n","Training loss (for one batch) at step 120: 274.1536, Accuracy: 0.8050\n","Training loss (for one batch) at step 130: 286.5276, Accuracy: 0.8035\n","Training loss (for one batch) at step 140: 263.1433, Accuracy: 0.8035\n","---- Training ----\n","Training loss: 248.0846\n","Training acc over epoch: 0.8054\n","---- Validation ----\n","Validation loss: 66.3383\n","Validation acc: 0.7378\n","Time taken: 9.79s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 275.4882, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 261.7820, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 269.8752, Accuracy: 0.8090\n","Training loss (for one batch) at step 30: 259.0664, Accuracy: 0.8129\n","Training loss (for one batch) at step 40: 269.5257, Accuracy: 0.8110\n","Training loss (for one batch) at step 50: 254.6925, Accuracy: 0.8124\n","Training loss (for one batch) at step 60: 261.6056, Accuracy: 0.8105\n","Training loss (for one batch) at step 70: 299.5078, Accuracy: 0.8110\n","Training loss (for one batch) at step 80: 271.6016, Accuracy: 0.8104\n","Training loss (for one batch) at step 90: 277.6672, Accuracy: 0.8114\n","Training loss (for one batch) at step 100: 263.1596, Accuracy: 0.8099\n","Training loss (for one batch) at step 110: 286.0884, Accuracy: 0.8097\n","Training loss (for one batch) at step 120: 264.4448, Accuracy: 0.8100\n","Training loss (for one batch) at step 130: 263.3330, Accuracy: 0.8128\n","Training loss (for one batch) at step 140: 265.5150, Accuracy: 0.8111\n","---- Training ----\n","Training loss: 250.7118\n","Training acc over epoch: 0.8113\n","---- Validation ----\n","Validation loss: 68.7559\n","Validation acc: 0.7440\n","Time taken: 9.74s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 282.8135, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 261.4398, Accuracy: 0.8200\n","Training loss (for one batch) at step 20: 271.4441, Accuracy: 0.8248\n","Training loss (for one batch) at step 30: 301.5090, Accuracy: 0.8161\n","Training loss (for one batch) at step 40: 271.2851, Accuracy: 0.8200\n","Training loss (for one batch) at step 50: 261.4096, Accuracy: 0.8188\n","Training loss (for one batch) at step 60: 279.2471, Accuracy: 0.8193\n","Training loss (for one batch) at step 70: 278.8556, Accuracy: 0.8173\n","Training loss (for one batch) at step 80: 266.0419, Accuracy: 0.8175\n","Training loss (for one batch) at step 90: 258.7251, Accuracy: 0.8186\n","Training loss (for one batch) at step 100: 252.0078, Accuracy: 0.8177\n","Training loss (for one batch) at step 110: 255.9392, Accuracy: 0.8180\n","Training loss (for one batch) at step 120: 264.7736, Accuracy: 0.8183\n","Training loss (for one batch) at step 130: 276.7805, Accuracy: 0.8177\n","Training loss (for one batch) at step 140: 255.4405, Accuracy: 0.8187\n","---- Training ----\n","Training loss: 241.5920\n","Training acc over epoch: 0.8187\n","---- Validation ----\n","Validation loss: 68.5262\n","Validation acc: 0.7440\n","Time taken: 9.77s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 253.7632, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 255.7845, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 239.3240, Accuracy: 0.8076\n","Training loss (for one batch) at step 30: 262.3959, Accuracy: 0.8187\n","Training loss (for one batch) at step 40: 272.3954, Accuracy: 0.8178\n","Training loss (for one batch) at step 50: 257.6448, Accuracy: 0.8210\n","Training loss (for one batch) at step 60: 273.6079, Accuracy: 0.8203\n","Training loss (for one batch) at step 70: 276.2386, Accuracy: 0.8232\n","Training loss (for one batch) at step 80: 267.2213, Accuracy: 0.8199\n","Training loss (for one batch) at step 90: 264.2238, Accuracy: 0.8190\n","Training loss (for one batch) at step 100: 258.3527, Accuracy: 0.8190\n","Training loss (for one batch) at step 110: 262.7326, Accuracy: 0.8171\n","Training loss (for one batch) at step 120: 240.0930, Accuracy: 0.8182\n","Training loss (for one batch) at step 130: 268.2049, Accuracy: 0.8175\n","Training loss (for one batch) at step 140: 279.5107, Accuracy: 0.8169\n","---- Training ----\n","Training loss: 251.8755\n","Training acc over epoch: 0.8166\n","---- Validation ----\n","Validation loss: 71.6059\n","Validation acc: 0.7399\n","Time taken: 9.75s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 263.2656, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 271.2404, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 271.4517, Accuracy: 0.8200\n","Training loss (for one batch) at step 30: 292.5586, Accuracy: 0.8194\n","Training loss (for one batch) at step 40: 253.8988, Accuracy: 0.8210\n","Training loss (for one batch) at step 50: 240.4776, Accuracy: 0.8198\n","Training loss (for one batch) at step 60: 275.2010, Accuracy: 0.8221\n","Training loss (for one batch) at step 70: 271.2932, Accuracy: 0.8232\n","Training loss (for one batch) at step 80: 265.1837, Accuracy: 0.8225\n","Training loss (for one batch) at step 90: 273.9573, Accuracy: 0.8232\n","Training loss (for one batch) at step 100: 271.3038, Accuracy: 0.8228\n","Training loss (for one batch) at step 110: 258.6874, Accuracy: 0.8227\n","Training loss (for one batch) at step 120: 263.2597, Accuracy: 0.8219\n","Training loss (for one batch) at step 130: 273.0908, Accuracy: 0.8206\n","Training loss (for one batch) at step 140: 259.9379, Accuracy: 0.8192\n","---- Training ----\n","Training loss: 239.9562\n","Training acc over epoch: 0.8186\n","---- Validation ----\n","Validation loss: 70.8823\n","Validation acc: 0.7399\n","Time taken: 9.66s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 258.7426, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 243.0337, Accuracy: 0.8300\n","Training loss (for one batch) at step 20: 270.5536, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 264.2528, Accuracy: 0.8255\n","Training loss (for one batch) at step 40: 278.2207, Accuracy: 0.8237\n","Training loss (for one batch) at step 50: 255.0169, Accuracy: 0.8280\n","Training loss (for one batch) at step 60: 253.4918, Accuracy: 0.8270\n","Training loss (for one batch) at step 70: 259.2103, Accuracy: 0.8259\n","Training loss (for one batch) at step 80: 248.1885, Accuracy: 0.8231\n","Training loss (for one batch) at step 90: 263.0259, Accuracy: 0.8214\n","Training loss (for one batch) at step 100: 247.5950, Accuracy: 0.8214\n","Training loss (for one batch) at step 110: 248.3674, Accuracy: 0.8223\n","Training loss (for one batch) at step 120: 253.2845, Accuracy: 0.8224\n","Training loss (for one batch) at step 130: 264.0943, Accuracy: 0.8218\n","Training loss (for one batch) at step 140: 269.7739, Accuracy: 0.8220\n","---- Training ----\n","Training loss: 232.6990\n","Training acc over epoch: 0.8201\n","---- Validation ----\n","Validation loss: 96.2177\n","Validation acc: 0.7335\n","Time taken: 9.72s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 253.2495, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 246.5605, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 247.5284, Accuracy: 0.8214\n","Training loss (for one batch) at step 30: 270.2652, Accuracy: 0.8203\n","Training loss (for one batch) at step 40: 245.0074, Accuracy: 0.8227\n","Training loss (for one batch) at step 50: 261.7828, Accuracy: 0.8269\n","Training loss (for one batch) at step 60: 251.0415, Accuracy: 0.8285\n","Training loss (for one batch) at step 70: 275.4407, Accuracy: 0.8285\n","Training loss (for one batch) at step 80: 264.6416, Accuracy: 0.8257\n","Training loss (for one batch) at step 90: 265.9407, Accuracy: 0.8240\n","Training loss (for one batch) at step 100: 245.9963, Accuracy: 0.8235\n","Training loss (for one batch) at step 110: 257.9826, Accuracy: 0.8238\n","Training loss (for one batch) at step 120: 239.1519, Accuracy: 0.8229\n","Training loss (for one batch) at step 130: 236.3181, Accuracy: 0.8219\n","Training loss (for one batch) at step 140: 258.9233, Accuracy: 0.8232\n","---- Training ----\n","Training loss: 249.2694\n","Training acc over epoch: 0.8231\n","---- Validation ----\n","Validation loss: 66.4979\n","Validation acc: 0.7294\n","Time taken: 33.32s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 257.1422, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 242.3030, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 260.1022, Accuracy: 0.8300\n","Training loss (for one batch) at step 30: 269.9256, Accuracy: 0.8242\n","Training loss (for one batch) at step 40: 248.6295, Accuracy: 0.8205\n","Training loss (for one batch) at step 50: 260.2169, Accuracy: 0.8239\n","Training loss (for one batch) at step 60: 254.9035, Accuracy: 0.8246\n","Training loss (for one batch) at step 70: 253.7647, Accuracy: 0.8255\n","Training loss (for one batch) at step 80: 225.3390, Accuracy: 0.8248\n","Training loss (for one batch) at step 90: 237.5625, Accuracy: 0.8232\n","Training loss (for one batch) at step 100: 250.8370, Accuracy: 0.8231\n","Training loss (for one batch) at step 110: 242.2875, Accuracy: 0.8231\n","Training loss (for one batch) at step 120: 240.9801, Accuracy: 0.8237\n","Training loss (for one batch) at step 130: 270.4885, Accuracy: 0.8235\n","Training loss (for one batch) at step 140: 255.9599, Accuracy: 0.8237\n","---- Training ----\n","Training loss: 209.1079\n","Training acc over epoch: 0.8232\n","---- Validation ----\n","Validation loss: 74.7744\n","Validation acc: 0.7219\n","Time taken: 35.55s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 255.8795, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 252.4229, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 246.0312, Accuracy: 0.8233\n","Training loss (for one batch) at step 30: 256.5553, Accuracy: 0.8210\n","Training loss (for one batch) at step 40: 237.4523, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 259.7664, Accuracy: 0.8325\n","Training loss (for one batch) at step 60: 258.7650, Accuracy: 0.8336\n","Training loss (for one batch) at step 70: 266.7847, Accuracy: 0.8323\n","Training loss (for one batch) at step 80: 235.0901, Accuracy: 0.8304\n","Training loss (for one batch) at step 90: 279.0255, Accuracy: 0.8300\n","Training loss (for one batch) at step 100: 247.8525, Accuracy: 0.8282\n","Training loss (for one batch) at step 110: 243.7610, Accuracy: 0.8276\n","Training loss (for one batch) at step 120: 263.4878, Accuracy: 0.8282\n","Training loss (for one batch) at step 130: 242.6169, Accuracy: 0.8269\n","Training loss (for one batch) at step 140: 256.4857, Accuracy: 0.8271\n","---- Training ----\n","Training loss: 213.5909\n","Training acc over epoch: 0.8260\n","---- Validation ----\n","Validation loss: 74.3274\n","Validation acc: 0.7286\n","Time taken: 9.61s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 236.2624, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 246.2603, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 244.8886, Accuracy: 0.8233\n","Training loss (for one batch) at step 30: 250.3239, Accuracy: 0.8258\n","Training loss (for one batch) at step 40: 237.8125, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 252.2343, Accuracy: 0.8290\n","Training loss (for one batch) at step 60: 247.0295, Accuracy: 0.8289\n","Training loss (for one batch) at step 70: 236.8265, Accuracy: 0.8259\n","Training loss (for one batch) at step 80: 240.3824, Accuracy: 0.8270\n","Training loss (for one batch) at step 90: 227.7638, Accuracy: 0.8264\n","Training loss (for one batch) at step 100: 249.4912, Accuracy: 0.8248\n","Training loss (for one batch) at step 110: 242.3490, Accuracy: 0.8258\n","Training loss (for one batch) at step 120: 240.2904, Accuracy: 0.8249\n","Training loss (for one batch) at step 130: 274.0797, Accuracy: 0.8245\n","Training loss (for one batch) at step 140: 240.4777, Accuracy: 0.8243\n","---- Training ----\n","Training loss: 248.6977\n","Training acc over epoch: 0.8250\n","---- Validation ----\n","Validation loss: 61.9003\n","Validation acc: 0.7273\n","Time taken: 9.67s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 248.4503, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 243.6034, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 243.0009, Accuracy: 0.8276\n","Training loss (for one batch) at step 30: 236.7988, Accuracy: 0.8245\n","Training loss (for one batch) at step 40: 230.9896, Accuracy: 0.8298\n","Training loss (for one batch) at step 50: 228.4066, Accuracy: 0.8308\n","Training loss (for one batch) at step 60: 248.5365, Accuracy: 0.8316\n","Training loss (for one batch) at step 70: 246.4857, Accuracy: 0.8317\n","Training loss (for one batch) at step 80: 252.1013, Accuracy: 0.8301\n","Training loss (for one batch) at step 90: 271.7401, Accuracy: 0.8292\n","Training loss (for one batch) at step 100: 265.8001, Accuracy: 0.8278\n","Training loss (for one batch) at step 110: 239.8875, Accuracy: 0.8290\n","Training loss (for one batch) at step 120: 268.1654, Accuracy: 0.8288\n","Training loss (for one batch) at step 130: 247.5780, Accuracy: 0.8279\n","Training loss (for one batch) at step 140: 249.7497, Accuracy: 0.8275\n","---- Training ----\n","Training loss: 206.3105\n","Training acc over epoch: 0.8272\n","---- Validation ----\n","Validation loss: 76.3413\n","Validation acc: 0.7276\n","Time taken: 9.79s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 229.5115, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 256.1622, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 236.5525, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 255.0166, Accuracy: 0.8361\n","Training loss (for one batch) at step 40: 231.8658, Accuracy: 0.8317\n","Training loss (for one batch) at step 50: 232.1328, Accuracy: 0.8343\n","Training loss (for one batch) at step 60: 237.4819, Accuracy: 0.8352\n","Training loss (for one batch) at step 70: 257.6141, Accuracy: 0.8346\n","Training loss (for one batch) at step 80: 239.6067, Accuracy: 0.8335\n","Training loss (for one batch) at step 90: 239.4392, Accuracy: 0.8322\n","Training loss (for one batch) at step 100: 240.2908, Accuracy: 0.8318\n","Training loss (for one batch) at step 110: 249.3186, Accuracy: 0.8302\n","Training loss (for one batch) at step 120: 242.5642, Accuracy: 0.8301\n","Training loss (for one batch) at step 130: 246.3630, Accuracy: 0.8285\n","Training loss (for one batch) at step 140: 242.3119, Accuracy: 0.8282\n","---- Training ----\n","Training loss: 217.8835\n","Training acc over epoch: 0.8274\n","---- Validation ----\n","Validation loss: 69.9534\n","Validation acc: 0.7222\n","Time taken: 9.63s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 233.6299, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 244.0276, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 238.1370, Accuracy: 0.8290\n","Training loss (for one batch) at step 30: 239.6181, Accuracy: 0.8352\n","Training loss (for one batch) at step 40: 262.5022, Accuracy: 0.8334\n","Training loss (for one batch) at step 50: 241.3688, Accuracy: 0.8331\n","Training loss (for one batch) at step 60: 232.0537, Accuracy: 0.8338\n","Training loss (for one batch) at step 70: 236.1346, Accuracy: 0.8366\n","Training loss (for one batch) at step 80: 265.7697, Accuracy: 0.8331\n","Training loss (for one batch) at step 90: 248.7201, Accuracy: 0.8340\n","Training loss (for one batch) at step 100: 243.4627, Accuracy: 0.8354\n","Training loss (for one batch) at step 110: 242.6279, Accuracy: 0.8348\n","Training loss (for one batch) at step 120: 251.1297, Accuracy: 0.8339\n","Training loss (for one batch) at step 130: 267.7305, Accuracy: 0.8327\n","Training loss (for one batch) at step 140: 234.1633, Accuracy: 0.8340\n","---- Training ----\n","Training loss: 217.6744\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 71.0761\n","Validation acc: 0.7289\n","Time taken: 12.46s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 224.0493, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 242.9144, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 246.6927, Accuracy: 0.8276\n","Training loss (for one batch) at step 30: 239.1884, Accuracy: 0.8268\n","Training loss (for one batch) at step 40: 226.7993, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 214.1775, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 227.0656, Accuracy: 0.8346\n","Training loss (for one batch) at step 70: 223.9466, Accuracy: 0.8366\n","Training loss (for one batch) at step 80: 238.5709, Accuracy: 0.8342\n","Training loss (for one batch) at step 90: 242.6380, Accuracy: 0.8321\n","Training loss (for one batch) at step 100: 231.7060, Accuracy: 0.8306\n","Training loss (for one batch) at step 110: 235.8912, Accuracy: 0.8314\n","Training loss (for one batch) at step 120: 229.0119, Accuracy: 0.8308\n","Training loss (for one batch) at step 130: 238.6536, Accuracy: 0.8307\n","Training loss (for one batch) at step 140: 252.1953, Accuracy: 0.8309\n","---- Training ----\n","Training loss: 193.2859\n","Training acc over epoch: 0.8320\n","---- Validation ----\n","Validation loss: 68.4195\n","Validation acc: 0.7206\n","Time taken: 13.41s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 243.5546, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 255.8400, Accuracy: 0.8200\n","Training loss (for one batch) at step 20: 237.8009, Accuracy: 0.8257\n","Training loss (for one batch) at step 30: 255.5854, Accuracy: 0.8265\n","Training loss (for one batch) at step 40: 237.8181, Accuracy: 0.8322\n","Training loss (for one batch) at step 50: 220.4936, Accuracy: 0.8335\n","Training loss (for one batch) at step 60: 238.8184, Accuracy: 0.8362\n","Training loss (for one batch) at step 70: 221.2426, Accuracy: 0.8389\n","Training loss (for one batch) at step 80: 216.7961, Accuracy: 0.8363\n","Training loss (for one batch) at step 90: 233.0320, Accuracy: 0.8354\n","Training loss (for one batch) at step 100: 221.2799, Accuracy: 0.8340\n","Training loss (for one batch) at step 110: 234.8210, Accuracy: 0.8328\n","Training loss (for one batch) at step 120: 239.8966, Accuracy: 0.8338\n","Training loss (for one batch) at step 130: 230.4378, Accuracy: 0.8340\n","Training loss (for one batch) at step 140: 229.5701, Accuracy: 0.8345\n","---- Training ----\n","Training loss: 207.6324\n","Training acc over epoch: 0.8347\n","---- Validation ----\n","Validation loss: 73.1994\n","Validation acc: 0.7289\n","Time taken: 12.91s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 220.9372, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 220.6064, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 265.4846, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 247.2813, Accuracy: 0.8319\n","Training loss (for one batch) at step 40: 226.2633, Accuracy: 0.8324\n","Training loss (for one batch) at step 50: 216.0493, Accuracy: 0.8376\n","Training loss (for one batch) at step 60: 227.9796, Accuracy: 0.8361\n","Training loss (for one batch) at step 70: 223.7591, Accuracy: 0.8370\n","Training loss (for one batch) at step 80: 232.2170, Accuracy: 0.8363\n","Training loss (for one batch) at step 90: 228.6297, Accuracy: 0.8354\n","Training loss (for one batch) at step 100: 230.5372, Accuracy: 0.8344\n","Training loss (for one batch) at step 110: 267.4941, Accuracy: 0.8336\n","Training loss (for one batch) at step 120: 253.6866, Accuracy: 0.8343\n","Training loss (for one batch) at step 130: 229.8225, Accuracy: 0.8327\n","Training loss (for one batch) at step 140: 246.7683, Accuracy: 0.8323\n","---- Training ----\n","Training loss: 218.4014\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 77.5786\n","Validation acc: 0.7214\n","Time taken: 13.41s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 247.2509, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 213.0305, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 221.9136, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 242.0569, Accuracy: 0.8348\n","Training loss (for one batch) at step 40: 231.7505, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 223.1748, Accuracy: 0.8382\n","Training loss (for one batch) at step 60: 227.7626, Accuracy: 0.8400\n","Training loss (for one batch) at step 70: 225.2627, Accuracy: 0.8376\n","Training loss (for one batch) at step 80: 225.8895, Accuracy: 0.8370\n","Training loss (for one batch) at step 90: 249.6244, Accuracy: 0.8353\n","Training loss (for one batch) at step 100: 228.7293, Accuracy: 0.8349\n","Training loss (for one batch) at step 110: 216.1018, Accuracy: 0.8357\n","Training loss (for one batch) at step 120: 226.2172, Accuracy: 0.8349\n","Training loss (for one batch) at step 130: 247.9024, Accuracy: 0.8342\n","Training loss (for one batch) at step 140: 232.4346, Accuracy: 0.8335\n","---- Training ----\n","Training loss: 195.5619\n","Training acc over epoch: 0.8332\n","---- Validation ----\n","Validation loss: 72.0201\n","Validation acc: 0.7077\n","Time taken: 9.74s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 229.5404, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 232.4581, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 231.4762, Accuracy: 0.8395\n","Training loss (for one batch) at step 30: 249.2728, Accuracy: 0.8387\n","Training loss (for one batch) at step 40: 227.3356, Accuracy: 0.8373\n","Training loss (for one batch) at step 50: 228.0128, Accuracy: 0.8420\n","Training loss (for one batch) at step 60: 207.9265, Accuracy: 0.8433\n","Training loss (for one batch) at step 70: 240.6616, Accuracy: 0.8400\n","Training loss (for one batch) at step 80: 246.0989, Accuracy: 0.8393\n","Training loss (for one batch) at step 90: 253.6156, Accuracy: 0.8396\n","Training loss (for one batch) at step 100: 229.0444, Accuracy: 0.8407\n","Training loss (for one batch) at step 110: 236.0768, Accuracy: 0.8405\n","Training loss (for one batch) at step 120: 207.0146, Accuracy: 0.8388\n","Training loss (for one batch) at step 130: 220.1304, Accuracy: 0.8386\n","Training loss (for one batch) at step 140: 222.1831, Accuracy: 0.8392\n","---- Training ----\n","Training loss: 205.1000\n","Training acc over epoch: 0.8381\n","---- Validation ----\n","Validation loss: 72.9050\n","Validation acc: 0.7319\n","Time taken: 9.57s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 237.4828, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 225.8495, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 210.8045, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 242.6969, Accuracy: 0.8345\n","Training loss (for one batch) at step 40: 214.1182, Accuracy: 0.8393\n","Training loss (for one batch) at step 50: 222.9761, Accuracy: 0.8420\n","Training loss (for one batch) at step 60: 215.1107, Accuracy: 0.8393\n","Training loss (for one batch) at step 70: 214.0560, Accuracy: 0.8407\n","Training loss (for one batch) at step 80: 226.8453, Accuracy: 0.8379\n","Training loss (for one batch) at step 90: 232.4670, Accuracy: 0.8376\n","Training loss (for one batch) at step 100: 243.2886, Accuracy: 0.8359\n","Training loss (for one batch) at step 110: 208.9450, Accuracy: 0.8365\n","Training loss (for one batch) at step 120: 237.3524, Accuracy: 0.8369\n","Training loss (for one batch) at step 130: 234.3568, Accuracy: 0.8366\n","Training loss (for one batch) at step 140: 215.3956, Accuracy: 0.8377\n","---- Training ----\n","Training loss: 199.7284\n","Training acc over epoch: 0.8366\n","---- Validation ----\n","Validation loss: 75.6455\n","Validation acc: 0.7332\n","Time taken: 9.61s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 232.5170, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 213.1121, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 223.8749, Accuracy: 0.8410\n","Training loss (for one batch) at step 30: 228.1187, Accuracy: 0.8381\n","Training loss (for one batch) at step 40: 218.9746, Accuracy: 0.8415\n","Training loss (for one batch) at step 50: 217.2534, Accuracy: 0.8424\n","Training loss (for one batch) at step 60: 218.2159, Accuracy: 0.8407\n","Training loss (for one batch) at step 70: 243.4404, Accuracy: 0.8428\n","Training loss (for one batch) at step 80: 239.5855, Accuracy: 0.8412\n","Training loss (for one batch) at step 90: 256.3999, Accuracy: 0.8380\n","Training loss (for one batch) at step 100: 222.0066, Accuracy: 0.8406\n","Training loss (for one batch) at step 110: 217.2809, Accuracy: 0.8407\n","Training loss (for one batch) at step 120: 207.1705, Accuracy: 0.8393\n","Training loss (for one batch) at step 130: 221.8052, Accuracy: 0.8373\n","Training loss (for one batch) at step 140: 203.7745, Accuracy: 0.8382\n","---- Training ----\n","Training loss: 210.4649\n","Training acc over epoch: 0.8377\n","---- Validation ----\n","Validation loss: 79.7405\n","Validation acc: 0.7335\n","Time taken: 9.66s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 241.4146, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 215.2948, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 230.4615, Accuracy: 0.8438\n","Training loss (for one batch) at step 30: 241.7024, Accuracy: 0.8432\n","Training loss (for one batch) at step 40: 213.5458, Accuracy: 0.8420\n","Training loss (for one batch) at step 50: 236.0212, Accuracy: 0.8469\n","Training loss (for one batch) at step 60: 228.7710, Accuracy: 0.8444\n","Training loss (for one batch) at step 70: 245.9820, Accuracy: 0.8454\n","Training loss (for one batch) at step 80: 223.1989, Accuracy: 0.8448\n","Training loss (for one batch) at step 90: 228.1320, Accuracy: 0.8447\n","Training loss (for one batch) at step 100: 225.7150, Accuracy: 0.8440\n","Training loss (for one batch) at step 110: 199.2722, Accuracy: 0.8424\n","Training loss (for one batch) at step 120: 246.2017, Accuracy: 0.8415\n","Training loss (for one batch) at step 130: 209.8448, Accuracy: 0.8404\n","Training loss (for one batch) at step 140: 242.5428, Accuracy: 0.8400\n","---- Training ----\n","Training loss: 189.7156\n","Training acc over epoch: 0.8417\n","---- Validation ----\n","Validation loss: 75.1653\n","Validation acc: 0.7203\n","Time taken: 9.59s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 227.8293, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 221.8518, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 227.5548, Accuracy: 0.8362\n","Training loss (for one batch) at step 30: 206.5211, Accuracy: 0.8387\n","Training loss (for one batch) at step 40: 194.6417, Accuracy: 0.8461\n","Training loss (for one batch) at step 50: 189.8850, Accuracy: 0.8441\n","Training loss (for one batch) at step 60: 232.0054, Accuracy: 0.8426\n","Training loss (for one batch) at step 70: 224.3347, Accuracy: 0.8434\n","Training loss (for one batch) at step 80: 214.4236, Accuracy: 0.8419\n","Training loss (for one batch) at step 90: 229.6440, Accuracy: 0.8407\n","Training loss (for one batch) at step 100: 218.1862, Accuracy: 0.8379\n","Training loss (for one batch) at step 110: 217.2684, Accuracy: 0.8393\n","Training loss (for one batch) at step 120: 215.3826, Accuracy: 0.8379\n","Training loss (for one batch) at step 130: 244.5262, Accuracy: 0.8389\n","Training loss (for one batch) at step 140: 222.5779, Accuracy: 0.8383\n","---- Training ----\n","Training loss: 195.1435\n","Training acc over epoch: 0.8380\n","---- Validation ----\n","Validation loss: 85.1623\n","Validation acc: 0.7251\n","Time taken: 9.61s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 220.7843, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 204.9423, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 225.5214, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 221.8191, Accuracy: 0.8410\n","Training loss (for one batch) at step 40: 239.5503, Accuracy: 0.8466\n","Training loss (for one batch) at step 50: 241.9908, Accuracy: 0.8451\n","Training loss (for one batch) at step 60: 205.3223, Accuracy: 0.8466\n","Training loss (for one batch) at step 70: 234.7407, Accuracy: 0.8456\n","Training loss (for one batch) at step 80: 231.8622, Accuracy: 0.8421\n","Training loss (for one batch) at step 90: 223.2458, Accuracy: 0.8427\n","Training loss (for one batch) at step 100: 222.9104, Accuracy: 0.8421\n","Training loss (for one batch) at step 110: 211.4394, Accuracy: 0.8423\n","Training loss (for one batch) at step 120: 225.6694, Accuracy: 0.8426\n","Training loss (for one batch) at step 130: 214.8026, Accuracy: 0.8418\n","Training loss (for one batch) at step 140: 229.0961, Accuracy: 0.8412\n","---- Training ----\n","Training loss: 206.1380\n","Training acc over epoch: 0.8410\n","---- Validation ----\n","Validation loss: 86.1588\n","Validation acc: 0.7174\n","Time taken: 9.61s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 205.7182, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 206.0654, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 219.1428, Accuracy: 0.8433\n","Training loss (for one batch) at step 30: 236.1178, Accuracy: 0.8374\n","Training loss (for one batch) at step 40: 218.2294, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 207.6625, Accuracy: 0.8443\n","Training loss (for one batch) at step 60: 208.5878, Accuracy: 0.8449\n","Training loss (for one batch) at step 70: 211.0733, Accuracy: 0.8451\n","Training loss (for one batch) at step 80: 241.8335, Accuracy: 0.8421\n","Training loss (for one batch) at step 90: 211.4266, Accuracy: 0.8412\n","Training loss (for one batch) at step 100: 214.8960, Accuracy: 0.8386\n","Training loss (for one batch) at step 110: 207.0420, Accuracy: 0.8400\n","Training loss (for one batch) at step 120: 212.9526, Accuracy: 0.8393\n","Training loss (for one batch) at step 130: 213.4765, Accuracy: 0.8391\n","Training loss (for one batch) at step 140: 228.9220, Accuracy: 0.8387\n","---- Training ----\n","Training loss: 187.3076\n","Training acc over epoch: 0.8388\n","---- Validation ----\n","Validation loss: 72.5629\n","Validation acc: 0.7284\n","Time taken: 9.55s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 229.7953, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 224.5193, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 216.3581, Accuracy: 0.8410\n","Training loss (for one batch) at step 30: 220.3492, Accuracy: 0.8394\n","Training loss (for one batch) at step 40: 201.5331, Accuracy: 0.8359\n","Training loss (for one batch) at step 50: 198.6077, Accuracy: 0.8429\n","Training loss (for one batch) at step 60: 220.0837, Accuracy: 0.8434\n","Training loss (for one batch) at step 70: 225.2080, Accuracy: 0.8382\n","Training loss (for one batch) at step 80: 220.5072, Accuracy: 0.8391\n","Training loss (for one batch) at step 90: 221.0550, Accuracy: 0.8375\n","Training loss (for one batch) at step 100: 207.4250, Accuracy: 0.8371\n","Training loss (for one batch) at step 110: 223.5929, Accuracy: 0.8393\n","Training loss (for one batch) at step 120: 218.0782, Accuracy: 0.8378\n","Training loss (for one batch) at step 130: 211.0209, Accuracy: 0.8382\n","Training loss (for one batch) at step 140: 225.5025, Accuracy: 0.8386\n","---- Training ----\n","Training loss: 203.5077\n","Training acc over epoch: 0.8397\n","---- Validation ----\n","Validation loss: 94.0007\n","Validation acc: 0.7260\n","Time taken: 9.63s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 215.1667, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 226.6041, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 225.3221, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 209.4616, Accuracy: 0.8410\n","Training loss (for one batch) at step 40: 212.1342, Accuracy: 0.8412\n","Training loss (for one batch) at step 50: 194.8992, Accuracy: 0.8453\n","Training loss (for one batch) at step 60: 214.3036, Accuracy: 0.8454\n","Training loss (for one batch) at step 70: 219.5392, Accuracy: 0.8486\n","Training loss (for one batch) at step 80: 204.3217, Accuracy: 0.8451\n","Training loss (for one batch) at step 90: 234.5965, Accuracy: 0.8429\n","Training loss (for one batch) at step 100: 210.6055, Accuracy: 0.8436\n","Training loss (for one batch) at step 110: 203.4795, Accuracy: 0.8448\n","Training loss (for one batch) at step 120: 226.5935, Accuracy: 0.8432\n","Training loss (for one batch) at step 130: 216.8984, Accuracy: 0.8429\n","Training loss (for one batch) at step 140: 221.8964, Accuracy: 0.8424\n","---- Training ----\n","Training loss: 175.3415\n","Training acc over epoch: 0.8423\n","---- Validation ----\n","Validation loss: 73.9187\n","Validation acc: 0.7243\n","Time taken: 9.80s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 209.2060, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 193.8835, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 195.1012, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 211.1396, Accuracy: 0.8352\n","Training loss (for one batch) at step 40: 211.1913, Accuracy: 0.8341\n","Training loss (for one batch) at step 50: 219.1919, Accuracy: 0.8392\n","Training loss (for one batch) at step 60: 205.8581, Accuracy: 0.8434\n","Training loss (for one batch) at step 70: 227.2318, Accuracy: 0.8435\n","Training loss (for one batch) at step 80: 225.4731, Accuracy: 0.8438\n","Training loss (for one batch) at step 90: 226.9149, Accuracy: 0.8420\n","Training loss (for one batch) at step 100: 212.0531, Accuracy: 0.8400\n","Training loss (for one batch) at step 110: 208.9631, Accuracy: 0.8411\n","Training loss (for one batch) at step 120: 222.7754, Accuracy: 0.8403\n","Training loss (for one batch) at step 130: 224.1968, Accuracy: 0.8408\n","Training loss (for one batch) at step 140: 212.5613, Accuracy: 0.8413\n","---- Training ----\n","Training loss: 198.5229\n","Training acc over epoch: 0.8411\n","---- Validation ----\n","Validation loss: 87.4493\n","Validation acc: 0.7222\n","Time taken: 9.68s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 195.9799, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 230.4171, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 223.7605, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 204.5818, Accuracy: 0.8345\n","Training loss (for one batch) at step 40: 202.6564, Accuracy: 0.8456\n","Training loss (for one batch) at step 50: 213.5964, Accuracy: 0.8451\n","Training loss (for one batch) at step 60: 194.5053, Accuracy: 0.8456\n","Training loss (for one batch) at step 70: 214.4104, Accuracy: 0.8458\n","Training loss (for one batch) at step 80: 204.4631, Accuracy: 0.8444\n","Training loss (for one batch) at step 90: 213.3010, Accuracy: 0.8437\n","Training loss (for one batch) at step 100: 217.6595, Accuracy: 0.8447\n","Training loss (for one batch) at step 110: 215.1500, Accuracy: 0.8442\n","Training loss (for one batch) at step 120: 197.6296, Accuracy: 0.8436\n","Training loss (for one batch) at step 130: 214.8552, Accuracy: 0.8437\n","Training loss (for one batch) at step 140: 218.7343, Accuracy: 0.8421\n","---- Training ----\n","Training loss: 184.1911\n","Training acc over epoch: 0.8418\n","---- Validation ----\n","Validation loss: 85.7193\n","Validation acc: 0.7273\n","Time taken: 9.66s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 209.1158, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 191.4656, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 221.0889, Accuracy: 0.8424\n","Training loss (for one batch) at step 30: 205.0467, Accuracy: 0.8345\n","Training loss (for one batch) at step 40: 181.6504, Accuracy: 0.8417\n","Training loss (for one batch) at step 50: 203.1536, Accuracy: 0.8449\n","Training loss (for one batch) at step 60: 210.2604, Accuracy: 0.8430\n","Training loss (for one batch) at step 70: 237.3985, Accuracy: 0.8430\n","Training loss (for one batch) at step 80: 220.5078, Accuracy: 0.8431\n","Training loss (for one batch) at step 90: 214.5979, Accuracy: 0.8432\n","Training loss (for one batch) at step 100: 207.3332, Accuracy: 0.8416\n","Training loss (for one batch) at step 110: 222.5513, Accuracy: 0.8429\n","Training loss (for one batch) at step 120: 226.6978, Accuracy: 0.8420\n","Training loss (for one batch) at step 130: 224.5389, Accuracy: 0.8409\n","Training loss (for one batch) at step 140: 196.2534, Accuracy: 0.8391\n","---- Training ----\n","Training loss: 175.2791\n","Training acc over epoch: 0.8398\n","---- Validation ----\n","Validation loss: 101.0878\n","Validation acc: 0.7346\n","Time taken: 9.69s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 200.1693, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 211.7359, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 231.1228, Accuracy: 0.8333\n","Training loss (for one batch) at step 30: 198.9076, Accuracy: 0.8342\n","Training loss (for one batch) at step 40: 195.6036, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 206.4157, Accuracy: 0.8457\n","Training loss (for one batch) at step 60: 196.9944, Accuracy: 0.8470\n","Training loss (for one batch) at step 70: 201.0112, Accuracy: 0.8465\n","Training loss (for one batch) at step 80: 208.3759, Accuracy: 0.8433\n","Training loss (for one batch) at step 90: 218.9194, Accuracy: 0.8415\n","Training loss (for one batch) at step 100: 203.7867, Accuracy: 0.8426\n","Training loss (for one batch) at step 110: 213.8533, Accuracy: 0.8431\n","Training loss (for one batch) at step 120: 211.5778, Accuracy: 0.8433\n","Training loss (for one batch) at step 130: 206.1498, Accuracy: 0.8424\n","Training loss (for one batch) at step 140: 170.6187, Accuracy: 0.8423\n","---- Training ----\n","Training loss: 190.3836\n","Training acc over epoch: 0.8425\n","---- Validation ----\n","Validation loss: 85.3031\n","Validation acc: 0.7276\n","Time taken: 9.67s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 206.0024, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 203.0271, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 236.1317, Accuracy: 0.8419\n","Training loss (for one batch) at step 30: 209.9834, Accuracy: 0.8410\n","Training loss (for one batch) at step 40: 201.5918, Accuracy: 0.8395\n","Training loss (for one batch) at step 50: 206.0454, Accuracy: 0.8467\n","Training loss (for one batch) at step 60: 223.7139, Accuracy: 0.8451\n","Training loss (for one batch) at step 70: 219.7950, Accuracy: 0.8458\n","Training loss (for one batch) at step 80: 219.4181, Accuracy: 0.8442\n","Training loss (for one batch) at step 90: 196.9211, Accuracy: 0.8440\n","Training loss (for one batch) at step 100: 215.7163, Accuracy: 0.8428\n","Training loss (for one batch) at step 110: 236.9913, Accuracy: 0.8426\n","Training loss (for one batch) at step 120: 216.0172, Accuracy: 0.8430\n","Training loss (for one batch) at step 130: 214.3946, Accuracy: 0.8419\n","Training loss (for one batch) at step 140: 206.1268, Accuracy: 0.8415\n","---- Training ----\n","Training loss: 185.7454\n","Training acc over epoch: 0.8416\n","---- Validation ----\n","Validation loss: 74.7693\n","Validation acc: 0.7257\n","Time taken: 9.69s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 205.8854, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 205.0148, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 202.9770, Accuracy: 0.8452\n","Training loss (for one batch) at step 30: 231.0651, Accuracy: 0.8455\n","Training loss (for one batch) at step 40: 198.3316, Accuracy: 0.8502\n","Training loss (for one batch) at step 50: 200.6381, Accuracy: 0.8486\n","Training loss (for one batch) at step 60: 203.1814, Accuracy: 0.8495\n","Training loss (for one batch) at step 70: 190.4228, Accuracy: 0.8504\n","Training loss (for one batch) at step 80: 201.1626, Accuracy: 0.8502\n","Training loss (for one batch) at step 90: 249.5471, Accuracy: 0.8486\n","Training loss (for one batch) at step 100: 188.7732, Accuracy: 0.8481\n","Training loss (for one batch) at step 110: 201.3288, Accuracy: 0.8484\n","Training loss (for one batch) at step 120: 191.9413, Accuracy: 0.8483\n","Training loss (for one batch) at step 130: 198.9489, Accuracy: 0.8484\n","Training loss (for one batch) at step 140: 197.6015, Accuracy: 0.8469\n","---- Training ----\n","Training loss: 179.9485\n","Training acc over epoch: 0.8466\n","---- Validation ----\n","Validation loss: 66.4867\n","Validation acc: 0.7268\n","Time taken: 9.61s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 193.6076, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 203.1969, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 214.6847, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 232.3889, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 206.6718, Accuracy: 0.8468\n","Training loss (for one batch) at step 50: 203.9940, Accuracy: 0.8433\n","Training loss (for one batch) at step 60: 184.2642, Accuracy: 0.8469\n","Training loss (for one batch) at step 70: 204.2090, Accuracy: 0.8463\n","Training loss (for one batch) at step 80: 187.6689, Accuracy: 0.8457\n","Training loss (for one batch) at step 90: 214.4445, Accuracy: 0.8459\n","Training loss (for one batch) at step 100: 208.1504, Accuracy: 0.8453\n","Training loss (for one batch) at step 110: 193.8879, Accuracy: 0.8461\n","Training loss (for one batch) at step 120: 214.8608, Accuracy: 0.8444\n","Training loss (for one batch) at step 130: 196.9614, Accuracy: 0.8434\n","Training loss (for one batch) at step 140: 224.1012, Accuracy: 0.8428\n","---- Training ----\n","Training loss: 191.6971\n","Training acc over epoch: 0.8436\n","---- Validation ----\n","Validation loss: 90.4779\n","Validation acc: 0.7243\n","Time taken: 9.71s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7416\n","Validation AUC: 0.7390\n","Validation Balanced_ACC: 0.4764\n","Validation MI: 0.1395\n","Validation Normalized MI: 0.2098\n","Validation Adjusted MI: 0.2098\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 523.5577, Accuracy: 0.4400\n","Training loss (for one batch) at step 10: 496.8537, Accuracy: 0.5073\n","Training loss (for one batch) at step 20: 413.1437, Accuracy: 0.5348\n","Training loss (for one batch) at step 30: 398.0397, Accuracy: 0.5400\n","Training loss (for one batch) at step 40: 416.8891, Accuracy: 0.5463\n","Training loss (for one batch) at step 50: 397.8508, Accuracy: 0.5473\n","Training loss (for one batch) at step 60: 450.8154, Accuracy: 0.5510\n","Training loss (for one batch) at step 70: 439.6840, Accuracy: 0.5568\n","Training loss (for one batch) at step 80: 427.2680, Accuracy: 0.5595\n","Training loss (for one batch) at step 90: 430.2664, Accuracy: 0.5634\n","Training loss (for one batch) at step 100: 416.2726, Accuracy: 0.5672\n","Training loss (for one batch) at step 110: 411.8481, Accuracy: 0.5679\n","Training loss (for one batch) at step 120: 393.8839, Accuracy: 0.5714\n","Training loss (for one batch) at step 130: 361.8430, Accuracy: 0.5744\n","Training loss (for one batch) at step 140: 399.6582, Accuracy: 0.5760\n","---- Training ----\n","Training loss: 367.4899\n","Training acc over epoch: 0.5740\n","---- Validation ----\n","Validation loss: 99.0939\n","Validation acc: 0.5134\n","Time taken: 12.35s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 397.8736, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 403.3751, Accuracy: 0.5900\n","Training loss (for one batch) at step 20: 376.9449, Accuracy: 0.5943\n","Training loss (for one batch) at step 30: 380.2177, Accuracy: 0.5981\n","Training loss (for one batch) at step 40: 397.8614, Accuracy: 0.6002\n","Training loss (for one batch) at step 50: 416.1226, Accuracy: 0.6006\n","Training loss (for one batch) at step 60: 363.2604, Accuracy: 0.5990\n","Training loss (for one batch) at step 70: 383.7071, Accuracy: 0.5970\n","Training loss (for one batch) at step 80: 416.7772, Accuracy: 0.5978\n","Training loss (for one batch) at step 90: 373.3311, Accuracy: 0.5982\n","Training loss (for one batch) at step 100: 377.6955, Accuracy: 0.6013\n","Training loss (for one batch) at step 110: 360.5224, Accuracy: 0.6038\n","Training loss (for one batch) at step 120: 375.3069, Accuracy: 0.6038\n","Training loss (for one batch) at step 130: 369.6777, Accuracy: 0.6043\n","Training loss (for one batch) at step 140: 360.0560, Accuracy: 0.6056\n","---- Training ----\n","Training loss: 353.4220\n","Training acc over epoch: 0.6052\n","---- Validation ----\n","Validation loss: 83.6148\n","Validation acc: 0.5148\n","Time taken: 9.55s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 373.3424, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 361.4643, Accuracy: 0.6400\n","Training loss (for one batch) at step 20: 376.0706, Accuracy: 0.6400\n","Training loss (for one batch) at step 30: 362.6948, Accuracy: 0.6365\n","Training loss (for one batch) at step 40: 386.9554, Accuracy: 0.6312\n","Training loss (for one batch) at step 50: 367.7979, Accuracy: 0.6263\n","Training loss (for one batch) at step 60: 375.0713, Accuracy: 0.6216\n","Training loss (for one batch) at step 70: 343.8536, Accuracy: 0.6256\n","Training loss (for one batch) at step 80: 343.2324, Accuracy: 0.6257\n","Training loss (for one batch) at step 90: 361.7728, Accuracy: 0.6299\n","Training loss (for one batch) at step 100: 347.8886, Accuracy: 0.6319\n","Training loss (for one batch) at step 110: 338.8393, Accuracy: 0.6316\n","Training loss (for one batch) at step 120: 346.3299, Accuracy: 0.6331\n","Training loss (for one batch) at step 130: 350.1644, Accuracy: 0.6347\n","Training loss (for one batch) at step 140: 367.9117, Accuracy: 0.6362\n","---- Training ----\n","Training loss: 324.0686\n","Training acc over epoch: 0.6366\n","---- Validation ----\n","Validation loss: 79.0656\n","Validation acc: 0.6846\n","Time taken: 9.71s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 341.9452, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 344.8378, Accuracy: 0.6545\n","Training loss (for one batch) at step 20: 366.5741, Accuracy: 0.6652\n","Training loss (for one batch) at step 30: 351.2097, Accuracy: 0.6639\n","Training loss (for one batch) at step 40: 345.7333, Accuracy: 0.6617\n","Training loss (for one batch) at step 50: 360.8411, Accuracy: 0.6637\n","Training loss (for one batch) at step 60: 350.2190, Accuracy: 0.6662\n","Training loss (for one batch) at step 70: 357.8407, Accuracy: 0.6662\n","Training loss (for one batch) at step 80: 333.3682, Accuracy: 0.6646\n","Training loss (for one batch) at step 90: 359.4087, Accuracy: 0.6632\n","Training loss (for one batch) at step 100: 343.2804, Accuracy: 0.6644\n","Training loss (for one batch) at step 110: 325.4107, Accuracy: 0.6625\n","Training loss (for one batch) at step 120: 335.7222, Accuracy: 0.6640\n","Training loss (for one batch) at step 130: 356.4016, Accuracy: 0.6640\n","Training loss (for one batch) at step 140: 377.8268, Accuracy: 0.6654\n","---- Training ----\n","Training loss: 307.2897\n","Training acc over epoch: 0.6640\n","---- Validation ----\n","Validation loss: 75.8633\n","Validation acc: 0.7133\n","Time taken: 9.85s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 340.4125, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 328.7814, Accuracy: 0.6982\n","Training loss (for one batch) at step 20: 335.0533, Accuracy: 0.6876\n","Training loss (for one batch) at step 30: 330.0056, Accuracy: 0.6819\n","Training loss (for one batch) at step 40: 323.6335, Accuracy: 0.6768\n","Training loss (for one batch) at step 50: 329.4039, Accuracy: 0.6794\n","Training loss (for one batch) at step 60: 338.8550, Accuracy: 0.6762\n","Training loss (for one batch) at step 70: 341.1678, Accuracy: 0.6780\n","Training loss (for one batch) at step 80: 346.7082, Accuracy: 0.6769\n","Training loss (for one batch) at step 90: 355.1392, Accuracy: 0.6754\n","Training loss (for one batch) at step 100: 358.2938, Accuracy: 0.6753\n","Training loss (for one batch) at step 110: 356.9773, Accuracy: 0.6742\n","Training loss (for one batch) at step 120: 347.1289, Accuracy: 0.6760\n","Training loss (for one batch) at step 130: 345.0469, Accuracy: 0.6752\n","Training loss (for one batch) at step 140: 346.7136, Accuracy: 0.6750\n","---- Training ----\n","Training loss: 312.8586\n","Training acc over epoch: 0.6769\n","---- Validation ----\n","Validation loss: 67.7869\n","Validation acc: 0.7152\n","Time taken: 9.65s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 339.3303, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 328.3836, Accuracy: 0.6873\n","Training loss (for one batch) at step 20: 321.5828, Accuracy: 0.6929\n","Training loss (for one batch) at step 30: 328.8307, Accuracy: 0.6903\n","Training loss (for one batch) at step 40: 342.0962, Accuracy: 0.6915\n","Training loss (for one batch) at step 50: 316.2831, Accuracy: 0.6949\n","Training loss (for one batch) at step 60: 324.3149, Accuracy: 0.6928\n","Training loss (for one batch) at step 70: 328.8148, Accuracy: 0.6954\n","Training loss (for one batch) at step 80: 322.5973, Accuracy: 0.6944\n","Training loss (for one batch) at step 90: 322.5962, Accuracy: 0.6942\n","Training loss (for one batch) at step 100: 319.6500, Accuracy: 0.6931\n","Training loss (for one batch) at step 110: 336.0776, Accuracy: 0.6929\n","Training loss (for one batch) at step 120: 315.4293, Accuracy: 0.6928\n","Training loss (for one batch) at step 130: 315.7061, Accuracy: 0.6942\n","Training loss (for one batch) at step 140: 329.6695, Accuracy: 0.6949\n","---- Training ----\n","Training loss: 266.6876\n","Training acc over epoch: 0.6950\n","---- Validation ----\n","Validation loss: 69.5787\n","Validation acc: 0.7061\n","Time taken: 9.68s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 312.6266, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 349.2459, Accuracy: 0.7100\n","Training loss (for one batch) at step 20: 336.0094, Accuracy: 0.7029\n","Training loss (for one batch) at step 30: 322.9905, Accuracy: 0.6990\n","Training loss (for one batch) at step 40: 306.4884, Accuracy: 0.7063\n","Training loss (for one batch) at step 50: 321.0471, Accuracy: 0.7059\n","Training loss (for one batch) at step 60: 305.2550, Accuracy: 0.7043\n","Training loss (for one batch) at step 70: 340.7637, Accuracy: 0.7032\n","Training loss (for one batch) at step 80: 324.0989, Accuracy: 0.6991\n","Training loss (for one batch) at step 90: 322.9695, Accuracy: 0.6991\n","Training loss (for one batch) at step 100: 330.0576, Accuracy: 0.6968\n","Training loss (for one batch) at step 110: 322.9632, Accuracy: 0.6959\n","Training loss (for one batch) at step 120: 327.8749, Accuracy: 0.6943\n","Training loss (for one batch) at step 130: 317.3699, Accuracy: 0.6948\n","Training loss (for one batch) at step 140: 313.3745, Accuracy: 0.6971\n","---- Training ----\n","Training loss: 280.9851\n","Training acc over epoch: 0.6980\n","---- Validation ----\n","Validation loss: 70.1408\n","Validation acc: 0.7249\n","Time taken: 9.73s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 312.1867, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 327.5435, Accuracy: 0.7218\n","Training loss (for one batch) at step 20: 308.5320, Accuracy: 0.7219\n","Training loss (for one batch) at step 30: 325.0603, Accuracy: 0.7190\n","Training loss (for one batch) at step 40: 307.8675, Accuracy: 0.7163\n","Training loss (for one batch) at step 50: 312.1379, Accuracy: 0.7188\n","Training loss (for one batch) at step 60: 332.5828, Accuracy: 0.7203\n","Training loss (for one batch) at step 70: 322.5126, Accuracy: 0.7189\n","Training loss (for one batch) at step 80: 328.8985, Accuracy: 0.7177\n","Training loss (for one batch) at step 90: 328.0935, Accuracy: 0.7144\n","Training loss (for one batch) at step 100: 313.2025, Accuracy: 0.7152\n","Training loss (for one batch) at step 110: 325.0549, Accuracy: 0.7157\n","Training loss (for one batch) at step 120: 313.5393, Accuracy: 0.7188\n","Training loss (for one batch) at step 130: 308.0646, Accuracy: 0.7179\n","Training loss (for one batch) at step 140: 310.2157, Accuracy: 0.7182\n","---- Training ----\n","Training loss: 274.0884\n","Training acc over epoch: 0.7194\n","---- Validation ----\n","Validation loss: 69.3793\n","Validation acc: 0.7098\n","Time taken: 9.67s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 331.7161, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 322.3951, Accuracy: 0.7155\n","Training loss (for one batch) at step 20: 306.5749, Accuracy: 0.7348\n","Training loss (for one batch) at step 30: 312.8910, Accuracy: 0.7306\n","Training loss (for one batch) at step 40: 311.7783, Accuracy: 0.7307\n","Training loss (for one batch) at step 50: 313.6484, Accuracy: 0.7325\n","Training loss (for one batch) at step 60: 305.6499, Accuracy: 0.7333\n","Training loss (for one batch) at step 70: 313.3863, Accuracy: 0.7289\n","Training loss (for one batch) at step 80: 333.0683, Accuracy: 0.7295\n","Training loss (for one batch) at step 90: 323.4733, Accuracy: 0.7276\n","Training loss (for one batch) at step 100: 306.0536, Accuracy: 0.7277\n","Training loss (for one batch) at step 110: 308.3853, Accuracy: 0.7292\n","Training loss (for one batch) at step 120: 305.1878, Accuracy: 0.7307\n","Training loss (for one batch) at step 130: 317.8726, Accuracy: 0.7307\n","Training loss (for one batch) at step 140: 310.3424, Accuracy: 0.7309\n","---- Training ----\n","Training loss: 281.5775\n","Training acc over epoch: 0.7311\n","---- Validation ----\n","Validation loss: 73.9246\n","Validation acc: 0.7120\n","Time taken: 9.61s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 305.4506, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 302.3869, Accuracy: 0.7418\n","Training loss (for one batch) at step 20: 325.8052, Accuracy: 0.7376\n","Training loss (for one batch) at step 30: 321.2041, Accuracy: 0.7403\n","Training loss (for one batch) at step 40: 303.0174, Accuracy: 0.7390\n","Training loss (for one batch) at step 50: 309.8930, Accuracy: 0.7422\n","Training loss (for one batch) at step 60: 293.6253, Accuracy: 0.7456\n","Training loss (for one batch) at step 70: 316.5260, Accuracy: 0.7446\n","Training loss (for one batch) at step 80: 310.7548, Accuracy: 0.7437\n","Training loss (for one batch) at step 90: 304.0634, Accuracy: 0.7433\n","Training loss (for one batch) at step 100: 300.9677, Accuracy: 0.7446\n","Training loss (for one batch) at step 110: 291.7099, Accuracy: 0.7441\n","Training loss (for one batch) at step 120: 310.7214, Accuracy: 0.7429\n","Training loss (for one batch) at step 130: 309.8682, Accuracy: 0.7433\n","Training loss (for one batch) at step 140: 308.5651, Accuracy: 0.7448\n","---- Training ----\n","Training loss: 274.3655\n","Training acc over epoch: 0.7436\n","---- Validation ----\n","Validation loss: 71.7713\n","Validation acc: 0.7002\n","Time taken: 9.65s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 305.3892, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 302.4653, Accuracy: 0.7391\n","Training loss (for one batch) at step 20: 317.2050, Accuracy: 0.7448\n","Training loss (for one batch) at step 30: 303.8953, Accuracy: 0.7484\n","Training loss (for one batch) at step 40: 301.2062, Accuracy: 0.7539\n","Training loss (for one batch) at step 50: 296.1666, Accuracy: 0.7559\n","Training loss (for one batch) at step 60: 300.4509, Accuracy: 0.7538\n","Training loss (for one batch) at step 70: 314.0891, Accuracy: 0.7541\n","Training loss (for one batch) at step 80: 323.2897, Accuracy: 0.7496\n","Training loss (for one batch) at step 90: 302.5661, Accuracy: 0.7505\n","Training loss (for one batch) at step 100: 312.6848, Accuracy: 0.7501\n","Training loss (for one batch) at step 110: 295.3481, Accuracy: 0.7502\n","Training loss (for one batch) at step 120: 326.8329, Accuracy: 0.7494\n","Training loss (for one batch) at step 130: 303.3159, Accuracy: 0.7500\n","Training loss (for one batch) at step 140: 304.4008, Accuracy: 0.7497\n","---- Training ----\n","Training loss: 258.5551\n","Training acc over epoch: 0.7501\n","---- Validation ----\n","Validation loss: 74.5096\n","Validation acc: 0.7372\n","Time taken: 9.80s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 303.3584, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 302.1181, Accuracy: 0.7682\n","Training loss (for one batch) at step 20: 303.2287, Accuracy: 0.7657\n","Training loss (for one batch) at step 30: 295.1436, Accuracy: 0.7655\n","Training loss (for one batch) at step 40: 305.6092, Accuracy: 0.7649\n","Training loss (for one batch) at step 50: 284.9089, Accuracy: 0.7690\n","Training loss (for one batch) at step 60: 292.5275, Accuracy: 0.7675\n","Training loss (for one batch) at step 70: 309.5633, Accuracy: 0.7654\n","Training loss (for one batch) at step 80: 302.1812, Accuracy: 0.7609\n","Training loss (for one batch) at step 90: 301.8081, Accuracy: 0.7610\n","Training loss (for one batch) at step 100: 297.2503, Accuracy: 0.7610\n","Training loss (for one batch) at step 110: 323.4384, Accuracy: 0.7593\n","Training loss (for one batch) at step 120: 277.8810, Accuracy: 0.7588\n","Training loss (for one batch) at step 130: 287.1664, Accuracy: 0.7591\n","Training loss (for one batch) at step 140: 295.8494, Accuracy: 0.7582\n","---- Training ----\n","Training loss: 272.7508\n","Training acc over epoch: 0.7576\n","---- Validation ----\n","Validation loss: 75.1702\n","Validation acc: 0.7316\n","Time taken: 33.48s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 297.0018, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 290.2651, Accuracy: 0.7591\n","Training loss (for one batch) at step 20: 290.0222, Accuracy: 0.7600\n","Training loss (for one batch) at step 30: 286.2743, Accuracy: 0.7645\n","Training loss (for one batch) at step 40: 287.7147, Accuracy: 0.7659\n","Training loss (for one batch) at step 50: 297.6000, Accuracy: 0.7700\n","Training loss (for one batch) at step 60: 274.8487, Accuracy: 0.7723\n","Training loss (for one batch) at step 70: 283.1437, Accuracy: 0.7714\n","Training loss (for one batch) at step 80: 295.8372, Accuracy: 0.7683\n","Training loss (for one batch) at step 90: 310.8080, Accuracy: 0.7665\n","Training loss (for one batch) at step 100: 282.6945, Accuracy: 0.7671\n","Training loss (for one batch) at step 110: 280.1568, Accuracy: 0.7679\n","Training loss (for one batch) at step 120: 289.8749, Accuracy: 0.7680\n","Training loss (for one batch) at step 130: 288.2380, Accuracy: 0.7673\n","Training loss (for one batch) at step 140: 308.8196, Accuracy: 0.7670\n","---- Training ----\n","Training loss: 246.0341\n","Training acc over epoch: 0.7663\n","---- Validation ----\n","Validation loss: 66.5882\n","Validation acc: 0.7354\n","Time taken: 22.14s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 289.8189, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 297.9207, Accuracy: 0.7745\n","Training loss (for one batch) at step 20: 289.0482, Accuracy: 0.7748\n","Training loss (for one batch) at step 30: 271.1974, Accuracy: 0.7713\n","Training loss (for one batch) at step 40: 290.3736, Accuracy: 0.7717\n","Training loss (for one batch) at step 50: 267.5084, Accuracy: 0.7724\n","Training loss (for one batch) at step 60: 303.4152, Accuracy: 0.7680\n","Training loss (for one batch) at step 70: 304.3085, Accuracy: 0.7701\n","Training loss (for one batch) at step 80: 296.8976, Accuracy: 0.7668\n","Training loss (for one batch) at step 90: 291.6685, Accuracy: 0.7656\n","Training loss (for one batch) at step 100: 296.5633, Accuracy: 0.7662\n","Training loss (for one batch) at step 110: 273.9217, Accuracy: 0.7678\n","Training loss (for one batch) at step 120: 291.2602, Accuracy: 0.7689\n","Training loss (for one batch) at step 130: 280.1744, Accuracy: 0.7698\n","Training loss (for one batch) at step 140: 294.1536, Accuracy: 0.7690\n","---- Training ----\n","Training loss: 256.8938\n","Training acc over epoch: 0.7689\n","---- Validation ----\n","Validation loss: 70.5112\n","Validation acc: 0.7214\n","Time taken: 45.33s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 283.8521, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 283.7940, Accuracy: 0.8055\n","Training loss (for one batch) at step 20: 302.5237, Accuracy: 0.7886\n","Training loss (for one batch) at step 30: 279.7384, Accuracy: 0.7858\n","Training loss (for one batch) at step 40: 293.9319, Accuracy: 0.7854\n","Training loss (for one batch) at step 50: 283.2734, Accuracy: 0.7865\n","Training loss (for one batch) at step 60: 314.3877, Accuracy: 0.7851\n","Training loss (for one batch) at step 70: 275.5642, Accuracy: 0.7842\n","Training loss (for one batch) at step 80: 290.5769, Accuracy: 0.7821\n","Training loss (for one batch) at step 90: 293.6895, Accuracy: 0.7798\n","Training loss (for one batch) at step 100: 276.5616, Accuracy: 0.7798\n","Training loss (for one batch) at step 110: 273.2014, Accuracy: 0.7814\n","Training loss (for one batch) at step 120: 303.5331, Accuracy: 0.7779\n","Training loss (for one batch) at step 130: 307.4468, Accuracy: 0.7780\n","Training loss (for one batch) at step 140: 280.0186, Accuracy: 0.7784\n","---- Training ----\n","Training loss: 243.2144\n","Training acc over epoch: 0.7793\n","---- Validation ----\n","Validation loss: 78.8393\n","Validation acc: 0.7278\n","Time taken: 13.30s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 284.7844, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 291.9615, Accuracy: 0.7964\n","Training loss (for one batch) at step 20: 278.4351, Accuracy: 0.7824\n","Training loss (for one batch) at step 30: 278.4301, Accuracy: 0.7819\n","Training loss (for one batch) at step 40: 290.4062, Accuracy: 0.7854\n","Training loss (for one batch) at step 50: 274.3217, Accuracy: 0.7906\n","Training loss (for one batch) at step 60: 308.3741, Accuracy: 0.7911\n","Training loss (for one batch) at step 70: 289.6917, Accuracy: 0.7907\n","Training loss (for one batch) at step 80: 291.0260, Accuracy: 0.7863\n","Training loss (for one batch) at step 90: 278.6240, Accuracy: 0.7847\n","Training loss (for one batch) at step 100: 295.4868, Accuracy: 0.7820\n","Training loss (for one batch) at step 110: 276.1996, Accuracy: 0.7832\n","Training loss (for one batch) at step 120: 304.7613, Accuracy: 0.7822\n","Training loss (for one batch) at step 130: 275.5863, Accuracy: 0.7830\n","Training loss (for one batch) at step 140: 283.1196, Accuracy: 0.7839\n","---- Training ----\n","Training loss: 252.8683\n","Training acc over epoch: 0.7841\n","---- Validation ----\n","Validation loss: 63.9631\n","Validation acc: 0.7133\n","Time taken: 9.80s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 279.3137, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 283.3649, Accuracy: 0.8036\n","Training loss (for one batch) at step 20: 289.8356, Accuracy: 0.7924\n","Training loss (for one batch) at step 30: 291.5695, Accuracy: 0.7945\n","Training loss (for one batch) at step 40: 279.7706, Accuracy: 0.7912\n","Training loss (for one batch) at step 50: 279.8132, Accuracy: 0.7943\n","Training loss (for one batch) at step 60: 280.1175, Accuracy: 0.7916\n","Training loss (for one batch) at step 70: 284.0613, Accuracy: 0.7907\n","Training loss (for one batch) at step 80: 306.2336, Accuracy: 0.7870\n","Training loss (for one batch) at step 90: 271.9615, Accuracy: 0.7876\n","Training loss (for one batch) at step 100: 295.1145, Accuracy: 0.7866\n","Training loss (for one batch) at step 110: 275.6613, Accuracy: 0.7843\n","Training loss (for one batch) at step 120: 283.1567, Accuracy: 0.7864\n","Training loss (for one batch) at step 130: 268.1418, Accuracy: 0.7869\n","Training loss (for one batch) at step 140: 279.2841, Accuracy: 0.7857\n","---- Training ----\n","Training loss: 256.8353\n","Training acc over epoch: 0.7859\n","---- Validation ----\n","Validation loss: 64.1541\n","Validation acc: 0.7440\n","Time taken: 9.76s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 270.6765, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 269.6879, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 275.7722, Accuracy: 0.8062\n","Training loss (for one batch) at step 30: 281.3021, Accuracy: 0.7945\n","Training loss (for one batch) at step 40: 270.8566, Accuracy: 0.7971\n","Training loss (for one batch) at step 50: 285.9362, Accuracy: 0.8022\n","Training loss (for one batch) at step 60: 287.9516, Accuracy: 0.7987\n","Training loss (for one batch) at step 70: 289.0279, Accuracy: 0.7966\n","Training loss (for one batch) at step 80: 262.9249, Accuracy: 0.7938\n","Training loss (for one batch) at step 90: 250.4714, Accuracy: 0.7940\n","Training loss (for one batch) at step 100: 289.0182, Accuracy: 0.7925\n","Training loss (for one batch) at step 110: 272.9794, Accuracy: 0.7940\n","Training loss (for one batch) at step 120: 281.9688, Accuracy: 0.7945\n","Training loss (for one batch) at step 130: 259.8760, Accuracy: 0.7944\n","Training loss (for one batch) at step 140: 289.7331, Accuracy: 0.7940\n","---- Training ----\n","Training loss: 252.3452\n","Training acc over epoch: 0.7937\n","---- Validation ----\n","Validation loss: 71.7642\n","Validation acc: 0.7407\n","Time taken: 9.63s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 288.4043, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 261.8428, Accuracy: 0.8000\n","Training loss (for one batch) at step 20: 265.2718, Accuracy: 0.7924\n","Training loss (for one batch) at step 30: 285.9737, Accuracy: 0.7935\n","Training loss (for one batch) at step 40: 279.8500, Accuracy: 0.7961\n","Training loss (for one batch) at step 50: 272.2643, Accuracy: 0.7982\n","Training loss (for one batch) at step 60: 267.2086, Accuracy: 0.7984\n","Training loss (for one batch) at step 70: 277.1343, Accuracy: 0.7938\n","Training loss (for one batch) at step 80: 292.8036, Accuracy: 0.7921\n","Training loss (for one batch) at step 90: 261.4859, Accuracy: 0.7922\n","Training loss (for one batch) at step 100: 260.5031, Accuracy: 0.7922\n","Training loss (for one batch) at step 110: 285.9489, Accuracy: 0.7904\n","Training loss (for one batch) at step 120: 266.7211, Accuracy: 0.7913\n","Training loss (for one batch) at step 130: 264.6856, Accuracy: 0.7908\n","Training loss (for one batch) at step 140: 264.5425, Accuracy: 0.7913\n","---- Training ----\n","Training loss: 228.4420\n","Training acc over epoch: 0.7913\n","---- Validation ----\n","Validation loss: 62.9184\n","Validation acc: 0.7182\n","Time taken: 9.82s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 277.8730, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 279.4507, Accuracy: 0.7845\n","Training loss (for one batch) at step 20: 273.3383, Accuracy: 0.7952\n","Training loss (for one batch) at step 30: 265.2821, Accuracy: 0.7913\n","Training loss (for one batch) at step 40: 259.7763, Accuracy: 0.7954\n","Training loss (for one batch) at step 50: 264.3455, Accuracy: 0.7969\n","Training loss (for one batch) at step 60: 291.0917, Accuracy: 0.7956\n","Training loss (for one batch) at step 70: 278.3216, Accuracy: 0.7969\n","Training loss (for one batch) at step 80: 265.0488, Accuracy: 0.7935\n","Training loss (for one batch) at step 90: 272.2105, Accuracy: 0.7935\n","Training loss (for one batch) at step 100: 260.1793, Accuracy: 0.7943\n","Training loss (for one batch) at step 110: 255.0437, Accuracy: 0.7984\n","Training loss (for one batch) at step 120: 278.7664, Accuracy: 0.7987\n","Training loss (for one batch) at step 130: 274.5306, Accuracy: 0.7985\n","Training loss (for one batch) at step 140: 278.2837, Accuracy: 0.7977\n","---- Training ----\n","Training loss: 251.8018\n","Training acc over epoch: 0.7986\n","---- Validation ----\n","Validation loss: 73.3798\n","Validation acc: 0.7391\n","Time taken: 9.83s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 270.2190, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 273.2096, Accuracy: 0.8118\n","Training loss (for one batch) at step 20: 268.8616, Accuracy: 0.8157\n","Training loss (for one batch) at step 30: 254.6424, Accuracy: 0.8126\n","Training loss (for one batch) at step 40: 258.7090, Accuracy: 0.8110\n","Training loss (for one batch) at step 50: 252.2193, Accuracy: 0.8082\n","Training loss (for one batch) at step 60: 263.3333, Accuracy: 0.8061\n","Training loss (for one batch) at step 70: 288.5100, Accuracy: 0.8061\n","Training loss (for one batch) at step 80: 281.6863, Accuracy: 0.8016\n","Training loss (for one batch) at step 90: 276.6441, Accuracy: 0.8010\n","Training loss (for one batch) at step 100: 270.7467, Accuracy: 0.8016\n","Training loss (for one batch) at step 110: 260.9901, Accuracy: 0.8015\n","Training loss (for one batch) at step 120: 270.3508, Accuracy: 0.8002\n","Training loss (for one batch) at step 130: 259.9927, Accuracy: 0.8015\n","Training loss (for one batch) at step 140: 275.5004, Accuracy: 0.8011\n","---- Training ----\n","Training loss: 232.8673\n","Training acc over epoch: 0.8015\n","---- Validation ----\n","Validation loss: 64.8887\n","Validation acc: 0.7528\n","Time taken: 9.68s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 277.7704, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 260.4329, Accuracy: 0.8064\n","Training loss (for one batch) at step 20: 273.4171, Accuracy: 0.7986\n","Training loss (for one batch) at step 30: 257.5088, Accuracy: 0.8013\n","Training loss (for one batch) at step 40: 277.6121, Accuracy: 0.7966\n","Training loss (for one batch) at step 50: 268.8433, Accuracy: 0.8033\n","Training loss (for one batch) at step 60: 258.4039, Accuracy: 0.8048\n","Training loss (for one batch) at step 70: 263.8005, Accuracy: 0.8041\n","Training loss (for one batch) at step 80: 284.7686, Accuracy: 0.7994\n","Training loss (for one batch) at step 90: 282.4944, Accuracy: 0.7984\n","Training loss (for one batch) at step 100: 282.3324, Accuracy: 0.7983\n","Training loss (for one batch) at step 110: 266.0971, Accuracy: 0.7983\n","Training loss (for one batch) at step 120: 248.3413, Accuracy: 0.7991\n","Training loss (for one batch) at step 130: 265.2509, Accuracy: 0.7985\n","Training loss (for one batch) at step 140: 276.2840, Accuracy: 0.7984\n","---- Training ----\n","Training loss: 229.1544\n","Training acc over epoch: 0.7992\n","---- Validation ----\n","Validation loss: 66.3113\n","Validation acc: 0.7292\n","Time taken: 9.86s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 260.0927, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 258.4279, Accuracy: 0.8118\n","Training loss (for one batch) at step 20: 257.5322, Accuracy: 0.8086\n","Training loss (for one batch) at step 30: 258.7373, Accuracy: 0.8074\n","Training loss (for one batch) at step 40: 276.6415, Accuracy: 0.8056\n","Training loss (for one batch) at step 50: 238.1049, Accuracy: 0.8061\n","Training loss (for one batch) at step 60: 249.1911, Accuracy: 0.8061\n","Training loss (for one batch) at step 70: 240.8532, Accuracy: 0.8062\n","Training loss (for one batch) at step 80: 270.2068, Accuracy: 0.8063\n","Training loss (for one batch) at step 90: 278.1066, Accuracy: 0.8043\n","Training loss (for one batch) at step 100: 271.6573, Accuracy: 0.8021\n","Training loss (for one batch) at step 110: 268.2300, Accuracy: 0.8041\n","Training loss (for one batch) at step 120: 261.8355, Accuracy: 0.8046\n","Training loss (for one batch) at step 130: 260.5448, Accuracy: 0.8047\n","Training loss (for one batch) at step 140: 256.5685, Accuracy: 0.8064\n","---- Training ----\n","Training loss: 238.7029\n","Training acc over epoch: 0.8064\n","---- Validation ----\n","Validation loss: 78.7513\n","Validation acc: 0.7211\n","Time taken: 9.73s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 245.8204, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 271.7341, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 254.7392, Accuracy: 0.8057\n","Training loss (for one batch) at step 30: 260.3712, Accuracy: 0.8106\n","Training loss (for one batch) at step 40: 244.8615, Accuracy: 0.8132\n","Training loss (for one batch) at step 50: 269.7298, Accuracy: 0.8141\n","Training loss (for one batch) at step 60: 261.0078, Accuracy: 0.8136\n","Training loss (for one batch) at step 70: 255.5837, Accuracy: 0.8099\n","Training loss (for one batch) at step 80: 274.6279, Accuracy: 0.8075\n","Training loss (for one batch) at step 90: 289.9460, Accuracy: 0.8058\n","Training loss (for one batch) at step 100: 264.8957, Accuracy: 0.8050\n","Training loss (for one batch) at step 110: 242.6129, Accuracy: 0.8072\n","Training loss (for one batch) at step 120: 262.0731, Accuracy: 0.8074\n","Training loss (for one batch) at step 130: 266.4477, Accuracy: 0.8069\n","Training loss (for one batch) at step 140: 266.1490, Accuracy: 0.8056\n","---- Training ----\n","Training loss: 248.4719\n","Training acc over epoch: 0.8060\n","---- Validation ----\n","Validation loss: 66.9454\n","Validation acc: 0.7262\n","Time taken: 9.69s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 262.0155, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 249.5278, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 259.6613, Accuracy: 0.8167\n","Training loss (for one batch) at step 30: 246.8008, Accuracy: 0.8113\n","Training loss (for one batch) at step 40: 252.5249, Accuracy: 0.8112\n","Training loss (for one batch) at step 50: 263.1897, Accuracy: 0.8100\n","Training loss (for one batch) at step 60: 258.9511, Accuracy: 0.8108\n","Training loss (for one batch) at step 70: 256.5532, Accuracy: 0.8089\n","Training loss (for one batch) at step 80: 260.7530, Accuracy: 0.8059\n","Training loss (for one batch) at step 90: 266.6212, Accuracy: 0.8062\n","Training loss (for one batch) at step 100: 250.7361, Accuracy: 0.8074\n","Training loss (for one batch) at step 110: 268.3583, Accuracy: 0.8082\n","Training loss (for one batch) at step 120: 252.4307, Accuracy: 0.8083\n","Training loss (for one batch) at step 130: 253.1690, Accuracy: 0.8089\n","Training loss (for one batch) at step 140: 244.9740, Accuracy: 0.8093\n","---- Training ----\n","Training loss: 222.5552\n","Training acc over epoch: 0.8093\n","---- Validation ----\n","Validation loss: 72.3517\n","Validation acc: 0.7157\n","Time taken: 9.70s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 262.0134, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 246.7338, Accuracy: 0.8127\n","Training loss (for one batch) at step 20: 255.3643, Accuracy: 0.8171\n","Training loss (for one batch) at step 30: 253.6146, Accuracy: 0.8148\n","Training loss (for one batch) at step 40: 251.2232, Accuracy: 0.8117\n","Training loss (for one batch) at step 50: 246.1183, Accuracy: 0.8153\n","Training loss (for one batch) at step 60: 234.6256, Accuracy: 0.8162\n","Training loss (for one batch) at step 70: 254.1388, Accuracy: 0.8159\n","Training loss (for one batch) at step 80: 275.7559, Accuracy: 0.8148\n","Training loss (for one batch) at step 90: 251.1138, Accuracy: 0.8144\n","Training loss (for one batch) at step 100: 257.4838, Accuracy: 0.8148\n","Training loss (for one batch) at step 110: 248.6616, Accuracy: 0.8160\n","Training loss (for one batch) at step 120: 259.9803, Accuracy: 0.8141\n","Training loss (for one batch) at step 130: 247.1849, Accuracy: 0.8161\n","Training loss (for one batch) at step 140: 249.9314, Accuracy: 0.8162\n","---- Training ----\n","Training loss: 219.6844\n","Training acc over epoch: 0.8159\n","---- Validation ----\n","Validation loss: 76.5519\n","Validation acc: 0.6932\n","Time taken: 9.62s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 254.6947, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 270.8635, Accuracy: 0.8400\n","Training loss (for one batch) at step 20: 233.7137, Accuracy: 0.8286\n","Training loss (for one batch) at step 30: 257.0399, Accuracy: 0.8210\n","Training loss (for one batch) at step 40: 240.1243, Accuracy: 0.8190\n","Training loss (for one batch) at step 50: 260.9127, Accuracy: 0.8176\n","Training loss (for one batch) at step 60: 250.6451, Accuracy: 0.8190\n","Training loss (for one batch) at step 70: 268.5210, Accuracy: 0.8173\n","Training loss (for one batch) at step 80: 240.2543, Accuracy: 0.8154\n","Training loss (for one batch) at step 90: 261.0985, Accuracy: 0.8146\n","Training loss (for one batch) at step 100: 257.3217, Accuracy: 0.8149\n","Training loss (for one batch) at step 110: 246.6407, Accuracy: 0.8156\n","Training loss (for one batch) at step 120: 242.5191, Accuracy: 0.8157\n","Training loss (for one batch) at step 130: 254.1900, Accuracy: 0.8172\n","Training loss (for one batch) at step 140: 269.4916, Accuracy: 0.8164\n","---- Training ----\n","Training loss: 234.4617\n","Training acc over epoch: 0.8160\n","---- Validation ----\n","Validation loss: 75.6732\n","Validation acc: 0.7163\n","Time taken: 9.58s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 260.9037, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 241.0548, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 252.8737, Accuracy: 0.8267\n","Training loss (for one batch) at step 30: 279.6652, Accuracy: 0.8229\n","Training loss (for one batch) at step 40: 246.9436, Accuracy: 0.8210\n","Training loss (for one batch) at step 50: 227.9259, Accuracy: 0.8188\n","Training loss (for one batch) at step 60: 234.2194, Accuracy: 0.8184\n","Training loss (for one batch) at step 70: 257.6734, Accuracy: 0.8175\n","Training loss (for one batch) at step 80: 274.2605, Accuracy: 0.8140\n","Training loss (for one batch) at step 90: 255.9962, Accuracy: 0.8127\n","Training loss (for one batch) at step 100: 253.2130, Accuracy: 0.8133\n","Training loss (for one batch) at step 110: 239.2866, Accuracy: 0.8139\n","Training loss (for one batch) at step 120: 263.7358, Accuracy: 0.8150\n","Training loss (for one batch) at step 130: 244.1194, Accuracy: 0.8147\n","Training loss (for one batch) at step 140: 256.5374, Accuracy: 0.8137\n","---- Training ----\n","Training loss: 212.1430\n","Training acc over epoch: 0.8133\n","---- Validation ----\n","Validation loss: 69.4186\n","Validation acc: 0.7367\n","Time taken: 9.82s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 255.8266, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 260.0836, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 248.3476, Accuracy: 0.8210\n","Training loss (for one batch) at step 30: 248.6258, Accuracy: 0.8139\n","Training loss (for one batch) at step 40: 236.7083, Accuracy: 0.8159\n","Training loss (for one batch) at step 50: 253.7329, Accuracy: 0.8176\n","Training loss (for one batch) at step 60: 243.6418, Accuracy: 0.8210\n","Training loss (for one batch) at step 70: 259.6647, Accuracy: 0.8215\n","Training loss (for one batch) at step 80: 258.1086, Accuracy: 0.8156\n","Training loss (for one batch) at step 90: 246.8475, Accuracy: 0.8160\n","Training loss (for one batch) at step 100: 243.2163, Accuracy: 0.8137\n","Training loss (for one batch) at step 110: 242.0460, Accuracy: 0.8159\n","Training loss (for one batch) at step 120: 239.5108, Accuracy: 0.8150\n","Training loss (for one batch) at step 130: 238.7832, Accuracy: 0.8147\n","Training loss (for one batch) at step 140: 266.5021, Accuracy: 0.8154\n","---- Training ----\n","Training loss: 213.2328\n","Training acc over epoch: 0.8152\n","---- Validation ----\n","Validation loss: 83.8322\n","Validation acc: 0.6937\n","Time taken: 9.82s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 245.5550, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 259.5939, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 222.9647, Accuracy: 0.8248\n","Training loss (for one batch) at step 30: 254.2589, Accuracy: 0.8216\n","Training loss (for one batch) at step 40: 235.8493, Accuracy: 0.8210\n","Training loss (for one batch) at step 50: 240.5926, Accuracy: 0.8225\n","Training loss (for one batch) at step 60: 236.2498, Accuracy: 0.8210\n","Training loss (for one batch) at step 70: 248.0257, Accuracy: 0.8192\n","Training loss (for one batch) at step 80: 234.8482, Accuracy: 0.8169\n","Training loss (for one batch) at step 90: 228.4471, Accuracy: 0.8167\n","Training loss (for one batch) at step 100: 242.9340, Accuracy: 0.8176\n","Training loss (for one batch) at step 110: 246.3657, Accuracy: 0.8183\n","Training loss (for one batch) at step 120: 235.6548, Accuracy: 0.8187\n","Training loss (for one batch) at step 130: 259.0857, Accuracy: 0.8189\n","Training loss (for one batch) at step 140: 239.2588, Accuracy: 0.8184\n","---- Training ----\n","Training loss: 212.3820\n","Training acc over epoch: 0.8185\n","---- Validation ----\n","Validation loss: 65.8474\n","Validation acc: 0.7061\n","Time taken: 9.69s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 251.1554, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 234.0223, Accuracy: 0.8282\n","Training loss (for one batch) at step 20: 238.2484, Accuracy: 0.8238\n","Training loss (for one batch) at step 30: 245.1299, Accuracy: 0.8261\n","Training loss (for one batch) at step 40: 239.8674, Accuracy: 0.8271\n","Training loss (for one batch) at step 50: 237.9555, Accuracy: 0.8306\n","Training loss (for one batch) at step 60: 230.4785, Accuracy: 0.8264\n","Training loss (for one batch) at step 70: 246.7509, Accuracy: 0.8225\n","Training loss (for one batch) at step 80: 259.5488, Accuracy: 0.8211\n","Training loss (for one batch) at step 90: 244.2393, Accuracy: 0.8215\n","Training loss (for one batch) at step 100: 236.9100, Accuracy: 0.8216\n","Training loss (for one batch) at step 110: 233.6225, Accuracy: 0.8227\n","Training loss (for one batch) at step 120: 237.4860, Accuracy: 0.8224\n","Training loss (for one batch) at step 130: 229.1586, Accuracy: 0.8213\n","Training loss (for one batch) at step 140: 244.2133, Accuracy: 0.8206\n","---- Training ----\n","Training loss: 204.7354\n","Training acc over epoch: 0.8207\n","---- Validation ----\n","Validation loss: 79.3417\n","Validation acc: 0.7257\n","Time taken: 9.66s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 243.4793, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 221.5486, Accuracy: 0.8218\n","Training loss (for one batch) at step 20: 253.6415, Accuracy: 0.8233\n","Training loss (for one batch) at step 30: 231.9599, Accuracy: 0.8248\n","Training loss (for one batch) at step 40: 207.1977, Accuracy: 0.8305\n","Training loss (for one batch) at step 50: 214.8837, Accuracy: 0.8298\n","Training loss (for one batch) at step 60: 239.1277, Accuracy: 0.8307\n","Training loss (for one batch) at step 70: 248.6750, Accuracy: 0.8285\n","Training loss (for one batch) at step 80: 240.5683, Accuracy: 0.8248\n","Training loss (for one batch) at step 90: 225.7527, Accuracy: 0.8235\n","Training loss (for one batch) at step 100: 245.4013, Accuracy: 0.8238\n","Training loss (for one batch) at step 110: 233.3436, Accuracy: 0.8243\n","Training loss (for one batch) at step 120: 230.4212, Accuracy: 0.8243\n","Training loss (for one batch) at step 130: 227.9573, Accuracy: 0.8233\n","Training loss (for one batch) at step 140: 242.5258, Accuracy: 0.8229\n","---- Training ----\n","Training loss: 216.8658\n","Training acc over epoch: 0.8231\n","---- Validation ----\n","Validation loss: 75.4566\n","Validation acc: 0.7192\n","Time taken: 9.72s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 221.8445, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 222.3437, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 220.4845, Accuracy: 0.8348\n","Training loss (for one batch) at step 30: 238.6906, Accuracy: 0.8358\n","Training loss (for one batch) at step 40: 258.0576, Accuracy: 0.8280\n","Training loss (for one batch) at step 50: 225.7975, Accuracy: 0.8337\n","Training loss (for one batch) at step 60: 246.2317, Accuracy: 0.8330\n","Training loss (for one batch) at step 70: 244.0434, Accuracy: 0.8293\n","Training loss (for one batch) at step 80: 254.8855, Accuracy: 0.8232\n","Training loss (for one batch) at step 90: 241.2968, Accuracy: 0.8225\n","Training loss (for one batch) at step 100: 238.2186, Accuracy: 0.8239\n","Training loss (for one batch) at step 110: 223.0889, Accuracy: 0.8259\n","Training loss (for one batch) at step 120: 222.2832, Accuracy: 0.8269\n","Training loss (for one batch) at step 130: 238.4604, Accuracy: 0.8276\n","Training loss (for one batch) at step 140: 242.1246, Accuracy: 0.8261\n","---- Training ----\n","Training loss: 214.1253\n","Training acc over epoch: 0.8253\n","---- Validation ----\n","Validation loss: 82.1255\n","Validation acc: 0.6999\n","Time taken: 9.62s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 245.7877, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 251.5473, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 234.4623, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 251.3935, Accuracy: 0.8339\n","Training loss (for one batch) at step 40: 232.2193, Accuracy: 0.8305\n","Training loss (for one batch) at step 50: 245.5891, Accuracy: 0.8290\n","Training loss (for one batch) at step 60: 230.6762, Accuracy: 0.8277\n","Training loss (for one batch) at step 70: 230.6402, Accuracy: 0.8286\n","Training loss (for one batch) at step 80: 252.7310, Accuracy: 0.8231\n","Training loss (for one batch) at step 90: 239.7009, Accuracy: 0.8238\n","Training loss (for one batch) at step 100: 257.0600, Accuracy: 0.8249\n","Training loss (for one batch) at step 110: 224.5509, Accuracy: 0.8250\n","Training loss (for one batch) at step 120: 219.3115, Accuracy: 0.8255\n","Training loss (for one batch) at step 130: 246.0827, Accuracy: 0.8250\n","Training loss (for one batch) at step 140: 244.6807, Accuracy: 0.8252\n","---- Training ----\n","Training loss: 205.4613\n","Training acc over epoch: 0.8256\n","---- Validation ----\n","Validation loss: 73.4359\n","Validation acc: 0.7187\n","Time taken: 9.66s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 221.5797, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 220.3046, Accuracy: 0.8409\n","Training loss (for one batch) at step 20: 223.0735, Accuracy: 0.8367\n","Training loss (for one batch) at step 30: 251.4079, Accuracy: 0.8339\n","Training loss (for one batch) at step 40: 251.2548, Accuracy: 0.8312\n","Training loss (for one batch) at step 50: 213.2662, Accuracy: 0.8312\n","Training loss (for one batch) at step 60: 233.8888, Accuracy: 0.8331\n","Training loss (for one batch) at step 70: 221.2214, Accuracy: 0.8314\n","Training loss (for one batch) at step 80: 229.7410, Accuracy: 0.8326\n","Training loss (for one batch) at step 90: 241.9162, Accuracy: 0.8295\n","Training loss (for one batch) at step 100: 235.4572, Accuracy: 0.8270\n","Training loss (for one batch) at step 110: 219.1344, Accuracy: 0.8276\n","Training loss (for one batch) at step 120: 253.9667, Accuracy: 0.8270\n","Training loss (for one batch) at step 130: 234.9843, Accuracy: 0.8279\n","Training loss (for one batch) at step 140: 233.1530, Accuracy: 0.8272\n","---- Training ----\n","Training loss: 186.5515\n","Training acc over epoch: 0.8283\n","---- Validation ----\n","Validation loss: 70.8898\n","Validation acc: 0.7230\n","Time taken: 9.64s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 230.5655, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 228.4539, Accuracy: 0.8255\n","Training loss (for one batch) at step 20: 223.5389, Accuracy: 0.8276\n","Training loss (for one batch) at step 30: 246.8777, Accuracy: 0.8258\n","Training loss (for one batch) at step 40: 224.5993, Accuracy: 0.8271\n","Training loss (for one batch) at step 50: 237.3859, Accuracy: 0.8251\n","Training loss (for one batch) at step 60: 222.6429, Accuracy: 0.8272\n","Training loss (for one batch) at step 70: 256.9885, Accuracy: 0.8293\n","Training loss (for one batch) at step 80: 237.2760, Accuracy: 0.8290\n","Training loss (for one batch) at step 90: 218.2788, Accuracy: 0.8271\n","Training loss (for one batch) at step 100: 233.9613, Accuracy: 0.8266\n","Training loss (for one batch) at step 110: 234.8932, Accuracy: 0.8267\n","Training loss (for one batch) at step 120: 257.3732, Accuracy: 0.8272\n","Training loss (for one batch) at step 130: 231.0124, Accuracy: 0.8281\n","Training loss (for one batch) at step 140: 215.6970, Accuracy: 0.8285\n","---- Training ----\n","Training loss: 211.6871\n","Training acc over epoch: 0.8278\n","---- Validation ----\n","Validation loss: 64.1217\n","Validation acc: 0.7270\n","Time taken: 9.68s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 235.8291, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 217.0844, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 220.5391, Accuracy: 0.8214\n","Training loss (for one batch) at step 30: 241.3681, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 235.0116, Accuracy: 0.8295\n","Training loss (for one batch) at step 50: 221.6135, Accuracy: 0.8324\n","Training loss (for one batch) at step 60: 224.8287, Accuracy: 0.8338\n","Training loss (for one batch) at step 70: 231.2912, Accuracy: 0.8339\n","Training loss (for one batch) at step 80: 238.2023, Accuracy: 0.8336\n","Training loss (for one batch) at step 90: 230.9406, Accuracy: 0.8333\n","Training loss (for one batch) at step 100: 238.8361, Accuracy: 0.8314\n","Training loss (for one batch) at step 110: 227.7415, Accuracy: 0.8321\n","Training loss (for one batch) at step 120: 219.0829, Accuracy: 0.8321\n","Training loss (for one batch) at step 130: 240.2886, Accuracy: 0.8317\n","Training loss (for one batch) at step 140: 221.3950, Accuracy: 0.8312\n","---- Training ----\n","Training loss: 238.3351\n","Training acc over epoch: 0.8317\n","---- Validation ----\n","Validation loss: 74.4597\n","Validation acc: 0.7246\n","Time taken: 9.85s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 228.1576, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 249.1261, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 236.6384, Accuracy: 0.8429\n","Training loss (for one batch) at step 30: 229.5894, Accuracy: 0.8361\n","Training loss (for one batch) at step 40: 210.6247, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 231.1001, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 234.4710, Accuracy: 0.8372\n","Training loss (for one batch) at step 70: 232.0543, Accuracy: 0.8368\n","Training loss (for one batch) at step 80: 227.9816, Accuracy: 0.8343\n","Training loss (for one batch) at step 90: 226.7880, Accuracy: 0.8342\n","Training loss (for one batch) at step 100: 227.3566, Accuracy: 0.8326\n","Training loss (for one batch) at step 110: 208.4181, Accuracy: 0.8329\n","Training loss (for one batch) at step 120: 212.9235, Accuracy: 0.8324\n","Training loss (for one batch) at step 130: 205.4568, Accuracy: 0.8335\n","Training loss (for one batch) at step 140: 227.6502, Accuracy: 0.8326\n","---- Training ----\n","Training loss: 213.4187\n","Training acc over epoch: 0.8328\n","---- Validation ----\n","Validation loss: 66.7370\n","Validation acc: 0.7431\n","Time taken: 9.71s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 235.6631, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 217.1687, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 221.8289, Accuracy: 0.8395\n","Training loss (for one batch) at step 30: 205.1404, Accuracy: 0.8365\n","Training loss (for one batch) at step 40: 251.9555, Accuracy: 0.8341\n","Training loss (for one batch) at step 50: 214.9336, Accuracy: 0.8345\n","Training loss (for one batch) at step 60: 250.1083, Accuracy: 0.8341\n","Training loss (for one batch) at step 70: 226.0323, Accuracy: 0.8355\n","Training loss (for one batch) at step 80: 225.0692, Accuracy: 0.8343\n","Training loss (for one batch) at step 90: 225.8282, Accuracy: 0.8341\n","Training loss (for one batch) at step 100: 205.4911, Accuracy: 0.8343\n","Training loss (for one batch) at step 110: 232.2691, Accuracy: 0.8321\n","Training loss (for one batch) at step 120: 208.5832, Accuracy: 0.8331\n","Training loss (for one batch) at step 130: 234.7570, Accuracy: 0.8327\n","Training loss (for one batch) at step 140: 225.3054, Accuracy: 0.8325\n","---- Training ----\n","Training loss: 203.7946\n","Training acc over epoch: 0.8315\n","---- Validation ----\n","Validation loss: 61.7093\n","Validation acc: 0.7117\n","Time taken: 9.72s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 227.1759, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 225.6120, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 214.3392, Accuracy: 0.8505\n","Training loss (for one batch) at step 30: 229.3203, Accuracy: 0.8416\n","Training loss (for one batch) at step 40: 236.5725, Accuracy: 0.8390\n","Training loss (for one batch) at step 50: 245.8931, Accuracy: 0.8347\n","Training loss (for one batch) at step 60: 227.8434, Accuracy: 0.8369\n","Training loss (for one batch) at step 70: 218.0571, Accuracy: 0.8368\n","Training loss (for one batch) at step 80: 222.8676, Accuracy: 0.8358\n","Training loss (for one batch) at step 90: 217.1672, Accuracy: 0.8352\n","Training loss (for one batch) at step 100: 228.2846, Accuracy: 0.8347\n","Training loss (for one batch) at step 110: 238.8609, Accuracy: 0.8337\n","Training loss (for one batch) at step 120: 242.9356, Accuracy: 0.8336\n","Training loss (for one batch) at step 130: 230.2004, Accuracy: 0.8335\n","Training loss (for one batch) at step 140: 218.6718, Accuracy: 0.8335\n","---- Training ----\n","Training loss: 193.5549\n","Training acc over epoch: 0.8344\n","---- Validation ----\n","Validation loss: 82.2726\n","Validation acc: 0.7217\n","Time taken: 9.61s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 229.0703, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 209.6482, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 209.3494, Accuracy: 0.8410\n","Training loss (for one batch) at step 30: 211.9675, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 200.8029, Accuracy: 0.8327\n","Training loss (for one batch) at step 50: 221.1208, Accuracy: 0.8365\n","Training loss (for one batch) at step 60: 219.1071, Accuracy: 0.8359\n","Training loss (for one batch) at step 70: 230.7221, Accuracy: 0.8361\n","Training loss (for one batch) at step 80: 201.8453, Accuracy: 0.8326\n","Training loss (for one batch) at step 90: 253.3650, Accuracy: 0.8327\n","Training loss (for one batch) at step 100: 224.3152, Accuracy: 0.8302\n","Training loss (for one batch) at step 110: 209.1953, Accuracy: 0.8341\n","Training loss (for one batch) at step 120: 208.0019, Accuracy: 0.8356\n","Training loss (for one batch) at step 130: 210.9671, Accuracy: 0.8347\n","Training loss (for one batch) at step 140: 240.9425, Accuracy: 0.8337\n","---- Training ----\n","Training loss: 197.7304\n","Training acc over epoch: 0.8338\n","---- Validation ----\n","Validation loss: 79.7555\n","Validation acc: 0.7254\n","Time taken: 9.85s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 231.7005, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 220.3152, Accuracy: 0.8255\n","Training loss (for one batch) at step 20: 250.5873, Accuracy: 0.8324\n","Training loss (for one batch) at step 30: 237.3512, Accuracy: 0.8381\n","Training loss (for one batch) at step 40: 225.3004, Accuracy: 0.8349\n","Training loss (for one batch) at step 50: 200.6082, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 223.2891, Accuracy: 0.8379\n","Training loss (for one batch) at step 70: 218.2725, Accuracy: 0.8380\n","Training loss (for one batch) at step 80: 220.1813, Accuracy: 0.8365\n","Training loss (for one batch) at step 90: 218.5956, Accuracy: 0.8344\n","Training loss (for one batch) at step 100: 189.7435, Accuracy: 0.8350\n","Training loss (for one batch) at step 110: 216.9005, Accuracy: 0.8356\n","Training loss (for one batch) at step 120: 223.4956, Accuracy: 0.8356\n","Training loss (for one batch) at step 130: 221.0033, Accuracy: 0.8354\n","Training loss (for one batch) at step 140: 222.2518, Accuracy: 0.8349\n","---- Training ----\n","Training loss: 226.3260\n","Training acc over epoch: 0.8354\n","---- Validation ----\n","Validation loss: 88.8410\n","Validation acc: 0.7337\n","Time taken: 9.73s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 245.9584, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 214.5247, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 220.8776, Accuracy: 0.8519\n","Training loss (for one batch) at step 30: 225.4285, Accuracy: 0.8432\n","Training loss (for one batch) at step 40: 205.5178, Accuracy: 0.8410\n","Training loss (for one batch) at step 50: 241.3149, Accuracy: 0.8367\n","Training loss (for one batch) at step 60: 233.4262, Accuracy: 0.8341\n","Training loss (for one batch) at step 70: 237.3621, Accuracy: 0.8352\n","Training loss (for one batch) at step 80: 222.0146, Accuracy: 0.8348\n","Training loss (for one batch) at step 90: 196.2911, Accuracy: 0.8344\n","Training loss (for one batch) at step 100: 223.3646, Accuracy: 0.8341\n","Training loss (for one batch) at step 110: 218.4725, Accuracy: 0.8359\n","Training loss (for one batch) at step 120: 211.5805, Accuracy: 0.8355\n","Training loss (for one batch) at step 130: 218.0740, Accuracy: 0.8349\n","Training loss (for one batch) at step 140: 250.1609, Accuracy: 0.8355\n","---- Training ----\n","Training loss: 221.4849\n","Training acc over epoch: 0.8342\n","---- Validation ----\n","Validation loss: 59.8087\n","Validation acc: 0.7176\n","Time taken: 10.84s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 234.6368, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 222.8586, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 219.1319, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 215.1850, Accuracy: 0.8326\n","Training loss (for one batch) at step 40: 217.9309, Accuracy: 0.8288\n","Training loss (for one batch) at step 50: 225.7124, Accuracy: 0.8327\n","Training loss (for one batch) at step 60: 204.6205, Accuracy: 0.8323\n","Training loss (for one batch) at step 70: 220.7912, Accuracy: 0.8365\n","Training loss (for one batch) at step 80: 221.8643, Accuracy: 0.8343\n","Training loss (for one batch) at step 90: 224.5237, Accuracy: 0.8307\n","Training loss (for one batch) at step 100: 226.0696, Accuracy: 0.8305\n","Training loss (for one batch) at step 110: 235.6399, Accuracy: 0.8332\n","Training loss (for one batch) at step 120: 224.4239, Accuracy: 0.8343\n","Training loss (for one batch) at step 130: 204.9830, Accuracy: 0.8332\n","Training loss (for one batch) at step 140: 211.7293, Accuracy: 0.8326\n","---- Training ----\n","Training loss: 191.7543\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 73.6476\n","Validation acc: 0.7144\n","Time taken: 37.80s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 205.5048, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 196.5634, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 198.9703, Accuracy: 0.8529\n","Training loss (for one batch) at step 30: 231.6635, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 212.1942, Accuracy: 0.8432\n","Training loss (for one batch) at step 50: 208.6806, Accuracy: 0.8424\n","Training loss (for one batch) at step 60: 213.0854, Accuracy: 0.8398\n","Training loss (for one batch) at step 70: 221.3107, Accuracy: 0.8404\n","Training loss (for one batch) at step 80: 200.4414, Accuracy: 0.8377\n","Training loss (for one batch) at step 90: 218.0146, Accuracy: 0.8366\n","Training loss (for one batch) at step 100: 218.5812, Accuracy: 0.8336\n","Training loss (for one batch) at step 110: 204.9092, Accuracy: 0.8342\n","Training loss (for one batch) at step 120: 220.5576, Accuracy: 0.8365\n","Training loss (for one batch) at step 130: 226.0870, Accuracy: 0.8372\n","Training loss (for one batch) at step 140: 213.5914, Accuracy: 0.8367\n","---- Training ----\n","Training loss: 192.1311\n","Training acc over epoch: 0.8364\n","---- Validation ----\n","Validation loss: 64.4159\n","Validation acc: 0.7050\n","Time taken: 27.54s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 225.0666, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 226.6065, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 213.0689, Accuracy: 0.8500\n","Training loss (for one batch) at step 30: 211.0777, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 207.4052, Accuracy: 0.8395\n","Training loss (for one batch) at step 50: 216.7556, Accuracy: 0.8416\n","Training loss (for one batch) at step 60: 224.7980, Accuracy: 0.8420\n","Training loss (for one batch) at step 70: 218.4248, Accuracy: 0.8417\n","Training loss (for one batch) at step 80: 198.1591, Accuracy: 0.8402\n","Training loss (for one batch) at step 90: 194.4312, Accuracy: 0.8392\n","Training loss (for one batch) at step 100: 208.9404, Accuracy: 0.8382\n","Training loss (for one batch) at step 110: 210.3226, Accuracy: 0.8385\n","Training loss (for one batch) at step 120: 207.2401, Accuracy: 0.8390\n","Training loss (for one batch) at step 130: 230.1906, Accuracy: 0.8393\n","Training loss (for one batch) at step 140: 226.3477, Accuracy: 0.8390\n","---- Training ----\n","Training loss: 204.0618\n","Training acc over epoch: 0.8386\n","---- Validation ----\n","Validation loss: 77.6111\n","Validation acc: 0.7208\n","Time taken: 47.16s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 206.1227, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 213.5980, Accuracy: 0.8655\n","Training loss (for one batch) at step 20: 219.3814, Accuracy: 0.8500\n","Training loss (for one batch) at step 30: 226.3470, Accuracy: 0.8484\n","Training loss (for one batch) at step 40: 213.7528, Accuracy: 0.8461\n","Training loss (for one batch) at step 50: 230.4827, Accuracy: 0.8455\n","Training loss (for one batch) at step 60: 208.9998, Accuracy: 0.8452\n","Training loss (for one batch) at step 70: 210.9646, Accuracy: 0.8434\n","Training loss (for one batch) at step 80: 201.8616, Accuracy: 0.8407\n","Training loss (for one batch) at step 90: 215.1056, Accuracy: 0.8395\n","Training loss (for one batch) at step 100: 203.1664, Accuracy: 0.8383\n","Training loss (for one batch) at step 110: 217.6331, Accuracy: 0.8389\n","Training loss (for one batch) at step 120: 210.8622, Accuracy: 0.8412\n","Training loss (for one batch) at step 130: 230.0669, Accuracy: 0.8401\n","Training loss (for one batch) at step 140: 209.8494, Accuracy: 0.8391\n","---- Training ----\n","Training loss: 181.0373\n","Training acc over epoch: 0.8381\n","---- Validation ----\n","Validation loss: 73.2525\n","Validation acc: 0.7372\n","Time taken: 58.57s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 210.6026, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 208.4711, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 214.3111, Accuracy: 0.8457\n","Training loss (for one batch) at step 30: 190.4108, Accuracy: 0.8439\n","Training loss (for one batch) at step 40: 201.4418, Accuracy: 0.8478\n","Training loss (for one batch) at step 50: 215.3839, Accuracy: 0.8492\n","Training loss (for one batch) at step 60: 216.9619, Accuracy: 0.8459\n","Training loss (for one batch) at step 70: 233.3026, Accuracy: 0.8435\n","Training loss (for one batch) at step 80: 203.4663, Accuracy: 0.8406\n","Training loss (for one batch) at step 90: 226.1748, Accuracy: 0.8364\n","Training loss (for one batch) at step 100: 202.3186, Accuracy: 0.8377\n","Training loss (for one batch) at step 110: 197.4052, Accuracy: 0.8377\n","Training loss (for one batch) at step 120: 223.3317, Accuracy: 0.8383\n","Training loss (for one batch) at step 130: 203.5482, Accuracy: 0.8391\n","Training loss (for one batch) at step 140: 195.9352, Accuracy: 0.8379\n","---- Training ----\n","Training loss: 183.5624\n","Training acc over epoch: 0.8376\n","---- Validation ----\n","Validation loss: 86.0679\n","Validation acc: 0.7112\n","Time taken: 54.37s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 209.6245, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 208.5541, Accuracy: 0.8536\n","Training loss (for one batch) at step 20: 214.9684, Accuracy: 0.8490\n","Training loss (for one batch) at step 30: 173.7951, Accuracy: 0.8490\n","Training loss (for one batch) at step 40: 208.8239, Accuracy: 0.8461\n","Training loss (for one batch) at step 50: 199.5753, Accuracy: 0.8473\n","Training loss (for one batch) at step 60: 219.0894, Accuracy: 0.8451\n","Training loss (for one batch) at step 70: 195.6334, Accuracy: 0.8452\n","Training loss (for one batch) at step 80: 208.3654, Accuracy: 0.8440\n","Training loss (for one batch) at step 90: 209.5982, Accuracy: 0.8393\n","Training loss (for one batch) at step 100: 206.4957, Accuracy: 0.8388\n","Training loss (for one batch) at step 110: 203.7782, Accuracy: 0.8395\n","Training loss (for one batch) at step 120: 194.6681, Accuracy: 0.8409\n","Training loss (for one batch) at step 130: 209.0646, Accuracy: 0.8398\n","Training loss (for one batch) at step 140: 206.8936, Accuracy: 0.8407\n","---- Training ----\n","Training loss: 174.5995\n","Training acc over epoch: 0.8403\n","---- Validation ----\n","Validation loss: 74.0856\n","Validation acc: 0.7203\n","Time taken: 58.37s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 260.8928, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 220.3501, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 208.4715, Accuracy: 0.8371\n","Training loss (for one batch) at step 30: 223.8263, Accuracy: 0.8339\n","Training loss (for one batch) at step 40: 205.8217, Accuracy: 0.8395\n","Training loss (for one batch) at step 50: 196.7227, Accuracy: 0.8449\n","Training loss (for one batch) at step 60: 197.4910, Accuracy: 0.8456\n","Training loss (for one batch) at step 70: 220.4878, Accuracy: 0.8456\n","Training loss (for one batch) at step 80: 217.5789, Accuracy: 0.8412\n","Training loss (for one batch) at step 90: 196.2101, Accuracy: 0.8411\n","Training loss (for one batch) at step 100: 215.7686, Accuracy: 0.8405\n","Training loss (for one batch) at step 110: 194.1468, Accuracy: 0.8402\n","Training loss (for one batch) at step 120: 213.4978, Accuracy: 0.8419\n","Training loss (for one batch) at step 130: 234.0367, Accuracy: 0.8412\n","Training loss (for one batch) at step 140: 221.6641, Accuracy: 0.8396\n","---- Training ----\n","Training loss: 175.4996\n","Training acc over epoch: 0.8393\n","---- Validation ----\n","Validation loss: 81.1796\n","Validation acc: 0.7176\n","Time taken: 67.53s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7347\n","Validation AUC: 0.7317\n","Validation Balanced_ACC: 0.4720\n","Validation MI: 0.1369\n","Validation Normalized MI: 0.2060\n","Validation Adjusted MI: 0.2060\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 477.0761, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 506.3525, Accuracy: 0.5173\n","Training loss (for one batch) at step 20: 487.0284, Accuracy: 0.5467\n","Training loss (for one batch) at step 30: 473.9713, Accuracy: 0.5361\n","Training loss (for one batch) at step 40: 449.3256, Accuracy: 0.5402\n","Training loss (for one batch) at step 50: 453.2224, Accuracy: 0.5414\n","Training loss (for one batch) at step 60: 443.9537, Accuracy: 0.5470\n","Training loss (for one batch) at step 70: 440.9017, Accuracy: 0.5532\n","Training loss (for one batch) at step 80: 439.6539, Accuracy: 0.5572\n","Training loss (for one batch) at step 90: 437.2178, Accuracy: 0.5582\n","Training loss (for one batch) at step 100: 482.1266, Accuracy: 0.5590\n","Training loss (for one batch) at step 110: 388.1071, Accuracy: 0.5580\n","Training loss (for one batch) at step 120: 416.1155, Accuracy: 0.5612\n","Training loss (for one batch) at step 130: 391.4337, Accuracy: 0.5630\n","Training loss (for one batch) at step 140: 461.9823, Accuracy: 0.5641\n","---- Training ----\n","Training loss: 377.0351\n","Training acc over epoch: 0.5653\n","---- Validation ----\n","Validation loss: 88.4529\n","Validation acc: 0.5134\n","Time taken: 78.99s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 431.1139, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 390.4585, Accuracy: 0.6227\n","Training loss (for one batch) at step 20: 379.4101, Accuracy: 0.6186\n","Training loss (for one batch) at step 30: 368.2219, Accuracy: 0.6268\n","Training loss (for one batch) at step 40: 390.5162, Accuracy: 0.6263\n","Training loss (for one batch) at step 50: 438.1699, Accuracy: 0.6149\n","Training loss (for one batch) at step 60: 385.5904, Accuracy: 0.6134\n","Training loss (for one batch) at step 70: 375.5879, Accuracy: 0.6201\n","Training loss (for one batch) at step 80: 416.7607, Accuracy: 0.6221\n","Training loss (for one batch) at step 90: 435.0162, Accuracy: 0.6191\n","Training loss (for one batch) at step 100: 413.9739, Accuracy: 0.6168\n","Training loss (for one batch) at step 110: 414.1771, Accuracy: 0.6179\n","Training loss (for one batch) at step 120: 360.6974, Accuracy: 0.6182\n","Training loss (for one batch) at step 130: 346.9713, Accuracy: 0.6178\n","Training loss (for one batch) at step 140: 374.7474, Accuracy: 0.6177\n","---- Training ----\n","Training loss: 362.3697\n","Training acc over epoch: 0.6175\n","---- Validation ----\n","Validation loss: 96.6653\n","Validation acc: 0.5159\n","Time taken: 45.85s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 369.3871, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 348.8453, Accuracy: 0.6236\n","Training loss (for one batch) at step 20: 371.2778, Accuracy: 0.6200\n","Training loss (for one batch) at step 30: 376.3615, Accuracy: 0.6132\n","Training loss (for one batch) at step 40: 372.2180, Accuracy: 0.6176\n","Training loss (for one batch) at step 50: 377.8003, Accuracy: 0.6220\n","Training loss (for one batch) at step 60: 396.0214, Accuracy: 0.6220\n","Training loss (for one batch) at step 70: 356.2463, Accuracy: 0.6207\n","Training loss (for one batch) at step 80: 383.8399, Accuracy: 0.6209\n","Training loss (for one batch) at step 90: 358.0132, Accuracy: 0.6237\n","Training loss (for one batch) at step 100: 345.5828, Accuracy: 0.6249\n","Training loss (for one batch) at step 110: 355.9901, Accuracy: 0.6259\n","Training loss (for one batch) at step 120: 380.2032, Accuracy: 0.6260\n","Training loss (for one batch) at step 130: 379.6596, Accuracy: 0.6250\n","Training loss (for one batch) at step 140: 359.1539, Accuracy: 0.6276\n","---- Training ----\n","Training loss: 319.8428\n","Training acc over epoch: 0.6280\n","---- Validation ----\n","Validation loss: 79.5554\n","Validation acc: 0.6805\n","Time taken: 71.67s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 346.6176, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 318.9057, Accuracy: 0.6455\n","Training loss (for one batch) at step 20: 357.4222, Accuracy: 0.6595\n","Training loss (for one batch) at step 30: 357.3973, Accuracy: 0.6623\n","Training loss (for one batch) at step 40: 363.3098, Accuracy: 0.6593\n","Training loss (for one batch) at step 50: 351.2932, Accuracy: 0.6553\n","Training loss (for one batch) at step 60: 338.0543, Accuracy: 0.6562\n","Training loss (for one batch) at step 70: 353.3246, Accuracy: 0.6572\n","Training loss (for one batch) at step 80: 373.9052, Accuracy: 0.6546\n","Training loss (for one batch) at step 90: 336.9559, Accuracy: 0.6546\n","Training loss (for one batch) at step 100: 358.1488, Accuracy: 0.6570\n","Training loss (for one batch) at step 110: 323.4912, Accuracy: 0.6573\n","Training loss (for one batch) at step 120: 332.7888, Accuracy: 0.6579\n","Training loss (for one batch) at step 130: 355.5302, Accuracy: 0.6588\n","Training loss (for one batch) at step 140: 348.7294, Accuracy: 0.6588\n","---- Training ----\n","Training loss: 319.9769\n","Training acc over epoch: 0.6603\n","---- Validation ----\n","Validation loss: 69.6073\n","Validation acc: 0.6918\n","Time taken: 73.00s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 333.3240, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 353.1679, Accuracy: 0.6591\n","Training loss (for one batch) at step 20: 356.3085, Accuracy: 0.6729\n","Training loss (for one batch) at step 30: 333.8976, Accuracy: 0.6700\n","Training loss (for one batch) at step 40: 348.7708, Accuracy: 0.6729\n","Training loss (for one batch) at step 50: 342.1309, Accuracy: 0.6675\n","Training loss (for one batch) at step 60: 340.6046, Accuracy: 0.6707\n","Training loss (for one batch) at step 70: 329.9415, Accuracy: 0.6708\n","Training loss (for one batch) at step 80: 367.1631, Accuracy: 0.6709\n","Training loss (for one batch) at step 90: 350.3102, Accuracy: 0.6704\n","Training loss (for one batch) at step 100: 361.4557, Accuracy: 0.6707\n","Training loss (for one batch) at step 110: 336.0394, Accuracy: 0.6724\n","Training loss (for one batch) at step 120: 353.7081, Accuracy: 0.6727\n","Training loss (for one batch) at step 130: 336.3063, Accuracy: 0.6727\n","Training loss (for one batch) at step 140: 361.5566, Accuracy: 0.6723\n","---- Training ----\n","Training loss: 324.8485\n","Training acc over epoch: 0.6730\n","---- Validation ----\n","Validation loss: 67.7408\n","Validation acc: 0.6948\n","Time taken: 78.07s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 329.1314, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 324.5102, Accuracy: 0.7018\n","Training loss (for one batch) at step 20: 337.5657, Accuracy: 0.6776\n","Training loss (for one batch) at step 30: 339.0176, Accuracy: 0.6735\n","Training loss (for one batch) at step 40: 323.7498, Accuracy: 0.6776\n","Training loss (for one batch) at step 50: 361.2840, Accuracy: 0.6794\n","Training loss (for one batch) at step 60: 341.9503, Accuracy: 0.6787\n","Training loss (for one batch) at step 70: 338.1142, Accuracy: 0.6813\n","Training loss (for one batch) at step 80: 346.2183, Accuracy: 0.6805\n","Training loss (for one batch) at step 90: 343.6707, Accuracy: 0.6807\n","Training loss (for one batch) at step 100: 327.8909, Accuracy: 0.6803\n","Training loss (for one batch) at step 110: 331.8201, Accuracy: 0.6832\n","Training loss (for one batch) at step 120: 338.4310, Accuracy: 0.6834\n","Training loss (for one batch) at step 130: 368.5698, Accuracy: 0.6827\n","Training loss (for one batch) at step 140: 305.1967, Accuracy: 0.6835\n","---- Training ----\n","Training loss: 288.6107\n","Training acc over epoch: 0.6836\n","---- Validation ----\n","Validation loss: 76.0657\n","Validation acc: 0.7166\n","Time taken: 70.55s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 319.5759, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 329.9948, Accuracy: 0.7109\n","Training loss (for one batch) at step 20: 329.5133, Accuracy: 0.6924\n","Training loss (for one batch) at step 30: 331.6005, Accuracy: 0.6894\n","Training loss (for one batch) at step 40: 318.9853, Accuracy: 0.6954\n","Training loss (for one batch) at step 50: 321.8914, Accuracy: 0.6945\n","Training loss (for one batch) at step 60: 338.3821, Accuracy: 0.6959\n","Training loss (for one batch) at step 70: 317.7752, Accuracy: 0.6972\n","Training loss (for one batch) at step 80: 342.1400, Accuracy: 0.6958\n","Training loss (for one batch) at step 90: 340.7303, Accuracy: 0.6954\n","Training loss (for one batch) at step 100: 336.8146, Accuracy: 0.6950\n","Training loss (for one batch) at step 110: 321.6323, Accuracy: 0.6979\n","Training loss (for one batch) at step 120: 304.7300, Accuracy: 0.6983\n","Training loss (for one batch) at step 130: 342.8239, Accuracy: 0.6998\n","Training loss (for one batch) at step 140: 320.0072, Accuracy: 0.6994\n","---- Training ----\n","Training loss: 312.5418\n","Training acc over epoch: 0.6992\n","---- Validation ----\n","Validation loss: 58.7544\n","Validation acc: 0.7114\n","Time taken: 70.45s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 329.4692, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 305.2718, Accuracy: 0.7145\n","Training loss (for one batch) at step 20: 310.0836, Accuracy: 0.7162\n","Training loss (for one batch) at step 30: 310.2146, Accuracy: 0.7132\n","Training loss (for one batch) at step 40: 339.4410, Accuracy: 0.7144\n","Training loss (for one batch) at step 50: 322.8439, Accuracy: 0.7155\n","Training loss (for one batch) at step 60: 327.6257, Accuracy: 0.7159\n","Training loss (for one batch) at step 70: 326.0757, Accuracy: 0.7141\n","Training loss (for one batch) at step 80: 301.7908, Accuracy: 0.7160\n","Training loss (for one batch) at step 90: 327.6942, Accuracy: 0.7148\n","Training loss (for one batch) at step 100: 327.3819, Accuracy: 0.7121\n","Training loss (for one batch) at step 110: 322.7970, Accuracy: 0.7100\n","Training loss (for one batch) at step 120: 338.4547, Accuracy: 0.7088\n","Training loss (for one batch) at step 130: 323.2469, Accuracy: 0.7105\n","Training loss (for one batch) at step 140: 326.9814, Accuracy: 0.7111\n","---- Training ----\n","Training loss: 276.5793\n","Training acc over epoch: 0.7125\n","---- Validation ----\n","Validation loss: 69.2640\n","Validation acc: 0.7133\n","Time taken: 70.15s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 321.8163, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 300.6227, Accuracy: 0.7236\n","Training loss (for one batch) at step 20: 312.6914, Accuracy: 0.7238\n","Training loss (for one batch) at step 30: 305.3797, Accuracy: 0.7281\n","Training loss (for one batch) at step 40: 338.6927, Accuracy: 0.7288\n","Training loss (for one batch) at step 50: 318.9518, Accuracy: 0.7275\n","Training loss (for one batch) at step 60: 309.6754, Accuracy: 0.7279\n","Training loss (for one batch) at step 70: 321.4627, Accuracy: 0.7280\n","Training loss (for one batch) at step 80: 324.2091, Accuracy: 0.7243\n","Training loss (for one batch) at step 90: 324.1690, Accuracy: 0.7235\n","Training loss (for one batch) at step 100: 313.1984, Accuracy: 0.7241\n","Training loss (for one batch) at step 110: 315.1064, Accuracy: 0.7255\n","Training loss (for one batch) at step 120: 327.5662, Accuracy: 0.7242\n","Training loss (for one batch) at step 130: 322.2669, Accuracy: 0.7247\n","Training loss (for one batch) at step 140: 316.4581, Accuracy: 0.7238\n","---- Training ----\n","Training loss: 302.3919\n","Training acc over epoch: 0.7228\n","---- Validation ----\n","Validation loss: 74.7830\n","Validation acc: 0.7289\n","Time taken: 71.17s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 318.1205, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 304.6411, Accuracy: 0.7436\n","Training loss (for one batch) at step 20: 321.0192, Accuracy: 0.7395\n","Training loss (for one batch) at step 30: 314.7537, Accuracy: 0.7323\n","Training loss (for one batch) at step 40: 301.5908, Accuracy: 0.7376\n","Training loss (for one batch) at step 50: 292.7885, Accuracy: 0.7384\n","Training loss (for one batch) at step 60: 319.1453, Accuracy: 0.7367\n","Training loss (for one batch) at step 70: 318.5576, Accuracy: 0.7375\n","Training loss (for one batch) at step 80: 307.1663, Accuracy: 0.7383\n","Training loss (for one batch) at step 90: 321.4703, Accuracy: 0.7368\n","Training loss (for one batch) at step 100: 302.1159, Accuracy: 0.7360\n","Training loss (for one batch) at step 110: 296.5016, Accuracy: 0.7360\n","Training loss (for one batch) at step 120: 301.4724, Accuracy: 0.7358\n","Training loss (for one batch) at step 130: 316.4069, Accuracy: 0.7363\n","Training loss (for one batch) at step 140: 307.5577, Accuracy: 0.7367\n","---- Training ----\n","Training loss: 262.2545\n","Training acc over epoch: 0.7368\n","---- Validation ----\n","Validation loss: 64.4143\n","Validation acc: 0.7354\n","Time taken: 73.14s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 310.5503, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 315.2387, Accuracy: 0.7618\n","Training loss (for one batch) at step 20: 313.4825, Accuracy: 0.7514\n","Training loss (for one batch) at step 30: 324.0898, Accuracy: 0.7468\n","Training loss (for one batch) at step 40: 291.5130, Accuracy: 0.7456\n","Training loss (for one batch) at step 50: 301.7930, Accuracy: 0.7471\n","Training loss (for one batch) at step 60: 310.0688, Accuracy: 0.7489\n","Training loss (for one batch) at step 70: 311.5931, Accuracy: 0.7499\n","Training loss (for one batch) at step 80: 322.8652, Accuracy: 0.7473\n","Training loss (for one batch) at step 90: 304.8158, Accuracy: 0.7452\n","Training loss (for one batch) at step 100: 320.9379, Accuracy: 0.7467\n","Training loss (for one batch) at step 110: 326.8735, Accuracy: 0.7468\n","Training loss (for one batch) at step 120: 304.0641, Accuracy: 0.7450\n","Training loss (for one batch) at step 130: 296.5829, Accuracy: 0.7463\n","Training loss (for one batch) at step 140: 303.5922, Accuracy: 0.7461\n","---- Training ----\n","Training loss: 269.7529\n","Training acc over epoch: 0.7473\n","---- Validation ----\n","Validation loss: 77.9043\n","Validation acc: 0.7190\n","Time taken: 72.22s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 295.2991, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 293.8992, Accuracy: 0.7527\n","Training loss (for one batch) at step 20: 305.0990, Accuracy: 0.7567\n","Training loss (for one batch) at step 30: 300.0253, Accuracy: 0.7623\n","Training loss (for one batch) at step 40: 286.5787, Accuracy: 0.7593\n","Training loss (for one batch) at step 50: 288.1582, Accuracy: 0.7614\n","Training loss (for one batch) at step 60: 325.2810, Accuracy: 0.7566\n","Training loss (for one batch) at step 70: 299.6144, Accuracy: 0.7565\n","Training loss (for one batch) at step 80: 314.4632, Accuracy: 0.7547\n","Training loss (for one batch) at step 90: 310.3198, Accuracy: 0.7541\n","Training loss (for one batch) at step 100: 286.0563, Accuracy: 0.7550\n","Training loss (for one batch) at step 110: 294.9359, Accuracy: 0.7559\n","Training loss (for one batch) at step 120: 303.7158, Accuracy: 0.7561\n","Training loss (for one batch) at step 130: 281.8908, Accuracy: 0.7563\n","Training loss (for one batch) at step 140: 302.1575, Accuracy: 0.7560\n","---- Training ----\n","Training loss: 260.9597\n","Training acc over epoch: 0.7567\n","---- Validation ----\n","Validation loss: 67.5639\n","Validation acc: 0.7270\n","Time taken: 73.93s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 300.1952, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 292.8661, Accuracy: 0.7609\n","Training loss (for one batch) at step 20: 304.6650, Accuracy: 0.7724\n","Training loss (for one batch) at step 30: 304.8558, Accuracy: 0.7674\n","Training loss (for one batch) at step 40: 298.7232, Accuracy: 0.7629\n","Training loss (for one batch) at step 50: 293.0960, Accuracy: 0.7665\n","Training loss (for one batch) at step 60: 291.0663, Accuracy: 0.7690\n","Training loss (for one batch) at step 70: 309.3863, Accuracy: 0.7655\n","Training loss (for one batch) at step 80: 305.5840, Accuracy: 0.7659\n","Training loss (for one batch) at step 90: 305.5389, Accuracy: 0.7657\n","Training loss (for one batch) at step 100: 310.2633, Accuracy: 0.7636\n","Training loss (for one batch) at step 110: 295.7637, Accuracy: 0.7650\n","Training loss (for one batch) at step 120: 311.0784, Accuracy: 0.7642\n","Training loss (for one batch) at step 130: 303.1721, Accuracy: 0.7631\n","Training loss (for one batch) at step 140: 297.2589, Accuracy: 0.7635\n","---- Training ----\n","Training loss: 251.1951\n","Training acc over epoch: 0.7641\n","---- Validation ----\n","Validation loss: 63.0459\n","Validation acc: 0.7268\n","Time taken: 75.88s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 301.3323, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 306.2533, Accuracy: 0.7700\n","Training loss (for one batch) at step 20: 290.1479, Accuracy: 0.7538\n","Training loss (for one batch) at step 30: 282.4838, Accuracy: 0.7635\n","Training loss (for one batch) at step 40: 288.8689, Accuracy: 0.7698\n","Training loss (for one batch) at step 50: 273.3527, Accuracy: 0.7712\n","Training loss (for one batch) at step 60: 298.4249, Accuracy: 0.7705\n","Training loss (for one batch) at step 70: 289.1207, Accuracy: 0.7715\n","Training loss (for one batch) at step 80: 289.9723, Accuracy: 0.7700\n","Training loss (for one batch) at step 90: 293.5947, Accuracy: 0.7668\n","Training loss (for one batch) at step 100: 298.9195, Accuracy: 0.7673\n","Training loss (for one batch) at step 110: 288.0560, Accuracy: 0.7674\n","Training loss (for one batch) at step 120: 284.0865, Accuracy: 0.7674\n","Training loss (for one batch) at step 130: 282.3078, Accuracy: 0.7675\n","Training loss (for one batch) at step 140: 285.4205, Accuracy: 0.7675\n","---- Training ----\n","Training loss: 247.3671\n","Training acc over epoch: 0.7682\n","---- Validation ----\n","Validation loss: 72.3659\n","Validation acc: 0.7346\n","Time taken: 74.29s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 292.0079, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 285.2299, Accuracy: 0.8009\n","Training loss (for one batch) at step 20: 269.2209, Accuracy: 0.7957\n","Training loss (for one batch) at step 30: 286.0503, Accuracy: 0.7913\n","Training loss (for one batch) at step 40: 282.7332, Accuracy: 0.7846\n","Training loss (for one batch) at step 50: 300.8488, Accuracy: 0.7857\n","Training loss (for one batch) at step 60: 287.8039, Accuracy: 0.7872\n","Training loss (for one batch) at step 70: 300.2922, Accuracy: 0.7831\n","Training loss (for one batch) at step 80: 286.8386, Accuracy: 0.7810\n","Training loss (for one batch) at step 90: 304.9008, Accuracy: 0.7779\n","Training loss (for one batch) at step 100: 297.4051, Accuracy: 0.7782\n","Training loss (for one batch) at step 110: 275.0313, Accuracy: 0.7805\n","Training loss (for one batch) at step 120: 295.3436, Accuracy: 0.7798\n","Training loss (for one batch) at step 130: 273.8640, Accuracy: 0.7789\n","Training loss (for one batch) at step 140: 291.1720, Accuracy: 0.7782\n","---- Training ----\n","Training loss: 267.6738\n","Training acc over epoch: 0.7777\n","---- Validation ----\n","Validation loss: 73.5635\n","Validation acc: 0.7356\n","Time taken: 72.03s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 299.0452, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 288.3185, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 272.9955, Accuracy: 0.8052\n","Training loss (for one batch) at step 30: 277.3845, Accuracy: 0.7968\n","Training loss (for one batch) at step 40: 276.7837, Accuracy: 0.7915\n","Training loss (for one batch) at step 50: 269.0900, Accuracy: 0.7880\n","Training loss (for one batch) at step 60: 272.8454, Accuracy: 0.7862\n","Training loss (for one batch) at step 70: 285.2678, Accuracy: 0.7817\n","Training loss (for one batch) at step 80: 296.8865, Accuracy: 0.7833\n","Training loss (for one batch) at step 90: 287.2521, Accuracy: 0.7825\n","Training loss (for one batch) at step 100: 291.4034, Accuracy: 0.7809\n","Training loss (for one batch) at step 110: 292.6112, Accuracy: 0.7814\n","Training loss (for one batch) at step 120: 292.5304, Accuracy: 0.7814\n","Training loss (for one batch) at step 130: 277.3731, Accuracy: 0.7831\n","Training loss (for one batch) at step 140: 286.7030, Accuracy: 0.7825\n","---- Training ----\n","Training loss: 247.9936\n","Training acc over epoch: 0.7826\n","---- Validation ----\n","Validation loss: 66.8202\n","Validation acc: 0.7413\n","Time taken: 73.77s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 281.1895, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 275.3210, Accuracy: 0.7973\n","Training loss (for one batch) at step 20: 295.4879, Accuracy: 0.7943\n","Training loss (for one batch) at step 30: 276.9759, Accuracy: 0.7890\n","Training loss (for one batch) at step 40: 274.9325, Accuracy: 0.7871\n","Training loss (for one batch) at step 50: 284.8924, Accuracy: 0.7910\n","Training loss (for one batch) at step 60: 280.5922, Accuracy: 0.7903\n","Training loss (for one batch) at step 70: 275.7258, Accuracy: 0.7894\n","Training loss (for one batch) at step 80: 278.0654, Accuracy: 0.7907\n","Training loss (for one batch) at step 90: 305.5441, Accuracy: 0.7893\n","Training loss (for one batch) at step 100: 296.8741, Accuracy: 0.7896\n","Training loss (for one batch) at step 110: 257.5922, Accuracy: 0.7894\n","Training loss (for one batch) at step 120: 281.2422, Accuracy: 0.7893\n","Training loss (for one batch) at step 130: 296.9188, Accuracy: 0.7882\n","Training loss (for one batch) at step 140: 287.4313, Accuracy: 0.7866\n","---- Training ----\n","Training loss: 231.9596\n","Training acc over epoch: 0.7872\n","---- Validation ----\n","Validation loss: 82.8343\n","Validation acc: 0.7405\n","Time taken: 71.36s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 281.6735, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 269.0828, Accuracy: 0.8145\n","Training loss (for one batch) at step 20: 281.5164, Accuracy: 0.8010\n","Training loss (for one batch) at step 30: 297.5991, Accuracy: 0.7948\n","Training loss (for one batch) at step 40: 277.0620, Accuracy: 0.8005\n","Training loss (for one batch) at step 50: 281.4669, Accuracy: 0.8010\n","Training loss (for one batch) at step 60: 275.3315, Accuracy: 0.7998\n","Training loss (for one batch) at step 70: 278.9253, Accuracy: 0.7985\n","Training loss (for one batch) at step 80: 282.5665, Accuracy: 0.7965\n","Training loss (for one batch) at step 90: 283.2708, Accuracy: 0.7949\n","Training loss (for one batch) at step 100: 276.5467, Accuracy: 0.7947\n","Training loss (for one batch) at step 110: 283.3846, Accuracy: 0.7964\n","Training loss (for one batch) at step 120: 299.6921, Accuracy: 0.7959\n","Training loss (for one batch) at step 130: 287.8276, Accuracy: 0.7937\n","Training loss (for one batch) at step 140: 301.5183, Accuracy: 0.7931\n","---- Training ----\n","Training loss: 238.0293\n","Training acc over epoch: 0.7927\n","---- Validation ----\n","Validation loss: 81.3899\n","Validation acc: 0.7504\n","Time taken: 71.34s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 266.4682, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 287.1421, Accuracy: 0.7955\n","Training loss (for one batch) at step 20: 278.5641, Accuracy: 0.8086\n","Training loss (for one batch) at step 30: 266.1347, Accuracy: 0.8045\n","Training loss (for one batch) at step 40: 298.0111, Accuracy: 0.8041\n","Training loss (for one batch) at step 50: 276.3456, Accuracy: 0.8047\n","Training loss (for one batch) at step 60: 281.3880, Accuracy: 0.8064\n","Training loss (for one batch) at step 70: 284.9993, Accuracy: 0.8061\n","Training loss (for one batch) at step 80: 261.9569, Accuracy: 0.8041\n","Training loss (for one batch) at step 90: 290.3067, Accuracy: 0.8001\n","Training loss (for one batch) at step 100: 264.6392, Accuracy: 0.7991\n","Training loss (for one batch) at step 110: 249.2981, Accuracy: 0.7998\n","Training loss (for one batch) at step 120: 292.5856, Accuracy: 0.7993\n","Training loss (for one batch) at step 130: 273.2161, Accuracy: 0.7969\n","Training loss (for one batch) at step 140: 275.6931, Accuracy: 0.7956\n","---- Training ----\n","Training loss: 249.2217\n","Training acc over epoch: 0.7966\n","---- Validation ----\n","Validation loss: 65.0352\n","Validation acc: 0.7297\n","Time taken: 71.16s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 282.4186, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 259.6514, Accuracy: 0.8218\n","Training loss (for one batch) at step 20: 268.1724, Accuracy: 0.8176\n","Training loss (for one batch) at step 30: 280.7770, Accuracy: 0.8100\n","Training loss (for one batch) at step 40: 246.4690, Accuracy: 0.8093\n","Training loss (for one batch) at step 50: 251.7276, Accuracy: 0.8124\n","Training loss (for one batch) at step 60: 262.9355, Accuracy: 0.8121\n","Training loss (for one batch) at step 70: 275.5515, Accuracy: 0.8089\n","Training loss (for one batch) at step 80: 261.9031, Accuracy: 0.8058\n","Training loss (for one batch) at step 90: 294.6574, Accuracy: 0.8040\n","Training loss (for one batch) at step 100: 296.3315, Accuracy: 0.8040\n","Training loss (for one batch) at step 110: 287.3327, Accuracy: 0.8049\n","Training loss (for one batch) at step 120: 259.8262, Accuracy: 0.8060\n","Training loss (for one batch) at step 130: 281.9769, Accuracy: 0.8045\n","Training loss (for one batch) at step 140: 262.2986, Accuracy: 0.8034\n","---- Training ----\n","Training loss: 240.1209\n","Training acc over epoch: 0.8031\n","---- Validation ----\n","Validation loss: 78.7696\n","Validation acc: 0.7316\n","Time taken: 71.55s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 268.0295, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 280.2883, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 269.3666, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 264.6096, Accuracy: 0.8255\n","Training loss (for one batch) at step 40: 270.0295, Accuracy: 0.8224\n","Training loss (for one batch) at step 50: 271.3235, Accuracy: 0.8237\n","Training loss (for one batch) at step 60: 279.3861, Accuracy: 0.8248\n","Training loss (for one batch) at step 70: 269.2138, Accuracy: 0.8208\n","Training loss (for one batch) at step 80: 278.8242, Accuracy: 0.8175\n","Training loss (for one batch) at step 90: 250.8933, Accuracy: 0.8171\n","Training loss (for one batch) at step 100: 294.4030, Accuracy: 0.8140\n","Training loss (for one batch) at step 110: 276.3112, Accuracy: 0.8153\n","Training loss (for one batch) at step 120: 262.6640, Accuracy: 0.8145\n","Training loss (for one batch) at step 130: 279.7787, Accuracy: 0.8125\n","Training loss (for one batch) at step 140: 272.1749, Accuracy: 0.8125\n","---- Training ----\n","Training loss: 231.3863\n","Training acc over epoch: 0.8115\n","---- Validation ----\n","Validation loss: 69.8801\n","Validation acc: 0.7421\n","Time taken: 70.62s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 254.9733, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 269.4165, Accuracy: 0.8164\n","Training loss (for one batch) at step 20: 250.0437, Accuracy: 0.8157\n","Training loss (for one batch) at step 30: 267.1422, Accuracy: 0.8132\n","Training loss (for one batch) at step 40: 262.7722, Accuracy: 0.8124\n","Training loss (for one batch) at step 50: 260.5438, Accuracy: 0.8182\n","Training loss (for one batch) at step 60: 251.2156, Accuracy: 0.8159\n","Training loss (for one batch) at step 70: 258.0803, Accuracy: 0.8130\n","Training loss (for one batch) at step 80: 282.4186, Accuracy: 0.8095\n","Training loss (for one batch) at step 90: 276.1891, Accuracy: 0.8090\n","Training loss (for one batch) at step 100: 275.2785, Accuracy: 0.8097\n","Training loss (for one batch) at step 110: 253.2360, Accuracy: 0.8110\n","Training loss (for one batch) at step 120: 266.8466, Accuracy: 0.8107\n","Training loss (for one batch) at step 130: 255.0706, Accuracy: 0.8096\n","Training loss (for one batch) at step 140: 263.4414, Accuracy: 0.8091\n","---- Training ----\n","Training loss: 235.3520\n","Training acc over epoch: 0.8076\n","---- Validation ----\n","Validation loss: 63.2341\n","Validation acc: 0.7421\n","Time taken: 70.67s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 253.6274, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 253.6279, Accuracy: 0.8282\n","Training loss (for one batch) at step 20: 276.7005, Accuracy: 0.8300\n","Training loss (for one batch) at step 30: 258.4392, Accuracy: 0.8290\n","Training loss (for one batch) at step 40: 290.6433, Accuracy: 0.8232\n","Training loss (for one batch) at step 50: 274.8335, Accuracy: 0.8251\n","Training loss (for one batch) at step 60: 271.8192, Accuracy: 0.8251\n","Training loss (for one batch) at step 70: 250.9925, Accuracy: 0.8246\n","Training loss (for one batch) at step 80: 252.2819, Accuracy: 0.8232\n","Training loss (for one batch) at step 90: 278.5620, Accuracy: 0.8195\n","Training loss (for one batch) at step 100: 253.4066, Accuracy: 0.8201\n","Training loss (for one batch) at step 110: 268.4791, Accuracy: 0.8195\n","Training loss (for one batch) at step 120: 254.0176, Accuracy: 0.8181\n","Training loss (for one batch) at step 130: 264.4153, Accuracy: 0.8182\n","Training loss (for one batch) at step 140: 257.9036, Accuracy: 0.8190\n","---- Training ----\n","Training loss: 223.2637\n","Training acc over epoch: 0.8176\n","---- Validation ----\n","Validation loss: 64.6007\n","Validation acc: 0.7270\n","Time taken: 76.91s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 248.1732, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 278.3231, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 255.8423, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 267.1412, Accuracy: 0.8245\n","Training loss (for one batch) at step 40: 261.0584, Accuracy: 0.8261\n","Training loss (for one batch) at step 50: 279.3692, Accuracy: 0.8259\n","Training loss (for one batch) at step 60: 250.7919, Accuracy: 0.8249\n","Training loss (for one batch) at step 70: 258.8534, Accuracy: 0.8227\n","Training loss (for one batch) at step 80: 271.7062, Accuracy: 0.8217\n","Training loss (for one batch) at step 90: 273.4159, Accuracy: 0.8187\n","Training loss (for one batch) at step 100: 265.5902, Accuracy: 0.8192\n","Training loss (for one batch) at step 110: 239.4798, Accuracy: 0.8199\n","Training loss (for one batch) at step 120: 252.0733, Accuracy: 0.8186\n","Training loss (for one batch) at step 130: 270.9268, Accuracy: 0.8170\n","Training loss (for one batch) at step 140: 245.7769, Accuracy: 0.8164\n","---- Training ----\n","Training loss: 227.7285\n","Training acc over epoch: 0.8165\n","---- Validation ----\n","Validation loss: 65.2358\n","Validation acc: 0.7364\n","Time taken: 71.21s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 253.0783, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 232.4052, Accuracy: 0.8218\n","Training loss (for one batch) at step 20: 278.7687, Accuracy: 0.8219\n","Training loss (for one batch) at step 30: 244.9971, Accuracy: 0.8206\n","Training loss (for one batch) at step 40: 255.2446, Accuracy: 0.8220\n","Training loss (for one batch) at step 50: 236.4393, Accuracy: 0.8259\n","Training loss (for one batch) at step 60: 255.0150, Accuracy: 0.8225\n","Training loss (for one batch) at step 70: 265.6529, Accuracy: 0.8224\n","Training loss (for one batch) at step 80: 254.8477, Accuracy: 0.8207\n","Training loss (for one batch) at step 90: 266.4260, Accuracy: 0.8210\n","Training loss (for one batch) at step 100: 255.1184, Accuracy: 0.8222\n","Training loss (for one batch) at step 110: 248.7098, Accuracy: 0.8197\n","Training loss (for one batch) at step 120: 281.0397, Accuracy: 0.8201\n","Training loss (for one batch) at step 130: 259.0579, Accuracy: 0.8202\n","Training loss (for one batch) at step 140: 261.9125, Accuracy: 0.8183\n","---- Training ----\n","Training loss: 227.3361\n","Training acc over epoch: 0.8176\n","---- Validation ----\n","Validation loss: 78.6923\n","Validation acc: 0.7367\n","Time taken: 70.30s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 244.5458, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 236.6589, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 250.6883, Accuracy: 0.8410\n","Training loss (for one batch) at step 30: 265.3478, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 258.7199, Accuracy: 0.8366\n","Training loss (for one batch) at step 50: 223.4241, Accuracy: 0.8357\n","Training loss (for one batch) at step 60: 261.6628, Accuracy: 0.8349\n","Training loss (for one batch) at step 70: 248.1772, Accuracy: 0.8342\n","Training loss (for one batch) at step 80: 283.1023, Accuracy: 0.8305\n","Training loss (for one batch) at step 90: 253.5290, Accuracy: 0.8291\n","Training loss (for one batch) at step 100: 262.2234, Accuracy: 0.8291\n","Training loss (for one batch) at step 110: 263.1727, Accuracy: 0.8290\n","Training loss (for one batch) at step 120: 249.2275, Accuracy: 0.8266\n","Training loss (for one batch) at step 130: 237.2230, Accuracy: 0.8276\n","Training loss (for one batch) at step 140: 266.5105, Accuracy: 0.8262\n","---- Training ----\n","Training loss: 228.1078\n","Training acc over epoch: 0.8256\n","---- Validation ----\n","Validation loss: 76.0080\n","Validation acc: 0.7434\n","Time taken: 71.12s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 262.2075, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 235.5043, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 253.5965, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 248.5832, Accuracy: 0.8323\n","Training loss (for one batch) at step 40: 238.5935, Accuracy: 0.8351\n","Training loss (for one batch) at step 50: 249.5223, Accuracy: 0.8357\n","Training loss (for one batch) at step 60: 291.7405, Accuracy: 0.8323\n","Training loss (for one batch) at step 70: 263.4925, Accuracy: 0.8294\n","Training loss (for one batch) at step 80: 254.9243, Accuracy: 0.8265\n","Training loss (for one batch) at step 90: 232.2543, Accuracy: 0.8273\n","Training loss (for one batch) at step 100: 246.1232, Accuracy: 0.8263\n","Training loss (for one batch) at step 110: 255.3308, Accuracy: 0.8259\n","Training loss (for one batch) at step 120: 278.7332, Accuracy: 0.8260\n","Training loss (for one batch) at step 130: 248.7212, Accuracy: 0.8257\n","Training loss (for one batch) at step 140: 264.8398, Accuracy: 0.8261\n","---- Training ----\n","Training loss: 229.5186\n","Training acc over epoch: 0.8262\n","---- Validation ----\n","Validation loss: 84.0394\n","Validation acc: 0.7238\n","Time taken: 71.07s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 267.9712, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 246.5451, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 258.2784, Accuracy: 0.8310\n","Training loss (for one batch) at step 30: 248.8747, Accuracy: 0.8274\n","Training loss (for one batch) at step 40: 253.2922, Accuracy: 0.8300\n","Training loss (for one batch) at step 50: 248.5294, Accuracy: 0.8325\n","Training loss (for one batch) at step 60: 235.3724, Accuracy: 0.8311\n","Training loss (for one batch) at step 70: 259.3443, Accuracy: 0.8306\n","Training loss (for one batch) at step 80: 260.0667, Accuracy: 0.8264\n","Training loss (for one batch) at step 90: 266.7815, Accuracy: 0.8248\n","Training loss (for one batch) at step 100: 234.5537, Accuracy: 0.8242\n","Training loss (for one batch) at step 110: 232.7592, Accuracy: 0.8270\n","Training loss (for one batch) at step 120: 249.1422, Accuracy: 0.8264\n","Training loss (for one batch) at step 130: 263.2557, Accuracy: 0.8252\n","Training loss (for one batch) at step 140: 253.5862, Accuracy: 0.8246\n","---- Training ----\n","Training loss: 213.7686\n","Training acc over epoch: 0.8240\n","---- Validation ----\n","Validation loss: 69.0073\n","Validation acc: 0.7421\n","Time taken: 69.86s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 233.1473, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 245.0698, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 250.2190, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 254.8922, Accuracy: 0.8435\n","Training loss (for one batch) at step 40: 240.9870, Accuracy: 0.8376\n","Training loss (for one batch) at step 50: 249.3602, Accuracy: 0.8353\n","Training loss (for one batch) at step 60: 245.3304, Accuracy: 0.8331\n","Training loss (for one batch) at step 70: 239.5867, Accuracy: 0.8335\n","Training loss (for one batch) at step 80: 249.6089, Accuracy: 0.8321\n","Training loss (for one batch) at step 90: 248.2612, Accuracy: 0.8329\n","Training loss (for one batch) at step 100: 229.3728, Accuracy: 0.8318\n","Training loss (for one batch) at step 110: 228.4113, Accuracy: 0.8315\n","Training loss (for one batch) at step 120: 262.9207, Accuracy: 0.8311\n","Training loss (for one batch) at step 130: 257.3103, Accuracy: 0.8303\n","Training loss (for one batch) at step 140: 256.3791, Accuracy: 0.8309\n","---- Training ----\n","Training loss: 229.7469\n","Training acc over epoch: 0.8303\n","---- Validation ----\n","Validation loss: 77.6415\n","Validation acc: 0.7397\n","Time taken: 70.67s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 249.5618, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 249.5747, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 246.7046, Accuracy: 0.8505\n","Training loss (for one batch) at step 30: 256.6929, Accuracy: 0.8426\n","Training loss (for one batch) at step 40: 229.3705, Accuracy: 0.8378\n","Training loss (for one batch) at step 50: 234.3325, Accuracy: 0.8406\n","Training loss (for one batch) at step 60: 271.8959, Accuracy: 0.8393\n","Training loss (for one batch) at step 70: 252.2665, Accuracy: 0.8387\n","Training loss (for one batch) at step 80: 245.0383, Accuracy: 0.8369\n","Training loss (for one batch) at step 90: 256.0618, Accuracy: 0.8347\n","Training loss (for one batch) at step 100: 247.5117, Accuracy: 0.8338\n","Training loss (for one batch) at step 110: 248.9980, Accuracy: 0.8342\n","Training loss (for one batch) at step 120: 244.7821, Accuracy: 0.8322\n","Training loss (for one batch) at step 130: 228.4512, Accuracy: 0.8313\n","Training loss (for one batch) at step 140: 254.1633, Accuracy: 0.8305\n","---- Training ----\n","Training loss: 238.2689\n","Training acc over epoch: 0.8311\n","---- Validation ----\n","Validation loss: 69.2916\n","Validation acc: 0.7367\n","Time taken: 71.33s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 252.9691, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 231.2312, Accuracy: 0.8545\n","Training loss (for one batch) at step 20: 254.6116, Accuracy: 0.8529\n","Training loss (for one batch) at step 30: 236.3284, Accuracy: 0.8494\n","Training loss (for one batch) at step 40: 256.6017, Accuracy: 0.8444\n","Training loss (for one batch) at step 50: 218.8051, Accuracy: 0.8461\n","Training loss (for one batch) at step 60: 243.3304, Accuracy: 0.8436\n","Training loss (for one batch) at step 70: 252.8861, Accuracy: 0.8448\n","Training loss (for one batch) at step 80: 240.8819, Accuracy: 0.8410\n","Training loss (for one batch) at step 90: 245.9350, Accuracy: 0.8405\n","Training loss (for one batch) at step 100: 243.9719, Accuracy: 0.8413\n","Training loss (for one batch) at step 110: 236.1724, Accuracy: 0.8410\n","Training loss (for one batch) at step 120: 241.5047, Accuracy: 0.8413\n","Training loss (for one batch) at step 130: 252.3178, Accuracy: 0.8392\n","Training loss (for one batch) at step 140: 258.1046, Accuracy: 0.8382\n","---- Training ----\n","Training loss: 243.9590\n","Training acc over epoch: 0.8381\n","---- Validation ----\n","Validation loss: 90.4517\n","Validation acc: 0.7413\n","Time taken: 69.92s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 252.3012, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 251.0342, Accuracy: 0.8400\n","Training loss (for one batch) at step 20: 235.6924, Accuracy: 0.8433\n","Training loss (for one batch) at step 30: 241.9285, Accuracy: 0.8403\n","Training loss (for one batch) at step 40: 242.1792, Accuracy: 0.8398\n","Training loss (for one batch) at step 50: 230.7759, Accuracy: 0.8433\n","Training loss (for one batch) at step 60: 243.9147, Accuracy: 0.8425\n","Training loss (for one batch) at step 70: 223.1204, Accuracy: 0.8401\n","Training loss (for one batch) at step 80: 248.2409, Accuracy: 0.8386\n","Training loss (for one batch) at step 90: 262.3276, Accuracy: 0.8380\n","Training loss (for one batch) at step 100: 236.2814, Accuracy: 0.8382\n","Training loss (for one batch) at step 110: 234.6989, Accuracy: 0.8376\n","Training loss (for one batch) at step 120: 235.0789, Accuracy: 0.8367\n","Training loss (for one batch) at step 130: 234.9076, Accuracy: 0.8349\n","Training loss (for one batch) at step 140: 212.8899, Accuracy: 0.8361\n","---- Training ----\n","Training loss: 211.9931\n","Training acc over epoch: 0.8354\n","---- Validation ----\n","Validation loss: 74.1251\n","Validation acc: 0.7260\n","Time taken: 78.07s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 256.9553, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 225.0548, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 232.7882, Accuracy: 0.8452\n","Training loss (for one batch) at step 30: 231.2988, Accuracy: 0.8365\n","Training loss (for one batch) at step 40: 229.6678, Accuracy: 0.8410\n","Training loss (for one batch) at step 50: 228.6440, Accuracy: 0.8439\n","Training loss (for one batch) at step 60: 253.4804, Accuracy: 0.8438\n","Training loss (for one batch) at step 70: 242.1429, Accuracy: 0.8401\n","Training loss (for one batch) at step 80: 239.2490, Accuracy: 0.8400\n","Training loss (for one batch) at step 90: 234.8797, Accuracy: 0.8407\n","Training loss (for one batch) at step 100: 242.4643, Accuracy: 0.8383\n","Training loss (for one batch) at step 110: 222.3867, Accuracy: 0.8390\n","Training loss (for one batch) at step 120: 235.2296, Accuracy: 0.8392\n","Training loss (for one batch) at step 130: 237.6597, Accuracy: 0.8377\n","Training loss (for one batch) at step 140: 247.4914, Accuracy: 0.8365\n","---- Training ----\n","Training loss: 220.0766\n","Training acc over epoch: 0.8373\n","---- Validation ----\n","Validation loss: 71.2525\n","Validation acc: 0.7246\n","Time taken: 70.51s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 245.6766, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 233.2555, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 224.3548, Accuracy: 0.8538\n","Training loss (for one batch) at step 30: 235.2061, Accuracy: 0.8477\n","Training loss (for one batch) at step 40: 244.1434, Accuracy: 0.8471\n","Training loss (for one batch) at step 50: 220.9570, Accuracy: 0.8439\n","Training loss (for one batch) at step 60: 252.7852, Accuracy: 0.8421\n","Training loss (for one batch) at step 70: 225.9279, Accuracy: 0.8420\n","Training loss (for one batch) at step 80: 242.2033, Accuracy: 0.8393\n","Training loss (for one batch) at step 90: 242.7005, Accuracy: 0.8364\n","Training loss (for one batch) at step 100: 240.8178, Accuracy: 0.8378\n","Training loss (for one batch) at step 110: 227.6865, Accuracy: 0.8383\n","Training loss (for one batch) at step 120: 228.7016, Accuracy: 0.8374\n","Training loss (for one batch) at step 130: 276.1204, Accuracy: 0.8373\n","Training loss (for one batch) at step 140: 245.1734, Accuracy: 0.8371\n","---- Training ----\n","Training loss: 200.6095\n","Training acc over epoch: 0.8362\n","---- Validation ----\n","Validation loss: 80.3235\n","Validation acc: 0.7321\n","Time taken: 70.07s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 230.2730, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 216.5594, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 255.3738, Accuracy: 0.8519\n","Training loss (for one batch) at step 30: 240.8221, Accuracy: 0.8494\n","Training loss (for one batch) at step 40: 225.1424, Accuracy: 0.8454\n","Training loss (for one batch) at step 50: 232.3917, Accuracy: 0.8475\n","Training loss (for one batch) at step 60: 227.4667, Accuracy: 0.8477\n","Training loss (for one batch) at step 70: 243.7313, Accuracy: 0.8469\n","Training loss (for one batch) at step 80: 243.0916, Accuracy: 0.8463\n","Training loss (for one batch) at step 90: 240.3670, Accuracy: 0.8446\n","Training loss (for one batch) at step 100: 232.2064, Accuracy: 0.8447\n","Training loss (for one batch) at step 110: 235.0001, Accuracy: 0.8433\n","Training loss (for one batch) at step 120: 241.0467, Accuracy: 0.8443\n","Training loss (for one batch) at step 130: 230.9917, Accuracy: 0.8434\n","Training loss (for one batch) at step 140: 240.3568, Accuracy: 0.8438\n","---- Training ----\n","Training loss: 220.1861\n","Training acc over epoch: 0.8420\n","---- Validation ----\n","Validation loss: 66.4659\n","Validation acc: 0.7351\n","Time taken: 76.94s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 248.9774, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 219.9746, Accuracy: 0.8591\n","Training loss (for one batch) at step 20: 249.0666, Accuracy: 0.8519\n","Training loss (for one batch) at step 30: 263.6258, Accuracy: 0.8490\n","Training loss (for one batch) at step 40: 226.1552, Accuracy: 0.8502\n","Training loss (for one batch) at step 50: 218.8947, Accuracy: 0.8484\n","Training loss (for one batch) at step 60: 221.6885, Accuracy: 0.8482\n","Training loss (for one batch) at step 70: 225.7033, Accuracy: 0.8469\n","Training loss (for one batch) at step 80: 242.3226, Accuracy: 0.8460\n","Training loss (for one batch) at step 90: 225.8151, Accuracy: 0.8441\n","Training loss (for one batch) at step 100: 238.7762, Accuracy: 0.8437\n","Training loss (for one batch) at step 110: 226.2378, Accuracy: 0.8441\n","Training loss (for one batch) at step 120: 216.5940, Accuracy: 0.8426\n","Training loss (for one batch) at step 130: 234.9611, Accuracy: 0.8423\n","Training loss (for one batch) at step 140: 247.5874, Accuracy: 0.8427\n","---- Training ----\n","Training loss: 205.3710\n","Training acc over epoch: 0.8428\n","---- Validation ----\n","Validation loss: 74.2019\n","Validation acc: 0.7351\n","Time taken: 72.89s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 233.4778, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 214.9951, Accuracy: 0.8682\n","Training loss (for one batch) at step 20: 216.3936, Accuracy: 0.8533\n","Training loss (for one batch) at step 30: 221.5726, Accuracy: 0.8523\n","Training loss (for one batch) at step 40: 229.5914, Accuracy: 0.8473\n","Training loss (for one batch) at step 50: 251.9168, Accuracy: 0.8488\n","Training loss (for one batch) at step 60: 232.0169, Accuracy: 0.8503\n","Training loss (for one batch) at step 70: 248.9740, Accuracy: 0.8476\n","Training loss (for one batch) at step 80: 239.1750, Accuracy: 0.8479\n","Training loss (for one batch) at step 90: 243.5117, Accuracy: 0.8453\n","Training loss (for one batch) at step 100: 249.8511, Accuracy: 0.8431\n","Training loss (for one batch) at step 110: 223.0560, Accuracy: 0.8430\n","Training loss (for one batch) at step 120: 235.3940, Accuracy: 0.8429\n","Training loss (for one batch) at step 130: 247.2392, Accuracy: 0.8424\n","Training loss (for one batch) at step 140: 235.0398, Accuracy: 0.8421\n","---- Training ----\n","Training loss: 196.0405\n","Training acc over epoch: 0.8426\n","---- Validation ----\n","Validation loss: 72.8664\n","Validation acc: 0.7319\n","Time taken: 71.12s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 224.2705, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 234.3240, Accuracy: 0.8664\n","Training loss (for one batch) at step 20: 242.2694, Accuracy: 0.8571\n","Training loss (for one batch) at step 30: 224.0434, Accuracy: 0.8510\n","Training loss (for one batch) at step 40: 233.1892, Accuracy: 0.8544\n","Training loss (for one batch) at step 50: 210.9580, Accuracy: 0.8512\n","Training loss (for one batch) at step 60: 226.1767, Accuracy: 0.8515\n","Training loss (for one batch) at step 70: 251.1866, Accuracy: 0.8511\n","Training loss (for one batch) at step 80: 227.9540, Accuracy: 0.8477\n","Training loss (for one batch) at step 90: 224.6239, Accuracy: 0.8469\n","Training loss (for one batch) at step 100: 217.3212, Accuracy: 0.8454\n","Training loss (for one batch) at step 110: 244.4680, Accuracy: 0.8471\n","Training loss (for one batch) at step 120: 238.3214, Accuracy: 0.8445\n","Training loss (for one batch) at step 130: 222.2251, Accuracy: 0.8439\n","Training loss (for one batch) at step 140: 227.4710, Accuracy: 0.8443\n","---- Training ----\n","Training loss: 194.3192\n","Training acc over epoch: 0.8439\n","---- Validation ----\n","Validation loss: 85.9939\n","Validation acc: 0.7327\n","Time taken: 71.18s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 201.8707, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 214.6804, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 212.8790, Accuracy: 0.8581\n","Training loss (for one batch) at step 30: 213.7237, Accuracy: 0.8526\n","Training loss (for one batch) at step 40: 228.7043, Accuracy: 0.8541\n","Training loss (for one batch) at step 50: 244.1780, Accuracy: 0.8533\n","Training loss (for one batch) at step 60: 242.8037, Accuracy: 0.8497\n","Training loss (for one batch) at step 70: 214.9339, Accuracy: 0.8461\n","Training loss (for one batch) at step 80: 238.1646, Accuracy: 0.8451\n","Training loss (for one batch) at step 90: 231.1182, Accuracy: 0.8446\n","Training loss (for one batch) at step 100: 220.2313, Accuracy: 0.8440\n","Training loss (for one batch) at step 110: 210.3379, Accuracy: 0.8429\n","Training loss (for one batch) at step 120: 240.0279, Accuracy: 0.8430\n","Training loss (for one batch) at step 130: 220.9193, Accuracy: 0.8424\n","Training loss (for one batch) at step 140: 246.5364, Accuracy: 0.8417\n","---- Training ----\n","Training loss: 229.0751\n","Training acc over epoch: 0.8414\n","---- Validation ----\n","Validation loss: 82.0959\n","Validation acc: 0.7308\n","Time taken: 72.61s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 239.3244, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 219.6543, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 223.9315, Accuracy: 0.8448\n","Training loss (for one batch) at step 30: 215.9297, Accuracy: 0.8471\n","Training loss (for one batch) at step 40: 218.1613, Accuracy: 0.8512\n","Training loss (for one batch) at step 50: 226.2424, Accuracy: 0.8506\n","Training loss (for one batch) at step 60: 241.5400, Accuracy: 0.8467\n","Training loss (for one batch) at step 70: 231.3845, Accuracy: 0.8465\n","Training loss (for one batch) at step 80: 228.5629, Accuracy: 0.8465\n","Training loss (for one batch) at step 90: 220.6923, Accuracy: 0.8451\n","Training loss (for one batch) at step 100: 247.2011, Accuracy: 0.8447\n","Training loss (for one batch) at step 110: 219.6858, Accuracy: 0.8446\n","Training loss (for one batch) at step 120: 230.5415, Accuracy: 0.8439\n","Training loss (for one batch) at step 130: 227.6658, Accuracy: 0.8425\n","Training loss (for one batch) at step 140: 233.2672, Accuracy: 0.8430\n","---- Training ----\n","Training loss: 212.7674\n","Training acc over epoch: 0.8440\n","---- Validation ----\n","Validation loss: 71.1630\n","Validation acc: 0.7329\n","Time taken: 70.81s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 230.1936, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 231.1985, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 239.0508, Accuracy: 0.8586\n","Training loss (for one batch) at step 30: 221.8375, Accuracy: 0.8465\n","Training loss (for one batch) at step 40: 220.0349, Accuracy: 0.8532\n","Training loss (for one batch) at step 50: 218.7218, Accuracy: 0.8518\n","Training loss (for one batch) at step 60: 228.8892, Accuracy: 0.8508\n","Training loss (for one batch) at step 70: 222.2599, Accuracy: 0.8483\n","Training loss (for one batch) at step 80: 250.5238, Accuracy: 0.8470\n","Training loss (for one batch) at step 90: 213.7153, Accuracy: 0.8460\n","Training loss (for one batch) at step 100: 225.4594, Accuracy: 0.8468\n","Training loss (for one batch) at step 110: 224.7060, Accuracy: 0.8468\n","Training loss (for one batch) at step 120: 214.5879, Accuracy: 0.8475\n","Training loss (for one batch) at step 130: 212.8345, Accuracy: 0.8457\n","Training loss (for one batch) at step 140: 210.8965, Accuracy: 0.8446\n","---- Training ----\n","Training loss: 215.1922\n","Training acc over epoch: 0.8461\n","---- Validation ----\n","Validation loss: 67.5760\n","Validation acc: 0.7319\n","Time taken: 70.28s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 221.5582, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 237.2514, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 212.6776, Accuracy: 0.8486\n","Training loss (for one batch) at step 30: 234.0656, Accuracy: 0.8461\n","Training loss (for one batch) at step 40: 232.9524, Accuracy: 0.8488\n","Training loss (for one batch) at step 50: 219.4377, Accuracy: 0.8533\n","Training loss (for one batch) at step 60: 210.7666, Accuracy: 0.8513\n","Training loss (for one batch) at step 70: 222.5486, Accuracy: 0.8539\n","Training loss (for one batch) at step 80: 228.6467, Accuracy: 0.8493\n","Training loss (for one batch) at step 90: 214.6617, Accuracy: 0.8495\n","Training loss (for one batch) at step 100: 214.5661, Accuracy: 0.8501\n","Training loss (for one batch) at step 110: 210.7866, Accuracy: 0.8495\n","Training loss (for one batch) at step 120: 232.4918, Accuracy: 0.8498\n","Training loss (for one batch) at step 130: 225.9841, Accuracy: 0.8498\n","Training loss (for one batch) at step 140: 202.8020, Accuracy: 0.8487\n","---- Training ----\n","Training loss: 172.5902\n","Training acc over epoch: 0.8493\n","---- Validation ----\n","Validation loss: 71.0669\n","Validation acc: 0.7383\n","Time taken: 72.32s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 233.3399, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 208.1093, Accuracy: 0.8536\n","Training loss (for one batch) at step 20: 202.5366, Accuracy: 0.8629\n","Training loss (for one batch) at step 30: 213.8197, Accuracy: 0.8555\n","Training loss (for one batch) at step 40: 248.0041, Accuracy: 0.8561\n","Training loss (for one batch) at step 50: 195.6380, Accuracy: 0.8547\n","Training loss (for one batch) at step 60: 209.6577, Accuracy: 0.8528\n","Training loss (for one batch) at step 70: 254.2601, Accuracy: 0.8515\n","Training loss (for one batch) at step 80: 215.9312, Accuracy: 0.8502\n","Training loss (for one batch) at step 90: 199.0269, Accuracy: 0.8480\n","Training loss (for one batch) at step 100: 246.5574, Accuracy: 0.8472\n","Training loss (for one batch) at step 110: 215.3420, Accuracy: 0.8473\n","Training loss (for one batch) at step 120: 209.0702, Accuracy: 0.8474\n","Training loss (for one batch) at step 130: 212.8100, Accuracy: 0.8483\n","Training loss (for one batch) at step 140: 228.9607, Accuracy: 0.8482\n","---- Training ----\n","Training loss: 198.4978\n","Training acc over epoch: 0.8477\n","---- Validation ----\n","Validation loss: 66.0798\n","Validation acc: 0.7278\n","Time taken: 72.74s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 242.1204, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 224.4248, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 207.7468, Accuracy: 0.8500\n","Training loss (for one batch) at step 30: 236.0043, Accuracy: 0.8484\n","Training loss (for one batch) at step 40: 227.1969, Accuracy: 0.8461\n","Training loss (for one batch) at step 50: 204.6025, Accuracy: 0.8473\n","Training loss (for one batch) at step 60: 221.0942, Accuracy: 0.8479\n","Training loss (for one batch) at step 70: 229.7359, Accuracy: 0.8497\n","Training loss (for one batch) at step 80: 217.3224, Accuracy: 0.8496\n","Training loss (for one batch) at step 90: 243.6421, Accuracy: 0.8477\n","Training loss (for one batch) at step 100: 206.0341, Accuracy: 0.8459\n","Training loss (for one batch) at step 110: 208.8016, Accuracy: 0.8468\n","Training loss (for one batch) at step 120: 236.7109, Accuracy: 0.8460\n","Training loss (for one batch) at step 130: 231.8559, Accuracy: 0.8468\n","Training loss (for one batch) at step 140: 206.9695, Accuracy: 0.8466\n","---- Training ----\n","Training loss: 189.2523\n","Training acc over epoch: 0.8466\n","---- Validation ----\n","Validation loss: 71.5507\n","Validation acc: 0.7316\n","Time taken: 69.52s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 199.2838, Accuracy: 0.9400\n","Training loss (for one batch) at step 10: 219.0789, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 203.2104, Accuracy: 0.8548\n","Training loss (for one batch) at step 30: 222.4464, Accuracy: 0.8535\n","Training loss (for one batch) at step 40: 223.7515, Accuracy: 0.8515\n","Training loss (for one batch) at step 50: 218.7480, Accuracy: 0.8508\n","Training loss (for one batch) at step 60: 207.6513, Accuracy: 0.8520\n","Training loss (for one batch) at step 70: 204.0736, Accuracy: 0.8525\n","Training loss (for one batch) at step 80: 235.2818, Accuracy: 0.8509\n","Training loss (for one batch) at step 90: 235.5622, Accuracy: 0.8501\n","Training loss (for one batch) at step 100: 248.8083, Accuracy: 0.8501\n","Training loss (for one batch) at step 110: 195.0711, Accuracy: 0.8500\n","Training loss (for one batch) at step 120: 218.1176, Accuracy: 0.8497\n","Training loss (for one batch) at step 130: 204.1860, Accuracy: 0.8500\n","Training loss (for one batch) at step 140: 228.2276, Accuracy: 0.8489\n","---- Training ----\n","Training loss: 207.4955\n","Training acc over epoch: 0.8492\n","---- Validation ----\n","Validation loss: 78.4742\n","Validation acc: 0.7286\n","Time taken: 70.58s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 252.6401, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 216.0220, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 210.0119, Accuracy: 0.8495\n","Training loss (for one batch) at step 30: 214.9314, Accuracy: 0.8500\n","Training loss (for one batch) at step 40: 206.6995, Accuracy: 0.8549\n","Training loss (for one batch) at step 50: 200.2455, Accuracy: 0.8555\n","Training loss (for one batch) at step 60: 219.4441, Accuracy: 0.8549\n","Training loss (for one batch) at step 70: 239.0741, Accuracy: 0.8572\n","Training loss (for one batch) at step 80: 201.3262, Accuracy: 0.8521\n","Training loss (for one batch) at step 90: 217.2632, Accuracy: 0.8524\n","Training loss (for one batch) at step 100: 222.3770, Accuracy: 0.8514\n","Training loss (for one batch) at step 110: 202.3416, Accuracy: 0.8495\n","Training loss (for one batch) at step 120: 222.6030, Accuracy: 0.8498\n","Training loss (for one batch) at step 130: 228.0228, Accuracy: 0.8500\n","Training loss (for one batch) at step 140: 243.6026, Accuracy: 0.8494\n","---- Training ----\n","Training loss: 186.2916\n","Training acc over epoch: 0.8497\n","---- Validation ----\n","Validation loss: 81.6577\n","Validation acc: 0.7375\n","Time taken: 71.03s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 212.1761, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 215.5739, Accuracy: 0.8609\n","Training loss (for one batch) at step 20: 199.2347, Accuracy: 0.8638\n","Training loss (for one batch) at step 30: 204.7001, Accuracy: 0.8545\n","Training loss (for one batch) at step 40: 215.9731, Accuracy: 0.8551\n","Training loss (for one batch) at step 50: 208.3211, Accuracy: 0.8598\n","Training loss (for one batch) at step 60: 197.2597, Accuracy: 0.8595\n","Training loss (for one batch) at step 70: 215.4899, Accuracy: 0.8607\n","Training loss (for one batch) at step 80: 211.1470, Accuracy: 0.8578\n","Training loss (for one batch) at step 90: 218.7868, Accuracy: 0.8581\n","Training loss (for one batch) at step 100: 208.5240, Accuracy: 0.8563\n","Training loss (for one batch) at step 110: 210.0506, Accuracy: 0.8569\n","Training loss (for one batch) at step 120: 209.2231, Accuracy: 0.8550\n","Training loss (for one batch) at step 130: 189.8694, Accuracy: 0.8537\n","Training loss (for one batch) at step 140: 231.8165, Accuracy: 0.8534\n","---- Training ----\n","Training loss: 182.5871\n","Training acc over epoch: 0.8542\n","---- Validation ----\n","Validation loss: 85.3009\n","Validation acc: 0.7402\n","Time taken: 71.74s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 206.6760, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 201.3867, Accuracy: 0.8491\n","Training loss (for one batch) at step 20: 206.5851, Accuracy: 0.8529\n","Training loss (for one batch) at step 30: 206.1318, Accuracy: 0.8545\n","Training loss (for one batch) at step 40: 218.0840, Accuracy: 0.8600\n","Training loss (for one batch) at step 50: 218.3000, Accuracy: 0.8639\n","Training loss (for one batch) at step 60: 203.8010, Accuracy: 0.8602\n","Training loss (for one batch) at step 70: 212.3615, Accuracy: 0.8597\n","Training loss (for one batch) at step 80: 239.9712, Accuracy: 0.8575\n","Training loss (for one batch) at step 90: 213.6705, Accuracy: 0.8565\n","Training loss (for one batch) at step 100: 203.0492, Accuracy: 0.8553\n","Training loss (for one batch) at step 110: 216.2920, Accuracy: 0.8542\n","Training loss (for one batch) at step 120: 221.1920, Accuracy: 0.8540\n","Training loss (for one batch) at step 130: 211.8812, Accuracy: 0.8547\n","Training loss (for one batch) at step 140: 215.4435, Accuracy: 0.8542\n","---- Training ----\n","Training loss: 234.1371\n","Training acc over epoch: 0.8540\n","---- Validation ----\n","Validation loss: 73.0761\n","Validation acc: 0.7219\n","Time taken: 71.38s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 199.4191, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 201.0973, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 236.0636, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 214.6983, Accuracy: 0.8477\n","Training loss (for one batch) at step 40: 209.0563, Accuracy: 0.8527\n","Training loss (for one batch) at step 50: 210.9386, Accuracy: 0.8524\n","Training loss (for one batch) at step 60: 217.0558, Accuracy: 0.8508\n","Training loss (for one batch) at step 70: 213.2432, Accuracy: 0.8497\n","Training loss (for one batch) at step 80: 222.9606, Accuracy: 0.8485\n","Training loss (for one batch) at step 90: 207.5662, Accuracy: 0.8492\n","Training loss (for one batch) at step 100: 191.4637, Accuracy: 0.8489\n","Training loss (for one batch) at step 110: 207.4812, Accuracy: 0.8502\n","Training loss (for one batch) at step 120: 203.0100, Accuracy: 0.8509\n","Training loss (for one batch) at step 130: 206.2034, Accuracy: 0.8511\n","Training loss (for one batch) at step 140: 211.8704, Accuracy: 0.8509\n","---- Training ----\n","Training loss: 183.3340\n","Training acc over epoch: 0.8518\n","---- Validation ----\n","Validation loss: 70.6234\n","Validation acc: 0.7268\n","Time taken: 70.93s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 204.3720, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 191.6340, Accuracy: 0.8600\n","Training loss (for one batch) at step 20: 193.4585, Accuracy: 0.8657\n","Training loss (for one batch) at step 30: 222.1819, Accuracy: 0.8545\n","Training loss (for one batch) at step 40: 200.0914, Accuracy: 0.8566\n","Training loss (for one batch) at step 50: 210.7502, Accuracy: 0.8573\n","Training loss (for one batch) at step 60: 212.7326, Accuracy: 0.8584\n","Training loss (for one batch) at step 70: 214.4258, Accuracy: 0.8601\n","Training loss (for one batch) at step 80: 214.3337, Accuracy: 0.8556\n","Training loss (for one batch) at step 90: 208.7932, Accuracy: 0.8558\n","Training loss (for one batch) at step 100: 212.1418, Accuracy: 0.8542\n","Training loss (for one batch) at step 110: 203.5922, Accuracy: 0.8547\n","Training loss (for one batch) at step 120: 216.2502, Accuracy: 0.8555\n","Training loss (for one batch) at step 130: 211.1794, Accuracy: 0.8543\n","Training loss (for one batch) at step 140: 218.6991, Accuracy: 0.8531\n","---- Training ----\n","Training loss: 191.5426\n","Training acc over epoch: 0.8535\n","---- Validation ----\n","Validation loss: 76.4332\n","Validation acc: 0.7219\n","Time taken: 71.61s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7309\n","Validation AUC: 0.7279\n","Validation Balanced_ACC: 0.4680\n","Validation MI: 0.1339\n","Validation Normalized MI: 0.2013\n","Validation Adjusted MI: 0.2013\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 494.2982, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 429.1270, Accuracy: 0.5264\n","Training loss (for one batch) at step 20: 467.7954, Accuracy: 0.5367\n","Training loss (for one batch) at step 30: 470.4799, Accuracy: 0.5413\n","Training loss (for one batch) at step 40: 469.8508, Accuracy: 0.5437\n","Training loss (for one batch) at step 50: 441.4360, Accuracy: 0.5469\n","Training loss (for one batch) at step 60: 458.9110, Accuracy: 0.5500\n","Training loss (for one batch) at step 70: 453.5223, Accuracy: 0.5530\n","Training loss (for one batch) at step 80: 445.4177, Accuracy: 0.5548\n","Training loss (for one batch) at step 90: 399.2392, Accuracy: 0.5544\n","Training loss (for one batch) at step 100: 440.9690, Accuracy: 0.5559\n","Training loss (for one batch) at step 110: 446.0576, Accuracy: 0.5547\n","Training loss (for one batch) at step 120: 438.1341, Accuracy: 0.5567\n","Training loss (for one batch) at step 130: 422.6629, Accuracy: 0.5586\n","Training loss (for one batch) at step 140: 441.1047, Accuracy: 0.5582\n","---- Training ----\n","Training loss: 370.2085\n","Training acc over epoch: 0.5596\n","---- Validation ----\n","Validation loss: 82.3310\n","Validation acc: 0.5134\n","Time taken: 63.15s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 393.1127, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 409.2948, Accuracy: 0.6164\n","Training loss (for one batch) at step 20: 389.2652, Accuracy: 0.6076\n","Training loss (for one batch) at step 30: 393.2419, Accuracy: 0.6077\n","Training loss (for one batch) at step 40: 384.4977, Accuracy: 0.6093\n","Training loss (for one batch) at step 50: 401.5500, Accuracy: 0.6100\n","Training loss (for one batch) at step 60: 388.2305, Accuracy: 0.6118\n","Training loss (for one batch) at step 70: 408.2529, Accuracy: 0.6104\n","Training loss (for one batch) at step 80: 358.2584, Accuracy: 0.6094\n","Training loss (for one batch) at step 90: 379.2693, Accuracy: 0.6101\n","Training loss (for one batch) at step 100: 383.9994, Accuracy: 0.6075\n","Training loss (for one batch) at step 110: 394.2795, Accuracy: 0.6063\n","Training loss (for one batch) at step 120: 352.2882, Accuracy: 0.6079\n","Training loss (for one batch) at step 130: 413.4967, Accuracy: 0.6079\n","Training loss (for one batch) at step 140: 389.0894, Accuracy: 0.6076\n","---- Training ----\n","Training loss: 315.8922\n","Training acc over epoch: 0.6090\n","---- Validation ----\n","Validation loss: 87.6288\n","Validation acc: 0.5150\n","Time taken: 60.13s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 374.3456, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 356.5573, Accuracy: 0.6273\n","Training loss (for one batch) at step 20: 394.9339, Accuracy: 0.6210\n","Training loss (for one batch) at step 30: 369.9269, Accuracy: 0.6219\n","Training loss (for one batch) at step 40: 368.9420, Accuracy: 0.6246\n","Training loss (for one batch) at step 50: 356.7285, Accuracy: 0.6271\n","Training loss (for one batch) at step 60: 395.6433, Accuracy: 0.6270\n","Training loss (for one batch) at step 70: 357.7514, Accuracy: 0.6245\n","Training loss (for one batch) at step 80: 387.7772, Accuracy: 0.6243\n","Training loss (for one batch) at step 90: 366.9972, Accuracy: 0.6254\n","Training loss (for one batch) at step 100: 379.4748, Accuracy: 0.6264\n","Training loss (for one batch) at step 110: 355.3553, Accuracy: 0.6265\n","Training loss (for one batch) at step 120: 367.5550, Accuracy: 0.6297\n","Training loss (for one batch) at step 130: 356.5649, Accuracy: 0.6308\n","Training loss (for one batch) at step 140: 365.4161, Accuracy: 0.6305\n","---- Training ----\n","Training loss: 306.8859\n","Training acc over epoch: 0.6310\n","---- Validation ----\n","Validation loss: 76.1748\n","Validation acc: 0.6354\n","Time taken: 58.49s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 356.6439, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 369.6841, Accuracy: 0.6409\n","Training loss (for one batch) at step 20: 345.5780, Accuracy: 0.6452\n","Training loss (for one batch) at step 30: 369.8271, Accuracy: 0.6435\n","Training loss (for one batch) at step 40: 350.8461, Accuracy: 0.6480\n","Training loss (for one batch) at step 50: 328.7591, Accuracy: 0.6496\n","Training loss (for one batch) at step 60: 337.3630, Accuracy: 0.6507\n","Training loss (for one batch) at step 70: 353.2992, Accuracy: 0.6532\n","Training loss (for one batch) at step 80: 339.7627, Accuracy: 0.6507\n","Training loss (for one batch) at step 90: 343.6734, Accuracy: 0.6531\n","Training loss (for one batch) at step 100: 328.7410, Accuracy: 0.6539\n","Training loss (for one batch) at step 110: 336.5019, Accuracy: 0.6555\n","Training loss (for one batch) at step 120: 358.9889, Accuracy: 0.6552\n","Training loss (for one batch) at step 130: 356.4265, Accuracy: 0.6574\n","Training loss (for one batch) at step 140: 341.4756, Accuracy: 0.6568\n","---- Training ----\n","Training loss: 309.4047\n","Training acc over epoch: 0.6577\n","---- Validation ----\n","Validation loss: 72.5334\n","Validation acc: 0.6738\n","Time taken: 58.16s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 349.3900, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 353.6425, Accuracy: 0.6827\n","Training loss (for one batch) at step 20: 338.1913, Accuracy: 0.6838\n","Training loss (for one batch) at step 30: 352.6078, Accuracy: 0.6768\n","Training loss (for one batch) at step 40: 337.3972, Accuracy: 0.6771\n","Training loss (for one batch) at step 50: 334.1714, Accuracy: 0.6720\n","Training loss (for one batch) at step 60: 340.6770, Accuracy: 0.6736\n","Training loss (for one batch) at step 70: 357.9701, Accuracy: 0.6777\n","Training loss (for one batch) at step 80: 349.0154, Accuracy: 0.6758\n","Training loss (for one batch) at step 90: 333.3956, Accuracy: 0.6747\n","Training loss (for one batch) at step 100: 320.8929, Accuracy: 0.6759\n","Training loss (for one batch) at step 110: 341.8129, Accuracy: 0.6752\n","Training loss (for one batch) at step 120: 330.9146, Accuracy: 0.6758\n","Training loss (for one batch) at step 130: 337.1300, Accuracy: 0.6757\n","Training loss (for one batch) at step 140: 355.7198, Accuracy: 0.6757\n","---- Training ----\n","Training loss: 325.2822\n","Training acc over epoch: 0.6769\n","---- Validation ----\n","Validation loss: 72.3226\n","Validation acc: 0.6824\n","Time taken: 58.91s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 337.3405, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 324.9061, Accuracy: 0.6945\n","Training loss (for one batch) at step 20: 343.8087, Accuracy: 0.6943\n","Training loss (for one batch) at step 30: 339.8022, Accuracy: 0.7026\n","Training loss (for one batch) at step 40: 331.7149, Accuracy: 0.7032\n","Training loss (for one batch) at step 50: 328.3177, Accuracy: 0.7049\n","Training loss (for one batch) at step 60: 327.9731, Accuracy: 0.7093\n","Training loss (for one batch) at step 70: 334.9857, Accuracy: 0.7068\n","Training loss (for one batch) at step 80: 330.8259, Accuracy: 0.7044\n","Training loss (for one batch) at step 90: 328.1377, Accuracy: 0.7030\n","Training loss (for one batch) at step 100: 329.4711, Accuracy: 0.7018\n","Training loss (for one batch) at step 110: 299.5565, Accuracy: 0.7007\n","Training loss (for one batch) at step 120: 318.4053, Accuracy: 0.7011\n","Training loss (for one batch) at step 130: 321.3568, Accuracy: 0.6998\n","Training loss (for one batch) at step 140: 333.7498, Accuracy: 0.7011\n","---- Training ----\n","Training loss: 290.1730\n","Training acc over epoch: 0.7006\n","---- Validation ----\n","Validation loss: 66.3156\n","Validation acc: 0.7050\n","Time taken: 58.51s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 329.1184, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 323.2693, Accuracy: 0.7236\n","Training loss (for one batch) at step 20: 318.1942, Accuracy: 0.7224\n","Training loss (for one batch) at step 30: 338.2969, Accuracy: 0.7171\n","Training loss (for one batch) at step 40: 318.0581, Accuracy: 0.7132\n","Training loss (for one batch) at step 50: 320.3927, Accuracy: 0.7133\n","Training loss (for one batch) at step 60: 317.8864, Accuracy: 0.7116\n","Training loss (for one batch) at step 70: 308.8051, Accuracy: 0.7148\n","Training loss (for one batch) at step 80: 328.2972, Accuracy: 0.7125\n","Training loss (for one batch) at step 90: 348.6631, Accuracy: 0.7090\n","Training loss (for one batch) at step 100: 311.0336, Accuracy: 0.7101\n","Training loss (for one batch) at step 110: 306.7491, Accuracy: 0.7123\n","Training loss (for one batch) at step 120: 316.0001, Accuracy: 0.7126\n","Training loss (for one batch) at step 130: 333.5078, Accuracy: 0.7108\n","Training loss (for one batch) at step 140: 328.9130, Accuracy: 0.7107\n","---- Training ----\n","Training loss: 280.2648\n","Training acc over epoch: 0.7099\n","---- Validation ----\n","Validation loss: 71.5815\n","Validation acc: 0.7187\n","Time taken: 58.58s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 312.1638, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 301.7016, Accuracy: 0.7264\n","Training loss (for one batch) at step 20: 326.5445, Accuracy: 0.7314\n","Training loss (for one batch) at step 30: 320.6260, Accuracy: 0.7323\n","Training loss (for one batch) at step 40: 311.9467, Accuracy: 0.7298\n","Training loss (for one batch) at step 50: 300.1324, Accuracy: 0.7331\n","Training loss (for one batch) at step 60: 282.2437, Accuracy: 0.7357\n","Training loss (for one batch) at step 70: 328.4769, Accuracy: 0.7337\n","Training loss (for one batch) at step 80: 319.2025, Accuracy: 0.7301\n","Training loss (for one batch) at step 90: 331.1868, Accuracy: 0.7290\n","Training loss (for one batch) at step 100: 313.5579, Accuracy: 0.7271\n","Training loss (for one batch) at step 110: 321.9979, Accuracy: 0.7267\n","Training loss (for one batch) at step 120: 322.5575, Accuracy: 0.7279\n","Training loss (for one batch) at step 130: 323.5835, Accuracy: 0.7285\n","Training loss (for one batch) at step 140: 323.3476, Accuracy: 0.7272\n","---- Training ----\n","Training loss: 298.2424\n","Training acc over epoch: 0.7266\n","---- Validation ----\n","Validation loss: 77.0843\n","Validation acc: 0.7171\n","Time taken: 58.87s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 316.2715, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 304.1441, Accuracy: 0.7409\n","Training loss (for one batch) at step 20: 325.1244, Accuracy: 0.7505\n","Training loss (for one batch) at step 30: 310.0576, Accuracy: 0.7484\n","Training loss (for one batch) at step 40: 315.5981, Accuracy: 0.7451\n","Training loss (for one batch) at step 50: 313.5701, Accuracy: 0.7422\n","Training loss (for one batch) at step 60: 315.1600, Accuracy: 0.7402\n","Training loss (for one batch) at step 70: 302.1552, Accuracy: 0.7392\n","Training loss (for one batch) at step 80: 317.1034, Accuracy: 0.7393\n","Training loss (for one batch) at step 90: 296.2130, Accuracy: 0.7367\n","Training loss (for one batch) at step 100: 324.4412, Accuracy: 0.7372\n","Training loss (for one batch) at step 110: 306.8328, Accuracy: 0.7379\n","Training loss (for one batch) at step 120: 315.8658, Accuracy: 0.7392\n","Training loss (for one batch) at step 130: 302.4374, Accuracy: 0.7398\n","Training loss (for one batch) at step 140: 304.0374, Accuracy: 0.7391\n","---- Training ----\n","Training loss: 274.4680\n","Training acc over epoch: 0.7382\n","---- Validation ----\n","Validation loss: 75.6183\n","Validation acc: 0.6873\n","Time taken: 60.11s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 304.6916, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 288.2548, Accuracy: 0.7545\n","Training loss (for one batch) at step 20: 313.5726, Accuracy: 0.7519\n","Training loss (for one batch) at step 30: 307.4376, Accuracy: 0.7474\n","Training loss (for one batch) at step 40: 302.2860, Accuracy: 0.7473\n","Training loss (for one batch) at step 50: 307.6369, Accuracy: 0.7531\n","Training loss (for one batch) at step 60: 308.1872, Accuracy: 0.7534\n","Training loss (for one batch) at step 70: 300.0274, Accuracy: 0.7527\n","Training loss (for one batch) at step 80: 309.5399, Accuracy: 0.7510\n","Training loss (for one batch) at step 90: 329.8799, Accuracy: 0.7478\n","Training loss (for one batch) at step 100: 299.7973, Accuracy: 0.7477\n","Training loss (for one batch) at step 110: 325.7569, Accuracy: 0.7474\n","Training loss (for one batch) at step 120: 308.2863, Accuracy: 0.7474\n","Training loss (for one batch) at step 130: 302.5773, Accuracy: 0.7494\n","Training loss (for one batch) at step 140: 320.9933, Accuracy: 0.7488\n","---- Training ----\n","Training loss: 275.5373\n","Training acc over epoch: 0.7485\n","---- Validation ----\n","Validation loss: 69.2700\n","Validation acc: 0.7297\n","Time taken: 62.19s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 297.1113, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 300.6179, Accuracy: 0.7627\n","Training loss (for one batch) at step 20: 301.5667, Accuracy: 0.7705\n","Training loss (for one batch) at step 30: 304.5979, Accuracy: 0.7681\n","Training loss (for one batch) at step 40: 296.0582, Accuracy: 0.7673\n","Training loss (for one batch) at step 50: 294.1250, Accuracy: 0.7673\n","Training loss (for one batch) at step 60: 301.8784, Accuracy: 0.7693\n","Training loss (for one batch) at step 70: 301.7025, Accuracy: 0.7662\n","Training loss (for one batch) at step 80: 313.1403, Accuracy: 0.7643\n","Training loss (for one batch) at step 90: 287.2819, Accuracy: 0.7660\n","Training loss (for one batch) at step 100: 294.6789, Accuracy: 0.7647\n","Training loss (for one batch) at step 110: 305.4336, Accuracy: 0.7644\n","Training loss (for one batch) at step 120: 284.1743, Accuracy: 0.7645\n","Training loss (for one batch) at step 130: 332.9721, Accuracy: 0.7643\n","Training loss (for one batch) at step 140: 322.5663, Accuracy: 0.7626\n","---- Training ----\n","Training loss: 278.8296\n","Training acc over epoch: 0.7618\n","---- Validation ----\n","Validation loss: 70.1846\n","Validation acc: 0.7257\n","Time taken: 61.28s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 300.6002, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 317.1957, Accuracy: 0.7855\n","Training loss (for one batch) at step 20: 302.4993, Accuracy: 0.7767\n","Training loss (for one batch) at step 30: 302.6344, Accuracy: 0.7774\n","Training loss (for one batch) at step 40: 301.7823, Accuracy: 0.7749\n","Training loss (for one batch) at step 50: 278.9137, Accuracy: 0.7731\n","Training loss (for one batch) at step 60: 282.1538, Accuracy: 0.7754\n","Training loss (for one batch) at step 70: 282.0321, Accuracy: 0.7718\n","Training loss (for one batch) at step 80: 305.1096, Accuracy: 0.7711\n","Training loss (for one batch) at step 90: 300.6519, Accuracy: 0.7693\n","Training loss (for one batch) at step 100: 296.7806, Accuracy: 0.7692\n","Training loss (for one batch) at step 110: 296.3461, Accuracy: 0.7704\n","Training loss (for one batch) at step 120: 284.5640, Accuracy: 0.7717\n","Training loss (for one batch) at step 130: 314.9088, Accuracy: 0.7705\n","Training loss (for one batch) at step 140: 305.2193, Accuracy: 0.7685\n","---- Training ----\n","Training loss: 272.8258\n","Training acc over epoch: 0.7684\n","---- Validation ----\n","Validation loss: 67.2181\n","Validation acc: 0.7053\n","Time taken: 63.36s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 290.6827, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 279.9060, Accuracy: 0.7891\n","Training loss (for one batch) at step 20: 279.2044, Accuracy: 0.7957\n","Training loss (for one batch) at step 30: 290.4339, Accuracy: 0.7868\n","Training loss (for one batch) at step 40: 278.5830, Accuracy: 0.7863\n","Training loss (for one batch) at step 50: 312.4780, Accuracy: 0.7835\n","Training loss (for one batch) at step 60: 270.9773, Accuracy: 0.7869\n","Training loss (for one batch) at step 70: 293.8774, Accuracy: 0.7879\n","Training loss (for one batch) at step 80: 309.4857, Accuracy: 0.7847\n","Training loss (for one batch) at step 90: 289.8896, Accuracy: 0.7840\n","Training loss (for one batch) at step 100: 289.4255, Accuracy: 0.7840\n","Training loss (for one batch) at step 110: 294.2259, Accuracy: 0.7825\n","Training loss (for one batch) at step 120: 300.5164, Accuracy: 0.7801\n","Training loss (for one batch) at step 130: 285.0321, Accuracy: 0.7792\n","Training loss (for one batch) at step 140: 293.0036, Accuracy: 0.7791\n","---- Training ----\n","Training loss: 255.9895\n","Training acc over epoch: 0.7789\n","---- Validation ----\n","Validation loss: 67.9607\n","Validation acc: 0.7235\n","Time taken: 63.39s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 294.2115, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 291.7189, Accuracy: 0.7855\n","Training loss (for one batch) at step 20: 284.9566, Accuracy: 0.7900\n","Training loss (for one batch) at step 30: 284.8986, Accuracy: 0.7929\n","Training loss (for one batch) at step 40: 292.0795, Accuracy: 0.7927\n","Training loss (for one batch) at step 50: 288.6299, Accuracy: 0.7894\n","Training loss (for one batch) at step 60: 276.9731, Accuracy: 0.7920\n","Training loss (for one batch) at step 70: 284.7023, Accuracy: 0.7892\n","Training loss (for one batch) at step 80: 308.8223, Accuracy: 0.7856\n","Training loss (for one batch) at step 90: 302.4090, Accuracy: 0.7826\n","Training loss (for one batch) at step 100: 278.1125, Accuracy: 0.7817\n","Training loss (for one batch) at step 110: 290.5946, Accuracy: 0.7820\n","Training loss (for one batch) at step 120: 295.2798, Accuracy: 0.7826\n","Training loss (for one batch) at step 130: 282.2979, Accuracy: 0.7828\n","Training loss (for one batch) at step 140: 291.6508, Accuracy: 0.7809\n","---- Training ----\n","Training loss: 265.9035\n","Training acc over epoch: 0.7812\n","---- Validation ----\n","Validation loss: 68.4405\n","Validation acc: 0.7311\n","Time taken: 63.31s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 303.6495, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 292.6938, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 275.9674, Accuracy: 0.8105\n","Training loss (for one batch) at step 30: 289.4449, Accuracy: 0.8061\n","Training loss (for one batch) at step 40: 266.6738, Accuracy: 0.8061\n","Training loss (for one batch) at step 50: 291.4922, Accuracy: 0.8002\n","Training loss (for one batch) at step 60: 277.8562, Accuracy: 0.8025\n","Training loss (for one batch) at step 70: 301.3664, Accuracy: 0.8004\n","Training loss (for one batch) at step 80: 285.8127, Accuracy: 0.7974\n","Training loss (for one batch) at step 90: 280.1414, Accuracy: 0.7975\n","Training loss (for one batch) at step 100: 291.7773, Accuracy: 0.7959\n","Training loss (for one batch) at step 110: 279.0008, Accuracy: 0.7959\n","Training loss (for one batch) at step 120: 296.1961, Accuracy: 0.7950\n","Training loss (for one batch) at step 130: 295.0339, Accuracy: 0.7927\n","Training loss (for one batch) at step 140: 309.7917, Accuracy: 0.7933\n","---- Training ----\n","Training loss: 259.6342\n","Training acc over epoch: 0.7929\n","---- Validation ----\n","Validation loss: 73.5063\n","Validation acc: 0.7214\n","Time taken: 66.47s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 292.3809, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 268.3986, Accuracy: 0.8027\n","Training loss (for one batch) at step 20: 274.4562, Accuracy: 0.8052\n","Training loss (for one batch) at step 30: 296.5916, Accuracy: 0.8019\n","Training loss (for one batch) at step 40: 280.9526, Accuracy: 0.8017\n","Training loss (for one batch) at step 50: 279.9615, Accuracy: 0.8012\n","Training loss (for one batch) at step 60: 282.1043, Accuracy: 0.8038\n","Training loss (for one batch) at step 70: 264.8644, Accuracy: 0.8034\n","Training loss (for one batch) at step 80: 285.1144, Accuracy: 0.8037\n","Training loss (for one batch) at step 90: 290.9933, Accuracy: 0.8022\n","Training loss (for one batch) at step 100: 281.9149, Accuracy: 0.8010\n","Training loss (for one batch) at step 110: 283.5230, Accuracy: 0.7999\n","Training loss (for one batch) at step 120: 283.2804, Accuracy: 0.8009\n","Training loss (for one batch) at step 130: 278.2902, Accuracy: 0.8006\n","Training loss (for one batch) at step 140: 292.0033, Accuracy: 0.7973\n","---- Training ----\n","Training loss: 251.3116\n","Training acc over epoch: 0.7969\n","---- Validation ----\n","Validation loss: 70.8645\n","Validation acc: 0.7372\n","Time taken: 78.97s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 284.0319, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 280.7471, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 276.9044, Accuracy: 0.8133\n","Training loss (for one batch) at step 30: 278.9291, Accuracy: 0.8094\n","Training loss (for one batch) at step 40: 278.7912, Accuracy: 0.8117\n","Training loss (for one batch) at step 50: 278.6562, Accuracy: 0.8151\n","Training loss (for one batch) at step 60: 262.9364, Accuracy: 0.8090\n","Training loss (for one batch) at step 70: 279.2637, Accuracy: 0.8086\n","Training loss (for one batch) at step 80: 279.7047, Accuracy: 0.8042\n","Training loss (for one batch) at step 90: 276.4367, Accuracy: 0.8037\n","Training loss (for one batch) at step 100: 282.4301, Accuracy: 0.8034\n","Training loss (for one batch) at step 110: 282.1104, Accuracy: 0.8027\n","Training loss (for one batch) at step 120: 273.3610, Accuracy: 0.8011\n","Training loss (for one batch) at step 130: 279.3221, Accuracy: 0.8008\n","Training loss (for one batch) at step 140: 262.8594, Accuracy: 0.8016\n","---- Training ----\n","Training loss: 240.7503\n","Training acc over epoch: 0.8012\n","---- Validation ----\n","Validation loss: 62.1120\n","Validation acc: 0.7211\n","Time taken: 71.98s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 282.7405, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 271.1815, Accuracy: 0.8182\n","Training loss (for one batch) at step 20: 274.1656, Accuracy: 0.8110\n","Training loss (for one batch) at step 30: 269.6262, Accuracy: 0.8110\n","Training loss (for one batch) at step 40: 264.8986, Accuracy: 0.8146\n","Training loss (for one batch) at step 50: 251.3193, Accuracy: 0.8169\n","Training loss (for one batch) at step 60: 274.3357, Accuracy: 0.8152\n","Training loss (for one batch) at step 70: 271.8763, Accuracy: 0.8151\n","Training loss (for one batch) at step 80: 274.1573, Accuracy: 0.8120\n","Training loss (for one batch) at step 90: 296.1013, Accuracy: 0.8109\n","Training loss (for one batch) at step 100: 279.0316, Accuracy: 0.8101\n","Training loss (for one batch) at step 110: 275.1507, Accuracy: 0.8097\n","Training loss (for one batch) at step 120: 268.8346, Accuracy: 0.8108\n","Training loss (for one batch) at step 130: 276.1705, Accuracy: 0.8075\n","Training loss (for one batch) at step 140: 273.9737, Accuracy: 0.8082\n","---- Training ----\n","Training loss: 242.4499\n","Training acc over epoch: 0.8086\n","---- Validation ----\n","Validation loss: 72.9416\n","Validation acc: 0.7214\n","Time taken: 69.72s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 271.2918, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 265.4796, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 266.0730, Accuracy: 0.8333\n","Training loss (for one batch) at step 30: 299.5827, Accuracy: 0.8310\n","Training loss (for one batch) at step 40: 256.2227, Accuracy: 0.8227\n","Training loss (for one batch) at step 50: 257.8638, Accuracy: 0.8241\n","Training loss (for one batch) at step 60: 272.8303, Accuracy: 0.8238\n","Training loss (for one batch) at step 70: 288.4526, Accuracy: 0.8217\n","Training loss (for one batch) at step 80: 273.1327, Accuracy: 0.8175\n","Training loss (for one batch) at step 90: 261.0544, Accuracy: 0.8148\n","Training loss (for one batch) at step 100: 267.9423, Accuracy: 0.8132\n","Training loss (for one batch) at step 110: 269.0757, Accuracy: 0.8150\n","Training loss (for one batch) at step 120: 263.3021, Accuracy: 0.8138\n","Training loss (for one batch) at step 130: 266.6402, Accuracy: 0.8133\n","Training loss (for one batch) at step 140: 267.9525, Accuracy: 0.8132\n","---- Training ----\n","Training loss: 248.3144\n","Training acc over epoch: 0.8127\n","---- Validation ----\n","Validation loss: 67.1001\n","Validation acc: 0.7386\n","Time taken: 69.36s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 273.2767, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 276.4742, Accuracy: 0.8300\n","Training loss (for one batch) at step 20: 256.4907, Accuracy: 0.8219\n","Training loss (for one batch) at step 30: 256.4679, Accuracy: 0.8142\n","Training loss (for one batch) at step 40: 265.1818, Accuracy: 0.8105\n","Training loss (for one batch) at step 50: 271.8712, Accuracy: 0.8141\n","Training loss (for one batch) at step 60: 289.7537, Accuracy: 0.8116\n","Training loss (for one batch) at step 70: 256.5101, Accuracy: 0.8132\n","Training loss (for one batch) at step 80: 287.4291, Accuracy: 0.8112\n","Training loss (for one batch) at step 90: 278.7672, Accuracy: 0.8087\n","Training loss (for one batch) at step 100: 256.2296, Accuracy: 0.8092\n","Training loss (for one batch) at step 110: 259.0880, Accuracy: 0.8099\n","Training loss (for one batch) at step 120: 263.2073, Accuracy: 0.8106\n","Training loss (for one batch) at step 130: 289.2071, Accuracy: 0.8099\n","Training loss (for one batch) at step 140: 273.6744, Accuracy: 0.8092\n","---- Training ----\n","Training loss: 241.0550\n","Training acc over epoch: 0.8094\n","---- Validation ----\n","Validation loss: 74.1026\n","Validation acc: 0.7136\n","Time taken: 67.80s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 263.4754, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 273.6353, Accuracy: 0.8127\n","Training loss (for one batch) at step 20: 252.3590, Accuracy: 0.8310\n","Training loss (for one batch) at step 30: 262.0111, Accuracy: 0.8329\n","Training loss (for one batch) at step 40: 259.3956, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 269.1504, Accuracy: 0.8302\n","Training loss (for one batch) at step 60: 256.0605, Accuracy: 0.8282\n","Training loss (for one batch) at step 70: 272.4451, Accuracy: 0.8270\n","Training loss (for one batch) at step 80: 257.7507, Accuracy: 0.8235\n","Training loss (for one batch) at step 90: 266.4801, Accuracy: 0.8208\n","Training loss (for one batch) at step 100: 271.8589, Accuracy: 0.8189\n","Training loss (for one batch) at step 110: 250.0699, Accuracy: 0.8182\n","Training loss (for one batch) at step 120: 274.8887, Accuracy: 0.8187\n","Training loss (for one batch) at step 130: 268.7538, Accuracy: 0.8182\n","Training loss (for one batch) at step 140: 272.3326, Accuracy: 0.8172\n","---- Training ----\n","Training loss: 218.7140\n","Training acc over epoch: 0.8176\n","---- Validation ----\n","Validation loss: 60.1897\n","Validation acc: 0.7303\n","Time taken: 67.87s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 267.1765, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 257.2922, Accuracy: 0.8255\n","Training loss (for one batch) at step 20: 279.3366, Accuracy: 0.8295\n","Training loss (for one batch) at step 30: 257.6978, Accuracy: 0.8287\n","Training loss (for one batch) at step 40: 258.4857, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 261.2383, Accuracy: 0.8337\n","Training loss (for one batch) at step 60: 265.6647, Accuracy: 0.8338\n","Training loss (for one batch) at step 70: 264.5196, Accuracy: 0.8334\n","Training loss (for one batch) at step 80: 267.9633, Accuracy: 0.8305\n","Training loss (for one batch) at step 90: 258.6729, Accuracy: 0.8271\n","Training loss (for one batch) at step 100: 270.1873, Accuracy: 0.8272\n","Training loss (for one batch) at step 110: 268.6890, Accuracy: 0.8275\n","Training loss (for one batch) at step 120: 269.5628, Accuracy: 0.8266\n","Training loss (for one batch) at step 130: 302.5329, Accuracy: 0.8264\n","Training loss (for one batch) at step 140: 265.7363, Accuracy: 0.8253\n","---- Training ----\n","Training loss: 243.8936\n","Training acc over epoch: 0.8240\n","---- Validation ----\n","Validation loss: 65.9794\n","Validation acc: 0.7431\n","Time taken: 66.96s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 253.4931, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 246.4455, Accuracy: 0.8200\n","Training loss (for one batch) at step 20: 259.3642, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 262.8441, Accuracy: 0.8245\n","Training loss (for one batch) at step 40: 245.1869, Accuracy: 0.8256\n","Training loss (for one batch) at step 50: 261.4973, Accuracy: 0.8257\n","Training loss (for one batch) at step 60: 258.9357, Accuracy: 0.8254\n","Training loss (for one batch) at step 70: 261.4117, Accuracy: 0.8268\n","Training loss (for one batch) at step 80: 258.4103, Accuracy: 0.8268\n","Training loss (for one batch) at step 90: 271.4064, Accuracy: 0.8235\n","Training loss (for one batch) at step 100: 244.5797, Accuracy: 0.8225\n","Training loss (for one batch) at step 110: 264.8665, Accuracy: 0.8224\n","Training loss (for one batch) at step 120: 248.4069, Accuracy: 0.8240\n","Training loss (for one batch) at step 130: 255.7404, Accuracy: 0.8229\n","Training loss (for one batch) at step 140: 257.9787, Accuracy: 0.8229\n","---- Training ----\n","Training loss: 232.1566\n","Training acc over epoch: 0.8231\n","---- Validation ----\n","Validation loss: 93.6913\n","Validation acc: 0.7372\n","Time taken: 67.73s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 256.8611, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 246.8127, Accuracy: 0.8300\n","Training loss (for one batch) at step 20: 255.5878, Accuracy: 0.8314\n","Training loss (for one batch) at step 30: 258.0337, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 247.8786, Accuracy: 0.8273\n","Training loss (for one batch) at step 50: 260.4521, Accuracy: 0.8290\n","Training loss (for one batch) at step 60: 270.1724, Accuracy: 0.8307\n","Training loss (for one batch) at step 70: 239.5860, Accuracy: 0.8339\n","Training loss (for one batch) at step 80: 247.2137, Accuracy: 0.8325\n","Training loss (for one batch) at step 90: 274.9747, Accuracy: 0.8322\n","Training loss (for one batch) at step 100: 238.0756, Accuracy: 0.8312\n","Training loss (for one batch) at step 110: 256.0657, Accuracy: 0.8302\n","Training loss (for one batch) at step 120: 242.7278, Accuracy: 0.8311\n","Training loss (for one batch) at step 130: 257.7177, Accuracy: 0.8298\n","Training loss (for one batch) at step 140: 263.8454, Accuracy: 0.8296\n","---- Training ----\n","Training loss: 223.1092\n","Training acc over epoch: 0.8300\n","---- Validation ----\n","Validation loss: 66.8415\n","Validation acc: 0.7429\n","Time taken: 69.32s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 278.4279, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 262.1873, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 260.9376, Accuracy: 0.8424\n","Training loss (for one batch) at step 30: 269.6154, Accuracy: 0.8355\n","Training loss (for one batch) at step 40: 239.2654, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 248.3800, Accuracy: 0.8394\n","Training loss (for one batch) at step 60: 259.9914, Accuracy: 0.8397\n","Training loss (for one batch) at step 70: 255.0090, Accuracy: 0.8375\n","Training loss (for one batch) at step 80: 280.5760, Accuracy: 0.8347\n","Training loss (for one batch) at step 90: 236.8332, Accuracy: 0.8353\n","Training loss (for one batch) at step 100: 273.0164, Accuracy: 0.8327\n","Training loss (for one batch) at step 110: 256.6340, Accuracy: 0.8344\n","Training loss (for one batch) at step 120: 251.1234, Accuracy: 0.8327\n","Training loss (for one batch) at step 130: 246.3402, Accuracy: 0.8326\n","Training loss (for one batch) at step 140: 250.4813, Accuracy: 0.8327\n","---- Training ----\n","Training loss: 231.5829\n","Training acc over epoch: 0.8317\n","---- Validation ----\n","Validation loss: 64.6319\n","Validation acc: 0.7445\n","Time taken: 66.44s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 242.8296, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 245.2188, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 247.6924, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 275.5354, Accuracy: 0.8429\n","Training loss (for one batch) at step 40: 260.1827, Accuracy: 0.8424\n","Training loss (for one batch) at step 50: 246.2232, Accuracy: 0.8429\n","Training loss (for one batch) at step 60: 236.9908, Accuracy: 0.8446\n","Training loss (for one batch) at step 70: 259.4993, Accuracy: 0.8411\n","Training loss (for one batch) at step 80: 237.4206, Accuracy: 0.8394\n","Training loss (for one batch) at step 90: 258.8099, Accuracy: 0.8397\n","Training loss (for one batch) at step 100: 244.1052, Accuracy: 0.8387\n","Training loss (for one batch) at step 110: 214.1281, Accuracy: 0.8375\n","Training loss (for one batch) at step 120: 273.3990, Accuracy: 0.8369\n","Training loss (for one batch) at step 130: 277.2602, Accuracy: 0.8351\n","Training loss (for one batch) at step 140: 245.8107, Accuracy: 0.8344\n","---- Training ----\n","Training loss: 211.6300\n","Training acc over epoch: 0.8343\n","---- Validation ----\n","Validation loss: 66.7979\n","Validation acc: 0.7442\n","Time taken: 68.17s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 223.3597, Accuracy: 0.9500\n","Training loss (for one batch) at step 10: 252.7291, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 234.9372, Accuracy: 0.8333\n","Training loss (for one batch) at step 30: 236.9168, Accuracy: 0.8345\n","Training loss (for one batch) at step 40: 253.7120, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 256.4134, Accuracy: 0.8375\n","Training loss (for one batch) at step 60: 243.0329, Accuracy: 0.8382\n","Training loss (for one batch) at step 70: 238.6723, Accuracy: 0.8386\n","Training loss (for one batch) at step 80: 259.7624, Accuracy: 0.8364\n","Training loss (for one batch) at step 90: 228.6145, Accuracy: 0.8343\n","Training loss (for one batch) at step 100: 225.2817, Accuracy: 0.8345\n","Training loss (for one batch) at step 110: 240.6514, Accuracy: 0.8359\n","Training loss (for one batch) at step 120: 237.1634, Accuracy: 0.8363\n","Training loss (for one batch) at step 130: 231.5793, Accuracy: 0.8364\n","Training loss (for one batch) at step 140: 232.8602, Accuracy: 0.8357\n","---- Training ----\n","Training loss: 225.5976\n","Training acc over epoch: 0.8351\n","---- Validation ----\n","Validation loss: 75.4099\n","Validation acc: 0.7238\n","Time taken: 66.76s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 246.9929, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 219.1791, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 249.6469, Accuracy: 0.8471\n","Training loss (for one batch) at step 30: 234.5275, Accuracy: 0.8481\n","Training loss (for one batch) at step 40: 258.4104, Accuracy: 0.8473\n","Training loss (for one batch) at step 50: 265.8637, Accuracy: 0.8437\n","Training loss (for one batch) at step 60: 232.5522, Accuracy: 0.8451\n","Training loss (for one batch) at step 70: 246.9565, Accuracy: 0.8430\n","Training loss (for one batch) at step 80: 242.7634, Accuracy: 0.8427\n","Training loss (for one batch) at step 90: 266.0863, Accuracy: 0.8396\n","Training loss (for one batch) at step 100: 230.8456, Accuracy: 0.8401\n","Training loss (for one batch) at step 110: 239.2389, Accuracy: 0.8414\n","Training loss (for one batch) at step 120: 250.1956, Accuracy: 0.8409\n","Training loss (for one batch) at step 130: 241.2181, Accuracy: 0.8415\n","Training loss (for one batch) at step 140: 237.7110, Accuracy: 0.8395\n","---- Training ----\n","Training loss: 217.1647\n","Training acc over epoch: 0.8395\n","---- Validation ----\n","Validation loss: 70.1898\n","Validation acc: 0.7477\n","Time taken: 67.16s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 238.9252, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 243.8648, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 241.5295, Accuracy: 0.8486\n","Training loss (for one batch) at step 30: 227.6915, Accuracy: 0.8535\n","Training loss (for one batch) at step 40: 225.8613, Accuracy: 0.8507\n","Training loss (for one batch) at step 50: 238.8187, Accuracy: 0.8504\n","Training loss (for one batch) at step 60: 240.5499, Accuracy: 0.8469\n","Training loss (for one batch) at step 70: 231.4587, Accuracy: 0.8480\n","Training loss (for one batch) at step 80: 251.2091, Accuracy: 0.8457\n","Training loss (for one batch) at step 90: 243.5055, Accuracy: 0.8442\n","Training loss (for one batch) at step 100: 236.3125, Accuracy: 0.8440\n","Training loss (for one batch) at step 110: 238.9787, Accuracy: 0.8450\n","Training loss (for one batch) at step 120: 233.0077, Accuracy: 0.8455\n","Training loss (for one batch) at step 130: 238.9308, Accuracy: 0.8448\n","Training loss (for one batch) at step 140: 256.0815, Accuracy: 0.8443\n","---- Training ----\n","Training loss: 220.9449\n","Training acc over epoch: 0.8437\n","---- Validation ----\n","Validation loss: 67.3767\n","Validation acc: 0.7509\n","Time taken: 67.71s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 216.3538, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 247.1378, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 235.5950, Accuracy: 0.8486\n","Training loss (for one batch) at step 30: 255.3487, Accuracy: 0.8439\n","Training loss (for one batch) at step 40: 242.0302, Accuracy: 0.8485\n","Training loss (for one batch) at step 50: 245.0492, Accuracy: 0.8506\n","Training loss (for one batch) at step 60: 235.6452, Accuracy: 0.8497\n","Training loss (for one batch) at step 70: 224.7468, Accuracy: 0.8497\n","Training loss (for one batch) at step 80: 232.9490, Accuracy: 0.8463\n","Training loss (for one batch) at step 90: 227.0915, Accuracy: 0.8456\n","Training loss (for one batch) at step 100: 248.4804, Accuracy: 0.8444\n","Training loss (for one batch) at step 110: 252.1366, Accuracy: 0.8427\n","Training loss (for one batch) at step 120: 229.4608, Accuracy: 0.8421\n","Training loss (for one batch) at step 130: 246.9330, Accuracy: 0.8418\n","Training loss (for one batch) at step 140: 242.1815, Accuracy: 0.8404\n","---- Training ----\n","Training loss: 205.6339\n","Training acc over epoch: 0.8418\n","---- Validation ----\n","Validation loss: 75.6080\n","Validation acc: 0.7405\n","Time taken: 69.32s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 233.3682, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 255.5298, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 257.5085, Accuracy: 0.8448\n","Training loss (for one batch) at step 30: 245.7526, Accuracy: 0.8481\n","Training loss (for one batch) at step 40: 230.3923, Accuracy: 0.8454\n","Training loss (for one batch) at step 50: 228.4948, Accuracy: 0.8494\n","Training loss (for one batch) at step 60: 244.0305, Accuracy: 0.8489\n","Training loss (for one batch) at step 70: 260.0940, Accuracy: 0.8494\n","Training loss (for one batch) at step 80: 232.9404, Accuracy: 0.8472\n","Training loss (for one batch) at step 90: 235.4927, Accuracy: 0.8447\n","Training loss (for one batch) at step 100: 237.8171, Accuracy: 0.8440\n","Training loss (for one batch) at step 110: 224.3257, Accuracy: 0.8431\n","Training loss (for one batch) at step 120: 242.0260, Accuracy: 0.8445\n","Training loss (for one batch) at step 130: 264.4606, Accuracy: 0.8441\n","Training loss (for one batch) at step 140: 239.1907, Accuracy: 0.8450\n","---- Training ----\n","Training loss: 217.7516\n","Training acc over epoch: 0.8443\n","---- Validation ----\n","Validation loss: 84.5131\n","Validation acc: 0.7407\n","Time taken: 68.39s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 216.4885, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 221.6921, Accuracy: 0.8536\n","Training loss (for one batch) at step 20: 239.2673, Accuracy: 0.8524\n","Training loss (for one batch) at step 30: 230.8830, Accuracy: 0.8542\n","Training loss (for one batch) at step 40: 227.5869, Accuracy: 0.8490\n","Training loss (for one batch) at step 50: 231.6962, Accuracy: 0.8522\n","Training loss (for one batch) at step 60: 230.0412, Accuracy: 0.8518\n","Training loss (for one batch) at step 70: 239.7722, Accuracy: 0.8501\n","Training loss (for one batch) at step 80: 241.5464, Accuracy: 0.8481\n","Training loss (for one batch) at step 90: 235.4116, Accuracy: 0.8481\n","Training loss (for one batch) at step 100: 208.7874, Accuracy: 0.8472\n","Training loss (for one batch) at step 110: 240.5688, Accuracy: 0.8478\n","Training loss (for one batch) at step 120: 242.2870, Accuracy: 0.8474\n","Training loss (for one batch) at step 130: 223.2198, Accuracy: 0.8469\n","Training loss (for one batch) at step 140: 238.3961, Accuracy: 0.8471\n","---- Training ----\n","Training loss: 215.5352\n","Training acc over epoch: 0.8468\n","---- Validation ----\n","Validation loss: 68.8896\n","Validation acc: 0.7308\n","Time taken: 67.93s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 220.0627, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 243.2468, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 236.9111, Accuracy: 0.8500\n","Training loss (for one batch) at step 30: 219.8075, Accuracy: 0.8497\n","Training loss (for one batch) at step 40: 224.0653, Accuracy: 0.8517\n","Training loss (for one batch) at step 50: 247.3477, Accuracy: 0.8533\n","Training loss (for one batch) at step 60: 238.0816, Accuracy: 0.8559\n","Training loss (for one batch) at step 70: 227.8209, Accuracy: 0.8556\n","Training loss (for one batch) at step 80: 236.7493, Accuracy: 0.8533\n","Training loss (for one batch) at step 90: 250.6701, Accuracy: 0.8515\n","Training loss (for one batch) at step 100: 245.1859, Accuracy: 0.8505\n","Training loss (for one batch) at step 110: 237.3576, Accuracy: 0.8511\n","Training loss (for one batch) at step 120: 247.0152, Accuracy: 0.8524\n","Training loss (for one batch) at step 130: 225.9743, Accuracy: 0.8524\n","Training loss (for one batch) at step 140: 242.6004, Accuracy: 0.8514\n","---- Training ----\n","Training loss: 216.5697\n","Training acc over epoch: 0.8506\n","---- Validation ----\n","Validation loss: 77.2240\n","Validation acc: 0.7225\n","Time taken: 68.61s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 245.5561, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 224.2067, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 255.2792, Accuracy: 0.8433\n","Training loss (for one batch) at step 30: 218.2554, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 225.0865, Accuracy: 0.8500\n","Training loss (for one batch) at step 50: 244.4693, Accuracy: 0.8506\n","Training loss (for one batch) at step 60: 237.1833, Accuracy: 0.8533\n","Training loss (for one batch) at step 70: 232.3649, Accuracy: 0.8535\n","Training loss (for one batch) at step 80: 220.5940, Accuracy: 0.8516\n","Training loss (for one batch) at step 90: 223.6911, Accuracy: 0.8500\n","Training loss (for one batch) at step 100: 241.4411, Accuracy: 0.8503\n","Training loss (for one batch) at step 110: 224.2835, Accuracy: 0.8502\n","Training loss (for one batch) at step 120: 227.6758, Accuracy: 0.8502\n","Training loss (for one batch) at step 130: 240.0103, Accuracy: 0.8505\n","Training loss (for one batch) at step 140: 245.0793, Accuracy: 0.8499\n","---- Training ----\n","Training loss: 203.2873\n","Training acc over epoch: 0.8503\n","---- Validation ----\n","Validation loss: 81.0593\n","Validation acc: 0.7474\n","Time taken: 69.16s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 223.8455, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 232.9957, Accuracy: 0.8582\n","Training loss (for one batch) at step 20: 217.5623, Accuracy: 0.8562\n","Training loss (for one batch) at step 30: 235.5132, Accuracy: 0.8558\n","Training loss (for one batch) at step 40: 222.9053, Accuracy: 0.8534\n","Training loss (for one batch) at step 50: 233.8642, Accuracy: 0.8549\n","Training loss (for one batch) at step 60: 231.1838, Accuracy: 0.8561\n","Training loss (for one batch) at step 70: 232.7214, Accuracy: 0.8561\n","Training loss (for one batch) at step 80: 235.7414, Accuracy: 0.8530\n","Training loss (for one batch) at step 90: 240.3885, Accuracy: 0.8534\n","Training loss (for one batch) at step 100: 204.4941, Accuracy: 0.8531\n","Training loss (for one batch) at step 110: 213.7382, Accuracy: 0.8532\n","Training loss (for one batch) at step 120: 237.3631, Accuracy: 0.8532\n","Training loss (for one batch) at step 130: 218.6816, Accuracy: 0.8543\n","Training loss (for one batch) at step 140: 227.0184, Accuracy: 0.8535\n","---- Training ----\n","Training loss: 209.8217\n","Training acc over epoch: 0.8527\n","---- Validation ----\n","Validation loss: 82.1615\n","Validation acc: 0.7332\n","Time taken: 69.73s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 233.7570, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 222.2446, Accuracy: 0.8582\n","Training loss (for one batch) at step 20: 224.4451, Accuracy: 0.8543\n","Training loss (for one batch) at step 30: 229.0810, Accuracy: 0.8506\n","Training loss (for one batch) at step 40: 205.3588, Accuracy: 0.8566\n","Training loss (for one batch) at step 50: 222.1508, Accuracy: 0.8606\n","Training loss (for one batch) at step 60: 225.5108, Accuracy: 0.8600\n","Training loss (for one batch) at step 70: 246.8335, Accuracy: 0.8613\n","Training loss (for one batch) at step 80: 219.5020, Accuracy: 0.8590\n","Training loss (for one batch) at step 90: 238.4201, Accuracy: 0.8571\n","Training loss (for one batch) at step 100: 227.3662, Accuracy: 0.8567\n","Training loss (for one batch) at step 110: 220.6105, Accuracy: 0.8561\n","Training loss (for one batch) at step 120: 225.8094, Accuracy: 0.8555\n","Training loss (for one batch) at step 130: 202.4098, Accuracy: 0.8549\n","Training loss (for one batch) at step 140: 236.1616, Accuracy: 0.8552\n","---- Training ----\n","Training loss: 209.5884\n","Training acc over epoch: 0.8551\n","---- Validation ----\n","Validation loss: 62.5400\n","Validation acc: 0.7426\n","Time taken: 77.08s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 239.8829, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 215.9677, Accuracy: 0.8773\n","Training loss (for one batch) at step 20: 221.2799, Accuracy: 0.8695\n","Training loss (for one batch) at step 30: 236.5106, Accuracy: 0.8655\n","Training loss (for one batch) at step 40: 213.1169, Accuracy: 0.8661\n","Training loss (for one batch) at step 50: 198.4839, Accuracy: 0.8669\n","Training loss (for one batch) at step 60: 227.7730, Accuracy: 0.8633\n","Training loss (for one batch) at step 70: 224.2946, Accuracy: 0.8637\n","Training loss (for one batch) at step 80: 223.5732, Accuracy: 0.8614\n","Training loss (for one batch) at step 90: 225.0855, Accuracy: 0.8590\n","Training loss (for one batch) at step 100: 222.5273, Accuracy: 0.8586\n","Training loss (for one batch) at step 110: 210.7423, Accuracy: 0.8591\n","Training loss (for one batch) at step 120: 211.0435, Accuracy: 0.8581\n","Training loss (for one batch) at step 130: 241.1289, Accuracy: 0.8575\n","Training loss (for one batch) at step 140: 216.0604, Accuracy: 0.8580\n","---- Training ----\n","Training loss: 214.0002\n","Training acc over epoch: 0.8576\n","---- Validation ----\n","Validation loss: 74.6673\n","Validation acc: 0.7286\n","Time taken: 68.26s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 234.3828, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 210.2650, Accuracy: 0.8655\n","Training loss (for one batch) at step 20: 212.6222, Accuracy: 0.8514\n","Training loss (for one batch) at step 30: 215.1895, Accuracy: 0.8497\n","Training loss (for one batch) at step 40: 219.1353, Accuracy: 0.8502\n","Training loss (for one batch) at step 50: 212.2303, Accuracy: 0.8522\n","Training loss (for one batch) at step 60: 221.2934, Accuracy: 0.8531\n","Training loss (for one batch) at step 70: 220.0280, Accuracy: 0.8568\n","Training loss (for one batch) at step 80: 231.9480, Accuracy: 0.8547\n","Training loss (for one batch) at step 90: 230.8134, Accuracy: 0.8532\n","Training loss (for one batch) at step 100: 216.4325, Accuracy: 0.8536\n","Training loss (for one batch) at step 110: 241.7591, Accuracy: 0.8531\n","Training loss (for one batch) at step 120: 223.7300, Accuracy: 0.8533\n","Training loss (for one batch) at step 130: 227.6797, Accuracy: 0.8540\n","Training loss (for one batch) at step 140: 218.2517, Accuracy: 0.8538\n","---- Training ----\n","Training loss: 202.8358\n","Training acc over epoch: 0.8535\n","---- Validation ----\n","Validation loss: 87.8902\n","Validation acc: 0.7356\n","Time taken: 68.92s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 218.7935, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 211.7301, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 205.1611, Accuracy: 0.8533\n","Training loss (for one batch) at step 30: 199.9520, Accuracy: 0.8587\n","Training loss (for one batch) at step 40: 202.3734, Accuracy: 0.8627\n","Training loss (for one batch) at step 50: 220.6781, Accuracy: 0.8612\n","Training loss (for one batch) at step 60: 195.3227, Accuracy: 0.8618\n","Training loss (for one batch) at step 70: 247.6304, Accuracy: 0.8641\n","Training loss (for one batch) at step 80: 225.3118, Accuracy: 0.8611\n","Training loss (for one batch) at step 90: 232.2464, Accuracy: 0.8600\n","Training loss (for one batch) at step 100: 215.1433, Accuracy: 0.8604\n","Training loss (for one batch) at step 110: 206.7505, Accuracy: 0.8595\n","Training loss (for one batch) at step 120: 237.8394, Accuracy: 0.8587\n","Training loss (for one batch) at step 130: 232.0750, Accuracy: 0.8585\n","Training loss (for one batch) at step 140: 224.9453, Accuracy: 0.8577\n","---- Training ----\n","Training loss: 184.8642\n","Training acc over epoch: 0.8581\n","---- Validation ----\n","Validation loss: 85.8565\n","Validation acc: 0.7300\n","Time taken: 68.15s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 199.7905, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 230.5731, Accuracy: 0.8745\n","Training loss (for one batch) at step 20: 220.1127, Accuracy: 0.8662\n","Training loss (for one batch) at step 30: 216.6084, Accuracy: 0.8610\n","Training loss (for one batch) at step 40: 212.5707, Accuracy: 0.8639\n","Training loss (for one batch) at step 50: 199.7648, Accuracy: 0.8645\n","Training loss (for one batch) at step 60: 238.6947, Accuracy: 0.8630\n","Training loss (for one batch) at step 70: 212.6417, Accuracy: 0.8607\n","Training loss (for one batch) at step 80: 241.4585, Accuracy: 0.8589\n","Training loss (for one batch) at step 90: 217.9520, Accuracy: 0.8603\n","Training loss (for one batch) at step 100: 212.2153, Accuracy: 0.8604\n","Training loss (for one batch) at step 110: 196.0398, Accuracy: 0.8608\n","Training loss (for one batch) at step 120: 209.8036, Accuracy: 0.8610\n","Training loss (for one batch) at step 130: 223.3758, Accuracy: 0.8607\n","Training loss (for one batch) at step 140: 221.4471, Accuracy: 0.8597\n","---- Training ----\n","Training loss: 190.6090\n","Training acc over epoch: 0.8595\n","---- Validation ----\n","Validation loss: 82.6428\n","Validation acc: 0.7466\n","Time taken: 68.62s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 213.8895, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 223.5952, Accuracy: 0.8691\n","Training loss (for one batch) at step 20: 191.5319, Accuracy: 0.8643\n","Training loss (for one batch) at step 30: 221.4435, Accuracy: 0.8639\n","Training loss (for one batch) at step 40: 234.0554, Accuracy: 0.8680\n","Training loss (for one batch) at step 50: 216.6220, Accuracy: 0.8647\n","Training loss (for one batch) at step 60: 227.7130, Accuracy: 0.8648\n","Training loss (for one batch) at step 70: 209.5352, Accuracy: 0.8618\n","Training loss (for one batch) at step 80: 210.4366, Accuracy: 0.8593\n","Training loss (for one batch) at step 90: 204.8168, Accuracy: 0.8601\n","Training loss (for one batch) at step 100: 203.0967, Accuracy: 0.8598\n","Training loss (for one batch) at step 110: 198.7122, Accuracy: 0.8597\n","Training loss (for one batch) at step 120: 230.5161, Accuracy: 0.8588\n","Training loss (for one batch) at step 130: 205.8431, Accuracy: 0.8593\n","Training loss (for one batch) at step 140: 228.5528, Accuracy: 0.8584\n","---- Training ----\n","Training loss: 193.5318\n","Training acc over epoch: 0.8586\n","---- Validation ----\n","Validation loss: 68.3918\n","Validation acc: 0.7566\n","Time taken: 70.54s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 202.3800, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 209.4181, Accuracy: 0.8673\n","Training loss (for one batch) at step 20: 203.8543, Accuracy: 0.8695\n","Training loss (for one batch) at step 30: 222.0368, Accuracy: 0.8732\n","Training loss (for one batch) at step 40: 197.8389, Accuracy: 0.8754\n","Training loss (for one batch) at step 50: 202.8191, Accuracy: 0.8757\n","Training loss (for one batch) at step 60: 214.0105, Accuracy: 0.8775\n","Training loss (for one batch) at step 70: 219.8753, Accuracy: 0.8737\n","Training loss (for one batch) at step 80: 209.8993, Accuracy: 0.8715\n","Training loss (for one batch) at step 90: 242.7058, Accuracy: 0.8704\n","Training loss (for one batch) at step 100: 236.4230, Accuracy: 0.8677\n","Training loss (for one batch) at step 110: 217.4476, Accuracy: 0.8680\n","Training loss (for one batch) at step 120: 212.0910, Accuracy: 0.8674\n","Training loss (for one batch) at step 130: 229.6881, Accuracy: 0.8643\n","Training loss (for one batch) at step 140: 233.3100, Accuracy: 0.8641\n","---- Training ----\n","Training loss: 192.9320\n","Training acc over epoch: 0.8649\n","---- Validation ----\n","Validation loss: 78.7127\n","Validation acc: 0.7515\n","Time taken: 69.51s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 221.3386, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 205.5416, Accuracy: 0.8618\n","Training loss (for one batch) at step 20: 201.3059, Accuracy: 0.8657\n","Training loss (for one batch) at step 30: 223.4975, Accuracy: 0.8619\n","Training loss (for one batch) at step 40: 217.3689, Accuracy: 0.8659\n","Training loss (for one batch) at step 50: 208.8163, Accuracy: 0.8678\n","Training loss (for one batch) at step 60: 210.1696, Accuracy: 0.8693\n","Training loss (for one batch) at step 70: 206.1843, Accuracy: 0.8692\n","Training loss (for one batch) at step 80: 223.8458, Accuracy: 0.8670\n","Training loss (for one batch) at step 90: 220.8161, Accuracy: 0.8638\n","Training loss (for one batch) at step 100: 208.6367, Accuracy: 0.8636\n","Training loss (for one batch) at step 110: 225.7956, Accuracy: 0.8632\n","Training loss (for one batch) at step 120: 214.1346, Accuracy: 0.8627\n","Training loss (for one batch) at step 130: 228.8580, Accuracy: 0.8623\n","Training loss (for one batch) at step 140: 226.0266, Accuracy: 0.8619\n","---- Training ----\n","Training loss: 195.5781\n","Training acc over epoch: 0.8623\n","---- Validation ----\n","Validation loss: 79.5384\n","Validation acc: 0.7512\n","Time taken: 68.24s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 225.3546, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 207.2565, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 242.2711, Accuracy: 0.8557\n","Training loss (for one batch) at step 30: 211.7282, Accuracy: 0.8548\n","Training loss (for one batch) at step 40: 230.7648, Accuracy: 0.8595\n","Training loss (for one batch) at step 50: 217.0191, Accuracy: 0.8600\n","Training loss (for one batch) at step 60: 210.0778, Accuracy: 0.8644\n","Training loss (for one batch) at step 70: 210.7972, Accuracy: 0.8642\n","Training loss (for one batch) at step 80: 222.4233, Accuracy: 0.8627\n","Training loss (for one batch) at step 90: 210.3564, Accuracy: 0.8613\n","Training loss (for one batch) at step 100: 237.0411, Accuracy: 0.8614\n","Training loss (for one batch) at step 110: 208.0184, Accuracy: 0.8619\n","Training loss (for one batch) at step 120: 199.0270, Accuracy: 0.8622\n","Training loss (for one batch) at step 130: 198.5163, Accuracy: 0.8613\n","Training loss (for one batch) at step 140: 240.2864, Accuracy: 0.8607\n","---- Training ----\n","Training loss: 186.0832\n","Training acc over epoch: 0.8609\n","---- Validation ----\n","Validation loss: 89.5566\n","Validation acc: 0.7483\n","Time taken: 69.53s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 194.2314, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 230.6817, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 215.7516, Accuracy: 0.8557\n","Training loss (for one batch) at step 30: 199.2933, Accuracy: 0.8594\n","Training loss (for one batch) at step 40: 214.8972, Accuracy: 0.8620\n","Training loss (for one batch) at step 50: 194.5885, Accuracy: 0.8653\n","Training loss (for one batch) at step 60: 220.6855, Accuracy: 0.8659\n","Training loss (for one batch) at step 70: 188.9528, Accuracy: 0.8648\n","Training loss (for one batch) at step 80: 210.8613, Accuracy: 0.8623\n","Training loss (for one batch) at step 90: 235.1337, Accuracy: 0.8613\n","Training loss (for one batch) at step 100: 191.5212, Accuracy: 0.8641\n","Training loss (for one batch) at step 110: 208.9428, Accuracy: 0.8640\n","Training loss (for one batch) at step 120: 213.0636, Accuracy: 0.8638\n","Training loss (for one batch) at step 130: 228.1841, Accuracy: 0.8636\n","Training loss (for one batch) at step 140: 219.4654, Accuracy: 0.8637\n","---- Training ----\n","Training loss: 200.5647\n","Training acc over epoch: 0.8634\n","---- Validation ----\n","Validation loss: 73.9984\n","Validation acc: 0.7453\n","Time taken: 68.77s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 221.1418, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 191.4192, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 212.8351, Accuracy: 0.8581\n","Training loss (for one batch) at step 30: 221.3518, Accuracy: 0.8597\n","Training loss (for one batch) at step 40: 190.3674, Accuracy: 0.8624\n","Training loss (for one batch) at step 50: 210.6183, Accuracy: 0.8659\n","Training loss (for one batch) at step 60: 203.7368, Accuracy: 0.8667\n","Training loss (for one batch) at step 70: 225.8612, Accuracy: 0.8661\n","Training loss (for one batch) at step 80: 215.6620, Accuracy: 0.8652\n","Training loss (for one batch) at step 90: 201.7220, Accuracy: 0.8645\n","Training loss (for one batch) at step 100: 219.9343, Accuracy: 0.8644\n","Training loss (for one batch) at step 110: 204.0164, Accuracy: 0.8667\n","Training loss (for one batch) at step 120: 212.6281, Accuracy: 0.8657\n","Training loss (for one batch) at step 130: 228.6744, Accuracy: 0.8653\n","Training loss (for one batch) at step 140: 182.7463, Accuracy: 0.8659\n","---- Training ----\n","Training loss: 188.5894\n","Training acc over epoch: 0.8659\n","---- Validation ----\n","Validation loss: 74.3637\n","Validation acc: 0.7442\n","Time taken: 68.97s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 212.9821, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 211.3275, Accuracy: 0.8673\n","Training loss (for one batch) at step 20: 218.6335, Accuracy: 0.8686\n","Training loss (for one batch) at step 30: 194.0941, Accuracy: 0.8674\n","Training loss (for one batch) at step 40: 221.5933, Accuracy: 0.8683\n","Training loss (for one batch) at step 50: 212.9799, Accuracy: 0.8696\n","Training loss (for one batch) at step 60: 206.3168, Accuracy: 0.8700\n","Training loss (for one batch) at step 70: 211.3698, Accuracy: 0.8680\n","Training loss (for one batch) at step 80: 199.7450, Accuracy: 0.8669\n","Training loss (for one batch) at step 90: 201.0044, Accuracy: 0.8646\n","Training loss (for one batch) at step 100: 180.7097, Accuracy: 0.8645\n","Training loss (for one batch) at step 110: 197.4804, Accuracy: 0.8651\n","Training loss (for one batch) at step 120: 199.7292, Accuracy: 0.8657\n","Training loss (for one batch) at step 130: 202.2857, Accuracy: 0.8650\n","Training loss (for one batch) at step 140: 202.5935, Accuracy: 0.8638\n","---- Training ----\n","Training loss: 178.1698\n","Training acc over epoch: 0.8647\n","---- Validation ----\n","Validation loss: 80.9751\n","Validation acc: 0.7488\n","Time taken: 70.00s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 194.0691, Accuracy: 0.9300\n","Training loss (for one batch) at step 10: 197.6391, Accuracy: 0.8755\n","Training loss (for one batch) at step 20: 236.3835, Accuracy: 0.8652\n","Training loss (for one batch) at step 30: 205.8907, Accuracy: 0.8674\n","Training loss (for one batch) at step 40: 192.8171, Accuracy: 0.8654\n","Training loss (for one batch) at step 50: 196.5798, Accuracy: 0.8692\n","Training loss (for one batch) at step 60: 211.5089, Accuracy: 0.8697\n","Training loss (for one batch) at step 70: 209.5021, Accuracy: 0.8696\n","Training loss (for one batch) at step 80: 191.7347, Accuracy: 0.8679\n","Training loss (for one batch) at step 90: 223.7015, Accuracy: 0.8670\n","Training loss (for one batch) at step 100: 210.4055, Accuracy: 0.8681\n","Training loss (for one batch) at step 110: 197.6241, Accuracy: 0.8687\n","Training loss (for one batch) at step 120: 218.5383, Accuracy: 0.8679\n","Training loss (for one batch) at step 130: 221.2603, Accuracy: 0.8668\n","Training loss (for one batch) at step 140: 191.6547, Accuracy: 0.8661\n","---- Training ----\n","Training loss: 181.1772\n","Training acc over epoch: 0.8664\n","---- Validation ----\n","Validation loss: 75.5287\n","Validation acc: 0.7526\n","Time taken: 70.41s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 214.0974, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 195.6995, Accuracy: 0.8682\n","Training loss (for one batch) at step 20: 186.2303, Accuracy: 0.8633\n","Training loss (for one batch) at step 30: 190.4309, Accuracy: 0.8577\n","Training loss (for one batch) at step 40: 192.2452, Accuracy: 0.8624\n","Training loss (for one batch) at step 50: 186.5523, Accuracy: 0.8669\n","Training loss (for one batch) at step 60: 204.1276, Accuracy: 0.8690\n","Training loss (for one batch) at step 70: 196.9592, Accuracy: 0.8701\n","Training loss (for one batch) at step 80: 204.1244, Accuracy: 0.8664\n","Training loss (for one batch) at step 90: 206.0963, Accuracy: 0.8669\n","Training loss (for one batch) at step 100: 191.7483, Accuracy: 0.8660\n","Training loss (for one batch) at step 110: 209.7218, Accuracy: 0.8665\n","Training loss (for one batch) at step 120: 206.2238, Accuracy: 0.8651\n","Training loss (for one batch) at step 130: 195.8844, Accuracy: 0.8643\n","Training loss (for one batch) at step 140: 212.9626, Accuracy: 0.8623\n","---- Training ----\n","Training loss: 190.1883\n","Training acc over epoch: 0.8634\n","---- Validation ----\n","Validation loss: 88.9194\n","Validation acc: 0.7367\n","Time taken: 70.60s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 211.0047, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 211.3248, Accuracy: 0.8627\n","Training loss (for one batch) at step 20: 216.0143, Accuracy: 0.8614\n","Training loss (for one batch) at step 30: 211.1638, Accuracy: 0.8632\n","Training loss (for one batch) at step 40: 190.2386, Accuracy: 0.8641\n","Training loss (for one batch) at step 50: 193.2777, Accuracy: 0.8686\n","Training loss (for one batch) at step 60: 205.3381, Accuracy: 0.8702\n","Training loss (for one batch) at step 70: 211.1266, Accuracy: 0.8692\n","Training loss (for one batch) at step 80: 217.9118, Accuracy: 0.8667\n","Training loss (for one batch) at step 90: 198.1941, Accuracy: 0.8658\n","Training loss (for one batch) at step 100: 199.5129, Accuracy: 0.8658\n","Training loss (for one batch) at step 110: 202.7959, Accuracy: 0.8665\n","Training loss (for one batch) at step 120: 218.4534, Accuracy: 0.8668\n","Training loss (for one batch) at step 130: 192.7267, Accuracy: 0.8652\n","Training loss (for one batch) at step 140: 196.5201, Accuracy: 0.8664\n","---- Training ----\n","Training loss: 192.8737\n","Training acc over epoch: 0.8657\n","---- Validation ----\n","Validation loss: 77.5828\n","Validation acc: 0.7284\n","Time taken: 71.71s\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABodElEQVR4nO2dZ3hVVdaA35XeQzqBAKH33gREQVBRESygYAN1LNh7mc+CqDM6OrYRC46KbcSCIiiISBGU3nsNAUInIY30ZH8/9klyE9K5Nze52e/z3Cf37HLO2snJWWevtfbaopTCYDAYDAYAN2cLYDAYDIa6g1EKBoPBYCjCKAWDwWAwFGGUgsFgMBiKMErBYDAYDEUYpWAwGAyGIoxSMBiqgYgMEZEEZ8thMDgKoxQMtYaIxIvIcGfLYTAYyscoBYPBRRARD2fLYKj/GKVgcDoi4i0ib4nIEevzloh4W3XhIvKziCSLSJKILBMRN6vuSRE5LCJpIrJLRIaVc/4rRGSDiKSKyCERmWxTFysiSkQmiMhBETklIv9nU+8rItNF5LSIbAf6VjKWt61rpIrIOhEZbFPnLiJ/F5F9lszrRKSZVddZRBZYYzwuIn+3yqeLyEs25yhhvrJmX0+KyGbgjIh4iMhTNtfYLiJXl5LxDhHZYVPfS0QeF5GZpdq9IyJvVzRegwuilDIf86mVDxAPDC+jfAqwEogEIoDlwItW3T+BDwBP6zMYEKA9cAhoYrWLBVqXc90hQFf0S1A34DhwlU0/BXwE+ALdgWygo1X/CrAMCAWaAVuBhArGeBMQBngAjwLHAB+r7nFgiyW7WNcKAwKBo1Z7H+u4v9VnOvBSqbEklPqdbrRk87XKxgJNrPFeD5wBom3qDqOVmwBtgBZAtNWukdXOAzgB9Hb2fWM+tftxugDm03A+FSiFfcDlNseXAvHW9ynAT0CbUn3aWA+t4YBnNeV4C3jT+l6oFGJs6lcD46zvccAIm7o7K1IKZVzrNNDd+r4LGF1Gm/HAhnL6V0Up3FaJDBsLrwvMBx4sp9084A7r+0hgu7PvGfOp/Y8xHxnqAk2AAzbHB6wygNeAvcBvIhInIk8BKKX2Ag8Bk4ETIjJDRJpQBiLSX0QWi8hJEUkB7gbCSzU7ZvM9Awiwke1QKdnKRUQes0wzKSKSDATbXKsZWgGWprzyqmIrHyJyi4hstExuyUCXKsgA8Bl6poP184tzkMlQTzFKwVAXOII2YRTS3CpDKZWmlHpUKdUKGAU8Uug7UEr9Tyl1vtVXAa+Wc/7/AbOBZkqpYLQ5Sqoo21H0g9RWtjKx/AdPANcBIUqpRkCKzbUOAa3L6HoIaFXOac8AfjbHjctoU5TqWERaoE1h9wFhlgxbqyADwCygm4h0Qc8UviqnncGFMUrBUNt4ioiPzccD+Bp4RkQiRCQceA74EkBERopIGxER9AM2HygQkfYicpHlkM4CMoGCcq4ZCCQppbJEpB9wQzXk/RZ4WkRCRCQGuL+CtoFAHnAS8BCR54Agm/r/Ai+KSFvRdBORMOBnIFpEHrKc7oEi0t/qsxG4XERCRaQxenZUEf5oJXESQERuRc8UbGV4TER6WzK0sRQJSqks4Hu0El2tlDpYybUMLohRCobaZi76AV74mQy8BKwFNqMdseutMoC2wO9AOrACeE8ptRjwRjuBT6FNP5HA0+Vc8x5gioikoRXOt9WQ9wW0yWg/8BsVm1TmA78Cu60+WZQ07bxhXfs3IBX4GO0cTgMuBq60xrIHGGr1+QLYhPYd/AZ8U5GwSqntwL/Rv6vjaAf7Xzb13wEvox/8aejZQajNKT6z+hjTUQNFlDKb7BgMBo2INAd2Ao2VUqnOlsdQ+5iZgsFgAMBa//EIMMMohIaLWQFpMBgQEX+0uekAMMLJ4hiciDEfGQwGg6EIYz4yGAwGQxFGKRgMBoOhCKMUDAaDwVCEUQoGg8FgKMIoBYPBYDAUYZSCwWAwGIowSsFgMBgMRRilYDAYDIYijFIwGAwGQxFGKRgMBoOhCKMUDAaDwVCEUQoGg8FgKMIoBYPBYDAUYZSCwWAwGIqo1/sphIeHq9jY2KLjM2fO4O/v7zyBagFXH2NdGt+6detOKaUinHHthnZvu/r4oG6NsaJ7u14rhdjYWNauXVt0vGTJEoYMGeI8gWoBVx9jXRqfiBxw1rUb2r3t6uODujXGiu5tYz4yGAwGQxFGKRgMBoOhCKMUDAaDwVBEvfYp1EVyc3NJSEggKyvLIecPDg5mx44dDjl3XcAZ4/Px8SEmJgZPT89ava7BUBcxSsHOJCQkEBgYSGxsLCJi9/OnpaURGBho9/PWFWp7fEopEhMTSUhIoGXLlrV2XYOhrmLMR3YmKyuLsLAwhygEg/0REcLCwhw2szMY6htGKTgAoxDqF+bvZTAU45JK4detR/nvsjhni2EwGAx241hKFikZuUXHBQWKtfFJfLY8ntNnckq0zcrNZ++J9BpdxyV9Cgt3nGDZnlP8bXArZ4tiMBgMZXIsJYt3Fu1hZLdoBrYOL7fd1sMpTF28l1+3HQOgfVQgnaKDWLU/icPJmQC8sWA3j17Sjsu6RPP16oN8viKeIB9Pfn/kQtzcqjcTdkmlEBrgRdKZHJRSDc40kJiYyLBhwwA4duwY7u7uRETo1eyrV6/Gy8ur3L5r167l888/55133qnwGgMHDmT58uV2k3n69OmsXbuWd999127nNBjqMtl5+dz15To2HUrmf6sOMqhNGA8Nb0fv5iFFD/FNh5J56/fdLN51kkAfD+4Z0hofD3dWxyexZPdJuscE8+gl7WgVEcC/ft3Jcz9t47mftgFwUYdI7hjcipo8/lxTKfh5kZNfQHp2HoE+DSvMMCwsjI0bNwIwefJkAgICeOyxx4rq8/Ly8PAo+8/ep08f+vTpU+k17KkQDIaGhlKK52ZtY9OhZN4e14NT6Tm8t3gvYz9YQXiAFxe0jSAlM5eFO0/QyM+Txy9tz80DWhBUwbPsq7/159etx9iUkMI1vZrSLqrmEXyuqRT89dtw0pkcpyqFF+ZsY/uRVLues224Ly9d26NafSZOnIiPjw8bNmxg0KBBjBs3jgcffJCsrCx8fX359NNPad++PUuWLOH111/n559/ZvLkyRw8eJC4uDgOHjzIQw89xAMPPABAQEAA6enpLFmyhMmTJxMeHs7WrVvp3bs3X375JSLC3LlzeeSRR/D392fQoEHExcXx888/VyrrgQMHeOCBBzh16hQRERF8+umnNG/enO+++44XXngBd3d3goODWbp0Kdu2bePWW28lJyeHgoICZs6cSdu2bWvyazUYHEJmTj4r9yfy155THDmcw+ngBI4kZ/HN2kPcf1EbRvdoCsC4vs2Yt/UYS3efZPGuExQoePzS9kwYGEuAd+WPaRHhsq7RXNY1+pxldkmlEBaglULimRxahNWNrITOJiEhgeXLl+Pu7k5qairLli3Dw8OD33//nb///e/MnDnzrD47d+5k8eLFpKWl0b59eyZNmnTWAq8NGzawbds2mjRpwqBBg/jrr7/o06cPd911F0uXLqVly5aMHz++ynI+/vjjTJgwgQkTJvDJJ5/wwAMPMGvWLKZMmcL8+fNp2rQpycnJAHzwwQc8+OCD3HjjjeTk5JCfn39OvyODoSasiU9i+d5Ebjs/tuglNDe/gBfmbOPbtQnk5BXg5eFGfn4Bc/dvAmBo+wgeGt6u6Bz+3h6M6R3DmN4xFBQoFOBeTV+AvXBJpRDq7w1wlke+tnn+ys52P2daWlqN+o0dOxZ3d3cAUlJSmDBhAnv27EFEyM3NLbPPFVdcgbe3N97e3kRGRnL8+HFiYmJKtOnXr19RWY8ePYiPjycgIIBWrVoVLQYbP34806ZNq5Kcq1evZvbs2QDcfPPNPPHEEwAMGjSIiRMnct1113HNNdcAMGDAAF5++WUSEhK45pprzCzBUGsopVgZl8Q7C/ewIi4RgJ83H+GjW/oQGeTNPV+tZ8muk4zr24zLu0bTr2Uofy5bSovOfTicnMl5rcLKfehX1zFsb1wyJDXMv3imYNDY5nF/9tlnGTp0KFu3bmXOnDnlLtzy9vYu+u7u7k5eXl6N2tiDDz74gJdeeolDhw7Ru3dvEhMTueGGG5g9eza+vr5cfvnlLFq0yCHXBhCRESKyS0T2ishTZdQ3F5HFIrJBRDaLyOVWeayIZIrIRuvzgcOENDgcpRSLd55gzAcrGP/RSvaeTOfZkZ34dGJfTqZnM+rdPxn7wQqW7j7JP67uyivXduOCdhH4eLrj4Sa0jQpkSPtIfDzdnT2UcnHRmUKxT8FwNikpKTRtqm2Z06dPt/v527dvT1xcHPHx8cTGxvLNN99UuW///v2ZMWMGN998M1999RWDBw8GYN++ffTv35/+/fszb948Dh06REpKCq1ateKBBx7g4MGDbN68mYsuusju4xERd2AqcDGQAKwRkdlKqe02zZ4BvlVKvS8inYC5QKxVt08p1cPughlqjYICxfxtx5i6ZC9bD6fSJNiHF0Z15vq+zYoe8HPuO587Pl/LnhPpvHdjb0Z0aexkqWuGSyoFPy93vD3cjFIohyeeeIIJEybw0ksvccUVV9j9/L6+vrz33nuMGDECf39/+vbtW+W+r732Gvfffz+vvfZakaMZtK9hz549KKUYNmwY3bt359VXX+WLL77A09OTxo0b8/e//93uY7HoB+xVSsUBiMgMYDRgqxQUEGR9DwaOOEoYg2NRSvHt2kOs2JdIkK8nAd4ezN92jH0nz9Ay3J9/jenGVT2a4uVR0tDSLNSPn+4bREpGLpFBPk6S/twRpZSzZagxffr0UeXtTjXgnwsZ2Dqcf1/XvVZl2rFjBx07dnTY+etLQrz09HQCAgJQSnHvvffStm1bHn744Ur7OWt8Zf3dRGSdUqqPiIwBRiil/maV3wz0V0rdZ9M2GvgNCAH8geFKqXUiEgtsA3YDqcAzSqllZckgIncCdwJERUX1njFjRlFd4e/TVakr48vMU3y6NZvVx/Jp5C3kFigyciEm0I2RrTzp29gdtxqufaorYwQYOnToOqVUmfHnDpspiIgPsBTwtq7zvVLqeRGZDlwIpFhNJyqlNopeZfY2cDmQYZWvr+n1Q/29SDqTfS5DMJwDH330EZ999hk5OTn07NmTu+66y9kiOZrxwHSl1L9FZADwhYh0AY4CzZVSiSLSG5glIp2VUmfFKiulpgHTQL/w2G7dWJe2cnQEdWF8q+ISeeGHLRxIzOeJEe25+4LWuLmJ3RbB1oUxVgVHmo+ygYuUUuki4gn8KSLzrLrHlVLfl2p/GdDW+vQH3rd+1gitFIz5yFk8/PDDZ80MPv30U95+++0SZYMGDWLq1Km1KVpNOAw0szmOscpsuR0YAaCUWmG9FIUrpU6g/xewZg77gHbAWgxORynFirhE3lm4h5VxSUQFefO/O87jvFZhRW0aWlYEhykFpe1ShRmZPK1PRbaq0cDnVr+VItJIRKKVUkdrcv0wfy/iE8/UpKvBQdx6663ceuutzhajJqwB2opIS7QyGAfcUKrNQWAYMF1EOgI+wEkRiQCSlFL5ItIK/dJjsjXWMonp2fxj7k78vNwZ0zuGbjHB/LVXK4PV8UlEBHrz7MhO3NCvOb5edTcyqDZwqKPZitpYB7QBpiqlVonIJOBlEXkOWAg8pZTKBpoCh2y6J1hlR0ud09buypIlS4rqClfZAmSczuZkSl6J+togODi4xmsJqkJ+fr5Dz+9snDW+rKyscu8VpVSeiNwHzAfcgU+UUttEZAqwVik1G3gU+EhEHka//ExUSikRuQCYIiK5QAFwt1IqqRaGZLDYcTSVv322lpPp2QjwxcoDhPl7kXgmh8ZBPky+shPj+jWv02GitYlDlYJSKh/oISKNgB8tG+vTwDHAC20/fRKYUo1zVsnuuk3t5bcDuzhv0OBa/WPv2LHDoY7S+uJorinOGp+Pjw89e/Yst14pNRcdZmpb9pzN9+3AoDL6zQTOXi5uqBUWbD/OgzM2EOjjwXd3DSA23J9fNh9lya4TDG4XwXV9YvD2MMrAlloJSVVKJYvIYnQEx+tWcbaIfAoUZmurit22ytiuVWjSyLempzEYDPWUz5bHM3nONro1DWbaLX2IssJEb+jfnBv6N3eydHUXh61oFpEIa4aAiPiiF/7stEL3sKKNrgK2Wl1mA7eI5jwgpab+BIAQP7OAzWBoiBQUKP4xdwfPz97G8I5RzLhzQJFCMFSOI9NcRAOLRWQz2lG3QCn1M/CViGwBtgDhwEtW+7loB9xe4CPgnnO5uG1SvIbE0KFDmT9/fomyt956i0mTJpXZfsiQIRSu9bj88suLks3ZMnnyZF5//fWzym2ZNWsW27cXr+V67rnn+P3336spfflMnz6d++67r/KGhgbJpkPJvDBnGzd/vIoBryxk2tI4bhnQgg9u6t3gHcfVxZHRR5uBs4y0Sqky8xBYUUf32uv6xeajhrVWYfz48cyYMYNLL720qGzGjBn861//qrTv3LlzK21THrNmzWLkyJF06tQJgClTquwmMhhqzNbDKby5YDcLd57A19OdtlEBDGodzvltw7m6Z9MGF05qD1wyzQUUJ8VLOlN2BtBaYd5TcGyLXU/pHdYeRr1Rbv2YMWN45plnyMnJwcvLi/j4eI4cOcLXX3/NI488QmZmJmPGjOGFF144q29sbCxr164lPDycl19+mc8++4zIyEiaNWtG7969Ab0obdq0aeTk5NCmTRu++OILNm7cyOzZs/njjz946aWXmDlzJi+++CIjR45kzJgxLFy4kMcee4y8vDz69u3L+++/j7e3N7GxsUyYMIE5c+aQm5vLd999V5STqSLi4+O57bbbzJ4LDZSjKZnM2XSE2ZuOsPVwKsG+ntXae8BQMS6ZJRUgyMcTdzdpcDOF0NBQ+vXrx7x5ep3gjBkzuO6663j55ZdZu3Ytmzdv5o8//mDz5s3lnmPdunXMmDGDjRs3MnfuXNasWVNUd80117BmzRo2bdpEx44d+fjjjxk4cCCjRo3itddeY+PGjbRu3bqofVZWFhMnTuSbb75hy5Yt5OXl8f777xfVh4eHs379eiZNmlSpiaqQ+++/nwkTJrB582ZuvPHGos1/Cvdc2LRpU1H67cI9FzZu3MjatWvPSv1tqF9sPZzC0NeX8I+5O3ET4ZkrOrLsyaHcO7SNUQh2wmV/i25uQoifk1c1X/aK3U+ZnZZG+bssawpNSKNHj2bGjBl8/PHHfPvtt0ybNo28vDyOHj3K9u3b6datW5n9ly1bxtVXX42fnx8Ao0aNKqrbunUrzzzzDMnJyaSnp5cwU5XFrl27aNmyJe3a6Q1FJkyYwNSpU3nooYcAivZG6N27Nz/88EMVfgOwYsWKorZmz4WGw5nsPB74egPBvp788sB5tI6oG3mEXA2XnSmANiElpjcsRzPA6NGjWbhwIevXrycjI4PQ0FBef/11Fi5cyObNm7niiivK3UOhMiZOnMi7777Lli1beP7552t8nkIK92Owx14Mzt5zweBYJs/exv7EM7x1fU+jEByISyuFEH/PBhmSGhAQwNChQ7ntttsYP348qamp+Pv7ExwczPHjx4tMS+VxwQUXMGvWLDIzM0lLS2POnDlFdWlpaURHR5Obm8tXX31VVB4YGFjmSuT27dsTHx/P3r17Afjiiy+48MILz2l8AwcOpDCDaFl7LkyZMoWIiAgOHTpEXFxc0Z4Lo0ePrtBsZqhbvL9kH3/7bA3//m0XbyzYzXfrErhvaBsGtA6rvLOhxris+QggzN+bHUfPSkbZIBg/fjxXX301M2bMoEOHDvTs2ZMOHTrQrFkzBg06a+FtCXr16sX1119P9+7diYyMLLEfwosvvkj//v2JiIigf//+RYpg3Lhx3HHHHbzzzjt8/31xrkMfHx8+/fRTxo4dW+Rovvvuu89pbP/5z3+49dZb69qeCwY7MnvTEV79dSdRQd4s3nWS/AJF7xYhPDjMmP8cjlKq3n569+6tbFm8eHGJ42d+3KK6TZ6vapPt27c79PypqakOPb+zcdb4yvq7ofMa1cl729WwHd+OoymqwzPz1Jj3/1LZufkqMydPbUlIVqmZOc4T0A7Upb9hRfe2S88UQv29SMnMJS+/AA93l7aUGQwuQUpmLnd9sY5AHw+m3tCraHezLk2DnSxZw8GllULhqubTGblEBHpX0tpQF/jyyy/58MMPS5TVkz0XDHbguZ+2ciQ5kxl3nlevt7Ssz7i0UrBNileeUth9PI3Js7fx4c29CfTxtMt1lZ12amqI3HTTTeWm5HAUqh5vSetK/LnnFD9tPMKDw9rSu0Wos8VpsLi0TaVQKSRWsIDt+3UJLN+XyPYj9nFI+/j4kJiYaB409QSlFImJifj4mLfS2iQrN5+Z6xI4bUUH5uQrnv1pK7Fhfkwa0rqS3gZH4tIzhTB/PTuoKCx16e6TABw6nVnzvT9tiImJISEhgZMnT9rhbGeTlZXl0g8wZ4zPx8fHrHSuRY6nZnHnF+vYdCiZ8AAvpozuwoL9uew/lcvnt/Uzm904GZdWCiH+2hxUnlI4nprFzmM6pDLhdIZdrunp6UnLli3tcq6yWLJkSYWbwdR3XH18DZ31B09z9xfrSM/OY/KVnZi5/jD3fLUeAUZ2i+aCdhHOFrHB49pKwdpTobxVzX9YswQPNyHhdGatyWUwNET2nUznho9WEhHozee3D6RD4yBuOq8FHy3bz8yVu3l2ZCdni2jAxZWCp7sbwb6enM4oWyks3X2SiEBvmof62W2mYDAYziYvv4BHvt2Ej6c73989sGjTGw93NyYNaU1HDpmNcOoILu1oBp3/6FjK2fl58gsUf+49xQVtI2gW4suhJDNTMJSPiIwQkV0isldEniqjvrmILBaRDSKyWUQut6l72uq3S0QqziDoonzwxz42HUrmxdFdzMO/juPySmFgmzAW7zrBkeSSD/3NCckkZ+RyYfsIYkL8OJaaRV5+gZOkNNRlRMQdmApcBnQCxotIaVvHM8C3SqmewDjgPatvJ+u4MzACeM86X4Nh25EU3l64hyu6RXNl9ybOFsdQCS6vFO6+sDVKwYd/7CtRvnT3KURgcJtwmoX6kl+gOFrGjMJgAPoBe5VScUqpHGAGMLpUGwUEWd+DgSPW99HADKVUtlJqP3q72X61IHOd4GBiBvd+tZ5Gfl68NLqLs8UxVAGX9ikAxIT4MaZ3DF+vOcS9Q9sUrZJcuuck3WIaEeLvRUyI3jfg0OkMmoX6OVNcQ92kKXDI5jgBzopgngz8JiL3A/7AcJu+K0v1LXN7ORG5E7gTICoqiiVLlhTVpaenlziuD+xNzuft9VkUKHiolw+b1iwvt219HF91qS9jdHmlAHDPkDZ8ty6BD5fG8ezITqzen8SGg6e5b2gbAGJCfAFMBJLhXBgPTFdK/VtEBgBfiEi1Xo2VUtOAaQB9+vRRQ4YMKapbsmQJtsd1nblbjvLa7xuJCvLj01v7Vrr/QX0bX02oL2NsEEqheZgfV/VoylerDnD4dCa/bjtGdLAP1/bWC5aig31xE6MUDOVyGGhmcxxjldlyO9pngFJqhYj4AOFV7Osy5Bco3liwi6mL99GreSM+uqUPYQEm71h9wuV9CoXcO7Q1OXkF/LH7JA8Pb8eiR4fQIswfAC8PNxoH+ZiwVEN5rAHaikhLEfFCO45nl2pzEBgGICIdAR/gpNVunIh4i0hLoC2wutYkr0VSs3K5/bM1TF28j3F9m/H1necZhVAPaRAzBYBWEQH8cM8gooN9ygyJiwnxI8GEpRrKQCmVJyL3AfMBd+ATpdQ2EZmCzks/G3gU+EhEHkY7nSdaeeu3ici3wHYgD7hXKZXvnJE4ltd+3cWfe07x8tVduLF/C2eLY6ghDlMK1vR5KeBtXed7pdTz1tvSDCAMWAfcrJTKERFv4HOgN5AIXK+UirenTD2aNSq3LibUl5X7Eu15OYMLoZSaC8wtVfaczfftQJlb2imlXgZedqiATiYlI5fv1yVwVc+mRiHUcxxpPsoGLlJKdQd6ACNE5DzgVeBNpVQb4DTaFov187RV/qbVrtYoXKuQk2fWKhgM1WXGmoNk5uZz66BYZ4tiOEccphSsXd/SrUNP66OAi4DCTXw/A66yvo+2jrHqh0ktbkoQE+JLgYKjKcaEZDBUh7z8Aj5fcYD+LUPp3MTskFbfcahPwVq5uQ5og14Rug9IVkrlWU1sY7aLYsEtG24K2sR0qtQ5HRLLnZiozby/LFlJp7CSC07/OpxLpJ8bbUOcvxC1vsQ61xRXH58rsmD7cQ4nZ5qEdi6CQ5WC5VDrISKNgB+BDnY4p0NiuVsnZfDqmsWENW/LkL7Ni8qz8/K5a/JvDGgdxh1XO38han2Jda4prj4+V+TTv+KJCfHl4k5RzhbFYAdqJSRVKZUMLAYGAI1EpFAZ2cZsF8VzW/XBaIdzrRAd7IN7GSm0NyekkJ1XYLed2QwGVyE9O4/3luxldXwSEwbE4u5mtqB1BRymFEQkwpohICK+wMXADrRyGGM1mwD8ZH2fbR1j1S9StbinpYe7G9HBPhxKKrlWYVWc1ksn0rI5lV7+tp4GQ0OhoEDx9u97GPjPhfzr110MbhvOuH7NKu9oqBc40nwUDXxm+RXc0BkkfxaR7cAMEXkJ2AB8bLX/GJ0aYC+QhF4gVKvEhPieNVNYtT8JDzchr0Cx42gqg9uanaEMDZu5W4/y5u+7Gd4xivsvakP3CkK9DfUPhykFpdRm4Kx9FZVScZSRJVIplQWMdZQ8VSEmxI8/9xT7tXPzC1h34DSXd41m9qYjbD9ilIKhYaOUYurifbSK8OfDm3sbk5EL0mDSXFSF9lGBHEvNYs9xvW/zlsMpZOTkc2nnxjQJ9mHHUeNXMDRsFu08wY6jqdw7pI1RCC6KUQo2XNOrKd4ebnzy134AVsUlAdCvZSidmgSx3SgFQwNGKcW7i/cSE+LLqB5msxxXxSgFG8ICvLm2dwwz1x/mVHo2q/Yn0jrCn4hAbzpGB7Hv5Bmycl0ybY3BUCkr9iWy4WAyd1/YGk938+hwVcxfthS3DWpJTl4Bny2PZ238afq3CgOgU3QQ+QWKPcfTKzmDweB6KKV4e+EeIgO9GWOlnDe4JkYplKJNZADDOkTy4R9xpGfncV6hUmiid1rcfjTFmeIZDE7h4z/3s2p/Evdf1AYfT+ev7Dc4DqMUyuD2wS3JydeJ8c5rGQpAsxA//L3czSI2Q4NjbXwSr8zbySWdorjpPJMB1dVpMPspVIcBrcLo0jSIzJz8oj2d3dyEjtFlO5tz8ws4lpJl9nc2uByn0rO5738baBriy2tju1OLOSoNTsIohTIQEf57S1+y80o6lTs1CeKH9YcpKFC4WeF4h5IyuP/rDWw8lMynt/ZlaPtIZ4hsMDiEZ37cSlJGDj/eM5BgX09ni2OoBYz5qBwaB/sUbddZSKfoINKz80g4nYlSil+3HuWKd5ax70Q6LcL8ePTbTRxPzXKSxAaDfTmWksVv249xx+CWJiV2A8LMFKpBx2jtbL5/xgYSkjJIPJND16bBvHtDT3LzC7jyP3/x0IyNfPm3/mZhj6He88OGBAoUXNfH5DVqSJiZQjVo3ziQxkE+JJ3JZkj7SF4b043vJw2gRZg/bSIDeWF0Z1bEJTJ18V5ni2ownBNKKb5fm0C/2NCzZsyGcyD9BLzTC5b929mSlIuZKVQDH093Vjx9UbnOtrG9Y/hj10neW7KXOy9oZUL3XAgRGQG8DbgD/1VKvVKq/k1gqHXoB0QqpRpZdfnAFqvuoFJqVK0IfQ6sP3iauFNnuHtIa2eL4lr8+RYk7YOFU/Tx4EedKk5ZGKVQTSqKvhARrunVlF+2HGX9wdMMbB1ei5IZHIWV6XcqOv17ArBGRGYrpbYXtlFKPWzT/n5KJoPMVEr1qCVx7cL36xLw9XTn8q7RzhbFZfDKToK1H0O360EVFCuGHjeBdyB4+kJ1o7v2L4NNX8OIV8AnyC5yGvORnenXMhR3N+Gvvacqb2yoL/QD9iql4pRSOcAM9J7i5TEe+LpWJHMAmTn5zNl0lMu7RhPg7SLvjce2wFdjYduPThOh+cGZkJ8LQ56Cqz6ALtdqxfDvdvCPaPhXK1g1DfLzKj9ZQT4seRU+HwUbv4LtP1Xep4q4yF+87hDo40n3mGD+2pvI45c6WxqDnSjaP9wiAehfVkMRaQG0BBbZFPuIyFogD3hFKTWrnL4O2X+8uiw/kkd6dh5tPU7V2jUdNT63/GxaHPiW5gd/QCgg6+A6Vh0PQLnVbnitd9Yp+h2Zz9GooezafBA4iITeSFjntnjlJOOen0Fo0kZC5j1O+tJ32dvmbySHdCvzXB65aXTe9i9CkjdzLGoIjZK3kf7XZ2xNtU9AgFEKDuD8NuG8u3gvqVm5BPl4kpdfwPXTVjKoTTiPXNzO2eIZHMs44Htrf/JCWiilDotIK2CRiGxRSu0r3dFR+49XB6UUb079ixZh7tx51ZCi9TiOxmHjm3EjHPxZm2haD8Vn5u1cGHwEek+ovG8hvzwGoS1hwL01l+OXRymggOjr3yA6xHZV+LDir0rBjjkE/PZ/9Nj0LHS6Ci55ERoV7xlPymH48hpIi4NR79K4503w69P4rP2EIQN6azPUOWLMRw5gYJtwChSs3Ke38vx12zHWHTjNOwv3sHT3SSdLZ6gBRfuHW9juLV6acZQyHSmlDls/44AllLH5VF3hj90n2ZSQwqQLW9eaQqgxeTlweL02DZ2Oh5wzJevz82DfIuhzG1w1VZtronvAn29WzURTeI31n8OyN6repzS5mbDhK45HDYWQCtKEiECnUXDvahj6f7B7PrzbF2Y/ABu+hH2L4eNLIPUI3PQD9LpZ9+l4JeRnw54FNZOvFEYpOICezRvh4+nG8n2JKKX4aNl+YsP8aBcVwKPfbSLpTI6zRTRUjzVAWxFpKSJe6Af/7NKNRKQDEAKssCkLERFv63s4MAjYXrpvXUApxTsL99C0kS/X9KoDmVCPbYFDa84u3/s7/HAXvN4GPhoKH5wPb3eHf3eAzOTidid3Qm4GNB+gj0Xggsfg9P6q+xZO7tAP3IxTELekZF36iaqdI+4PyMvkROT5VWvv6QsXPgH3rdEP/G0/wk/3whdXQUEuTPwFWg4ubt/8PPALh50/V+38lWCUggPw9nCnX8sw/tx7inUHTrPpUDK3n9+St67vSUpGLk/N3IxSytliGqqIUioPuA+YD+xA7ze+TUSmiIhteOk4YIYq+cftCKwVkU3AYrRPoU4qheX7Ell/MJm7h7TGy8PJj4aCAm36mX45HFheXL7mY/jyWtgzHzqMhDGfwnVfwJCnITsVDq4obnt4nf7ZtHdxWfsrIKKjXieQmwVnEvWnPI5s1D/dvWDLt8Xl+5fC6+1g59zKx7JrLngFktyoS+VtbWnUDK79Lzx5QM8erv0Y7lwC0aV8DW7u0P4y2P0b5GVX7xplYHwKDmJQ6zD+OW8nr8zbSSM/T67tHYOflwePXdqOf8zdyU8bj3BVz6bOFtNQRZRSc4G5pcqeK3U8uYx+y4GuDhXOTry9cA+Ng3y4rk8dmCXEL4XkA+AVADNugL8thBM7YO5j0G6EVgQeXsXt216iTTzxf+oHJGil4BMMoa2K27m5weBH4Ic74OUoXSZucPvvEGOjPAo5skGfo9No2DITcjLAwwd+exZQ2qzT4fLyx1FQoM1AbS6quXPbzQ0i2utPeXQcBRu+0LOSdpfU7DqFlzun3oZyGdRGr1FYe+A0N/Zvjp+X1r9/O78VXZoG8fpvu85KuGcwOItVcYms3p/EXRe2wtvDDosuc7Mgu4INqVKParPPiZ1l16//HHwawe0LANGmk5m3Q5NeMOaTkgoBwNMHYvrAgb+Ky46s17OE0rH/Xa6FS16Gi56Fy/4FviGw+OWy5TiyQfshul4HuWf0W//2WXB0I4S1hT2/QUZS+eM8ugHSj0H7ChSHPWh1IXgFws4553wqoxQcRKfoIBr5eeLpLtwyILao3M1NeOLSDiSczuTrVQedJ6DBYMNHy+II9fdifL/mlTeuCrPvg09GlF+/Y7b2GeyZf3ZdRhLsmKMXeUV1gnH/g7RjEBwDN3wLXuWk3WgxCI5ugqxU/UZ/fHtJ01Ehbu4w8D7tX+h/Fwx6CPYthIMrS7bLy4bj26BJD33uwCZ6odiilyCykzbtFOTCth+K++RmQbLN//WuX/VMpO25vb1Xioe3niHs/EWP/RwwSsFBuLkJd1/YmoeGtyPK2pOhkMFtwxnQKoz/LNpLenYNIxoMBjsRf+oMC3ee4Kb+ze2TmiUnA3b8DMe3wMndZbfZbSmDIxvOrtv8DeTnQK9b9HGLAXD3n3rW4B9W/nVjB+mVwodWwbHNoPLLVgql6fs38I+Exf8oWX5iu37oN+mpTThdr9VO7qR9MOx5iO6ulcNmy9dQUABfXw//6a19DgC750Gz88AvtHI5zpU+t0NGIvz5xjmdxmFKQUSaichiEdkuIttE5EGrfLKIHBaRjdbncps+T4vIXhHZJSL1funX3Re25t6hbc4qFxGeGNGexDM5fPLnfidIZjAUM315PB5uYr9d1fYthLxM/b2siJicM9r2D8WO3EKU0qajpr2hsY1jNqJ95Q/WmH7g5qnPXehkbtKrcnm9/OD8h2D/H8VyQbHCamJFEHe9Tv9sPgDaXarNUt2u00ooaT8sf0dHKHkHaif57vl6NtS+ghmTPYkdpGX8621IPGsZTJVx5EwhD3hUKdUJOA+4V0Q6WXVvKqV6WJ+5AFbdOKAzMAJ4z8o545L0bB7CpZ2jmLY0jtMmRNXgJFKzcvlu7SGu7NakaJfBanE6HuY9WTIUdMfP2h8Q3b1spRD3hw7zbDVEh4dmni6uO7xOv6EXzhKqg5efViaFSiG4GQRGVa1vn9sgIErPFgqDx45s1ONoZCnLxl11jqFR7xb7KbqO1T8XPAuLXtQO37uWagf51+N0naP9CbZc8pJ2hM99rHgc1cRhSkEpdVQptd76noYO5aso3GY0OpwvWym1H9iLzjnjsjxycXvSs/P4eo3xLRicw3drEziTk8+tg1oWF675WPsDTlWSAr4gX68XWPWBfjsFndtn9zz9IOw0Wj+cU4+U7LdnvnaKnnePPradLWz6Gjx8ofM1NRtQ7CD9hn9gOTStwiyhEE9fuOBx7ajeYS1BObJBzxIKFYAInDcJwm1m/8ExEDtY+0ACGsOod3TZTd/rMYa1hfC2NRtLTQiM0gvf9i2qcT6kWglJFZFY9CrOVejFO/eJyC3AWvRs4jRaYdh6ehIoQ4nUlfww9qJjqBsfL9lNB3UIt1JREkopftiTS6iPMLS5Dmerj2OsDq4+vrpEfoFi+vL99I0NoWuMzc5qexboeP+PLoJrP9KmkrJY+T4cWgkhLbVi6H83nNgGWSnQcSSEtdEJ33bN1XZ70G+vexZA6yEQ01eXHd0I9NR1u36FNsNqnvGzxSC9BiHtaNX8Cbb0vhXWfQa/Pq0f9Ce2w8D7K+/Xa4J2Ul/7kY5kAojqDHf9oX0ctU3fv8HGL3XYbIeR4F69x7zDlYKIBAAzgYeUUqki8j7wIqCsn/8Gbqvq+epCfhh7khl2lElfrSc/qhMXdSo51f1i5QHmxG3V9t5Lz6NtVGC9HGN1cPXx1SX+2nuKQ0mZPDWiY8mKlAT9QM3Phf9dDyPf0OYVW07t0eaSdpfBpS/rdAx/vqH7ePpB64u0GSOsjY6IKVQKx7dC6mG92MwvFEJi9Rt5ZE9tf09NgKFP13xQzfqDuFfdyWyLuwdc8W/45BL4/lYoyCv2J1RE1zE68sen1JaloS3Lbu9o3D1g9FQd9VRNhQAOjj4SEU+0QvhKKfUDgFLquFIqXylVAHxEsYmoOvllXIaLO0URHezD5yviS5RvPZzCi3O2M7B1GP7eHjwza6tZBW0H5syZQ0GBE97e6iALth/H19OdYR0jS1akHNQO2tt/02/zy/9Tsr6gAGbdox/6V74FYa2h542w9hOdkqHN8OK9ATpcoSNxCn0OhVFHhSGa0T2KHbq75gECbc8hxsQ7QJuNxE2fu7o076+T5xWmtKiKUhA5WyE4m+ju2gdSAxwZfSTAx8AOpdQbNuW2u3ZcDWy1vs8GxomIt4i0BNoCqx0lX13Bw92NG/o1Z9meU+w7qRf7pGblcs9X6wkL8OLdG3rx5IgOrNqfxI8bztaRmxOSuej1JRxLyapt0esl33zzDW3btuWJJ55g585yFk41AJRSLNxxnMFtw0uGoWalavNPo2b6wd5pFCTF6cVmhSSs1p+Lp0BgY112wRP6Z2aSdrYW0mGkfuPe8IU2seyYrR/WhQ7gJj0h+SAeuanaFxHTFwIizm1wff+mTUHeATXrf/EL2sHsG6qd1Q0MR84UBgE3AxeVCj/9l4hsEZHN6O0LHwZQSm0DvkUnC/sVuLdU+mGXZVy/5ni6C1MX7+XdRXu44p1lHE7O5D/jexLq78W4vs3o0awR/5i7gzO5JWcLS3efJO7UGb5fd6icsxts+fLLL9mwYQOtW7dm4sSJDBgwgGnTppGWluZs0WqVHUfTOJKSxfCOpaJzUhL0z2Ar1UWLQfqn7UrhvQv1m3gnm4d/o2bQ707w9C+ZZqFpH+2A/e0Z+ORSvbisw8ji+iY9AAg/tUbPGOwRvtl9nDZ51RT/cBg7Ha54vfo7obkADvMpKKX+BMr6jZabQUop9TJQznpz1yUi0JvLu0bzw3o9ExjQKowpo7rQJ1bHZbu5CS9d1YUr3/2ThQcVV9j03XlMP8y+X5fAvUPbVLhdqEETFBTEmDFjyMzM5K233uLHH3/ktdde44EHHuD++6vgWKzP5GXDj3eRc9qb89zaMrTd0JL1RUrBekNu3E1H0cT/qW3noNchNO1T7FQt5OIp2jFra0pxc4Obf4TEPTpM0ydYmzYKsb63OGAtAKvN8M2KaD208jYuikmIV0d4ckQHujQJ5tLOjWke5ndWfZemwbSNDGBfcmaJ8l3H0vDxdCM+MYO1B07TN7YWVk7WY2bPns2nn37K3r17ueWWW1i9ejWRkZFkZGTQqVMn11cKu3+FbT/SFTdmeBXAR9O07yAkVtenWOHRhUrB3UOvKC6cKWQk6T0MLnzy7HO7uRebk2yJ6qQ/ZeEbAqGt8E2K0+sBIjqc0/AM545Jc1FHaNLIlzsuaFWmQiikS9Ng4lOLnaTZefnEnTrDDf1a4OflzndrjQmpMmbOnMnDDz/Mli1bePzxx4mM1E5WPz8/Pv74YydLVwtsmkG+fxQ9sqaxqO3/QfpxOGCTbjolQa8KDrAxK7UYBKd26/0D4pYASoeN2otCh3D7yxukuaauYZRCPaJr02BSshXHU7VTed+JM+QXKHo2b8QVXaP5ZfNRMnJMLqWKmDx5Mv36Fa+JzMzMJD4+HoBhw+z4oKuLnDkFe35jd9TlpOFH9JC/6X0CTu4obpOSAMFNtdmnkFhrc5gDf2nTkU9w1dJHVJXCCJ/aSgdhqBCjFOoRXZpqW+2WhBQAdh1PBaBD40DG9mnGmZx85m055jT56gNjx47FzeaB5+7uztixY50oUS2ydSYU5PF19iCaNvKlQ5MQveLWNn118qGzI26iu2t/QPyfsHcRtLywRvHv5dLjRva2vk0vGDM4HaMU6hGdooMQYMthrRR2HkvDy92N2HB/+saG0CLMj+/KiELKys0nv8CscQDIy8vDy6s4F7+Xlxc5OQ0k99TG/5Ef1ZVvDwYwrGOkDkqI7KA3rykkJaE48qgQd0+9KGzLd5B2xL6mIwD/MBKajdY+CYPTMUqhHuHv7UG0v7DtiDVTOJZG68gAPN3dEBGu69OMlXFJRfWg/Q6Xv72MF3+ukztA1joRERHMnl28vfJPP/1EeHi4EyWqJU7sgKMbWeo7nKzcAsb2tmYDkR21czk7Xa9GTjtSdmx+7CC9fgH0amWDy2KUQj2jRbBb0Uxh17E0OjQOLKq76bwWBHp78O6i4kRmM1YfIu7UGZbtOVnrstZFPvjgA/7xj3/QvHlzmjVrxquvvsqHH37obLEcz6YZKHHn2X0dGNktujjXUYSV4uLkLp0vSBWcPVMAaGH5FcLaQiM7bcRjqJOYkNR6RmyQOyuOZLP3RDpHU7Job6MUgn09mTgolv8s2svu42nEhPjyn0V7cRPYd/IMyRk5NPLzquDsrk/r1q1ZuXIl6el69XhAQNVWvYrICOBtwB34r1LqlVL1b6IXYwL4AZFKqUZW3QTgGavuJaXUZ+c4jOqz9Qd2BfTnWGIQj11is9dvZKFS2AF51qr4RmXMFJr01OGjhfsfG1yWKikFEfEHMpVSBSLSDugAzFNK5TpUOsNZxAbpyd3M9XqRka1SALhtUEs++XM/7y7aS4foQE6lZ/PYJe14/bfdbDiUzND2OgRTKcXWw6l0aRrU4Ba8/fLLL2zbto2srOLUIM8991y57a19PaYCF6Oz964RkdlKqSKbnFLqYZv296OzAiMiocDzQB90Esh1Vl+bTQQcTEoCpBzk27yh3NC/ObHhNttZhsTqHEYnduhQVCjbfOThBfes1OkfDC5NVc1HSwEfEWkK/IZOXzHdUUIZyqd5kBsi8IOlFDqUUgoh/l7cNKAFczYf4f3F+7ioQyS3DmqJm8CGA8XPob/2JnLlu3/y9eqGtbbh7rvv5ptvvuE///kPSim+++47Dhw4UFm3fsBepVScUioHmIHe/6M8xgNfW98vBRYopZIsRbAAvYlU7XFIpxDb6taeB4aVyu3v5g7h7bRSSLHuhaBytj0JbAyeNdiIx1CvqKr5SJRSGSJyO/CeUupfIrLRgXIZysHXQ2gZ7k/cyTME+XjQuIzdsu4Y3IrPlseTlp3Ho5e0w9/bg/aNg1h/MLmozS9bdIKztxfu5ppeTe2zN289YPny5WzevJlu3brx/PPP8+ijj3LZZZWaRJoCttozAehfVkMRaQG0BBZV0LfMp66j9gppuecHIpUXoY1j2bp2xVn1HVQojRI2kpThQbhnMMuX134eyoawj0Z9GWOVlYKIDABuBG63yhrGU6QO0rVpMHEnz9Chcdmmn/AAb/5+eUcS03Po3EQ7FHs1b8RPG48UhaYu2H6cVuH+xJ06wxcrDnDHBa0AOH0mh9MZObSKqGGGyTqOj49Won5+fhw5coSwsDCOHj1aSa9qMQ74vibJHB21V8iZbZPZrFoxenAvhnSNPruB+3pYuIQm7qchvKVT9rNoCPto1JcxVtV89BDwNPCjUmqbiLQCFjtMKkOFdLUWsZX2J9hyy4BYHr64XdFxr+YhpGfnsfdEOhsOnuZUejYPDm/L4LbhvLdkL2lZuWw9nMKIt5cyeupfZOe5ZoLaK6+8kuTkZB5//HF69epFbGwsN9xwQ2XdqrPXxziKTUfV7Wt/crPwObWFDQVt6dG8UdltIq28RIfXlu1kNjQoqjRTUEr9AfwBICJuwCml1AOOFMxQPoVv/xUphdL0tB4I6w+eJu5kOp7uwtAOkbQM92fUu3/x8DcbWb4vEYCMnHzW7D/N+W2L4/fjT50hwMeD8ABv+w2klikoKGDYsGE0atSIa6+9lpEjR5KVlUVwcKUbpKwB2lr7fBxGP/jP0iQi0gEIAWxtNPOBf4hIYUrRS9AvWLXD0Y24qzz2eXcs09QI6AVsYIWjGqXQ0KnSTEFE/iciQVYU0lZgu4g87ljRDOXRNzaEJ0a058ruTarcp2W4PyF+nqw/cJr5244zqE04QT6edItpxGVdGvP7jhO0iQxg3oOD8fJwY/GuE0V9z2TnMfI/f3L+q4t4+ZftnEzL5lhKFnM2HeH9JfvqzazCzc2Ne++9t+jY29u7KgoBpVQecB/6Ab8D+NaaMU8REZtNBRgHzFA2W+QppZLQ286usT5TrLLawXIyFzTtW36UWXBzvYUmlL1GwdCgqKpPoZO1v/KNwDzgKWAd8JrDJDOUi4e7G/cMaVOtPiJCz+Yh/Lr1GGnZeUwa0rqobvKozvRo1ohbBsTi6+XOgFZhLN51gmdHarPCr1uPkZ6dxwXtIvj4z/188ld8ibQZ0cE+XNWznIiVOsawYcOYOXMm11xzTbVCcZVScym1F4hS6rlSx5PL6fsJ8En1pT13cg+s4khBJK1atiq/kZsbRLTXm9yYmUKDp6o+BU9rv+WrgNnW+gSTTKee0at5I9Ky8xChxI5bUUE+3HVha3y9dOzA0PYRxJ08w4HEMwD8uOEwzUJ9+ezWvvz+yIX8bXBLnh3ZiZ/uHUTjIJ+iSKaKOJqSybhpK5hXhbaO5MMPP2Ts2LF4e3sTFBREYGAgQUFBTpXJYShFwaHVrFdt6dGsUcVtC/0KZqbQ4KmqUvgQiAf8gaVW2F2qo4QyOIaezbVZu0+LECICy/cNDLEWuC3ZdZKjKZn8te8UV/eMQURoFRHA05d15PbzW9K9WSMu69qYP3afJC2r/HWMWiGsZGVcEm/+vhsb60qtk5aWRkFBATk5OaSmppKWlkZqqoveyimH8M48wYaCtsVpLcojuju4eRRvtmNosFTV0fwO8I5N0QERabj71dVTujdrRCM/T67tVfHbYGy4P63C/Vm86wSZufkoBdeUYx66oms0n/4Vz8IdJ4pMSNl5+Ww/koqflwd5BQXc89V6ktJzuOm85ny58iDrDybTu0VImedzNEuXLi2z/IILLqhlSWoBy59wolF3gnw8K27b+1a9b4Kf2bmvoVPVNBfB6KX6hf85fwBTgJRyOxnqHAHeHqz++3A83Su3pQ9pH8lXqw5wMDGDXs0blUyNYEOv5iFFJqSrejYlL7+A8dNWllgoF+jtwee396NdVCA/rj/M16sPOk0pvPZasRssKyuL1atX07t3bxYtWlRBr/qJOrSKLLwJatG98sYeXhDV2fFCGeo8VXU0f4KOOrrOOr4Z+BS4xhFCGRyHl0fVLIZDO0TwyV/7iTt1hpeu6lJuOzc34bKujflq1UHSsnL5YuUB1h9M5okR7WkR6k96di59Y0OLFsON6tGUHzck8NyVnSp/e3UAc+bMKXF86NAhHnrooVqXw+FkJlOwZSYr8zvQtXkDSA1usBtV9Sm0Vko9b+V+iVNKvQBUEM5gqO/0axmKr6c7Xu5ujOxWxipYG67oGk1OXgHvLdnHWwv2cHnXxky6sDVXdIvm+r7NS6yOHt+vGVm5Bfy0ofbWb1VETEwMO3bsqLxhfeOPV3HLPM1redfTszIns8FgQ1VnCpkicr5S6k8AERkEZFbUQUSaAZ8DUehIpWlKqbetrJHfALFo5/V1SqnTouMD3wYuBzKAiUqp9dUfksEeeHu4c2P/5iioNN12oQnp/SX7CPP34sXRXcoN9+zaNJjOTYL43+pD3HRei1rP0Hr//fcXXbOgoICNGzfSq5cd9xuuC5zYAas+ZH3EaPYebVWtRY4GQ1WVwt3A55ZvAeA0MKGSPnnAo0qp9SISiE4ZvACYCCxUSr0iIk+h1zw8CVwGtLU+/YH3KSfpmKF2eMZap1AZbm7C5V2j+eSv/fzjmq6EVbDqWUQY1685z87aypbDKXSLaWQnaatGnz59ir57eHgwfvx4Bg0aVKsyOBSlYN6T4B3I2+o6ujYNxtPd7KVlqDpVjT7aBHQXkSDrOFVEHgI2V9DnKHDU+p4mIjvQ2SFHA0OsZp8BS9BKYTTwubUadKWINBKRaOs8hjrO/Re1YXDbcIZ2iKy07ZXdonnup60s2XXSLkqhMNqpMOS2IsaMGYOPjw/u7npNRn5+PhkZGfj5+Z2zHHWCnb/A/j/IuvhV/voF7hkS5myJDPWMar1CKKVSlVKFQd2PVLWfiMSiNx1ZBUTZPOiPoc1LUI0Uw4a6R4i/V5UUAmhzVIfGQazan2iXa0//K56r31vOjqOVrzcYNmwYmZnFls/MzEyGDx9uFznqBLt/Bd9Q/gq+kvwCxcDWxslsqB7nsh1nlYzBIhIAzAQesmYYRXVKKSUi1VrJ5Kic8/UFVxljjFc2f8Tl8fuixXi4Fd8TNRnfdyv1Q/7tn1YwrkPFCftOnTrF2rVrS5SdOHHCJX6nACQfgLDWLItLxsfTjV4tGjlbIkM941yUQqUPcys1xkzgK6XUD1bx8UKzkIhEA4WZ16qUYthROefrC64yxqzwoyz4cj0hrbvTu0XxgqnKxpeSkUuQr0eRs/hkWjb75v+Oh5uw9pQ77w6+AI8KbOhRUVEEBQUVOZfXrVtHRESES/xOATgdD836s3zfKfrGhuLtYbY9MVSPCs1HIpImIqllfNKAClN0WtFEHwM7lFJv2FTNpthJPQH4yab8FtGcB6QYf4Lr0q+ltnWvjKtawtCUzFwmz95Gzxd/48OlcUXli3eeQCm476I2nErPZtmeUxWe56233mLs2LEMHjyY888/n+uvv55333235gOpS+TnQsphzvjFsPt4Oue3MaYjQ/WpcKaglDqXWLZB6EVuW2y27vw78ArwrbW15wGKF8TNRYej7kWHpN56Dtc21HFC/b1oFxXAqv1J3FsqYcrpMzn8c94Oth9NpXmoH1FBPszZdISkMzlEBvrw0dI4JlgZXRfsOE7TRr5MGtKaz5bHM3N9QoW+jb59+7Jz50527dpFWmYuyxO96Najo4NHW0ukJIDKZ1e2nnkNMkrBUAMcFqumlPpTKSVKqW5KqR7WZ65SKlEpNUwp1VYpNbwwt7zS3KuUaq2U6qqUWlvZNQz1m/4tw1gXn0RefkFR2ZpjeVz85h/8sP4wwb6e7DyaxlcrDxIb5s/s+87n7XE9SDyTw3frDpGZk8+yPScZ3jESbw93RnVvwm/bj5OSWX5yvqlTp5Kens7O7Ebc9+sp3pm/ladeer02hut4TscDsCo5iEZ+nnSKdtHsrwaHci4+BYPhnOjfKpQvVh5g65FUejRrxBsLdjN1YzZdmgbxxe396Wg91JRSRT4EpRS9mjdi2tI4IgN9yMotYHgnHcB2be8YPltxgF82H+WG/s3LvOa0aR+xzLMXK+OS6NW8EZ/f3o+brhgCzz9RK2N2KMkHAFhwxJuBrcNwc6vdhYEG18CsajE4jX4ttZljVVwiv28/zjsL9zCoiQc/3jOoSCEAJVY9iwh3X9iahNOZTJmzjUBvD/pb/omuTYNpExnAzPUJ5V4zMT2TFfsSmTK6M9/fPZAOUQHk5OQ4aIS1zOl4lJsHG1MDTCiqocYYpWBwGpGBPrSK8OfnzUd55NuNdGkaxITOXpWuwB3eMYo2kQEcScniwvYRRUn+RITr+sSw7sDpMtcsZOXmk9+kOwW/v0nTjH0sXryI8ePHc9lllzlkfLXO6QOk+TShADfjZDbUGKMUDE7lvFZhbDmsM7C/f2NvvKqQ1tvNTbjrAp2P8eJOUSXqruvTDB9PNz5fEX9Wv+/WHsJr4M2MG30ZH3zwAR988AFdu3YtsZitXnM6nqMSSWSgNy3CXGSFtqHWMUrB4FQubBeBm8Ab1/WgWWjVH2TX9orhk4l9GNmtZGR0Iz8vrurRlB83HCY5o9gslJNXwPtL9tEnNozxIy8iNjaW1atXs2jRIjp2rDz6SERGiMguEdlr5ewqq811IrJdRLaJyP9syvNFZKP1mV3lQVaX5APszQ2nc5OgWk80aHAdjKPZ4FQu6RTF2mcuJtS/4kyspXFzEy7qEFVm3YSBscxYc4hv1x7izgtaA/DurKVs/+UTEo6s5oEmUVx//fUALF68uNJriYg7MBW4GJ1+ZY2IzFZKbbdp0xZ4GhhkZf21jYvNVEr1qNYAq0t2GmQksjUvhM5NKtl602CoADNTMDgVEam2QqiMjtFB9GsZyucrDpBfoFixL5FHr7sIj+PbWDh/Ln/++Sf3339/UVK8KtAP2GvtJZIDzEAncLTlDmCqUuo0gFLqBLXJaR15dKAggk5NTCiqoeaYmYLBJZkwIJZ7/7ee26av4Y/dJ+l88ws0T97IRRddxIgRIxg3bhw6IW+VKCtZY+m07u0AROQvwB2YrJT61arzEZG16HTyryilZpV1kXPJ6xV+ciVdgIMqkrSDO1iSuKuqY6sTuEpOr4qoL2M0SsHgklzSOYrGQT78sfskEwfG8sSIS/Hz8uDMmTP89NNPvPXWW5w4cYJJkyZx9dVXc8kll5zrJT3Qe4EMQeftWioiXZVSyUALpdRhEWkFLBKRLUqpfaVPcE55vZZvhW2Q5NWEsZcNrXdrFFwlp1dF1JcxGqVgcEk83d34ZGJfsvPyS+yz4O/vzw033MANN9zA6dOn+e6773j11VcrUwpVSdaYAKxSSuUC+0VkN1pJrFFKHQZQSsWJyBJ0GvmzlMI5kXyAM+JP06jG9U4hGOoWxqdgcFk6NQmqcOOdkJAQ7rzzThYuXFjZqdYAbUWkpYh4AePQCRxtmYW1eZSIhKPNSXEiEiIi3jblg4Dt2BmVFM+Bggg6N21k71MbGhhmpmAwVIJSKk9E7gPmo/0FnyiltonIFGCtUmq2VXeJiGwH8oHHlVKJIjIQ+FBECtAvYa/YRi3Zi9zE/drJbPIdGc4RoxQMhiqglJqLzuRrW/aczXeF3o3wkVJtlgNdHSwc7ikHOajaMchEHhnOEWM+MhjqO+nHcS/I5giRtI0KcLY0hnqOUQoGQ33HSpmdF9zC7LRmOGeMUjAY6jvJeglFUOPWThbE4AoYpWAw1HPSUhIBaNYk2smSGFwBoxQMhnrOiaTTALRuWv42pAZDVTFKwWCo55xI1EqhY/OyEwQaDNXBKAWDoZ6TePo0OXgS5OfjbFEMLoBRCgZDPSa/QJGWmkKeu6+zRTG4CEYpGAz1mN3H03DPzwIvs9OawT4YpWAw1GPWHTiNn2Tj6e3vbFEMLoLDlIKIfCIiJ0Rkq03ZZBE5bLM14eU2dU9bWx3uEpFLHSWXweBKrDtwmmCPXDx8zUpmg31w5ExhOjCijPI3lVI9rM9cABHphM482dnq8561BaLBYKiAtQeSiPTORzzNTMFgHxymFJRSS4GkKjYfDcxQSmUrpfYDe9FbIBoMhnI4kZrFoaRMQrzywNM4mg32wRk+hftEZLNlXipMdl/WdodNa180g6H+sO6AXp8Q6JZjHM0Gu1HbqbPfB14ElPXz38Bt1TnBuexj6wq4+hhdfXz2ZN2B03h5uOGjssCYjwx2olaVglLqeOF3EfkI+Nk6rMp2h4XnqPk+ti6Aq4/R1cdnT9YeOE33mGAkLdPMFAx2o1bNRyJim7HraqAwMmk2ME5EvEWkJXpv29W1KZvBUJ/Iys1n25EUercIhZwM8DRKwWAfHDZTEJGv0XvWhotIAvA8MEREeqDNR/HAXQDW1obfoveuzQPuVUrlO0o2g6G+s/t4Grn5ih4xQbDKKAWD/XCYUlBKjS+j+OMK2r8MvOwoeQwGV+JoShYAMYFugDLmI4PdMCuaDYYqICIjrIWVe0XkqXLaXCci20Vkm4j8z6Z8gojssT4T7CHPiVStFKJ8rQm1mSkY7ERtRx8ZDPUOayHlVOBidLj0GhGZrZTabtOmLfA0MEgpdVpEIq3yULTptA/abLrO6nv6XGQ6npqNu5sQ6pmnC4xSMNgJM1MwGCqnH7BXKRWnlMoBZqAXXNpyBzC18GGvlDphlV8KLFBKJVl1Cyh7pX+1OJ6aRUSAN+55mbrAmI8MdsLMFAyGyilrcWX/Um3aAYjIX4A7MFkp9Ws5fctcmFmdNTg7DmThK4p1K5fRG9iyM47EU0uorzSE9Sn1ZYxGKRgM9sEDHUo9BL3OZqmIdK3OCaqzBueVjUtpE+lH726BsB669uoHrS481zE4jYawPqW+jNGYjwyGyqnK4soEYLZSKtfK37UbrSSqvDCzOhxPzSIqyFuvUQDwMiuaDfbBKAWDoXLWAG1FpKWIeKEz+s4u1WYWepaAiISjzUlxwHzgEhEJsXJ9XWKV1ZjsvHxOZ+QSFegDuWd0oXE0G+yEMR8ZDJWglMoTkfvQD3N34BNrweUUYK1SajbFD//tQD7wuFIqEUBEXkQrFoApSqmqZg8ukxOp2QBEBflAruVoNllSDXbCKAWDoQpYe3/MLVX2nM13BTxifUr3/QT4xF6ynEjTaxQig7whxZopGPORwU4Y85HBUM84lmI7U7B8CsZ8ZLATRikYDPWM44WrmYN8ih3NRikY7IRRCgZDPeN4WhZe7m6E+HnqmYKHD7iZf2WDfTB3ksFQzziRmk1kkDciopWCmSUY7IhRCgZDPUOvUfDRBzkZxslssCtGKRgM9YyihWtgZgoGu2OUgsFQzziRmk1koDVTyM0waxQMdsUoBYOhHnEmO4+07DxjPjI4DKMUDIZ6xIm0wjUKheajM8Z8ZLArRikYDPWIEmsUQKe5MOYjgx0xSsFgqEcUKwVrpmDMRwY7Y5SCwVCPOHumYMxHBvtilILBUI84npqNn5c7Ad5WLsvcTLMVp8GuGKVgMNQjCheuiQgUFJh1Cga74zClICKfiMgJEdlqUxYqIgtEZI/1M8QqFxF5R0T2ishmEenlKLkMhvqMXqNg+RPyCvdSMErBYD8cuZ/CdOBd4HObsqeAhUqpV0TkKev4SeAy9NaFbdEbor/P2RujGwwNnuNpWXSPaaQPXGwrztzcXBISEsjKynK2KA4hODiYHTt21Oo1fXx8iImJwdPTs8p9HKYUlFJLRSS2VPForC0Lgc+AJWilMBr43NqoZKWINBKRaKXUUUfJZzDUN5RSZ6e4AJcJSU1ISCAwMJDY2FhtHnMx0tLSCAwMrLXrKaVITEwkISGBli1bVrlfbfsUomwe9MeAKOt7U+CQTbsEq8xgMFhk5RbQJjKAluEBusDFNtjJysoiLCzMJRWCMxARwsLCqj3zctp2nEopJSKquv1E5E7gToCoqCiWLFlSVJeenl7i2BVx9TG6+vjOBV8vd36+f3BxgYuZjwCjEOxMTX6fta0UjheahUQkGjhhlR8Gmtm0i7HKzkIpNQ2YBtCnTx81ZMiQorolS5Zge+yKuPoY6+r4RGQE8DbgDvxXKfVKqfqJwGsU37fvKqX+a9XlA1us8oNKqVF2EcrFZgrOJjExkWHDhgFw7Ngx3N3diYiIAGD16tV4eXmV23ft2rV8/vnnvPPOOxVeY+DAgSxfvtx+QjuA2lYKs4EJwCvWz59syu8TkRloB3OK8SfUgPxcyE4Dv1BnS+JSiIg7MBW4GG3aXCMis5VS20s1/UYpdV8Zp8hUSvWwu2BGKdiVsLAwNm7cCMDkyZMJCAjgscceK6rPy8vDw6PsR2afPn3o06dPpdeo6woBHBuS+jWwAmgvIgkicjtaGVwsInuA4dYxwFwgDtgLfATc4yi5XJrl/4F3+0B+nrMlcTX6AXuVUnFKqRxgBjo4wrnknNE/zeI1hzFx4kTuvvtu+vfvzxNPPMHq1asZMGAAPXv2ZODAgezatQvQM9yRI0cCWqHcdtttDBkyhFatWpWYPQQEBBS1HzJkCGPGjKFDhw7ceOON6DgbmDt3Lh06dKB379488MADReetLRwZfTS+nKphZbRVwL2OkqXBcHgdZCTC6XgIb+NsaVyJsgIhygqZvlZELgB2Aw8rpQr7+IjIWiAPeEUpNausi1TXX9b46Ho6ACvXbSbL93j1R1WHSE9PJzg4mLS0NABe/W0fO4+n2/UaHaICePKS1lVqm52djaenJ7m5uRw7doz58+fj7u5Oamoqc+fOxcPDg8WLF/PEE0/w5ZdfkpGRQV5eHmlpaWRnZ7Nt2zZ++eUX0tPT6dWrFzfddBNu1j7aaWlpZGRksGHDBlatWkV0dDQXX3wxCxYsoGfPntx5553MmzeP2NhYbr311qLz1pSsrKxq+emc5mg2OIBTu/XPkztdXynkZsLqj6Dv7dV3tGYmg08w2NepOQf4WimVLSJ3oUOuL7LqWiilDotIK2CRiGxRSu0rfYJq+8tW74FdcN7giyAgwp5jqXWWLFmCj49PUcimp5cn7u7udr2Gp5dnlUNCvb298fb2xtPTk/Hjx9OoUSMAkpOTue2229izZw8iQm5uLoGBgfj5+eHh4UFgYCDe3t6MGjWK8PBwwsPDiYqKIiMjg+DgYICi9v369aNDhw4A9O7dmxMnTnD48GFat25N165dAbjllluYNm3aOYWy+vj40LNnzyq3d32lkHwIPHzq/T9NpeTnQlKc/n5yJ3Ss3SlntSgogI1fQrP+ENG+ZudYNx0WPKsf7r0nVL1f8iFtYrvi39Dzpqr2qjQQQimVaHP4X+BfNnWHrZ9xIrIE6AmcpRSqjQubj56/srOzRSjC37/4pePZZ59l6NCh/Pjjj8THx5cbFOHt7V303d3dnby8s026VWnjDFw799GJnfD+QPjmRmdL4niS4qDAuqlO7nKuLJWxdwHMvh+m9oOvx8PBVdXrX5APK98vPld12D4L8rL0LKPqrAHaikhLEfECxqGDI4qwoukKGQXssMpDRMTb+h4ODAJKO6hrRqGj2cM1Fq/VB1JSUmjaVC+hmj59ut3P3759e+Li4oiPjwfgm2++sfs1KsN1lcKZRPj6eh2Nc2iVVhCuTKEi8I+Ekw5YSn98G2Qk2edc234E72C48Ek4uBI+uQR+eVSbhKrCzl8g+QA0agFxf+hZUpWvPQvEDY5uhKObqtRFKZUH3AfMRz/sv1VKbRORKSJSGF76gIhsE5FNwAPARKu8I7DWKl+M9inYRynkWGmz3Vz337iu8cQTT/D000/Ts2dPh7zZ+/r68t577zFixAh69+5NYGBgkdmp1lBK1dtP7969lS2LFy/WX3KzlfrkMqWmRCi1c65SL4Qq9evflStQNMbS/PEvpZ4PUmr2g0q9GKlUfp79LppyRJ/zx3vO/Vy5WUr9I0apHyfp4+x0/bd5Pkipqeep1XOmV36Ojy9V6s0uSm39Uffbv6xq1z59ULf/7Vl9b/z8aIXNgbWqrt3btsx5WKlXW1Zt7HWcxYsXq+3btztbDIeSmppapXZpaWlKKaUKCgrUpEmT1BtvvHFO1y3r91rRve2arxjzHocDf8FV70H7y/Rn09eQl+NsyRzHyd0Q3Aya9tLmkeQD9jv3X2/rc+75TfsDykIpSFgLf74JX14L854su92+xZCdCp2u0sde/nDpy3DTTDhzih4b/w9yK1iWf3g9HFwB/e+G1heBmwfsKceEVJBfUt4dlsWn1wToNBo2f1v12UldJDcDPF1nNbNB89FHH9GjRw86d+5MSkoKd911V61e3zWVQscrYdjz0HWMPu55iw7V3D3PuXI5klO7ILwdROhoBrv5FdKOwbpPITAazpyA41vObpNzBmbcCP8dBr9PhkNrYM1/y37gbvtRO4dbDSlZ3mY4XP0+nnlpsP+PsmUpyNdrMbwCoefN4BMEzc6DvQvPbpufB59dCZ+OKJZj2yxo3BXCWkOvWyA7BbbPPrtvfSHnjEs6mRs6Dz/8MBs3bmT79u189dVX+PnV7t/YNZVCm+Ew+BGb42EQ2ATWf+E8mRxJQQGc2mMpBSua56SdfCh/va1t9mM/08el38rTjsP0K7TCvXgKPLYXrpmmnd5HNpRsm5sFu+ZChyvBo4yUAbEXkOfuBzt/Llm+5r/w3+HwzxjY9oOONvIJ0nVth2tFlVpqAfzyt/Vs8dAqmPMgpCRAwmo9QwCIPR9CW8H6z6m35Ga6TIZUQ93BNZVCadzcoccNsG8hpJSZUqli1n4CK6bqcMa6SGqCNiVEtNNv4YFN7ONYTzumx97temjeH6K7l3wrTzmsH9Ynd8G4r2HQgzr0N6avrj9UKqpo3yJtOup8ddnX8/AiKbQX7JqnZwUApw/A3Md18rdet8Do9/QssJA2F+ufe38vLju+HZa8ok1UQ5+Bzd/omQxAJ+vaInq2ceBPOLW3Rr8ep2PMRwYH0DCUAuiYdFUAvz5ZPTvyxv/Bzw/D/L/DW13go2FwZKPDxKwRhYvWwq1ZQkT7ymcKuVmw5mO9kKs8/npHzxIusPK/tBmuH/SFfRa/DOnH4da50H5EcT//MAhrA4dWlzzf9lng0whaXVj+UML7w5mT2j8BepaAwI3fwmWvQs8bS84yojprJVgYmpqfC7MmgXeQXotwwWN6dnB0I0R1Kbmor8cN0OOm+hu9Y8xHBgdQT/8bakBoSxj+AuyYA59eDqlHKu9zeB3MeQhaXgD3rtFvqCkJ8N0EHepaUw6tgexqLuEvKIDfniEopYyH/UlLKRSajiI6aEVRnlMYYOV78Msj8O3NZYd0Jh/SD+Ru12sbPOi3cpWvbf4ndmjnfb87oEkZqyWb9ddKwcrnQm4m7JwLHUaCe/m7QCWG9QY3T21CysnQ5p2OV0JwTNkdRLR5cM8CmD4SpvbXCmDkG+Afruuvel9f9/yHS/YNbAxXTdVmpPqI2Z/Z4AAajlIAOP8hGPc/be6YNgS+nQCz7tWmhtIRL+knYMZNEBgFY6Zr08zgR2DsdEg+CL8+XTMZVn8EHw/Xq2q3fF/80LRl2b/hi6tLzmjWfgzL/0PzgzPPbn9qF/iG6ocgQGQH/cBIKcfclZWifQWNWsD+pXqNQGk5lvxT/xz69+KymL56fcGeBbDoJfAKgMGPln2NZv0g41TxKutdcyEnDbqNLbu9Rb6Hv7b37/xFm32yknWkUUX0vAlCYiE/ByI7wqX/LPYdgI5wGvdVceCBq5CbaZSCHRk6dCjz588vUfbWW28xadKkMtsPGTKEtWv1jPbyyy8nOTn5rDaTJ0/m9ddfr/C6s2bNYvv24qUrzz33HL///nsFPRxLw1IKAB2ugL8t0E7ZE9shbrF+AP72THGb3Cz45ibIPK2ViH9YcV2LATDoIdjwhX5wgX7IVsXfsHMuzHsCWg2FgEiYeTt8Pkr3LyQ7HZa9qe3vvz6ly1KPwO8vgLgTmrTh7FnGyd0l00UURSCVY0Ja+b5+2F73uX6or/8MVrxbXH98e/EsoJFNdgd3D2g9REcQ7fwZBj5QfpruZla+uEIT0qYZENQUYgeX3d6WDldA0j79d2ncDZqfV3H75ufBPSvg9t/0w39AA0mya8xHdmX8+PHMmDGjRNmMGTMYP7683J7FzJ07tyg/UnUprRSmTJnC8OHDa3Que9DwlAJoO/TEn+G+NfDIdhhwH6z5SIcnKgVzHtC286vf1yGMpRnytH5YzZoE/+kDrzTX/oafHy7brKSUfjh+f5s2tYz7H9yxGC5/Xb+pr5ha3HbLd/qNuu2lOr/Ppm+0o7UgF658GzeVW9KpCsXhqIVUFIGUkaSv12EkNOmhHbGdRmulOOteXb9wig77LGsW0GY45KSDfwScV/YbFKD9G97B+veYfkI7qLuO1U7/ymh/uf6ZflzPEsxuXGVjzEd2ZcyYMfzyyy/k5Oj1TPHx8Rw5coSvv/6aPn360LlzZ55//vky+8bGxnLq1CkAXn75Zdq1a8f5559flFobdFqMvn370r17d6699loyMjJYvnw5s2fP5vHHH6dHjx7s27ePiRMn8v333wOwcOFCevbsSdeuXbntttvIzs4uut7zzz9Pr1696Nq1Kzt32i9jg+snxKsKw57X4Yuz79M/N3+jH5YVRMlw7X/1m35wM213z0iEVR/Ant/1m2pKgra7Jx/Qb/q5GdpcM/6b4re7fndYSuE9/fDzDdFmoqguWnF8diX8dK9WCMMnQ48byJn3d7x2zIHOV+lznEnU17adKfiGQEDjstcqLH9HK65Cs5CbG1zzEYS21nW7ftEzpGHPlz0LaHuJfhAN/T/wDij/d+rmBjF9tDLcOlP7IrqPq+wvoQluqpVn8kHocm3V+jQ0Cgr0gkJXVQrznoJjZayJORcad4XLXim3OjQ0lH79+jFv3jxGjx7NjBkzuO666/j73/9OaGgo+fn5DBs2jM2bN9OtW7cyz7Fu3TpmzJjBxo0bycvLo1evXvTu3RuAK6+8kvvvvx+AZ555ho8//pj777+fUaNGMXLkSMaMKWnezMrKYuLEiSxcuJB27dpxyy238P777/PQQw8BEB4ezvr163nvvfd4/fXX+e9//2uHX1JDnSmUxsMLxnyi/9FWfQBdryuOuCmPiPZw958w/mu48HF9s932q3ai/vqUdtKeOalvxD63wSUvw63zzs7WOuRp/ea9YqqOuDm2Rbd399Ay+QRDVFc9m3FzJzGsn15ZnKffGDhlPfjD25c8b1QnbeJZ/q522KYdg/n/p6/T5Ro9WyoavzcMfx7u/EM7XUNalm/HD2wMj++DPrdW/ntt1l+b6NZ+osNZIztW3qeQqz/Uq5w9farepyFRmAzPmI/siq0JqdB09O2339KrVy969uzJtm3bSph6SrNs2TKuvvpq/Pz8CAoKYtSo4p1Xd+zYweDBg+natStfffUV27Ztq1CWXbt20bJlS9q101aACRMmsHTp0qL6a665BtBptwsT6NkDM1MoJLQVjP1UP0hHvFozk0Xz8+CelZB2VEfLVMVUEtVJv/Wv+kAnnfMKgG7X6bqgaLh3lX5oWxE7JyMGEH3sdz3DaH0RLP6HTg0eXerN5dJ/av/Fb/+nU0/kpGtHbNfr4JKXypalcRf420K9RsC9glujqg+iZv0ApSOhRpT/hlYmNU2p3VBw9a04K3ijdySjR4/m4YcfZv369WRkZBAaGsrrr7/OmjVrCAkJYeLEiWRlVZCGpQImTZrETz/9RPfu3Zk+fXq1Nr4pi8LU2/ZOu21mCra0vRiufPvc3k49vCCkRdUUQiEXPqWdhrvnaVOUt82GGv7hJY6TG3XT9v4dc7RCiF8GV7yhHde2RHaACbPh1l+1sup2Hdy3Fq75sOK9JUQqVgjVoWlvnZFU3KGLi0X+OJuivRTM4jV7EhAQwNChQ7ntttsYP348qamp+Pv7ExwczPHjx5k3r+JUORdccAGzZs0iMzOTtLQ05syZU1SXlpZGdHQ0ubm5fPXVV0XlgYGBZe6s1r59e+Lj49m7Vy+u/OKLL7jwwvLX+NgLM1OoC0R20Lbzrd9r01EFFLh7aeW15XvIPaNX5fasYL+IFgP0xxn4BOkw1oAo19/kqDZJPqgXVYJJc+EAxo8fz9VXX82MGTPo0KEDPXv2pEOHDjRr1oxBgwZV2LdXr15cf/31dO/encjISPr27VtU98wzz9C/f38iIiLo379/kSIYN24cd9xxB++8806Rgxn0jmmffvopY8eOJS8vj759+3L33ZWEZ9sBUWXFydcT+vTpowrjhKGcLQvrCxlJOlKn/WUVNluyZAlDwpPg+1u1r+FvC+r2gyHnjJ4pVHH2VZf+hiKyTinVxxnXLvPe7tcNvriqeB+IqK4w/n/QqLkzRLQrS5YsISoqio4dq+F3qmekpaWd07aaNWXHjh1n/V4rurfNTKGu4BdaqUIoov1l0H8SnHd33VYIYMwb9sQ3REewdblWhxQXrjQ3GOyIUQr1EU9fpzniDE5EBK530Uy/hjqDcTQbDAaDoQinzBREJB5IA/KBPKVUHxEJBb4BYoF44Dql1GlnyGcwGJyDUgoxK9jtRk18xs6cKQxVSvWwcXY8BSxUSrUFFlrHBkOdQERGiMguEdkrImfdmyIyUUROishG6/M3m7oJIrLH+kyoXcnrDz4+PiQmJtboQWY4G6UUiYmJ+PhUL8S+LvkURgNDrO+fAUuAcjb6NRhqDxFxB6YCFwMJwBoRma2UKr209Rul1H2l+oYCzwN9AAWss/qaWXApYmJiSEhI4OTJk84WxSFkZWVV+wF9rvj4+BATU07a+XJwllJQwG8iooAPlVLTgCilVOGeiseAqLI6isidwJ0AUVFRJVYFpqenn/MqwbqOq4+xjo6vH7BXKRUHICIz0C8x5ec7KOZSYIFSKsnquwAYAXztIFnrLZ6enrRs2dLZYjiMJUuW0LNnGXuP1DGcpRTOV0odFpFIYIGIlEjxp5RSlsI4C0uBTAMdy20b016XYtwdhauPsY6Orylgmxs9AehfRrtrReQCYDfwsFLqUDl9m5Z1kYb8wuPq44P6M0anKAWl1GHr5wkR+RH9JnZcRKKVUkdFJBo44QzZDIYaMgf4WimVLSJ3oU2gF1XnBA35hcfVxwf1Z4y17mgWEX8RCSz8DlwCbAVmA4VOuAnAT7Utm8FQDocBm92GiLHKilBKJSqlrNS1/BfoXdW+BkNdotbTXIhIK+BH69AD+J9S6mURCQO+BZoDB9AhqUmVnOuk1baQcOCU/aWuU7j6GOvS+FoopSJExANtEhqGfqCvAW5QShXlPi6c5VrfrwaeVEqdZzma1wG9rKbrgd7m3j4LVx8f1K0xtlBKlZmQrNbNR5azrnsZ5Ynof7rqnKvEoERkrbNy1dQWrj7Gujg+pVSeiNwHzAfcgU+UUttEZAqwVik1G3hAREYBeUASMNHqmyQiL6IVCcCUyhSC1a9B3duuPj6oP2Os1wnxSlNffunngquP0dXHV1Nc/ffi6uOD+jNGk+bCYDAYDEW4mlKY5mwBagFXH6Orj6+muPrvxdXHB/VkjC5lPjIYDAbDueFqMwWDwWAwnAMuoxQqS1hW3xCRZiKyWES2i8g2EXnQKg8VkQVWcrUFIhLibFnPBRFxF5ENIvKzddxSRFZZf8dvRMTL2TI6E1e7r8Hc23X93nYJpWCTsOwyoBMwXkQ6OVeqcyYPeFQp1Qk4D7jXGpOrZZN9ENhhc/wq8KZSqg1wGrjdKVLVAVz0vgZzb9fpe9sllAI2CcuUUjlAYcKyeotS6qhSar31PQ19czVFj+szq9lnwFVOEdAOiEgMcAV6BTCiE+lfBBTuXl6vx2cHXO6+BnNvW03q7PhcRSlUOelYfUREYoGewCqqmE22nvAW8ARQYB2HAclKqTzr2KX+jjXApe9rMPe2E+SqFFdRCi6LiAQAM4GHlFKptnVKh47Vy/AxERkJnFBKrXO2LAbnYO7tukld2mTnXHDJpGMi4on+p/lKKfWDVewq2WQHAaNE5HLABwgC3gYaiYiH9UblEn/Hc8Al72sw9zZ1+G/pKjOFNUBby7vvBYxDZ12tt1g2yI+BHUqpN2yqXCKbrFLqaaVUjFIqFv33WqSUuhFYDIyxmtXb8dkJl7uvwdzbVrM6Oz6XUAqW5i1MWLYD+NY2g2U9ZRBwM3CRFO/7eznwCnCxiOwBhlvHrsSTwCMishdth/3YyfI4DRe9r8Hc23X63jYrmg0Gg8FQhEvMFAwGg8FgH4xSMBgMBkMRRikYDAaDoQijFAwGg8FQhFEKBoPBYCjCKIV6iIjk24TybbRn9kwRiRWRrfY6n8FQHcy97XxcZUVzQyNTKdXD2UIYDA7A3NtOxswUXAgRiReRf4nIFhFZLSJtrPJYEVkkIptFZKGINLfKo0TkRxHZZH0GWqdyF5GPrFz3v4mIr9MGZTBg7u3axCiF+olvqSn29TZ1KUqprsC76EyNAP8BPlNKdQO+At6xyt8B/lBKdQd6AYWrZdsCU5VSnYFk4FqHjsZgKMbc207GrGiuh4hIulIqoIzyeOAipVSclXDsmFIqTEROAdFKqVyr/KhSKlxETgIxSqlsm3PEAgusjU4QkScBT6XUS7UwNEMDx9zbzsfMFFwPVc736pBt8z0f43sy1A3MvV0LGKXgelxv83OF9X05OlsjwI3AMuv7QmASFO0nG1xbQhoMNcDc27WA0ZL1E18R2Whz/KtSqjB0L0RENqPfiMZbZfcDn4rI48BJ4Far/EFgmojcjn5rmgQcxWBwHubedjLGp+BCWHbXPkqpU86WxWCwJ+berj2M+chgMBgMRZiZgsFgMBiKMDMFg8FgMBRhlILBYDAYijBKwWAwGAxFGKVgMBgMhiKMUjAYDAZDEUYpGAwGg6GI/weAXkDYnxd2RwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7334\n","Validation AUC: 0.7304\n","Validation Balanced_ACC: 0.4663\n","Validation MI: 0.1334\n","Validation Normalized MI: 0.2009\n","Validation Adjusted MI: 0.2009\n"]}],"source":["from sklearn.metrics import classification_report, balanced_accuracy_score\n","from sklearn.metrics import normalized_mutual_info_score, mutual_info_score, adjusted_mutual_info_score\n","#model = create_model()\n","K=2\n","R=5\n","val_q = [0.0001]   #0.2, 0.4, 0.6, 0.8]\n","NUM_RUNS = 5\n","N_EPOCHS = 50 \n","ACC = np.zeros(NUM_RUNS)\n","AUC = np.zeros(NUM_RUNS)\n","MI = np.zeros(NUM_RUNS)\n","NMI = np.zeros(NUM_RUNS)\n","AMI = np.zeros(NUM_RUNS)\n","BACC = np.zeros(NUM_RUNS)\n","BACC1 = []\n","MI1 = []\n","NMI1 =[]\n","AMI1 = []\n","val_acc = np.zeros(NUM_RUNS)\n","for i in range(NUM_RUNS):\n","  MA = MultipleAnnotators_Classification(2, 5, val_q[0])\n","  model =  create_model()\n","  model = MA.fit(model, train_batches_MA, val_batches_MA, N_EPOCHS)\n","  #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n","  ACC[i] = MA.eval_model(test_batches_MA)\n","  print(\"===== Q: %.4f\" % (float(val_q[0]),))\n","  print(\"Validation acc: %.4f\" % (float(ACC[i]),))\n","\n","\n","    #AUC =======================\n","  val_AUC_metric = tf.keras.metrics.AUC( from_logits = True)\n","  for x_batch_val, y_batch_val in test_batches_MA:\n","      val_logits = model(x_batch_val.numpy(), training=False)\n","      # tf.print(y_batch_val)\n","      val_AUC_metric.update_state(y_batch_val, val_logits[:,:K].numpy().argmax(axis=1).astype('float'))   #val_logits[:,Y.shape[1]:].argmax(axis=1).astype('float'))\n","      BACC1.append(balanced_accuracy_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True))\n","      MI1.append(mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","      NMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","      AMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","\n","  val_AUC = val_AUC_metric.result()\n","  val_AUC_metric.reset_states()\n","  val_AUC = val_AUC.numpy()\n","  print(\"Validation AUC: %.4f\" % (float(val_AUC),))\n","  AUC[i] = val_AUC\n","  #===================================================\n","    \n","  # balanced. Accurcy\n","  BACC[i] = np.array(BACC1).mean() # balanced_accuracy_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True)\n","  print(\"Validation Balanced_ACC: %.4f\" % (float(BACC[i])))\n","\n","  #MI\n","  \n","  MI[i] =  np.array(MI1).mean()  #mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation MI: %.4f\" % (float(MI[i]),))\n","  NMI[i] =  np.array(NMI1).mean()   #normalized_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation Normalized MI: %.4f\" % (float(NMI[i]),))\n","  AMI[i]= np.array(AMI1).mean()  #adjusted_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation Adjusted MI: %.4f\" % (float(AMI[i]),))\n","\n","    \n","import pandas as pd\n","df = pd.DataFrame(ACC)\n","#df.to_csv('/content/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output"]},{"cell_type":"code","execution_count":18,"id":"cf74209e","metadata":{"execution":{"iopub.execute_input":"2023-02-06T16:58:41.45835Z","iopub.status.busy":"2023-02-06T16:58:41.457889Z","iopub.status.idle":"2023-02-06T16:58:41.469908Z","shell.execute_reply":"2023-02-06T16:58:41.468872Z"},"id":"_H_sb1cl1FC_","outputId":"59d957da-9223-4a01-e4d9-33933f7a2f4a","papermill":{"duration":0.33605,"end_time":"2023-02-06T16:58:41.471767","exception":false,"start_time":"2023-02-06T16:58:41.135717","status":"completed"},"tags":[]},"outputs":[],"source":["# classification_report_r= []\n","# model = create_model()\n","# K=2\n","# R=5\n","# NUM_RUNS = 10\n","# N_EPOCHS = 30\n","# val_acc = np.zeros(NUM_RUNS)\n","# for i in range(NUM_RUNS):\n","#   MA = MultipleAnnotators_Classification(K, R, 0.1)\n","#   model = create_model()\n","#   optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n","#   model.compile(optimizer=optimizer, loss= MA.loss())\n","#   history_model = model.fit(train_batches_MA, validation_data=val_batches_MA, epochs= N_EPOCHS, callbacks=callbacks, verbose=0)\n","#   #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n","#   pred_2 = model.predict(X_test)\n","\n","#   lambda_R_ = pred_2[:, K:] #annotators reliability prediction N x R   \n","#   classification_report_r += [classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel(),output_dict=True)]\n","#   print(classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel()))\n","#   #val_acc[i] = MA.eval_model(test_batches_MA)\n","#   #print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n","#   # Create the history figure\n","#   plt.figure(figsize=(16,9))\n","#   for i in  history_model.history:\n","#       plt.plot(history_model.history[i],label=i)\n","#   plt.title('Model history')\n","#   plt.legend()\n","#   plt.grid()\n","\n","# import pandas as pd\n","# df = pd.DataFrame(val_acc)\n","# #df.to_csimport pandas as pddf = pd.DataFrame(val_acc)#df.to_csv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook outputv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output\n"]},{"cell_type":"code","execution_count":19,"id":"57321b73","metadata":{"execution":{"iopub.execute_input":"2023-02-06T16:58:41.914826Z","iopub.status.busy":"2023-02-06T16:58:41.91445Z","iopub.status.idle":"2023-02-06T16:58:41.925797Z","shell.execute_reply":"2023-02-06T16:58:41.924541Z"},"id":"Mu0lyAUIGSTB","outputId":"cb82872d-c3ba-4d76-a28c-237eb266e78b","papermill":{"duration":0.235273,"end_time":"2023-02-06T16:58:41.930712","exception":false,"start_time":"2023-02-06T16:58:41.695439","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy:  73.6\n","Average std:  0.38999999999999996\n","==============================================\n","Average AUC:  73.31\n","Average AUC std:  0.4\n","==============================================\n","Average Balanced Accuracy:  47.08\n","Average std:  0.35000000000000003\n","==============================================\n","Average MI:  13.669999999999998\n","Average std:  0.27\n","==============================================\n","Average Normalized MI:  20.599999999999998\n","Average std:  0.44\n","==============================================\n","Average Ajdusted MI:  20.599999999999998\n","Average std:  0.44\n"]}],"source":["print('Average Accuracy: ', np.round( ACC.mean(),4)*100) \n","print('Average std: ',np.round(np.std( ACC),4)*100)\n","print('==============================================')\n","print('Average AUC: ', np.round( AUC.mean(),4)*100) \n","print('Average AUC std: ',np.round(np.std( AUC),4)*100)\n","print('==============================================')\n","print('Average Balanced Accuracy: ', np.round( BACC.mean(),4)*100) \n","print('Average std: ',np.round(np.std( BACC),4)*100)\n","print('==============================================')\n","print('Average MI: ', np.round( MI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(MI),4)*100)\n","print('==============================================')\n","print('Average Normalized MI: ', np.round( NMI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(NMI),4)*100)\n","print('==============================================')\n","print('Average Ajdusted MI: ', np.round( AMI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(AMI),4)*100)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":9100.26965,"end_time":"2023-02-06T16:58:46.020127","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-02-06T14:27:05.750477","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}