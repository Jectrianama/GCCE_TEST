{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jenntm/gcce-catvsdog-dic-22?scriptVersionId=118201827\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"68359751","metadata":{"id":"oAuRT75GdLFw","papermill":{"duration":0.006631,"end_time":"2023-02-04T13:36:09.587632","exception":false,"start_time":"2023-02-04T13:36:09.581001","status":"completed"},"tags":[]},"source":["# Cats vs. Dogs Class dataset for multiple annotators\n"]},{"cell_type":"markdown","id":"9b5acf1a","metadata":{"id":"9rK94t33nwDC","papermill":{"duration":0.005062,"end_time":"2023-02-04T13:36:09.598127","exception":false,"start_time":"2023-02-04T13:36:09.593065","status":"completed"},"tags":[]},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"id":"8a54cfdb","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:09.611077Z","iopub.status.busy":"2023-02-04T13:36:09.610233Z","iopub.status.idle":"2023-02-04T13:36:15.673179Z","shell.execute_reply":"2023-02-04T13:36:15.672224Z"},"id":"zSyMHuCVys-O","papermill":{"duration":6.072509,"end_time":"2023-02-04T13:36:15.6759","exception":false,"start_time":"2023-02-04T13:36:09.603391","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n","from keras.utils.vis_utils import plot_model\n","from tensorflow.keras import regularizers\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy as sp\n","import cv2\n","import os\n","import time\n","import sys"]},{"cell_type":"code","execution_count":2,"id":"fa3e31fb","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:15.689745Z","iopub.status.busy":"2023-02-04T13:36:15.688042Z","iopub.status.idle":"2023-02-04T13:36:15.69347Z","shell.execute_reply":"2023-02-04T13:36:15.692623Z"},"id":"-E1MJt8cxlwg","outputId":"ea43c1c9-075f-44de-d2d8-e135799b6630","papermill":{"duration":0.013954,"end_time":"2023-02-04T13:36:15.695445","exception":false,"start_time":"2023-02-04T13:36:15.681491","status":"completed"},"tags":[]},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"985c1282","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:15.707406Z","iopub.status.busy":"2023-02-04T13:36:15.707117Z","iopub.status.idle":"2023-02-04T13:36:15.711414Z","shell.execute_reply":"2023-02-04T13:36:15.710487Z"},"id":"QJPvjdZ-f8ca","papermill":{"duration":0.012483,"end_time":"2023-02-04T13:36:15.713282","exception":false,"start_time":"2023-02-04T13:36:15.700799","status":"completed"},"tags":[]},"outputs":[],"source":["# os.chdir('/content/drive/Shareddrives/Multiple Anotators/CrowdLayer/Notebooks')\n","# cwd = os.getcwd()\n","# sys.path.append(\"../Models\")\n","\n","\n","# from Multiple_Annotators_C import MultipleAnnotators_Classification\n","\n","#import sys\n","#sys.path.insert(1, '../input/multiple-annotators-c/')\n","#os.chdir('/Multiple Anotators-c/')\n","#cwd = os.getcwd()\n","#sys.path.append('/input/multiple-annotators-c')\n","#from Multiple_Annotators_C import MultipleAnnotators_Classification\n","\n","# seed_value= 12321 \n","# from numpy.random import seed\n","# seed(seed_value)\n","# tf.random.set_seed(seed_value)"]},{"cell_type":"markdown","id":"22ea4628","metadata":{"id":"6Un5nFWgnyem","papermill":{"duration":0.005132,"end_time":"2023-02-04T13:36:15.723696","exception":false,"start_time":"2023-02-04T13:36:15.718564","status":"completed"},"tags":[]},"source":["## Download and Prepare the Dataset\n","\n","We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset and we can load it via Tensorflow Datasets. The images are labeled 0 for cats and 1 for dogs."]},{"cell_type":"markdown","id":"82dbb15b","metadata":{"id":"Gw6K2Uey06kh","papermill":{"duration":0.005081,"end_time":"2023-02-04T13:36:15.734005","exception":false,"start_time":"2023-02-04T13:36:15.728924","status":"completed"},"tags":[]},"source":["# Multiple annotators model"]},{"cell_type":"code","execution_count":4,"id":"aa062640","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:15.746676Z","iopub.status.busy":"2023-02-04T13:36:15.745272Z","iopub.status.idle":"2023-02-04T13:36:18.404581Z","shell.execute_reply":"2023-02-04T13:36:18.403686Z"},"id":"xam4REp209Sd","papermill":{"duration":2.667659,"end_time":"2023-02-04T13:36:18.406884","exception":false,"start_time":"2023-02-04T13:36:15.739225","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-04 13:36:15.834610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:16.035844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:16.036691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:16.038570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-04 13:36:16.042724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:16.043446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:16.044150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:18.008789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:18.009617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:18.010319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-04 13:36:18.010923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["\n","validation_data = tf.data.experimental.load('/kaggle/input/catsvsdog-ma/cats_dogs_Te')\n","train_data_MA = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_MA_sin_Tr_1')\n","\n"]},{"cell_type":"code","execution_count":5,"id":"e7265159","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.421052Z","iopub.status.busy":"2023-02-04T13:36:18.42076Z","iopub.status.idle":"2023-02-04T13:36:18.429597Z","shell.execute_reply":"2023-02-04T13:36:18.428572Z"},"id":"D_S0EJ3mFdfK","outputId":"9ed3c2c7-50b4-4445-a01e-c9a3d780c403","papermill":{"duration":0.017648,"end_time":"2023-02-04T13:36:18.431952","exception":false,"start_time":"2023-02-04T13:36:18.414304","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["18610"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["image_count = tf.data.experimental.cardinality(train_data_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count"]},{"cell_type":"code","execution_count":6,"id":"16cf22ae","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.444595Z","iopub.status.busy":"2023-02-04T13:36:18.443836Z","iopub.status.idle":"2023-02-04T13:36:18.450503Z","shell.execute_reply":"2023-02-04T13:36:18.449513Z"},"id":"ctjLei0TxcVh","outputId":"6f578b73-ebdf-4465-91c7-2adb7d127174","papermill":{"duration":0.015129,"end_time":"2023-02-04T13:36:18.452502","exception":false,"start_time":"2023-02-04T13:36:18.437373","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["4652"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["image_count1 = tf.data.experimental.cardinality(validation_data).numpy() # los datos de training son 18610\n","image_count1"]},{"cell_type":"code","execution_count":7,"id":"0ac1792c","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.465363Z","iopub.status.busy":"2023-02-04T13:36:18.464488Z","iopub.status.idle":"2023-02-04T13:36:18.468874Z","shell.execute_reply":"2023-02-04T13:36:18.468038Z"},"id":"opk5MXl4IwjC","papermill":{"duration":0.012754,"end_time":"2023-02-04T13:36:18.470764","exception":false,"start_time":"2023-02-04T13:36:18.45801","status":"completed"},"tags":[]},"outputs":[],"source":["#X_test = [validation_data[i][0] for i in range(image_count1)]\n","#Y_true_test = [validation_data[i][1] for i in range(image_count1)]\n","#Y_true_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n","#X_test = np.asarray([aux[0].numpy() for aux  in validation_data])"]},{"cell_type":"code","execution_count":8,"id":"437bf121","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.484455Z","iopub.status.busy":"2023-02-04T13:36:18.482888Z","iopub.status.idle":"2023-02-04T13:36:18.489492Z","shell.execute_reply":"2023-02-04T13:36:18.488544Z"},"id":"-BydcVOQxcVh","outputId":"8c1b4ed2-7c43-4675-f055-f9e4e3f5b3dd","papermill":{"duration":0.014971,"end_time":"2023-02-04T13:36:18.491415","exception":false,"start_time":"2023-02-04T13:36:18.476444","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["18610"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["image_count"]},{"cell_type":"code","execution_count":9,"id":"db9d82a4","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.504249Z","iopub.status.busy":"2023-02-04T13:36:18.503373Z","iopub.status.idle":"2023-02-04T13:36:18.511666Z","shell.execute_reply":"2023-02-04T13:36:18.510866Z"},"id":"HdFme6fdxcVh","papermill":{"duration":0.01663,"end_time":"2023-02-04T13:36:18.513672","exception":false,"start_time":"2023-02-04T13:36:18.497042","status":"completed"},"tags":[]},"outputs":[],"source":["val_size = int(image_count * 0.2)\n","train_ds_MA = train_data_MA.skip(val_size)\n","val_ds_MA = train_data_MA.take(val_size)"]},{"cell_type":"code","execution_count":10,"id":"3212de14","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.526373Z","iopub.status.busy":"2023-02-04T13:36:18.525532Z","iopub.status.idle":"2023-02-04T13:36:18.536632Z","shell.execute_reply":"2023-02-04T13:36:18.535683Z"},"id":"aVHIlFpgxcVi","papermill":{"duration":0.019428,"end_time":"2023-02-04T13:36:18.538599","exception":false,"start_time":"2023-02-04T13:36:18.519171","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 100\n","train_batches_MA = train_ds_MA.shuffle(1024).batch(batch_size)\n","val_batches_MA = val_ds_MA.shuffle(1024).batch(batch_size)\n","test_batches_MA = validation_data.shuffle(1024).batch(batch_size)"]},{"cell_type":"code","execution_count":11,"id":"5bb04b58","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.55149Z","iopub.status.busy":"2023-02-04T13:36:18.550755Z","iopub.status.idle":"2023-02-04T13:36:18.557241Z","shell.execute_reply":"2023-02-04T13:36:18.556296Z"},"id":"GsB4EA2-xcVi","outputId":"2d45809e-a9cc-408f-9a8b-745e8fe850e9","papermill":{"duration":0.014807,"end_time":"2023-02-04T13:36:18.559122","exception":false,"start_time":"2023-02-04T13:36:18.544315","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["14888"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["image_count = tf.data.experimental.cardinality(train_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count"]},{"cell_type":"code","execution_count":12,"id":"a7052039","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.572613Z","iopub.status.busy":"2023-02-04T13:36:18.571059Z","iopub.status.idle":"2023-02-04T13:36:18.578031Z","shell.execute_reply":"2023-02-04T13:36:18.577131Z"},"id":"Hk33DzwkxcVi","outputId":"aad91eec-842c-4995-de90-5bb715539b6a","papermill":{"duration":0.015376,"end_time":"2023-02-04T13:36:18.580017","exception":false,"start_time":"2023-02-04T13:36:18.564641","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["3722"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["image_count_val = tf.data.experimental.cardinality(val_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count_val"]},{"cell_type":"code","execution_count":null,"id":"bb44a0a2","metadata":{"id":"UMeK3NG3xcVi","papermill":{"duration":0.005781,"end_time":"2023-02-04T13:36:18.591532","exception":false,"start_time":"2023-02-04T13:36:18.585751","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"id":"7cab9d2e","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:18.604714Z","iopub.status.busy":"2023-02-04T13:36:18.603837Z","iopub.status.idle":"2023-02-04T13:36:34.890699Z","shell.execute_reply":"2023-02-04T13:36:34.889839Z"},"id":"uvwc7eixxcVi","outputId":"d7766078-8c40-41ed-fb01-66b5f62a07f1","papermill":{"duration":16.296513,"end_time":"2023-02-04T13:36:34.893783","exception":false,"start_time":"2023-02-04T13:36:18.59727","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-04 13:36:19.204546: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2023-02-04 13:36:30.218961: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n","2023-02-04 13:36:33.245625: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["annotator 1\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.76      0.82        55\n","         1.0       0.75      0.89      0.82        45\n","\n","    accuracy                           0.82       100\n","   macro avg       0.82      0.83      0.82       100\n","weighted avg       0.83      0.82      0.82       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","         0.0       0.61      0.65      0.63        55\n","         1.0       0.54      0.49      0.51        45\n","\n","    accuracy                           0.58       100\n","   macro avg       0.57      0.57      0.57       100\n","weighted avg       0.58      0.58      0.58       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","         0.0       0.61      0.60      0.61        55\n","         1.0       0.52      0.53      0.53        45\n","\n","    accuracy                           0.57       100\n","   macro avg       0.57      0.57      0.57       100\n","weighted avg       0.57      0.57      0.57       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","         0.0       0.54      0.56      0.55        55\n","         1.0       0.44      0.42      0.43        45\n","\n","    accuracy                           0.50       100\n","   macro avg       0.49      0.49      0.49       100\n","weighted avg       0.50      0.50      0.50       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","         0.0       0.20      0.16      0.18        55\n","         1.0       0.15      0.18      0.16        45\n","\n","    accuracy                           0.17       100\n","   macro avg       0.17      0.17      0.17       100\n","weighted avg       0.17      0.17      0.17       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.89      0.83        44\n","         1.0       0.90      0.80      0.85        56\n","\n","    accuracy                           0.84       100\n","   macro avg       0.84      0.84      0.84       100\n","weighted avg       0.85      0.84      0.84       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","         0.0       0.61      0.68      0.65        44\n","         1.0       0.73      0.66      0.69        56\n","\n","    accuracy                           0.67       100\n","   macro avg       0.67      0.67      0.67       100\n","weighted avg       0.68      0.67      0.67       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.55      0.51        44\n","         1.0       0.59      0.52      0.55        56\n","\n","    accuracy                           0.53       100\n","   macro avg       0.53      0.53      0.53       100\n","weighted avg       0.54      0.53      0.53       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.59      0.55        44\n","         1.0       0.64      0.57      0.60        56\n","\n","    accuracy                           0.58       100\n","   macro avg       0.58      0.58      0.58       100\n","weighted avg       0.59      0.58      0.58       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","         0.0       0.11      0.14      0.12        44\n","         1.0       0.17      0.14      0.16        56\n","\n","    accuracy                           0.14       100\n","   macro avg       0.14      0.14      0.14       100\n","weighted avg       0.15      0.14      0.14       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.82      0.83        50\n","         1.0       0.82      0.84      0.83        50\n","\n","    accuracy                           0.83       100\n","   macro avg       0.83      0.83      0.83       100\n","weighted avg       0.83      0.83      0.83       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.54      0.51        50\n","         1.0       0.48      0.42      0.45        50\n","\n","    accuracy                           0.48       100\n","   macro avg       0.48      0.48      0.48       100\n","weighted avg       0.48      0.48      0.48       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.66      0.67        50\n","         1.0       0.67      0.68      0.67        50\n","\n","    accuracy                           0.67       100\n","   macro avg       0.67      0.67      0.67       100\n","weighted avg       0.67      0.67      0.67       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","         0.0       0.51      0.52      0.51        50\n","         1.0       0.51      0.50      0.51        50\n","\n","    accuracy                           0.51       100\n","   macro avg       0.51      0.51      0.51       100\n","weighted avg       0.51      0.51      0.51       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.24      0.24        50\n","         1.0       0.25      0.26      0.26        50\n","\n","    accuracy                           0.25       100\n","   macro avg       0.25      0.25      0.25       100\n","weighted avg       0.25      0.25      0.25       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.92      0.91        49\n","         1.0       0.92      0.90      0.91        51\n","\n","    accuracy                           0.91       100\n","   macro avg       0.91      0.91      0.91       100\n","weighted avg       0.91      0.91      0.91       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","         0.0       0.56      0.51      0.53        49\n","         1.0       0.56      0.61      0.58        51\n","\n","    accuracy                           0.56       100\n","   macro avg       0.56      0.56      0.56       100\n","weighted avg       0.56      0.56      0.56       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.55      0.53        49\n","         1.0       0.54      0.51      0.53        51\n","\n","    accuracy                           0.53       100\n","   macro avg       0.53      0.53      0.53       100\n","weighted avg       0.53      0.53      0.53       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","         0.0       0.39      0.41      0.40        49\n","         1.0       0.41      0.39      0.40        51\n","\n","    accuracy                           0.40       100\n","   macro avg       0.40      0.40      0.40       100\n","weighted avg       0.40      0.40      0.40       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","         0.0       0.28      0.31      0.29        49\n","         1.0       0.26      0.24      0.25        51\n","\n","    accuracy                           0.27       100\n","   macro avg       0.27      0.27      0.27       100\n","weighted avg       0.27      0.27      0.27       100\n","\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from sklearn.metrics import classification_report\n","i = 0\n","fig, ax = plt.subplots(1, 4)\n","for image, label, label2 in train_batches_MA.take(4):\n","   # predictedLabel = int(predictions[i] >= 0.5)\n","   # print(label2)\n","    ax[i].axis('off')\n","   # ax[i].set_title(classNames[label[i]])\n","    ax[i].imshow(image[0])\n","    i += 1\n","    for j in range(label2.shape[1]):\n","      print('annotator',j+1)\n","      print(classification_report(label ,label2[:,j]))\n","plt.show()"]},{"cell_type":"markdown","id":"5ae62d49","metadata":{"id":"9AgOHREc1bmd","papermill":{"duration":0.013361,"end_time":"2023-02-04T13:36:34.930291","exception":false,"start_time":"2023-02-04T13:36:34.91693","status":"completed"},"tags":[]},"source":["## Build the classifier from multiple annotators"]},{"cell_type":"code","execution_count":14,"id":"5a0f4fac","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:34.954361Z","iopub.status.busy":"2023-02-04T13:36:34.953954Z","iopub.status.idle":"2023-02-04T13:36:34.993476Z","shell.execute_reply":"2023-02-04T13:36:34.992683Z"},"id":"k-ePr0-fxcVi","papermill":{"duration":0.054485,"end_time":"2023-02-04T13:36:34.995976","exception":false,"start_time":"2023-02-04T13:36:34.941491","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import time\n","from tensorflow.keras import regularizers\n","\n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n","from keras.utils.vis_utils import plot_model\n","\n","class MultipleAnnotators_Classification():\n","    def __init__(self, output_dim, num_annotators, q= 0.0001):\n","        self.K = output_dim\n","        self.R = num_annotators\n","        self.q = q\n","        #self.callbacks #=callbacks\n","        #self.l1_param=l1_param \n","        #self.l2_param=l1_param\n","\n","    def CrowdLayer(self, input):\n","       #x = keras.layers.Dense(self.R + self.K,  ,  activation='tanh')(input)\n","        output_cla = keras.layers.Dense(self.K,    activation='softmax')(input)\n","        output_ann = keras.layers.Dense(self.R, activation='sigmoid')(input)\n","        output = keras.layers.Concatenate()([output_cla, output_ann])\n","        \n","        return output\n","#RCDNN   \n","#     def loss(self):\n","#         def custom_loss(y_true, y_pred):\n","#             # print(y_true,y_pred)\n","#             pred = y_pred[:, :self.K]\n","#             pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1-1e-9) #estabilidad numerica de la funcion de costo\n","#             ann_ = y_pred[:, self.K:]\n","#             Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n","#             Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n","#             p_logreg = tf.math.reduce_prod(tf.math.pow(Y_hat, Y_true), axis=1)\n","#             temp1 = ann_*tf.math.log(p_logreg)  \n","#             temp2 = (1 - ann_)*tf.math.log(1/self.K)*tf.reduce_sum(Y_true,axis=1)\n","#             # temp2 = (tf.ones(tf.shape(ann_)) - ann_)*tf.math.log(1/K)\n","#             # print(tf.reduce_mean(Y_true,axis=1).numpy())\n","#             return -tf.math.reduce_sum((temp1 + temp2))\n","#         return custom_loss\n","    \n","    def loss(self):\n","        def custom_loss(y_true, y_pred):\n","               # print(y_true,y_pred)\n","           # q = 0.1\n","            pred = y_pred[:, :self.K]\n","            pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n","            ann_ = y_pred[:, self.K:]\n","            # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n","            Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n","            Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n","\n","            p_gcce = Y_true*(1 - Y_hat**self.q)/self.q\n","            temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n","            temp2 = (1 - ann_)*(1-(1/self.K)**self.q)/self.q*tf.reduce_sum(Y_true,axis=1)\n","            return tf.math.reduce_sum((temp1 + temp2))\n","        return custom_loss\n","\n","    @tf.function\n","    def train_step(self, x, Y, y):\n","        with tf.GradientTape() as tape:\n","            logits = self.model(x, training=True)\n","            loss_value = self.loss_fn(Y, logits)\n","        grads = tape.gradient(loss_value, self.model.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n","        self.train_acc_metric.update_state(y, logits[:, :self.K])\n","        return loss_value\n","\n","    @tf.function\n","    def test_step(self, x, y):\n","        val_logits = self.model(x, training=False)\n","        self.val_acc_metric.update_state(y, val_logits[:,:self.K])\n","\n","    def fit(self, model, Data_tr, Data_Val, epochs):\n","        self.model = model\n","        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        # Instantiate an optimizer.\n","        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n","        #self.optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n","        #self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, clipnorm=1.0)\n","        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        # Instantiate a loss function.\n","        self.loss_fn = self.loss()\n","        self.train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","        train_loss = np.zeros(epochs)\n","        train_accur = np.zeros(epochs)\n","        val_accur = np.zeros(epochs)\n","        val_loss = np.zeros(epochs)\n","\n","        for epoch in range(epochs):\n","            print(\"\\nStart of epoch %d\" % (epoch,))\n","            start_time = time.time()\n","\n","            # Iterate over the batches of the dataset.\n","            for step, (x_batch_train, y_batch_train, Y_batch_train) in enumerate(Data_tr):\n","                # print(y_batch_train, Y_batch_train)\n","                loss_value = self.train_step(x_batch_train, Y_batch_train, y_batch_train)\n","\n","                # Log every 200 batches.\n","                if step % 10 == 0:\n","                    train_acc = self.train_acc_metric.result()\n","                    print(\n","                      \"Training loss (for one batch) at step %d: %.4f, Accuracy: %.4f\"\n","                      % (step, float(loss_value), float(train_acc))\n","                            )\n","                # print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n","\n","\n","\n","            # Run a validation loop at the end of each epoch.\n","            for x_batch_val, y_batch_val,Y_batch_val in Data_Val:\n","\n","                val_logits = model(x_batch_val, training=False)\n","\n","                val_loss_value = self.loss_fn(Y_batch_val, val_logits)\n","\n","                self.val_acc_metric.update_state(y_batch_val, val_logits[:,:self.K])\n","                \n","               # np.round(np.mean([model(x_batch_val, training= True) for sample in range(100)]), 2)\n","\n","\n","             # Display metrics at the end of each epoch.\n","            train_acc = self.train_acc_metric.result()\n","            val_acc = self.val_acc_metric.result()\n","\n","\n","            print('---- Training ----')\n","            print(\"Training loss: %.4f\" % (float(loss_value),))\n","            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","            # Reset training metrics at the end of each epoch\n","            self.train_acc_metric.reset_states()\n","            self.val_acc_metric.reset_states()\n","\n","\n","            train_loss[epoch] = float(loss_value)\n","            train_accur[epoch] = float(train_acc)\n","\n","            val_accur[epoch] = float(val_acc)\n","            val_loss[epoch] = float(val_loss_value) \n","\n","\n","            print('---- Validation ----')\n","            print(\"Validation loss: %.4f\" % (float(val_loss_value),))\n","            print(\"Validation acc: %.4f\" % (float(val_acc),))\n","\n","            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n","\n","        fig, (ax1, ax2) = plt.subplots(1, 2)\n","        fig.suptitle('Loss and accuracy')\n","        ax1.plot(range(1,epochs+1),train_loss)\n","        ax1.plot(range(1,epochs+1), val_loss)\n","        ax2.plot(range(1,epochs+1),train_accur)\n","        ax2.plot(range(1,epochs+1),val_accur)\n","        #plt.figure(figsize=(16,9))\n","        ax1.set(xlabel= 'Epoch', ylabel=\"Loss\")\n","        ax2.set(xlabel= 'Epoch',ylabel=\"Accuracy\")\n","        ax1.legend(['Training_loss', 'Validation_loss'])\n","        ax2.legend(['Training', 'Validation'])\n","        ax1.grid()\n","        ax2.grid()\n","        plt.show()\n","        return self.model\n","\n","    def eval_model(self, Data):\n","        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","        for x_batch_val, y_batch_val in Data:\n","            self.test_step(x_batch_val, y_batch_val)\n","\n","        val_acc = self.val_acc_metric.result()\n","        self.val_acc_metric.reset_states()\n","        return val_acc\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":15,"id":"9b2bd258","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:35.019353Z","iopub.status.busy":"2023-02-04T13:36:35.019033Z","iopub.status.idle":"2023-02-04T13:36:35.029217Z","shell.execute_reply":"2023-02-04T13:36:35.028444Z"},"id":"4l-_pkpaBkSv","papermill":{"duration":0.024628,"end_time":"2023-02-04T13:36:35.03184","exception":false,"start_time":"2023-02-04T13:36:35.007212","status":"completed"},"tags":[]},"outputs":[],"source":["def custom_loss(y_true, y_pred):\n","  # print(y_true,y_pred)\n","  K = 2 #len(np.unique(y_true))\n","  R = 5\n","  q = 0.1\n","  pred = y_pred[:, K]\n","  pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n","  ann_ = y_pred[:,  K:]\n","  # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n","  Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=K, axis=1)\n","  Y_hat = tf.repeat(tf.expand_dims(pred,-1), R, axis = -1)\n","\n","  p_gcce = Y_true*(1 - Y_hat**q)/q\n","  temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n","  temp2 = (1 - ann_)*(1-(1/K)**q)/q*tf.reduce_sum(Y_true,axis=1)\n","  return tf.math.reduce_sum((temp1 + temp2))\n","\n"]},{"cell_type":"code","execution_count":16,"id":"5607d748","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:35.060358Z","iopub.status.busy":"2023-02-04T13:36:35.0601Z","iopub.status.idle":"2023-02-04T13:36:35.079194Z","shell.execute_reply":"2023-02-04T13:36:35.078314Z"},"id":"Z-fV95n3GEqa","papermill":{"duration":0.034943,"end_time":"2023-02-04T13:36:35.081083","exception":false,"start_time":"2023-02-04T13:36:35.04614","status":"completed"},"tags":[]},"outputs":[],"source":["MA = MultipleAnnotators_Classification(2, 5, 0.001)\n"," \n","def create_model():\n","   \n","    l1 = 1e-2\n","    # Block 1\n","    inputs = keras.layers.Input(shape=(150, 150, 3), name='entrada')\n","    x = keras.layers.BatchNormalization()(inputs)\n","    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\" , name=\"block1_conv1\")(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n","\n","\n","    # Block 2\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", name=\"block2_conv1\")(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    #x = keras.layers.Dropout(0.2)(x)\n","    \n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n","\n","    # Block 3\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block3_conv1\" )(x)             \n","    x = keras.layers.BatchNormalization()(x)\n","   # x = keras.layers.Dropout(0.2)(x)\n","   \n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n","    \n","    # Block 4\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block4_conv1\")(x)            \n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n","    #x = keras.layers.Dropout(0.2)(x)\n","    \n","    #x = keras.layers.GlobalAveragePooling2D()(x)\n","   \n","    x = keras.layers.Flatten()(x)\n","    #x = keras.layers.Dropout(0.5)(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Dense(128, activation='relu')(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Dropout(0.5)(x)\n","    output = MA.CrowdLayer(x)\n","    model = keras.Model(inputs=inputs,outputs=output)\n","\n","    return model\n","  \n","  "]},{"cell_type":"code","execution_count":17,"id":"57bb72c8","metadata":{"execution":{"iopub.execute_input":"2023-02-04T13:36:35.104238Z","iopub.status.busy":"2023-02-04T13:36:35.103979Z","iopub.status.idle":"2023-02-04T15:42:21.758239Z","shell.execute_reply":"2023-02-04T15:42:21.756356Z"},"papermill":{"duration":7546.884702,"end_time":"2023-02-04T15:42:21.978932","exception":false,"start_time":"2023-02-04T13:36:35.09423","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-04 13:36:38.977931: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 528.2190, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 474.2592, Accuracy: 0.5100\n","Training loss (for one batch) at step 20: 489.0238, Accuracy: 0.5029\n","Training loss (for one batch) at step 30: 485.8841, Accuracy: 0.5113\n","Training loss (for one batch) at step 40: 460.2279, Accuracy: 0.5063\n","Training loss (for one batch) at step 50: 432.0956, Accuracy: 0.5106\n","Training loss (for one batch) at step 60: 479.1130, Accuracy: 0.5111\n","Training loss (for one batch) at step 70: 415.6093, Accuracy: 0.5070\n","Training loss (for one batch) at step 80: 439.8459, Accuracy: 0.5115\n","Training loss (for one batch) at step 90: 435.6530, Accuracy: 0.5112\n","Training loss (for one batch) at step 100: 428.6831, Accuracy: 0.5098\n","Training loss (for one batch) at step 110: 433.0191, Accuracy: 0.5104\n","Training loss (for one batch) at step 120: 403.5164, Accuracy: 0.5115\n","Training loss (for one batch) at step 130: 420.3900, Accuracy: 0.5089\n","Training loss (for one batch) at step 140: 397.4548, Accuracy: 0.5087\n","---- Training ----\n","Training loss: 355.5303\n","Training acc over epoch: 0.5093\n","---- Validation ----\n","Validation loss: 77.0278\n","Validation acc: 0.4766\n","Time taken: 54.85s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 393.6550, Accuracy: 0.4500\n","Training loss (for one batch) at step 10: 416.5048, Accuracy: 0.5273\n","Training loss (for one batch) at step 20: 377.9005, Accuracy: 0.5352\n","Training loss (for one batch) at step 30: 421.6516, Accuracy: 0.5271\n","Training loss (for one batch) at step 40: 397.5245, Accuracy: 0.5207\n","Training loss (for one batch) at step 50: 392.9753, Accuracy: 0.5171\n","Training loss (for one batch) at step 60: 389.2101, Accuracy: 0.5208\n","Training loss (for one batch) at step 70: 383.5821, Accuracy: 0.5208\n","Training loss (for one batch) at step 80: 393.6904, Accuracy: 0.5217\n","Training loss (for one batch) at step 90: 380.8775, Accuracy: 0.5199\n","Training loss (for one batch) at step 100: 383.3206, Accuracy: 0.5185\n","Training loss (for one batch) at step 110: 374.1821, Accuracy: 0.5161\n","Training loss (for one batch) at step 120: 384.0448, Accuracy: 0.5168\n","Training loss (for one batch) at step 130: 383.7707, Accuracy: 0.5164\n","Training loss (for one batch) at step 140: 378.0396, Accuracy: 0.5152\n","---- Training ----\n","Training loss: 346.0424\n","Training acc over epoch: 0.5147\n","---- Validation ----\n","Validation loss: 76.3850\n","Validation acc: 0.4901\n","Time taken: 9.90s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 388.2696, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 371.4988, Accuracy: 0.5000\n","Training loss (for one batch) at step 20: 375.8737, Accuracy: 0.5176\n","Training loss (for one batch) at step 30: 373.1558, Accuracy: 0.5197\n","Training loss (for one batch) at step 40: 362.1118, Accuracy: 0.5205\n","Training loss (for one batch) at step 50: 368.7637, Accuracy: 0.5167\n","Training loss (for one batch) at step 60: 372.7306, Accuracy: 0.5189\n","Training loss (for one batch) at step 70: 365.5386, Accuracy: 0.5139\n","Training loss (for one batch) at step 80: 364.7776, Accuracy: 0.5152\n","Training loss (for one batch) at step 90: 368.6743, Accuracy: 0.5140\n","Training loss (for one batch) at step 100: 361.5617, Accuracy: 0.5146\n","Training loss (for one batch) at step 110: 379.8098, Accuracy: 0.5150\n","Training loss (for one batch) at step 120: 368.9099, Accuracy: 0.5159\n","Training loss (for one batch) at step 130: 369.9002, Accuracy: 0.5156\n","Training loss (for one batch) at step 140: 358.8438, Accuracy: 0.5148\n","---- Training ----\n","Training loss: 326.9532\n","Training acc over epoch: 0.5147\n","---- Validation ----\n","Validation loss: 77.4129\n","Validation acc: 0.5570\n","Time taken: 9.93s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 369.6752, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 363.9397, Accuracy: 0.5118\n","Training loss (for one batch) at step 20: 359.7941, Accuracy: 0.5133\n","Training loss (for one batch) at step 30: 359.2756, Accuracy: 0.5135\n","Training loss (for one batch) at step 40: 357.2288, Accuracy: 0.5178\n","Training loss (for one batch) at step 50: 359.0864, Accuracy: 0.5218\n","Training loss (for one batch) at step 60: 358.8144, Accuracy: 0.5226\n","Training loss (for one batch) at step 70: 361.8445, Accuracy: 0.5207\n","Training loss (for one batch) at step 80: 354.0905, Accuracy: 0.5186\n","Training loss (for one batch) at step 90: 370.0545, Accuracy: 0.5179\n","Training loss (for one batch) at step 100: 367.1631, Accuracy: 0.5187\n","Training loss (for one batch) at step 110: 358.9340, Accuracy: 0.5174\n","Training loss (for one batch) at step 120: 363.8601, Accuracy: 0.5169\n","Training loss (for one batch) at step 130: 357.8553, Accuracy: 0.5164\n","Training loss (for one batch) at step 140: 361.4447, Accuracy: 0.5167\n","---- Training ----\n","Training loss: 315.9557\n","Training acc over epoch: 0.5166\n","---- Validation ----\n","Validation loss: 76.5935\n","Validation acc: 0.5674\n","Time taken: 9.88s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 355.3558, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 360.2245, Accuracy: 0.4973\n","Training loss (for one batch) at step 20: 362.8026, Accuracy: 0.5000\n","Training loss (for one batch) at step 30: 357.9030, Accuracy: 0.5077\n","Training loss (for one batch) at step 40: 356.4138, Accuracy: 0.5156\n","Training loss (for one batch) at step 50: 357.9791, Accuracy: 0.5165\n","Training loss (for one batch) at step 60: 356.3448, Accuracy: 0.5166\n","Training loss (for one batch) at step 70: 352.5566, Accuracy: 0.5179\n","Training loss (for one batch) at step 80: 353.0869, Accuracy: 0.5174\n","Training loss (for one batch) at step 90: 361.1038, Accuracy: 0.5205\n","Training loss (for one batch) at step 100: 351.8860, Accuracy: 0.5198\n","Training loss (for one batch) at step 110: 352.4701, Accuracy: 0.5190\n","Training loss (for one batch) at step 120: 351.1273, Accuracy: 0.5197\n","Training loss (for one batch) at step 130: 354.0716, Accuracy: 0.5203\n","Training loss (for one batch) at step 140: 352.0387, Accuracy: 0.5213\n","---- Training ----\n","Training loss: 313.5975\n","Training acc over epoch: 0.5210\n","---- Validation ----\n","Validation loss: 76.5359\n","Validation acc: 0.5752\n","Time taken: 10.26s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 358.4264, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 353.9647, Accuracy: 0.5373\n","Training loss (for one batch) at step 20: 351.2076, Accuracy: 0.5310\n","Training loss (for one batch) at step 30: 353.8107, Accuracy: 0.5397\n","Training loss (for one batch) at step 40: 354.8189, Accuracy: 0.5398\n","Training loss (for one batch) at step 50: 352.5196, Accuracy: 0.5396\n","Training loss (for one batch) at step 60: 359.8954, Accuracy: 0.5415\n","Training loss (for one batch) at step 70: 348.7063, Accuracy: 0.5380\n","Training loss (for one batch) at step 80: 349.1013, Accuracy: 0.5381\n","Training loss (for one batch) at step 90: 348.3611, Accuracy: 0.5352\n","Training loss (for one batch) at step 100: 353.4886, Accuracy: 0.5341\n","Training loss (for one batch) at step 110: 352.0957, Accuracy: 0.5367\n","Training loss (for one batch) at step 120: 351.9163, Accuracy: 0.5379\n","Training loss (for one batch) at step 130: 352.1578, Accuracy: 0.5379\n","Training loss (for one batch) at step 140: 351.2208, Accuracy: 0.5381\n","---- Training ----\n","Training loss: 307.7454\n","Training acc over epoch: 0.5373\n","---- Validation ----\n","Validation loss: 76.1969\n","Validation acc: 0.5113\n","Time taken: 9.89s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 353.4986, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 347.6212, Accuracy: 0.5327\n","Training loss (for one batch) at step 20: 346.6678, Accuracy: 0.5352\n","Training loss (for one batch) at step 30: 347.3174, Accuracy: 0.5368\n","Training loss (for one batch) at step 40: 350.1877, Accuracy: 0.5368\n","Training loss (for one batch) at step 50: 349.5074, Accuracy: 0.5329\n","Training loss (for one batch) at step 60: 350.4284, Accuracy: 0.5336\n","Training loss (for one batch) at step 70: 354.3038, Accuracy: 0.5375\n","Training loss (for one batch) at step 80: 351.1057, Accuracy: 0.5394\n","Training loss (for one batch) at step 90: 348.4449, Accuracy: 0.5426\n","Training loss (for one batch) at step 100: 353.2621, Accuracy: 0.5438\n","Training loss (for one batch) at step 110: 348.1171, Accuracy: 0.5431\n","Training loss (for one batch) at step 120: 353.3140, Accuracy: 0.5433\n","Training loss (for one batch) at step 130: 346.8164, Accuracy: 0.5417\n","Training loss (for one batch) at step 140: 350.4336, Accuracy: 0.5405\n","---- Training ----\n","Training loss: 311.4045\n","Training acc over epoch: 0.5393\n","---- Validation ----\n","Validation loss: 76.1418\n","Validation acc: 0.5672\n","Time taken: 9.76s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 347.1526, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 350.5419, Accuracy: 0.5536\n","Training loss (for one batch) at step 20: 349.4150, Accuracy: 0.5419\n","Training loss (for one batch) at step 30: 351.1910, Accuracy: 0.5487\n","Training loss (for one batch) at step 40: 350.1412, Accuracy: 0.5512\n","Training loss (for one batch) at step 50: 349.2141, Accuracy: 0.5439\n","Training loss (for one batch) at step 60: 350.6494, Accuracy: 0.5479\n","Training loss (for one batch) at step 70: 348.9350, Accuracy: 0.5476\n","Training loss (for one batch) at step 80: 351.4583, Accuracy: 0.5500\n","Training loss (for one batch) at step 90: 351.6404, Accuracy: 0.5488\n","Training loss (for one batch) at step 100: 351.1595, Accuracy: 0.5488\n","Training loss (for one batch) at step 110: 346.4229, Accuracy: 0.5491\n","Training loss (for one batch) at step 120: 347.6337, Accuracy: 0.5495\n","Training loss (for one batch) at step 130: 347.9322, Accuracy: 0.5483\n","Training loss (for one batch) at step 140: 347.1729, Accuracy: 0.5497\n","---- Training ----\n","Training loss: 308.2989\n","Training acc over epoch: 0.5494\n","---- Validation ----\n","Validation loss: 76.1355\n","Validation acc: 0.5562\n","Time taken: 9.59s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 348.1673, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 352.5895, Accuracy: 0.5618\n","Training loss (for one batch) at step 20: 347.1125, Accuracy: 0.5652\n","Training loss (for one batch) at step 30: 350.6466, Accuracy: 0.5635\n","Training loss (for one batch) at step 40: 346.0850, Accuracy: 0.5707\n","Training loss (for one batch) at step 50: 349.9630, Accuracy: 0.5686\n","Training loss (for one batch) at step 60: 347.6419, Accuracy: 0.5664\n","Training loss (for one batch) at step 70: 350.8828, Accuracy: 0.5686\n","Training loss (for one batch) at step 80: 344.2361, Accuracy: 0.5698\n","Training loss (for one batch) at step 90: 346.9627, Accuracy: 0.5720\n","Training loss (for one batch) at step 100: 351.1960, Accuracy: 0.5726\n","Training loss (for one batch) at step 110: 348.1185, Accuracy: 0.5723\n","Training loss (for one batch) at step 120: 347.8770, Accuracy: 0.5757\n","Training loss (for one batch) at step 130: 347.8698, Accuracy: 0.5747\n","Training loss (for one batch) at step 140: 345.3734, Accuracy: 0.5719\n","---- Training ----\n","Training loss: 307.3688\n","Training acc over epoch: 0.5719\n","---- Validation ----\n","Validation loss: 76.5118\n","Validation acc: 0.5828\n","Time taken: 9.74s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 354.6176, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 346.5902, Accuracy: 0.5591\n","Training loss (for one batch) at step 20: 350.0687, Accuracy: 0.5600\n","Training loss (for one batch) at step 30: 348.6139, Accuracy: 0.5632\n","Training loss (for one batch) at step 40: 344.5049, Accuracy: 0.5732\n","Training loss (for one batch) at step 50: 347.4168, Accuracy: 0.5765\n","Training loss (for one batch) at step 60: 342.6219, Accuracy: 0.5777\n","Training loss (for one batch) at step 70: 349.6052, Accuracy: 0.5761\n","Training loss (for one batch) at step 80: 349.8510, Accuracy: 0.5774\n","Training loss (for one batch) at step 90: 348.0982, Accuracy: 0.5797\n","Training loss (for one batch) at step 100: 348.4737, Accuracy: 0.5796\n","Training loss (for one batch) at step 110: 346.6640, Accuracy: 0.5804\n","Training loss (for one batch) at step 120: 346.6437, Accuracy: 0.5793\n","Training loss (for one batch) at step 130: 345.5900, Accuracy: 0.5786\n","Training loss (for one batch) at step 140: 351.0289, Accuracy: 0.5791\n","---- Training ----\n","Training loss: 304.5836\n","Training acc over epoch: 0.5784\n","---- Validation ----\n","Validation loss: 75.7936\n","Validation acc: 0.6206\n","Time taken: 9.90s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 346.1152, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 346.8779, Accuracy: 0.5782\n","Training loss (for one batch) at step 20: 348.1880, Accuracy: 0.5762\n","Training loss (for one batch) at step 30: 350.6150, Accuracy: 0.5855\n","Training loss (for one batch) at step 40: 346.4249, Accuracy: 0.5924\n","Training loss (for one batch) at step 50: 351.0359, Accuracy: 0.5957\n","Training loss (for one batch) at step 60: 345.1410, Accuracy: 0.5979\n","Training loss (for one batch) at step 70: 342.9283, Accuracy: 0.5990\n","Training loss (for one batch) at step 80: 346.8228, Accuracy: 0.6019\n","Training loss (for one batch) at step 90: 348.4533, Accuracy: 0.5997\n","Training loss (for one batch) at step 100: 349.6804, Accuracy: 0.6014\n","Training loss (for one batch) at step 110: 343.4318, Accuracy: 0.6013\n","Training loss (for one batch) at step 120: 342.2576, Accuracy: 0.5995\n","Training loss (for one batch) at step 130: 342.7884, Accuracy: 0.5972\n","Training loss (for one batch) at step 140: 342.6573, Accuracy: 0.5975\n","---- Training ----\n","Training loss: 302.6168\n","Training acc over epoch: 0.5973\n","---- Validation ----\n","Validation loss: 77.4292\n","Validation acc: 0.6161\n","Time taken: 9.96s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 351.6205, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 343.2555, Accuracy: 0.6145\n","Training loss (for one batch) at step 20: 341.2147, Accuracy: 0.6005\n","Training loss (for one batch) at step 30: 347.1101, Accuracy: 0.6103\n","Training loss (for one batch) at step 40: 345.0620, Accuracy: 0.6171\n","Training loss (for one batch) at step 50: 342.2553, Accuracy: 0.6145\n","Training loss (for one batch) at step 60: 343.8807, Accuracy: 0.6144\n","Training loss (for one batch) at step 70: 342.0068, Accuracy: 0.6162\n","Training loss (for one batch) at step 80: 346.5836, Accuracy: 0.6178\n","Training loss (for one batch) at step 90: 348.9207, Accuracy: 0.6158\n","Training loss (for one batch) at step 100: 346.2164, Accuracy: 0.6139\n","Training loss (for one batch) at step 110: 340.0077, Accuracy: 0.6114\n","Training loss (for one batch) at step 120: 340.1822, Accuracy: 0.6096\n","Training loss (for one batch) at step 130: 345.6067, Accuracy: 0.6073\n","Training loss (for one batch) at step 140: 349.1569, Accuracy: 0.6077\n","---- Training ----\n","Training loss: 305.0498\n","Training acc over epoch: 0.6075\n","---- Validation ----\n","Validation loss: 76.4864\n","Validation acc: 0.6005\n","Time taken: 9.74s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 348.8643, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 346.6669, Accuracy: 0.6500\n","Training loss (for one batch) at step 20: 344.7513, Accuracy: 0.6276\n","Training loss (for one batch) at step 30: 340.9454, Accuracy: 0.6313\n","Training loss (for one batch) at step 40: 342.8141, Accuracy: 0.6283\n","Training loss (for one batch) at step 50: 340.2028, Accuracy: 0.6265\n","Training loss (for one batch) at step 60: 344.9725, Accuracy: 0.6264\n","Training loss (for one batch) at step 70: 343.4253, Accuracy: 0.6280\n","Training loss (for one batch) at step 80: 345.5383, Accuracy: 0.6247\n","Training loss (for one batch) at step 90: 340.6459, Accuracy: 0.6290\n","Training loss (for one batch) at step 100: 343.7465, Accuracy: 0.6297\n","Training loss (for one batch) at step 110: 345.6566, Accuracy: 0.6269\n","Training loss (for one batch) at step 120: 346.7911, Accuracy: 0.6263\n","Training loss (for one batch) at step 130: 345.1419, Accuracy: 0.6240\n","Training loss (for one batch) at step 140: 345.7120, Accuracy: 0.6220\n","---- Training ----\n","Training loss: 300.8530\n","Training acc over epoch: 0.6215\n","---- Validation ----\n","Validation loss: 75.5075\n","Validation acc: 0.6204\n","Time taken: 9.63s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 347.0146, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 343.0438, Accuracy: 0.6373\n","Training loss (for one batch) at step 20: 340.4700, Accuracy: 0.6252\n","Training loss (for one batch) at step 30: 344.3864, Accuracy: 0.6148\n","Training loss (for one batch) at step 40: 336.5139, Accuracy: 0.6290\n","Training loss (for one batch) at step 50: 342.9934, Accuracy: 0.6312\n","Training loss (for one batch) at step 60: 339.3000, Accuracy: 0.6364\n","Training loss (for one batch) at step 70: 343.6293, Accuracy: 0.6352\n","Training loss (for one batch) at step 80: 341.6509, Accuracy: 0.6359\n","Training loss (for one batch) at step 90: 344.7643, Accuracy: 0.6368\n","Training loss (for one batch) at step 100: 342.5599, Accuracy: 0.6366\n","Training loss (for one batch) at step 110: 347.6344, Accuracy: 0.6353\n","Training loss (for one batch) at step 120: 341.4593, Accuracy: 0.6369\n","Training loss (for one batch) at step 130: 347.4998, Accuracy: 0.6382\n","Training loss (for one batch) at step 140: 342.6716, Accuracy: 0.6357\n","---- Training ----\n","Training loss: 303.2385\n","Training acc over epoch: 0.6356\n","---- Validation ----\n","Validation loss: 77.4892\n","Validation acc: 0.6131\n","Time taken: 10.44s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 341.0754, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 342.9496, Accuracy: 0.6473\n","Training loss (for one batch) at step 20: 342.2402, Accuracy: 0.6286\n","Training loss (for one batch) at step 30: 342.2825, Accuracy: 0.6303\n","Training loss (for one batch) at step 40: 334.8517, Accuracy: 0.6420\n","Training loss (for one batch) at step 50: 341.5632, Accuracy: 0.6384\n","Training loss (for one batch) at step 60: 340.1492, Accuracy: 0.6375\n","Training loss (for one batch) at step 70: 341.2410, Accuracy: 0.6411\n","Training loss (for one batch) at step 80: 340.9121, Accuracy: 0.6417\n","Training loss (for one batch) at step 90: 341.2485, Accuracy: 0.6410\n","Training loss (for one batch) at step 100: 340.5327, Accuracy: 0.6400\n","Training loss (for one batch) at step 110: 343.6423, Accuracy: 0.6374\n","Training loss (for one batch) at step 120: 340.8894, Accuracy: 0.6365\n","Training loss (for one batch) at step 130: 339.0001, Accuracy: 0.6352\n","Training loss (for one batch) at step 140: 341.7782, Accuracy: 0.6348\n","---- Training ----\n","Training loss: 297.7250\n","Training acc over epoch: 0.6345\n","---- Validation ----\n","Validation loss: 75.3855\n","Validation acc: 0.6080\n","Time taken: 9.54s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 344.4470, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 341.2034, Accuracy: 0.6555\n","Training loss (for one batch) at step 20: 335.6888, Accuracy: 0.6433\n","Training loss (for one batch) at step 30: 342.1106, Accuracy: 0.6416\n","Training loss (for one batch) at step 40: 340.6572, Accuracy: 0.6412\n","Training loss (for one batch) at step 50: 334.7889, Accuracy: 0.6455\n","Training loss (for one batch) at step 60: 333.6779, Accuracy: 0.6454\n","Training loss (for one batch) at step 70: 335.2208, Accuracy: 0.6508\n","Training loss (for one batch) at step 80: 349.2060, Accuracy: 0.6521\n","Training loss (for one batch) at step 90: 344.7619, Accuracy: 0.6510\n","Training loss (for one batch) at step 100: 346.6428, Accuracy: 0.6477\n","Training loss (for one batch) at step 110: 345.8358, Accuracy: 0.6458\n","Training loss (for one batch) at step 120: 344.3336, Accuracy: 0.6457\n","Training loss (for one batch) at step 130: 342.5157, Accuracy: 0.6479\n","Training loss (for one batch) at step 140: 338.5530, Accuracy: 0.6467\n","---- Training ----\n","Training loss: 299.7084\n","Training acc over epoch: 0.6457\n","---- Validation ----\n","Validation loss: 75.2964\n","Validation acc: 0.6171\n","Time taken: 9.50s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 339.3991, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 343.2572, Accuracy: 0.6373\n","Training loss (for one batch) at step 20: 334.2603, Accuracy: 0.6338\n","Training loss (for one batch) at step 30: 341.8762, Accuracy: 0.6439\n","Training loss (for one batch) at step 40: 337.1595, Accuracy: 0.6490\n","Training loss (for one batch) at step 50: 339.3910, Accuracy: 0.6496\n","Training loss (for one batch) at step 60: 335.6007, Accuracy: 0.6505\n","Training loss (for one batch) at step 70: 347.5149, Accuracy: 0.6528\n","Training loss (for one batch) at step 80: 342.5493, Accuracy: 0.6527\n","Training loss (for one batch) at step 90: 340.7928, Accuracy: 0.6513\n","Training loss (for one batch) at step 100: 343.4755, Accuracy: 0.6501\n","Training loss (for one batch) at step 110: 342.2034, Accuracy: 0.6498\n","Training loss (for one batch) at step 120: 338.5827, Accuracy: 0.6507\n","Training loss (for one batch) at step 130: 335.3796, Accuracy: 0.6503\n","Training loss (for one batch) at step 140: 338.9276, Accuracy: 0.6491\n","---- Training ----\n","Training loss: 300.8317\n","Training acc over epoch: 0.6488\n","---- Validation ----\n","Validation loss: 76.4469\n","Validation acc: 0.6384\n","Time taken: 9.69s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 338.4835, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 344.0197, Accuracy: 0.6755\n","Training loss (for one batch) at step 20: 333.4831, Accuracy: 0.6495\n","Training loss (for one batch) at step 30: 334.8911, Accuracy: 0.6571\n","Training loss (for one batch) at step 40: 332.8116, Accuracy: 0.6595\n","Training loss (for one batch) at step 50: 330.2015, Accuracy: 0.6627\n","Training loss (for one batch) at step 60: 334.6612, Accuracy: 0.6634\n","Training loss (for one batch) at step 70: 333.7859, Accuracy: 0.6662\n","Training loss (for one batch) at step 80: 341.5685, Accuracy: 0.6653\n","Training loss (for one batch) at step 90: 340.9084, Accuracy: 0.6669\n","Training loss (for one batch) at step 100: 341.3294, Accuracy: 0.6648\n","Training loss (for one batch) at step 110: 340.7997, Accuracy: 0.6634\n","Training loss (for one batch) at step 120: 335.3368, Accuracy: 0.6618\n","Training loss (for one batch) at step 130: 339.3309, Accuracy: 0.6638\n","Training loss (for one batch) at step 140: 342.0079, Accuracy: 0.6632\n","---- Training ----\n","Training loss: 298.0212\n","Training acc over epoch: 0.6615\n","---- Validation ----\n","Validation loss: 76.8367\n","Validation acc: 0.6456\n","Time taken: 9.60s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 344.9696, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 338.2163, Accuracy: 0.6545\n","Training loss (for one batch) at step 20: 335.5937, Accuracy: 0.6462\n","Training loss (for one batch) at step 30: 339.7330, Accuracy: 0.6577\n","Training loss (for one batch) at step 40: 328.6178, Accuracy: 0.6559\n","Training loss (for one batch) at step 50: 332.0111, Accuracy: 0.6596\n","Training loss (for one batch) at step 60: 327.6066, Accuracy: 0.6636\n","Training loss (for one batch) at step 70: 327.7282, Accuracy: 0.6661\n","Training loss (for one batch) at step 80: 343.6727, Accuracy: 0.6665\n","Training loss (for one batch) at step 90: 340.7504, Accuracy: 0.6629\n","Training loss (for one batch) at step 100: 345.4112, Accuracy: 0.6608\n","Training loss (for one batch) at step 110: 334.3723, Accuracy: 0.6586\n","Training loss (for one batch) at step 120: 332.2831, Accuracy: 0.6584\n","Training loss (for one batch) at step 130: 333.3388, Accuracy: 0.6568\n","Training loss (for one batch) at step 140: 341.8714, Accuracy: 0.6567\n","---- Training ----\n","Training loss: 300.0664\n","Training acc over epoch: 0.6558\n","---- Validation ----\n","Validation loss: 74.5199\n","Validation acc: 0.6252\n","Time taken: 9.62s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 337.7319, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 357.0043, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 339.7660, Accuracy: 0.6552\n","Training loss (for one batch) at step 30: 334.8654, Accuracy: 0.6652\n","Training loss (for one batch) at step 40: 328.8922, Accuracy: 0.6693\n","Training loss (for one batch) at step 50: 331.2781, Accuracy: 0.6727\n","Training loss (for one batch) at step 60: 325.7569, Accuracy: 0.6749\n","Training loss (for one batch) at step 70: 326.8974, Accuracy: 0.6768\n","Training loss (for one batch) at step 80: 340.2243, Accuracy: 0.6789\n","Training loss (for one batch) at step 90: 339.9126, Accuracy: 0.6786\n","Training loss (for one batch) at step 100: 334.3264, Accuracy: 0.6749\n","Training loss (for one batch) at step 110: 341.2916, Accuracy: 0.6693\n","Training loss (for one batch) at step 120: 328.0516, Accuracy: 0.6681\n","Training loss (for one batch) at step 130: 334.8813, Accuracy: 0.6676\n","Training loss (for one batch) at step 140: 336.8746, Accuracy: 0.6662\n","---- Training ----\n","Training loss: 292.1381\n","Training acc over epoch: 0.6649\n","---- Validation ----\n","Validation loss: 77.4875\n","Validation acc: 0.6620\n","Time taken: 9.50s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 332.0570, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 346.7973, Accuracy: 0.6373\n","Training loss (for one batch) at step 20: 324.7933, Accuracy: 0.6371\n","Training loss (for one batch) at step 30: 328.2315, Accuracy: 0.6410\n","Training loss (for one batch) at step 40: 331.9912, Accuracy: 0.6551\n","Training loss (for one batch) at step 50: 326.7047, Accuracy: 0.6576\n","Training loss (for one batch) at step 60: 332.2466, Accuracy: 0.6628\n","Training loss (for one batch) at step 70: 325.2744, Accuracy: 0.6694\n","Training loss (for one batch) at step 80: 339.9660, Accuracy: 0.6681\n","Training loss (for one batch) at step 90: 333.5076, Accuracy: 0.6681\n","Training loss (for one batch) at step 100: 340.2830, Accuracy: 0.6671\n","Training loss (for one batch) at step 110: 334.7290, Accuracy: 0.6650\n","Training loss (for one batch) at step 120: 328.4292, Accuracy: 0.6651\n","Training loss (for one batch) at step 130: 336.1363, Accuracy: 0.6634\n","Training loss (for one batch) at step 140: 330.5174, Accuracy: 0.6619\n","---- Training ----\n","Training loss: 290.7082\n","Training acc over epoch: 0.6623\n","---- Validation ----\n","Validation loss: 76.8224\n","Validation acc: 0.6445\n","Time taken: 9.70s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 345.2916, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 339.1686, Accuracy: 0.6655\n","Training loss (for one batch) at step 20: 334.4259, Accuracy: 0.6657\n","Training loss (for one batch) at step 30: 329.4316, Accuracy: 0.6723\n","Training loss (for one batch) at step 40: 326.9633, Accuracy: 0.6729\n","Training loss (for one batch) at step 50: 322.5291, Accuracy: 0.6755\n","Training loss (for one batch) at step 60: 327.0413, Accuracy: 0.6789\n","Training loss (for one batch) at step 70: 342.2151, Accuracy: 0.6770\n","Training loss (for one batch) at step 80: 333.6630, Accuracy: 0.6807\n","Training loss (for one batch) at step 90: 341.9543, Accuracy: 0.6785\n","Training loss (for one batch) at step 100: 336.1464, Accuracy: 0.6764\n","Training loss (for one batch) at step 110: 336.7485, Accuracy: 0.6750\n","Training loss (for one batch) at step 120: 322.0082, Accuracy: 0.6743\n","Training loss (for one batch) at step 130: 330.1357, Accuracy: 0.6740\n","Training loss (for one batch) at step 140: 336.3302, Accuracy: 0.6743\n","---- Training ----\n","Training loss: 291.0195\n","Training acc over epoch: 0.6734\n","---- Validation ----\n","Validation loss: 76.0671\n","Validation acc: 0.6295\n","Time taken: 9.54s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 339.8390, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 338.6825, Accuracy: 0.6582\n","Training loss (for one batch) at step 20: 334.3322, Accuracy: 0.6652\n","Training loss (for one batch) at step 30: 324.9828, Accuracy: 0.6713\n","Training loss (for one batch) at step 40: 328.1703, Accuracy: 0.6776\n","Training loss (for one batch) at step 50: 328.1919, Accuracy: 0.6804\n","Training loss (for one batch) at step 60: 330.2253, Accuracy: 0.6833\n","Training loss (for one batch) at step 70: 319.7951, Accuracy: 0.6858\n","Training loss (for one batch) at step 80: 327.8702, Accuracy: 0.6836\n","Training loss (for one batch) at step 90: 333.3973, Accuracy: 0.6825\n","Training loss (for one batch) at step 100: 328.5026, Accuracy: 0.6795\n","Training loss (for one batch) at step 110: 329.7162, Accuracy: 0.6761\n","Training loss (for one batch) at step 120: 334.2187, Accuracy: 0.6741\n","Training loss (for one batch) at step 130: 320.5515, Accuracy: 0.6708\n","Training loss (for one batch) at step 140: 324.9494, Accuracy: 0.6709\n","---- Training ----\n","Training loss: 294.9135\n","Training acc over epoch: 0.6712\n","---- Validation ----\n","Validation loss: 77.7269\n","Validation acc: 0.6566\n","Time taken: 9.54s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 337.1899, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 345.6502, Accuracy: 0.6518\n","Training loss (for one batch) at step 20: 326.3127, Accuracy: 0.6529\n","Training loss (for one batch) at step 30: 338.4015, Accuracy: 0.6623\n","Training loss (for one batch) at step 40: 329.0333, Accuracy: 0.6763\n","Training loss (for one batch) at step 50: 324.4194, Accuracy: 0.6782\n","Training loss (for one batch) at step 60: 314.5990, Accuracy: 0.6792\n","Training loss (for one batch) at step 70: 315.4960, Accuracy: 0.6838\n","Training loss (for one batch) at step 80: 329.8429, Accuracy: 0.6842\n","Training loss (for one batch) at step 90: 340.4901, Accuracy: 0.6799\n","Training loss (for one batch) at step 100: 335.0713, Accuracy: 0.6773\n","Training loss (for one batch) at step 110: 326.0356, Accuracy: 0.6748\n","Training loss (for one batch) at step 120: 325.3630, Accuracy: 0.6745\n","Training loss (for one batch) at step 130: 322.7659, Accuracy: 0.6736\n","Training loss (for one batch) at step 140: 328.9111, Accuracy: 0.6719\n","---- Training ----\n","Training loss: 305.1901\n","Training acc over epoch: 0.6731\n","---- Validation ----\n","Validation loss: 76.2531\n","Validation acc: 0.6378\n","Time taken: 9.64s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 338.6275, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 328.4068, Accuracy: 0.6509\n","Training loss (for one batch) at step 20: 331.3847, Accuracy: 0.6643\n","Training loss (for one batch) at step 30: 312.4879, Accuracy: 0.6761\n","Training loss (for one batch) at step 40: 319.5168, Accuracy: 0.6812\n","Training loss (for one batch) at step 50: 330.1271, Accuracy: 0.6843\n","Training loss (for one batch) at step 60: 320.0929, Accuracy: 0.6874\n","Training loss (for one batch) at step 70: 313.3484, Accuracy: 0.6911\n","Training loss (for one batch) at step 80: 324.2982, Accuracy: 0.6886\n","Training loss (for one batch) at step 90: 331.4118, Accuracy: 0.6869\n","Training loss (for one batch) at step 100: 338.4705, Accuracy: 0.6850\n","Training loss (for one batch) at step 110: 324.6719, Accuracy: 0.6811\n","Training loss (for one batch) at step 120: 336.3073, Accuracy: 0.6793\n","Training loss (for one batch) at step 130: 322.8076, Accuracy: 0.6793\n","Training loss (for one batch) at step 140: 330.2592, Accuracy: 0.6788\n","---- Training ----\n","Training loss: 293.2513\n","Training acc over epoch: 0.6783\n","---- Validation ----\n","Validation loss: 78.3888\n","Validation acc: 0.6475\n","Time taken: 9.60s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 347.2974, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 334.6536, Accuracy: 0.6527\n","Training loss (for one batch) at step 20: 330.2016, Accuracy: 0.6552\n","Training loss (for one batch) at step 30: 320.0024, Accuracy: 0.6745\n","Training loss (for one batch) at step 40: 317.1871, Accuracy: 0.6841\n","Training loss (for one batch) at step 50: 312.7037, Accuracy: 0.6824\n","Training loss (for one batch) at step 60: 307.6231, Accuracy: 0.6862\n","Training loss (for one batch) at step 70: 316.8316, Accuracy: 0.6893\n","Training loss (for one batch) at step 80: 331.6751, Accuracy: 0.6901\n","Training loss (for one batch) at step 90: 349.4524, Accuracy: 0.6848\n","Training loss (for one batch) at step 100: 339.6114, Accuracy: 0.6837\n","Training loss (for one batch) at step 110: 329.4173, Accuracy: 0.6816\n","Training loss (for one batch) at step 120: 325.3947, Accuracy: 0.6810\n","Training loss (for one batch) at step 130: 322.5251, Accuracy: 0.6803\n","Training loss (for one batch) at step 140: 337.2625, Accuracy: 0.6770\n","---- Training ----\n","Training loss: 293.9306\n","Training acc over epoch: 0.6762\n","---- Validation ----\n","Validation loss: 76.8159\n","Validation acc: 0.6464\n","Time taken: 10.84s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 330.1072, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 342.1093, Accuracy: 0.6482\n","Training loss (for one batch) at step 20: 336.7478, Accuracy: 0.6686\n","Training loss (for one batch) at step 30: 312.7356, Accuracy: 0.6765\n","Training loss (for one batch) at step 40: 311.9822, Accuracy: 0.6829\n","Training loss (for one batch) at step 50: 313.4942, Accuracy: 0.6851\n","Training loss (for one batch) at step 60: 305.9781, Accuracy: 0.6841\n","Training loss (for one batch) at step 70: 312.2923, Accuracy: 0.6863\n","Training loss (for one batch) at step 80: 331.5716, Accuracy: 0.6853\n","Training loss (for one batch) at step 90: 328.3774, Accuracy: 0.6835\n","Training loss (for one batch) at step 100: 334.2817, Accuracy: 0.6799\n","Training loss (for one batch) at step 110: 322.1874, Accuracy: 0.6782\n","Training loss (for one batch) at step 120: 316.2229, Accuracy: 0.6775\n","Training loss (for one batch) at step 130: 320.7848, Accuracy: 0.6765\n","Training loss (for one batch) at step 140: 319.1684, Accuracy: 0.6767\n","---- Training ----\n","Training loss: 291.7132\n","Training acc over epoch: 0.6750\n","---- Validation ----\n","Validation loss: 74.7522\n","Validation acc: 0.6486\n","Time taken: 13.53s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 326.2295, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 331.3948, Accuracy: 0.6545\n","Training loss (for one batch) at step 20: 322.2331, Accuracy: 0.6624\n","Training loss (for one batch) at step 30: 319.2390, Accuracy: 0.6745\n","Training loss (for one batch) at step 40: 306.8199, Accuracy: 0.6839\n","Training loss (for one batch) at step 50: 321.1234, Accuracy: 0.6912\n","Training loss (for one batch) at step 60: 311.7891, Accuracy: 0.6911\n","Training loss (for one batch) at step 70: 326.1312, Accuracy: 0.6946\n","Training loss (for one batch) at step 80: 323.1656, Accuracy: 0.6919\n","Training loss (for one batch) at step 90: 337.4006, Accuracy: 0.6884\n","Training loss (for one batch) at step 100: 326.7629, Accuracy: 0.6831\n","Training loss (for one batch) at step 110: 322.8562, Accuracy: 0.6805\n","Training loss (for one batch) at step 120: 323.2719, Accuracy: 0.6788\n","Training loss (for one batch) at step 130: 324.8994, Accuracy: 0.6796\n","Training loss (for one batch) at step 140: 323.8796, Accuracy: 0.6796\n","---- Training ----\n","Training loss: 281.4498\n","Training acc over epoch: 0.6808\n","---- Validation ----\n","Validation loss: 80.4667\n","Validation acc: 0.6437\n","Time taken: 12.35s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 339.3221, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 327.4794, Accuracy: 0.6555\n","Training loss (for one batch) at step 20: 325.0150, Accuracy: 0.6624\n","Training loss (for one batch) at step 30: 316.3696, Accuracy: 0.6674\n","Training loss (for one batch) at step 40: 317.6223, Accuracy: 0.6793\n","Training loss (for one batch) at step 50: 319.2693, Accuracy: 0.6847\n","Training loss (for one batch) at step 60: 305.1407, Accuracy: 0.6875\n","Training loss (for one batch) at step 70: 306.6193, Accuracy: 0.6920\n","Training loss (for one batch) at step 80: 324.0687, Accuracy: 0.6928\n","Training loss (for one batch) at step 90: 323.4937, Accuracy: 0.6854\n","Training loss (for one batch) at step 100: 331.0325, Accuracy: 0.6825\n","Training loss (for one batch) at step 110: 323.7705, Accuracy: 0.6788\n","Training loss (for one batch) at step 120: 325.5573, Accuracy: 0.6792\n","Training loss (for one batch) at step 130: 323.9099, Accuracy: 0.6779\n","Training loss (for one batch) at step 140: 317.4251, Accuracy: 0.6774\n","---- Training ----\n","Training loss: 284.5230\n","Training acc over epoch: 0.6753\n","---- Validation ----\n","Validation loss: 73.7733\n","Validation acc: 0.6448\n","Time taken: 10.45s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 338.0749, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 332.6409, Accuracy: 0.6336\n","Training loss (for one batch) at step 20: 316.5970, Accuracy: 0.6381\n","Training loss (for one batch) at step 30: 307.4677, Accuracy: 0.6465\n","Training loss (for one batch) at step 40: 308.8267, Accuracy: 0.6607\n","Training loss (for one batch) at step 50: 310.3082, Accuracy: 0.6716\n","Training loss (for one batch) at step 60: 304.5625, Accuracy: 0.6774\n","Training loss (for one batch) at step 70: 303.4374, Accuracy: 0.6803\n","Training loss (for one batch) at step 80: 321.9530, Accuracy: 0.6840\n","Training loss (for one batch) at step 90: 318.6924, Accuracy: 0.6789\n","Training loss (for one batch) at step 100: 336.2148, Accuracy: 0.6746\n","Training loss (for one batch) at step 110: 316.9345, Accuracy: 0.6700\n","Training loss (for one batch) at step 120: 315.5705, Accuracy: 0.6697\n","Training loss (for one batch) at step 130: 314.6941, Accuracy: 0.6687\n","Training loss (for one batch) at step 140: 324.0832, Accuracy: 0.6687\n","---- Training ----\n","Training loss: 273.9620\n","Training acc over epoch: 0.6667\n","---- Validation ----\n","Validation loss: 79.3387\n","Validation acc: 0.6491\n","Time taken: 9.59s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 332.5922, Accuracy: 0.5200\n","Training loss (for one batch) at step 10: 320.0813, Accuracy: 0.6264\n","Training loss (for one batch) at step 20: 322.0210, Accuracy: 0.6471\n","Training loss (for one batch) at step 30: 307.9887, Accuracy: 0.6603\n","Training loss (for one batch) at step 40: 312.1016, Accuracy: 0.6698\n","Training loss (for one batch) at step 50: 313.8865, Accuracy: 0.6802\n","Training loss (for one batch) at step 60: 292.4333, Accuracy: 0.6857\n","Training loss (for one batch) at step 70: 302.9116, Accuracy: 0.6873\n","Training loss (for one batch) at step 80: 312.1825, Accuracy: 0.6872\n","Training loss (for one batch) at step 90: 322.3242, Accuracy: 0.6818\n","Training loss (for one batch) at step 100: 328.9642, Accuracy: 0.6750\n","Training loss (for one batch) at step 110: 311.2912, Accuracy: 0.6729\n","Training loss (for one batch) at step 120: 306.8006, Accuracy: 0.6741\n","Training loss (for one batch) at step 130: 301.5881, Accuracy: 0.6752\n","Training loss (for one batch) at step 140: 311.7379, Accuracy: 0.6761\n","---- Training ----\n","Training loss: 265.4529\n","Training acc over epoch: 0.6741\n","---- Validation ----\n","Validation loss: 79.0702\n","Validation acc: 0.6384\n","Time taken: 9.54s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 345.8006, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 341.4844, Accuracy: 0.6509\n","Training loss (for one batch) at step 20: 309.4058, Accuracy: 0.6481\n","Training loss (for one batch) at step 30: 304.4634, Accuracy: 0.6642\n","Training loss (for one batch) at step 40: 305.3116, Accuracy: 0.6754\n","Training loss (for one batch) at step 50: 312.4717, Accuracy: 0.6800\n","Training loss (for one batch) at step 60: 301.8121, Accuracy: 0.6831\n","Training loss (for one batch) at step 70: 308.7918, Accuracy: 0.6887\n","Training loss (for one batch) at step 80: 327.2280, Accuracy: 0.6906\n","Training loss (for one batch) at step 90: 316.0486, Accuracy: 0.6868\n","Training loss (for one batch) at step 100: 319.0359, Accuracy: 0.6824\n","Training loss (for one batch) at step 110: 312.9251, Accuracy: 0.6768\n","Training loss (for one batch) at step 120: 305.8349, Accuracy: 0.6761\n","Training loss (for one batch) at step 130: 301.2672, Accuracy: 0.6759\n","Training loss (for one batch) at step 140: 315.8316, Accuracy: 0.6753\n","---- Training ----\n","Training loss: 270.8672\n","Training acc over epoch: 0.6744\n","---- Validation ----\n","Validation loss: 82.2179\n","Validation acc: 0.6505\n","Time taken: 9.53s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 325.7300, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 327.6372, Accuracy: 0.6418\n","Training loss (for one batch) at step 20: 304.4695, Accuracy: 0.6414\n","Training loss (for one batch) at step 30: 298.9649, Accuracy: 0.6565\n","Training loss (for one batch) at step 40: 305.7669, Accuracy: 0.6698\n","Training loss (for one batch) at step 50: 301.9876, Accuracy: 0.6775\n","Training loss (for one batch) at step 60: 306.0039, Accuracy: 0.6870\n","Training loss (for one batch) at step 70: 297.5306, Accuracy: 0.6911\n","Training loss (for one batch) at step 80: 321.8364, Accuracy: 0.6910\n","Training loss (for one batch) at step 90: 330.0322, Accuracy: 0.6864\n","Training loss (for one batch) at step 100: 327.9773, Accuracy: 0.6818\n","Training loss (for one batch) at step 110: 308.3262, Accuracy: 0.6796\n","Training loss (for one batch) at step 120: 310.4105, Accuracy: 0.6793\n","Training loss (for one batch) at step 130: 308.7197, Accuracy: 0.6786\n","Training loss (for one batch) at step 140: 300.7921, Accuracy: 0.6781\n","---- Training ----\n","Training loss: 287.0850\n","Training acc over epoch: 0.6763\n","---- Validation ----\n","Validation loss: 84.5163\n","Validation acc: 0.6357\n","Time taken: 9.66s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 326.0719, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 312.6423, Accuracy: 0.6345\n","Training loss (for one batch) at step 20: 311.0328, Accuracy: 0.6329\n","Training loss (for one batch) at step 30: 288.9070, Accuracy: 0.6535\n","Training loss (for one batch) at step 40: 301.5308, Accuracy: 0.6627\n","Training loss (for one batch) at step 50: 295.9159, Accuracy: 0.6747\n","Training loss (for one batch) at step 60: 297.0007, Accuracy: 0.6848\n","Training loss (for one batch) at step 70: 307.9760, Accuracy: 0.6869\n","Training loss (for one batch) at step 80: 315.7755, Accuracy: 0.6880\n","Training loss (for one batch) at step 90: 320.9432, Accuracy: 0.6866\n","Training loss (for one batch) at step 100: 326.9804, Accuracy: 0.6815\n","Training loss (for one batch) at step 110: 308.6558, Accuracy: 0.6780\n","Training loss (for one batch) at step 120: 303.4828, Accuracy: 0.6772\n","Training loss (for one batch) at step 130: 306.7495, Accuracy: 0.6767\n","Training loss (for one batch) at step 140: 305.3493, Accuracy: 0.6772\n","---- Training ----\n","Training loss: 261.3392\n","Training acc over epoch: 0.6754\n","---- Validation ----\n","Validation loss: 87.7089\n","Validation acc: 0.6526\n","Time taken: 9.49s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 317.7118, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 320.7552, Accuracy: 0.6309\n","Training loss (for one batch) at step 20: 309.0764, Accuracy: 0.6443\n","Training loss (for one batch) at step 30: 296.0111, Accuracy: 0.6574\n","Training loss (for one batch) at step 40: 289.3843, Accuracy: 0.6702\n","Training loss (for one batch) at step 50: 302.5659, Accuracy: 0.6810\n","Training loss (for one batch) at step 60: 296.7674, Accuracy: 0.6839\n","Training loss (for one batch) at step 70: 294.2676, Accuracy: 0.6873\n","Training loss (for one batch) at step 80: 305.3122, Accuracy: 0.6889\n","Training loss (for one batch) at step 90: 328.5022, Accuracy: 0.6875\n","Training loss (for one batch) at step 100: 314.3911, Accuracy: 0.6810\n","Training loss (for one batch) at step 110: 320.4852, Accuracy: 0.6772\n","Training loss (for one batch) at step 120: 298.9733, Accuracy: 0.6751\n","Training loss (for one batch) at step 130: 307.2205, Accuracy: 0.6759\n","Training loss (for one batch) at step 140: 310.3542, Accuracy: 0.6753\n","---- Training ----\n","Training loss: 286.8267\n","Training acc over epoch: 0.6771\n","---- Validation ----\n","Validation loss: 82.7509\n","Validation acc: 0.6424\n","Time taken: 9.71s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 313.8113, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 317.0390, Accuracy: 0.6491\n","Training loss (for one batch) at step 20: 290.5026, Accuracy: 0.6490\n","Training loss (for one batch) at step 30: 298.5555, Accuracy: 0.6626\n","Training loss (for one batch) at step 40: 280.6670, Accuracy: 0.6759\n","Training loss (for one batch) at step 50: 291.9499, Accuracy: 0.6843\n","Training loss (for one batch) at step 60: 289.9543, Accuracy: 0.6903\n","Training loss (for one batch) at step 70: 303.9562, Accuracy: 0.6934\n","Training loss (for one batch) at step 80: 309.4324, Accuracy: 0.6927\n","Training loss (for one batch) at step 90: 322.3022, Accuracy: 0.6885\n","Training loss (for one batch) at step 100: 318.7679, Accuracy: 0.6811\n","Training loss (for one batch) at step 110: 316.6899, Accuracy: 0.6764\n","Training loss (for one batch) at step 120: 291.7547, Accuracy: 0.6756\n","Training loss (for one batch) at step 130: 304.5630, Accuracy: 0.6746\n","Training loss (for one batch) at step 140: 322.2583, Accuracy: 0.6748\n","---- Training ----\n","Training loss: 258.8902\n","Training acc over epoch: 0.6743\n","---- Validation ----\n","Validation loss: 79.1087\n","Validation acc: 0.6588\n","Time taken: 9.74s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 319.9026, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 308.1409, Accuracy: 0.6518\n","Training loss (for one batch) at step 20: 297.2877, Accuracy: 0.6433\n","Training loss (for one batch) at step 30: 308.8176, Accuracy: 0.6603\n","Training loss (for one batch) at step 40: 316.6257, Accuracy: 0.6773\n","Training loss (for one batch) at step 50: 281.0253, Accuracy: 0.6875\n","Training loss (for one batch) at step 60: 296.6994, Accuracy: 0.6936\n","Training loss (for one batch) at step 70: 291.0421, Accuracy: 0.6982\n","Training loss (for one batch) at step 80: 305.0832, Accuracy: 0.6985\n","Training loss (for one batch) at step 90: 320.5976, Accuracy: 0.6892\n","Training loss (for one batch) at step 100: 312.0746, Accuracy: 0.6850\n","Training loss (for one batch) at step 110: 292.7153, Accuracy: 0.6814\n","Training loss (for one batch) at step 120: 296.6281, Accuracy: 0.6810\n","Training loss (for one batch) at step 130: 288.1941, Accuracy: 0.6832\n","Training loss (for one batch) at step 140: 309.7557, Accuracy: 0.6818\n","---- Training ----\n","Training loss: 263.7765\n","Training acc over epoch: 0.6799\n","---- Validation ----\n","Validation loss: 83.0240\n","Validation acc: 0.6580\n","Time taken: 9.53s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 319.3524, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 313.7026, Accuracy: 0.6318\n","Training loss (for one batch) at step 20: 293.4699, Accuracy: 0.6348\n","Training loss (for one batch) at step 30: 288.6673, Accuracy: 0.6568\n","Training loss (for one batch) at step 40: 292.3896, Accuracy: 0.6722\n","Training loss (for one batch) at step 50: 294.7308, Accuracy: 0.6816\n","Training loss (for one batch) at step 60: 281.7968, Accuracy: 0.6887\n","Training loss (for one batch) at step 70: 289.6824, Accuracy: 0.6949\n","Training loss (for one batch) at step 80: 300.1330, Accuracy: 0.6947\n","Training loss (for one batch) at step 90: 297.4565, Accuracy: 0.6905\n","Training loss (for one batch) at step 100: 304.3073, Accuracy: 0.6855\n","Training loss (for one batch) at step 110: 291.6246, Accuracy: 0.6805\n","Training loss (for one batch) at step 120: 297.2181, Accuracy: 0.6800\n","Training loss (for one batch) at step 130: 289.0363, Accuracy: 0.6792\n","Training loss (for one batch) at step 140: 298.8456, Accuracy: 0.6792\n","---- Training ----\n","Training loss: 276.2359\n","Training acc over epoch: 0.6785\n","---- Validation ----\n","Validation loss: 76.6433\n","Validation acc: 0.6445\n","Time taken: 9.51s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 317.8274, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 319.3828, Accuracy: 0.6373\n","Training loss (for one batch) at step 20: 289.3264, Accuracy: 0.6400\n","Training loss (for one batch) at step 30: 301.9283, Accuracy: 0.6561\n","Training loss (for one batch) at step 40: 288.8223, Accuracy: 0.6724\n","Training loss (for one batch) at step 50: 288.9202, Accuracy: 0.6827\n","Training loss (for one batch) at step 60: 280.0807, Accuracy: 0.6920\n","Training loss (for one batch) at step 70: 280.1177, Accuracy: 0.7007\n","Training loss (for one batch) at step 80: 292.6319, Accuracy: 0.6988\n","Training loss (for one batch) at step 90: 310.1276, Accuracy: 0.6927\n","Training loss (for one batch) at step 100: 304.4685, Accuracy: 0.6859\n","Training loss (for one batch) at step 110: 293.8123, Accuracy: 0.6813\n","Training loss (for one batch) at step 120: 295.8034, Accuracy: 0.6812\n","Training loss (for one batch) at step 130: 287.1153, Accuracy: 0.6827\n","Training loss (for one batch) at step 140: 290.4420, Accuracy: 0.6815\n","---- Training ----\n","Training loss: 255.4996\n","Training acc over epoch: 0.6814\n","---- Validation ----\n","Validation loss: 78.4787\n","Validation acc: 0.6303\n","Time taken: 9.56s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 319.4681, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 331.3972, Accuracy: 0.6109\n","Training loss (for one batch) at step 20: 296.0914, Accuracy: 0.6333\n","Training loss (for one batch) at step 30: 293.3088, Accuracy: 0.6474\n","Training loss (for one batch) at step 40: 299.2906, Accuracy: 0.6612\n","Training loss (for one batch) at step 50: 298.6928, Accuracy: 0.6735\n","Training loss (for one batch) at step 60: 290.8867, Accuracy: 0.6805\n","Training loss (for one batch) at step 70: 287.8914, Accuracy: 0.6877\n","Training loss (for one batch) at step 80: 296.7483, Accuracy: 0.6898\n","Training loss (for one batch) at step 90: 314.7963, Accuracy: 0.6841\n","Training loss (for one batch) at step 100: 317.6697, Accuracy: 0.6750\n","Training loss (for one batch) at step 110: 300.7247, Accuracy: 0.6703\n","Training loss (for one batch) at step 120: 294.8968, Accuracy: 0.6719\n","Training loss (for one batch) at step 130: 294.9978, Accuracy: 0.6718\n","Training loss (for one batch) at step 140: 303.7245, Accuracy: 0.6719\n","---- Training ----\n","Training loss: 264.3987\n","Training acc over epoch: 0.6710\n","---- Validation ----\n","Validation loss: 86.0859\n","Validation acc: 0.6402\n","Time taken: 9.55s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 318.1306, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 318.9012, Accuracy: 0.6445\n","Training loss (for one batch) at step 20: 280.2330, Accuracy: 0.6333\n","Training loss (for one batch) at step 30: 284.0038, Accuracy: 0.6565\n","Training loss (for one batch) at step 40: 273.5153, Accuracy: 0.6654\n","Training loss (for one batch) at step 50: 287.8107, Accuracy: 0.6743\n","Training loss (for one batch) at step 60: 280.5008, Accuracy: 0.6818\n","Training loss (for one batch) at step 70: 282.9192, Accuracy: 0.6877\n","Training loss (for one batch) at step 80: 297.7324, Accuracy: 0.6912\n","Training loss (for one batch) at step 90: 299.3929, Accuracy: 0.6870\n","Training loss (for one batch) at step 100: 308.7727, Accuracy: 0.6786\n","Training loss (for one batch) at step 110: 296.7443, Accuracy: 0.6729\n","Training loss (for one batch) at step 120: 291.9287, Accuracy: 0.6739\n","Training loss (for one batch) at step 130: 291.1933, Accuracy: 0.6754\n","Training loss (for one batch) at step 140: 297.2657, Accuracy: 0.6750\n","---- Training ----\n","Training loss: 254.9919\n","Training acc over epoch: 0.6734\n","---- Validation ----\n","Validation loss: 99.7339\n","Validation acc: 0.6354\n","Time taken: 9.64s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 312.5793, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 308.1505, Accuracy: 0.6373\n","Training loss (for one batch) at step 20: 299.7318, Accuracy: 0.6381\n","Training loss (for one batch) at step 30: 275.5189, Accuracy: 0.6574\n","Training loss (for one batch) at step 40: 278.6577, Accuracy: 0.6734\n","Training loss (for one batch) at step 50: 277.6026, Accuracy: 0.6822\n","Training loss (for one batch) at step 60: 298.3055, Accuracy: 0.6902\n","Training loss (for one batch) at step 70: 287.3865, Accuracy: 0.6989\n","Training loss (for one batch) at step 80: 305.0734, Accuracy: 0.6985\n","Training loss (for one batch) at step 90: 307.7318, Accuracy: 0.6908\n","Training loss (for one batch) at step 100: 308.4657, Accuracy: 0.6829\n","Training loss (for one batch) at step 110: 295.3854, Accuracy: 0.6772\n","Training loss (for one batch) at step 120: 280.5422, Accuracy: 0.6779\n","Training loss (for one batch) at step 130: 289.1839, Accuracy: 0.6784\n","Training loss (for one batch) at step 140: 292.2985, Accuracy: 0.6781\n","---- Training ----\n","Training loss: 267.7103\n","Training acc over epoch: 0.6765\n","---- Validation ----\n","Validation loss: 84.5790\n","Validation acc: 0.6110\n","Time taken: 9.56s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 308.6475, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 320.5060, Accuracy: 0.5936\n","Training loss (for one batch) at step 20: 309.1391, Accuracy: 0.6124\n","Training loss (for one batch) at step 30: 269.4113, Accuracy: 0.6374\n","Training loss (for one batch) at step 40: 285.7930, Accuracy: 0.6585\n","Training loss (for one batch) at step 50: 271.6723, Accuracy: 0.6663\n","Training loss (for one batch) at step 60: 258.2513, Accuracy: 0.6766\n","Training loss (for one batch) at step 70: 281.1801, Accuracy: 0.6873\n","Training loss (for one batch) at step 80: 279.1779, Accuracy: 0.6881\n","Training loss (for one batch) at step 90: 296.8602, Accuracy: 0.6820\n","Training loss (for one batch) at step 100: 295.7051, Accuracy: 0.6747\n","Training loss (for one batch) at step 110: 293.8595, Accuracy: 0.6705\n","Training loss (for one batch) at step 120: 284.0424, Accuracy: 0.6726\n","Training loss (for one batch) at step 130: 288.4456, Accuracy: 0.6718\n","Training loss (for one batch) at step 140: 296.0143, Accuracy: 0.6713\n","---- Training ----\n","Training loss: 274.6748\n","Training acc over epoch: 0.6704\n","---- Validation ----\n","Validation loss: 83.0418\n","Validation acc: 0.6365\n","Time taken: 9.64s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 311.0773, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 302.5231, Accuracy: 0.6164\n","Training loss (for one batch) at step 20: 293.6922, Accuracy: 0.6248\n","Training loss (for one batch) at step 30: 276.4248, Accuracy: 0.6394\n","Training loss (for one batch) at step 40: 273.9614, Accuracy: 0.6534\n","Training loss (for one batch) at step 50: 274.2398, Accuracy: 0.6665\n","Training loss (for one batch) at step 60: 274.6713, Accuracy: 0.6807\n","Training loss (for one batch) at step 70: 275.9779, Accuracy: 0.6872\n","Training loss (for one batch) at step 80: 294.1585, Accuracy: 0.6870\n","Training loss (for one batch) at step 90: 303.1038, Accuracy: 0.6804\n","Training loss (for one batch) at step 100: 293.4485, Accuracy: 0.6738\n","Training loss (for one batch) at step 110: 290.9258, Accuracy: 0.6677\n","Training loss (for one batch) at step 120: 279.9877, Accuracy: 0.6687\n","Training loss (for one batch) at step 130: 273.9854, Accuracy: 0.6715\n","Training loss (for one batch) at step 140: 289.9084, Accuracy: 0.6710\n","---- Training ----\n","Training loss: 270.8820\n","Training acc over epoch: 0.6695\n","---- Validation ----\n","Validation loss: 88.6530\n","Validation acc: 0.6464\n","Time taken: 9.58s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 316.9258, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 296.8690, Accuracy: 0.6191\n","Training loss (for one batch) at step 20: 304.0772, Accuracy: 0.6081\n","Training loss (for one batch) at step 30: 268.8024, Accuracy: 0.6339\n","Training loss (for one batch) at step 40: 275.4311, Accuracy: 0.6549\n","Training loss (for one batch) at step 50: 272.0692, Accuracy: 0.6659\n","Training loss (for one batch) at step 60: 284.2213, Accuracy: 0.6748\n","Training loss (for one batch) at step 70: 266.1217, Accuracy: 0.6807\n","Training loss (for one batch) at step 80: 290.6721, Accuracy: 0.6815\n","Training loss (for one batch) at step 90: 277.2826, Accuracy: 0.6770\n","Training loss (for one batch) at step 100: 298.4726, Accuracy: 0.6690\n","Training loss (for one batch) at step 110: 299.5031, Accuracy: 0.6647\n","Training loss (for one batch) at step 120: 297.6094, Accuracy: 0.6671\n","Training loss (for one batch) at step 130: 276.7646, Accuracy: 0.6680\n","Training loss (for one batch) at step 140: 282.5883, Accuracy: 0.6681\n","---- Training ----\n","Training loss: 271.5886\n","Training acc over epoch: 0.6662\n","---- Validation ----\n","Validation loss: 79.3011\n","Validation acc: 0.6351\n","Time taken: 9.52s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 310.7131, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 311.0573, Accuracy: 0.6118\n","Training loss (for one batch) at step 20: 286.2299, Accuracy: 0.6224\n","Training loss (for one batch) at step 30: 271.3095, Accuracy: 0.6413\n","Training loss (for one batch) at step 40: 287.7349, Accuracy: 0.6578\n","Training loss (for one batch) at step 50: 269.2158, Accuracy: 0.6718\n","Training loss (for one batch) at step 60: 277.9686, Accuracy: 0.6816\n","Training loss (for one batch) at step 70: 265.3995, Accuracy: 0.6886\n","Training loss (for one batch) at step 80: 284.2007, Accuracy: 0.6883\n","Training loss (for one batch) at step 90: 298.4185, Accuracy: 0.6836\n","Training loss (for one batch) at step 100: 296.4135, Accuracy: 0.6764\n","Training loss (for one batch) at step 110: 302.6652, Accuracy: 0.6721\n","Training loss (for one batch) at step 120: 290.3948, Accuracy: 0.6726\n","Training loss (for one batch) at step 130: 287.6010, Accuracy: 0.6744\n","Training loss (for one batch) at step 140: 288.0794, Accuracy: 0.6755\n","---- Training ----\n","Training loss: 254.4084\n","Training acc over epoch: 0.6738\n","---- Validation ----\n","Validation loss: 85.9026\n","Validation acc: 0.6190\n","Time taken: 9.61s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 316.8987, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 311.8613, Accuracy: 0.5891\n","Training loss (for one batch) at step 20: 281.3870, Accuracy: 0.6081\n","Training loss (for one batch) at step 30: 273.0720, Accuracy: 0.6274\n","Training loss (for one batch) at step 40: 274.1763, Accuracy: 0.6493\n","Training loss (for one batch) at step 50: 270.7696, Accuracy: 0.6627\n","Training loss (for one batch) at step 60: 274.6284, Accuracy: 0.6785\n","Training loss (for one batch) at step 70: 279.6415, Accuracy: 0.6866\n","Training loss (for one batch) at step 80: 290.0909, Accuracy: 0.6843\n","Training loss (for one batch) at step 90: 305.7645, Accuracy: 0.6792\n","Training loss (for one batch) at step 100: 290.1122, Accuracy: 0.6715\n","Training loss (for one batch) at step 110: 262.2064, Accuracy: 0.6653\n","Training loss (for one batch) at step 120: 273.9105, Accuracy: 0.6655\n","Training loss (for one batch) at step 130: 273.5638, Accuracy: 0.6683\n","Training loss (for one batch) at step 140: 297.2951, Accuracy: 0.6692\n","---- Training ----\n","Training loss: 259.8785\n","Training acc over epoch: 0.6673\n","---- Validation ----\n","Validation loss: 99.2489\n","Validation acc: 0.6244\n","Time taken: 9.60s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 306.0800, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 297.8033, Accuracy: 0.5800\n","Training loss (for one batch) at step 20: 293.5678, Accuracy: 0.6038\n","Training loss (for one batch) at step 30: 284.3279, Accuracy: 0.6235\n","Training loss (for one batch) at step 40: 273.8602, Accuracy: 0.6471\n","Training loss (for one batch) at step 50: 277.6859, Accuracy: 0.6643\n","Training loss (for one batch) at step 60: 268.3675, Accuracy: 0.6775\n","Training loss (for one batch) at step 70: 250.7065, Accuracy: 0.6863\n","Training loss (for one batch) at step 80: 280.5237, Accuracy: 0.6841\n","Training loss (for one batch) at step 90: 279.5855, Accuracy: 0.6777\n","Training loss (for one batch) at step 100: 303.4364, Accuracy: 0.6691\n","Training loss (for one batch) at step 110: 288.7810, Accuracy: 0.6656\n","Training loss (for one batch) at step 120: 267.3791, Accuracy: 0.6672\n","Training loss (for one batch) at step 130: 267.3484, Accuracy: 0.6692\n","Training loss (for one batch) at step 140: 285.2556, Accuracy: 0.6700\n","---- Training ----\n","Training loss: 256.1819\n","Training acc over epoch: 0.6675\n","---- Validation ----\n","Validation loss: 92.7539\n","Validation acc: 0.6327\n","Time taken: 9.60s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 290.6709, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 305.1960, Accuracy: 0.5855\n","Training loss (for one batch) at step 20: 278.4930, Accuracy: 0.6071\n","Training loss (for one batch) at step 30: 282.1253, Accuracy: 0.6368\n","Training loss (for one batch) at step 40: 274.4591, Accuracy: 0.6520\n","Training loss (for one batch) at step 50: 249.5995, Accuracy: 0.6690\n","Training loss (for one batch) at step 60: 258.5305, Accuracy: 0.6831\n","Training loss (for one batch) at step 70: 280.6577, Accuracy: 0.6892\n","Training loss (for one batch) at step 80: 265.0708, Accuracy: 0.6907\n","Training loss (for one batch) at step 90: 288.3712, Accuracy: 0.6847\n","Training loss (for one batch) at step 100: 283.4154, Accuracy: 0.6757\n","Training loss (for one batch) at step 110: 279.7435, Accuracy: 0.6723\n","Training loss (for one batch) at step 120: 281.7151, Accuracy: 0.6726\n","Training loss (for one batch) at step 130: 275.4866, Accuracy: 0.6726\n","Training loss (for one batch) at step 140: 286.1975, Accuracy: 0.6724\n","---- Training ----\n","Training loss: 254.9047\n","Training acc over epoch: 0.6707\n","---- Validation ----\n","Validation loss: 89.7605\n","Validation acc: 0.6263\n","Time taken: 9.62s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 305.2094, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 309.8240, Accuracy: 0.5836\n","Training loss (for one batch) at step 20: 275.6327, Accuracy: 0.5924\n","Training loss (for one batch) at step 30: 265.6973, Accuracy: 0.6194\n","Training loss (for one batch) at step 40: 262.6076, Accuracy: 0.6424\n","Training loss (for one batch) at step 50: 261.4375, Accuracy: 0.6610\n","Training loss (for one batch) at step 60: 260.0940, Accuracy: 0.6726\n","Training loss (for one batch) at step 70: 259.6079, Accuracy: 0.6810\n","Training loss (for one batch) at step 80: 286.1422, Accuracy: 0.6822\n","Training loss (for one batch) at step 90: 286.7321, Accuracy: 0.6760\n","Training loss (for one batch) at step 100: 281.0309, Accuracy: 0.6689\n","Training loss (for one batch) at step 110: 289.5585, Accuracy: 0.6639\n","Training loss (for one batch) at step 120: 280.6916, Accuracy: 0.6650\n","Training loss (for one batch) at step 130: 268.1536, Accuracy: 0.6669\n","Training loss (for one batch) at step 140: 285.4684, Accuracy: 0.6672\n","---- Training ----\n","Training loss: 281.3245\n","Training acc over epoch: 0.6663\n","---- Validation ----\n","Validation loss: 93.4914\n","Validation acc: 0.6220\n","Time taken: 9.64s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.6232\n","Validation AUC: 0.6236\n","Validation Balanced_ACC: 0.2460\n","Validation MI: 0.0377\n","Validation Normalized MI: 0.0548\n","Validation Adjusted MI: 0.0548\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 490.5670, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 468.5676, Accuracy: 0.5182\n","Training loss (for one batch) at step 20: 447.7473, Accuracy: 0.5138\n","Training loss (for one batch) at step 30: 430.2632, Accuracy: 0.5158\n","Training loss (for one batch) at step 40: 406.5933, Accuracy: 0.5171\n","Training loss (for one batch) at step 50: 468.2566, Accuracy: 0.5163\n","Training loss (for one batch) at step 60: 428.0286, Accuracy: 0.5133\n","Training loss (for one batch) at step 70: 461.4500, Accuracy: 0.5085\n","Training loss (for one batch) at step 80: 441.0796, Accuracy: 0.5127\n","Training loss (for one batch) at step 90: 438.1328, Accuracy: 0.5127\n","Training loss (for one batch) at step 100: 413.0956, Accuracy: 0.5131\n","Training loss (for one batch) at step 110: 421.4083, Accuracy: 0.5131\n","Training loss (for one batch) at step 120: 405.2443, Accuracy: 0.5121\n","Training loss (for one batch) at step 130: 457.2428, Accuracy: 0.5124\n","Training loss (for one batch) at step 140: 438.4429, Accuracy: 0.5122\n","---- Training ----\n","Training loss: 367.9784\n","Training acc over epoch: 0.5119\n","---- Validation ----\n","Validation loss: 76.4922\n","Validation acc: 0.4938\n","Time taken: 35.37s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 451.1980, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 423.5407, Accuracy: 0.5318\n","Training loss (for one batch) at step 20: 401.6177, Accuracy: 0.5186\n","Training loss (for one batch) at step 30: 418.1152, Accuracy: 0.5223\n","Training loss (for one batch) at step 40: 402.6947, Accuracy: 0.5159\n","Training loss (for one batch) at step 50: 405.0690, Accuracy: 0.5147\n","Training loss (for one batch) at step 60: 390.5868, Accuracy: 0.5152\n","Training loss (for one batch) at step 70: 393.2913, Accuracy: 0.5151\n","Training loss (for one batch) at step 80: 392.6739, Accuracy: 0.5164\n","Training loss (for one batch) at step 90: 389.9820, Accuracy: 0.5226\n","Training loss (for one batch) at step 100: 397.8190, Accuracy: 0.5221\n","Training loss (for one batch) at step 110: 395.4173, Accuracy: 0.5215\n","Training loss (for one batch) at step 120: 387.7181, Accuracy: 0.5194\n","Training loss (for one batch) at step 130: 386.0304, Accuracy: 0.5191\n","Training loss (for one batch) at step 140: 401.2484, Accuracy: 0.5184\n","---- Training ----\n","Training loss: 352.9490\n","Training acc over epoch: 0.5186\n","---- Validation ----\n","Validation loss: 76.1814\n","Validation acc: 0.5164\n","Time taken: 9.58s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 386.7480, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 375.6260, Accuracy: 0.5000\n","Training loss (for one batch) at step 20: 378.9072, Accuracy: 0.5081\n","Training loss (for one batch) at step 30: 391.8675, Accuracy: 0.5184\n","Training loss (for one batch) at step 40: 376.1496, Accuracy: 0.5185\n","Training loss (for one batch) at step 50: 377.1560, Accuracy: 0.5216\n","Training loss (for one batch) at step 60: 387.8567, Accuracy: 0.5249\n","Training loss (for one batch) at step 70: 367.5748, Accuracy: 0.5235\n","Training loss (for one batch) at step 80: 378.3188, Accuracy: 0.5249\n","Training loss (for one batch) at step 90: 372.0172, Accuracy: 0.5210\n","Training loss (for one batch) at step 100: 374.2556, Accuracy: 0.5250\n","Training loss (for one batch) at step 110: 363.3540, Accuracy: 0.5231\n","Training loss (for one batch) at step 120: 381.4058, Accuracy: 0.5258\n","Training loss (for one batch) at step 130: 369.8670, Accuracy: 0.5256\n","Training loss (for one batch) at step 140: 369.3434, Accuracy: 0.5250\n","---- Training ----\n","Training loss: 329.7141\n","Training acc over epoch: 0.5262\n","---- Validation ----\n","Validation loss: 76.6472\n","Validation acc: 0.5215\n","Time taken: 9.59s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 369.8261, Accuracy: 0.4300\n","Training loss (for one batch) at step 10: 371.5851, Accuracy: 0.5173\n","Training loss (for one batch) at step 20: 369.0494, Accuracy: 0.5262\n","Training loss (for one batch) at step 30: 387.3214, Accuracy: 0.5323\n","Training loss (for one batch) at step 40: 376.8123, Accuracy: 0.5288\n","Training loss (for one batch) at step 50: 364.4216, Accuracy: 0.5304\n","Training loss (for one batch) at step 60: 363.0652, Accuracy: 0.5330\n","Training loss (for one batch) at step 70: 360.0616, Accuracy: 0.5335\n","Training loss (for one batch) at step 80: 348.9204, Accuracy: 0.5332\n","Training loss (for one batch) at step 90: 364.6180, Accuracy: 0.5345\n","Training loss (for one batch) at step 100: 366.3794, Accuracy: 0.5329\n","Training loss (for one batch) at step 110: 360.9484, Accuracy: 0.5314\n","Training loss (for one batch) at step 120: 369.4192, Accuracy: 0.5288\n","Training loss (for one batch) at step 130: 366.0546, Accuracy: 0.5284\n","Training loss (for one batch) at step 140: 359.5022, Accuracy: 0.5296\n","---- Training ----\n","Training loss: 323.6081\n","Training acc over epoch: 0.5300\n","---- Validation ----\n","Validation loss: 75.7621\n","Validation acc: 0.5664\n","Time taken: 9.64s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 366.4987, Accuracy: 0.5600\n","Training loss (for one batch) at step 10: 358.6082, Accuracy: 0.5300\n","Training loss (for one batch) at step 20: 357.8208, Accuracy: 0.5248\n","Training loss (for one batch) at step 30: 369.0724, Accuracy: 0.5306\n","Training loss (for one batch) at step 40: 351.1598, Accuracy: 0.5351\n","Training loss (for one batch) at step 50: 353.0816, Accuracy: 0.5327\n","Training loss (for one batch) at step 60: 364.2967, Accuracy: 0.5349\n","Training loss (for one batch) at step 70: 366.3987, Accuracy: 0.5363\n","Training loss (for one batch) at step 80: 350.4472, Accuracy: 0.5402\n","Training loss (for one batch) at step 90: 356.8929, Accuracy: 0.5426\n","Training loss (for one batch) at step 100: 356.1332, Accuracy: 0.5425\n","Training loss (for one batch) at step 110: 360.4294, Accuracy: 0.5401\n","Training loss (for one batch) at step 120: 358.8433, Accuracy: 0.5388\n","Training loss (for one batch) at step 130: 358.5696, Accuracy: 0.5382\n","Training loss (for one batch) at step 140: 357.1820, Accuracy: 0.5387\n","---- Training ----\n","Training loss: 308.8807\n","Training acc over epoch: 0.5399\n","---- Validation ----\n","Validation loss: 75.9501\n","Validation acc: 0.5825\n","Time taken: 9.72s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 366.1420, Accuracy: 0.4300\n","Training loss (for one batch) at step 10: 353.7109, Accuracy: 0.5364\n","Training loss (for one batch) at step 20: 351.0596, Accuracy: 0.5471\n","Training loss (for one batch) at step 30: 350.6729, Accuracy: 0.5400\n","Training loss (for one batch) at step 40: 350.7384, Accuracy: 0.5420\n","Training loss (for one batch) at step 50: 358.3387, Accuracy: 0.5427\n","Training loss (for one batch) at step 60: 350.0260, Accuracy: 0.5430\n","Training loss (for one batch) at step 70: 359.2673, Accuracy: 0.5476\n","Training loss (for one batch) at step 80: 359.4733, Accuracy: 0.5490\n","Training loss (for one batch) at step 90: 349.8071, Accuracy: 0.5514\n","Training loss (for one batch) at step 100: 359.3401, Accuracy: 0.5496\n","Training loss (for one batch) at step 110: 357.3227, Accuracy: 0.5471\n","Training loss (for one batch) at step 120: 367.5251, Accuracy: 0.5491\n","Training loss (for one batch) at step 130: 351.0769, Accuracy: 0.5480\n","Training loss (for one batch) at step 140: 362.3624, Accuracy: 0.5483\n","---- Training ----\n","Training loss: 308.8912\n","Training acc over epoch: 0.5498\n","---- Validation ----\n","Validation loss: 76.7388\n","Validation acc: 0.6185\n","Time taken: 9.65s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 349.6329, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 357.0898, Accuracy: 0.5564\n","Training loss (for one batch) at step 20: 353.3044, Accuracy: 0.5519\n","Training loss (for one batch) at step 30: 349.8768, Accuracy: 0.5568\n","Training loss (for one batch) at step 40: 358.7310, Accuracy: 0.5646\n","Training loss (for one batch) at step 50: 352.4976, Accuracy: 0.5625\n","Training loss (for one batch) at step 60: 350.1390, Accuracy: 0.5644\n","Training loss (for one batch) at step 70: 350.9434, Accuracy: 0.5666\n","Training loss (for one batch) at step 80: 351.7062, Accuracy: 0.5637\n","Training loss (for one batch) at step 90: 351.3953, Accuracy: 0.5632\n","Training loss (for one batch) at step 100: 352.0447, Accuracy: 0.5649\n","Training loss (for one batch) at step 110: 347.8573, Accuracy: 0.5637\n","Training loss (for one batch) at step 120: 351.7641, Accuracy: 0.5625\n","Training loss (for one batch) at step 130: 351.2604, Accuracy: 0.5612\n","Training loss (for one batch) at step 140: 346.6655, Accuracy: 0.5616\n","---- Training ----\n","Training loss: 310.6417\n","Training acc over epoch: 0.5629\n","---- Validation ----\n","Validation loss: 76.2263\n","Validation acc: 0.6231\n","Time taken: 9.72s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 359.6377, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 351.1233, Accuracy: 0.5727\n","Training loss (for one batch) at step 20: 350.1790, Accuracy: 0.5800\n","Training loss (for one batch) at step 30: 347.8394, Accuracy: 0.5768\n","Training loss (for one batch) at step 40: 354.1466, Accuracy: 0.5737\n","Training loss (for one batch) at step 50: 343.9311, Accuracy: 0.5775\n","Training loss (for one batch) at step 60: 359.5822, Accuracy: 0.5807\n","Training loss (for one batch) at step 70: 348.0392, Accuracy: 0.5815\n","Training loss (for one batch) at step 80: 348.6127, Accuracy: 0.5821\n","Training loss (for one batch) at step 90: 346.5273, Accuracy: 0.5779\n","Training loss (for one batch) at step 100: 351.2296, Accuracy: 0.5760\n","Training loss (for one batch) at step 110: 349.1321, Accuracy: 0.5751\n","Training loss (for one batch) at step 120: 344.1656, Accuracy: 0.5752\n","Training loss (for one batch) at step 130: 347.4065, Accuracy: 0.5769\n","Training loss (for one batch) at step 140: 352.2326, Accuracy: 0.5789\n","---- Training ----\n","Training loss: 308.3513\n","Training acc over epoch: 0.5778\n","---- Validation ----\n","Validation loss: 76.1825\n","Validation acc: 0.6222\n","Time taken: 9.70s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 350.2764, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 347.6138, Accuracy: 0.5891\n","Training loss (for one batch) at step 20: 347.7224, Accuracy: 0.6014\n","Training loss (for one batch) at step 30: 348.8408, Accuracy: 0.5952\n","Training loss (for one batch) at step 40: 349.0349, Accuracy: 0.5961\n","Training loss (for one batch) at step 50: 352.3472, Accuracy: 0.5924\n","Training loss (for one batch) at step 60: 349.7650, Accuracy: 0.5910\n","Training loss (for one batch) at step 70: 345.1662, Accuracy: 0.5887\n","Training loss (for one batch) at step 80: 346.8498, Accuracy: 0.5888\n","Training loss (for one batch) at step 90: 349.9258, Accuracy: 0.5897\n","Training loss (for one batch) at step 100: 353.6127, Accuracy: 0.5926\n","Training loss (for one batch) at step 110: 345.9385, Accuracy: 0.5940\n","Training loss (for one batch) at step 120: 347.4838, Accuracy: 0.5932\n","Training loss (for one batch) at step 130: 351.5509, Accuracy: 0.5934\n","Training loss (for one batch) at step 140: 343.8581, Accuracy: 0.5935\n","---- Training ----\n","Training loss: 306.4250\n","Training acc over epoch: 0.5948\n","---- Validation ----\n","Validation loss: 75.6480\n","Validation acc: 0.6429\n","Time taken: 9.66s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 345.4512, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 344.0757, Accuracy: 0.6000\n","Training loss (for one batch) at step 20: 346.0732, Accuracy: 0.5819\n","Training loss (for one batch) at step 30: 344.8091, Accuracy: 0.5861\n","Training loss (for one batch) at step 40: 345.9366, Accuracy: 0.5839\n","Training loss (for one batch) at step 50: 346.0433, Accuracy: 0.5855\n","Training loss (for one batch) at step 60: 346.4501, Accuracy: 0.5923\n","Training loss (for one batch) at step 70: 344.1448, Accuracy: 0.5959\n","Training loss (for one batch) at step 80: 345.3197, Accuracy: 0.5998\n","Training loss (for one batch) at step 90: 345.5408, Accuracy: 0.6025\n","Training loss (for one batch) at step 100: 347.8946, Accuracy: 0.6027\n","Training loss (for one batch) at step 110: 347.2793, Accuracy: 0.6031\n","Training loss (for one batch) at step 120: 346.4197, Accuracy: 0.6045\n","Training loss (for one batch) at step 130: 345.1172, Accuracy: 0.6054\n","Training loss (for one batch) at step 140: 343.5271, Accuracy: 0.6043\n","---- Training ----\n","Training loss: 304.4172\n","Training acc over epoch: 0.6059\n","---- Validation ----\n","Validation loss: 75.7273\n","Validation acc: 0.6593\n","Time taken: 9.53s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 343.6817, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 346.9161, Accuracy: 0.6518\n","Training loss (for one batch) at step 20: 341.5611, Accuracy: 0.6319\n","Training loss (for one batch) at step 30: 343.5939, Accuracy: 0.6287\n","Training loss (for one batch) at step 40: 345.2100, Accuracy: 0.6200\n","Training loss (for one batch) at step 50: 343.9133, Accuracy: 0.6173\n","Training loss (for one batch) at step 60: 345.4050, Accuracy: 0.6230\n","Training loss (for one batch) at step 70: 340.2366, Accuracy: 0.6268\n","Training loss (for one batch) at step 80: 346.1982, Accuracy: 0.6272\n","Training loss (for one batch) at step 90: 340.8029, Accuracy: 0.6266\n","Training loss (for one batch) at step 100: 342.5371, Accuracy: 0.6261\n","Training loss (for one batch) at step 110: 346.8633, Accuracy: 0.6247\n","Training loss (for one batch) at step 120: 343.8900, Accuracy: 0.6239\n","Training loss (for one batch) at step 130: 348.2163, Accuracy: 0.6224\n","Training loss (for one batch) at step 140: 343.9730, Accuracy: 0.6243\n","---- Training ----\n","Training loss: 301.4749\n","Training acc over epoch: 0.6241\n","---- Validation ----\n","Validation loss: 75.7764\n","Validation acc: 0.6749\n","Time taken: 9.64s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 342.5825, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 342.7008, Accuracy: 0.6291\n","Training loss (for one batch) at step 20: 343.3750, Accuracy: 0.6224\n","Training loss (for one batch) at step 30: 340.5861, Accuracy: 0.6297\n","Training loss (for one batch) at step 40: 339.0328, Accuracy: 0.6322\n","Training loss (for one batch) at step 50: 343.0742, Accuracy: 0.6345\n","Training loss (for one batch) at step 60: 343.8834, Accuracy: 0.6351\n","Training loss (for one batch) at step 70: 342.2109, Accuracy: 0.6379\n","Training loss (for one batch) at step 80: 339.2165, Accuracy: 0.6358\n","Training loss (for one batch) at step 90: 342.9665, Accuracy: 0.6385\n","Training loss (for one batch) at step 100: 343.3571, Accuracy: 0.6383\n","Training loss (for one batch) at step 110: 340.5274, Accuracy: 0.6354\n","Training loss (for one batch) at step 120: 346.9635, Accuracy: 0.6358\n","Training loss (for one batch) at step 130: 343.3065, Accuracy: 0.6364\n","Training loss (for one batch) at step 140: 341.2702, Accuracy: 0.6368\n","---- Training ----\n","Training loss: 301.2366\n","Training acc over epoch: 0.6363\n","---- Validation ----\n","Validation loss: 75.2857\n","Validation acc: 0.6693\n","Time taken: 9.60s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 344.5245, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 340.1654, Accuracy: 0.6427\n","Training loss (for one batch) at step 20: 339.3102, Accuracy: 0.6362\n","Training loss (for one batch) at step 30: 338.9474, Accuracy: 0.6403\n","Training loss (for one batch) at step 40: 338.2640, Accuracy: 0.6424\n","Training loss (for one batch) at step 50: 350.1130, Accuracy: 0.6443\n","Training loss (for one batch) at step 60: 339.5312, Accuracy: 0.6497\n","Training loss (for one batch) at step 70: 350.5818, Accuracy: 0.6538\n","Training loss (for one batch) at step 80: 341.0292, Accuracy: 0.6548\n","Training loss (for one batch) at step 90: 337.7502, Accuracy: 0.6547\n","Training loss (for one batch) at step 100: 342.3028, Accuracy: 0.6534\n","Training loss (for one batch) at step 110: 347.9434, Accuracy: 0.6496\n","Training loss (for one batch) at step 120: 339.9866, Accuracy: 0.6492\n","Training loss (for one batch) at step 130: 342.5222, Accuracy: 0.6492\n","Training loss (for one batch) at step 140: 340.4603, Accuracy: 0.6509\n","---- Training ----\n","Training loss: 303.0425\n","Training acc over epoch: 0.6511\n","---- Validation ----\n","Validation loss: 76.7335\n","Validation acc: 0.6870\n","Time taken: 9.61s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 345.9911, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 343.8575, Accuracy: 0.6282\n","Training loss (for one batch) at step 20: 339.3272, Accuracy: 0.6438\n","Training loss (for one batch) at step 30: 338.8125, Accuracy: 0.6494\n","Training loss (for one batch) at step 40: 335.2338, Accuracy: 0.6544\n","Training loss (for one batch) at step 50: 336.8933, Accuracy: 0.6547\n","Training loss (for one batch) at step 60: 333.0631, Accuracy: 0.6582\n","Training loss (for one batch) at step 70: 344.3884, Accuracy: 0.6610\n","Training loss (for one batch) at step 80: 342.7010, Accuracy: 0.6611\n","Training loss (for one batch) at step 90: 344.7547, Accuracy: 0.6584\n","Training loss (for one batch) at step 100: 342.1105, Accuracy: 0.6545\n","Training loss (for one batch) at step 110: 340.1722, Accuracy: 0.6527\n","Training loss (for one batch) at step 120: 339.7750, Accuracy: 0.6525\n","Training loss (for one batch) at step 130: 342.6802, Accuracy: 0.6533\n","Training loss (for one batch) at step 140: 342.1164, Accuracy: 0.6553\n","---- Training ----\n","Training loss: 297.8549\n","Training acc over epoch: 0.6564\n","---- Validation ----\n","Validation loss: 77.5258\n","Validation acc: 0.6975\n","Time taken: 9.61s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 336.5000, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 337.0208, Accuracy: 0.6545\n","Training loss (for one batch) at step 20: 342.5676, Accuracy: 0.6500\n","Training loss (for one batch) at step 30: 336.4825, Accuracy: 0.6445\n","Training loss (for one batch) at step 40: 335.8274, Accuracy: 0.6473\n","Training loss (for one batch) at step 50: 338.1993, Accuracy: 0.6535\n","Training loss (for one batch) at step 60: 341.3071, Accuracy: 0.6611\n","Training loss (for one batch) at step 70: 342.2939, Accuracy: 0.6639\n","Training loss (for one batch) at step 80: 343.3073, Accuracy: 0.6631\n","Training loss (for one batch) at step 90: 340.2755, Accuracy: 0.6636\n","Training loss (for one batch) at step 100: 339.5547, Accuracy: 0.6609\n","Training loss (for one batch) at step 110: 342.0144, Accuracy: 0.6600\n","Training loss (for one batch) at step 120: 340.9376, Accuracy: 0.6598\n","Training loss (for one batch) at step 130: 337.2637, Accuracy: 0.6621\n","Training loss (for one batch) at step 140: 338.6278, Accuracy: 0.6626\n","---- Training ----\n","Training loss: 298.5871\n","Training acc over epoch: 0.6625\n","---- Validation ----\n","Validation loss: 76.9532\n","Validation acc: 0.6776\n","Time taken: 9.82s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 343.3006, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 339.9764, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 343.8738, Accuracy: 0.6562\n","Training loss (for one batch) at step 30: 335.1943, Accuracy: 0.6600\n","Training loss (for one batch) at step 40: 340.6293, Accuracy: 0.6685\n","Training loss (for one batch) at step 50: 334.6995, Accuracy: 0.6733\n","Training loss (for one batch) at step 60: 329.0001, Accuracy: 0.6759\n","Training loss (for one batch) at step 70: 330.3723, Accuracy: 0.6780\n","Training loss (for one batch) at step 80: 342.5876, Accuracy: 0.6781\n","Training loss (for one batch) at step 90: 338.6005, Accuracy: 0.6824\n","Training loss (for one batch) at step 100: 343.4738, Accuracy: 0.6790\n","Training loss (for one batch) at step 110: 336.3036, Accuracy: 0.6777\n","Training loss (for one batch) at step 120: 333.8550, Accuracy: 0.6777\n","Training loss (for one batch) at step 130: 337.4234, Accuracy: 0.6792\n","Training loss (for one batch) at step 140: 336.1509, Accuracy: 0.6809\n","---- Training ----\n","Training loss: 297.9182\n","Training acc over epoch: 0.6789\n","---- Validation ----\n","Validation loss: 74.7509\n","Validation acc: 0.6983\n","Time taken: 9.65s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 337.3459, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 335.8232, Accuracy: 0.6545\n","Training loss (for one batch) at step 20: 338.7401, Accuracy: 0.6571\n","Training loss (for one batch) at step 30: 339.2161, Accuracy: 0.6677\n","Training loss (for one batch) at step 40: 329.4169, Accuracy: 0.6698\n","Training loss (for one batch) at step 50: 330.9081, Accuracy: 0.6755\n","Training loss (for one batch) at step 60: 328.2085, Accuracy: 0.6828\n","Training loss (for one batch) at step 70: 327.1870, Accuracy: 0.6858\n","Training loss (for one batch) at step 80: 335.5171, Accuracy: 0.6844\n","Training loss (for one batch) at step 90: 337.7435, Accuracy: 0.6822\n","Training loss (for one batch) at step 100: 335.0672, Accuracy: 0.6813\n","Training loss (for one batch) at step 110: 329.5330, Accuracy: 0.6780\n","Training loss (for one batch) at step 120: 330.4518, Accuracy: 0.6770\n","Training loss (for one batch) at step 130: 329.2235, Accuracy: 0.6790\n","Training loss (for one batch) at step 140: 337.5078, Accuracy: 0.6781\n","---- Training ----\n","Training loss: 296.5766\n","Training acc over epoch: 0.6793\n","---- Validation ----\n","Validation loss: 76.4735\n","Validation acc: 0.6953\n","Time taken: 9.76s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 340.2445, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 335.2285, Accuracy: 0.6618\n","Training loss (for one batch) at step 20: 340.5253, Accuracy: 0.6657\n","Training loss (for one batch) at step 30: 338.4024, Accuracy: 0.6697\n","Training loss (for one batch) at step 40: 334.9221, Accuracy: 0.6737\n","Training loss (for one batch) at step 50: 334.1323, Accuracy: 0.6806\n","Training loss (for one batch) at step 60: 327.2607, Accuracy: 0.6856\n","Training loss (for one batch) at step 70: 325.8607, Accuracy: 0.6913\n","Training loss (for one batch) at step 80: 333.0872, Accuracy: 0.6907\n","Training loss (for one batch) at step 90: 335.9493, Accuracy: 0.6877\n","Training loss (for one batch) at step 100: 342.6632, Accuracy: 0.6810\n","Training loss (for one batch) at step 110: 331.6581, Accuracy: 0.6773\n","Training loss (for one batch) at step 120: 327.6046, Accuracy: 0.6771\n","Training loss (for one batch) at step 130: 334.2244, Accuracy: 0.6782\n","Training loss (for one batch) at step 140: 332.5910, Accuracy: 0.6789\n","---- Training ----\n","Training loss: 297.0721\n","Training acc over epoch: 0.6784\n","---- Validation ----\n","Validation loss: 76.0266\n","Validation acc: 0.6870\n","Time taken: 10.43s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 336.5385, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 339.6277, Accuracy: 0.6845\n","Training loss (for one batch) at step 20: 344.4875, Accuracy: 0.6771\n","Training loss (for one batch) at step 30: 331.8597, Accuracy: 0.6726\n","Training loss (for one batch) at step 40: 331.1091, Accuracy: 0.6778\n","Training loss (for one batch) at step 50: 330.5565, Accuracy: 0.6853\n","Training loss (for one batch) at step 60: 328.1995, Accuracy: 0.6892\n","Training loss (for one batch) at step 70: 328.2214, Accuracy: 0.6924\n","Training loss (for one batch) at step 80: 343.2753, Accuracy: 0.6940\n","Training loss (for one batch) at step 90: 337.6961, Accuracy: 0.6916\n","Training loss (for one batch) at step 100: 332.1317, Accuracy: 0.6886\n","Training loss (for one batch) at step 110: 329.9664, Accuracy: 0.6867\n","Training loss (for one batch) at step 120: 335.4919, Accuracy: 0.6864\n","Training loss (for one batch) at step 130: 325.2051, Accuracy: 0.6875\n","Training loss (for one batch) at step 140: 335.7448, Accuracy: 0.6874\n","---- Training ----\n","Training loss: 292.3119\n","Training acc over epoch: 0.6873\n","---- Validation ----\n","Validation loss: 76.8450\n","Validation acc: 0.7015\n","Time taken: 9.66s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 331.8716, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 335.6759, Accuracy: 0.6745\n","Training loss (for one batch) at step 20: 333.7672, Accuracy: 0.6752\n","Training loss (for one batch) at step 30: 327.2564, Accuracy: 0.6845\n","Training loss (for one batch) at step 40: 331.2852, Accuracy: 0.6878\n","Training loss (for one batch) at step 50: 334.1715, Accuracy: 0.6896\n","Training loss (for one batch) at step 60: 322.4476, Accuracy: 0.6959\n","Training loss (for one batch) at step 70: 335.6224, Accuracy: 0.7013\n","Training loss (for one batch) at step 80: 332.1870, Accuracy: 0.7005\n","Training loss (for one batch) at step 90: 330.8281, Accuracy: 0.6985\n","Training loss (for one batch) at step 100: 328.3530, Accuracy: 0.6960\n","Training loss (for one batch) at step 110: 333.7708, Accuracy: 0.6932\n","Training loss (for one batch) at step 120: 324.9373, Accuracy: 0.6914\n","Training loss (for one batch) at step 130: 324.9254, Accuracy: 0.6926\n","Training loss (for one batch) at step 140: 337.8064, Accuracy: 0.6926\n","---- Training ----\n","Training loss: 293.0650\n","Training acc over epoch: 0.6931\n","---- Validation ----\n","Validation loss: 79.9915\n","Validation acc: 0.6961\n","Time taken: 9.68s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 335.7461, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 333.6175, Accuracy: 0.6855\n","Training loss (for one batch) at step 20: 335.8966, Accuracy: 0.6881\n","Training loss (for one batch) at step 30: 330.0791, Accuracy: 0.6929\n","Training loss (for one batch) at step 40: 329.9315, Accuracy: 0.6951\n","Training loss (for one batch) at step 50: 328.5675, Accuracy: 0.7008\n","Training loss (for one batch) at step 60: 330.6750, Accuracy: 0.7056\n","Training loss (for one batch) at step 70: 326.4714, Accuracy: 0.7070\n","Training loss (for one batch) at step 80: 336.0193, Accuracy: 0.7069\n","Training loss (for one batch) at step 90: 334.7787, Accuracy: 0.7033\n","Training loss (for one batch) at step 100: 329.6572, Accuracy: 0.6972\n","Training loss (for one batch) at step 110: 323.9380, Accuracy: 0.6972\n","Training loss (for one batch) at step 120: 321.2814, Accuracy: 0.6962\n","Training loss (for one batch) at step 130: 326.5622, Accuracy: 0.6982\n","Training loss (for one batch) at step 140: 329.0175, Accuracy: 0.6994\n","---- Training ----\n","Training loss: 295.3267\n","Training acc over epoch: 0.6980\n","---- Validation ----\n","Validation loss: 78.0087\n","Validation acc: 0.7042\n","Time taken: 9.79s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 339.0046, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 337.0613, Accuracy: 0.6864\n","Training loss (for one batch) at step 20: 324.6570, Accuracy: 0.6890\n","Training loss (for one batch) at step 30: 318.7884, Accuracy: 0.6961\n","Training loss (for one batch) at step 40: 324.4537, Accuracy: 0.7002\n","Training loss (for one batch) at step 50: 322.7085, Accuracy: 0.7075\n","Training loss (for one batch) at step 60: 328.2454, Accuracy: 0.7128\n","Training loss (for one batch) at step 70: 323.2674, Accuracy: 0.7162\n","Training loss (for one batch) at step 80: 331.3745, Accuracy: 0.7133\n","Training loss (for one batch) at step 90: 336.6944, Accuracy: 0.7116\n","Training loss (for one batch) at step 100: 327.0356, Accuracy: 0.7068\n","Training loss (for one batch) at step 110: 329.9790, Accuracy: 0.7029\n","Training loss (for one batch) at step 120: 325.9254, Accuracy: 0.7031\n","Training loss (for one batch) at step 130: 325.9523, Accuracy: 0.7033\n","Training loss (for one batch) at step 140: 331.7776, Accuracy: 0.7038\n","---- Training ----\n","Training loss: 297.0934\n","Training acc over epoch: 0.7039\n","---- Validation ----\n","Validation loss: 82.7555\n","Validation acc: 0.6945\n","Time taken: 9.65s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 340.6365, Accuracy: 0.5600\n","Training loss (for one batch) at step 10: 337.5824, Accuracy: 0.6764\n","Training loss (for one batch) at step 20: 330.6882, Accuracy: 0.6910\n","Training loss (for one batch) at step 30: 323.4445, Accuracy: 0.7003\n","Training loss (for one batch) at step 40: 327.7936, Accuracy: 0.7068\n","Training loss (for one batch) at step 50: 321.0234, Accuracy: 0.7129\n","Training loss (for one batch) at step 60: 327.9679, Accuracy: 0.7166\n","Training loss (for one batch) at step 70: 324.7143, Accuracy: 0.7213\n","Training loss (for one batch) at step 80: 331.3925, Accuracy: 0.7191\n","Training loss (for one batch) at step 90: 329.6987, Accuracy: 0.7136\n","Training loss (for one batch) at step 100: 327.1039, Accuracy: 0.7094\n","Training loss (for one batch) at step 110: 315.1140, Accuracy: 0.7050\n","Training loss (for one batch) at step 120: 321.1668, Accuracy: 0.7037\n","Training loss (for one batch) at step 130: 329.5068, Accuracy: 0.7040\n","Training loss (for one batch) at step 140: 328.7869, Accuracy: 0.7057\n","---- Training ----\n","Training loss: 292.1589\n","Training acc over epoch: 0.7047\n","---- Validation ----\n","Validation loss: 79.2394\n","Validation acc: 0.7010\n","Time taken: 9.62s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 326.9188, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 329.5401, Accuracy: 0.6809\n","Training loss (for one batch) at step 20: 322.5980, Accuracy: 0.6833\n","Training loss (for one batch) at step 30: 327.0463, Accuracy: 0.6906\n","Training loss (for one batch) at step 40: 325.5456, Accuracy: 0.7046\n","Training loss (for one batch) at step 50: 324.1714, Accuracy: 0.7080\n","Training loss (for one batch) at step 60: 318.1476, Accuracy: 0.7113\n","Training loss (for one batch) at step 70: 312.2018, Accuracy: 0.7158\n","Training loss (for one batch) at step 80: 326.2107, Accuracy: 0.7163\n","Training loss (for one batch) at step 90: 332.3032, Accuracy: 0.7140\n","Training loss (for one batch) at step 100: 328.4635, Accuracy: 0.7121\n","Training loss (for one batch) at step 110: 336.8629, Accuracy: 0.7081\n","Training loss (for one batch) at step 120: 325.8008, Accuracy: 0.7068\n","Training loss (for one batch) at step 130: 320.3672, Accuracy: 0.7079\n","Training loss (for one batch) at step 140: 317.2897, Accuracy: 0.7080\n","---- Training ----\n","Training loss: 276.6018\n","Training acc over epoch: 0.7076\n","---- Validation ----\n","Validation loss: 75.9965\n","Validation acc: 0.7066\n","Time taken: 9.81s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 346.8756, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 339.2490, Accuracy: 0.6845\n","Training loss (for one batch) at step 20: 326.3598, Accuracy: 0.6933\n","Training loss (for one batch) at step 30: 319.5313, Accuracy: 0.7029\n","Training loss (for one batch) at step 40: 314.0620, Accuracy: 0.7080\n","Training loss (for one batch) at step 50: 310.5415, Accuracy: 0.7114\n","Training loss (for one batch) at step 60: 313.1785, Accuracy: 0.7195\n","Training loss (for one batch) at step 70: 324.0720, Accuracy: 0.7218\n","Training loss (for one batch) at step 80: 326.9875, Accuracy: 0.7246\n","Training loss (for one batch) at step 90: 328.2428, Accuracy: 0.7204\n","Training loss (for one batch) at step 100: 333.1718, Accuracy: 0.7150\n","Training loss (for one batch) at step 110: 310.4831, Accuracy: 0.7115\n","Training loss (for one batch) at step 120: 320.3502, Accuracy: 0.7110\n","Training loss (for one batch) at step 130: 331.1180, Accuracy: 0.7132\n","Training loss (for one batch) at step 140: 335.0942, Accuracy: 0.7120\n","---- Training ----\n","Training loss: 279.9496\n","Training acc over epoch: 0.7114\n","---- Validation ----\n","Validation loss: 78.4417\n","Validation acc: 0.7144\n","Time taken: 11.10s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 324.1496, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 327.7921, Accuracy: 0.6800\n","Training loss (for one batch) at step 20: 329.2180, Accuracy: 0.6810\n","Training loss (for one batch) at step 30: 323.2153, Accuracy: 0.7016\n","Training loss (for one batch) at step 40: 310.3657, Accuracy: 0.6983\n","Training loss (for one batch) at step 50: 319.3607, Accuracy: 0.7106\n","Training loss (for one batch) at step 60: 311.0024, Accuracy: 0.7159\n","Training loss (for one batch) at step 70: 310.1748, Accuracy: 0.7227\n","Training loss (for one batch) at step 80: 326.1435, Accuracy: 0.7225\n","Training loss (for one batch) at step 90: 329.9315, Accuracy: 0.7190\n","Training loss (for one batch) at step 100: 326.9598, Accuracy: 0.7148\n","Training loss (for one batch) at step 110: 317.0193, Accuracy: 0.7104\n","Training loss (for one batch) at step 120: 316.7373, Accuracy: 0.7119\n","Training loss (for one batch) at step 130: 313.8978, Accuracy: 0.7131\n","Training loss (for one batch) at step 140: 325.3618, Accuracy: 0.7121\n","---- Training ----\n","Training loss: 279.4727\n","Training acc over epoch: 0.7116\n","---- Validation ----\n","Validation loss: 79.7179\n","Validation acc: 0.6910\n","Time taken: 9.66s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 326.7227, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 328.9565, Accuracy: 0.6800\n","Training loss (for one batch) at step 20: 317.1661, Accuracy: 0.6819\n","Training loss (for one batch) at step 30: 302.6041, Accuracy: 0.7045\n","Training loss (for one batch) at step 40: 311.3993, Accuracy: 0.7090\n","Training loss (for one batch) at step 50: 313.6668, Accuracy: 0.7188\n","Training loss (for one batch) at step 60: 310.7139, Accuracy: 0.7246\n","Training loss (for one batch) at step 70: 307.3625, Accuracy: 0.7262\n","Training loss (for one batch) at step 80: 322.6222, Accuracy: 0.7275\n","Training loss (for one batch) at step 90: 326.3747, Accuracy: 0.7244\n","Training loss (for one batch) at step 100: 326.6000, Accuracy: 0.7189\n","Training loss (for one batch) at step 110: 317.7612, Accuracy: 0.7141\n","Training loss (for one batch) at step 120: 313.3233, Accuracy: 0.7131\n","Training loss (for one batch) at step 130: 314.3927, Accuracy: 0.7141\n","Training loss (for one batch) at step 140: 321.2132, Accuracy: 0.7146\n","---- Training ----\n","Training loss: 282.4019\n","Training acc over epoch: 0.7140\n","---- Validation ----\n","Validation loss: 77.7810\n","Validation acc: 0.7063\n","Time taken: 9.91s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 317.3088, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 328.6291, Accuracy: 0.7036\n","Training loss (for one batch) at step 20: 312.3439, Accuracy: 0.7062\n","Training loss (for one batch) at step 30: 312.7794, Accuracy: 0.7129\n","Training loss (for one batch) at step 40: 313.2040, Accuracy: 0.7151\n","Training loss (for one batch) at step 50: 307.5544, Accuracy: 0.7265\n","Training loss (for one batch) at step 60: 307.1649, Accuracy: 0.7336\n","Training loss (for one batch) at step 70: 306.4679, Accuracy: 0.7399\n","Training loss (for one batch) at step 80: 313.6081, Accuracy: 0.7398\n","Training loss (for one batch) at step 90: 322.8666, Accuracy: 0.7313\n","Training loss (for one batch) at step 100: 323.3207, Accuracy: 0.7249\n","Training loss (for one batch) at step 110: 312.7086, Accuracy: 0.7203\n","Training loss (for one batch) at step 120: 316.0294, Accuracy: 0.7206\n","Training loss (for one batch) at step 130: 322.2324, Accuracy: 0.7207\n","Training loss (for one batch) at step 140: 315.5927, Accuracy: 0.7213\n","---- Training ----\n","Training loss: 275.0423\n","Training acc over epoch: 0.7193\n","---- Validation ----\n","Validation loss: 75.4498\n","Validation acc: 0.6956\n","Time taken: 9.57s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 322.1302, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 327.9487, Accuracy: 0.6800\n","Training loss (for one batch) at step 20: 319.2336, Accuracy: 0.6910\n","Training loss (for one batch) at step 30: 314.0223, Accuracy: 0.7097\n","Training loss (for one batch) at step 40: 306.6329, Accuracy: 0.7251\n","Training loss (for one batch) at step 50: 299.2606, Accuracy: 0.7273\n","Training loss (for one batch) at step 60: 297.8678, Accuracy: 0.7325\n","Training loss (for one batch) at step 70: 302.3099, Accuracy: 0.7387\n","Training loss (for one batch) at step 80: 312.1834, Accuracy: 0.7390\n","Training loss (for one batch) at step 90: 317.6284, Accuracy: 0.7353\n","Training loss (for one batch) at step 100: 320.6977, Accuracy: 0.7307\n","Training loss (for one batch) at step 110: 321.8607, Accuracy: 0.7262\n","Training loss (for one batch) at step 120: 322.9128, Accuracy: 0.7267\n","Training loss (for one batch) at step 130: 313.3012, Accuracy: 0.7270\n","Training loss (for one batch) at step 140: 305.1837, Accuracy: 0.7262\n","---- Training ----\n","Training loss: 281.5849\n","Training acc over epoch: 0.7258\n","---- Validation ----\n","Validation loss: 81.2450\n","Validation acc: 0.6967\n","Time taken: 9.55s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 336.4195, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 323.7161, Accuracy: 0.6809\n","Training loss (for one batch) at step 20: 320.0193, Accuracy: 0.6905\n","Training loss (for one batch) at step 30: 307.6790, Accuracy: 0.7032\n","Training loss (for one batch) at step 40: 305.1900, Accuracy: 0.7141\n","Training loss (for one batch) at step 50: 316.2448, Accuracy: 0.7204\n","Training loss (for one batch) at step 60: 301.9493, Accuracy: 0.7280\n","Training loss (for one batch) at step 70: 293.7112, Accuracy: 0.7334\n","Training loss (for one batch) at step 80: 303.4993, Accuracy: 0.7304\n","Training loss (for one batch) at step 90: 314.3081, Accuracy: 0.7290\n","Training loss (for one batch) at step 100: 314.0414, Accuracy: 0.7230\n","Training loss (for one batch) at step 110: 315.0287, Accuracy: 0.7193\n","Training loss (for one batch) at step 120: 321.1796, Accuracy: 0.7186\n","Training loss (for one batch) at step 130: 312.3376, Accuracy: 0.7213\n","Training loss (for one batch) at step 140: 312.3969, Accuracy: 0.7215\n","---- Training ----\n","Training loss: 269.6374\n","Training acc over epoch: 0.7200\n","---- Validation ----\n","Validation loss: 74.6108\n","Validation acc: 0.6875\n","Time taken: 9.61s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 333.8911, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 310.8610, Accuracy: 0.6891\n","Training loss (for one batch) at step 20: 311.2222, Accuracy: 0.7033\n","Training loss (for one batch) at step 30: 317.7449, Accuracy: 0.7081\n","Training loss (for one batch) at step 40: 311.2204, Accuracy: 0.7215\n","Training loss (for one batch) at step 50: 302.8874, Accuracy: 0.7255\n","Training loss (for one batch) at step 60: 291.7988, Accuracy: 0.7341\n","Training loss (for one batch) at step 70: 303.5904, Accuracy: 0.7414\n","Training loss (for one batch) at step 80: 309.1273, Accuracy: 0.7405\n","Training loss (for one batch) at step 90: 304.2948, Accuracy: 0.7354\n","Training loss (for one batch) at step 100: 315.9543, Accuracy: 0.7330\n","Training loss (for one batch) at step 110: 314.0571, Accuracy: 0.7275\n","Training loss (for one batch) at step 120: 302.6620, Accuracy: 0.7278\n","Training loss (for one batch) at step 130: 299.4953, Accuracy: 0.7279\n","Training loss (for one batch) at step 140: 302.6844, Accuracy: 0.7275\n","---- Training ----\n","Training loss: 261.2318\n","Training acc over epoch: 0.7263\n","---- Validation ----\n","Validation loss: 82.7223\n","Validation acc: 0.7069\n","Time taken: 9.73s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 325.2121, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 315.6781, Accuracy: 0.7000\n","Training loss (for one batch) at step 20: 321.2003, Accuracy: 0.6962\n","Training loss (for one batch) at step 30: 305.3134, Accuracy: 0.7071\n","Training loss (for one batch) at step 40: 316.0564, Accuracy: 0.7210\n","Training loss (for one batch) at step 50: 293.2471, Accuracy: 0.7318\n","Training loss (for one batch) at step 60: 299.0479, Accuracy: 0.7393\n","Training loss (for one batch) at step 70: 301.2708, Accuracy: 0.7446\n","Training loss (for one batch) at step 80: 313.6841, Accuracy: 0.7419\n","Training loss (for one batch) at step 90: 318.9023, Accuracy: 0.7362\n","Training loss (for one batch) at step 100: 321.1102, Accuracy: 0.7284\n","Training loss (for one batch) at step 110: 306.0920, Accuracy: 0.7243\n","Training loss (for one batch) at step 120: 313.8559, Accuracy: 0.7228\n","Training loss (for one batch) at step 130: 292.7762, Accuracy: 0.7275\n","Training loss (for one batch) at step 140: 315.6943, Accuracy: 0.7259\n","---- Training ----\n","Training loss: 266.9072\n","Training acc over epoch: 0.7258\n","---- Validation ----\n","Validation loss: 80.9578\n","Validation acc: 0.6967\n","Time taken: 9.55s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 321.5157, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 317.0723, Accuracy: 0.6909\n","Training loss (for one batch) at step 20: 298.5692, Accuracy: 0.7010\n","Training loss (for one batch) at step 30: 312.7942, Accuracy: 0.7065\n","Training loss (for one batch) at step 40: 299.0975, Accuracy: 0.7224\n","Training loss (for one batch) at step 50: 303.1450, Accuracy: 0.7322\n","Training loss (for one batch) at step 60: 296.8253, Accuracy: 0.7389\n","Training loss (for one batch) at step 70: 297.4636, Accuracy: 0.7454\n","Training loss (for one batch) at step 80: 300.5409, Accuracy: 0.7457\n","Training loss (for one batch) at step 90: 332.6647, Accuracy: 0.7408\n","Training loss (for one batch) at step 100: 314.4654, Accuracy: 0.7331\n","Training loss (for one batch) at step 110: 316.2971, Accuracy: 0.7293\n","Training loss (for one batch) at step 120: 317.6087, Accuracy: 0.7295\n","Training loss (for one batch) at step 130: 303.9879, Accuracy: 0.7310\n","Training loss (for one batch) at step 140: 305.8511, Accuracy: 0.7311\n","---- Training ----\n","Training loss: 267.8020\n","Training acc over epoch: 0.7306\n","---- Validation ----\n","Validation loss: 78.1905\n","Validation acc: 0.7082\n","Time taken: 13.54s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 330.7257, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 310.3091, Accuracy: 0.7127\n","Training loss (for one batch) at step 20: 315.6647, Accuracy: 0.7152\n","Training loss (for one batch) at step 30: 298.3989, Accuracy: 0.7190\n","Training loss (for one batch) at step 40: 287.3825, Accuracy: 0.7307\n","Training loss (for one batch) at step 50: 303.9119, Accuracy: 0.7400\n","Training loss (for one batch) at step 60: 286.1018, Accuracy: 0.7457\n","Training loss (for one batch) at step 70: 296.3896, Accuracy: 0.7508\n","Training loss (for one batch) at step 80: 294.1561, Accuracy: 0.7512\n","Training loss (for one batch) at step 90: 319.6342, Accuracy: 0.7469\n","Training loss (for one batch) at step 100: 315.4403, Accuracy: 0.7394\n","Training loss (for one batch) at step 110: 305.1206, Accuracy: 0.7354\n","Training loss (for one batch) at step 120: 306.3657, Accuracy: 0.7333\n","Training loss (for one batch) at step 130: 295.9244, Accuracy: 0.7345\n","Training loss (for one batch) at step 140: 295.0602, Accuracy: 0.7357\n","---- Training ----\n","Training loss: 277.4336\n","Training acc over epoch: 0.7343\n","---- Validation ----\n","Validation loss: 82.8391\n","Validation acc: 0.7171\n","Time taken: 14.35s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 326.1141, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 317.4926, Accuracy: 0.6973\n","Training loss (for one batch) at step 20: 299.5471, Accuracy: 0.7048\n","Training loss (for one batch) at step 30: 303.2328, Accuracy: 0.7248\n","Training loss (for one batch) at step 40: 296.0487, Accuracy: 0.7339\n","Training loss (for one batch) at step 50: 287.4433, Accuracy: 0.7424\n","Training loss (for one batch) at step 60: 287.3871, Accuracy: 0.7492\n","Training loss (for one batch) at step 70: 288.7397, Accuracy: 0.7554\n","Training loss (for one batch) at step 80: 307.5977, Accuracy: 0.7525\n","Training loss (for one batch) at step 90: 309.4496, Accuracy: 0.7473\n","Training loss (for one batch) at step 100: 313.4044, Accuracy: 0.7403\n","Training loss (for one batch) at step 110: 310.1357, Accuracy: 0.7349\n","Training loss (for one batch) at step 120: 296.2611, Accuracy: 0.7335\n","Training loss (for one batch) at step 130: 297.3618, Accuracy: 0.7350\n","Training loss (for one batch) at step 140: 298.3326, Accuracy: 0.7341\n","---- Training ----\n","Training loss: 271.2870\n","Training acc over epoch: 0.7328\n","---- Validation ----\n","Validation loss: 85.5490\n","Validation acc: 0.7050\n","Time taken: 9.58s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 314.3871, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 311.1172, Accuracy: 0.6955\n","Training loss (for one batch) at step 20: 313.8579, Accuracy: 0.7110\n","Training loss (for one batch) at step 30: 296.4306, Accuracy: 0.7245\n","Training loss (for one batch) at step 40: 297.4657, Accuracy: 0.7366\n","Training loss (for one batch) at step 50: 281.3863, Accuracy: 0.7408\n","Training loss (for one batch) at step 60: 285.1154, Accuracy: 0.7470\n","Training loss (for one batch) at step 70: 298.5245, Accuracy: 0.7537\n","Training loss (for one batch) at step 80: 305.1596, Accuracy: 0.7516\n","Training loss (for one batch) at step 90: 306.0934, Accuracy: 0.7449\n","Training loss (for one batch) at step 100: 310.4965, Accuracy: 0.7376\n","Training loss (for one batch) at step 110: 304.9777, Accuracy: 0.7333\n","Training loss (for one batch) at step 120: 301.0049, Accuracy: 0.7349\n","Training loss (for one batch) at step 130: 292.1779, Accuracy: 0.7369\n","Training loss (for one batch) at step 140: 293.4846, Accuracy: 0.7387\n","---- Training ----\n","Training loss: 264.8271\n","Training acc over epoch: 0.7373\n","---- Validation ----\n","Validation loss: 92.9194\n","Validation acc: 0.7123\n","Time taken: 9.69s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 312.6930, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 301.5970, Accuracy: 0.7018\n","Training loss (for one batch) at step 20: 299.6602, Accuracy: 0.6967\n","Training loss (for one batch) at step 30: 301.3147, Accuracy: 0.7232\n","Training loss (for one batch) at step 40: 288.6887, Accuracy: 0.7398\n","Training loss (for one batch) at step 50: 287.5788, Accuracy: 0.7443\n","Training loss (for one batch) at step 60: 288.2091, Accuracy: 0.7498\n","Training loss (for one batch) at step 70: 277.5060, Accuracy: 0.7568\n","Training loss (for one batch) at step 80: 301.0090, Accuracy: 0.7581\n","Training loss (for one batch) at step 90: 301.2528, Accuracy: 0.7554\n","Training loss (for one batch) at step 100: 294.4230, Accuracy: 0.7483\n","Training loss (for one batch) at step 110: 301.1283, Accuracy: 0.7423\n","Training loss (for one batch) at step 120: 311.0300, Accuracy: 0.7414\n","Training loss (for one batch) at step 130: 302.8278, Accuracy: 0.7418\n","Training loss (for one batch) at step 140: 295.8415, Accuracy: 0.7419\n","---- Training ----\n","Training loss: 274.4958\n","Training acc over epoch: 0.7410\n","---- Validation ----\n","Validation loss: 87.7072\n","Validation acc: 0.7074\n","Time taken: 9.58s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 313.8142, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 305.6512, Accuracy: 0.6873\n","Training loss (for one batch) at step 20: 311.8010, Accuracy: 0.7014\n","Training loss (for one batch) at step 30: 287.7949, Accuracy: 0.7168\n","Training loss (for one batch) at step 40: 296.5415, Accuracy: 0.7307\n","Training loss (for one batch) at step 50: 287.5751, Accuracy: 0.7408\n","Training loss (for one batch) at step 60: 277.4893, Accuracy: 0.7503\n","Training loss (for one batch) at step 70: 285.0916, Accuracy: 0.7585\n","Training loss (for one batch) at step 80: 304.7996, Accuracy: 0.7562\n","Training loss (for one batch) at step 90: 299.2454, Accuracy: 0.7509\n","Training loss (for one batch) at step 100: 315.5392, Accuracy: 0.7443\n","Training loss (for one batch) at step 110: 290.7032, Accuracy: 0.7371\n","Training loss (for one batch) at step 120: 285.9046, Accuracy: 0.7390\n","Training loss (for one batch) at step 130: 292.1303, Accuracy: 0.7414\n","Training loss (for one batch) at step 140: 318.1091, Accuracy: 0.7389\n","---- Training ----\n","Training loss: 273.3360\n","Training acc over epoch: 0.7372\n","---- Validation ----\n","Validation loss: 83.7352\n","Validation acc: 0.7031\n","Time taken: 9.56s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 314.1015, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 302.4578, Accuracy: 0.7000\n","Training loss (for one batch) at step 20: 296.5087, Accuracy: 0.7119\n","Training loss (for one batch) at step 30: 280.1797, Accuracy: 0.7255\n","Training loss (for one batch) at step 40: 283.7761, Accuracy: 0.7405\n","Training loss (for one batch) at step 50: 286.5193, Accuracy: 0.7498\n","Training loss (for one batch) at step 60: 278.1469, Accuracy: 0.7590\n","Training loss (for one batch) at step 70: 277.2890, Accuracy: 0.7632\n","Training loss (for one batch) at step 80: 285.8363, Accuracy: 0.7601\n","Training loss (for one batch) at step 90: 298.3676, Accuracy: 0.7565\n","Training loss (for one batch) at step 100: 304.5762, Accuracy: 0.7484\n","Training loss (for one batch) at step 110: 309.2897, Accuracy: 0.7441\n","Training loss (for one batch) at step 120: 289.1244, Accuracy: 0.7452\n","Training loss (for one batch) at step 130: 299.5864, Accuracy: 0.7470\n","Training loss (for one batch) at step 140: 289.7947, Accuracy: 0.7471\n","---- Training ----\n","Training loss: 266.8987\n","Training acc over epoch: 0.7450\n","---- Validation ----\n","Validation loss: 78.8276\n","Validation acc: 0.7117\n","Time taken: 10.36s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 313.5008, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 292.6286, Accuracy: 0.6936\n","Training loss (for one batch) at step 20: 302.9028, Accuracy: 0.6938\n","Training loss (for one batch) at step 30: 296.1251, Accuracy: 0.7139\n","Training loss (for one batch) at step 40: 295.2946, Accuracy: 0.7307\n","Training loss (for one batch) at step 50: 285.3101, Accuracy: 0.7437\n","Training loss (for one batch) at step 60: 279.6002, Accuracy: 0.7533\n","Training loss (for one batch) at step 70: 274.7595, Accuracy: 0.7592\n","Training loss (for one batch) at step 80: 308.2218, Accuracy: 0.7584\n","Training loss (for one batch) at step 90: 303.3319, Accuracy: 0.7510\n","Training loss (for one batch) at step 100: 300.4601, Accuracy: 0.7442\n","Training loss (for one batch) at step 110: 291.9742, Accuracy: 0.7387\n","Training loss (for one batch) at step 120: 285.1598, Accuracy: 0.7402\n","Training loss (for one batch) at step 130: 285.0003, Accuracy: 0.7400\n","Training loss (for one batch) at step 140: 289.8081, Accuracy: 0.7410\n","---- Training ----\n","Training loss: 262.2482\n","Training acc over epoch: 0.7404\n","---- Validation ----\n","Validation loss: 82.0966\n","Validation acc: 0.7080\n","Time taken: 9.74s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 312.3086, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 306.3939, Accuracy: 0.6836\n","Training loss (for one batch) at step 20: 312.1440, Accuracy: 0.6929\n","Training loss (for one batch) at step 30: 287.2438, Accuracy: 0.7165\n","Training loss (for one batch) at step 40: 281.3559, Accuracy: 0.7334\n","Training loss (for one batch) at step 50: 278.5285, Accuracy: 0.7445\n","Training loss (for one batch) at step 60: 271.6969, Accuracy: 0.7511\n","Training loss (for one batch) at step 70: 279.7212, Accuracy: 0.7596\n","Training loss (for one batch) at step 80: 291.2577, Accuracy: 0.7581\n","Training loss (for one batch) at step 90: 308.1074, Accuracy: 0.7507\n","Training loss (for one batch) at step 100: 303.0441, Accuracy: 0.7457\n","Training loss (for one batch) at step 110: 300.1024, Accuracy: 0.7400\n","Training loss (for one batch) at step 120: 286.0881, Accuracy: 0.7411\n","Training loss (for one batch) at step 130: 288.0582, Accuracy: 0.7424\n","Training loss (for one batch) at step 140: 287.8462, Accuracy: 0.7419\n","---- Training ----\n","Training loss: 264.2391\n","Training acc over epoch: 0.7409\n","---- Validation ----\n","Validation loss: 88.5755\n","Validation acc: 0.7077\n","Time taken: 9.51s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 303.1046, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 305.0496, Accuracy: 0.6855\n","Training loss (for one batch) at step 20: 289.4064, Accuracy: 0.7005\n","Training loss (for one batch) at step 30: 281.0330, Accuracy: 0.7232\n","Training loss (for one batch) at step 40: 277.5901, Accuracy: 0.7368\n","Training loss (for one batch) at step 50: 275.6011, Accuracy: 0.7455\n","Training loss (for one batch) at step 60: 279.5020, Accuracy: 0.7543\n","Training loss (for one batch) at step 70: 272.7109, Accuracy: 0.7603\n","Training loss (for one batch) at step 80: 287.1123, Accuracy: 0.7605\n","Training loss (for one batch) at step 90: 290.6513, Accuracy: 0.7538\n","Training loss (for one batch) at step 100: 296.8141, Accuracy: 0.7477\n","Training loss (for one batch) at step 110: 299.6447, Accuracy: 0.7402\n","Training loss (for one batch) at step 120: 286.0648, Accuracy: 0.7427\n","Training loss (for one batch) at step 130: 286.3492, Accuracy: 0.7472\n","Training loss (for one batch) at step 140: 299.3760, Accuracy: 0.7462\n","---- Training ----\n","Training loss: 263.1601\n","Training acc over epoch: 0.7443\n","---- Validation ----\n","Validation loss: 76.9431\n","Validation acc: 0.6994\n","Time taken: 9.64s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 325.6235, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 317.8419, Accuracy: 0.6918\n","Training loss (for one batch) at step 20: 297.8347, Accuracy: 0.7071\n","Training loss (for one batch) at step 30: 275.6420, Accuracy: 0.7297\n","Training loss (for one batch) at step 40: 292.6391, Accuracy: 0.7454\n","Training loss (for one batch) at step 50: 279.2148, Accuracy: 0.7575\n","Training loss (for one batch) at step 60: 281.4195, Accuracy: 0.7616\n","Training loss (for one batch) at step 70: 269.0944, Accuracy: 0.7675\n","Training loss (for one batch) at step 80: 289.6349, Accuracy: 0.7684\n","Training loss (for one batch) at step 90: 296.4579, Accuracy: 0.7638\n","Training loss (for one batch) at step 100: 303.5081, Accuracy: 0.7542\n","Training loss (for one batch) at step 110: 314.6498, Accuracy: 0.7468\n","Training loss (for one batch) at step 120: 274.4943, Accuracy: 0.7467\n","Training loss (for one batch) at step 130: 290.0459, Accuracy: 0.7486\n","Training loss (for one batch) at step 140: 308.0427, Accuracy: 0.7498\n","---- Training ----\n","Training loss: 254.1099\n","Training acc over epoch: 0.7476\n","---- Validation ----\n","Validation loss: 83.5182\n","Validation acc: 0.7149\n","Time taken: 9.68s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 324.8770, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 296.1006, Accuracy: 0.6909\n","Training loss (for one batch) at step 20: 277.7829, Accuracy: 0.7076\n","Training loss (for one batch) at step 30: 277.3151, Accuracy: 0.7274\n","Training loss (for one batch) at step 40: 274.6032, Accuracy: 0.7459\n","Training loss (for one batch) at step 50: 272.4920, Accuracy: 0.7508\n","Training loss (for one batch) at step 60: 271.0428, Accuracy: 0.7595\n","Training loss (for one batch) at step 70: 285.8203, Accuracy: 0.7665\n","Training loss (for one batch) at step 80: 303.0458, Accuracy: 0.7648\n","Training loss (for one batch) at step 90: 290.3024, Accuracy: 0.7577\n","Training loss (for one batch) at step 100: 308.4774, Accuracy: 0.7490\n","Training loss (for one batch) at step 110: 287.3716, Accuracy: 0.7438\n","Training loss (for one batch) at step 120: 270.0730, Accuracy: 0.7465\n","Training loss (for one batch) at step 130: 279.3144, Accuracy: 0.7466\n","Training loss (for one batch) at step 140: 283.4303, Accuracy: 0.7460\n","---- Training ----\n","Training loss: 241.4884\n","Training acc over epoch: 0.7450\n","---- Validation ----\n","Validation loss: 95.7262\n","Validation acc: 0.7125\n","Time taken: 9.53s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 317.4055, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 291.2167, Accuracy: 0.7036\n","Training loss (for one batch) at step 20: 284.8102, Accuracy: 0.7086\n","Training loss (for one batch) at step 30: 277.9558, Accuracy: 0.7219\n","Training loss (for one batch) at step 40: 277.9358, Accuracy: 0.7388\n","Training loss (for one batch) at step 50: 271.8394, Accuracy: 0.7555\n","Training loss (for one batch) at step 60: 280.5457, Accuracy: 0.7654\n","Training loss (for one batch) at step 70: 261.5763, Accuracy: 0.7701\n","Training loss (for one batch) at step 80: 286.6279, Accuracy: 0.7679\n","Training loss (for one batch) at step 90: 284.6831, Accuracy: 0.7603\n","Training loss (for one batch) at step 100: 296.7370, Accuracy: 0.7523\n","Training loss (for one batch) at step 110: 285.7184, Accuracy: 0.7493\n","Training loss (for one batch) at step 120: 282.8494, Accuracy: 0.7488\n","Training loss (for one batch) at step 130: 285.7282, Accuracy: 0.7516\n","Training loss (for one batch) at step 140: 286.7640, Accuracy: 0.7539\n","---- Training ----\n","Training loss: 254.3870\n","Training acc over epoch: 0.7513\n","---- Validation ----\n","Validation loss: 96.1866\n","Validation acc: 0.7104\n","Time taken: 9.61s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 279.6160, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 290.2021, Accuracy: 0.6936\n","Training loss (for one batch) at step 20: 294.7032, Accuracy: 0.6986\n","Training loss (for one batch) at step 30: 279.0786, Accuracy: 0.7271\n","Training loss (for one batch) at step 40: 271.7233, Accuracy: 0.7424\n","Training loss (for one batch) at step 50: 263.4313, Accuracy: 0.7533\n","Training loss (for one batch) at step 60: 288.3567, Accuracy: 0.7585\n","Training loss (for one batch) at step 70: 282.9569, Accuracy: 0.7685\n","Training loss (for one batch) at step 80: 292.5079, Accuracy: 0.7648\n","Training loss (for one batch) at step 90: 284.0687, Accuracy: 0.7590\n","Training loss (for one batch) at step 100: 294.6474, Accuracy: 0.7509\n","Training loss (for one batch) at step 110: 293.8667, Accuracy: 0.7444\n","Training loss (for one batch) at step 120: 289.7990, Accuracy: 0.7455\n","Training loss (for one batch) at step 130: 269.5887, Accuracy: 0.7495\n","Training loss (for one batch) at step 140: 282.6186, Accuracy: 0.7496\n","---- Training ----\n","Training loss: 249.4286\n","Training acc over epoch: 0.7489\n","---- Validation ----\n","Validation loss: 95.1864\n","Validation acc: 0.7015\n","Time taken: 9.62s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 337.1142, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 290.9865, Accuracy: 0.7009\n","Training loss (for one batch) at step 20: 292.3884, Accuracy: 0.7062\n","Training loss (for one batch) at step 30: 268.0639, Accuracy: 0.7226\n","Training loss (for one batch) at step 40: 291.4750, Accuracy: 0.7395\n","Training loss (for one batch) at step 50: 260.1214, Accuracy: 0.7525\n","Training loss (for one batch) at step 60: 262.2480, Accuracy: 0.7610\n","Training loss (for one batch) at step 70: 264.0003, Accuracy: 0.7687\n","Training loss (for one batch) at step 80: 290.7085, Accuracy: 0.7662\n","Training loss (for one batch) at step 90: 291.2721, Accuracy: 0.7607\n","Training loss (for one batch) at step 100: 301.9478, Accuracy: 0.7522\n","Training loss (for one batch) at step 110: 290.8656, Accuracy: 0.7459\n","Training loss (for one batch) at step 120: 260.8695, Accuracy: 0.7460\n","Training loss (for one batch) at step 130: 266.1054, Accuracy: 0.7486\n","Training loss (for one batch) at step 140: 278.3919, Accuracy: 0.7479\n","---- Training ----\n","Training loss: 249.8263\n","Training acc over epoch: 0.7467\n","---- Validation ----\n","Validation loss: 84.1237\n","Validation acc: 0.7096\n","Time taken: 9.61s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 300.7006, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 301.1176, Accuracy: 0.6773\n","Training loss (for one batch) at step 20: 290.7474, Accuracy: 0.7029\n","Training loss (for one batch) at step 30: 281.3712, Accuracy: 0.7252\n","Training loss (for one batch) at step 40: 281.2993, Accuracy: 0.7407\n","Training loss (for one batch) at step 50: 266.2566, Accuracy: 0.7541\n","Training loss (for one batch) at step 60: 268.3257, Accuracy: 0.7641\n","Training loss (for one batch) at step 70: 274.2320, Accuracy: 0.7680\n","Training loss (for one batch) at step 80: 276.9623, Accuracy: 0.7679\n","Training loss (for one batch) at step 90: 299.5009, Accuracy: 0.7607\n","Training loss (for one batch) at step 100: 307.5708, Accuracy: 0.7532\n","Training loss (for one batch) at step 110: 278.3058, Accuracy: 0.7459\n","Training loss (for one batch) at step 120: 278.4156, Accuracy: 0.7460\n","Training loss (for one batch) at step 130: 271.0179, Accuracy: 0.7489\n","Training loss (for one batch) at step 140: 285.8594, Accuracy: 0.7509\n","---- Training ----\n","Training loss: 251.7560\n","Training acc over epoch: 0.7485\n","---- Validation ----\n","Validation loss: 82.0452\n","Validation acc: 0.7077\n","Time taken: 9.62s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 292.2361, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 307.3529, Accuracy: 0.6800\n","Training loss (for one batch) at step 20: 291.6929, Accuracy: 0.7000\n","Training loss (for one batch) at step 30: 278.9135, Accuracy: 0.7306\n","Training loss (for one batch) at step 40: 275.2836, Accuracy: 0.7471\n","Training loss (for one batch) at step 50: 254.7866, Accuracy: 0.7567\n","Training loss (for one batch) at step 60: 262.1389, Accuracy: 0.7667\n","Training loss (for one batch) at step 70: 263.4606, Accuracy: 0.7692\n","Training loss (for one batch) at step 80: 277.9877, Accuracy: 0.7662\n","Training loss (for one batch) at step 90: 307.6725, Accuracy: 0.7588\n","Training loss (for one batch) at step 100: 300.3972, Accuracy: 0.7510\n","Training loss (for one batch) at step 110: 279.9063, Accuracy: 0.7464\n","Training loss (for one batch) at step 120: 257.7335, Accuracy: 0.7480\n","Training loss (for one batch) at step 130: 265.6494, Accuracy: 0.7494\n","Training loss (for one batch) at step 140: 285.0053, Accuracy: 0.7508\n","---- Training ----\n","Training loss: 252.4682\n","Training acc over epoch: 0.7490\n","---- Validation ----\n","Validation loss: 92.5795\n","Validation acc: 0.7069\n","Time taken: 9.66s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 313.9917, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 292.3438, Accuracy: 0.6918\n","Training loss (for one batch) at step 20: 284.1648, Accuracy: 0.7067\n","Training loss (for one batch) at step 30: 258.9263, Accuracy: 0.7268\n","Training loss (for one batch) at step 40: 255.9325, Accuracy: 0.7432\n","Training loss (for one batch) at step 50: 263.9716, Accuracy: 0.7580\n","Training loss (for one batch) at step 60: 270.6266, Accuracy: 0.7662\n","Training loss (for one batch) at step 70: 249.6085, Accuracy: 0.7723\n","Training loss (for one batch) at step 80: 283.5001, Accuracy: 0.7702\n","Training loss (for one batch) at step 90: 288.3343, Accuracy: 0.7623\n","Training loss (for one batch) at step 100: 295.2161, Accuracy: 0.7539\n","Training loss (for one batch) at step 110: 291.2736, Accuracy: 0.7507\n","Training loss (for one batch) at step 120: 279.0740, Accuracy: 0.7521\n","Training loss (for one batch) at step 130: 284.5387, Accuracy: 0.7545\n","Training loss (for one batch) at step 140: 283.7618, Accuracy: 0.7539\n","---- Training ----\n","Training loss: 249.1489\n","Training acc over epoch: 0.7521\n","---- Validation ----\n","Validation loss: 107.2238\n","Validation acc: 0.7074\n","Time taken: 9.70s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.6967\n","Validation AUC: 0.6971\n","Validation Balanced_ACC: 0.3192\n","Validation MI: 0.0620\n","Validation Normalized MI: 0.0900\n","Validation Adjusted MI: 0.0900\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 562.7127, Accuracy: 0.4400\n","Training loss (for one batch) at step 10: 460.6549, Accuracy: 0.5136\n","Training loss (for one batch) at step 20: 484.0602, Accuracy: 0.5110\n","Training loss (for one batch) at step 30: 477.4155, Accuracy: 0.5097\n","Training loss (for one batch) at step 40: 455.1656, Accuracy: 0.5100\n","Training loss (for one batch) at step 50: 441.7368, Accuracy: 0.5073\n","Training loss (for one batch) at step 60: 479.7435, Accuracy: 0.5100\n","Training loss (for one batch) at step 70: 487.5462, Accuracy: 0.5096\n","Training loss (for one batch) at step 80: 486.9509, Accuracy: 0.5099\n","Training loss (for one batch) at step 90: 460.6304, Accuracy: 0.5093\n","Training loss (for one batch) at step 100: 441.2349, Accuracy: 0.5078\n","Training loss (for one batch) at step 110: 452.1587, Accuracy: 0.5106\n","Training loss (for one batch) at step 120: 420.8704, Accuracy: 0.5086\n","Training loss (for one batch) at step 130: 424.2744, Accuracy: 0.5096\n","Training loss (for one batch) at step 140: 445.4619, Accuracy: 0.5103\n","---- Training ----\n","Training loss: 365.3603\n","Training acc over epoch: 0.5109\n","---- Validation ----\n","Validation loss: 79.3517\n","Validation acc: 0.5134\n","Time taken: 12.32s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 408.4884, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 427.8831, Accuracy: 0.5118\n","Training loss (for one batch) at step 20: 395.1977, Accuracy: 0.5271\n","Training loss (for one batch) at step 30: 408.1055, Accuracy: 0.5277\n","Training loss (for one batch) at step 40: 416.2772, Accuracy: 0.5251\n","Training loss (for one batch) at step 50: 425.7378, Accuracy: 0.5247\n","Training loss (for one batch) at step 60: 415.3058, Accuracy: 0.5221\n","Training loss (for one batch) at step 70: 403.2907, Accuracy: 0.5237\n","Training loss (for one batch) at step 80: 417.5343, Accuracy: 0.5260\n","Training loss (for one batch) at step 90: 424.8747, Accuracy: 0.5252\n","Training loss (for one batch) at step 100: 402.2992, Accuracy: 0.5254\n","Training loss (for one batch) at step 110: 408.0344, Accuracy: 0.5251\n","Training loss (for one batch) at step 120: 395.2573, Accuracy: 0.5249\n","Training loss (for one batch) at step 130: 416.3198, Accuracy: 0.5243\n","Training loss (for one batch) at step 140: 406.0481, Accuracy: 0.5244\n","---- Training ----\n","Training loss: 377.7123\n","Training acc over epoch: 0.5234\n","---- Validation ----\n","Validation loss: 78.8731\n","Validation acc: 0.5226\n","Time taken: 9.55s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 399.2804, Accuracy: 0.5600\n","Training loss (for one batch) at step 10: 396.6444, Accuracy: 0.4982\n","Training loss (for one batch) at step 20: 421.7504, Accuracy: 0.5076\n","Training loss (for one batch) at step 30: 383.5182, Accuracy: 0.5110\n","Training loss (for one batch) at step 40: 398.4522, Accuracy: 0.5185\n","Training loss (for one batch) at step 50: 389.8477, Accuracy: 0.5159\n","Training loss (for one batch) at step 60: 391.7271, Accuracy: 0.5167\n","Training loss (for one batch) at step 70: 394.8060, Accuracy: 0.5161\n","Training loss (for one batch) at step 80: 374.1259, Accuracy: 0.5181\n","Training loss (for one batch) at step 90: 381.8492, Accuracy: 0.5205\n","Training loss (for one batch) at step 100: 388.5081, Accuracy: 0.5194\n","Training loss (for one batch) at step 110: 380.2894, Accuracy: 0.5199\n","Training loss (for one batch) at step 120: 378.8657, Accuracy: 0.5185\n","Training loss (for one batch) at step 130: 390.1139, Accuracy: 0.5185\n","Training loss (for one batch) at step 140: 377.3057, Accuracy: 0.5174\n","---- Training ----\n","Training loss: 352.4437\n","Training acc over epoch: 0.5161\n","---- Validation ----\n","Validation loss: 79.2496\n","Validation acc: 0.5548\n","Time taken: 9.63s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 371.2058, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 375.3092, Accuracy: 0.5173\n","Training loss (for one batch) at step 20: 384.7914, Accuracy: 0.5248\n","Training loss (for one batch) at step 30: 377.7029, Accuracy: 0.5223\n","Training loss (for one batch) at step 40: 392.2927, Accuracy: 0.5220\n","Training loss (for one batch) at step 50: 397.2916, Accuracy: 0.5239\n","Training loss (for one batch) at step 60: 383.6299, Accuracy: 0.5239\n","Training loss (for one batch) at step 70: 371.4832, Accuracy: 0.5232\n","Training loss (for one batch) at step 80: 375.8071, Accuracy: 0.5226\n","Training loss (for one batch) at step 90: 365.3604, Accuracy: 0.5252\n","Training loss (for one batch) at step 100: 377.1401, Accuracy: 0.5252\n","Training loss (for one batch) at step 110: 379.2489, Accuracy: 0.5233\n","Training loss (for one batch) at step 120: 388.6891, Accuracy: 0.5227\n","Training loss (for one batch) at step 130: 371.7573, Accuracy: 0.5205\n","Training loss (for one batch) at step 140: 361.4866, Accuracy: 0.5203\n","---- Training ----\n","Training loss: 350.6696\n","Training acc over epoch: 0.5204\n","---- Validation ----\n","Validation loss: 76.0036\n","Validation acc: 0.5422\n","Time taken: 9.61s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 380.1242, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 374.8038, Accuracy: 0.5191\n","Training loss (for one batch) at step 20: 372.6599, Accuracy: 0.5248\n","Training loss (for one batch) at step 30: 369.6958, Accuracy: 0.5197\n","Training loss (for one batch) at step 40: 355.0204, Accuracy: 0.5229\n","Training loss (for one batch) at step 50: 377.1414, Accuracy: 0.5176\n","Training loss (for one batch) at step 60: 367.9451, Accuracy: 0.5182\n","Training loss (for one batch) at step 70: 368.2938, Accuracy: 0.5179\n","Training loss (for one batch) at step 80: 360.6914, Accuracy: 0.5196\n","Training loss (for one batch) at step 90: 367.0938, Accuracy: 0.5171\n","Training loss (for one batch) at step 100: 360.3851, Accuracy: 0.5190\n","Training loss (for one batch) at step 110: 361.6823, Accuracy: 0.5205\n","Training loss (for one batch) at step 120: 360.6482, Accuracy: 0.5207\n","Training loss (for one batch) at step 130: 364.2635, Accuracy: 0.5230\n","Training loss (for one batch) at step 140: 364.6760, Accuracy: 0.5224\n","---- Training ----\n","Training loss: 318.0136\n","Training acc over epoch: 0.5214\n","---- Validation ----\n","Validation loss: 76.4853\n","Validation acc: 0.5567\n","Time taken: 9.59s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 368.4019, Accuracy: 0.4700\n","Training loss (for one batch) at step 10: 356.6215, Accuracy: 0.5027\n","Training loss (for one batch) at step 20: 361.4895, Accuracy: 0.5214\n","Training loss (for one batch) at step 30: 367.5591, Accuracy: 0.5258\n","Training loss (for one batch) at step 40: 360.3834, Accuracy: 0.5193\n","Training loss (for one batch) at step 50: 358.3957, Accuracy: 0.5225\n","Training loss (for one batch) at step 60: 359.1482, Accuracy: 0.5246\n","Training loss (for one batch) at step 70: 367.8800, Accuracy: 0.5244\n","Training loss (for one batch) at step 80: 366.0873, Accuracy: 0.5252\n","Training loss (for one batch) at step 90: 364.8582, Accuracy: 0.5242\n","Training loss (for one batch) at step 100: 359.0913, Accuracy: 0.5234\n","Training loss (for one batch) at step 110: 355.6158, Accuracy: 0.5188\n","Training loss (for one batch) at step 120: 361.6274, Accuracy: 0.5198\n","Training loss (for one batch) at step 130: 358.7679, Accuracy: 0.5214\n","Training loss (for one batch) at step 140: 363.2021, Accuracy: 0.5213\n","---- Training ----\n","Training loss: 319.6490\n","Training acc over epoch: 0.5204\n","---- Validation ----\n","Validation loss: 76.6990\n","Validation acc: 0.5588\n","Time taken: 9.78s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 350.7317, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 359.6668, Accuracy: 0.5109\n","Training loss (for one batch) at step 20: 355.6925, Accuracy: 0.5019\n","Training loss (for one batch) at step 30: 357.1891, Accuracy: 0.5071\n","Training loss (for one batch) at step 40: 351.2353, Accuracy: 0.5137\n","Training loss (for one batch) at step 50: 355.7039, Accuracy: 0.5159\n","Training loss (for one batch) at step 60: 352.6460, Accuracy: 0.5216\n","Training loss (for one batch) at step 70: 352.5013, Accuracy: 0.5239\n","Training loss (for one batch) at step 80: 355.1097, Accuracy: 0.5243\n","Training loss (for one batch) at step 90: 356.3646, Accuracy: 0.5230\n","Training loss (for one batch) at step 100: 356.2939, Accuracy: 0.5221\n","Training loss (for one batch) at step 110: 360.6817, Accuracy: 0.5223\n","Training loss (for one batch) at step 120: 354.4174, Accuracy: 0.5198\n","Training loss (for one batch) at step 130: 356.0367, Accuracy: 0.5200\n","Training loss (for one batch) at step 140: 349.7124, Accuracy: 0.5216\n","---- Training ----\n","Training loss: 313.8380\n","Training acc over epoch: 0.5210\n","---- Validation ----\n","Validation loss: 77.0161\n","Validation acc: 0.5473\n","Time taken: 9.61s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 356.2520, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 358.3849, Accuracy: 0.5418\n","Training loss (for one batch) at step 20: 346.5833, Accuracy: 0.5229\n","Training loss (for one batch) at step 30: 362.3109, Accuracy: 0.5261\n","Training loss (for one batch) at step 40: 352.0871, Accuracy: 0.5312\n","Training loss (for one batch) at step 50: 352.3970, Accuracy: 0.5251\n","Training loss (for one batch) at step 60: 350.9148, Accuracy: 0.5238\n","Training loss (for one batch) at step 70: 353.7194, Accuracy: 0.5263\n","Training loss (for one batch) at step 80: 346.2047, Accuracy: 0.5300\n","Training loss (for one batch) at step 90: 354.0146, Accuracy: 0.5329\n","Training loss (for one batch) at step 100: 348.5724, Accuracy: 0.5354\n","Training loss (for one batch) at step 110: 351.7749, Accuracy: 0.5379\n","Training loss (for one batch) at step 120: 350.3373, Accuracy: 0.5405\n","Training loss (for one batch) at step 130: 346.5583, Accuracy: 0.5398\n","Training loss (for one batch) at step 140: 349.0498, Accuracy: 0.5410\n","---- Training ----\n","Training loss: 314.4562\n","Training acc over epoch: 0.5398\n","---- Validation ----\n","Validation loss: 76.1274\n","Validation acc: 0.5567\n","Time taken: 9.63s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 350.4630, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 350.2481, Accuracy: 0.5182\n","Training loss (for one batch) at step 20: 349.2733, Accuracy: 0.5171\n","Training loss (for one batch) at step 30: 350.3744, Accuracy: 0.5210\n","Training loss (for one batch) at step 40: 353.7614, Accuracy: 0.5300\n","Training loss (for one batch) at step 50: 350.9201, Accuracy: 0.5353\n","Training loss (for one batch) at step 60: 347.2686, Accuracy: 0.5393\n","Training loss (for one batch) at step 70: 342.1412, Accuracy: 0.5441\n","Training loss (for one batch) at step 80: 349.5940, Accuracy: 0.5479\n","Training loss (for one batch) at step 90: 348.7700, Accuracy: 0.5482\n","Training loss (for one batch) at step 100: 349.5836, Accuracy: 0.5501\n","Training loss (for one batch) at step 110: 350.9650, Accuracy: 0.5515\n","Training loss (for one batch) at step 120: 347.9694, Accuracy: 0.5474\n","Training loss (for one batch) at step 130: 347.9047, Accuracy: 0.5469\n","Training loss (for one batch) at step 140: 349.2465, Accuracy: 0.5463\n","---- Training ----\n","Training loss: 308.1052\n","Training acc over epoch: 0.5470\n","---- Validation ----\n","Validation loss: 76.5558\n","Validation acc: 0.5838\n","Time taken: 9.52s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 350.7160, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 351.1212, Accuracy: 0.5564\n","Training loss (for one batch) at step 20: 351.2097, Accuracy: 0.5557\n","Training loss (for one batch) at step 30: 350.0813, Accuracy: 0.5503\n","Training loss (for one batch) at step 40: 346.6069, Accuracy: 0.5517\n","Training loss (for one batch) at step 50: 349.3394, Accuracy: 0.5539\n","Training loss (for one batch) at step 60: 342.1691, Accuracy: 0.5513\n","Training loss (for one batch) at step 70: 341.7366, Accuracy: 0.5551\n","Training loss (for one batch) at step 80: 351.0930, Accuracy: 0.5532\n","Training loss (for one batch) at step 90: 345.8315, Accuracy: 0.5553\n","Training loss (for one batch) at step 100: 349.9069, Accuracy: 0.5587\n","Training loss (for one batch) at step 110: 350.4744, Accuracy: 0.5576\n","Training loss (for one batch) at step 120: 348.3295, Accuracy: 0.5578\n","Training loss (for one batch) at step 130: 347.3198, Accuracy: 0.5594\n","Training loss (for one batch) at step 140: 348.5938, Accuracy: 0.5595\n","---- Training ----\n","Training loss: 311.5338\n","Training acc over epoch: 0.5594\n","---- Validation ----\n","Validation loss: 77.0435\n","Validation acc: 0.5938\n","Time taken: 9.68s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 344.7688, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 348.0591, Accuracy: 0.5418\n","Training loss (for one batch) at step 20: 343.7940, Accuracy: 0.5429\n","Training loss (for one batch) at step 30: 347.9174, Accuracy: 0.5539\n","Training loss (for one batch) at step 40: 344.8077, Accuracy: 0.5607\n","Training loss (for one batch) at step 50: 337.7239, Accuracy: 0.5592\n","Training loss (for one batch) at step 60: 344.9712, Accuracy: 0.5646\n","Training loss (for one batch) at step 70: 342.8813, Accuracy: 0.5707\n","Training loss (for one batch) at step 80: 347.4056, Accuracy: 0.5738\n","Training loss (for one batch) at step 90: 349.9490, Accuracy: 0.5763\n","Training loss (for one batch) at step 100: 353.0125, Accuracy: 0.5760\n","Training loss (for one batch) at step 110: 342.9292, Accuracy: 0.5744\n","Training loss (for one batch) at step 120: 348.2896, Accuracy: 0.5741\n","Training loss (for one batch) at step 130: 345.5571, Accuracy: 0.5734\n","Training loss (for one batch) at step 140: 352.4190, Accuracy: 0.5739\n","---- Training ----\n","Training loss: 309.3537\n","Training acc over epoch: 0.5740\n","---- Validation ----\n","Validation loss: 75.5917\n","Validation acc: 0.5913\n","Time taken: 9.54s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 343.6501, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 349.9497, Accuracy: 0.5645\n","Training loss (for one batch) at step 20: 350.1333, Accuracy: 0.5610\n","Training loss (for one batch) at step 30: 345.7928, Accuracy: 0.5658\n","Training loss (for one batch) at step 40: 342.6110, Accuracy: 0.5724\n","Training loss (for one batch) at step 50: 336.2910, Accuracy: 0.5722\n","Training loss (for one batch) at step 60: 345.3276, Accuracy: 0.5779\n","Training loss (for one batch) at step 70: 343.0822, Accuracy: 0.5794\n","Training loss (for one batch) at step 80: 345.7167, Accuracy: 0.5825\n","Training loss (for one batch) at step 90: 350.3420, Accuracy: 0.5838\n","Training loss (for one batch) at step 100: 346.4327, Accuracy: 0.5842\n","Training loss (for one batch) at step 110: 341.4489, Accuracy: 0.5841\n","Training loss (for one batch) at step 120: 339.3263, Accuracy: 0.5820\n","Training loss (for one batch) at step 130: 339.2897, Accuracy: 0.5827\n","Training loss (for one batch) at step 140: 341.5996, Accuracy: 0.5831\n","---- Training ----\n","Training loss: 304.6505\n","Training acc over epoch: 0.5821\n","---- Validation ----\n","Validation loss: 75.4903\n","Validation acc: 0.6064\n","Time taken: 9.54s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 344.8393, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 345.6451, Accuracy: 0.5527\n","Training loss (for one batch) at step 20: 346.2445, Accuracy: 0.5495\n","Training loss (for one batch) at step 30: 343.9568, Accuracy: 0.5658\n","Training loss (for one batch) at step 40: 341.3467, Accuracy: 0.5741\n","Training loss (for one batch) at step 50: 347.0221, Accuracy: 0.5814\n","Training loss (for one batch) at step 60: 346.5392, Accuracy: 0.5789\n","Training loss (for one batch) at step 70: 338.9719, Accuracy: 0.5813\n","Training loss (for one batch) at step 80: 338.0478, Accuracy: 0.5811\n","Training loss (for one batch) at step 90: 347.8520, Accuracy: 0.5833\n","Training loss (for one batch) at step 100: 346.9819, Accuracy: 0.5816\n","Training loss (for one batch) at step 110: 348.5729, Accuracy: 0.5807\n","Training loss (for one batch) at step 120: 339.0122, Accuracy: 0.5804\n","Training loss (for one batch) at step 130: 344.2386, Accuracy: 0.5813\n","Training loss (for one batch) at step 140: 343.6808, Accuracy: 0.5828\n","---- Training ----\n","Training loss: 299.9441\n","Training acc over epoch: 0.5844\n","---- Validation ----\n","Validation loss: 75.2396\n","Validation acc: 0.6013\n","Time taken: 9.77s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 346.7418, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 346.2781, Accuracy: 0.5436\n","Training loss (for one batch) at step 20: 348.0587, Accuracy: 0.5543\n","Training loss (for one batch) at step 30: 343.3042, Accuracy: 0.5700\n","Training loss (for one batch) at step 40: 339.5439, Accuracy: 0.5805\n","Training loss (for one batch) at step 50: 335.4921, Accuracy: 0.5824\n","Training loss (for one batch) at step 60: 337.1413, Accuracy: 0.5867\n","Training loss (for one batch) at step 70: 335.8932, Accuracy: 0.5938\n","Training loss (for one batch) at step 80: 339.6656, Accuracy: 0.5957\n","Training loss (for one batch) at step 90: 346.2119, Accuracy: 0.5949\n","Training loss (for one batch) at step 100: 352.4259, Accuracy: 0.5918\n","Training loss (for one batch) at step 110: 342.8771, Accuracy: 0.5881\n","Training loss (for one batch) at step 120: 334.2838, Accuracy: 0.5876\n","Training loss (for one batch) at step 130: 346.2674, Accuracy: 0.5875\n","Training loss (for one batch) at step 140: 343.2606, Accuracy: 0.5897\n","---- Training ----\n","Training loss: 298.5126\n","Training acc over epoch: 0.5893\n","---- Validation ----\n","Validation loss: 76.5050\n","Validation acc: 0.6024\n","Time taken: 9.58s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 345.4520, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 346.8026, Accuracy: 0.5573\n","Training loss (for one batch) at step 20: 347.7487, Accuracy: 0.5533\n","Training loss (for one batch) at step 30: 340.7074, Accuracy: 0.5735\n","Training loss (for one batch) at step 40: 340.6688, Accuracy: 0.5820\n","Training loss (for one batch) at step 50: 337.7813, Accuracy: 0.5853\n","Training loss (for one batch) at step 60: 328.9741, Accuracy: 0.5913\n","Training loss (for one batch) at step 70: 342.2624, Accuracy: 0.5959\n","Training loss (for one batch) at step 80: 337.8427, Accuracy: 0.6007\n","Training loss (for one batch) at step 90: 342.3364, Accuracy: 0.6029\n","Training loss (for one batch) at step 100: 343.7581, Accuracy: 0.6023\n","Training loss (for one batch) at step 110: 344.7883, Accuracy: 0.5993\n","Training loss (for one batch) at step 120: 340.8442, Accuracy: 0.5981\n","Training loss (for one batch) at step 130: 340.7506, Accuracy: 0.5992\n","Training loss (for one batch) at step 140: 346.5892, Accuracy: 0.5998\n","---- Training ----\n","Training loss: 299.3829\n","Training acc over epoch: 0.5998\n","---- Validation ----\n","Validation loss: 76.1163\n","Validation acc: 0.6075\n","Time taken: 9.62s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 345.5416, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 344.8987, Accuracy: 0.5873\n","Training loss (for one batch) at step 20: 337.8605, Accuracy: 0.5795\n","Training loss (for one batch) at step 30: 338.9229, Accuracy: 0.5832\n","Training loss (for one batch) at step 40: 334.3616, Accuracy: 0.5920\n","Training loss (for one batch) at step 50: 333.2768, Accuracy: 0.5949\n","Training loss (for one batch) at step 60: 336.1537, Accuracy: 0.6005\n","Training loss (for one batch) at step 70: 329.5667, Accuracy: 0.6055\n","Training loss (for one batch) at step 80: 344.6895, Accuracy: 0.6075\n","Training loss (for one batch) at step 90: 343.6305, Accuracy: 0.6067\n","Training loss (for one batch) at step 100: 350.2993, Accuracy: 0.6055\n","Training loss (for one batch) at step 110: 345.2262, Accuracy: 0.6019\n","Training loss (for one batch) at step 120: 342.6655, Accuracy: 0.6008\n","Training loss (for one batch) at step 130: 342.9781, Accuracy: 0.6017\n","Training loss (for one batch) at step 140: 339.1515, Accuracy: 0.6013\n","---- Training ----\n","Training loss: 299.4324\n","Training acc over epoch: 0.6011\n","---- Validation ----\n","Validation loss: 76.3855\n","Validation acc: 0.5991\n","Time taken: 9.77s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 348.0191, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 338.2692, Accuracy: 0.5800\n","Training loss (for one batch) at step 20: 338.0722, Accuracy: 0.5695\n","Training loss (for one batch) at step 30: 329.9686, Accuracy: 0.5900\n","Training loss (for one batch) at step 40: 342.0546, Accuracy: 0.5917\n","Training loss (for one batch) at step 50: 332.5324, Accuracy: 0.5963\n","Training loss (for one batch) at step 60: 331.4356, Accuracy: 0.6038\n","Training loss (for one batch) at step 70: 336.9560, Accuracy: 0.6085\n","Training loss (for one batch) at step 80: 338.2961, Accuracy: 0.6095\n","Training loss (for one batch) at step 90: 346.7173, Accuracy: 0.6080\n","Training loss (for one batch) at step 100: 346.6783, Accuracy: 0.6053\n","Training loss (for one batch) at step 110: 342.2503, Accuracy: 0.6037\n","Training loss (for one batch) at step 120: 336.5357, Accuracy: 0.6031\n","Training loss (for one batch) at step 130: 335.4279, Accuracy: 0.6031\n","Training loss (for one batch) at step 140: 342.4195, Accuracy: 0.6044\n","---- Training ----\n","Training loss: 300.7969\n","Training acc over epoch: 0.6046\n","---- Validation ----\n","Validation loss: 76.1265\n","Validation acc: 0.5938\n","Time taken: 9.58s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 340.2561, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 339.4590, Accuracy: 0.5700\n","Training loss (for one batch) at step 20: 338.2614, Accuracy: 0.5690\n","Training loss (for one batch) at step 30: 341.0990, Accuracy: 0.5735\n","Training loss (for one batch) at step 40: 342.2164, Accuracy: 0.5885\n","Training loss (for one batch) at step 50: 333.1863, Accuracy: 0.5955\n","Training loss (for one batch) at step 60: 321.2084, Accuracy: 0.6044\n","Training loss (for one batch) at step 70: 328.4800, Accuracy: 0.6097\n","Training loss (for one batch) at step 80: 345.3085, Accuracy: 0.6131\n","Training loss (for one batch) at step 90: 343.6460, Accuracy: 0.6141\n","Training loss (for one batch) at step 100: 344.7093, Accuracy: 0.6124\n","Training loss (for one batch) at step 110: 329.9904, Accuracy: 0.6076\n","Training loss (for one batch) at step 120: 333.5373, Accuracy: 0.6064\n","Training loss (for one batch) at step 130: 330.7190, Accuracy: 0.6089\n","Training loss (for one batch) at step 140: 339.5060, Accuracy: 0.6081\n","---- Training ----\n","Training loss: 297.8412\n","Training acc over epoch: 0.6076\n","---- Validation ----\n","Validation loss: 77.6931\n","Validation acc: 0.6051\n","Time taken: 9.70s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 341.4813, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 343.9273, Accuracy: 0.5727\n","Training loss (for one batch) at step 20: 333.6067, Accuracy: 0.5729\n","Training loss (for one batch) at step 30: 334.1020, Accuracy: 0.5845\n","Training loss (for one batch) at step 40: 335.6734, Accuracy: 0.5922\n","Training loss (for one batch) at step 50: 323.8292, Accuracy: 0.5994\n","Training loss (for one batch) at step 60: 328.0602, Accuracy: 0.6039\n","Training loss (for one batch) at step 70: 324.1134, Accuracy: 0.6070\n","Training loss (for one batch) at step 80: 335.3935, Accuracy: 0.6111\n","Training loss (for one batch) at step 90: 340.7360, Accuracy: 0.6085\n","Training loss (for one batch) at step 100: 341.9165, Accuracy: 0.6056\n","Training loss (for one batch) at step 110: 335.1580, Accuracy: 0.6041\n","Training loss (for one batch) at step 120: 335.3858, Accuracy: 0.6039\n","Training loss (for one batch) at step 130: 333.4424, Accuracy: 0.6043\n","Training loss (for one batch) at step 140: 340.2669, Accuracy: 0.6037\n","---- Training ----\n","Training loss: 295.8681\n","Training acc over epoch: 0.6053\n","---- Validation ----\n","Validation loss: 79.1767\n","Validation acc: 0.5981\n","Time taken: 9.66s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 334.6679, Accuracy: 0.5600\n","Training loss (for one batch) at step 10: 334.2707, Accuracy: 0.5764\n","Training loss (for one batch) at step 20: 340.5313, Accuracy: 0.5724\n","Training loss (for one batch) at step 30: 334.0032, Accuracy: 0.5797\n","Training loss (for one batch) at step 40: 326.5537, Accuracy: 0.5954\n","Training loss (for one batch) at step 50: 323.0966, Accuracy: 0.6035\n","Training loss (for one batch) at step 60: 326.5466, Accuracy: 0.6116\n","Training loss (for one batch) at step 70: 325.1561, Accuracy: 0.6185\n","Training loss (for one batch) at step 80: 323.9606, Accuracy: 0.6196\n","Training loss (for one batch) at step 90: 339.4577, Accuracy: 0.6151\n","Training loss (for one batch) at step 100: 336.3422, Accuracy: 0.6087\n","Training loss (for one batch) at step 110: 333.7426, Accuracy: 0.6052\n","Training loss (for one batch) at step 120: 338.6219, Accuracy: 0.6049\n","Training loss (for one batch) at step 130: 329.5387, Accuracy: 0.6063\n","Training loss (for one batch) at step 140: 330.2692, Accuracy: 0.6067\n","---- Training ----\n","Training loss: 287.9253\n","Training acc over epoch: 0.6081\n","---- Validation ----\n","Validation loss: 76.1377\n","Validation acc: 0.5962\n","Time taken: 9.78s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 334.3287, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 340.5855, Accuracy: 0.5918\n","Training loss (for one batch) at step 20: 327.7975, Accuracy: 0.5786\n","Training loss (for one batch) at step 30: 330.8694, Accuracy: 0.5913\n","Training loss (for one batch) at step 40: 325.1086, Accuracy: 0.5993\n","Training loss (for one batch) at step 50: 315.7816, Accuracy: 0.6051\n","Training loss (for one batch) at step 60: 313.4030, Accuracy: 0.6161\n","Training loss (for one batch) at step 70: 316.6740, Accuracy: 0.6165\n","Training loss (for one batch) at step 80: 327.6668, Accuracy: 0.6214\n","Training loss (for one batch) at step 90: 335.7328, Accuracy: 0.6177\n","Training loss (for one batch) at step 100: 335.2026, Accuracy: 0.6134\n","Training loss (for one batch) at step 110: 335.1636, Accuracy: 0.6112\n","Training loss (for one batch) at step 120: 328.7500, Accuracy: 0.6106\n","Training loss (for one batch) at step 130: 329.6516, Accuracy: 0.6111\n","Training loss (for one batch) at step 140: 336.5390, Accuracy: 0.6109\n","---- Training ----\n","Training loss: 285.4042\n","Training acc over epoch: 0.6102\n","---- Validation ----\n","Validation loss: 77.6484\n","Validation acc: 0.5860\n","Time taken: 9.65s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 334.6082, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 337.8044, Accuracy: 0.5545\n","Training loss (for one batch) at step 20: 332.6551, Accuracy: 0.5562\n","Training loss (for one batch) at step 30: 324.2382, Accuracy: 0.5752\n","Training loss (for one batch) at step 40: 330.6546, Accuracy: 0.5863\n","Training loss (for one batch) at step 50: 323.1714, Accuracy: 0.5924\n","Training loss (for one batch) at step 60: 314.2004, Accuracy: 0.6018\n","Training loss (for one batch) at step 70: 313.8486, Accuracy: 0.6085\n","Training loss (for one batch) at step 80: 325.6457, Accuracy: 0.6130\n","Training loss (for one batch) at step 90: 336.6898, Accuracy: 0.6116\n","Training loss (for one batch) at step 100: 336.4714, Accuracy: 0.6085\n","Training loss (for one batch) at step 110: 333.2492, Accuracy: 0.6048\n","Training loss (for one batch) at step 120: 334.9037, Accuracy: 0.6065\n","Training loss (for one batch) at step 130: 321.0176, Accuracy: 0.6073\n","Training loss (for one batch) at step 140: 325.4796, Accuracy: 0.6089\n","---- Training ----\n","Training loss: 308.1998\n","Training acc over epoch: 0.6075\n","---- Validation ----\n","Validation loss: 79.2196\n","Validation acc: 0.5868\n","Time taken: 9.64s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 333.5944, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 338.1208, Accuracy: 0.5464\n","Training loss (for one batch) at step 20: 318.6883, Accuracy: 0.5619\n","Training loss (for one batch) at step 30: 324.3109, Accuracy: 0.5784\n","Training loss (for one batch) at step 40: 328.1270, Accuracy: 0.5941\n","Training loss (for one batch) at step 50: 328.5621, Accuracy: 0.6027\n","Training loss (for one batch) at step 60: 312.7031, Accuracy: 0.6097\n","Training loss (for one batch) at step 70: 311.0594, Accuracy: 0.6165\n","Training loss (for one batch) at step 80: 336.2181, Accuracy: 0.6188\n","Training loss (for one batch) at step 90: 344.1315, Accuracy: 0.6176\n","Training loss (for one batch) at step 100: 338.3943, Accuracy: 0.6132\n","Training loss (for one batch) at step 110: 331.4984, Accuracy: 0.6090\n","Training loss (for one batch) at step 120: 331.6852, Accuracy: 0.6086\n","Training loss (for one batch) at step 130: 325.5171, Accuracy: 0.6099\n","Training loss (for one batch) at step 140: 327.4382, Accuracy: 0.6095\n","---- Training ----\n","Training loss: 289.8142\n","Training acc over epoch: 0.6094\n","---- Validation ----\n","Validation loss: 76.9489\n","Validation acc: 0.6005\n","Time taken: 12.28s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 336.8483, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 346.4577, Accuracy: 0.5727\n","Training loss (for one batch) at step 20: 328.7226, Accuracy: 0.5767\n","Training loss (for one batch) at step 30: 334.9930, Accuracy: 0.5848\n","Training loss (for one batch) at step 40: 318.6382, Accuracy: 0.5961\n","Training loss (for one batch) at step 50: 322.6724, Accuracy: 0.6041\n","Training loss (for one batch) at step 60: 322.5620, Accuracy: 0.6149\n","Training loss (for one batch) at step 70: 303.7821, Accuracy: 0.6217\n","Training loss (for one batch) at step 80: 327.8456, Accuracy: 0.6236\n","Training loss (for one batch) at step 90: 341.4044, Accuracy: 0.6230\n","Training loss (for one batch) at step 100: 331.0978, Accuracy: 0.6172\n","Training loss (for one batch) at step 110: 328.4796, Accuracy: 0.6150\n","Training loss (for one batch) at step 120: 337.6360, Accuracy: 0.6136\n","Training loss (for one batch) at step 130: 324.7293, Accuracy: 0.6152\n","Training loss (for one batch) at step 140: 331.8992, Accuracy: 0.6154\n","---- Training ----\n","Training loss: 291.5623\n","Training acc over epoch: 0.6149\n","---- Validation ----\n","Validation loss: 76.6946\n","Validation acc: 0.6042\n","Time taken: 29.88s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 334.6246, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 329.6911, Accuracy: 0.5536\n","Training loss (for one batch) at step 20: 329.4321, Accuracy: 0.5652\n","Training loss (for one batch) at step 30: 323.5604, Accuracy: 0.5894\n","Training loss (for one batch) at step 40: 313.4906, Accuracy: 0.6024\n","Training loss (for one batch) at step 50: 317.1629, Accuracy: 0.6086\n","Training loss (for one batch) at step 60: 314.0666, Accuracy: 0.6172\n","Training loss (for one batch) at step 70: 311.3079, Accuracy: 0.6244\n","Training loss (for one batch) at step 80: 318.4893, Accuracy: 0.6280\n","Training loss (for one batch) at step 90: 334.3674, Accuracy: 0.6242\n","Training loss (for one batch) at step 100: 335.9858, Accuracy: 0.6202\n","Training loss (for one batch) at step 110: 330.1472, Accuracy: 0.6172\n","Training loss (for one batch) at step 120: 328.1593, Accuracy: 0.6178\n","Training loss (for one batch) at step 130: 330.5038, Accuracy: 0.6193\n","Training loss (for one batch) at step 140: 319.2593, Accuracy: 0.6198\n","---- Training ----\n","Training loss: 290.2875\n","Training acc over epoch: 0.6206\n","---- Validation ----\n","Validation loss: 75.0511\n","Validation acc: 0.5922\n","Time taken: 38.47s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 344.4735, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 336.5983, Accuracy: 0.5273\n","Training loss (for one batch) at step 20: 322.3855, Accuracy: 0.5524\n","Training loss (for one batch) at step 30: 318.9788, Accuracy: 0.5832\n","Training loss (for one batch) at step 40: 316.4277, Accuracy: 0.5995\n","Training loss (for one batch) at step 50: 315.6444, Accuracy: 0.6102\n","Training loss (for one batch) at step 60: 321.2632, Accuracy: 0.6231\n","Training loss (for one batch) at step 70: 313.1920, Accuracy: 0.6290\n","Training loss (for one batch) at step 80: 325.7168, Accuracy: 0.6353\n","Training loss (for one batch) at step 90: 330.1096, Accuracy: 0.6295\n","Training loss (for one batch) at step 100: 330.7798, Accuracy: 0.6217\n","Training loss (for one batch) at step 110: 324.3406, Accuracy: 0.6192\n","Training loss (for one batch) at step 120: 325.0195, Accuracy: 0.6193\n","Training loss (for one batch) at step 130: 316.2964, Accuracy: 0.6189\n","Training loss (for one batch) at step 140: 327.2055, Accuracy: 0.6191\n","---- Training ----\n","Training loss: 284.0937\n","Training acc over epoch: 0.6190\n","---- Validation ----\n","Validation loss: 79.2842\n","Validation acc: 0.5940\n","Time taken: 12.06s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 336.0916, Accuracy: 0.5600\n","Training loss (for one batch) at step 10: 333.0018, Accuracy: 0.5455\n","Training loss (for one batch) at step 20: 318.4463, Accuracy: 0.5524\n","Training loss (for one batch) at step 30: 313.6210, Accuracy: 0.5645\n","Training loss (for one batch) at step 40: 318.1906, Accuracy: 0.5839\n","Training loss (for one batch) at step 50: 301.7175, Accuracy: 0.5969\n","Training loss (for one batch) at step 60: 300.3631, Accuracy: 0.6115\n","Training loss (for one batch) at step 70: 310.8893, Accuracy: 0.6265\n","Training loss (for one batch) at step 80: 315.3619, Accuracy: 0.6283\n","Training loss (for one batch) at step 90: 319.1880, Accuracy: 0.6244\n","Training loss (for one batch) at step 100: 335.4048, Accuracy: 0.6180\n","Training loss (for one batch) at step 110: 331.3880, Accuracy: 0.6134\n","Training loss (for one batch) at step 120: 315.5753, Accuracy: 0.6136\n","Training loss (for one batch) at step 130: 323.6331, Accuracy: 0.6134\n","Training loss (for one batch) at step 140: 321.2312, Accuracy: 0.6144\n","---- Training ----\n","Training loss: 287.7984\n","Training acc over epoch: 0.6155\n","---- Validation ----\n","Validation loss: 80.5498\n","Validation acc: 0.5908\n","Time taken: 9.61s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 333.4815, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 330.5126, Accuracy: 0.5582\n","Training loss (for one batch) at step 20: 316.9601, Accuracy: 0.5614\n","Training loss (for one batch) at step 30: 314.8058, Accuracy: 0.5887\n","Training loss (for one batch) at step 40: 310.7805, Accuracy: 0.6007\n","Training loss (for one batch) at step 50: 313.1742, Accuracy: 0.6131\n","Training loss (for one batch) at step 60: 309.2968, Accuracy: 0.6244\n","Training loss (for one batch) at step 70: 306.6925, Accuracy: 0.6318\n","Training loss (for one batch) at step 80: 319.1799, Accuracy: 0.6323\n","Training loss (for one batch) at step 90: 329.3581, Accuracy: 0.6286\n","Training loss (for one batch) at step 100: 325.7072, Accuracy: 0.6225\n","Training loss (for one batch) at step 110: 321.2907, Accuracy: 0.6169\n","Training loss (for one batch) at step 120: 313.7943, Accuracy: 0.6160\n","Training loss (for one batch) at step 130: 312.2578, Accuracy: 0.6180\n","Training loss (for one batch) at step 140: 322.6664, Accuracy: 0.6182\n","---- Training ----\n","Training loss: 284.0961\n","Training acc over epoch: 0.6178\n","---- Validation ----\n","Validation loss: 78.3636\n","Validation acc: 0.5897\n","Time taken: 9.50s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 332.1732, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 334.8843, Accuracy: 0.5391\n","Training loss (for one batch) at step 20: 320.4974, Accuracy: 0.5438\n","Training loss (for one batch) at step 30: 324.6808, Accuracy: 0.5710\n","Training loss (for one batch) at step 40: 322.6401, Accuracy: 0.5885\n","Training loss (for one batch) at step 50: 299.5106, Accuracy: 0.6006\n","Training loss (for one batch) at step 60: 297.2415, Accuracy: 0.6141\n","Training loss (for one batch) at step 70: 294.1843, Accuracy: 0.6254\n","Training loss (for one batch) at step 80: 316.2818, Accuracy: 0.6274\n","Training loss (for one batch) at step 90: 323.3705, Accuracy: 0.6251\n","Training loss (for one batch) at step 100: 336.1748, Accuracy: 0.6206\n","Training loss (for one batch) at step 110: 318.0150, Accuracy: 0.6169\n","Training loss (for one batch) at step 120: 311.5627, Accuracy: 0.6178\n","Training loss (for one batch) at step 130: 318.1554, Accuracy: 0.6207\n","Training loss (for one batch) at step 140: 313.7698, Accuracy: 0.6207\n","---- Training ----\n","Training loss: 281.5928\n","Training acc over epoch: 0.6188\n","---- Validation ----\n","Validation loss: 87.0111\n","Validation acc: 0.6032\n","Time taken: 9.54s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 329.3197, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 334.5826, Accuracy: 0.5555\n","Training loss (for one batch) at step 20: 327.0245, Accuracy: 0.5619\n","Training loss (for one batch) at step 30: 313.3764, Accuracy: 0.5852\n","Training loss (for one batch) at step 40: 315.4128, Accuracy: 0.6054\n","Training loss (for one batch) at step 50: 308.0953, Accuracy: 0.6171\n","Training loss (for one batch) at step 60: 295.9008, Accuracy: 0.6261\n","Training loss (for one batch) at step 70: 295.5240, Accuracy: 0.6342\n","Training loss (for one batch) at step 80: 307.1095, Accuracy: 0.6338\n","Training loss (for one batch) at step 90: 309.1376, Accuracy: 0.6280\n","Training loss (for one batch) at step 100: 327.7009, Accuracy: 0.6211\n","Training loss (for one batch) at step 110: 316.2349, Accuracy: 0.6177\n","Training loss (for one batch) at step 120: 303.9694, Accuracy: 0.6186\n","Training loss (for one batch) at step 130: 301.6635, Accuracy: 0.6205\n","Training loss (for one batch) at step 140: 314.1126, Accuracy: 0.6192\n","---- Training ----\n","Training loss: 284.2177\n","Training acc over epoch: 0.6194\n","---- Validation ----\n","Validation loss: 79.3305\n","Validation acc: 0.5935\n","Time taken: 9.80s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 320.0406, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 331.9732, Accuracy: 0.5536\n","Training loss (for one batch) at step 20: 329.5271, Accuracy: 0.5595\n","Training loss (for one batch) at step 30: 292.6904, Accuracy: 0.5890\n","Training loss (for one batch) at step 40: 302.5144, Accuracy: 0.6098\n","Training loss (for one batch) at step 50: 298.0904, Accuracy: 0.6227\n","Training loss (for one batch) at step 60: 296.3739, Accuracy: 0.6313\n","Training loss (for one batch) at step 70: 295.4894, Accuracy: 0.6399\n","Training loss (for one batch) at step 80: 319.0489, Accuracy: 0.6414\n","Training loss (for one batch) at step 90: 314.9348, Accuracy: 0.6356\n","Training loss (for one batch) at step 100: 316.9887, Accuracy: 0.6267\n","Training loss (for one batch) at step 110: 315.6290, Accuracy: 0.6205\n","Training loss (for one batch) at step 120: 303.4865, Accuracy: 0.6211\n","Training loss (for one batch) at step 130: 314.1294, Accuracy: 0.6246\n","Training loss (for one batch) at step 140: 315.2397, Accuracy: 0.6266\n","---- Training ----\n","Training loss: 270.0946\n","Training acc over epoch: 0.6243\n","---- Validation ----\n","Validation loss: 83.5978\n","Validation acc: 0.5830\n","Time taken: 9.61s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 321.6212, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 327.2219, Accuracy: 0.5564\n","Training loss (for one batch) at step 20: 313.7384, Accuracy: 0.5705\n","Training loss (for one batch) at step 30: 306.3058, Accuracy: 0.5942\n","Training loss (for one batch) at step 40: 301.4841, Accuracy: 0.6117\n","Training loss (for one batch) at step 50: 308.4294, Accuracy: 0.6237\n","Training loss (for one batch) at step 60: 302.1024, Accuracy: 0.6338\n","Training loss (for one batch) at step 70: 284.1145, Accuracy: 0.6415\n","Training loss (for one batch) at step 80: 313.8561, Accuracy: 0.6447\n","Training loss (for one batch) at step 90: 307.9499, Accuracy: 0.6390\n","Training loss (for one batch) at step 100: 327.6041, Accuracy: 0.6277\n","Training loss (for one batch) at step 110: 309.4636, Accuracy: 0.6214\n","Training loss (for one batch) at step 120: 306.8252, Accuracy: 0.6231\n","Training loss (for one batch) at step 130: 301.2024, Accuracy: 0.6250\n","Training loss (for one batch) at step 140: 313.4564, Accuracy: 0.6260\n","---- Training ----\n","Training loss: 281.4516\n","Training acc over epoch: 0.6254\n","---- Validation ----\n","Validation loss: 79.6046\n","Validation acc: 0.5943\n","Time taken: 9.67s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 326.3247, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 312.7434, Accuracy: 0.5518\n","Training loss (for one batch) at step 20: 318.6377, Accuracy: 0.5624\n","Training loss (for one batch) at step 30: 314.8995, Accuracy: 0.5881\n","Training loss (for one batch) at step 40: 307.9532, Accuracy: 0.6032\n","Training loss (for one batch) at step 50: 287.0857, Accuracy: 0.6155\n","Training loss (for one batch) at step 60: 300.3078, Accuracy: 0.6251\n","Training loss (for one batch) at step 70: 291.2133, Accuracy: 0.6369\n","Training loss (for one batch) at step 80: 310.2600, Accuracy: 0.6396\n","Training loss (for one batch) at step 90: 317.0926, Accuracy: 0.6341\n","Training loss (for one batch) at step 100: 316.6334, Accuracy: 0.6270\n","Training loss (for one batch) at step 110: 310.7814, Accuracy: 0.6205\n","Training loss (for one batch) at step 120: 301.6741, Accuracy: 0.6212\n","Training loss (for one batch) at step 130: 301.6338, Accuracy: 0.6248\n","Training loss (for one batch) at step 140: 316.8077, Accuracy: 0.6256\n","---- Training ----\n","Training loss: 266.5710\n","Training acc over epoch: 0.6247\n","---- Validation ----\n","Validation loss: 78.1871\n","Validation acc: 0.5965\n","Time taken: 9.65s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 332.1686, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 316.4189, Accuracy: 0.5273\n","Training loss (for one batch) at step 20: 301.6212, Accuracy: 0.5571\n","Training loss (for one batch) at step 30: 301.0417, Accuracy: 0.5903\n","Training loss (for one batch) at step 40: 307.0003, Accuracy: 0.6056\n","Training loss (for one batch) at step 50: 291.9081, Accuracy: 0.6196\n","Training loss (for one batch) at step 60: 298.9631, Accuracy: 0.6292\n","Training loss (for one batch) at step 70: 294.3823, Accuracy: 0.6418\n","Training loss (for one batch) at step 80: 312.8175, Accuracy: 0.6399\n","Training loss (for one batch) at step 90: 313.3578, Accuracy: 0.6323\n","Training loss (for one batch) at step 100: 316.8124, Accuracy: 0.6256\n","Training loss (for one batch) at step 110: 311.1828, Accuracy: 0.6215\n","Training loss (for one batch) at step 120: 315.0651, Accuracy: 0.6226\n","Training loss (for one batch) at step 130: 308.8637, Accuracy: 0.6246\n","Training loss (for one batch) at step 140: 308.1057, Accuracy: 0.6236\n","---- Training ----\n","Training loss: 266.3328\n","Training acc over epoch: 0.6239\n","---- Validation ----\n","Validation loss: 84.2832\n","Validation acc: 0.5854\n","Time taken: 9.64s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 325.0359, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 319.0272, Accuracy: 0.5545\n","Training loss (for one batch) at step 20: 311.4429, Accuracy: 0.5538\n","Training loss (for one batch) at step 30: 304.9525, Accuracy: 0.5871\n","Training loss (for one batch) at step 40: 296.3716, Accuracy: 0.6083\n","Training loss (for one batch) at step 50: 292.7146, Accuracy: 0.6218\n","Training loss (for one batch) at step 60: 285.4137, Accuracy: 0.6311\n","Training loss (for one batch) at step 70: 282.3065, Accuracy: 0.6406\n","Training loss (for one batch) at step 80: 308.3951, Accuracy: 0.6432\n","Training loss (for one batch) at step 90: 316.3795, Accuracy: 0.6357\n","Training loss (for one batch) at step 100: 319.4667, Accuracy: 0.6253\n","Training loss (for one batch) at step 110: 305.9228, Accuracy: 0.6214\n","Training loss (for one batch) at step 120: 306.2180, Accuracy: 0.6240\n","Training loss (for one batch) at step 130: 290.8265, Accuracy: 0.6264\n","Training loss (for one batch) at step 140: 309.8350, Accuracy: 0.6277\n","---- Training ----\n","Training loss: 278.4982\n","Training acc over epoch: 0.6273\n","---- Validation ----\n","Validation loss: 85.0694\n","Validation acc: 0.5892\n","Time taken: 9.60s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 320.7423, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 314.9821, Accuracy: 0.5273\n","Training loss (for one batch) at step 20: 301.8580, Accuracy: 0.5486\n","Training loss (for one batch) at step 30: 291.4719, Accuracy: 0.5845\n","Training loss (for one batch) at step 40: 299.9263, Accuracy: 0.6063\n","Training loss (for one batch) at step 50: 296.9459, Accuracy: 0.6214\n","Training loss (for one batch) at step 60: 287.2977, Accuracy: 0.6290\n","Training loss (for one batch) at step 70: 300.8453, Accuracy: 0.6424\n","Training loss (for one batch) at step 80: 316.5063, Accuracy: 0.6457\n","Training loss (for one batch) at step 90: 324.8528, Accuracy: 0.6386\n","Training loss (for one batch) at step 100: 318.8544, Accuracy: 0.6300\n","Training loss (for one batch) at step 110: 307.6680, Accuracy: 0.6236\n","Training loss (for one batch) at step 120: 299.8056, Accuracy: 0.6245\n","Training loss (for one batch) at step 130: 303.8525, Accuracy: 0.6256\n","Training loss (for one batch) at step 140: 300.2617, Accuracy: 0.6275\n","---- Training ----\n","Training loss: 267.1257\n","Training acc over epoch: 0.6259\n","---- Validation ----\n","Validation loss: 84.3406\n","Validation acc: 0.5892\n","Time taken: 9.66s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 314.7524, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 322.7049, Accuracy: 0.5282\n","Training loss (for one batch) at step 20: 320.1407, Accuracy: 0.5376\n","Training loss (for one batch) at step 30: 307.6249, Accuracy: 0.5794\n","Training loss (for one batch) at step 40: 290.2604, Accuracy: 0.6022\n","Training loss (for one batch) at step 50: 301.5674, Accuracy: 0.6139\n","Training loss (for one batch) at step 60: 276.3777, Accuracy: 0.6274\n","Training loss (for one batch) at step 70: 279.7325, Accuracy: 0.6379\n","Training loss (for one batch) at step 80: 296.2538, Accuracy: 0.6417\n","Training loss (for one batch) at step 90: 300.9740, Accuracy: 0.6359\n","Training loss (for one batch) at step 100: 316.1948, Accuracy: 0.6264\n","Training loss (for one batch) at step 110: 313.5900, Accuracy: 0.6214\n","Training loss (for one batch) at step 120: 314.5559, Accuracy: 0.6233\n","Training loss (for one batch) at step 130: 299.7198, Accuracy: 0.6264\n","Training loss (for one batch) at step 140: 297.4170, Accuracy: 0.6274\n","---- Training ----\n","Training loss: 270.5307\n","Training acc over epoch: 0.6253\n","---- Validation ----\n","Validation loss: 86.7105\n","Validation acc: 0.5908\n","Time taken: 9.64s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 322.9389, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 312.7032, Accuracy: 0.5191\n","Training loss (for one batch) at step 20: 301.6788, Accuracy: 0.5395\n","Training loss (for one batch) at step 30: 300.2454, Accuracy: 0.5781\n","Training loss (for one batch) at step 40: 301.8859, Accuracy: 0.6010\n","Training loss (for one batch) at step 50: 296.2952, Accuracy: 0.6175\n","Training loss (for one batch) at step 60: 291.6707, Accuracy: 0.6303\n","Training loss (for one batch) at step 70: 278.5273, Accuracy: 0.6389\n","Training loss (for one batch) at step 80: 315.0749, Accuracy: 0.6411\n","Training loss (for one batch) at step 90: 314.3350, Accuracy: 0.6357\n","Training loss (for one batch) at step 100: 306.9407, Accuracy: 0.6268\n","Training loss (for one batch) at step 110: 298.6956, Accuracy: 0.6191\n","Training loss (for one batch) at step 120: 279.1562, Accuracy: 0.6211\n","Training loss (for one batch) at step 130: 300.5881, Accuracy: 0.6247\n","Training loss (for one batch) at step 140: 305.7476, Accuracy: 0.6243\n","---- Training ----\n","Training loss: 272.0098\n","Training acc over epoch: 0.6245\n","---- Validation ----\n","Validation loss: 78.4432\n","Validation acc: 0.6018\n","Time taken: 9.56s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 305.8120, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 305.9633, Accuracy: 0.5364\n","Training loss (for one batch) at step 20: 306.0687, Accuracy: 0.5438\n","Training loss (for one batch) at step 30: 292.5207, Accuracy: 0.5784\n","Training loss (for one batch) at step 40: 302.4907, Accuracy: 0.6000\n","Training loss (for one batch) at step 50: 290.0578, Accuracy: 0.6165\n","Training loss (for one batch) at step 60: 281.4765, Accuracy: 0.6269\n","Training loss (for one batch) at step 70: 305.1261, Accuracy: 0.6365\n","Training loss (for one batch) at step 80: 302.3328, Accuracy: 0.6381\n","Training loss (for one batch) at step 90: 308.7190, Accuracy: 0.6290\n","Training loss (for one batch) at step 100: 305.7861, Accuracy: 0.6201\n","Training loss (for one batch) at step 110: 283.7094, Accuracy: 0.6163\n","Training loss (for one batch) at step 120: 289.8003, Accuracy: 0.6183\n","Training loss (for one batch) at step 130: 288.5642, Accuracy: 0.6231\n","Training loss (for one batch) at step 140: 307.9019, Accuracy: 0.6241\n","---- Training ----\n","Training loss: 269.0868\n","Training acc over epoch: 0.6217\n","---- Validation ----\n","Validation loss: 77.5834\n","Validation acc: 0.5895\n","Time taken: 9.62s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 316.2838, Accuracy: 0.3900\n","Training loss (for one batch) at step 10: 304.1991, Accuracy: 0.5018\n","Training loss (for one batch) at step 20: 280.8487, Accuracy: 0.5319\n","Training loss (for one batch) at step 30: 284.9582, Accuracy: 0.5713\n","Training loss (for one batch) at step 40: 292.1755, Accuracy: 0.5963\n","Training loss (for one batch) at step 50: 280.7326, Accuracy: 0.6127\n","Training loss (for one batch) at step 60: 293.6279, Accuracy: 0.6267\n","Training loss (for one batch) at step 70: 290.9435, Accuracy: 0.6399\n","Training loss (for one batch) at step 80: 304.1638, Accuracy: 0.6436\n","Training loss (for one batch) at step 90: 303.1655, Accuracy: 0.6376\n","Training loss (for one batch) at step 100: 295.3298, Accuracy: 0.6285\n","Training loss (for one batch) at step 110: 297.6026, Accuracy: 0.6240\n","Training loss (for one batch) at step 120: 310.7323, Accuracy: 0.6250\n","Training loss (for one batch) at step 130: 291.3141, Accuracy: 0.6273\n","Training loss (for one batch) at step 140: 293.1981, Accuracy: 0.6289\n","---- Training ----\n","Training loss: 266.6649\n","Training acc over epoch: 0.6277\n","---- Validation ----\n","Validation loss: 84.9495\n","Validation acc: 0.5946\n","Time taken: 9.75s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 313.8360, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 302.2629, Accuracy: 0.5218\n","Training loss (for one batch) at step 20: 298.5666, Accuracy: 0.5519\n","Training loss (for one batch) at step 30: 277.2030, Accuracy: 0.5803\n","Training loss (for one batch) at step 40: 285.7968, Accuracy: 0.6054\n","Training loss (for one batch) at step 50: 281.8470, Accuracy: 0.6214\n","Training loss (for one batch) at step 60: 277.7239, Accuracy: 0.6325\n","Training loss (for one batch) at step 70: 284.9247, Accuracy: 0.6420\n","Training loss (for one batch) at step 80: 304.8366, Accuracy: 0.6433\n","Training loss (for one batch) at step 90: 297.6397, Accuracy: 0.6345\n","Training loss (for one batch) at step 100: 301.4894, Accuracy: 0.6260\n","Training loss (for one batch) at step 110: 303.2151, Accuracy: 0.6213\n","Training loss (for one batch) at step 120: 293.3024, Accuracy: 0.6226\n","Training loss (for one batch) at step 130: 292.6282, Accuracy: 0.6257\n","Training loss (for one batch) at step 140: 286.2220, Accuracy: 0.6282\n","---- Training ----\n","Training loss: 270.1676\n","Training acc over epoch: 0.6256\n","---- Validation ----\n","Validation loss: 88.8768\n","Validation acc: 0.5948\n","Time taken: 9.55s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 307.7512, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 308.3223, Accuracy: 0.5191\n","Training loss (for one batch) at step 20: 284.3843, Accuracy: 0.5386\n","Training loss (for one batch) at step 30: 283.7475, Accuracy: 0.5742\n","Training loss (for one batch) at step 40: 295.0410, Accuracy: 0.6000\n","Training loss (for one batch) at step 50: 274.4668, Accuracy: 0.6178\n","Training loss (for one batch) at step 60: 280.0061, Accuracy: 0.6326\n","Training loss (for one batch) at step 70: 277.3151, Accuracy: 0.6421\n","Training loss (for one batch) at step 80: 286.9111, Accuracy: 0.6464\n","Training loss (for one batch) at step 90: 304.3363, Accuracy: 0.6390\n","Training loss (for one batch) at step 100: 298.7474, Accuracy: 0.6300\n","Training loss (for one batch) at step 110: 301.8081, Accuracy: 0.6236\n","Training loss (for one batch) at step 120: 286.7036, Accuracy: 0.6258\n","Training loss (for one batch) at step 130: 280.1679, Accuracy: 0.6273\n","Training loss (for one batch) at step 140: 290.9360, Accuracy: 0.6265\n","---- Training ----\n","Training loss: 254.8941\n","Training acc over epoch: 0.6261\n","---- Validation ----\n","Validation loss: 82.1027\n","Validation acc: 0.5924\n","Time taken: 9.74s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 312.2687, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 320.5561, Accuracy: 0.5136\n","Training loss (for one batch) at step 20: 288.9225, Accuracy: 0.5371\n","Training loss (for one batch) at step 30: 283.4482, Accuracy: 0.5726\n","Training loss (for one batch) at step 40: 273.8392, Accuracy: 0.6051\n","Training loss (for one batch) at step 50: 280.4291, Accuracy: 0.6229\n","Training loss (for one batch) at step 60: 264.8219, Accuracy: 0.6374\n","Training loss (for one batch) at step 70: 284.6586, Accuracy: 0.6480\n","Training loss (for one batch) at step 80: 297.3870, Accuracy: 0.6506\n","Training loss (for one batch) at step 90: 297.2062, Accuracy: 0.6410\n","Training loss (for one batch) at step 100: 295.2170, Accuracy: 0.6317\n","Training loss (for one batch) at step 110: 290.8698, Accuracy: 0.6257\n","Training loss (for one batch) at step 120: 296.2233, Accuracy: 0.6265\n","Training loss (for one batch) at step 130: 289.4589, Accuracy: 0.6292\n","Training loss (for one batch) at step 140: 278.0916, Accuracy: 0.6302\n","---- Training ----\n","Training loss: 254.0408\n","Training acc over epoch: 0.6303\n","---- Validation ----\n","Validation loss: 87.3470\n","Validation acc: 0.5895\n","Time taken: 9.70s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 307.3115, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 302.1001, Accuracy: 0.5036\n","Training loss (for one batch) at step 20: 281.6644, Accuracy: 0.5371\n","Training loss (for one batch) at step 30: 268.8239, Accuracy: 0.5752\n","Training loss (for one batch) at step 40: 269.2453, Accuracy: 0.6061\n","Training loss (for one batch) at step 50: 273.6526, Accuracy: 0.6163\n","Training loss (for one batch) at step 60: 274.8057, Accuracy: 0.6307\n","Training loss (for one batch) at step 70: 258.9061, Accuracy: 0.6430\n","Training loss (for one batch) at step 80: 290.3039, Accuracy: 0.6452\n","Training loss (for one batch) at step 90: 293.5678, Accuracy: 0.6356\n","Training loss (for one batch) at step 100: 306.8145, Accuracy: 0.6234\n","Training loss (for one batch) at step 110: 302.7083, Accuracy: 0.6175\n","Training loss (for one batch) at step 120: 294.2794, Accuracy: 0.6217\n","Training loss (for one batch) at step 130: 299.3943, Accuracy: 0.6237\n","Training loss (for one batch) at step 140: 302.1870, Accuracy: 0.6250\n","---- Training ----\n","Training loss: 254.1016\n","Training acc over epoch: 0.6247\n","---- Validation ----\n","Validation loss: 93.1556\n","Validation acc: 0.5938\n","Time taken: 9.58s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 306.5435, Accuracy: 0.5000\n","Training loss (for one batch) at step 10: 305.6064, Accuracy: 0.5118\n","Training loss (for one batch) at step 20: 285.8000, Accuracy: 0.5405\n","Training loss (for one batch) at step 30: 268.7014, Accuracy: 0.5777\n","Training loss (for one batch) at step 40: 281.3842, Accuracy: 0.6051\n","Training loss (for one batch) at step 50: 270.4543, Accuracy: 0.6184\n","Training loss (for one batch) at step 60: 283.4461, Accuracy: 0.6330\n","Training loss (for one batch) at step 70: 277.3074, Accuracy: 0.6461\n","Training loss (for one batch) at step 80: 292.7330, Accuracy: 0.6481\n","Training loss (for one batch) at step 90: 293.0738, Accuracy: 0.6429\n","Training loss (for one batch) at step 100: 293.0630, Accuracy: 0.6325\n","Training loss (for one batch) at step 110: 296.7886, Accuracy: 0.6273\n","Training loss (for one batch) at step 120: 296.9493, Accuracy: 0.6284\n","Training loss (for one batch) at step 130: 282.1498, Accuracy: 0.6308\n","Training loss (for one batch) at step 140: 293.6347, Accuracy: 0.6312\n","---- Training ----\n","Training loss: 269.0294\n","Training acc over epoch: 0.6296\n","---- Validation ----\n","Validation loss: 79.5387\n","Validation acc: 0.5841\n","Time taken: 9.51s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 297.9299, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 299.1632, Accuracy: 0.5091\n","Training loss (for one batch) at step 20: 298.8887, Accuracy: 0.5386\n","Training loss (for one batch) at step 30: 277.0310, Accuracy: 0.5848\n","Training loss (for one batch) at step 40: 291.5262, Accuracy: 0.6105\n","Training loss (for one batch) at step 50: 271.7563, Accuracy: 0.6290\n","Training loss (for one batch) at step 60: 265.2050, Accuracy: 0.6400\n","Training loss (for one batch) at step 70: 270.4578, Accuracy: 0.6521\n","Training loss (for one batch) at step 80: 298.1675, Accuracy: 0.6510\n","Training loss (for one batch) at step 90: 304.6040, Accuracy: 0.6437\n","Training loss (for one batch) at step 100: 300.1378, Accuracy: 0.6341\n","Training loss (for one batch) at step 110: 302.1991, Accuracy: 0.6269\n","Training loss (for one batch) at step 120: 281.6064, Accuracy: 0.6275\n","Training loss (for one batch) at step 130: 277.1111, Accuracy: 0.6317\n","Training loss (for one batch) at step 140: 294.5269, Accuracy: 0.6321\n","---- Training ----\n","Training loss: 263.1607\n","Training acc over epoch: 0.6306\n","---- Validation ----\n","Validation loss: 91.1480\n","Validation acc: 0.5905\n","Time taken: 10.46s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 307.5778, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 307.4785, Accuracy: 0.5000\n","Training loss (for one batch) at step 20: 285.9478, Accuracy: 0.5295\n","Training loss (for one batch) at step 30: 289.2993, Accuracy: 0.5690\n","Training loss (for one batch) at step 40: 269.2287, Accuracy: 0.5954\n","Training loss (for one batch) at step 50: 283.7422, Accuracy: 0.6116\n","Training loss (for one batch) at step 60: 259.3986, Accuracy: 0.6274\n","Training loss (for one batch) at step 70: 270.3216, Accuracy: 0.6406\n","Training loss (for one batch) at step 80: 287.7792, Accuracy: 0.6412\n","Training loss (for one batch) at step 90: 292.5292, Accuracy: 0.6325\n","Training loss (for one batch) at step 100: 289.6953, Accuracy: 0.6235\n","Training loss (for one batch) at step 110: 285.6687, Accuracy: 0.6189\n","Training loss (for one batch) at step 120: 287.2210, Accuracy: 0.6183\n","Training loss (for one batch) at step 130: 285.2254, Accuracy: 0.6219\n","Training loss (for one batch) at step 140: 290.3526, Accuracy: 0.6223\n","---- Training ----\n","Training loss: 246.0985\n","Training acc over epoch: 0.6220\n","---- Validation ----\n","Validation loss: 88.5749\n","Validation acc: 0.5922\n","Time taken: 9.53s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 299.9457, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 301.1442, Accuracy: 0.4955\n","Training loss (for one batch) at step 20: 295.5125, Accuracy: 0.5286\n","Training loss (for one batch) at step 30: 274.5476, Accuracy: 0.5645\n","Training loss (for one batch) at step 40: 279.6927, Accuracy: 0.5963\n","Training loss (for one batch) at step 50: 276.4726, Accuracy: 0.6165\n","Training loss (for one batch) at step 60: 262.7413, Accuracy: 0.6272\n","Training loss (for one batch) at step 70: 257.4579, Accuracy: 0.6424\n","Training loss (for one batch) at step 80: 285.9587, Accuracy: 0.6416\n","Training loss (for one batch) at step 90: 298.1818, Accuracy: 0.6316\n","Training loss (for one batch) at step 100: 290.7849, Accuracy: 0.6243\n","Training loss (for one batch) at step 110: 286.4691, Accuracy: 0.6187\n","Training loss (for one batch) at step 120: 274.4770, Accuracy: 0.6220\n","Training loss (for one batch) at step 130: 280.4572, Accuracy: 0.6247\n","Training loss (for one batch) at step 140: 272.7349, Accuracy: 0.6262\n","---- Training ----\n","Training loss: 248.5790\n","Training acc over epoch: 0.6245\n","---- Validation ----\n","Validation loss: 89.1557\n","Validation acc: 0.5798\n","Time taken: 9.62s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 311.3182, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 314.3186, Accuracy: 0.5127\n","Training loss (for one batch) at step 20: 279.9480, Accuracy: 0.5267\n","Training loss (for one batch) at step 30: 276.3713, Accuracy: 0.5684\n","Training loss (for one batch) at step 40: 259.7043, Accuracy: 0.5993\n","Training loss (for one batch) at step 50: 280.6012, Accuracy: 0.6200\n","Training loss (for one batch) at step 60: 270.3357, Accuracy: 0.6354\n","Training loss (for one batch) at step 70: 267.1253, Accuracy: 0.6470\n","Training loss (for one batch) at step 80: 284.1635, Accuracy: 0.6499\n","Training loss (for one batch) at step 90: 292.7099, Accuracy: 0.6386\n","Training loss (for one batch) at step 100: 306.7687, Accuracy: 0.6281\n","Training loss (for one batch) at step 110: 298.9702, Accuracy: 0.6247\n","Training loss (for one batch) at step 120: 279.5592, Accuracy: 0.6281\n","Training loss (for one batch) at step 130: 273.9386, Accuracy: 0.6298\n","Training loss (for one batch) at step 140: 298.4814, Accuracy: 0.6303\n","---- Training ----\n","Training loss: 243.4813\n","Training acc over epoch: 0.6286\n","---- Validation ----\n","Validation loss: 95.7832\n","Validation acc: 0.5825\n","Time taken: 9.52s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 302.6979, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 286.3472, Accuracy: 0.4973\n","Training loss (for one batch) at step 20: 274.9455, Accuracy: 0.5362\n","Training loss (for one batch) at step 30: 262.4268, Accuracy: 0.5726\n","Training loss (for one batch) at step 40: 276.2912, Accuracy: 0.6027\n","Training loss (for one batch) at step 50: 262.4818, Accuracy: 0.6196\n","Training loss (for one batch) at step 60: 284.4233, Accuracy: 0.6351\n","Training loss (for one batch) at step 70: 262.9029, Accuracy: 0.6479\n","Training loss (for one batch) at step 80: 274.6386, Accuracy: 0.6474\n","Training loss (for one batch) at step 90: 279.8882, Accuracy: 0.6395\n","Training loss (for one batch) at step 100: 290.9641, Accuracy: 0.6298\n","Training loss (for one batch) at step 110: 294.3752, Accuracy: 0.6222\n","Training loss (for one batch) at step 120: 297.9754, Accuracy: 0.6262\n","Training loss (for one batch) at step 130: 269.9886, Accuracy: 0.6309\n","Training loss (for one batch) at step 140: 281.3754, Accuracy: 0.6313\n","---- Training ----\n","Training loss: 243.8163\n","Training acc over epoch: 0.6293\n","---- Validation ----\n","Validation loss: 87.2727\n","Validation acc: 0.5790\n","Time taken: 10.14s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.5959\n","Validation AUC: 0.5979\n","Validation Balanced_ACC: 0.2784\n","Validation MI: 0.0493\n","Validation Normalized MI: 0.0718\n","Validation Adjusted MI: 0.0718\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 510.7460, Accuracy: 0.4600\n","Training loss (for one batch) at step 10: 490.0892, Accuracy: 0.4682\n","Training loss (for one batch) at step 20: 446.7142, Accuracy: 0.4943\n","Training loss (for one batch) at step 30: 455.0324, Accuracy: 0.5061\n","Training loss (for one batch) at step 40: 470.2642, Accuracy: 0.5110\n","Training loss (for one batch) at step 50: 435.9034, Accuracy: 0.5061\n","Training loss (for one batch) at step 60: 427.1537, Accuracy: 0.5100\n","Training loss (for one batch) at step 70: 475.5691, Accuracy: 0.5114\n","Training loss (for one batch) at step 80: 436.4732, Accuracy: 0.5106\n","Training loss (for one batch) at step 90: 431.8240, Accuracy: 0.5104\n","Training loss (for one batch) at step 100: 424.7387, Accuracy: 0.5089\n","Training loss (for one batch) at step 110: 424.6738, Accuracy: 0.5086\n","Training loss (for one batch) at step 120: 409.3933, Accuracy: 0.5081\n","Training loss (for one batch) at step 130: 397.1188, Accuracy: 0.5078\n","Training loss (for one batch) at step 140: 413.7980, Accuracy: 0.5078\n","---- Training ----\n","Training loss: 355.5565\n","Training acc over epoch: 0.5069\n","---- Validation ----\n","Validation loss: 78.3123\n","Validation acc: 0.5134\n","Time taken: 55.08s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 423.8087, Accuracy: 0.4400\n","Training loss (for one batch) at step 10: 388.4330, Accuracy: 0.5100\n","Training loss (for one batch) at step 20: 406.4615, Accuracy: 0.5062\n","Training loss (for one batch) at step 30: 399.9499, Accuracy: 0.5113\n","Training loss (for one batch) at step 40: 389.8984, Accuracy: 0.5083\n","Training loss (for one batch) at step 50: 408.2895, Accuracy: 0.5131\n","Training loss (for one batch) at step 60: 390.5297, Accuracy: 0.5120\n","Training loss (for one batch) at step 70: 381.1076, Accuracy: 0.5108\n","Training loss (for one batch) at step 80: 380.2352, Accuracy: 0.5100\n","Training loss (for one batch) at step 90: 377.7240, Accuracy: 0.5123\n","Training loss (for one batch) at step 100: 392.5083, Accuracy: 0.5127\n","Training loss (for one batch) at step 110: 368.4059, Accuracy: 0.5127\n","Training loss (for one batch) at step 120: 377.3509, Accuracy: 0.5107\n","Training loss (for one batch) at step 130: 391.4637, Accuracy: 0.5099\n","Training loss (for one batch) at step 140: 394.3664, Accuracy: 0.5096\n","---- Training ----\n","Training loss: 334.3082\n","Training acc over epoch: 0.5080\n","---- Validation ----\n","Validation loss: 76.6975\n","Validation acc: 0.5435\n","Time taken: 48.34s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 368.5896, Accuracy: 0.4700\n","Training loss (for one batch) at step 10: 387.5765, Accuracy: 0.5364\n","Training loss (for one batch) at step 20: 375.5999, Accuracy: 0.5348\n","Training loss (for one batch) at step 30: 378.1287, Accuracy: 0.5290\n","Training loss (for one batch) at step 40: 370.4348, Accuracy: 0.5217\n","Training loss (for one batch) at step 50: 370.0974, Accuracy: 0.5267\n","Training loss (for one batch) at step 60: 361.0314, Accuracy: 0.5223\n","Training loss (for one batch) at step 70: 369.2986, Accuracy: 0.5217\n","Training loss (for one batch) at step 80: 377.8754, Accuracy: 0.5219\n","Training loss (for one batch) at step 90: 375.6799, Accuracy: 0.5240\n","Training loss (for one batch) at step 100: 372.3833, Accuracy: 0.5228\n","Training loss (for one batch) at step 110: 373.3389, Accuracy: 0.5212\n","Training loss (for one batch) at step 120: 371.4557, Accuracy: 0.5192\n","Training loss (for one batch) at step 130: 378.5492, Accuracy: 0.5185\n","Training loss (for one batch) at step 140: 365.2657, Accuracy: 0.5193\n","---- Training ----\n","Training loss: 320.1938\n","Training acc over epoch: 0.5187\n","---- Validation ----\n","Validation loss: 75.8529\n","Validation acc: 0.5253\n","Time taken: 10.02s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 368.8414, Accuracy: 0.4600\n","Training loss (for one batch) at step 10: 374.7054, Accuracy: 0.5155\n","Training loss (for one batch) at step 20: 373.6733, Accuracy: 0.5114\n","Training loss (for one batch) at step 30: 358.9207, Accuracy: 0.5061\n","Training loss (for one batch) at step 40: 362.3766, Accuracy: 0.5027\n","Training loss (for one batch) at step 50: 373.9600, Accuracy: 0.5049\n","Training loss (for one batch) at step 60: 371.4502, Accuracy: 0.5046\n","Training loss (for one batch) at step 70: 365.6354, Accuracy: 0.5092\n","Training loss (for one batch) at step 80: 356.1190, Accuracy: 0.5119\n","Training loss (for one batch) at step 90: 363.0635, Accuracy: 0.5148\n","Training loss (for one batch) at step 100: 376.1284, Accuracy: 0.5177\n","Training loss (for one batch) at step 110: 363.8564, Accuracy: 0.5159\n","Training loss (for one batch) at step 120: 359.5446, Accuracy: 0.5167\n","Training loss (for one batch) at step 130: 376.8338, Accuracy: 0.5166\n","Training loss (for one batch) at step 140: 363.8885, Accuracy: 0.5149\n","---- Training ----\n","Training loss: 327.1801\n","Training acc over epoch: 0.5156\n","---- Validation ----\n","Validation loss: 76.8289\n","Validation acc: 0.5618\n","Time taken: 36.29s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 362.1235, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 357.0388, Accuracy: 0.5445\n","Training loss (for one batch) at step 20: 353.2173, Accuracy: 0.5333\n","Training loss (for one batch) at step 30: 355.9639, Accuracy: 0.5235\n","Training loss (for one batch) at step 40: 362.3733, Accuracy: 0.5161\n","Training loss (for one batch) at step 50: 363.1742, Accuracy: 0.5169\n","Training loss (for one batch) at step 60: 357.2323, Accuracy: 0.5175\n","Training loss (for one batch) at step 70: 367.8877, Accuracy: 0.5176\n","Training loss (for one batch) at step 80: 359.1698, Accuracy: 0.5170\n","Training loss (for one batch) at step 90: 358.2529, Accuracy: 0.5203\n","Training loss (for one batch) at step 100: 358.8929, Accuracy: 0.5188\n","Training loss (for one batch) at step 110: 358.0782, Accuracy: 0.5168\n","Training loss (for one batch) at step 120: 369.2930, Accuracy: 0.5149\n","Training loss (for one batch) at step 130: 352.9292, Accuracy: 0.5132\n","Training loss (for one batch) at step 140: 355.6935, Accuracy: 0.5115\n","---- Training ----\n","Training loss: 311.3877\n","Training acc over epoch: 0.5114\n","---- Validation ----\n","Validation loss: 76.1066\n","Validation acc: 0.5304\n","Time taken: 12.33s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 353.8874, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 352.2919, Accuracy: 0.5045\n","Training loss (for one batch) at step 20: 354.0441, Accuracy: 0.5057\n","Training loss (for one batch) at step 30: 353.9929, Accuracy: 0.5048\n","Training loss (for one batch) at step 40: 355.2100, Accuracy: 0.5010\n","Training loss (for one batch) at step 50: 357.3354, Accuracy: 0.4996\n","Training loss (for one batch) at step 60: 351.6045, Accuracy: 0.5046\n","Training loss (for one batch) at step 70: 356.5888, Accuracy: 0.5092\n","Training loss (for one batch) at step 80: 352.5685, Accuracy: 0.5138\n","Training loss (for one batch) at step 90: 357.5508, Accuracy: 0.5144\n","Training loss (for one batch) at step 100: 356.5230, Accuracy: 0.5166\n","Training loss (for one batch) at step 110: 350.5423, Accuracy: 0.5160\n","Training loss (for one batch) at step 120: 350.8868, Accuracy: 0.5156\n","Training loss (for one batch) at step 130: 358.2411, Accuracy: 0.5189\n","Training loss (for one batch) at step 140: 351.6860, Accuracy: 0.5176\n","---- Training ----\n","Training loss: 311.0215\n","Training acc over epoch: 0.5180\n","---- Validation ----\n","Validation loss: 76.4032\n","Validation acc: 0.5406\n","Time taken: 54.95s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 353.6107, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 349.5263, Accuracy: 0.5018\n","Training loss (for one batch) at step 20: 352.6999, Accuracy: 0.5038\n","Training loss (for one batch) at step 30: 361.0659, Accuracy: 0.5135\n","Training loss (for one batch) at step 40: 356.7308, Accuracy: 0.5185\n","Training loss (for one batch) at step 50: 355.8012, Accuracy: 0.5182\n","Training loss (for one batch) at step 60: 350.4518, Accuracy: 0.5175\n","Training loss (for one batch) at step 70: 349.4881, Accuracy: 0.5199\n","Training loss (for one batch) at step 80: 351.3052, Accuracy: 0.5226\n","Training loss (for one batch) at step 90: 353.7389, Accuracy: 0.5253\n","Training loss (for one batch) at step 100: 350.1930, Accuracy: 0.5265\n","Training loss (for one batch) at step 110: 353.0909, Accuracy: 0.5274\n","Training loss (for one batch) at step 120: 353.1088, Accuracy: 0.5287\n","Training loss (for one batch) at step 130: 351.1856, Accuracy: 0.5275\n","Training loss (for one batch) at step 140: 355.2392, Accuracy: 0.5252\n","---- Training ----\n","Training loss: 308.6020\n","Training acc over epoch: 0.5253\n","---- Validation ----\n","Validation loss: 76.4551\n","Validation acc: 0.5865\n","Time taken: 24.62s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 352.1994, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 354.5425, Accuracy: 0.5073\n","Training loss (for one batch) at step 20: 352.1247, Accuracy: 0.5357\n","Training loss (for one batch) at step 30: 349.9040, Accuracy: 0.5290\n","Training loss (for one batch) at step 40: 350.5248, Accuracy: 0.5302\n","Training loss (for one batch) at step 50: 348.6502, Accuracy: 0.5294\n","Training loss (for one batch) at step 60: 352.4284, Accuracy: 0.5230\n","Training loss (for one batch) at step 70: 350.3981, Accuracy: 0.5200\n","Training loss (for one batch) at step 80: 349.7602, Accuracy: 0.5220\n","Training loss (for one batch) at step 90: 351.2935, Accuracy: 0.5255\n","Training loss (for one batch) at step 100: 345.3687, Accuracy: 0.5271\n","Training loss (for one batch) at step 110: 355.3726, Accuracy: 0.5322\n","Training loss (for one batch) at step 120: 346.7810, Accuracy: 0.5330\n","Training loss (for one batch) at step 130: 348.4290, Accuracy: 0.5311\n","Training loss (for one batch) at step 140: 359.5452, Accuracy: 0.5318\n","---- Training ----\n","Training loss: 311.2519\n","Training acc over epoch: 0.5321\n","---- Validation ----\n","Validation loss: 76.3211\n","Validation acc: 0.5425\n","Time taken: 41.54s\n","\n","Start of epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-04 14:09:10.798549: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 881 of 1024\n","2023-02-04 14:09:11.232416: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 350.4502, Accuracy: 0.4800\n","Training loss (for one batch) at step 10: 348.0705, Accuracy: 0.5255\n","Training loss (for one batch) at step 20: 352.5125, Accuracy: 0.5462\n","Training loss (for one batch) at step 30: 347.1598, Accuracy: 0.5448\n","Training loss (for one batch) at step 40: 350.6831, Accuracy: 0.5393\n","Training loss (for one batch) at step 50: 345.7856, Accuracy: 0.5410\n","Training loss (for one batch) at step 60: 352.7996, Accuracy: 0.5395\n","Training loss (for one batch) at step 70: 351.9790, Accuracy: 0.5372\n","Training loss (for one batch) at step 80: 350.0493, Accuracy: 0.5368\n","Training loss (for one batch) at step 90: 353.5868, Accuracy: 0.5388\n","Training loss (for one batch) at step 100: 348.4237, Accuracy: 0.5376\n","Training loss (for one batch) at step 110: 350.2419, Accuracy: 0.5396\n","Training loss (for one batch) at step 120: 350.4424, Accuracy: 0.5394\n","Training loss (for one batch) at step 130: 348.6350, Accuracy: 0.5407\n","Training loss (for one batch) at step 140: 348.7892, Accuracy: 0.5406\n","---- Training ----\n","Training loss: 308.7260\n","Training acc over epoch: 0.5407\n","---- Validation ----\n","Validation loss: 76.2832\n","Validation acc: 0.5704\n","Time taken: 61.13s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 348.1905, Accuracy: 0.4800\n","Training loss (for one batch) at step 10: 344.3516, Accuracy: 0.5391\n","Training loss (for one batch) at step 20: 348.3352, Accuracy: 0.5481\n","Training loss (for one batch) at step 30: 348.8081, Accuracy: 0.5406\n","Training loss (for one batch) at step 40: 348.8705, Accuracy: 0.5373\n","Training loss (for one batch) at step 50: 346.8283, Accuracy: 0.5390\n","Training loss (for one batch) at step 60: 342.9843, Accuracy: 0.5441\n","Training loss (for one batch) at step 70: 351.9957, Accuracy: 0.5449\n","Training loss (for one batch) at step 80: 347.6669, Accuracy: 0.5449\n","Training loss (for one batch) at step 90: 349.8094, Accuracy: 0.5457\n","Training loss (for one batch) at step 100: 348.0587, Accuracy: 0.5478\n","Training loss (for one batch) at step 110: 347.2755, Accuracy: 0.5468\n","Training loss (for one batch) at step 120: 344.8954, Accuracy: 0.5471\n","Training loss (for one batch) at step 130: 347.8976, Accuracy: 0.5456\n","Training loss (for one batch) at step 140: 348.0924, Accuracy: 0.5460\n","---- Training ----\n","Training loss: 304.6773\n","Training acc over epoch: 0.5462\n","---- Validation ----\n","Validation loss: 76.1842\n","Validation acc: 0.5613\n","Time taken: 44.88s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 350.1653, Accuracy: 0.5200\n","Training loss (for one batch) at step 10: 350.4262, Accuracy: 0.5427\n","Training loss (for one batch) at step 20: 347.7266, Accuracy: 0.5538\n","Training loss (for one batch) at step 30: 345.7443, Accuracy: 0.5574\n","Training loss (for one batch) at step 40: 346.7278, Accuracy: 0.5644\n","Training loss (for one batch) at step 50: 346.5714, Accuracy: 0.5618\n","Training loss (for one batch) at step 60: 344.0833, Accuracy: 0.5569\n","Training loss (for one batch) at step 70: 345.3396, Accuracy: 0.5573\n","Training loss (for one batch) at step 80: 346.9688, Accuracy: 0.5579\n","Training loss (for one batch) at step 90: 350.6187, Accuracy: 0.5575\n","Training loss (for one batch) at step 100: 342.6400, Accuracy: 0.5568\n","Training loss (for one batch) at step 110: 351.7459, Accuracy: 0.5545\n","Training loss (for one batch) at step 120: 344.2277, Accuracy: 0.5537\n","Training loss (for one batch) at step 130: 346.3366, Accuracy: 0.5514\n","Training loss (for one batch) at step 140: 345.6794, Accuracy: 0.5496\n","---- Training ----\n","Training loss: 305.9456\n","Training acc over epoch: 0.5508\n","---- Validation ----\n","Validation loss: 76.9313\n","Validation acc: 0.5677\n","Time taken: 66.38s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 344.3289, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 346.4940, Accuracy: 0.5464\n","Training loss (for one batch) at step 20: 345.5896, Accuracy: 0.5452\n","Training loss (for one batch) at step 30: 345.9907, Accuracy: 0.5365\n","Training loss (for one batch) at step 40: 345.6886, Accuracy: 0.5400\n","Training loss (for one batch) at step 50: 345.2711, Accuracy: 0.5396\n","Training loss (for one batch) at step 60: 345.5999, Accuracy: 0.5415\n","Training loss (for one batch) at step 70: 345.6320, Accuracy: 0.5441\n","Training loss (for one batch) at step 80: 345.4979, Accuracy: 0.5469\n","Training loss (for one batch) at step 90: 346.2439, Accuracy: 0.5488\n","Training loss (for one batch) at step 100: 347.7346, Accuracy: 0.5488\n","Training loss (for one batch) at step 110: 346.0710, Accuracy: 0.5513\n","Training loss (for one batch) at step 120: 346.5023, Accuracy: 0.5501\n","Training loss (for one batch) at step 130: 346.0547, Accuracy: 0.5494\n","Training loss (for one batch) at step 140: 343.7426, Accuracy: 0.5484\n","---- Training ----\n","Training loss: 303.9127\n","Training acc over epoch: 0.5466\n","---- Validation ----\n","Validation loss: 74.6677\n","Validation acc: 0.5696\n","Time taken: 58.31s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 341.7383, Accuracy: 0.4800\n","Training loss (for one batch) at step 10: 344.7975, Accuracy: 0.5655\n","Training loss (for one batch) at step 20: 346.5312, Accuracy: 0.5595\n","Training loss (for one batch) at step 30: 347.1234, Accuracy: 0.5658\n","Training loss (for one batch) at step 40: 348.2130, Accuracy: 0.5698\n","Training loss (for one batch) at step 50: 345.9282, Accuracy: 0.5614\n","Training loss (for one batch) at step 60: 342.8066, Accuracy: 0.5605\n","Training loss (for one batch) at step 70: 343.6960, Accuracy: 0.5599\n","Training loss (for one batch) at step 80: 341.6575, Accuracy: 0.5599\n","Training loss (for one batch) at step 90: 346.4567, Accuracy: 0.5620\n","Training loss (for one batch) at step 100: 353.6042, Accuracy: 0.5605\n","Training loss (for one batch) at step 110: 341.9187, Accuracy: 0.5608\n","Training loss (for one batch) at step 120: 345.4212, Accuracy: 0.5599\n","Training loss (for one batch) at step 130: 345.0909, Accuracy: 0.5576\n","Training loss (for one batch) at step 140: 339.6021, Accuracy: 0.5563\n","---- Training ----\n","Training loss: 299.1796\n","Training acc over epoch: 0.5560\n","---- Validation ----\n","Validation loss: 75.8885\n","Validation acc: 0.5645\n","Time taken: 63.54s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 343.7708, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 344.3435, Accuracy: 0.5745\n","Training loss (for one batch) at step 20: 339.6771, Accuracy: 0.5838\n","Training loss (for one batch) at step 30: 351.2776, Accuracy: 0.5816\n","Training loss (for one batch) at step 40: 342.7109, Accuracy: 0.5734\n","Training loss (for one batch) at step 50: 338.3924, Accuracy: 0.5673\n","Training loss (for one batch) at step 60: 344.1125, Accuracy: 0.5670\n","Training loss (for one batch) at step 70: 347.7223, Accuracy: 0.5676\n","Training loss (for one batch) at step 80: 344.3998, Accuracy: 0.5674\n","Training loss (for one batch) at step 90: 341.3501, Accuracy: 0.5691\n","Training loss (for one batch) at step 100: 348.3954, Accuracy: 0.5690\n","Training loss (for one batch) at step 110: 341.6374, Accuracy: 0.5683\n","Training loss (for one batch) at step 120: 342.9572, Accuracy: 0.5678\n","Training loss (for one batch) at step 130: 339.3607, Accuracy: 0.5669\n","Training loss (for one batch) at step 140: 339.8360, Accuracy: 0.5668\n","---- Training ----\n","Training loss: 305.4699\n","Training acc over epoch: 0.5656\n","---- Validation ----\n","Validation loss: 75.4652\n","Validation acc: 0.5838\n","Time taken: 48.86s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 342.7874, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 343.6305, Accuracy: 0.5473\n","Training loss (for one batch) at step 20: 342.1843, Accuracy: 0.5686\n","Training loss (for one batch) at step 30: 338.8709, Accuracy: 0.5723\n","Training loss (for one batch) at step 40: 338.1470, Accuracy: 0.5666\n","Training loss (for one batch) at step 50: 346.5555, Accuracy: 0.5673\n","Training loss (for one batch) at step 60: 339.2701, Accuracy: 0.5657\n","Training loss (for one batch) at step 70: 342.2021, Accuracy: 0.5656\n","Training loss (for one batch) at step 80: 341.7976, Accuracy: 0.5675\n","Training loss (for one batch) at step 90: 338.5329, Accuracy: 0.5686\n","Training loss (for one batch) at step 100: 339.3712, Accuracy: 0.5688\n","Training loss (for one batch) at step 110: 346.3949, Accuracy: 0.5665\n","Training loss (for one batch) at step 120: 349.7079, Accuracy: 0.5647\n","Training loss (for one batch) at step 130: 337.5081, Accuracy: 0.5639\n","Training loss (for one batch) at step 140: 336.2133, Accuracy: 0.5630\n","---- Training ----\n","Training loss: 305.0397\n","Training acc over epoch: 0.5626\n","---- Validation ----\n","Validation loss: 76.5443\n","Validation acc: 0.5793\n","Time taken: 68.13s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 345.6610, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 343.1683, Accuracy: 0.5500\n","Training loss (for one batch) at step 20: 341.5716, Accuracy: 0.5724\n","Training loss (for one batch) at step 30: 341.5977, Accuracy: 0.5610\n","Training loss (for one batch) at step 40: 345.3127, Accuracy: 0.5615\n","Training loss (for one batch) at step 50: 339.6014, Accuracy: 0.5584\n","Training loss (for one batch) at step 60: 341.6877, Accuracy: 0.5584\n","Training loss (for one batch) at step 70: 339.1528, Accuracy: 0.5618\n","Training loss (for one batch) at step 80: 339.7332, Accuracy: 0.5635\n","Training loss (for one batch) at step 90: 342.9573, Accuracy: 0.5667\n","Training loss (for one batch) at step 100: 336.4517, Accuracy: 0.5668\n","Training loss (for one batch) at step 110: 341.9322, Accuracy: 0.5671\n","Training loss (for one batch) at step 120: 339.6411, Accuracy: 0.5652\n","Training loss (for one batch) at step 130: 338.2154, Accuracy: 0.5614\n","Training loss (for one batch) at step 140: 337.1452, Accuracy: 0.5589\n","---- Training ----\n","Training loss: 305.1873\n","Training acc over epoch: 0.5586\n","---- Validation ----\n","Validation loss: 74.2957\n","Validation acc: 0.5787\n","Time taken: 55.74s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 335.6370, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 338.7189, Accuracy: 0.5836\n","Training loss (for one batch) at step 20: 349.2897, Accuracy: 0.5924\n","Training loss (for one batch) at step 30: 339.8885, Accuracy: 0.5774\n","Training loss (for one batch) at step 40: 339.9303, Accuracy: 0.5773\n","Training loss (for one batch) at step 50: 345.9097, Accuracy: 0.5729\n","Training loss (for one batch) at step 60: 345.0828, Accuracy: 0.5715\n","Training loss (for one batch) at step 70: 342.2228, Accuracy: 0.5694\n","Training loss (for one batch) at step 80: 349.1234, Accuracy: 0.5668\n","Training loss (for one batch) at step 90: 335.4682, Accuracy: 0.5686\n","Training loss (for one batch) at step 100: 340.7142, Accuracy: 0.5705\n","Training loss (for one batch) at step 110: 340.2190, Accuracy: 0.5690\n","Training loss (for one batch) at step 120: 334.5568, Accuracy: 0.5674\n","Training loss (for one batch) at step 130: 343.8235, Accuracy: 0.5657\n","Training loss (for one batch) at step 140: 332.5363, Accuracy: 0.5644\n","---- Training ----\n","Training loss: 298.8552\n","Training acc over epoch: 0.5639\n","---- Validation ----\n","Validation loss: 77.4125\n","Validation acc: 0.5828\n","Time taken: 78.80s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 333.4539, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 335.0753, Accuracy: 0.5745\n","Training loss (for one batch) at step 20: 332.3172, Accuracy: 0.5786\n","Training loss (for one batch) at step 30: 336.4101, Accuracy: 0.5765\n","Training loss (for one batch) at step 40: 333.9336, Accuracy: 0.5715\n","Training loss (for one batch) at step 50: 338.6764, Accuracy: 0.5647\n","Training loss (for one batch) at step 60: 337.9876, Accuracy: 0.5628\n","Training loss (for one batch) at step 70: 335.5974, Accuracy: 0.5623\n","Training loss (for one batch) at step 80: 336.6760, Accuracy: 0.5621\n","Training loss (for one batch) at step 90: 339.3033, Accuracy: 0.5590\n","Training loss (for one batch) at step 100: 333.6978, Accuracy: 0.5633\n","Training loss (for one batch) at step 110: 341.7740, Accuracy: 0.5652\n","Training loss (for one batch) at step 120: 339.3823, Accuracy: 0.5640\n","Training loss (for one batch) at step 130: 339.4585, Accuracy: 0.5628\n","Training loss (for one batch) at step 140: 341.7575, Accuracy: 0.5626\n","---- Training ----\n","Training loss: 293.8719\n","Training acc over epoch: 0.5637\n","---- Validation ----\n","Validation loss: 77.5957\n","Validation acc: 0.5712\n","Time taken: 48.10s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 335.2056, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 335.7608, Accuracy: 0.5909\n","Training loss (for one batch) at step 20: 336.4888, Accuracy: 0.5900\n","Training loss (for one batch) at step 30: 338.7028, Accuracy: 0.5816\n","Training loss (for one batch) at step 40: 342.1121, Accuracy: 0.5737\n","Training loss (for one batch) at step 50: 339.7327, Accuracy: 0.5653\n","Training loss (for one batch) at step 60: 328.1473, Accuracy: 0.5646\n","Training loss (for one batch) at step 70: 335.9633, Accuracy: 0.5623\n","Training loss (for one batch) at step 80: 339.7057, Accuracy: 0.5616\n","Training loss (for one batch) at step 90: 331.6047, Accuracy: 0.5658\n","Training loss (for one batch) at step 100: 331.3636, Accuracy: 0.5657\n","Training loss (for one batch) at step 110: 337.2056, Accuracy: 0.5671\n","Training loss (for one batch) at step 120: 340.3860, Accuracy: 0.5655\n","Training loss (for one batch) at step 130: 332.5648, Accuracy: 0.5626\n","Training loss (for one batch) at step 140: 336.2882, Accuracy: 0.5627\n","---- Training ----\n","Training loss: 296.2934\n","Training acc over epoch: 0.5637\n","---- Validation ----\n","Validation loss: 75.8947\n","Validation acc: 0.5739\n","Time taken: 69.59s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 335.6717, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 337.2840, Accuracy: 0.6018\n","Training loss (for one batch) at step 20: 339.0537, Accuracy: 0.5890\n","Training loss (for one batch) at step 30: 340.5883, Accuracy: 0.5713\n","Training loss (for one batch) at step 40: 334.3913, Accuracy: 0.5615\n","Training loss (for one batch) at step 50: 331.1921, Accuracy: 0.5575\n","Training loss (for one batch) at step 60: 331.1383, Accuracy: 0.5521\n","Training loss (for one batch) at step 70: 346.3757, Accuracy: 0.5548\n","Training loss (for one batch) at step 80: 341.8327, Accuracy: 0.5537\n","Training loss (for one batch) at step 90: 333.7395, Accuracy: 0.5560\n","Training loss (for one batch) at step 100: 337.8723, Accuracy: 0.5589\n","Training loss (for one batch) at step 110: 332.7801, Accuracy: 0.5628\n","Training loss (for one batch) at step 120: 328.7056, Accuracy: 0.5607\n","Training loss (for one batch) at step 130: 341.9092, Accuracy: 0.5576\n","Training loss (for one batch) at step 140: 334.5234, Accuracy: 0.5571\n","---- Training ----\n","Training loss: 292.6959\n","Training acc over epoch: 0.5564\n","---- Validation ----\n","Validation loss: 77.5370\n","Validation acc: 0.5801\n","Time taken: 44.64s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 336.3127, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 326.9450, Accuracy: 0.6027\n","Training loss (for one batch) at step 20: 330.2367, Accuracy: 0.6005\n","Training loss (for one batch) at step 30: 334.3731, Accuracy: 0.5958\n","Training loss (for one batch) at step 40: 336.1140, Accuracy: 0.5861\n","Training loss (for one batch) at step 50: 332.4329, Accuracy: 0.5790\n","Training loss (for one batch) at step 60: 336.2905, Accuracy: 0.5769\n","Training loss (for one batch) at step 70: 342.0573, Accuracy: 0.5765\n","Training loss (for one batch) at step 80: 334.5595, Accuracy: 0.5727\n","Training loss (for one batch) at step 90: 330.1782, Accuracy: 0.5749\n","Training loss (for one batch) at step 100: 335.2807, Accuracy: 0.5737\n","Training loss (for one batch) at step 110: 334.4740, Accuracy: 0.5749\n","Training loss (for one batch) at step 120: 323.5868, Accuracy: 0.5726\n","Training loss (for one batch) at step 130: 332.9196, Accuracy: 0.5706\n","Training loss (for one batch) at step 140: 330.3514, Accuracy: 0.5659\n","---- Training ----\n","Training loss: 299.6602\n","Training acc over epoch: 0.5655\n","---- Validation ----\n","Validation loss: 75.7850\n","Validation acc: 0.5798\n","Time taken: 68.28s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 337.1250, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 330.4738, Accuracy: 0.5900\n","Training loss (for one batch) at step 20: 329.7253, Accuracy: 0.5752\n","Training loss (for one batch) at step 30: 328.5456, Accuracy: 0.5739\n","Training loss (for one batch) at step 40: 330.5942, Accuracy: 0.5717\n","Training loss (for one batch) at step 50: 334.2823, Accuracy: 0.5671\n","Training loss (for one batch) at step 60: 333.9069, Accuracy: 0.5667\n","Training loss (for one batch) at step 70: 328.6356, Accuracy: 0.5635\n","Training loss (for one batch) at step 80: 337.0335, Accuracy: 0.5619\n","Training loss (for one batch) at step 90: 331.4199, Accuracy: 0.5652\n","Training loss (for one batch) at step 100: 324.9057, Accuracy: 0.5661\n","Training loss (for one batch) at step 110: 330.3280, Accuracy: 0.5660\n","Training loss (for one batch) at step 120: 337.1000, Accuracy: 0.5638\n","Training loss (for one batch) at step 130: 334.2598, Accuracy: 0.5624\n","Training loss (for one batch) at step 140: 339.3457, Accuracy: 0.5612\n","---- Training ----\n","Training loss: 290.8933\n","Training acc over epoch: 0.5594\n","---- Validation ----\n","Validation loss: 75.7460\n","Validation acc: 0.5656\n","Time taken: 46.35s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 329.0130, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 334.0518, Accuracy: 0.5773\n","Training loss (for one batch) at step 20: 324.7720, Accuracy: 0.5752\n","Training loss (for one batch) at step 30: 335.4765, Accuracy: 0.5761\n","Training loss (for one batch) at step 40: 333.8416, Accuracy: 0.5727\n","Training loss (for one batch) at step 50: 329.5001, Accuracy: 0.5653\n","Training loss (for one batch) at step 60: 325.5688, Accuracy: 0.5592\n","Training loss (for one batch) at step 70: 330.1478, Accuracy: 0.5590\n","Training loss (for one batch) at step 80: 339.0320, Accuracy: 0.5612\n","Training loss (for one batch) at step 90: 326.6302, Accuracy: 0.5619\n","Training loss (for one batch) at step 100: 332.0228, Accuracy: 0.5627\n","Training loss (for one batch) at step 110: 321.6327, Accuracy: 0.5659\n","Training loss (for one batch) at step 120: 336.8387, Accuracy: 0.5655\n","Training loss (for one batch) at step 130: 327.7886, Accuracy: 0.5613\n","Training loss (for one batch) at step 140: 330.9451, Accuracy: 0.5611\n","---- Training ----\n","Training loss: 296.1609\n","Training acc over epoch: 0.5605\n","---- Validation ----\n","Validation loss: 80.0125\n","Validation acc: 0.5841\n","Time taken: 68.03s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 336.7638, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 330.1903, Accuracy: 0.5918\n","Training loss (for one batch) at step 20: 325.6492, Accuracy: 0.5819\n","Training loss (for one batch) at step 30: 329.7549, Accuracy: 0.5839\n","Training loss (for one batch) at step 40: 329.9354, Accuracy: 0.5763\n","Training loss (for one batch) at step 50: 322.6278, Accuracy: 0.5682\n","Training loss (for one batch) at step 60: 335.0669, Accuracy: 0.5654\n","Training loss (for one batch) at step 70: 329.6194, Accuracy: 0.5669\n","Training loss (for one batch) at step 80: 320.6689, Accuracy: 0.5593\n","Training loss (for one batch) at step 90: 328.3495, Accuracy: 0.5610\n","Training loss (for one batch) at step 100: 327.6603, Accuracy: 0.5605\n","Training loss (for one batch) at step 110: 328.6061, Accuracy: 0.5612\n","Training loss (for one batch) at step 120: 326.9784, Accuracy: 0.5612\n","Training loss (for one batch) at step 130: 327.8334, Accuracy: 0.5592\n","Training loss (for one batch) at step 140: 330.9972, Accuracy: 0.5591\n","---- Training ----\n","Training loss: 292.3489\n","Training acc over epoch: 0.5587\n","---- Validation ----\n","Validation loss: 77.7673\n","Validation acc: 0.5591\n","Time taken: 47.88s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 334.3765, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 320.9031, Accuracy: 0.5945\n","Training loss (for one batch) at step 20: 327.9291, Accuracy: 0.5929\n","Training loss (for one batch) at step 30: 327.6694, Accuracy: 0.5787\n","Training loss (for one batch) at step 40: 327.0951, Accuracy: 0.5668\n","Training loss (for one batch) at step 50: 325.8221, Accuracy: 0.5598\n","Training loss (for one batch) at step 60: 326.0931, Accuracy: 0.5579\n","Training loss (for one batch) at step 70: 331.0706, Accuracy: 0.5573\n","Training loss (for one batch) at step 80: 330.5094, Accuracy: 0.5569\n","Training loss (for one batch) at step 90: 334.5755, Accuracy: 0.5573\n","Training loss (for one batch) at step 100: 330.1429, Accuracy: 0.5604\n","Training loss (for one batch) at step 110: 330.8715, Accuracy: 0.5605\n","Training loss (for one batch) at step 120: 320.4518, Accuracy: 0.5617\n","Training loss (for one batch) at step 130: 322.4713, Accuracy: 0.5590\n","Training loss (for one batch) at step 140: 327.6831, Accuracy: 0.5573\n","---- Training ----\n","Training loss: 293.2875\n","Training acc over epoch: 0.5586\n","---- Validation ----\n","Validation loss: 76.6472\n","Validation acc: 0.5615\n","Time taken: 66.42s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 325.3528, Accuracy: 0.5600\n","Training loss (for one batch) at step 10: 320.8793, Accuracy: 0.5927\n","Training loss (for one batch) at step 20: 316.0877, Accuracy: 0.5924\n","Training loss (for one batch) at step 30: 330.7984, Accuracy: 0.5781\n","Training loss (for one batch) at step 40: 334.0618, Accuracy: 0.5656\n","Training loss (for one batch) at step 50: 324.7357, Accuracy: 0.5624\n","Training loss (for one batch) at step 60: 328.5768, Accuracy: 0.5620\n","Training loss (for one batch) at step 70: 328.3294, Accuracy: 0.5587\n","Training loss (for one batch) at step 80: 323.4808, Accuracy: 0.5575\n","Training loss (for one batch) at step 90: 327.6811, Accuracy: 0.5589\n","Training loss (for one batch) at step 100: 324.3013, Accuracy: 0.5593\n","Training loss (for one batch) at step 110: 330.2951, Accuracy: 0.5613\n","Training loss (for one batch) at step 120: 320.5576, Accuracy: 0.5588\n","Training loss (for one batch) at step 130: 324.9229, Accuracy: 0.5562\n","Training loss (for one batch) at step 140: 329.2630, Accuracy: 0.5557\n","---- Training ----\n","Training loss: 291.4213\n","Training acc over epoch: 0.5555\n","---- Validation ----\n","Validation loss: 78.6241\n","Validation acc: 0.5586\n","Time taken: 54.29s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 322.2826, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 313.3329, Accuracy: 0.6100\n","Training loss (for one batch) at step 20: 332.4405, Accuracy: 0.6062\n","Training loss (for one batch) at step 30: 320.4786, Accuracy: 0.5948\n","Training loss (for one batch) at step 40: 321.9469, Accuracy: 0.5851\n","Training loss (for one batch) at step 50: 326.8210, Accuracy: 0.5761\n","Training loss (for one batch) at step 60: 321.5747, Accuracy: 0.5674\n","Training loss (for one batch) at step 70: 332.1510, Accuracy: 0.5654\n","Training loss (for one batch) at step 80: 324.4835, Accuracy: 0.5638\n","Training loss (for one batch) at step 90: 322.4172, Accuracy: 0.5657\n","Training loss (for one batch) at step 100: 325.0076, Accuracy: 0.5689\n","Training loss (for one batch) at step 110: 328.6229, Accuracy: 0.5694\n","Training loss (for one batch) at step 120: 323.0266, Accuracy: 0.5688\n","Training loss (for one batch) at step 130: 316.6903, Accuracy: 0.5637\n","Training loss (for one batch) at step 140: 331.7076, Accuracy: 0.5633\n","---- Training ----\n","Training loss: 279.5857\n","Training acc over epoch: 0.5621\n","---- Validation ----\n","Validation loss: 77.0590\n","Validation acc: 0.5540\n","Time taken: 72.01s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 324.0652, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 317.9462, Accuracy: 0.5836\n","Training loss (for one batch) at step 20: 311.6865, Accuracy: 0.5976\n","Training loss (for one batch) at step 30: 328.4012, Accuracy: 0.5784\n","Training loss (for one batch) at step 40: 326.4974, Accuracy: 0.5705\n","Training loss (for one batch) at step 50: 315.3343, Accuracy: 0.5612\n","Training loss (for one batch) at step 60: 324.2797, Accuracy: 0.5592\n","Training loss (for one batch) at step 70: 321.9810, Accuracy: 0.5572\n","Training loss (for one batch) at step 80: 330.5049, Accuracy: 0.5577\n","Training loss (for one batch) at step 90: 329.4475, Accuracy: 0.5630\n","Training loss (for one batch) at step 100: 323.7241, Accuracy: 0.5652\n","Training loss (for one batch) at step 110: 319.6944, Accuracy: 0.5649\n","Training loss (for one batch) at step 120: 318.7482, Accuracy: 0.5623\n","Training loss (for one batch) at step 130: 324.5313, Accuracy: 0.5603\n","Training loss (for one batch) at step 140: 329.2931, Accuracy: 0.5589\n","---- Training ----\n","Training loss: 277.0285\n","Training acc over epoch: 0.5596\n","---- Validation ----\n","Validation loss: 77.1372\n","Validation acc: 0.5709\n","Time taken: 63.66s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 318.5751, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 318.7379, Accuracy: 0.6182\n","Training loss (for one batch) at step 20: 325.1154, Accuracy: 0.6052\n","Training loss (for one batch) at step 30: 319.6432, Accuracy: 0.5823\n","Training loss (for one batch) at step 40: 323.6873, Accuracy: 0.5744\n","Training loss (for one batch) at step 50: 325.0244, Accuracy: 0.5604\n","Training loss (for one batch) at step 60: 321.0353, Accuracy: 0.5538\n","Training loss (for one batch) at step 70: 321.0788, Accuracy: 0.5531\n","Training loss (for one batch) at step 80: 312.2830, Accuracy: 0.5556\n","Training loss (for one batch) at step 90: 324.0509, Accuracy: 0.5578\n","Training loss (for one batch) at step 100: 322.9505, Accuracy: 0.5595\n","Training loss (for one batch) at step 110: 322.6213, Accuracy: 0.5603\n","Training loss (for one batch) at step 120: 334.0167, Accuracy: 0.5587\n","Training loss (for one batch) at step 130: 321.7015, Accuracy: 0.5573\n","Training loss (for one batch) at step 140: 311.4991, Accuracy: 0.5548\n","---- Training ----\n","Training loss: 288.6113\n","Training acc over epoch: 0.5552\n","---- Validation ----\n","Validation loss: 76.7051\n","Validation acc: 0.5723\n","Time taken: 63.08s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 314.3020, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 313.5974, Accuracy: 0.6027\n","Training loss (for one batch) at step 20: 318.6006, Accuracy: 0.5881\n","Training loss (for one batch) at step 30: 322.6417, Accuracy: 0.5768\n","Training loss (for one batch) at step 40: 315.4834, Accuracy: 0.5688\n","Training loss (for one batch) at step 50: 324.9510, Accuracy: 0.5596\n","Training loss (for one batch) at step 60: 323.7611, Accuracy: 0.5608\n","Training loss (for one batch) at step 70: 334.1464, Accuracy: 0.5576\n","Training loss (for one batch) at step 80: 322.6264, Accuracy: 0.5577\n","Training loss (for one batch) at step 90: 321.4059, Accuracy: 0.5614\n","Training loss (for one batch) at step 100: 317.5585, Accuracy: 0.5651\n","Training loss (for one batch) at step 110: 316.1633, Accuracy: 0.5672\n","Training loss (for one batch) at step 120: 327.6815, Accuracy: 0.5643\n","Training loss (for one batch) at step 130: 323.3951, Accuracy: 0.5583\n","Training loss (for one batch) at step 140: 319.8686, Accuracy: 0.5574\n","---- Training ----\n","Training loss: 289.0845\n","Training acc over epoch: 0.5588\n","---- Validation ----\n","Validation loss: 79.1887\n","Validation acc: 0.5661\n","Time taken: 66.02s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 319.1943, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 319.7152, Accuracy: 0.6291\n","Training loss (for one batch) at step 20: 324.1276, Accuracy: 0.5943\n","Training loss (for one batch) at step 30: 326.7818, Accuracy: 0.5787\n","Training loss (for one batch) at step 40: 318.6210, Accuracy: 0.5673\n","Training loss (for one batch) at step 50: 316.3281, Accuracy: 0.5578\n","Training loss (for one batch) at step 60: 329.0651, Accuracy: 0.5551\n","Training loss (for one batch) at step 70: 321.0266, Accuracy: 0.5563\n","Training loss (for one batch) at step 80: 325.4836, Accuracy: 0.5570\n","Training loss (for one batch) at step 90: 317.5962, Accuracy: 0.5587\n","Training loss (for one batch) at step 100: 322.2710, Accuracy: 0.5621\n","Training loss (for one batch) at step 110: 321.1326, Accuracy: 0.5615\n","Training loss (for one batch) at step 120: 310.0016, Accuracy: 0.5602\n","Training loss (for one batch) at step 130: 317.3263, Accuracy: 0.5569\n","Training loss (for one batch) at step 140: 317.4355, Accuracy: 0.5538\n","---- Training ----\n","Training loss: 277.7789\n","Training acc over epoch: 0.5551\n","---- Validation ----\n","Validation loss: 76.4656\n","Validation acc: 0.5556\n","Time taken: 65.62s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 333.5278, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 307.4445, Accuracy: 0.5909\n","Training loss (for one batch) at step 20: 321.5567, Accuracy: 0.5971\n","Training loss (for one batch) at step 30: 314.4747, Accuracy: 0.5839\n","Training loss (for one batch) at step 40: 306.6827, Accuracy: 0.5690\n","Training loss (for one batch) at step 50: 314.0280, Accuracy: 0.5600\n","Training loss (for one batch) at step 60: 319.4421, Accuracy: 0.5546\n","Training loss (for one batch) at step 70: 329.4219, Accuracy: 0.5493\n","Training loss (for one batch) at step 80: 326.6841, Accuracy: 0.5491\n","Training loss (for one batch) at step 90: 313.9247, Accuracy: 0.5491\n","Training loss (for one batch) at step 100: 322.4154, Accuracy: 0.5505\n","Training loss (for one batch) at step 110: 322.1750, Accuracy: 0.5524\n","Training loss (for one batch) at step 120: 312.4794, Accuracy: 0.5498\n","Training loss (for one batch) at step 130: 312.3269, Accuracy: 0.5479\n","Training loss (for one batch) at step 140: 309.9155, Accuracy: 0.5472\n","---- Training ----\n","Training loss: 281.5236\n","Training acc over epoch: 0.5494\n","---- Validation ----\n","Validation loss: 77.1392\n","Validation acc: 0.5527\n","Time taken: 63.87s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 317.1992, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 311.8010, Accuracy: 0.6145\n","Training loss (for one batch) at step 20: 330.4521, Accuracy: 0.5952\n","Training loss (for one batch) at step 30: 318.7244, Accuracy: 0.5752\n","Training loss (for one batch) at step 40: 310.3711, Accuracy: 0.5620\n","Training loss (for one batch) at step 50: 321.7877, Accuracy: 0.5563\n","Training loss (for one batch) at step 60: 306.7599, Accuracy: 0.5531\n","Training loss (for one batch) at step 70: 314.1437, Accuracy: 0.5511\n","Training loss (for one batch) at step 80: 324.2878, Accuracy: 0.5510\n","Training loss (for one batch) at step 90: 306.7363, Accuracy: 0.5545\n","Training loss (for one batch) at step 100: 309.9454, Accuracy: 0.5559\n","Training loss (for one batch) at step 110: 312.1415, Accuracy: 0.5580\n","Training loss (for one batch) at step 120: 313.5108, Accuracy: 0.5546\n","Training loss (for one batch) at step 130: 317.7830, Accuracy: 0.5522\n","Training loss (for one batch) at step 140: 315.9613, Accuracy: 0.5517\n","---- Training ----\n","Training loss: 279.1006\n","Training acc over epoch: 0.5504\n","---- Validation ----\n","Validation loss: 80.6706\n","Validation acc: 0.5505\n","Time taken: 72.75s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 315.4140, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 309.2891, Accuracy: 0.5827\n","Training loss (for one batch) at step 20: 312.2710, Accuracy: 0.5829\n","Training loss (for one batch) at step 30: 319.4664, Accuracy: 0.5658\n","Training loss (for one batch) at step 40: 309.6465, Accuracy: 0.5639\n","Training loss (for one batch) at step 50: 308.0115, Accuracy: 0.5584\n","Training loss (for one batch) at step 60: 321.1715, Accuracy: 0.5544\n","Training loss (for one batch) at step 70: 308.2657, Accuracy: 0.5525\n","Training loss (for one batch) at step 80: 314.5112, Accuracy: 0.5507\n","Training loss (for one batch) at step 90: 310.2387, Accuracy: 0.5530\n","Training loss (for one batch) at step 100: 312.2787, Accuracy: 0.5545\n","Training loss (for one batch) at step 110: 321.1768, Accuracy: 0.5559\n","Training loss (for one batch) at step 120: 311.3316, Accuracy: 0.5557\n","Training loss (for one batch) at step 130: 301.8989, Accuracy: 0.5521\n","Training loss (for one batch) at step 140: 299.8600, Accuracy: 0.5496\n","---- Training ----\n","Training loss: 278.5800\n","Training acc over epoch: 0.5500\n","---- Validation ----\n","Validation loss: 79.7774\n","Validation acc: 0.5551\n","Time taken: 65.77s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 310.8477, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 313.1160, Accuracy: 0.5918\n","Training loss (for one batch) at step 20: 326.1101, Accuracy: 0.5786\n","Training loss (for one batch) at step 30: 313.0891, Accuracy: 0.5800\n","Training loss (for one batch) at step 40: 325.1343, Accuracy: 0.5663\n","Training loss (for one batch) at step 50: 321.3404, Accuracy: 0.5512\n","Training loss (for one batch) at step 60: 307.1525, Accuracy: 0.5485\n","Training loss (for one batch) at step 70: 312.9041, Accuracy: 0.5446\n","Training loss (for one batch) at step 80: 316.1881, Accuracy: 0.5463\n","Training loss (for one batch) at step 90: 314.3136, Accuracy: 0.5475\n","Training loss (for one batch) at step 100: 305.7350, Accuracy: 0.5505\n","Training loss (for one batch) at step 110: 307.2912, Accuracy: 0.5519\n","Training loss (for one batch) at step 120: 313.3896, Accuracy: 0.5517\n","Training loss (for one batch) at step 130: 311.4680, Accuracy: 0.5500\n","Training loss (for one batch) at step 140: 298.8722, Accuracy: 0.5501\n","---- Training ----\n","Training loss: 269.6288\n","Training acc over epoch: 0.5513\n","---- Validation ----\n","Validation loss: 75.5413\n","Validation acc: 0.5613\n","Time taken: 65.26s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 317.4614, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 308.8339, Accuracy: 0.6145\n","Training loss (for one batch) at step 20: 317.3416, Accuracy: 0.5900\n","Training loss (for one batch) at step 30: 311.9621, Accuracy: 0.5768\n","Training loss (for one batch) at step 40: 312.9690, Accuracy: 0.5654\n","Training loss (for one batch) at step 50: 307.4166, Accuracy: 0.5527\n","Training loss (for one batch) at step 60: 301.3922, Accuracy: 0.5492\n","Training loss (for one batch) at step 70: 310.5542, Accuracy: 0.5454\n","Training loss (for one batch) at step 80: 312.2570, Accuracy: 0.5446\n","Training loss (for one batch) at step 90: 309.4922, Accuracy: 0.5460\n","Training loss (for one batch) at step 100: 316.8336, Accuracy: 0.5479\n","Training loss (for one batch) at step 110: 320.5767, Accuracy: 0.5508\n","Training loss (for one batch) at step 120: 309.7778, Accuracy: 0.5502\n","Training loss (for one batch) at step 130: 311.0392, Accuracy: 0.5482\n","Training loss (for one batch) at step 140: 315.0999, Accuracy: 0.5462\n","---- Training ----\n","Training loss: 277.4804\n","Training acc over epoch: 0.5478\n","---- Validation ----\n","Validation loss: 86.8689\n","Validation acc: 0.5537\n","Time taken: 63.04s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 314.9705, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 315.6653, Accuracy: 0.5891\n","Training loss (for one batch) at step 20: 317.1662, Accuracy: 0.5871\n","Training loss (for one batch) at step 30: 313.3704, Accuracy: 0.5639\n","Training loss (for one batch) at step 40: 308.5796, Accuracy: 0.5520\n","Training loss (for one batch) at step 50: 302.1927, Accuracy: 0.5469\n","Training loss (for one batch) at step 60: 308.2231, Accuracy: 0.5466\n","Training loss (for one batch) at step 70: 295.0794, Accuracy: 0.5410\n","Training loss (for one batch) at step 80: 320.7468, Accuracy: 0.5423\n","Training loss (for one batch) at step 90: 305.4355, Accuracy: 0.5443\n","Training loss (for one batch) at step 100: 309.0040, Accuracy: 0.5479\n","Training loss (for one batch) at step 110: 298.3913, Accuracy: 0.5510\n","Training loss (for one batch) at step 120: 299.9673, Accuracy: 0.5494\n","Training loss (for one batch) at step 130: 309.7509, Accuracy: 0.5457\n","Training loss (for one batch) at step 140: 299.4438, Accuracy: 0.5450\n","---- Training ----\n","Training loss: 273.3592\n","Training acc over epoch: 0.5455\n","---- Validation ----\n","Validation loss: 75.2836\n","Validation acc: 0.5548\n","Time taken: 60.61s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 310.2854, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 325.1444, Accuracy: 0.5955\n","Training loss (for one batch) at step 20: 292.1944, Accuracy: 0.5910\n","Training loss (for one batch) at step 30: 310.6443, Accuracy: 0.5697\n","Training loss (for one batch) at step 40: 316.2588, Accuracy: 0.5639\n","Training loss (for one batch) at step 50: 300.3604, Accuracy: 0.5553\n","Training loss (for one batch) at step 60: 310.1622, Accuracy: 0.5516\n","Training loss (for one batch) at step 70: 308.0040, Accuracy: 0.5458\n","Training loss (for one batch) at step 80: 309.0045, Accuracy: 0.5417\n","Training loss (for one batch) at step 90: 315.8528, Accuracy: 0.5462\n","Training loss (for one batch) at step 100: 307.8394, Accuracy: 0.5502\n","Training loss (for one batch) at step 110: 299.2513, Accuracy: 0.5506\n","Training loss (for one batch) at step 120: 313.3602, Accuracy: 0.5485\n","Training loss (for one batch) at step 130: 296.3113, Accuracy: 0.5453\n","Training loss (for one batch) at step 140: 289.2937, Accuracy: 0.5446\n","---- Training ----\n","Training loss: 275.1199\n","Training acc over epoch: 0.5453\n","---- Validation ----\n","Validation loss: 81.7473\n","Validation acc: 0.5357\n","Time taken: 62.58s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 306.0943, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 303.1338, Accuracy: 0.6009\n","Training loss (for one batch) at step 20: 309.5114, Accuracy: 0.5833\n","Training loss (for one batch) at step 30: 308.3839, Accuracy: 0.5729\n","Training loss (for one batch) at step 40: 297.6282, Accuracy: 0.5600\n","Training loss (for one batch) at step 50: 316.0510, Accuracy: 0.5502\n","Training loss (for one batch) at step 60: 306.1985, Accuracy: 0.5436\n","Training loss (for one batch) at step 70: 315.0904, Accuracy: 0.5369\n","Training loss (for one batch) at step 80: 313.6263, Accuracy: 0.5359\n","Training loss (for one batch) at step 90: 314.0166, Accuracy: 0.5393\n","Training loss (for one batch) at step 100: 295.2631, Accuracy: 0.5447\n","Training loss (for one batch) at step 110: 316.7125, Accuracy: 0.5476\n","Training loss (for one batch) at step 120: 333.3458, Accuracy: 0.5468\n","Training loss (for one batch) at step 130: 291.1713, Accuracy: 0.5432\n","Training loss (for one batch) at step 140: 308.9156, Accuracy: 0.5419\n","---- Training ----\n","Training loss: 259.6596\n","Training acc over epoch: 0.5434\n","---- Validation ----\n","Validation loss: 81.3633\n","Validation acc: 0.5416\n","Time taken: 65.75s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 309.1850, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 302.3889, Accuracy: 0.5873\n","Training loss (for one batch) at step 20: 291.2243, Accuracy: 0.5948\n","Training loss (for one batch) at step 30: 306.0555, Accuracy: 0.5819\n","Training loss (for one batch) at step 40: 302.1344, Accuracy: 0.5705\n","Training loss (for one batch) at step 50: 301.6903, Accuracy: 0.5553\n","Training loss (for one batch) at step 60: 304.1201, Accuracy: 0.5469\n","Training loss (for one batch) at step 70: 305.3992, Accuracy: 0.5437\n","Training loss (for one batch) at step 80: 301.2970, Accuracy: 0.5432\n","Training loss (for one batch) at step 90: 299.4441, Accuracy: 0.5456\n","Training loss (for one batch) at step 100: 312.2908, Accuracy: 0.5492\n","Training loss (for one batch) at step 110: 304.8472, Accuracy: 0.5492\n","Training loss (for one batch) at step 120: 311.9940, Accuracy: 0.5462\n","Training loss (for one batch) at step 130: 304.9085, Accuracy: 0.5447\n","Training loss (for one batch) at step 140: 317.4778, Accuracy: 0.5437\n","---- Training ----\n","Training loss: 262.1736\n","Training acc over epoch: 0.5441\n","---- Validation ----\n","Validation loss: 78.3365\n","Validation acc: 0.5425\n","Time taken: 66.38s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 307.7106, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 318.0111, Accuracy: 0.5873\n","Training loss (for one batch) at step 20: 295.9027, Accuracy: 0.5848\n","Training loss (for one batch) at step 30: 313.5559, Accuracy: 0.5739\n","Training loss (for one batch) at step 40: 291.5902, Accuracy: 0.5551\n","Training loss (for one batch) at step 50: 304.3476, Accuracy: 0.5475\n","Training loss (for one batch) at step 60: 304.6009, Accuracy: 0.5387\n","Training loss (for one batch) at step 70: 303.9089, Accuracy: 0.5369\n","Training loss (for one batch) at step 80: 298.9791, Accuracy: 0.5364\n","Training loss (for one batch) at step 90: 312.9048, Accuracy: 0.5392\n","Training loss (for one batch) at step 100: 310.8003, Accuracy: 0.5460\n","Training loss (for one batch) at step 110: 318.5925, Accuracy: 0.5479\n","Training loss (for one batch) at step 120: 304.8713, Accuracy: 0.5464\n","Training loss (for one batch) at step 130: 306.4040, Accuracy: 0.5438\n","Training loss (for one batch) at step 140: 316.3770, Accuracy: 0.5438\n","---- Training ----\n","Training loss: 267.6142\n","Training acc over epoch: 0.5437\n","---- Validation ----\n","Validation loss: 78.1191\n","Validation acc: 0.5425\n","Time taken: 69.75s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 299.2707, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 294.8253, Accuracy: 0.6000\n","Training loss (for one batch) at step 20: 311.8162, Accuracy: 0.5919\n","Training loss (for one batch) at step 30: 283.7398, Accuracy: 0.5774\n","Training loss (for one batch) at step 40: 299.4595, Accuracy: 0.5639\n","Training loss (for one batch) at step 50: 298.8004, Accuracy: 0.5551\n","Training loss (for one batch) at step 60: 289.0583, Accuracy: 0.5467\n","Training loss (for one batch) at step 70: 290.9039, Accuracy: 0.5438\n","Training loss (for one batch) at step 80: 301.0514, Accuracy: 0.5407\n","Training loss (for one batch) at step 90: 300.5468, Accuracy: 0.5442\n","Training loss (for one batch) at step 100: 289.0399, Accuracy: 0.5474\n","Training loss (for one batch) at step 110: 306.6198, Accuracy: 0.5502\n","Training loss (for one batch) at step 120: 301.5215, Accuracy: 0.5493\n","Training loss (for one batch) at step 130: 301.1162, Accuracy: 0.5450\n","Training loss (for one batch) at step 140: 299.0510, Accuracy: 0.5448\n","---- Training ----\n","Training loss: 259.3423\n","Training acc over epoch: 0.5447\n","---- Validation ----\n","Validation loss: 81.0604\n","Validation acc: 0.5341\n","Time taken: 69.67s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 313.9865, Accuracy: 0.5200\n","Training loss (for one batch) at step 10: 308.2803, Accuracy: 0.5845\n","Training loss (for one batch) at step 20: 294.1221, Accuracy: 0.5871\n","Training loss (for one batch) at step 30: 292.5214, Accuracy: 0.5723\n","Training loss (for one batch) at step 40: 291.6687, Accuracy: 0.5576\n","Training loss (for one batch) at step 50: 295.0345, Accuracy: 0.5455\n","Training loss (for one batch) at step 60: 299.2278, Accuracy: 0.5364\n","Training loss (for one batch) at step 70: 305.0883, Accuracy: 0.5348\n","Training loss (for one batch) at step 80: 311.5189, Accuracy: 0.5368\n","Training loss (for one batch) at step 90: 292.4203, Accuracy: 0.5382\n","Training loss (for one batch) at step 100: 292.9538, Accuracy: 0.5422\n","Training loss (for one batch) at step 110: 296.6290, Accuracy: 0.5432\n","Training loss (for one batch) at step 120: 288.3360, Accuracy: 0.5419\n","Training loss (for one batch) at step 130: 285.0130, Accuracy: 0.5390\n","Training loss (for one batch) at step 140: 312.1672, Accuracy: 0.5377\n","---- Training ----\n","Training loss: 249.4597\n","Training acc over epoch: 0.5387\n","---- Validation ----\n","Validation loss: 89.2668\n","Validation acc: 0.5382\n","Time taken: 68.72s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 315.8455, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 304.7107, Accuracy: 0.6018\n","Training loss (for one batch) at step 20: 294.5643, Accuracy: 0.5876\n","Training loss (for one batch) at step 30: 291.8048, Accuracy: 0.5787\n","Training loss (for one batch) at step 40: 299.4381, Accuracy: 0.5634\n","Training loss (for one batch) at step 50: 292.5295, Accuracy: 0.5516\n","Training loss (for one batch) at step 60: 293.9456, Accuracy: 0.5454\n","Training loss (for one batch) at step 70: 289.1662, Accuracy: 0.5425\n","Training loss (for one batch) at step 80: 290.4102, Accuracy: 0.5416\n","Training loss (for one batch) at step 90: 302.9436, Accuracy: 0.5460\n","Training loss (for one batch) at step 100: 308.8401, Accuracy: 0.5495\n","Training loss (for one batch) at step 110: 300.8586, Accuracy: 0.5503\n","Training loss (for one batch) at step 120: 282.9482, Accuracy: 0.5488\n","Training loss (for one batch) at step 130: 290.1761, Accuracy: 0.5447\n","Training loss (for one batch) at step 140: 305.3644, Accuracy: 0.5421\n","---- Training ----\n","Training loss: 252.7030\n","Training acc over epoch: 0.5431\n","---- Validation ----\n","Validation loss: 80.4616\n","Validation acc: 0.5427\n","Time taken: 64.62s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 316.3646, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 293.1657, Accuracy: 0.6209\n","Training loss (for one batch) at step 20: 304.0032, Accuracy: 0.6029\n","Training loss (for one batch) at step 30: 297.2775, Accuracy: 0.5855\n","Training loss (for one batch) at step 40: 286.5334, Accuracy: 0.5666\n","Training loss (for one batch) at step 50: 297.8309, Accuracy: 0.5533\n","Training loss (for one batch) at step 60: 303.4431, Accuracy: 0.5459\n","Training loss (for one batch) at step 70: 288.3904, Accuracy: 0.5407\n","Training loss (for one batch) at step 80: 290.2413, Accuracy: 0.5409\n","Training loss (for one batch) at step 90: 300.2766, Accuracy: 0.5420\n","Training loss (for one batch) at step 100: 303.7953, Accuracy: 0.5435\n","Training loss (for one batch) at step 110: 309.9390, Accuracy: 0.5450\n","Training loss (for one batch) at step 120: 297.9265, Accuracy: 0.5419\n","Training loss (for one batch) at step 130: 280.7610, Accuracy: 0.5396\n","Training loss (for one batch) at step 140: 290.8787, Accuracy: 0.5383\n","---- Training ----\n","Training loss: 256.3725\n","Training acc over epoch: 0.5403\n","---- Validation ----\n","Validation loss: 82.1589\n","Validation acc: 0.5476\n","Time taken: 60.32s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 317.9440, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 283.1938, Accuracy: 0.5900\n","Training loss (for one batch) at step 20: 287.8340, Accuracy: 0.5843\n","Training loss (for one batch) at step 30: 288.6461, Accuracy: 0.5661\n","Training loss (for one batch) at step 40: 287.3683, Accuracy: 0.5585\n","Training loss (for one batch) at step 50: 298.9772, Accuracy: 0.5463\n","Training loss (for one batch) at step 60: 307.2817, Accuracy: 0.5397\n","Training loss (for one batch) at step 70: 288.1541, Accuracy: 0.5386\n","Training loss (for one batch) at step 80: 297.2254, Accuracy: 0.5368\n","Training loss (for one batch) at step 90: 305.5429, Accuracy: 0.5388\n","Training loss (for one batch) at step 100: 282.4576, Accuracy: 0.5431\n","Training loss (for one batch) at step 110: 293.7168, Accuracy: 0.5441\n","Training loss (for one batch) at step 120: 295.7979, Accuracy: 0.5427\n","Training loss (for one batch) at step 130: 297.1122, Accuracy: 0.5388\n","Training loss (for one batch) at step 140: 299.8632, Accuracy: 0.5374\n","---- Training ----\n","Training loss: 269.4606\n","Training acc over epoch: 0.5392\n","---- Validation ----\n","Validation loss: 84.9520\n","Validation acc: 0.5398\n","Time taken: 59.95s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 308.7594, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 302.3310, Accuracy: 0.5855\n","Training loss (for one batch) at step 20: 298.4171, Accuracy: 0.5710\n","Training loss (for one batch) at step 30: 301.5148, Accuracy: 0.5687\n","Training loss (for one batch) at step 40: 278.5379, Accuracy: 0.5563\n","Training loss (for one batch) at step 50: 288.8513, Accuracy: 0.5429\n","Training loss (for one batch) at step 60: 310.5944, Accuracy: 0.5379\n","Training loss (for one batch) at step 70: 293.9958, Accuracy: 0.5308\n","Training loss (for one batch) at step 80: 296.0932, Accuracy: 0.5320\n","Training loss (for one batch) at step 90: 313.2462, Accuracy: 0.5334\n","Training loss (for one batch) at step 100: 293.6788, Accuracy: 0.5393\n","Training loss (for one batch) at step 110: 290.5818, Accuracy: 0.5417\n","Training loss (for one batch) at step 120: 292.3132, Accuracy: 0.5401\n","Training loss (for one batch) at step 130: 286.9351, Accuracy: 0.5383\n","Training loss (for one batch) at step 140: 306.0729, Accuracy: 0.5387\n","---- Training ----\n","Training loss: 253.8223\n","Training acc over epoch: 0.5392\n","---- Validation ----\n","Validation loss: 78.6945\n","Validation acc: 0.5349\n","Time taken: 60.01s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 300.1634, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 296.0390, Accuracy: 0.5827\n","Training loss (for one batch) at step 20: 283.4761, Accuracy: 0.5790\n","Training loss (for one batch) at step 30: 291.4289, Accuracy: 0.5735\n","Training loss (for one batch) at step 40: 281.3301, Accuracy: 0.5573\n","Training loss (for one batch) at step 50: 279.8319, Accuracy: 0.5476\n","Training loss (for one batch) at step 60: 290.8257, Accuracy: 0.5407\n","Training loss (for one batch) at step 70: 285.7980, Accuracy: 0.5359\n","Training loss (for one batch) at step 80: 300.8836, Accuracy: 0.5348\n","Training loss (for one batch) at step 90: 281.6218, Accuracy: 0.5360\n","Training loss (for one batch) at step 100: 296.4056, Accuracy: 0.5400\n","Training loss (for one batch) at step 110: 288.5163, Accuracy: 0.5426\n","Training loss (for one batch) at step 120: 283.6032, Accuracy: 0.5399\n","Training loss (for one batch) at step 130: 280.0110, Accuracy: 0.5370\n","Training loss (for one batch) at step 140: 282.0896, Accuracy: 0.5361\n","---- Training ----\n","Training loss: 261.9459\n","Training acc over epoch: 0.5367\n","---- Validation ----\n","Validation loss: 86.2573\n","Validation acc: 0.5435\n","Time taken: 59.46s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 309.1046, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 307.5515, Accuracy: 0.6191\n","Training loss (for one batch) at step 20: 297.1652, Accuracy: 0.5948\n","Training loss (for one batch) at step 30: 294.4981, Accuracy: 0.5768\n","Training loss (for one batch) at step 40: 289.8372, Accuracy: 0.5598\n","Training loss (for one batch) at step 50: 296.3187, Accuracy: 0.5484\n","Training loss (for one batch) at step 60: 293.5527, Accuracy: 0.5374\n","Training loss (for one batch) at step 70: 284.1288, Accuracy: 0.5330\n","Training loss (for one batch) at step 80: 292.2429, Accuracy: 0.5338\n","Training loss (for one batch) at step 90: 290.8568, Accuracy: 0.5381\n","Training loss (for one batch) at step 100: 286.1481, Accuracy: 0.5395\n","Training loss (for one batch) at step 110: 304.8803, Accuracy: 0.5399\n","Training loss (for one batch) at step 120: 294.6198, Accuracy: 0.5380\n","Training loss (for one batch) at step 130: 299.0451, Accuracy: 0.5360\n","Training loss (for one batch) at step 140: 276.9734, Accuracy: 0.5338\n","---- Training ----\n","Training loss: 248.9415\n","Training acc over epoch: 0.5348\n","---- Validation ----\n","Validation loss: 77.7899\n","Validation acc: 0.5449\n","Time taken: 52.66s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 292.7941, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 288.1159, Accuracy: 0.6136\n","Training loss (for one batch) at step 20: 271.7322, Accuracy: 0.5848\n","Training loss (for one batch) at step 30: 287.6173, Accuracy: 0.5671\n","Training loss (for one batch) at step 40: 286.7916, Accuracy: 0.5502\n","Training loss (for one batch) at step 50: 283.1916, Accuracy: 0.5380\n","Training loss (for one batch) at step 60: 279.3706, Accuracy: 0.5325\n","Training loss (for one batch) at step 70: 286.8518, Accuracy: 0.5315\n","Training loss (for one batch) at step 80: 293.8423, Accuracy: 0.5323\n","Training loss (for one batch) at step 90: 293.6621, Accuracy: 0.5340\n","Training loss (for one batch) at step 100: 286.9604, Accuracy: 0.5380\n","Training loss (for one batch) at step 110: 295.0456, Accuracy: 0.5412\n","Training loss (for one batch) at step 120: 285.5421, Accuracy: 0.5403\n","Training loss (for one batch) at step 130: 282.3210, Accuracy: 0.5360\n","Training loss (for one batch) at step 140: 284.7571, Accuracy: 0.5343\n","---- Training ----\n","Training loss: 253.9462\n","Training acc over epoch: 0.5353\n","---- Validation ----\n","Validation loss: 80.9145\n","Validation acc: 0.5384\n","Time taken: 54.51s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.5269\n","Validation AUC: 0.5282\n","Validation Balanced_ACC: 0.2228\n","Validation MI: 0.0381\n","Validation Normalized MI: 0.0555\n","Validation Adjusted MI: 0.0555\n","\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-04 14:52:59.862148: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 628 of 1024\n","2023-02-04 14:53:01.016213: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 506.0920, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 484.5080, Accuracy: 0.5200\n","Training loss (for one batch) at step 20: 510.9998, Accuracy: 0.5267\n","Training loss (for one batch) at step 30: 486.6156, Accuracy: 0.5190\n","Training loss (for one batch) at step 40: 474.3538, Accuracy: 0.5117\n","Training loss (for one batch) at step 50: 496.3777, Accuracy: 0.5157\n","Training loss (for one batch) at step 60: 471.9480, Accuracy: 0.5138\n","Training loss (for one batch) at step 70: 437.8120, Accuracy: 0.5161\n","Training loss (for one batch) at step 80: 477.4695, Accuracy: 0.5163\n","Training loss (for one batch) at step 90: 463.7956, Accuracy: 0.5188\n","Training loss (for one batch) at step 100: 465.6212, Accuracy: 0.5173\n","Training loss (for one batch) at step 110: 478.5704, Accuracy: 0.5158\n","Training loss (for one batch) at step 120: 443.3830, Accuracy: 0.5166\n","Training loss (for one batch) at step 130: 450.7891, Accuracy: 0.5162\n","Training loss (for one batch) at step 140: 435.8438, Accuracy: 0.5164\n","---- Training ----\n","Training loss: 408.4094\n","Training acc over epoch: 0.5173\n","---- Validation ----\n","Validation loss: 76.9933\n","Validation acc: 0.4801\n","Time taken: 71.31s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 424.1264, Accuracy: 0.4700\n","Training loss (for one batch) at step 10: 445.5172, Accuracy: 0.5209\n","Training loss (for one batch) at step 20: 444.5091, Accuracy: 0.5190\n","Training loss (for one batch) at step 30: 394.1301, Accuracy: 0.5110\n","Training loss (for one batch) at step 40: 440.2781, Accuracy: 0.5117\n","Training loss (for one batch) at step 50: 448.5295, Accuracy: 0.5090\n","Training loss (for one batch) at step 60: 404.0046, Accuracy: 0.5102\n","Training loss (for one batch) at step 70: 417.1227, Accuracy: 0.5132\n","Training loss (for one batch) at step 80: 453.9399, Accuracy: 0.5119\n","Training loss (for one batch) at step 90: 432.3094, Accuracy: 0.5134\n","Training loss (for one batch) at step 100: 416.8249, Accuracy: 0.5123\n","Training loss (for one batch) at step 110: 434.5895, Accuracy: 0.5097\n","Training loss (for one batch) at step 120: 411.8766, Accuracy: 0.5108\n","Training loss (for one batch) at step 130: 412.4223, Accuracy: 0.5113\n","Training loss (for one batch) at step 140: 399.5160, Accuracy: 0.5104\n","---- Training ----\n","Training loss: 351.2694\n","Training acc over epoch: 0.5114\n","---- Validation ----\n","Validation loss: 77.5444\n","Validation acc: 0.5059\n","Time taken: 45.93s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 415.4022, Accuracy: 0.4700\n","Training loss (for one batch) at step 10: 396.7973, Accuracy: 0.5127\n","Training loss (for one batch) at step 20: 398.8356, Accuracy: 0.5105\n","Training loss (for one batch) at step 30: 393.0471, Accuracy: 0.5145\n","Training loss (for one batch) at step 40: 389.3087, Accuracy: 0.5178\n","Training loss (for one batch) at step 50: 401.2429, Accuracy: 0.5192\n","Training loss (for one batch) at step 60: 394.3807, Accuracy: 0.5256\n","Training loss (for one batch) at step 70: 389.3023, Accuracy: 0.5268\n","Training loss (for one batch) at step 80: 394.4897, Accuracy: 0.5260\n","Training loss (for one batch) at step 90: 397.2536, Accuracy: 0.5248\n","Training loss (for one batch) at step 100: 394.9556, Accuracy: 0.5246\n","Training loss (for one batch) at step 110: 389.2457, Accuracy: 0.5244\n","Training loss (for one batch) at step 120: 368.4522, Accuracy: 0.5259\n","Training loss (for one batch) at step 130: 375.0760, Accuracy: 0.5247\n","Training loss (for one batch) at step 140: 382.0723, Accuracy: 0.5262\n","---- Training ----\n","Training loss: 329.3769\n","Training acc over epoch: 0.5244\n","---- Validation ----\n","Validation loss: 78.0844\n","Validation acc: 0.4941\n","Time taken: 46.50s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 378.7973, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 366.4337, Accuracy: 0.5145\n","Training loss (for one batch) at step 20: 387.8419, Accuracy: 0.5119\n","Training loss (for one batch) at step 30: 378.8317, Accuracy: 0.5200\n","Training loss (for one batch) at step 40: 389.6220, Accuracy: 0.5249\n","Training loss (for one batch) at step 50: 379.8093, Accuracy: 0.5312\n","Training loss (for one batch) at step 60: 371.1957, Accuracy: 0.5298\n","Training loss (for one batch) at step 70: 374.1033, Accuracy: 0.5280\n","Training loss (for one batch) at step 80: 362.0887, Accuracy: 0.5296\n","Training loss (for one batch) at step 90: 363.2621, Accuracy: 0.5329\n","Training loss (for one batch) at step 100: 369.3101, Accuracy: 0.5313\n","Training loss (for one batch) at step 110: 367.8297, Accuracy: 0.5330\n","Training loss (for one batch) at step 120: 367.1566, Accuracy: 0.5309\n","Training loss (for one batch) at step 130: 378.8504, Accuracy: 0.5312\n","Training loss (for one batch) at step 140: 378.2056, Accuracy: 0.5308\n","---- Training ----\n","Training loss: 325.5069\n","Training acc over epoch: 0.5323\n","---- Validation ----\n","Validation loss: 77.1387\n","Validation acc: 0.5494\n","Time taken: 42.21s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 367.4080, Accuracy: 0.4400\n","Training loss (for one batch) at step 10: 368.7549, Accuracy: 0.4909\n","Training loss (for one batch) at step 20: 367.8559, Accuracy: 0.4976\n","Training loss (for one batch) at step 30: 363.3984, Accuracy: 0.5181\n","Training loss (for one batch) at step 40: 372.1264, Accuracy: 0.5115\n","Training loss (for one batch) at step 50: 366.5978, Accuracy: 0.5161\n","Training loss (for one batch) at step 60: 363.3095, Accuracy: 0.5174\n","Training loss (for one batch) at step 70: 377.2898, Accuracy: 0.5183\n","Training loss (for one batch) at step 80: 360.9517, Accuracy: 0.5226\n","Training loss (for one batch) at step 90: 359.3984, Accuracy: 0.5231\n","Training loss (for one batch) at step 100: 368.3282, Accuracy: 0.5224\n","Training loss (for one batch) at step 110: 369.0268, Accuracy: 0.5245\n","Training loss (for one batch) at step 120: 368.5178, Accuracy: 0.5236\n","Training loss (for one batch) at step 130: 358.3538, Accuracy: 0.5250\n","Training loss (for one batch) at step 140: 363.7481, Accuracy: 0.5254\n","---- Training ----\n","Training loss: 326.3453\n","Training acc over epoch: 0.5251\n","---- Validation ----\n","Validation loss: 75.6393\n","Validation acc: 0.5841\n","Time taken: 57.84s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 363.6118, Accuracy: 0.4800\n","Training loss (for one batch) at step 10: 357.7001, Accuracy: 0.5127\n","Training loss (for one batch) at step 20: 361.1237, Accuracy: 0.5152\n","Training loss (for one batch) at step 30: 362.5999, Accuracy: 0.5161\n","Training loss (for one batch) at step 40: 358.4818, Accuracy: 0.5193\n","Training loss (for one batch) at step 50: 357.4432, Accuracy: 0.5227\n","Training loss (for one batch) at step 60: 359.6821, Accuracy: 0.5213\n","Training loss (for one batch) at step 70: 366.3629, Accuracy: 0.5266\n","Training loss (for one batch) at step 80: 370.0302, Accuracy: 0.5291\n","Training loss (for one batch) at step 90: 353.0850, Accuracy: 0.5313\n","Training loss (for one batch) at step 100: 351.0968, Accuracy: 0.5342\n","Training loss (for one batch) at step 110: 368.1855, Accuracy: 0.5361\n","Training loss (for one batch) at step 120: 357.5479, Accuracy: 0.5352\n","Training loss (for one batch) at step 130: 357.0316, Accuracy: 0.5325\n","Training loss (for one batch) at step 140: 354.9185, Accuracy: 0.5326\n","---- Training ----\n","Training loss: 317.6107\n","Training acc over epoch: 0.5327\n","---- Validation ----\n","Validation loss: 76.0176\n","Validation acc: 0.5927\n","Time taken: 44.15s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 350.7717, Accuracy: 0.4500\n","Training loss (for one batch) at step 10: 368.9113, Accuracy: 0.5300\n","Training loss (for one batch) at step 20: 352.4701, Accuracy: 0.5205\n","Training loss (for one batch) at step 30: 361.1774, Accuracy: 0.5239\n","Training loss (for one batch) at step 40: 357.8835, Accuracy: 0.5298\n","Training loss (for one batch) at step 50: 354.6324, Accuracy: 0.5329\n","Training loss (for one batch) at step 60: 354.7510, Accuracy: 0.5303\n","Training loss (for one batch) at step 70: 351.7689, Accuracy: 0.5349\n","Training loss (for one batch) at step 80: 356.9058, Accuracy: 0.5335\n","Training loss (for one batch) at step 90: 351.0455, Accuracy: 0.5352\n","Training loss (for one batch) at step 100: 354.9843, Accuracy: 0.5369\n","Training loss (for one batch) at step 110: 356.6476, Accuracy: 0.5368\n","Training loss (for one batch) at step 120: 355.1963, Accuracy: 0.5402\n","Training loss (for one batch) at step 130: 361.4750, Accuracy: 0.5397\n","Training loss (for one batch) at step 140: 358.9591, Accuracy: 0.5394\n","---- Training ----\n","Training loss: 312.2762\n","Training acc over epoch: 0.5386\n","---- Validation ----\n","Validation loss: 76.5828\n","Validation acc: 0.6061\n","Time taken: 54.57s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 352.1852, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 354.7264, Accuracy: 0.5455\n","Training loss (for one batch) at step 20: 350.3119, Accuracy: 0.5600\n","Training loss (for one batch) at step 30: 352.2480, Accuracy: 0.5587\n","Training loss (for one batch) at step 40: 345.9816, Accuracy: 0.5580\n","Training loss (for one batch) at step 50: 362.4955, Accuracy: 0.5576\n","Training loss (for one batch) at step 60: 355.7475, Accuracy: 0.5584\n","Training loss (for one batch) at step 70: 350.8719, Accuracy: 0.5568\n","Training loss (for one batch) at step 80: 347.7376, Accuracy: 0.5574\n","Training loss (for one batch) at step 90: 351.9968, Accuracy: 0.5546\n","Training loss (for one batch) at step 100: 350.9843, Accuracy: 0.5563\n","Training loss (for one batch) at step 110: 353.8492, Accuracy: 0.5549\n","Training loss (for one batch) at step 120: 349.8835, Accuracy: 0.5540\n","Training loss (for one batch) at step 130: 348.5919, Accuracy: 0.5549\n","Training loss (for one batch) at step 140: 346.8133, Accuracy: 0.5561\n","---- Training ----\n","Training loss: 311.1110\n","Training acc over epoch: 0.5574\n","---- Validation ----\n","Validation loss: 76.6407\n","Validation acc: 0.6024\n","Time taken: 52.60s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 351.6726, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 351.8934, Accuracy: 0.5436\n","Training loss (for one batch) at step 20: 351.4466, Accuracy: 0.5429\n","Training loss (for one batch) at step 30: 347.4945, Accuracy: 0.5552\n","Training loss (for one batch) at step 40: 349.9377, Accuracy: 0.5612\n","Training loss (for one batch) at step 50: 349.0636, Accuracy: 0.5604\n","Training loss (for one batch) at step 60: 350.4687, Accuracy: 0.5562\n","Training loss (for one batch) at step 70: 349.6148, Accuracy: 0.5561\n","Training loss (for one batch) at step 80: 351.7079, Accuracy: 0.5584\n","Training loss (for one batch) at step 90: 353.3060, Accuracy: 0.5595\n","Training loss (for one batch) at step 100: 361.2916, Accuracy: 0.5584\n","Training loss (for one batch) at step 110: 344.3721, Accuracy: 0.5601\n","Training loss (for one batch) at step 120: 354.1941, Accuracy: 0.5614\n","Training loss (for one batch) at step 130: 354.4671, Accuracy: 0.5598\n","Training loss (for one batch) at step 140: 354.1544, Accuracy: 0.5596\n","---- Training ----\n","Training loss: 306.6865\n","Training acc over epoch: 0.5605\n","---- Validation ----\n","Validation loss: 76.0070\n","Validation acc: 0.6158\n","Time taken: 49.93s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 347.9162, Accuracy: 0.5400\n","Training loss (for one batch) at step 10: 351.2650, Accuracy: 0.5782\n","Training loss (for one batch) at step 20: 347.2047, Accuracy: 0.5876\n","Training loss (for one batch) at step 30: 353.3907, Accuracy: 0.5816\n","Training loss (for one batch) at step 40: 350.5362, Accuracy: 0.5773\n","Training loss (for one batch) at step 50: 347.8533, Accuracy: 0.5737\n","Training loss (for one batch) at step 60: 345.7950, Accuracy: 0.5734\n","Training loss (for one batch) at step 70: 347.3777, Accuracy: 0.5741\n","Training loss (for one batch) at step 80: 343.2352, Accuracy: 0.5769\n","Training loss (for one batch) at step 90: 347.3680, Accuracy: 0.5767\n","Training loss (for one batch) at step 100: 349.7099, Accuracy: 0.5747\n","Training loss (for one batch) at step 110: 344.4461, Accuracy: 0.5737\n","Training loss (for one batch) at step 120: 354.8561, Accuracy: 0.5750\n","Training loss (for one batch) at step 130: 347.7299, Accuracy: 0.5774\n","Training loss (for one batch) at step 140: 348.0383, Accuracy: 0.5778\n","---- Training ----\n","Training loss: 303.1534\n","Training acc over epoch: 0.5756\n","---- Validation ----\n","Validation loss: 77.1146\n","Validation acc: 0.6147\n","Time taken: 58.52s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 343.5643, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 346.4339, Accuracy: 0.5955\n","Training loss (for one batch) at step 20: 348.8033, Accuracy: 0.5957\n","Training loss (for one batch) at step 30: 353.2575, Accuracy: 0.5871\n","Training loss (for one batch) at step 40: 344.3276, Accuracy: 0.5873\n","Training loss (for one batch) at step 50: 348.2214, Accuracy: 0.5833\n","Training loss (for one batch) at step 60: 343.8048, Accuracy: 0.5889\n","Training loss (for one batch) at step 70: 344.6427, Accuracy: 0.5876\n","Training loss (for one batch) at step 80: 349.3387, Accuracy: 0.5893\n","Training loss (for one batch) at step 90: 346.5788, Accuracy: 0.5889\n","Training loss (for one batch) at step 100: 348.2703, Accuracy: 0.5905\n","Training loss (for one batch) at step 110: 348.6995, Accuracy: 0.5903\n","Training loss (for one batch) at step 120: 345.6771, Accuracy: 0.5919\n","Training loss (for one batch) at step 130: 345.9414, Accuracy: 0.5931\n","Training loss (for one batch) at step 140: 345.6422, Accuracy: 0.5937\n","---- Training ----\n","Training loss: 307.1667\n","Training acc over epoch: 0.5950\n","---- Validation ----\n","Validation loss: 76.5011\n","Validation acc: 0.6325\n","Time taken: 67.34s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 344.9276, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 347.8914, Accuracy: 0.5773\n","Training loss (for one batch) at step 20: 341.7962, Accuracy: 0.5729\n","Training loss (for one batch) at step 30: 344.5405, Accuracy: 0.5868\n","Training loss (for one batch) at step 40: 343.8182, Accuracy: 0.5939\n","Training loss (for one batch) at step 50: 344.4091, Accuracy: 0.5927\n","Training loss (for one batch) at step 60: 340.7177, Accuracy: 0.5956\n","Training loss (for one batch) at step 70: 351.7553, Accuracy: 0.5972\n","Training loss (for one batch) at step 80: 352.4034, Accuracy: 0.6001\n","Training loss (for one batch) at step 90: 346.6070, Accuracy: 0.6049\n","Training loss (for one batch) at step 100: 350.6727, Accuracy: 0.6023\n","Training loss (for one batch) at step 110: 350.4449, Accuracy: 0.6024\n","Training loss (for one batch) at step 120: 346.1571, Accuracy: 0.6032\n","Training loss (for one batch) at step 130: 345.4149, Accuracy: 0.6023\n","Training loss (for one batch) at step 140: 345.5080, Accuracy: 0.6026\n","---- Training ----\n","Training loss: 303.2911\n","Training acc over epoch: 0.6033\n","---- Validation ----\n","Validation loss: 77.3919\n","Validation acc: 0.6252\n","Time taken: 64.95s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 351.0021, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 345.4710, Accuracy: 0.6118\n","Training loss (for one batch) at step 20: 343.4073, Accuracy: 0.6071\n","Training loss (for one batch) at step 30: 347.2596, Accuracy: 0.6081\n","Training loss (for one batch) at step 40: 347.2379, Accuracy: 0.6154\n","Training loss (for one batch) at step 50: 351.5294, Accuracy: 0.6163\n","Training loss (for one batch) at step 60: 345.8925, Accuracy: 0.6195\n","Training loss (for one batch) at step 70: 347.4471, Accuracy: 0.6214\n","Training loss (for one batch) at step 80: 348.1859, Accuracy: 0.6200\n","Training loss (for one batch) at step 90: 346.2267, Accuracy: 0.6218\n","Training loss (for one batch) at step 100: 346.4803, Accuracy: 0.6244\n","Training loss (for one batch) at step 110: 343.6687, Accuracy: 0.6203\n","Training loss (for one batch) at step 120: 346.4054, Accuracy: 0.6203\n","Training loss (for one batch) at step 130: 343.9514, Accuracy: 0.6189\n","Training loss (for one batch) at step 140: 347.5795, Accuracy: 0.6172\n","---- Training ----\n","Training loss: 307.0051\n","Training acc over epoch: 0.6186\n","---- Validation ----\n","Validation loss: 76.9355\n","Validation acc: 0.6537\n","Time taken: 52.66s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 347.4189, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 348.7463, Accuracy: 0.6318\n","Training loss (for one batch) at step 20: 346.6858, Accuracy: 0.6214\n","Training loss (for one batch) at step 30: 342.5636, Accuracy: 0.6187\n","Training loss (for one batch) at step 40: 341.4637, Accuracy: 0.6171\n","Training loss (for one batch) at step 50: 342.8113, Accuracy: 0.6204\n","Training loss (for one batch) at step 60: 341.1560, Accuracy: 0.6207\n","Training loss (for one batch) at step 70: 339.6269, Accuracy: 0.6235\n","Training loss (for one batch) at step 80: 339.2141, Accuracy: 0.6281\n","Training loss (for one batch) at step 90: 344.9948, Accuracy: 0.6265\n","Training loss (for one batch) at step 100: 351.0197, Accuracy: 0.6258\n","Training loss (for one batch) at step 110: 342.7625, Accuracy: 0.6269\n","Training loss (for one batch) at step 120: 340.1269, Accuracy: 0.6269\n","Training loss (for one batch) at step 130: 345.3149, Accuracy: 0.6266\n","Training loss (for one batch) at step 140: 345.5386, Accuracy: 0.6271\n","---- Training ----\n","Training loss: 302.3706\n","Training acc over epoch: 0.6277\n","---- Validation ----\n","Validation loss: 77.2438\n","Validation acc: 0.6582\n","Time taken: 58.00s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 346.5225, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 342.5568, Accuracy: 0.6264\n","Training loss (for one batch) at step 20: 348.4970, Accuracy: 0.6138\n","Training loss (for one batch) at step 30: 340.0809, Accuracy: 0.6168\n","Training loss (for one batch) at step 40: 340.4901, Accuracy: 0.6234\n","Training loss (for one batch) at step 50: 343.5056, Accuracy: 0.6318\n","Training loss (for one batch) at step 60: 339.2746, Accuracy: 0.6387\n","Training loss (for one batch) at step 70: 342.8786, Accuracy: 0.6415\n","Training loss (for one batch) at step 80: 340.9327, Accuracy: 0.6447\n","Training loss (for one batch) at step 90: 346.1125, Accuracy: 0.6462\n","Training loss (for one batch) at step 100: 347.8886, Accuracy: 0.6458\n","Training loss (for one batch) at step 110: 343.2798, Accuracy: 0.6449\n","Training loss (for one batch) at step 120: 345.4684, Accuracy: 0.6443\n","Training loss (for one batch) at step 130: 340.4609, Accuracy: 0.6460\n","Training loss (for one batch) at step 140: 344.5004, Accuracy: 0.6479\n","---- Training ----\n","Training loss: 301.9349\n","Training acc over epoch: 0.6472\n","---- Validation ----\n","Validation loss: 76.9265\n","Validation acc: 0.6765\n","Time taken: 55.19s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 352.6883, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 345.1693, Accuracy: 0.6336\n","Training loss (for one batch) at step 20: 343.6043, Accuracy: 0.6210\n","Training loss (for one batch) at step 30: 341.7390, Accuracy: 0.6365\n","Training loss (for one batch) at step 40: 340.5663, Accuracy: 0.6471\n","Training loss (for one batch) at step 50: 334.3983, Accuracy: 0.6486\n","Training loss (for one batch) at step 60: 332.6888, Accuracy: 0.6530\n","Training loss (for one batch) at step 70: 338.6740, Accuracy: 0.6566\n","Training loss (for one batch) at step 80: 337.0538, Accuracy: 0.6606\n","Training loss (for one batch) at step 90: 345.7135, Accuracy: 0.6614\n","Training loss (for one batch) at step 100: 339.2757, Accuracy: 0.6608\n","Training loss (for one batch) at step 110: 342.0877, Accuracy: 0.6569\n","Training loss (for one batch) at step 120: 342.2380, Accuracy: 0.6545\n","Training loss (for one batch) at step 130: 346.6757, Accuracy: 0.6544\n","Training loss (for one batch) at step 140: 342.6181, Accuracy: 0.6525\n","---- Training ----\n","Training loss: 302.9583\n","Training acc over epoch: 0.6523\n","---- Validation ----\n","Validation loss: 74.9176\n","Validation acc: 0.6687\n","Time taken: 58.33s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 346.5034, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 346.9429, Accuracy: 0.6218\n","Training loss (for one batch) at step 20: 348.0181, Accuracy: 0.6290\n","Training loss (for one batch) at step 30: 340.6200, Accuracy: 0.6365\n","Training loss (for one batch) at step 40: 338.6197, Accuracy: 0.6471\n","Training loss (for one batch) at step 50: 340.4503, Accuracy: 0.6529\n","Training loss (for one batch) at step 60: 334.5394, Accuracy: 0.6557\n","Training loss (for one batch) at step 70: 331.1021, Accuracy: 0.6599\n","Training loss (for one batch) at step 80: 336.5583, Accuracy: 0.6633\n","Training loss (for one batch) at step 90: 348.3918, Accuracy: 0.6656\n","Training loss (for one batch) at step 100: 342.5565, Accuracy: 0.6628\n","Training loss (for one batch) at step 110: 344.0631, Accuracy: 0.6615\n","Training loss (for one batch) at step 120: 339.9943, Accuracy: 0.6638\n","Training loss (for one batch) at step 130: 343.6255, Accuracy: 0.6642\n","Training loss (for one batch) at step 140: 342.0966, Accuracy: 0.6640\n","---- Training ----\n","Training loss: 298.5501\n","Training acc over epoch: 0.6632\n","---- Validation ----\n","Validation loss: 77.5280\n","Validation acc: 0.6574\n","Time taken: 54.24s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 341.8640, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 340.5334, Accuracy: 0.6345\n","Training loss (for one batch) at step 20: 339.5646, Accuracy: 0.6429\n","Training loss (for one batch) at step 30: 329.8758, Accuracy: 0.6516\n","Training loss (for one batch) at step 40: 343.2054, Accuracy: 0.6520\n","Training loss (for one batch) at step 50: 334.5660, Accuracy: 0.6588\n","Training loss (for one batch) at step 60: 343.6563, Accuracy: 0.6634\n","Training loss (for one batch) at step 70: 335.4227, Accuracy: 0.6700\n","Training loss (for one batch) at step 80: 338.5106, Accuracy: 0.6726\n","Training loss (for one batch) at step 90: 341.1762, Accuracy: 0.6731\n","Training loss (for one batch) at step 100: 349.7682, Accuracy: 0.6705\n","Training loss (for one batch) at step 110: 334.0049, Accuracy: 0.6686\n","Training loss (for one batch) at step 120: 338.3788, Accuracy: 0.6679\n","Training loss (for one batch) at step 130: 333.6010, Accuracy: 0.6695\n","Training loss (for one batch) at step 140: 336.3720, Accuracy: 0.6681\n","---- Training ----\n","Training loss: 298.8089\n","Training acc over epoch: 0.6671\n","---- Validation ----\n","Validation loss: 78.5851\n","Validation acc: 0.6730\n","Time taken: 54.59s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 340.5428, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 346.0736, Accuracy: 0.6591\n","Training loss (for one batch) at step 20: 340.9084, Accuracy: 0.6586\n","Training loss (for one batch) at step 30: 332.6398, Accuracy: 0.6655\n","Training loss (for one batch) at step 40: 334.8896, Accuracy: 0.6646\n","Training loss (for one batch) at step 50: 337.8025, Accuracy: 0.6688\n","Training loss (for one batch) at step 60: 337.8270, Accuracy: 0.6711\n","Training loss (for one batch) at step 70: 332.1762, Accuracy: 0.6738\n","Training loss (for one batch) at step 80: 335.5511, Accuracy: 0.6773\n","Training loss (for one batch) at step 90: 342.4500, Accuracy: 0.6781\n","Training loss (for one batch) at step 100: 336.6492, Accuracy: 0.6762\n","Training loss (for one batch) at step 110: 342.6785, Accuracy: 0.6750\n","Training loss (for one batch) at step 120: 339.2952, Accuracy: 0.6760\n","Training loss (for one batch) at step 130: 327.8317, Accuracy: 0.6760\n","Training loss (for one batch) at step 140: 337.0857, Accuracy: 0.6743\n","---- Training ----\n","Training loss: 301.9355\n","Training acc over epoch: 0.6722\n","---- Validation ----\n","Validation loss: 76.4512\n","Validation acc: 0.6725\n","Time taken: 52.37s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 341.6335, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 343.3985, Accuracy: 0.6573\n","Training loss (for one batch) at step 20: 335.7186, Accuracy: 0.6438\n","Training loss (for one batch) at step 30: 324.7721, Accuracy: 0.6542\n","Training loss (for one batch) at step 40: 335.6642, Accuracy: 0.6632\n","Training loss (for one batch) at step 50: 326.6747, Accuracy: 0.6739\n","Training loss (for one batch) at step 60: 330.5176, Accuracy: 0.6769\n","Training loss (for one batch) at step 70: 326.7289, Accuracy: 0.6800\n","Training loss (for one batch) at step 80: 334.9715, Accuracy: 0.6817\n","Training loss (for one batch) at step 90: 341.2689, Accuracy: 0.6826\n","Training loss (for one batch) at step 100: 336.4829, Accuracy: 0.6805\n","Training loss (for one batch) at step 110: 334.9771, Accuracy: 0.6776\n","Training loss (for one batch) at step 120: 330.8887, Accuracy: 0.6771\n","Training loss (for one batch) at step 130: 343.4453, Accuracy: 0.6779\n","Training loss (for one batch) at step 140: 341.1177, Accuracy: 0.6777\n","---- Training ----\n","Training loss: 295.9355\n","Training acc over epoch: 0.6774\n","---- Validation ----\n","Validation loss: 76.7731\n","Validation acc: 0.6703\n","Time taken: 54.95s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 337.4669, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 339.6238, Accuracy: 0.6655\n","Training loss (for one batch) at step 20: 334.9020, Accuracy: 0.6586\n","Training loss (for one batch) at step 30: 338.0204, Accuracy: 0.6632\n","Training loss (for one batch) at step 40: 327.6107, Accuracy: 0.6732\n","Training loss (for one batch) at step 50: 330.2162, Accuracy: 0.6804\n","Training loss (for one batch) at step 60: 321.4818, Accuracy: 0.6843\n","Training loss (for one batch) at step 70: 331.2086, Accuracy: 0.6872\n","Training loss (for one batch) at step 80: 336.5920, Accuracy: 0.6862\n","Training loss (for one batch) at step 90: 334.9549, Accuracy: 0.6860\n","Training loss (for one batch) at step 100: 342.7253, Accuracy: 0.6820\n","Training loss (for one batch) at step 110: 332.1324, Accuracy: 0.6790\n","Training loss (for one batch) at step 120: 327.3835, Accuracy: 0.6780\n","Training loss (for one batch) at step 130: 331.3603, Accuracy: 0.6798\n","Training loss (for one batch) at step 140: 336.1852, Accuracy: 0.6784\n","---- Training ----\n","Training loss: 289.3240\n","Training acc over epoch: 0.6776\n","---- Validation ----\n","Validation loss: 76.1854\n","Validation acc: 0.6711\n","Time taken: 54.30s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 334.0664, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 338.1078, Accuracy: 0.6591\n","Training loss (for one batch) at step 20: 343.0141, Accuracy: 0.6614\n","Training loss (for one batch) at step 30: 329.4432, Accuracy: 0.6645\n","Training loss (for one batch) at step 40: 322.9007, Accuracy: 0.6737\n","Training loss (for one batch) at step 50: 324.0674, Accuracy: 0.6824\n","Training loss (for one batch) at step 60: 330.8295, Accuracy: 0.6890\n","Training loss (for one batch) at step 70: 321.7038, Accuracy: 0.6949\n","Training loss (for one batch) at step 80: 329.6864, Accuracy: 0.6968\n","Training loss (for one batch) at step 90: 338.1431, Accuracy: 0.6967\n","Training loss (for one batch) at step 100: 338.8903, Accuracy: 0.6932\n","Training loss (for one batch) at step 110: 331.9272, Accuracy: 0.6906\n","Training loss (for one batch) at step 120: 318.2737, Accuracy: 0.6918\n","Training loss (for one batch) at step 130: 334.9695, Accuracy: 0.6922\n","Training loss (for one batch) at step 140: 339.9846, Accuracy: 0.6916\n","---- Training ----\n","Training loss: 296.9060\n","Training acc over epoch: 0.6900\n","---- Validation ----\n","Validation loss: 76.2104\n","Validation acc: 0.6738\n","Time taken: 55.54s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 344.2441, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 337.5821, Accuracy: 0.6536\n","Training loss (for one batch) at step 20: 326.3172, Accuracy: 0.6581\n","Training loss (for one batch) at step 30: 328.9858, Accuracy: 0.6703\n","Training loss (for one batch) at step 40: 319.0520, Accuracy: 0.6776\n","Training loss (for one batch) at step 50: 321.6719, Accuracy: 0.6857\n","Training loss (for one batch) at step 60: 319.7620, Accuracy: 0.6907\n","Training loss (for one batch) at step 70: 322.9195, Accuracy: 0.6949\n","Training loss (for one batch) at step 80: 337.9840, Accuracy: 0.6978\n","Training loss (for one batch) at step 90: 336.8731, Accuracy: 0.6943\n","Training loss (for one batch) at step 100: 336.5861, Accuracy: 0.6908\n","Training loss (for one batch) at step 110: 330.2525, Accuracy: 0.6901\n","Training loss (for one batch) at step 120: 334.8377, Accuracy: 0.6877\n","Training loss (for one batch) at step 130: 331.2996, Accuracy: 0.6873\n","Training loss (for one batch) at step 140: 331.1600, Accuracy: 0.6888\n","---- Training ----\n","Training loss: 298.8304\n","Training acc over epoch: 0.6873\n","---- Validation ----\n","Validation loss: 76.9611\n","Validation acc: 0.6582\n","Time taken: 56.38s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 338.3651, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 329.3438, Accuracy: 0.6509\n","Training loss (for one batch) at step 20: 326.9675, Accuracy: 0.6519\n","Training loss (for one batch) at step 30: 328.3295, Accuracy: 0.6597\n","Training loss (for one batch) at step 40: 322.2192, Accuracy: 0.6632\n","Training loss (for one batch) at step 50: 319.0136, Accuracy: 0.6753\n","Training loss (for one batch) at step 60: 312.7010, Accuracy: 0.6826\n","Training loss (for one batch) at step 70: 321.3795, Accuracy: 0.6896\n","Training loss (for one batch) at step 80: 314.5894, Accuracy: 0.6907\n","Training loss (for one batch) at step 90: 346.9661, Accuracy: 0.6930\n","Training loss (for one batch) at step 100: 335.5934, Accuracy: 0.6909\n","Training loss (for one batch) at step 110: 330.3467, Accuracy: 0.6894\n","Training loss (for one batch) at step 120: 322.8676, Accuracy: 0.6903\n","Training loss (for one batch) at step 130: 318.3866, Accuracy: 0.6902\n","Training loss (for one batch) at step 140: 331.9982, Accuracy: 0.6898\n","---- Training ----\n","Training loss: 292.3398\n","Training acc over epoch: 0.6890\n","---- Validation ----\n","Validation loss: 77.7540\n","Validation acc: 0.6797\n","Time taken: 56.68s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 336.8246, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 338.0926, Accuracy: 0.6327\n","Training loss (for one batch) at step 20: 324.5523, Accuracy: 0.6471\n","Training loss (for one batch) at step 30: 330.9643, Accuracy: 0.6606\n","Training loss (for one batch) at step 40: 323.7335, Accuracy: 0.6763\n","Training loss (for one batch) at step 50: 321.6976, Accuracy: 0.6869\n","Training loss (for one batch) at step 60: 323.8927, Accuracy: 0.6926\n","Training loss (for one batch) at step 70: 320.9850, Accuracy: 0.6989\n","Training loss (for one batch) at step 80: 331.1436, Accuracy: 0.7033\n","Training loss (for one batch) at step 90: 339.3804, Accuracy: 0.7029\n","Training loss (for one batch) at step 100: 331.4031, Accuracy: 0.7006\n","Training loss (for one batch) at step 110: 325.9019, Accuracy: 0.6946\n","Training loss (for one batch) at step 120: 314.7047, Accuracy: 0.6936\n","Training loss (for one batch) at step 130: 323.1689, Accuracy: 0.6927\n","Training loss (for one batch) at step 140: 327.1436, Accuracy: 0.6938\n","---- Training ----\n","Training loss: 283.5743\n","Training acc over epoch: 0.6941\n","---- Validation ----\n","Validation loss: 78.9787\n","Validation acc: 0.6792\n","Time taken: 57.16s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 336.1370, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 339.3184, Accuracy: 0.6645\n","Training loss (for one batch) at step 20: 333.4502, Accuracy: 0.6643\n","Training loss (for one batch) at step 30: 327.4492, Accuracy: 0.6713\n","Training loss (for one batch) at step 40: 319.9132, Accuracy: 0.6817\n","Training loss (for one batch) at step 50: 324.1344, Accuracy: 0.6900\n","Training loss (for one batch) at step 60: 316.5570, Accuracy: 0.6974\n","Training loss (for one batch) at step 70: 315.0450, Accuracy: 0.7035\n","Training loss (for one batch) at step 80: 316.0134, Accuracy: 0.7059\n","Training loss (for one batch) at step 90: 338.7346, Accuracy: 0.7022\n","Training loss (for one batch) at step 100: 326.0276, Accuracy: 0.6969\n","Training loss (for one batch) at step 110: 322.7263, Accuracy: 0.6917\n","Training loss (for one batch) at step 120: 329.9206, Accuracy: 0.6924\n","Training loss (for one batch) at step 130: 330.0537, Accuracy: 0.6952\n","Training loss (for one batch) at step 140: 325.5118, Accuracy: 0.6954\n","---- Training ----\n","Training loss: 291.2844\n","Training acc over epoch: 0.6940\n","---- Validation ----\n","Validation loss: 78.6862\n","Validation acc: 0.6693\n","Time taken: 65.63s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 338.1549, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 337.1104, Accuracy: 0.6455\n","Training loss (for one batch) at step 20: 323.5365, Accuracy: 0.6490\n","Training loss (for one batch) at step 30: 319.8158, Accuracy: 0.6665\n","Training loss (for one batch) at step 40: 313.1324, Accuracy: 0.6793\n","Training loss (for one batch) at step 50: 306.9621, Accuracy: 0.6888\n","Training loss (for one batch) at step 60: 315.4974, Accuracy: 0.6959\n","Training loss (for one batch) at step 70: 313.2447, Accuracy: 0.7031\n","Training loss (for one batch) at step 80: 325.6277, Accuracy: 0.7036\n","Training loss (for one batch) at step 90: 330.6292, Accuracy: 0.7021\n","Training loss (for one batch) at step 100: 331.0981, Accuracy: 0.6989\n","Training loss (for one batch) at step 110: 318.2110, Accuracy: 0.6957\n","Training loss (for one batch) at step 120: 321.7829, Accuracy: 0.6945\n","Training loss (for one batch) at step 130: 311.4881, Accuracy: 0.6956\n","Training loss (for one batch) at step 140: 329.4646, Accuracy: 0.6954\n","---- Training ----\n","Training loss: 284.9525\n","Training acc over epoch: 0.6941\n","---- Validation ----\n","Validation loss: 75.8812\n","Validation acc: 0.6733\n","Time taken: 62.32s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 334.2251, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 332.3853, Accuracy: 0.6436\n","Training loss (for one batch) at step 20: 330.6992, Accuracy: 0.6648\n","Training loss (for one batch) at step 30: 313.9108, Accuracy: 0.6781\n","Training loss (for one batch) at step 40: 309.9773, Accuracy: 0.6895\n","Training loss (for one batch) at step 50: 298.9098, Accuracy: 0.6980\n","Training loss (for one batch) at step 60: 305.7842, Accuracy: 0.7069\n","Training loss (for one batch) at step 70: 309.2351, Accuracy: 0.7118\n","Training loss (for one batch) at step 80: 326.9340, Accuracy: 0.7117\n","Training loss (for one batch) at step 90: 336.0720, Accuracy: 0.7075\n","Training loss (for one batch) at step 100: 325.9992, Accuracy: 0.7044\n","Training loss (for one batch) at step 110: 321.9869, Accuracy: 0.7002\n","Training loss (for one batch) at step 120: 307.6263, Accuracy: 0.7030\n","Training loss (for one batch) at step 130: 320.0266, Accuracy: 0.7034\n","Training loss (for one batch) at step 140: 325.8681, Accuracy: 0.7039\n","---- Training ----\n","Training loss: 275.5864\n","Training acc over epoch: 0.7029\n","---- Validation ----\n","Validation loss: 82.0035\n","Validation acc: 0.6916\n","Time taken: 68.57s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 334.3320, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 321.0753, Accuracy: 0.6400\n","Training loss (for one batch) at step 20: 327.5875, Accuracy: 0.6524\n","Training loss (for one batch) at step 30: 319.0902, Accuracy: 0.6674\n","Training loss (for one batch) at step 40: 306.0502, Accuracy: 0.6863\n","Training loss (for one batch) at step 50: 307.2781, Accuracy: 0.7035\n","Training loss (for one batch) at step 60: 304.1194, Accuracy: 0.7095\n","Training loss (for one batch) at step 70: 302.5784, Accuracy: 0.7175\n","Training loss (for one batch) at step 80: 315.0236, Accuracy: 0.7199\n","Training loss (for one batch) at step 90: 330.3434, Accuracy: 0.7170\n","Training loss (for one batch) at step 100: 323.3727, Accuracy: 0.7127\n","Training loss (for one batch) at step 110: 328.0674, Accuracy: 0.7107\n","Training loss (for one batch) at step 120: 314.7800, Accuracy: 0.7087\n","Training loss (for one batch) at step 130: 310.9474, Accuracy: 0.7097\n","Training loss (for one batch) at step 140: 321.9352, Accuracy: 0.7082\n","---- Training ----\n","Training loss: 284.1523\n","Training acc over epoch: 0.7061\n","---- Validation ----\n","Validation loss: 80.5978\n","Validation acc: 0.6752\n","Time taken: 56.90s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 333.5171, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 336.5141, Accuracy: 0.6536\n","Training loss (for one batch) at step 20: 317.1564, Accuracy: 0.6676\n","Training loss (for one batch) at step 30: 298.5814, Accuracy: 0.6842\n","Training loss (for one batch) at step 40: 313.7041, Accuracy: 0.6966\n","Training loss (for one batch) at step 50: 298.6607, Accuracy: 0.7086\n","Training loss (for one batch) at step 60: 299.6082, Accuracy: 0.7144\n","Training loss (for one batch) at step 70: 317.5907, Accuracy: 0.7163\n","Training loss (for one batch) at step 80: 320.3484, Accuracy: 0.7200\n","Training loss (for one batch) at step 90: 328.6395, Accuracy: 0.7170\n","Training loss (for one batch) at step 100: 331.2266, Accuracy: 0.7123\n","Training loss (for one batch) at step 110: 316.1872, Accuracy: 0.7089\n","Training loss (for one batch) at step 120: 316.9719, Accuracy: 0.7088\n","Training loss (for one batch) at step 130: 315.7662, Accuracy: 0.7117\n","Training loss (for one batch) at step 140: 316.8481, Accuracy: 0.7110\n","---- Training ----\n","Training loss: 287.4930\n","Training acc over epoch: 0.7080\n","---- Validation ----\n","Validation loss: 79.8444\n","Validation acc: 0.6862\n","Time taken: 59.95s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 339.4643, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 320.3808, Accuracy: 0.6645\n","Training loss (for one batch) at step 20: 317.8158, Accuracy: 0.6605\n","Training loss (for one batch) at step 30: 310.1787, Accuracy: 0.6813\n","Training loss (for one batch) at step 40: 307.0992, Accuracy: 0.6937\n","Training loss (for one batch) at step 50: 296.2289, Accuracy: 0.7031\n","Training loss (for one batch) at step 60: 306.4372, Accuracy: 0.7118\n","Training loss (for one batch) at step 70: 300.8145, Accuracy: 0.7186\n","Training loss (for one batch) at step 80: 307.4356, Accuracy: 0.7186\n","Training loss (for one batch) at step 90: 320.4533, Accuracy: 0.7127\n","Training loss (for one batch) at step 100: 323.5157, Accuracy: 0.7087\n","Training loss (for one batch) at step 110: 310.1339, Accuracy: 0.7042\n","Training loss (for one batch) at step 120: 304.3033, Accuracy: 0.7070\n","Training loss (for one batch) at step 130: 297.8594, Accuracy: 0.7086\n","Training loss (for one batch) at step 140: 320.7268, Accuracy: 0.7072\n","---- Training ----\n","Training loss: 285.8352\n","Training acc over epoch: 0.7071\n","---- Validation ----\n","Validation loss: 72.8751\n","Validation acc: 0.6854\n","Time taken: 69.13s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 334.4467, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 330.4408, Accuracy: 0.6700\n","Training loss (for one batch) at step 20: 320.4157, Accuracy: 0.6705\n","Training loss (for one batch) at step 30: 302.1196, Accuracy: 0.6819\n","Training loss (for one batch) at step 40: 291.5619, Accuracy: 0.6976\n","Training loss (for one batch) at step 50: 306.2038, Accuracy: 0.7088\n","Training loss (for one batch) at step 60: 288.9287, Accuracy: 0.7179\n","Training loss (for one batch) at step 70: 298.6088, Accuracy: 0.7270\n","Training loss (for one batch) at step 80: 316.2276, Accuracy: 0.7275\n","Training loss (for one batch) at step 90: 329.9117, Accuracy: 0.7243\n","Training loss (for one batch) at step 100: 326.4173, Accuracy: 0.7193\n","Training loss (for one batch) at step 110: 311.9297, Accuracy: 0.7187\n","Training loss (for one batch) at step 120: 306.8656, Accuracy: 0.7178\n","Training loss (for one batch) at step 130: 303.6232, Accuracy: 0.7188\n","Training loss (for one batch) at step 140: 324.7123, Accuracy: 0.7186\n","---- Training ----\n","Training loss: 285.7950\n","Training acc over epoch: 0.7166\n","---- Validation ----\n","Validation loss: 84.0270\n","Validation acc: 0.6827\n","Time taken: 60.97s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 326.8900, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 318.0806, Accuracy: 0.6582\n","Training loss (for one batch) at step 20: 305.8289, Accuracy: 0.6543\n","Training loss (for one batch) at step 30: 315.6180, Accuracy: 0.6684\n","Training loss (for one batch) at step 40: 316.6405, Accuracy: 0.6878\n","Training loss (for one batch) at step 50: 294.7314, Accuracy: 0.6998\n","Training loss (for one batch) at step 60: 296.6217, Accuracy: 0.7074\n","Training loss (for one batch) at step 70: 296.6896, Accuracy: 0.7158\n","Training loss (for one batch) at step 80: 325.1310, Accuracy: 0.7160\n","Training loss (for one batch) at step 90: 313.6986, Accuracy: 0.7112\n","Training loss (for one batch) at step 100: 326.0635, Accuracy: 0.7044\n","Training loss (for one batch) at step 110: 314.1895, Accuracy: 0.7032\n","Training loss (for one batch) at step 120: 306.3937, Accuracy: 0.7043\n","Training loss (for one batch) at step 130: 306.4084, Accuracy: 0.7050\n","Training loss (for one batch) at step 140: 315.5312, Accuracy: 0.7055\n","---- Training ----\n","Training loss: 290.4823\n","Training acc over epoch: 0.7039\n","---- Validation ----\n","Validation loss: 82.0472\n","Validation acc: 0.6773\n","Time taken: 66.28s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 322.6088, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 324.5607, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 302.0407, Accuracy: 0.6719\n","Training loss (for one batch) at step 30: 318.1986, Accuracy: 0.6861\n","Training loss (for one batch) at step 40: 282.9843, Accuracy: 0.6985\n","Training loss (for one batch) at step 50: 288.3015, Accuracy: 0.7098\n","Training loss (for one batch) at step 60: 298.4395, Accuracy: 0.7205\n","Training loss (for one batch) at step 70: 285.4134, Accuracy: 0.7238\n","Training loss (for one batch) at step 80: 313.1692, Accuracy: 0.7238\n","Training loss (for one batch) at step 90: 317.7152, Accuracy: 0.7202\n","Training loss (for one batch) at step 100: 320.2773, Accuracy: 0.7154\n","Training loss (for one batch) at step 110: 319.2152, Accuracy: 0.7122\n","Training loss (for one batch) at step 120: 302.5306, Accuracy: 0.7119\n","Training loss (for one batch) at step 130: 307.4464, Accuracy: 0.7131\n","Training loss (for one batch) at step 140: 307.6559, Accuracy: 0.7130\n","---- Training ----\n","Training loss: 275.6658\n","Training acc over epoch: 0.7114\n","---- Validation ----\n","Validation loss: 75.3643\n","Validation acc: 0.6830\n","Time taken: 63.52s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 325.4539, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 323.7530, Accuracy: 0.6855\n","Training loss (for one batch) at step 20: 304.9984, Accuracy: 0.6767\n","Training loss (for one batch) at step 30: 302.9057, Accuracy: 0.6971\n","Training loss (for one batch) at step 40: 298.7703, Accuracy: 0.7063\n","Training loss (for one batch) at step 50: 282.8688, Accuracy: 0.7133\n","Training loss (for one batch) at step 60: 281.6641, Accuracy: 0.7233\n","Training loss (for one batch) at step 70: 288.4841, Accuracy: 0.7289\n","Training loss (for one batch) at step 80: 301.2897, Accuracy: 0.7284\n","Training loss (for one batch) at step 90: 325.9133, Accuracy: 0.7224\n","Training loss (for one batch) at step 100: 314.4024, Accuracy: 0.7149\n","Training loss (for one batch) at step 110: 311.1734, Accuracy: 0.7078\n","Training loss (for one batch) at step 120: 287.6800, Accuracy: 0.7093\n","Training loss (for one batch) at step 130: 295.9769, Accuracy: 0.7111\n","Training loss (for one batch) at step 140: 301.0451, Accuracy: 0.7114\n","---- Training ----\n","Training loss: 275.7361\n","Training acc over epoch: 0.7087\n","---- Validation ----\n","Validation loss: 78.1682\n","Validation acc: 0.6762\n","Time taken: 58.12s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 316.4216, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 326.0200, Accuracy: 0.6600\n","Training loss (for one batch) at step 20: 310.9742, Accuracy: 0.6757\n","Training loss (for one batch) at step 30: 302.3677, Accuracy: 0.6919\n","Training loss (for one batch) at step 40: 295.1885, Accuracy: 0.7032\n","Training loss (for one batch) at step 50: 292.3240, Accuracy: 0.7188\n","Training loss (for one batch) at step 60: 289.0965, Accuracy: 0.7243\n","Training loss (for one batch) at step 70: 296.1803, Accuracy: 0.7301\n","Training loss (for one batch) at step 80: 309.1332, Accuracy: 0.7300\n","Training loss (for one batch) at step 90: 318.5998, Accuracy: 0.7260\n","Training loss (for one batch) at step 100: 313.4990, Accuracy: 0.7209\n","Training loss (for one batch) at step 110: 307.4049, Accuracy: 0.7195\n","Training loss (for one batch) at step 120: 295.9848, Accuracy: 0.7207\n","Training loss (for one batch) at step 130: 289.1775, Accuracy: 0.7226\n","Training loss (for one batch) at step 140: 310.8510, Accuracy: 0.7199\n","---- Training ----\n","Training loss: 269.0205\n","Training acc over epoch: 0.7185\n","---- Validation ----\n","Validation loss: 89.7543\n","Validation acc: 0.6881\n","Time taken: 59.41s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 325.2151, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 326.5553, Accuracy: 0.6436\n","Training loss (for one batch) at step 20: 298.1023, Accuracy: 0.6486\n","Training loss (for one batch) at step 30: 310.1138, Accuracy: 0.6755\n","Training loss (for one batch) at step 40: 297.4911, Accuracy: 0.6961\n","Training loss (for one batch) at step 50: 290.5563, Accuracy: 0.7069\n","Training loss (for one batch) at step 60: 290.9032, Accuracy: 0.7148\n","Training loss (for one batch) at step 70: 282.6151, Accuracy: 0.7193\n","Training loss (for one batch) at step 80: 297.6716, Accuracy: 0.7205\n","Training loss (for one batch) at step 90: 303.5675, Accuracy: 0.7171\n","Training loss (for one batch) at step 100: 321.6284, Accuracy: 0.7108\n","Training loss (for one batch) at step 110: 310.6567, Accuracy: 0.7086\n","Training loss (for one batch) at step 120: 301.8875, Accuracy: 0.7102\n","Training loss (for one batch) at step 130: 306.5387, Accuracy: 0.7127\n","Training loss (for one batch) at step 140: 303.9676, Accuracy: 0.7122\n","---- Training ----\n","Training loss: 276.7408\n","Training acc over epoch: 0.7118\n","---- Validation ----\n","Validation loss: 81.8964\n","Validation acc: 0.6789\n","Time taken: 60.55s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 311.7094, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 312.4387, Accuracy: 0.6645\n","Training loss (for one batch) at step 20: 310.6017, Accuracy: 0.6719\n","Training loss (for one batch) at step 30: 290.7772, Accuracy: 0.6829\n","Training loss (for one batch) at step 40: 279.8762, Accuracy: 0.7061\n","Training loss (for one batch) at step 50: 281.1912, Accuracy: 0.7153\n","Training loss (for one batch) at step 60: 287.4286, Accuracy: 0.7238\n","Training loss (for one batch) at step 70: 288.8629, Accuracy: 0.7287\n","Training loss (for one batch) at step 80: 298.9552, Accuracy: 0.7279\n","Training loss (for one batch) at step 90: 314.4004, Accuracy: 0.7223\n","Training loss (for one batch) at step 100: 303.0982, Accuracy: 0.7179\n","Training loss (for one batch) at step 110: 312.8806, Accuracy: 0.7116\n","Training loss (for one batch) at step 120: 295.8588, Accuracy: 0.7131\n","Training loss (for one batch) at step 130: 284.2370, Accuracy: 0.7144\n","Training loss (for one batch) at step 140: 310.9101, Accuracy: 0.7140\n","---- Training ----\n","Training loss: 266.5536\n","Training acc over epoch: 0.7131\n","---- Validation ----\n","Validation loss: 82.1325\n","Validation acc: 0.6709\n","Time taken: 60.47s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 311.4165, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 313.6684, Accuracy: 0.6555\n","Training loss (for one batch) at step 20: 295.3564, Accuracy: 0.6619\n","Training loss (for one batch) at step 30: 292.1481, Accuracy: 0.6806\n","Training loss (for one batch) at step 40: 285.0927, Accuracy: 0.7020\n","Training loss (for one batch) at step 50: 307.4939, Accuracy: 0.7139\n","Training loss (for one batch) at step 60: 277.7450, Accuracy: 0.7238\n","Training loss (for one batch) at step 70: 282.9870, Accuracy: 0.7300\n","Training loss (for one batch) at step 80: 297.5948, Accuracy: 0.7304\n","Training loss (for one batch) at step 90: 292.0827, Accuracy: 0.7254\n","Training loss (for one batch) at step 100: 313.8903, Accuracy: 0.7160\n","Training loss (for one batch) at step 110: 299.1289, Accuracy: 0.7129\n","Training loss (for one batch) at step 120: 283.1517, Accuracy: 0.7160\n","Training loss (for one batch) at step 130: 289.0382, Accuracy: 0.7198\n","Training loss (for one batch) at step 140: 310.4775, Accuracy: 0.7186\n","---- Training ----\n","Training loss: 279.2586\n","Training acc over epoch: 0.7163\n","---- Validation ----\n","Validation loss: 80.6206\n","Validation acc: 0.6881\n","Time taken: 61.96s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 324.1309, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 319.8051, Accuracy: 0.6609\n","Training loss (for one batch) at step 20: 306.7780, Accuracy: 0.6624\n","Training loss (for one batch) at step 30: 295.4466, Accuracy: 0.6839\n","Training loss (for one batch) at step 40: 276.4771, Accuracy: 0.6990\n","Training loss (for one batch) at step 50: 280.8740, Accuracy: 0.7124\n","Training loss (for one batch) at step 60: 281.8482, Accuracy: 0.7220\n","Training loss (for one batch) at step 70: 273.9535, Accuracy: 0.7293\n","Training loss (for one batch) at step 80: 291.3590, Accuracy: 0.7289\n","Training loss (for one batch) at step 90: 299.0891, Accuracy: 0.7226\n","Training loss (for one batch) at step 100: 310.4086, Accuracy: 0.7178\n","Training loss (for one batch) at step 110: 305.6695, Accuracy: 0.7143\n","Training loss (for one batch) at step 120: 285.6058, Accuracy: 0.7154\n","Training loss (for one batch) at step 130: 287.5815, Accuracy: 0.7175\n","Training loss (for one batch) at step 140: 286.8615, Accuracy: 0.7174\n","---- Training ----\n","Training loss: 260.2793\n","Training acc over epoch: 0.7157\n","---- Validation ----\n","Validation loss: 71.9498\n","Validation acc: 0.6752\n","Time taken: 59.27s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 325.4793, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 323.9180, Accuracy: 0.6718\n","Training loss (for one batch) at step 20: 297.9431, Accuracy: 0.6776\n","Training loss (for one batch) at step 30: 300.0926, Accuracy: 0.6884\n","Training loss (for one batch) at step 40: 275.2254, Accuracy: 0.7066\n","Training loss (for one batch) at step 50: 276.7917, Accuracy: 0.7182\n","Training loss (for one batch) at step 60: 281.1273, Accuracy: 0.7254\n","Training loss (for one batch) at step 70: 276.4636, Accuracy: 0.7311\n","Training loss (for one batch) at step 80: 305.5411, Accuracy: 0.7330\n","Training loss (for one batch) at step 90: 313.2358, Accuracy: 0.7242\n","Training loss (for one batch) at step 100: 297.2430, Accuracy: 0.7168\n","Training loss (for one batch) at step 110: 295.5443, Accuracy: 0.7149\n","Training loss (for one batch) at step 120: 297.8946, Accuracy: 0.7156\n","Training loss (for one batch) at step 130: 291.2054, Accuracy: 0.7195\n","Training loss (for one batch) at step 140: 288.2368, Accuracy: 0.7199\n","---- Training ----\n","Training loss: 261.6111\n","Training acc over epoch: 0.7176\n","---- Validation ----\n","Validation loss: 82.1592\n","Validation acc: 0.6776\n","Time taken: 60.91s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 308.9675, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 314.8729, Accuracy: 0.6745\n","Training loss (for one batch) at step 20: 296.6920, Accuracy: 0.6748\n","Training loss (for one batch) at step 30: 282.0129, Accuracy: 0.6961\n","Training loss (for one batch) at step 40: 281.7182, Accuracy: 0.7102\n","Training loss (for one batch) at step 50: 275.6915, Accuracy: 0.7231\n","Training loss (for one batch) at step 60: 279.6864, Accuracy: 0.7315\n","Training loss (for one batch) at step 70: 269.4745, Accuracy: 0.7385\n","Training loss (for one batch) at step 80: 284.9267, Accuracy: 0.7396\n","Training loss (for one batch) at step 90: 284.9189, Accuracy: 0.7309\n","Training loss (for one batch) at step 100: 311.1798, Accuracy: 0.7234\n","Training loss (for one batch) at step 110: 286.2980, Accuracy: 0.7186\n","Training loss (for one batch) at step 120: 290.8319, Accuracy: 0.7183\n","Training loss (for one batch) at step 130: 282.2695, Accuracy: 0.7221\n","Training loss (for one batch) at step 140: 315.3654, Accuracy: 0.7218\n","---- Training ----\n","Training loss: 262.2349\n","Training acc over epoch: 0.7200\n","---- Validation ----\n","Validation loss: 80.1764\n","Validation acc: 0.6765\n","Time taken: 58.63s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 323.8125, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 305.5237, Accuracy: 0.6427\n","Training loss (for one batch) at step 20: 299.0493, Accuracy: 0.6495\n","Training loss (for one batch) at step 30: 278.0796, Accuracy: 0.6839\n","Training loss (for one batch) at step 40: 285.7223, Accuracy: 0.6949\n","Training loss (for one batch) at step 50: 275.8095, Accuracy: 0.7124\n","Training loss (for one batch) at step 60: 263.9500, Accuracy: 0.7231\n","Training loss (for one batch) at step 70: 256.3717, Accuracy: 0.7327\n","Training loss (for one batch) at step 80: 296.2852, Accuracy: 0.7330\n","Training loss (for one batch) at step 90: 309.5761, Accuracy: 0.7274\n","Training loss (for one batch) at step 100: 305.4254, Accuracy: 0.7174\n","Training loss (for one batch) at step 110: 291.9685, Accuracy: 0.7124\n","Training loss (for one batch) at step 120: 286.7846, Accuracy: 0.7140\n","Training loss (for one batch) at step 130: 285.6569, Accuracy: 0.7176\n","Training loss (for one batch) at step 140: 289.0867, Accuracy: 0.7182\n","---- Training ----\n","Training loss: 261.1317\n","Training acc over epoch: 0.7161\n","---- Validation ----\n","Validation loss: 83.8673\n","Validation acc: 0.6816\n","Time taken: 60.78s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 321.3251, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 314.5966, Accuracy: 0.6618\n","Training loss (for one batch) at step 20: 282.8336, Accuracy: 0.6671\n","Training loss (for one batch) at step 30: 285.1535, Accuracy: 0.6832\n","Training loss (for one batch) at step 40: 279.9457, Accuracy: 0.6998\n","Training loss (for one batch) at step 50: 270.8296, Accuracy: 0.7173\n","Training loss (for one batch) at step 60: 269.5844, Accuracy: 0.7256\n","Training loss (for one batch) at step 70: 286.4791, Accuracy: 0.7328\n","Training loss (for one batch) at step 80: 292.8326, Accuracy: 0.7322\n","Training loss (for one batch) at step 90: 298.4222, Accuracy: 0.7299\n","Training loss (for one batch) at step 100: 302.7618, Accuracy: 0.7214\n","Training loss (for one batch) at step 110: 289.4296, Accuracy: 0.7186\n","Training loss (for one batch) at step 120: 281.1386, Accuracy: 0.7186\n","Training loss (for one batch) at step 130: 284.9765, Accuracy: 0.7205\n","Training loss (for one batch) at step 140: 301.6501, Accuracy: 0.7215\n","---- Training ----\n","Training loss: 253.9908\n","Training acc over epoch: 0.7198\n","---- Validation ----\n","Validation loss: 79.5825\n","Validation acc: 0.6757\n","Time taken: 57.61s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 303.7071, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 330.6287, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 285.7685, Accuracy: 0.6700\n","Training loss (for one batch) at step 30: 284.8036, Accuracy: 0.6932\n","Training loss (for one batch) at step 40: 277.5192, Accuracy: 0.7098\n","Training loss (for one batch) at step 50: 265.1468, Accuracy: 0.7200\n","Training loss (for one batch) at step 60: 278.2734, Accuracy: 0.7289\n","Training loss (for one batch) at step 70: 277.0728, Accuracy: 0.7348\n","Training loss (for one batch) at step 80: 296.7113, Accuracy: 0.7346\n","Training loss (for one batch) at step 90: 306.8313, Accuracy: 0.7267\n","Training loss (for one batch) at step 100: 290.3511, Accuracy: 0.7206\n","Training loss (for one batch) at step 110: 312.7147, Accuracy: 0.7171\n","Training loss (for one batch) at step 120: 279.7087, Accuracy: 0.7193\n","Training loss (for one batch) at step 130: 279.0129, Accuracy: 0.7210\n","Training loss (for one batch) at step 140: 305.7570, Accuracy: 0.7209\n","---- Training ----\n","Training loss: 256.4562\n","Training acc over epoch: 0.7193\n","---- Validation ----\n","Validation loss: 80.1663\n","Validation acc: 0.6687\n","Time taken: 58.64s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 310.4981, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 308.0144, Accuracy: 0.6445\n","Training loss (for one batch) at step 20: 290.6945, Accuracy: 0.6543\n","Training loss (for one batch) at step 30: 273.2641, Accuracy: 0.6832\n","Training loss (for one batch) at step 40: 270.6027, Accuracy: 0.7029\n","Training loss (for one batch) at step 50: 262.1652, Accuracy: 0.7102\n","Training loss (for one batch) at step 60: 285.9265, Accuracy: 0.7236\n","Training loss (for one batch) at step 70: 256.3081, Accuracy: 0.7325\n","Training loss (for one batch) at step 80: 304.6816, Accuracy: 0.7328\n","Training loss (for one batch) at step 90: 293.5688, Accuracy: 0.7251\n","Training loss (for one batch) at step 100: 302.5426, Accuracy: 0.7189\n","Training loss (for one batch) at step 110: 285.0724, Accuracy: 0.7154\n","Training loss (for one batch) at step 120: 282.3097, Accuracy: 0.7170\n","Training loss (for one batch) at step 130: 275.1954, Accuracy: 0.7192\n","Training loss (for one batch) at step 140: 279.7166, Accuracy: 0.7183\n","---- Training ----\n","Training loss: 248.2395\n","Training acc over epoch: 0.7166\n","---- Validation ----\n","Validation loss: 90.2576\n","Validation acc: 0.6706\n","Time taken: 63.50s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 311.2977, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 298.2990, Accuracy: 0.6364\n","Training loss (for one batch) at step 20: 283.6876, Accuracy: 0.6571\n","Training loss (for one batch) at step 30: 281.7365, Accuracy: 0.6890\n","Training loss (for one batch) at step 40: 266.1864, Accuracy: 0.7093\n","Training loss (for one batch) at step 50: 262.1621, Accuracy: 0.7222\n","Training loss (for one batch) at step 60: 260.9467, Accuracy: 0.7341\n","Training loss (for one batch) at step 70: 246.1888, Accuracy: 0.7410\n","Training loss (for one batch) at step 80: 286.0931, Accuracy: 0.7407\n","Training loss (for one batch) at step 90: 299.9378, Accuracy: 0.7332\n","Training loss (for one batch) at step 100: 304.7274, Accuracy: 0.7269\n","Training loss (for one batch) at step 110: 280.2412, Accuracy: 0.7220\n","Training loss (for one batch) at step 120: 275.8063, Accuracy: 0.7230\n","Training loss (for one batch) at step 130: 275.5567, Accuracy: 0.7248\n","Training loss (for one batch) at step 140: 280.4230, Accuracy: 0.7249\n","---- Training ----\n","Training loss: 249.2673\n","Training acc over epoch: 0.7228\n","---- Validation ----\n","Validation loss: 90.3816\n","Validation acc: 0.6867\n","Time taken: 64.37s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 312.8740, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 301.9001, Accuracy: 0.6191\n","Training loss (for one batch) at step 20: 287.1490, Accuracy: 0.6619\n","Training loss (for one batch) at step 30: 289.0984, Accuracy: 0.6835\n","Training loss (for one batch) at step 40: 271.3109, Accuracy: 0.7044\n","Training loss (for one batch) at step 50: 271.9997, Accuracy: 0.7192\n","Training loss (for one batch) at step 60: 268.6298, Accuracy: 0.7315\n","Training loss (for one batch) at step 70: 272.4957, Accuracy: 0.7407\n","Training loss (for one batch) at step 80: 275.2705, Accuracy: 0.7401\n","Training loss (for one batch) at step 90: 290.7023, Accuracy: 0.7336\n","Training loss (for one batch) at step 100: 300.3577, Accuracy: 0.7244\n","Training loss (for one batch) at step 110: 291.9899, Accuracy: 0.7208\n","Training loss (for one batch) at step 120: 279.0391, Accuracy: 0.7231\n","Training loss (for one batch) at step 130: 275.3135, Accuracy: 0.7248\n","Training loss (for one batch) at step 140: 275.0074, Accuracy: 0.7242\n","---- Training ----\n","Training loss: 258.7379\n","Training acc over epoch: 0.7212\n","---- Validation ----\n","Validation loss: 80.5114\n","Validation acc: 0.6779\n","Time taken: 69.09s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 314.4879, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 308.9766, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 275.6439, Accuracy: 0.6633\n","Training loss (for one batch) at step 30: 259.7398, Accuracy: 0.6803\n","Training loss (for one batch) at step 40: 271.4697, Accuracy: 0.7017\n","Training loss (for one batch) at step 50: 274.1106, Accuracy: 0.7173\n","Training loss (for one batch) at step 60: 252.3720, Accuracy: 0.7303\n","Training loss (for one batch) at step 70: 264.5188, Accuracy: 0.7375\n","Training loss (for one batch) at step 80: 270.5515, Accuracy: 0.7396\n","Training loss (for one batch) at step 90: 280.7374, Accuracy: 0.7319\n","Training loss (for one batch) at step 100: 281.9282, Accuracy: 0.7231\n","Training loss (for one batch) at step 110: 286.2033, Accuracy: 0.7205\n","Training loss (for one batch) at step 120: 295.2085, Accuracy: 0.7217\n","Training loss (for one batch) at step 130: 271.7343, Accuracy: 0.7244\n","Training loss (for one batch) at step 140: 305.0774, Accuracy: 0.7230\n","---- Training ----\n","Training loss: 243.9538\n","Training acc over epoch: 0.7213\n","---- Validation ----\n","Validation loss: 82.7623\n","Validation acc: 0.6918\n","Time taken: 66.78s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 311.0050, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 316.9012, Accuracy: 0.6164\n","Training loss (for one batch) at step 20: 275.7422, Accuracy: 0.6438\n","Training loss (for one batch) at step 30: 265.2653, Accuracy: 0.6803\n","Training loss (for one batch) at step 40: 266.5280, Accuracy: 0.7046\n","Training loss (for one batch) at step 50: 266.0379, Accuracy: 0.7173\n","Training loss (for one batch) at step 60: 260.8486, Accuracy: 0.7293\n","Training loss (for one batch) at step 70: 256.1661, Accuracy: 0.7400\n","Training loss (for one batch) at step 80: 275.8712, Accuracy: 0.7394\n","Training loss (for one batch) at step 90: 286.7112, Accuracy: 0.7332\n","Training loss (for one batch) at step 100: 290.1153, Accuracy: 0.7231\n","Training loss (for one batch) at step 110: 279.7135, Accuracy: 0.7192\n","Training loss (for one batch) at step 120: 285.5184, Accuracy: 0.7213\n","Training loss (for one batch) at step 130: 283.3520, Accuracy: 0.7234\n","Training loss (for one batch) at step 140: 289.9988, Accuracy: 0.7235\n","---- Training ----\n","Training loss: 237.8899\n","Training acc over epoch: 0.7215\n","---- Validation ----\n","Validation loss: 91.4699\n","Validation acc: 0.6800\n","Time taken: 66.02s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.6862\n","Validation AUC: 0.6863\n","Validation Balanced_ACC: 0.2531\n","Validation MI: 0.0456\n","Validation Normalized MI: 0.0664\n","Validation Adjusted MI: 0.0664\n"]}],"source":["from sklearn.metrics import classification_report, balanced_accuracy_score\n","from sklearn.metrics import normalized_mutual_info_score, mutual_info_score, adjusted_mutual_info_score\n","#model = create_model()\n","K=2\n","R=5\n","val_q = [0.0001]   #0.2, 0.4, 0.6, 0.8]\n","NUM_RUNS = 5\n","N_EPOCHS = 50 \n","ACC = np.zeros(NUM_RUNS)\n","AUC = np.zeros(NUM_RUNS)\n","MI = np.zeros(NUM_RUNS)\n","NMI = np.zeros(NUM_RUNS)\n","AMI = np.zeros(NUM_RUNS)\n","BACC = np.zeros(NUM_RUNS)\n","BACC1 = []\n","MI1 = []\n","NMI1 =[]\n","AMI1 = []\n","val_acc = np.zeros(NUM_RUNS)\n","for i in range(NUM_RUNS):\n","  MA = MultipleAnnotators_Classification(2, 5, val_q[0])\n","  model =  create_model()\n","  model = MA.fit(model, train_batches_MA, val_batches_MA, N_EPOCHS)\n","  #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n","  ACC[i] = MA.eval_model(test_batches_MA)\n","  print(\"===== Q: %.4f\" % (float(val_q[0]),))\n","  print(\"Validation acc: %.4f\" % (float(ACC[i]),))\n","\n","\n","    #AUC =======================\n","  val_AUC_metric = tf.keras.metrics.AUC( from_logits = True)\n","  for x_batch_val, y_batch_val in test_batches_MA:\n","      val_logits = model(x_batch_val.numpy(), training=False)\n","      # tf.print(y_batch_val)\n","      val_AUC_metric.update_state(y_batch_val, val_logits[:,:K].numpy().argmax(axis=1).astype('float'))   #val_logits[:,Y.shape[1]:].argmax(axis=1).astype('float'))\n","      BACC1.append(balanced_accuracy_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True))\n","      MI1.append(mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","      NMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","      AMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","\n","  val_AUC = val_AUC_metric.result()\n","  val_AUC_metric.reset_states()\n","  val_AUC = val_AUC.numpy()\n","  print(\"Validation AUC: %.4f\" % (float(val_AUC),))\n","  AUC[i] = val_AUC\n","  #===================================================\n","    \n","  # balanced. Accurcy\n","  BACC[i] = np.array(BACC1).mean() # balanced_accuracy_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True)\n","  print(\"Validation Balanced_ACC: %.4f\" % (float(BACC[i])))\n","\n","  #MI\n","  \n","  MI[i] =  np.array(MI1).mean()  #mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation MI: %.4f\" % (float(MI[i]),))\n","  NMI[i] =  np.array(NMI1).mean()   #normalized_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation Normalized MI: %.4f\" % (float(NMI[i]),))\n","  AMI[i]= np.array(AMI1).mean()  #adjusted_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation Adjusted MI: %.4f\" % (float(AMI[i]),))\n","\n","    \n","import pandas as pd\n","df = pd.DataFrame(ACC)\n","#df.to_csv('/content/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output"]},{"cell_type":"code","execution_count":18,"id":"3aa5b53c","metadata":{"execution":{"iopub.execute_input":"2023-02-04T15:42:22.414202Z","iopub.status.busy":"2023-02-04T15:42:22.413758Z","iopub.status.idle":"2023-02-04T15:42:22.41994Z","shell.execute_reply":"2023-02-04T15:42:22.418824Z"},"id":"_H_sb1cl1FC_","outputId":"59d957da-9223-4a01-e4d9-33933f7a2f4a","papermill":{"duration":0.228536,"end_time":"2023-02-04T15:42:22.422597","exception":false,"start_time":"2023-02-04T15:42:22.194061","status":"completed"},"tags":[]},"outputs":[],"source":["# classification_report_r= []\n","# model = create_model()\n","# K=2\n","# R=5\n","# NUM_RUNS = 10\n","# N_EPOCHS = 30\n","# val_acc = np.zeros(NUM_RUNS)\n","# for i in range(NUM_RUNS):\n","#   MA = MultipleAnnotators_Classification(K, R, 0.1)\n","#   model = create_model()\n","#   optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n","#   model.compile(optimizer=optimizer, loss= MA.loss())\n","#   history_model = model.fit(train_batches_MA, validation_data=val_batches_MA, epochs= N_EPOCHS, callbacks=callbacks, verbose=0)\n","#   #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n","#   pred_2 = model.predict(X_test)\n","\n","#   lambda_R_ = pred_2[:, K:] #annotators reliability prediction N x R   \n","#   classification_report_r += [classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel(),output_dict=True)]\n","#   print(classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel()))\n","#   #val_acc[i] = MA.eval_model(test_batches_MA)\n","#   #print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n","#   # Create the history figure\n","#   plt.figure(figsize=(16,9))\n","#   for i in  history_model.history:\n","#       plt.plot(history_model.history[i],label=i)\n","#   plt.title('Model history')\n","#   plt.legend()\n","#   plt.grid()\n","\n","# import pandas as pd\n","# df = pd.DataFrame(val_acc)\n","# #df.to_csimport pandas as pddf = pd.DataFrame(val_acc)#df.to_csv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output​v('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output\n"]},{"cell_type":"code","execution_count":19,"id":"1407e7a1","metadata":{"execution":{"iopub.execute_input":"2023-02-04T15:42:22.856982Z","iopub.status.busy":"2023-02-04T15:42:22.856593Z","iopub.status.idle":"2023-02-04T15:42:22.867883Z","shell.execute_reply":"2023-02-04T15:42:22.866681Z"},"id":"Mu0lyAUIGSTB","outputId":"cb82872d-c3ba-4d76-a28c-237eb266e78b","papermill":{"duration":0.230441,"end_time":"2023-02-04T15:42:22.869734","exception":false,"start_time":"2023-02-04T15:42:22.639293","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy:  62.580000000000005\n","Average std:  6.22\n","==============================================\n","Average AUC:  62.660000000000004\n","Average AUC std:  6.17\n","==============================================\n","Average Balanced Accuracy:  26.39\n","Average std:  3.2800000000000002\n","==============================================\n","Average MI:  4.66\n","Average std:  0.89\n","==============================================\n","Average Normalized MI:  6.77\n","Average std:  1.29\n","==============================================\n","Average Ajdusted MI:  6.77\n","Average std:  1.29\n"]}],"source":["print('Average Accuracy: ', np.round( ACC.mean(),4)*100) \n","print('Average std: ',np.round(np.std( ACC),4)*100)\n","print('==============================================')\n","print('Average AUC: ', np.round( AUC.mean(),4)*100) \n","print('Average AUC std: ',np.round(np.std( AUC),4)*100)\n","print('==============================================')\n","print('Average Balanced Accuracy: ', np.round( BACC.mean(),4)*100) \n","print('Average std: ',np.round(np.std( BACC),4)*100)\n","print('==============================================')\n","print('Average MI: ', np.round( MI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(MI),4)*100)\n","print('==============================================')\n","print('Average Normalized MI: ', np.round( NMI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(NMI),4)*100)\n","print('==============================================')\n","print('Average Ajdusted MI: ', np.round( AMI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(AMI),4)*100)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":7585.315231,"end_time":"2023-02-04T15:42:27.411412","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-02-04T13:36:02.096181","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}