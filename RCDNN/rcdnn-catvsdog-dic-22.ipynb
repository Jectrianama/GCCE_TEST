{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5a842b",
   "metadata": {
    "id": "oAuRT75GdLFw",
    "papermill": {
     "duration": 0.01025,
     "end_time": "2022-12-20T22:09:38.282681",
     "exception": false,
     "start_time": "2022-12-20T22:09:38.272431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cats vs. Dogs Class dataset for multiple annotators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bca97",
   "metadata": {
    "id": "9rK94t33nwDC",
    "papermill": {
     "duration": 0.008358,
     "end_time": "2022-12-20T22:09:38.299905",
     "exception": false,
     "start_time": "2022-12-20T22:09:38.291547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d346b00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:38.319461Z",
     "iopub.status.busy": "2022-12-20T22:09:38.318595Z",
     "iopub.status.idle": "2022-12-20T22:09:44.964776Z",
     "shell.execute_reply": "2022-12-20T22:09:44.963774Z"
    },
    "id": "zSyMHuCVys-O",
    "papermill": {
     "duration": 6.658956,
     "end_time": "2022-12-20T22:09:44.967307",
     "exception": false,
     "start_time": "2022-12-20T22:09:38.308351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d76753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:44.986160Z",
     "iopub.status.busy": "2022-12-20T22:09:44.984979Z",
     "iopub.status.idle": "2022-12-20T22:09:44.989685Z",
     "shell.execute_reply": "2022-12-20T22:09:44.988806Z"
    },
    "id": "-E1MJt8cxlwg",
    "outputId": "ea43c1c9-075f-44de-d2d8-e135799b6630",
    "papermill": {
     "duration": 0.015725,
     "end_time": "2022-12-20T22:09:44.991501",
     "exception": false,
     "start_time": "2022-12-20T22:09:44.975776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a71a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:45.010114Z",
     "iopub.status.busy": "2022-12-20T22:09:45.008640Z",
     "iopub.status.idle": "2022-12-20T22:09:45.013625Z",
     "shell.execute_reply": "2022-12-20T22:09:45.012773Z"
    },
    "id": "QJPvjdZ-f8ca",
    "papermill": {
     "duration": 0.015906,
     "end_time": "2022-12-20T22:09:45.015541",
     "exception": false,
     "start_time": "2022-12-20T22:09:44.999635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/Shareddrives/Multiple Anotators/CrowdLayer/Notebooks')\n",
    "# cwd = os.getcwd()\n",
    "# sys.path.append(\"../Models\")\n",
    "\n",
    "\n",
    "# from Multiple_Annotators_C import MultipleAnnotators_Classification\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(1, '../input/multiple-annotators-c/')\n",
    "#os.chdir('/Multiple Anotators-c/')\n",
    "#cwd = os.getcwd()\n",
    "#sys.path.append('/input/multiple-annotators-c')\n",
    "#from Multiple_Annotators_C import MultipleAnnotators_Classification\n",
    "\n",
    "# seed_value= 12321 \n",
    "# from numpy.random import seed\n",
    "# seed(seed_value)\n",
    "# tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671bbbd",
   "metadata": {
    "id": "6Un5nFWgnyem",
    "papermill": {
     "duration": 0.007956,
     "end_time": "2022-12-20T22:09:45.031703",
     "exception": false,
     "start_time": "2022-12-20T22:09:45.023747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download and Prepare the Dataset\n",
    "\n",
    "We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset and we can load it via Tensorflow Datasets. The images are labeled 0 for cats and 1 for dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415289cd",
   "metadata": {
    "id": "Gw6K2Uey06kh",
    "papermill": {
     "duration": 0.00768,
     "end_time": "2022-12-20T22:09:45.047269",
     "exception": false,
     "start_time": "2022-12-20T22:09:45.039589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiple annotators model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe34f44c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:45.065789Z",
     "iopub.status.busy": "2022-12-20T22:09:45.064952Z",
     "iopub.status.idle": "2022-12-20T22:09:48.095865Z",
     "shell.execute_reply": "2022-12-20T22:09:48.094864Z"
    },
    "id": "xam4REp209Sd",
    "papermill": {
     "duration": 3.041854,
     "end_time": "2022-12-20T22:09:48.098101",
     "exception": false,
     "start_time": "2022-12-20T22:09:45.056247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 22:09:45.161513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:45.260542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:45.261408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:45.263416: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 22:09:45.267691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:45.268474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:45.269217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:47.650567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:47.651453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:47.652159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 22:09:47.652788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_data = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_Te')\n",
    "train_data_MA = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_MA_sin_Tr_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c1c623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:48.117828Z",
     "iopub.status.busy": "2022-12-20T22:09:48.116218Z",
     "iopub.status.idle": "2022-12-20T22:09:48.126461Z",
     "shell.execute_reply": "2022-12-20T22:09:48.125601Z"
    },
    "id": "D_S0EJ3mFdfK",
    "outputId": "9ed3c2c7-50b4-4445-a01e-c9a3d780c403",
    "papermill": {
     "duration": 0.02169,
     "end_time": "2022-12-20T22:09:48.128588",
     "exception": false,
     "start_time": "2022-12-20T22:09:48.106898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_data_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89a2ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:48.146722Z",
     "iopub.status.busy": "2022-12-20T22:09:48.146433Z",
     "iopub.status.idle": "2022-12-20T22:09:48.153204Z",
     "shell.execute_reply": "2022-12-20T22:09:48.152147Z"
    },
    "id": "ctjLei0TxcVh",
    "outputId": "6f578b73-ebdf-4465-91c7-2adb7d127174",
    "papermill": {
     "duration": 0.018747,
     "end_time": "2022-12-20T22:09:48.155872",
     "exception": false,
     "start_time": "2022-12-20T22:09:48.137125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4652"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count1 = tf.data.experimental.cardinality(validation_data).numpy() # los datos de training son 18610\n",
    "image_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23f8ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:09:48.174246Z",
     "iopub.status.busy": "2022-12-20T22:09:48.173963Z",
     "iopub.status.idle": "2022-12-20T22:10:06.039201Z",
     "shell.execute_reply": "2022-12-20T22:10:06.038128Z"
    },
    "id": "opk5MXl4IwjC",
    "papermill": {
     "duration": 17.877356,
     "end_time": "2022-12-20T22:10:06.042046",
     "exception": false,
     "start_time": "2022-12-20T22:09:48.164690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 22:09:48.201972: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "#X_test = [validation_data[i][0] for i in range(image_count1)]\n",
    "#Y_true_test = [validation_data[i][1] for i in range(image_count1)]\n",
    "Y_true_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n",
    "X_test = np.asarray([aux[0].numpy() for aux  in validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875dca03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:06.061317Z",
     "iopub.status.busy": "2022-12-20T22:10:06.060983Z",
     "iopub.status.idle": "2022-12-20T22:10:06.067569Z",
     "shell.execute_reply": "2022-12-20T22:10:06.066471Z"
    },
    "id": "-BydcVOQxcVh",
    "outputId": "8c1b4ed2-7c43-4675-f055-f9e4e3f5b3dd",
    "papermill": {
     "duration": 0.019682,
     "end_time": "2022-12-20T22:10:06.070828",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.051146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262f3708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:06.089580Z",
     "iopub.status.busy": "2022-12-20T22:10:06.089299Z",
     "iopub.status.idle": "2022-12-20T22:10:06.096902Z",
     "shell.execute_reply": "2022-12-20T22:10:06.096024Z"
    },
    "id": "HdFme6fdxcVh",
    "papermill": {
     "duration": 0.019303,
     "end_time": "2022-12-20T22:10:06.098981",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.079678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds_MA = train_data_MA.skip(val_size)\n",
    "val_ds_MA = train_data_MA.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a33fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:06.118302Z",
     "iopub.status.busy": "2022-12-20T22:10:06.117671Z",
     "iopub.status.idle": "2022-12-20T22:10:06.128147Z",
     "shell.execute_reply": "2022-12-20T22:10:06.127286Z"
    },
    "id": "aVHIlFpgxcVi",
    "papermill": {
     "duration": 0.022484,
     "end_time": "2022-12-20T22:10:06.130340",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.107856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_batches_MA = train_ds_MA.shuffle(1024).batch(batch_size)\n",
    "val_batches_MA = val_ds_MA.shuffle(1024).batch(batch_size)\n",
    "test_batches_MA = validation_data.shuffle(1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6aa7169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:06.148835Z",
     "iopub.status.busy": "2022-12-20T22:10:06.148545Z",
     "iopub.status.idle": "2022-12-20T22:10:06.155444Z",
     "shell.execute_reply": "2022-12-20T22:10:06.154496Z"
    },
    "id": "GsB4EA2-xcVi",
    "outputId": "2d45809e-a9cc-408f-9a8b-745e8fe850e9",
    "papermill": {
     "duration": 0.018272,
     "end_time": "2022-12-20T22:10:06.157449",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.139177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64d84b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:06.175534Z",
     "iopub.status.busy": "2022-12-20T22:10:06.175264Z",
     "iopub.status.idle": "2022-12-20T22:10:06.182364Z",
     "shell.execute_reply": "2022-12-20T22:10:06.181422Z"
    },
    "id": "Hk33DzwkxcVi",
    "outputId": "aad91eec-842c-4995-de90-5bb715539b6a",
    "papermill": {
     "duration": 0.01856,
     "end_time": "2022-12-20T22:10:06.184465",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.165905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3722"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count_val = tf.data.experimental.cardinality(val_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8604b",
   "metadata": {
    "id": "UMeK3NG3xcVi",
    "papermill": {
     "duration": 0.008939,
     "end_time": "2022-12-20T22:10:06.202153",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.193214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30fa3ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:06.221316Z",
     "iopub.status.busy": "2022-12-20T22:10:06.221029Z",
     "iopub.status.idle": "2022-12-20T22:10:23.981043Z",
     "shell.execute_reply": "2022-12-20T22:10:23.979971Z"
    },
    "id": "uvwc7eixxcVi",
    "outputId": "d7766078-8c40-41ed-fb01-66b5f62a07f1",
    "papermill": {
     "duration": 17.772781,
     "end_time": "2022-12-20T22:10:23.984012",
     "exception": false,
     "start_time": "2022-12-20T22:10:06.211231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 22:10:18.426785: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n",
      "2022-12-20 22:10:21.718282: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.83      0.82        63\n",
      "         1.0       0.83      0.82      0.82        65\n",
      "\n",
      "    accuracy                           0.82       128\n",
      "   macro avg       0.82      0.82      0.82       128\n",
      "weighted avg       0.82      0.82      0.82       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.59      0.59        63\n",
      "         1.0       0.60      0.60      0.60        65\n",
      "\n",
      "    accuracy                           0.59       128\n",
      "   macro avg       0.59      0.59      0.59       128\n",
      "weighted avg       0.59      0.59      0.59       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.67      0.65        63\n",
      "         1.0       0.66      0.63      0.65        65\n",
      "\n",
      "    accuracy                           0.65       128\n",
      "   macro avg       0.65      0.65      0.65       128\n",
      "weighted avg       0.65      0.65      0.65       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.49      0.49        63\n",
      "         1.0       0.50      0.49      0.50        65\n",
      "\n",
      "    accuracy                           0.49       128\n",
      "   macro avg       0.49      0.49      0.49       128\n",
      "weighted avg       0.49      0.49      0.49       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.29      0.27        63\n",
      "         1.0       0.21      0.18      0.20        65\n",
      "\n",
      "    accuracy                           0.23       128\n",
      "   macro avg       0.23      0.24      0.23       128\n",
      "weighted avg       0.23      0.23      0.23       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83        70\n",
      "         1.0       0.79      0.79      0.79        58\n",
      "\n",
      "    accuracy                           0.81       128\n",
      "   macro avg       0.81      0.81      0.81       128\n",
      "weighted avg       0.81      0.81      0.81       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.59      0.63        70\n",
      "         1.0       0.57      0.66      0.61        58\n",
      "\n",
      "    accuracy                           0.62       128\n",
      "   macro avg       0.62      0.62      0.62       128\n",
      "weighted avg       0.62      0.62      0.62       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.63      0.62        70\n",
      "         1.0       0.54      0.52      0.53        58\n",
      "\n",
      "    accuracy                           0.58       128\n",
      "   macro avg       0.57      0.57      0.57       128\n",
      "weighted avg       0.58      0.58      0.58       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.51      0.52        70\n",
      "         1.0       0.42      0.43      0.43        58\n",
      "\n",
      "    accuracy                           0.48       128\n",
      "   macro avg       0.47      0.47      0.47       128\n",
      "weighted avg       0.48      0.48      0.48       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.24      0.25        70\n",
      "         1.0       0.13      0.14      0.13        58\n",
      "\n",
      "    accuracy                           0.20       128\n",
      "   macro avg       0.19      0.19      0.19       128\n",
      "weighted avg       0.20      0.20      0.20       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79        61\n",
      "         1.0       0.82      0.79      0.80        67\n",
      "\n",
      "    accuracy                           0.80       128\n",
      "   macro avg       0.80      0.80      0.80       128\n",
      "weighted avg       0.80      0.80      0.80       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.51      0.51        61\n",
      "         1.0       0.55      0.55      0.55        67\n",
      "\n",
      "    accuracy                           0.53       128\n",
      "   macro avg       0.53      0.53      0.53       128\n",
      "weighted avg       0.53      0.53      0.53       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.56      0.58        61\n",
      "         1.0       0.62      0.67      0.65        67\n",
      "\n",
      "    accuracy                           0.62       128\n",
      "   macro avg       0.62      0.61      0.61       128\n",
      "weighted avg       0.62      0.62      0.62       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.56      0.55        61\n",
      "         1.0       0.59      0.58      0.59        67\n",
      "\n",
      "    accuracy                           0.57       128\n",
      "   macro avg       0.57      0.57      0.57       128\n",
      "weighted avg       0.57      0.57      0.57       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.19      0.21      0.20        61\n",
      "         1.0       0.21      0.19      0.20        67\n",
      "\n",
      "    accuracy                           0.20       128\n",
      "   macro avg       0.20      0.20      0.20       128\n",
      "weighted avg       0.20      0.20      0.20       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.81      0.83        62\n",
      "         1.0       0.83      0.86      0.84        66\n",
      "\n",
      "    accuracy                           0.84       128\n",
      "   macro avg       0.84      0.84      0.84       128\n",
      "weighted avg       0.84      0.84      0.84       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.48      0.51        62\n",
      "         1.0       0.56      0.62      0.59        66\n",
      "\n",
      "    accuracy                           0.55       128\n",
      "   macro avg       0.55      0.55      0.55       128\n",
      "weighted avg       0.55      0.55      0.55       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.73      0.66        62\n",
      "         1.0       0.69      0.56      0.62        66\n",
      "\n",
      "    accuracy                           0.64       128\n",
      "   macro avg       0.65      0.64      0.64       128\n",
      "weighted avg       0.65      0.64      0.64       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.48      0.48        62\n",
      "         1.0       0.51      0.50      0.50        66\n",
      "\n",
      "    accuracy                           0.49       128\n",
      "   macro avg       0.49      0.49      0.49       128\n",
      "weighted avg       0.49      0.49      0.49       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.32      0.29        62\n",
      "         1.0       0.18      0.14      0.15        66\n",
      "\n",
      "    accuracy                           0.23       128\n",
      "   macro avg       0.22      0.23      0.22       128\n",
      "weighted avg       0.22      0.23      0.22       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "i = 0\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for image, label, label2 in train_batches_MA.take(4):\n",
    "   # predictedLabel = int(predictions[i] >= 0.5)\n",
    "   # print(label2)\n",
    "    ax[i].axis('off')\n",
    "   # ax[i].set_title(classNames[label[i]])\n",
    "    ax[i].imshow(image[0])\n",
    "    i += 1\n",
    "    for j in range(label2.shape[1]):\n",
    "      print('annotator',j+1)\n",
    "      print(classification_report(label ,label2[:,j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c161a23",
   "metadata": {
    "id": "9AgOHREc1bmd",
    "papermill": {
     "duration": 0.016412,
     "end_time": "2022-12-20T22:10:24.018411",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.001999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the classifier from multiple annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09df670e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:24.052977Z",
     "iopub.status.busy": "2022-12-20T22:10:24.052447Z",
     "iopub.status.idle": "2022-12-20T22:10:24.091852Z",
     "shell.execute_reply": "2022-12-20T22:10:24.090866Z"
    },
    "id": "k-ePr0-fxcVi",
    "papermill": {
     "duration": 0.060008,
     "end_time": "2022-12-20T22:10:24.094591",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.034583",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "class MultipleAnnotators_Classification():\n",
    "    def __init__(self, output_dim, num_annotators, q= 0.0001):\n",
    "        self.K = output_dim\n",
    "        self.R = num_annotators\n",
    "        self.q = q\n",
    "        #self.callbacks #=callbacks\n",
    "        #self.l1_param=l1_param \n",
    "        #self.l2_param=l1_param\n",
    "\n",
    "    def CrowdLayer(self, input):\n",
    "       #x = keras.layers.Dense(self.R + self.K, kernel_regularizer=regularizers.L1L2(l1= 1e-2, l2=1e-3),  activation='tanh')(input)\n",
    "        output_cla = keras.layers.Dense(self.K,  activation='softmax')(input)\n",
    "        output_ann = keras.layers.Dense(self.R,  activation='sigmoid')(input)\n",
    "        output = keras.layers.Concatenate()([output_cla, output_ann])\n",
    "        \n",
    "        return output\n",
    "#RCDNN   \n",
    "    def loss(self):\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            # print(y_true,y_pred)\n",
    "            pred = y_pred[:, :self.K]\n",
    "            pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1-1e-9) #estabilidad numerica de la funcion de costo\n",
    "            ann_ = y_pred[:, self.K:]\n",
    "            Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n",
    "            Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n",
    "            p_logreg = tf.math.reduce_prod(tf.math.pow(Y_hat, Y_true), axis=1)\n",
    "            temp1 = ann_*tf.math.log(p_logreg)  \n",
    "            temp2 = (1 - ann_)*tf.math.log(1/self.K)*tf.reduce_sum(Y_true,axis=1)\n",
    "            # temp2 = (tf.ones(tf.shape(ann_)) - ann_)*tf.math.log(1/K)\n",
    "            # print(tf.reduce_mean(Y_true,axis=1).numpy())\n",
    "            return -tf.math.reduce_sum((temp1 + temp2))\n",
    "        return custom_loss\n",
    "    \n",
    "#     def loss(self):\n",
    "#         def custom_loss(y_true, y_pred):\n",
    "#                # print(y_true,y_pred)\n",
    "#            # q = 0.1\n",
    "#             pred = y_pred[:, :self.K]\n",
    "#             pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n",
    "#             ann_ = y_pred[:, self.K:]\n",
    "#             # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n",
    "#             Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n",
    "#             Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n",
    "\n",
    "#             p_gcce = Y_true*(1 - Y_hat**self.q)/self.q\n",
    "#             temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n",
    "#             temp2 = (1 - ann_)*(1-(1/self.K)**self.q)/self.q*tf.reduce_sum(Y_true,axis=1)\n",
    "#             return tf.math.reduce_sum((temp1 + temp2))\n",
    "#         return custom_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x, Y, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(x, training=True)\n",
    "            loss_value = self.loss_fn(Y, logits)\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        self.train_acc_metric.update_state(y, logits[:, :self.K])\n",
    "        return loss_value\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, x, y):\n",
    "        val_logits = self.model(x, training=False)\n",
    "        self.val_acc_metric.update_state(y, val_logits[:,:self.K])\n",
    "\n",
    "    def fit(self, model, Data_tr, Data_Val, epochs):\n",
    "        self.model = model\n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # Instantiate an optimizer.\n",
    "        #self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "        self.optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        #self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, clipnorm=1.0)\n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # Instantiate a loss function.\n",
    "        self.loss_fn = self.loss()\n",
    "        self.train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        train_loss = np.zeros(epochs)\n",
    "        train_accur = np.zeros(epochs)\n",
    "        val_accur = np.zeros(epochs)\n",
    "        val_loss = np.zeros(epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train, Y_batch_train) in enumerate(Data_tr):\n",
    "                # print(y_batch_train, Y_batch_train)\n",
    "                loss_value = self.train_step(x_batch_train, Y_batch_train, y_batch_train)\n",
    "\n",
    "                # Log every 200 batches.\n",
    "                if step % 10 == 0:\n",
    "                    train_acc = self.train_acc_metric.result()\n",
    "                    print(\n",
    "                      \"Training loss (for one batch) at step %d: %.4f, Accuracy: %.4f\"\n",
    "                      % (step, float(loss_value), float(train_acc))\n",
    "                            )\n",
    "                # print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "\n",
    "\n",
    "            # Run a validation loop at the end of each epoch.\n",
    "            for x_batch_val, y_batch_val,Y_batch_val in Data_Val:\n",
    "\n",
    "                val_logits = model(x_batch_val, training=False)\n",
    "\n",
    "                val_loss_value = self.loss_fn(Y_batch_val, val_logits)\n",
    "\n",
    "                self.val_acc_metric.update_state(y_batch_val, val_logits[:,:self.K])\n",
    "                \n",
    "               # np.round(np.mean([model(x_batch_val, training= True) for sample in range(100)]), 2)\n",
    "\n",
    "\n",
    "             # Display metrics at the end of each epoch.\n",
    "            train_acc = self.train_acc_metric.result()\n",
    "            val_acc = self.val_acc_metric.result()\n",
    "\n",
    "\n",
    "            print('---- Training ----')\n",
    "            print(\"Training loss: %.4f\" % (float(loss_value),))\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            self.train_acc_metric.reset_states()\n",
    "            self.val_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "            train_loss[epoch] = float(loss_value)\n",
    "            train_accur[epoch] = float(train_acc)\n",
    "\n",
    "            val_accur[epoch] = float(val_acc)\n",
    "            val_loss[epoch] = float(val_loss_value) \n",
    "\n",
    "\n",
    "            print('---- Validation ----')\n",
    "            print(\"Validation loss: %.4f\" % (float(val_loss_value),))\n",
    "            print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "\n",
    "            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Loss and accuracy')\n",
    "        ax1.plot(range(1,epochs+1),train_loss)\n",
    "        ax1.plot(range(1,epochs+1), val_loss)\n",
    "        ax2.plot(range(1,epochs+1),train_accur)\n",
    "        ax2.plot(range(1,epochs+1),val_accur)\n",
    "        #plt.figure(figsize=(16,9))\n",
    "        ax1.set(xlabel= 'Epoch', ylabel=\"Loss\")\n",
    "        ax2.set(xlabel= 'Epoch',ylabel=\"Accuracy\")\n",
    "        ax1.legend(['Training_loss', 'Validation_loss'])\n",
    "        ax2.legend(['Training', 'Validation'])\n",
    "        ax1.grid()\n",
    "        ax2.grid()\n",
    "        plt.show()\n",
    "        return self.model\n",
    "\n",
    "    def eval_model(self, Data):\n",
    "        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "        for x_batch_val, y_batch_val in Data:\n",
    "            self.test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        val_acc = self.val_acc_metric.result()\n",
    "        self.val_acc_metric.reset_states()\n",
    "        return val_acc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd65949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:24.124724Z",
     "iopub.status.busy": "2022-12-20T22:10:24.124290Z",
     "iopub.status.idle": "2022-12-20T22:10:24.134937Z",
     "shell.execute_reply": "2022-12-20T22:10:24.133761Z"
    },
    "id": "4l-_pkpaBkSv",
    "papermill": {
     "duration": 0.028232,
     "end_time": "2022-12-20T22:10:24.137371",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.109139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # print(y_true,y_pred)\n",
    "  K = 2 #len(np.unique(y_true))\n",
    "  R = 5\n",
    "  q = 0.1\n",
    "  pred = y_pred[:, K]\n",
    "  pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n",
    "  ann_ = y_pred[:,  K:]\n",
    "  # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n",
    "  Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=K, axis=1)\n",
    "  Y_hat = tf.repeat(tf.expand_dims(pred,-1), R, axis = -1)\n",
    "\n",
    "  p_gcce = Y_true*(1 - Y_hat**q)/q\n",
    "  temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n",
    "  temp2 = (1 - ann_)*(1-(1/K)**q)/q*tf.reduce_sum(Y_true,axis=1)\n",
    "  return tf.math.reduce_sum((temp1 + temp2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f321ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:24.169135Z",
     "iopub.status.busy": "2022-12-20T22:10:24.168728Z",
     "iopub.status.idle": "2022-12-20T22:10:24.186134Z",
     "shell.execute_reply": "2022-12-20T22:10:24.185176Z"
    },
    "id": "0I4Rrc5TxcVj",
    "papermill": {
     "duration": 0.035878,
     "end_time": "2022-12-20T22:10:24.188720",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.152842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MA = MultipleAnnotators_Classification(2, 5, 0.001)\n",
    " \n",
    "def create_model():\n",
    "   \n",
    "    l1 = 1e-2\n",
    "    # Block 1\n",
    "    inputs = keras.layers.Input(shape=(150, 150, 3), name='entrada')\n",
    "    x = keras.layers.BatchNormalization()(inputs)\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\" , name=\"block1_conv1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "\n",
    "\n",
    "    # Block 2\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", name=\"block2_conv1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block3_conv1\" )(x)             \n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "   # x = keras.layers.Dropout(0.2)(x)\n",
    "   \n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "    \n",
    "    # Block 4\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block4_conv1\")(x)            \n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    #x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "   \n",
    "    x = keras.layers.Flatten()(x)\n",
    "    #x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    output = MA.CrowdLayer(x)\n",
    "    model = keras.Model(inputs=inputs,outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c12032f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:24.221274Z",
     "iopub.status.busy": "2022-12-20T22:10:24.220922Z",
     "iopub.status.idle": "2022-12-20T22:10:24.225303Z",
     "shell.execute_reply": "2022-12-20T22:10:24.224359Z"
    },
    "id": "iZAxrNF3_hE_",
    "papermill": {
     "duration": 0.023356,
     "end_time": "2022-12-20T22:10:24.227496",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.204140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# callbacks = [\n",
    "#     EarlyStopping(patience=10, verbose=1),\n",
    "#     ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "#     ModelCheckpoint('model1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bdae5",
   "metadata": {
    "id": "Z-fV95n3GEqa",
    "papermill": {
     "duration": 0.014567,
     "end_time": "2022-12-20T22:10:24.257891",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.243324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "356173a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:24.288820Z",
     "iopub.status.busy": "2022-12-20T22:10:24.288463Z",
     "iopub.status.idle": "2022-12-20T22:10:24.294317Z",
     "shell.execute_reply": "2022-12-20T22:10:24.293400Z"
    },
    "id": "_H_sb1cl1FC_",
    "outputId": "59d957da-9223-4a01-e4d9-33933f7a2f4a",
    "papermill": {
     "duration": 0.026935,
     "end_time": "2022-12-20T22:10:24.299316",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.272381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classification_report_r= []\n",
    "# model = create_model()\n",
    "# K=2\n",
    "# R=5\n",
    "# NUM_RUNS = 5\n",
    "# N_EPOCHS = 30\n",
    "# val_acc = np.zeros(NUM_RUNS)\n",
    "# for i in range(NUM_RUNS):\n",
    "#   MA = MultipleAnnotators_Classification(K, R, 0.1)\n",
    "#   model = create_model()\n",
    "#   optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "#   model.compile(optimizer=optimizer, loss= MA.loss())\n",
    "#   history_model = model.fit(train_batches_MA, validation_data=val_batches_MA, epochs= N_EPOCHS, callbacks=callbacks, verbose=0)\n",
    "#   #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n",
    "#   pred_2 = model.predict(X_test)\n",
    "\n",
    "#   lambda_R_ = pred_2[:, K:] #annotators reliability prediction N x R   \n",
    "#   classification_report_r += [classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel(),output_dict=True)]\n",
    "#   print(classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel()))\n",
    "#   #val_acc[i] = MA.eval_model(test_batches_MA)\n",
    "#   #print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n",
    "#   # Create the history figure\n",
    "#   plt.figure(figsize=(16,9))\n",
    "#   for i in  history_model.history:\n",
    "#       plt.plot(history_model.history[i],label=i)\n",
    "#   plt.title('Model history')\n",
    "#   plt.legend()\n",
    "#   plt.grid()\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(val_acc)\n",
    "# #df.to_csimport pandas as pddf = pd.DataFrame(val_acc)#df.to_csv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output​v('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a75e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:10:24.335281Z",
     "iopub.status.busy": "2022-12-20T22:10:24.334968Z",
     "iopub.status.idle": "2022-12-20T22:48:47.610056Z",
     "shell.execute_reply": "2022-12-20T22:48:47.607942Z"
    },
    "id": "Mu0lyAUIGSTB",
    "outputId": "cb82872d-c3ba-4d76-a28c-237eb266e78b",
    "papermill": {
     "duration": 2303.295489,
     "end_time": "2022-12-20T22:48:47.614357",
     "exception": false,
     "start_time": "2022-12-20T22:10:24.318868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 22:10:27.610142: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 628.3044, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 672.0573, Accuracy: 0.5142\n",
      "Training loss (for one batch) at step 20: 563.8323, Accuracy: 0.5030\n",
      "Training loss (for one batch) at step 30: 530.1647, Accuracy: 0.5010\n",
      "Training loss (for one batch) at step 40: 544.0790, Accuracy: 0.5059\n",
      "Training loss (for one batch) at step 50: 533.6938, Accuracy: 0.5061\n",
      "Training loss (for one batch) at step 60: 491.6225, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 70: 487.1225, Accuracy: 0.5092\n",
      "Training loss (for one batch) at step 80: 466.3415, Accuracy: 0.5069\n",
      "Training loss (for one batch) at step 90: 478.2764, Accuracy: 0.5062\n",
      "Training loss (for one batch) at step 100: 477.3760, Accuracy: 0.5056\n",
      "Training loss (for one batch) at step 110: 471.0901, Accuracy: 0.5070\n",
      "---- Training ----\n",
      "Training loss: 142.6965\n",
      "Training acc over epoch: 0.5057\n",
      "---- Validation ----\n",
      "Validation loss: 34.5555\n",
      "Validation acc: 0.5032\n",
      "Time taken: 70.08s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 462.3390, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 467.1551, Accuracy: 0.5163\n",
      "Training loss (for one batch) at step 20: 471.8078, Accuracy: 0.5186\n",
      "Training loss (for one batch) at step 30: 454.6046, Accuracy: 0.5154\n",
      "Training loss (for one batch) at step 40: 458.5007, Accuracy: 0.5208\n",
      "Training loss (for one batch) at step 50: 454.8164, Accuracy: 0.5216\n",
      "Training loss (for one batch) at step 60: 449.6375, Accuracy: 0.5227\n",
      "Training loss (for one batch) at step 70: 448.2415, Accuracy: 0.5262\n",
      "Training loss (for one batch) at step 80: 454.5549, Accuracy: 0.5253\n",
      "Training loss (for one batch) at step 90: 465.0599, Accuracy: 0.5241\n",
      "Training loss (for one batch) at step 100: 453.9415, Accuracy: 0.5260\n",
      "Training loss (for one batch) at step 110: 454.3482, Accuracy: 0.5251\n",
      "---- Training ----\n",
      "Training loss: 143.5648\n",
      "Training acc over epoch: 0.5250\n",
      "---- Validation ----\n",
      "Validation loss: 34.8182\n",
      "Validation acc: 0.5124\n",
      "Time taken: 15.45s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 450.9218, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 449.6801, Accuracy: 0.5213\n",
      "Training loss (for one batch) at step 20: 448.2459, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 30: 451.6373, Accuracy: 0.5287\n",
      "Training loss (for one batch) at step 40: 445.9313, Accuracy: 0.5297\n",
      "Training loss (for one batch) at step 50: 446.0670, Accuracy: 0.5286\n",
      "Training loss (for one batch) at step 60: 445.7953, Accuracy: 0.5323\n",
      "Training loss (for one batch) at step 70: 448.6393, Accuracy: 0.5341\n",
      "Training loss (for one batch) at step 80: 452.6078, Accuracy: 0.5352\n",
      "Training loss (for one batch) at step 90: 446.9362, Accuracy: 0.5352\n",
      "Training loss (for one batch) at step 100: 445.7273, Accuracy: 0.5350\n",
      "Training loss (for one batch) at step 110: 445.4995, Accuracy: 0.5377\n",
      "---- Training ----\n",
      "Training loss: 138.4210\n",
      "Training acc over epoch: 0.5391\n",
      "---- Validation ----\n",
      "Validation loss: 34.5963\n",
      "Validation acc: 0.5296\n",
      "Time taken: 11.27s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 445.6773, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 451.1441, Accuracy: 0.5490\n",
      "Training loss (for one batch) at step 20: 449.1195, Accuracy: 0.5387\n",
      "Training loss (for one batch) at step 30: 445.2463, Accuracy: 0.5459\n",
      "Training loss (for one batch) at step 40: 447.1510, Accuracy: 0.5492\n",
      "Training loss (for one batch) at step 50: 440.2845, Accuracy: 0.5493\n",
      "Training loss (for one batch) at step 60: 444.2920, Accuracy: 0.5498\n",
      "Training loss (for one batch) at step 70: 448.9078, Accuracy: 0.5555\n",
      "Training loss (for one batch) at step 80: 443.1167, Accuracy: 0.5572\n",
      "Training loss (for one batch) at step 90: 445.9094, Accuracy: 0.5578\n",
      "Training loss (for one batch) at step 100: 442.0058, Accuracy: 0.5569\n",
      "Training loss (for one batch) at step 110: 442.6463, Accuracy: 0.5589\n",
      "---- Training ----\n",
      "Training loss: 138.5845\n",
      "Training acc over epoch: 0.5611\n",
      "---- Validation ----\n",
      "Validation loss: 35.1069\n",
      "Validation acc: 0.5736\n",
      "Time taken: 11.21s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 444.0899, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 442.4323, Accuracy: 0.5632\n",
      "Training loss (for one batch) at step 20: 440.8029, Accuracy: 0.5577\n",
      "Training loss (for one batch) at step 30: 441.6907, Accuracy: 0.5660\n",
      "Training loss (for one batch) at step 40: 442.2248, Accuracy: 0.5749\n",
      "Training loss (for one batch) at step 50: 442.7741, Accuracy: 0.5722\n",
      "Training loss (for one batch) at step 60: 443.5085, Accuracy: 0.5733\n",
      "Training loss (for one batch) at step 70: 443.1268, Accuracy: 0.5765\n",
      "Training loss (for one batch) at step 80: 444.2383, Accuracy: 0.5790\n",
      "Training loss (for one batch) at step 90: 443.5942, Accuracy: 0.5791\n",
      "Training loss (for one batch) at step 100: 443.2643, Accuracy: 0.5798\n",
      "Training loss (for one batch) at step 110: 445.0815, Accuracy: 0.5828\n",
      "---- Training ----\n",
      "Training loss: 137.2834\n",
      "Training acc over epoch: 0.5840\n",
      "---- Validation ----\n",
      "Validation loss: 34.7276\n",
      "Validation acc: 0.6179\n",
      "Time taken: 11.31s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.2023, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 443.8623, Accuracy: 0.5888\n",
      "Training loss (for one batch) at step 20: 443.0369, Accuracy: 0.5740\n",
      "Training loss (for one batch) at step 30: 442.2362, Accuracy: 0.5839\n",
      "Training loss (for one batch) at step 40: 440.1635, Accuracy: 0.5877\n",
      "Training loss (for one batch) at step 50: 441.5034, Accuracy: 0.5939\n",
      "Training loss (for one batch) at step 60: 441.8205, Accuracy: 0.5972\n",
      "Training loss (for one batch) at step 70: 439.9158, Accuracy: 0.6021\n",
      "Training loss (for one batch) at step 80: 444.4756, Accuracy: 0.6039\n",
      "Training loss (for one batch) at step 90: 441.4164, Accuracy: 0.6004\n",
      "Training loss (for one batch) at step 100: 442.3740, Accuracy: 0.5956\n",
      "Training loss (for one batch) at step 110: 440.7505, Accuracy: 0.5989\n",
      "---- Training ----\n",
      "Training loss: 137.8932\n",
      "Training acc over epoch: 0.6001\n",
      "---- Validation ----\n",
      "Validation loss: 35.4355\n",
      "Validation acc: 0.6373\n",
      "Time taken: 10.88s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 444.1739, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 444.8282, Accuracy: 0.6143\n",
      "Training loss (for one batch) at step 20: 439.7324, Accuracy: 0.6038\n",
      "Training loss (for one batch) at step 30: 436.2810, Accuracy: 0.6147\n",
      "Training loss (for one batch) at step 40: 443.7491, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 50: 439.3190, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 60: 440.7164, Accuracy: 0.6182\n",
      "Training loss (for one batch) at step 70: 442.9440, Accuracy: 0.6187\n",
      "Training loss (for one batch) at step 80: 440.8620, Accuracy: 0.6177\n",
      "Training loss (for one batch) at step 90: 440.6710, Accuracy: 0.6154\n",
      "Training loss (for one batch) at step 100: 439.8259, Accuracy: 0.6163\n",
      "Training loss (for one batch) at step 110: 439.2079, Accuracy: 0.6186\n",
      "---- Training ----\n",
      "Training loss: 140.8093\n",
      "Training acc over epoch: 0.6179\n",
      "---- Validation ----\n",
      "Validation loss: 35.8164\n",
      "Validation acc: 0.6456\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 444.7150, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 445.5813, Accuracy: 0.6193\n",
      "Training loss (for one batch) at step 20: 441.2300, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 30: 436.6545, Accuracy: 0.6245\n",
      "Training loss (for one batch) at step 40: 438.1265, Accuracy: 0.6267\n",
      "Training loss (for one batch) at step 50: 439.5020, Accuracy: 0.6302\n",
      "Training loss (for one batch) at step 60: 443.1617, Accuracy: 0.6315\n",
      "Training loss (for one batch) at step 70: 444.4895, Accuracy: 0.6318\n",
      "Training loss (for one batch) at step 80: 443.0372, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 90: 442.6300, Accuracy: 0.6227\n",
      "Training loss (for one batch) at step 100: 438.0240, Accuracy: 0.6223\n",
      "Training loss (for one batch) at step 110: 439.1407, Accuracy: 0.6246\n",
      "---- Training ----\n",
      "Training loss: 137.5266\n",
      "Training acc over epoch: 0.6256\n",
      "---- Validation ----\n",
      "Validation loss: 34.8448\n",
      "Validation acc: 0.6548\n",
      "Time taken: 11.32s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 444.7781, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 444.5047, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 20: 438.6181, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 30: 433.3542, Accuracy: 0.6295\n",
      "Training loss (for one batch) at step 40: 438.6926, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 50: 426.7929, Accuracy: 0.6437\n",
      "Training loss (for one batch) at step 60: 436.1789, Accuracy: 0.6450\n",
      "Training loss (for one batch) at step 70: 443.8843, Accuracy: 0.6465\n",
      "Training loss (for one batch) at step 80: 438.6273, Accuracy: 0.6425\n",
      "Training loss (for one batch) at step 90: 441.3311, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 100: 438.4353, Accuracy: 0.6369\n",
      "Training loss (for one batch) at step 110: 440.8376, Accuracy: 0.6372\n",
      "---- Training ----\n",
      "Training loss: 137.1334\n",
      "Training acc over epoch: 0.6384\n",
      "---- Validation ----\n",
      "Validation loss: 34.5156\n",
      "Validation acc: 0.6733\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 442.8017, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 446.9822, Accuracy: 0.6449\n",
      "Training loss (for one batch) at step 20: 438.2223, Accuracy: 0.6414\n",
      "Training loss (for one batch) at step 30: 435.8401, Accuracy: 0.6479\n",
      "Training loss (for one batch) at step 40: 441.7797, Accuracy: 0.6521\n",
      "Training loss (for one batch) at step 50: 436.8333, Accuracy: 0.6550\n",
      "Training loss (for one batch) at step 60: 434.7610, Accuracy: 0.6595\n",
      "Training loss (for one batch) at step 70: 444.3497, Accuracy: 0.6625\n",
      "Training loss (for one batch) at step 80: 441.7104, Accuracy: 0.6573\n",
      "Training loss (for one batch) at step 90: 441.7448, Accuracy: 0.6520\n",
      "Training loss (for one batch) at step 100: 438.1747, Accuracy: 0.6501\n",
      "Training loss (for one batch) at step 110: 443.6983, Accuracy: 0.6510\n",
      "---- Training ----\n",
      "Training loss: 137.6218\n",
      "Training acc over epoch: 0.6515\n",
      "---- Validation ----\n",
      "Validation loss: 34.2958\n",
      "Validation acc: 0.6644\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 443.8527, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 445.6722, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 20: 437.2061, Accuracy: 0.6302\n",
      "Training loss (for one batch) at step 30: 432.4965, Accuracy: 0.6424\n",
      "Training loss (for one batch) at step 40: 432.0341, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 50: 429.5061, Accuracy: 0.6578\n",
      "Training loss (for one batch) at step 60: 430.6279, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 70: 442.9601, Accuracy: 0.6736\n",
      "Training loss (for one batch) at step 80: 444.3560, Accuracy: 0.6652\n",
      "Training loss (for one batch) at step 90: 438.2726, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 100: 438.2695, Accuracy: 0.6621\n",
      "Training loss (for one batch) at step 110: 443.8728, Accuracy: 0.6622\n",
      "---- Training ----\n",
      "Training loss: 135.0958\n",
      "Training acc over epoch: 0.6632\n",
      "---- Validation ----\n",
      "Validation loss: 34.4993\n",
      "Validation acc: 0.6891\n",
      "Time taken: 11.05s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 437.2134, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 441.1866, Accuracy: 0.6705\n",
      "Training loss (for one batch) at step 20: 434.0959, Accuracy: 0.6793\n",
      "Training loss (for one batch) at step 30: 429.5222, Accuracy: 0.6895\n",
      "Training loss (for one batch) at step 40: 431.7621, Accuracy: 0.6987\n",
      "Training loss (for one batch) at step 50: 422.7043, Accuracy: 0.6991\n",
      "Training loss (for one batch) at step 60: 441.0336, Accuracy: 0.7017\n",
      "Training loss (for one batch) at step 70: 443.8884, Accuracy: 0.6987\n",
      "Training loss (for one batch) at step 80: 442.2974, Accuracy: 0.6912\n",
      "Training loss (for one batch) at step 90: 438.3641, Accuracy: 0.6846\n",
      "Training loss (for one batch) at step 100: 435.6714, Accuracy: 0.6866\n",
      "Training loss (for one batch) at step 110: 442.2563, Accuracy: 0.6895\n",
      "---- Training ----\n",
      "Training loss: 138.0976\n",
      "Training acc over epoch: 0.6895\n",
      "---- Validation ----\n",
      "Validation loss: 34.2722\n",
      "Validation acc: 0.7061\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 445.6681, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 441.2934, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 20: 437.1523, Accuracy: 0.6656\n",
      "Training loss (for one batch) at step 30: 425.4685, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 40: 421.4576, Accuracy: 0.7005\n",
      "Training loss (for one batch) at step 50: 423.9924, Accuracy: 0.7070\n",
      "Training loss (for one batch) at step 60: 425.1417, Accuracy: 0.7161\n",
      "Training loss (for one batch) at step 70: 450.2467, Accuracy: 0.7135\n",
      "Training loss (for one batch) at step 80: 444.1571, Accuracy: 0.7011\n",
      "Training loss (for one batch) at step 90: 441.4799, Accuracy: 0.6940\n",
      "Training loss (for one batch) at step 100: 435.7048, Accuracy: 0.6921\n",
      "Training loss (for one batch) at step 110: 435.6551, Accuracy: 0.6945\n",
      "---- Training ----\n",
      "Training loss: 136.2448\n",
      "Training acc over epoch: 0.6956\n",
      "---- Validation ----\n",
      "Validation loss: 36.7260\n",
      "Validation acc: 0.6854\n",
      "Time taken: 10.79s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 445.6702, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 437.8165, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 20: 435.2875, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 431.5422, Accuracy: 0.7084\n",
      "Training loss (for one batch) at step 40: 418.8881, Accuracy: 0.7212\n",
      "Training loss (for one batch) at step 50: 417.9548, Accuracy: 0.7324\n",
      "Training loss (for one batch) at step 60: 439.4427, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 70: 437.7906, Accuracy: 0.7312\n",
      "Training loss (for one batch) at step 80: 444.2831, Accuracy: 0.7206\n",
      "Training loss (for one batch) at step 90: 437.8719, Accuracy: 0.7118\n",
      "Training loss (for one batch) at step 100: 432.7850, Accuracy: 0.7100\n",
      "Training loss (for one batch) at step 110: 438.3029, Accuracy: 0.7097\n",
      "---- Training ----\n",
      "Training loss: 134.9132\n",
      "Training acc over epoch: 0.7100\n",
      "---- Validation ----\n",
      "Validation loss: 35.3304\n",
      "Validation acc: 0.7214\n",
      "Time taken: 17.94s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 438.4807, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 435.6452, Accuracy: 0.7337\n",
      "Training loss (for one batch) at step 20: 430.1588, Accuracy: 0.7236\n",
      "Training loss (for one batch) at step 30: 421.9595, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 40: 422.7751, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 50: 410.3253, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 60: 424.9735, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 70: 436.5646, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 80: 446.6474, Accuracy: 0.7427\n",
      "Training loss (for one batch) at step 90: 435.5190, Accuracy: 0.7332\n",
      "Training loss (for one batch) at step 100: 432.2622, Accuracy: 0.7311\n",
      "Training loss (for one batch) at step 110: 438.2127, Accuracy: 0.7304\n",
      "---- Training ----\n",
      "Training loss: 138.6651\n",
      "Training acc over epoch: 0.7307\n",
      "---- Validation ----\n",
      "Validation loss: 36.5627\n",
      "Validation acc: 0.7241\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 438.5679, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 441.6794, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 20: 432.6094, Accuracy: 0.7113\n",
      "Training loss (for one batch) at step 30: 434.3717, Accuracy: 0.7137\n",
      "Training loss (for one batch) at step 40: 432.7193, Accuracy: 0.7203\n",
      "Training loss (for one batch) at step 50: 405.2202, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 60: 412.9008, Accuracy: 0.7460\n",
      "Training loss (for one batch) at step 70: 440.1622, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 80: 449.3578, Accuracy: 0.7383\n",
      "Training loss (for one batch) at step 90: 429.2943, Accuracy: 0.7309\n",
      "Training loss (for one batch) at step 100: 427.3542, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 110: 436.4642, Accuracy: 0.7309\n",
      "---- Training ----\n",
      "Training loss: 134.5202\n",
      "Training acc over epoch: 0.7297\n",
      "---- Validation ----\n",
      "Validation loss: 35.6779\n",
      "Validation acc: 0.7147\n",
      "Time taken: 10.96s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 448.3198, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 439.7155, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 20: 431.5887, Accuracy: 0.6949\n",
      "Training loss (for one batch) at step 30: 427.4295, Accuracy: 0.7089\n",
      "Training loss (for one batch) at step 40: 420.9981, Accuracy: 0.7252\n",
      "Training loss (for one batch) at step 50: 407.0854, Accuracy: 0.7431\n",
      "Training loss (for one batch) at step 60: 405.8148, Accuracy: 0.7537\n",
      "Training loss (for one batch) at step 70: 437.8398, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 80: 441.7075, Accuracy: 0.7475\n",
      "Training loss (for one batch) at step 90: 436.2717, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 100: 433.0727, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 110: 433.7985, Accuracy: 0.7368\n",
      "---- Training ----\n",
      "Training loss: 137.2116\n",
      "Training acc over epoch: 0.7364\n",
      "---- Validation ----\n",
      "Validation loss: 32.7624\n",
      "Validation acc: 0.7074\n",
      "Time taken: 16.38s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 449.0823, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 440.8874, Accuracy: 0.7301\n",
      "Training loss (for one batch) at step 20: 427.6460, Accuracy: 0.7262\n",
      "Training loss (for one batch) at step 30: 426.1145, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 40: 399.9605, Accuracy: 0.7502\n",
      "Training loss (for one batch) at step 50: 390.1094, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 60: 415.3922, Accuracy: 0.7697\n",
      "Training loss (for one batch) at step 70: 439.0159, Accuracy: 0.7666\n",
      "Training loss (for one batch) at step 80: 438.3963, Accuracy: 0.7555\n",
      "Training loss (for one batch) at step 90: 432.1749, Accuracy: 0.7474\n",
      "Training loss (for one batch) at step 100: 424.0070, Accuracy: 0.7477\n",
      "Training loss (for one batch) at step 110: 438.4742, Accuracy: 0.7481\n",
      "---- Training ----\n",
      "Training loss: 135.9456\n",
      "Training acc over epoch: 0.7488\n",
      "---- Validation ----\n",
      "Validation loss: 34.8236\n",
      "Validation acc: 0.7053\n",
      "Time taken: 15.93s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 438.0578, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 442.3071, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 20: 425.3363, Accuracy: 0.7247\n",
      "Training loss (for one batch) at step 30: 422.1880, Accuracy: 0.7314\n",
      "Training loss (for one batch) at step 40: 395.9580, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 50: 378.4427, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 60: 417.2947, Accuracy: 0.7745\n",
      "Training loss (for one batch) at step 70: 434.3416, Accuracy: 0.7712\n",
      "Training loss (for one batch) at step 80: 442.3734, Accuracy: 0.7620\n",
      "Training loss (for one batch) at step 90: 431.3535, Accuracy: 0.7535\n",
      "Training loss (for one batch) at step 100: 431.0539, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 110: 425.4974, Accuracy: 0.7515\n",
      "---- Training ----\n",
      "Training loss: 138.8483\n",
      "Training acc over epoch: 0.7500\n",
      "---- Validation ----\n",
      "Validation loss: 38.9717\n",
      "Validation acc: 0.6883\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 447.4060, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 437.5614, Accuracy: 0.7280\n",
      "Training loss (for one batch) at step 20: 435.5168, Accuracy: 0.7321\n",
      "Training loss (for one batch) at step 30: 410.4525, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 40: 404.4308, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 50: 389.3136, Accuracy: 0.7725\n",
      "Training loss (for one batch) at step 60: 401.2001, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 70: 433.7671, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 80: 425.2393, Accuracy: 0.7643\n",
      "Training loss (for one batch) at step 90: 432.1255, Accuracy: 0.7541\n",
      "Training loss (for one batch) at step 100: 424.4130, Accuracy: 0.7537\n",
      "Training loss (for one batch) at step 110: 428.3610, Accuracy: 0.7530\n",
      "---- Training ----\n",
      "Training loss: 130.4881\n",
      "Training acc over epoch: 0.7517\n",
      "---- Validation ----\n",
      "Validation loss: 33.0030\n",
      "Validation acc: 0.6929\n",
      "Time taken: 10.74s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 443.7274, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 439.8806, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 433.4831, Accuracy: 0.7191\n",
      "Training loss (for one batch) at step 30: 411.7726, Accuracy: 0.7356\n",
      "Training loss (for one batch) at step 40: 407.1768, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 50: 395.7374, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 60: 397.6930, Accuracy: 0.7773\n",
      "Training loss (for one batch) at step 70: 429.8731, Accuracy: 0.7739\n",
      "Training loss (for one batch) at step 80: 427.5367, Accuracy: 0.7628\n",
      "Training loss (for one batch) at step 90: 425.9002, Accuracy: 0.7558\n",
      "Training loss (for one batch) at step 100: 414.9457, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 110: 415.3511, Accuracy: 0.7544\n",
      "---- Training ----\n",
      "Training loss: 132.5948\n",
      "Training acc over epoch: 0.7537\n",
      "---- Validation ----\n",
      "Validation loss: 36.3846\n",
      "Validation acc: 0.7106\n",
      "Time taken: 11.03s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 441.8096, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 429.9219, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 20: 427.8620, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 30: 420.7408, Accuracy: 0.7402\n",
      "Training loss (for one batch) at step 40: 390.5299, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 50: 383.3310, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 60: 409.8495, Accuracy: 0.7838\n",
      "Training loss (for one batch) at step 70: 436.8406, Accuracy: 0.7765\n",
      "Training loss (for one batch) at step 80: 428.7003, Accuracy: 0.7654\n",
      "Training loss (for one batch) at step 90: 417.3438, Accuracy: 0.7546\n",
      "Training loss (for one batch) at step 100: 422.5596, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 110: 426.2306, Accuracy: 0.7535\n",
      "---- Training ----\n",
      "Training loss: 129.5050\n",
      "Training acc over epoch: 0.7538\n",
      "---- Validation ----\n",
      "Validation loss: 37.5593\n",
      "Validation acc: 0.7190\n",
      "Time taken: 12.36s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 445.2598, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 441.4459, Accuracy: 0.6996\n",
      "Training loss (for one batch) at step 20: 419.8203, Accuracy: 0.7072\n",
      "Training loss (for one batch) at step 30: 402.6467, Accuracy: 0.7281\n",
      "Training loss (for one batch) at step 40: 386.2750, Accuracy: 0.7506\n",
      "Training loss (for one batch) at step 50: 367.3163, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 60: 370.9691, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 70: 419.9286, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 80: 423.2493, Accuracy: 0.7605\n",
      "Training loss (for one batch) at step 90: 426.9107, Accuracy: 0.7526\n",
      "Training loss (for one batch) at step 100: 416.6883, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 110: 420.3624, Accuracy: 0.7555\n",
      "---- Training ----\n",
      "Training loss: 132.1730\n",
      "Training acc over epoch: 0.7560\n",
      "---- Validation ----\n",
      "Validation loss: 36.1389\n",
      "Validation acc: 0.7329\n",
      "Time taken: 14.77s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 431.6621, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 425.8487, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 415.6555, Accuracy: 0.7333\n",
      "Training loss (for one batch) at step 30: 407.3627, Accuracy: 0.7535\n",
      "Training loss (for one batch) at step 40: 394.3295, Accuracy: 0.7687\n",
      "Training loss (for one batch) at step 50: 377.3977, Accuracy: 0.7839\n",
      "Training loss (for one batch) at step 60: 373.3448, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 70: 421.4164, Accuracy: 0.7862\n",
      "Training loss (for one batch) at step 80: 420.0182, Accuracy: 0.7725\n",
      "Training loss (for one batch) at step 90: 420.0699, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 100: 405.0451, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 110: 427.5154, Accuracy: 0.7642\n",
      "---- Training ----\n",
      "Training loss: 132.3785\n",
      "Training acc over epoch: 0.7622\n",
      "---- Validation ----\n",
      "Validation loss: 34.6901\n",
      "Validation acc: 0.7031\n",
      "Time taken: 11.23s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 451.8302, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 433.0627, Accuracy: 0.7074\n",
      "Training loss (for one batch) at step 20: 412.0712, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 30: 403.4962, Accuracy: 0.7434\n",
      "Training loss (for one batch) at step 40: 389.9286, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 50: 380.1014, Accuracy: 0.7756\n",
      "Training loss (for one batch) at step 60: 387.4727, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 70: 419.9887, Accuracy: 0.7810\n",
      "Training loss (for one batch) at step 80: 428.3668, Accuracy: 0.7674\n",
      "Training loss (for one batch) at step 90: 424.8513, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 100: 414.9566, Accuracy: 0.7581\n",
      "Training loss (for one batch) at step 110: 414.3044, Accuracy: 0.7594\n",
      "---- Training ----\n",
      "Training loss: 128.8595\n",
      "Training acc over epoch: 0.7585\n",
      "---- Validation ----\n",
      "Validation loss: 36.6562\n",
      "Validation acc: 0.7152\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 438.3280, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 421.5567, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 20: 408.8839, Accuracy: 0.7374\n",
      "Training loss (for one batch) at step 30: 397.7268, Accuracy: 0.7608\n",
      "Training loss (for one batch) at step 40: 371.8107, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 50: 372.9711, Accuracy: 0.7884\n",
      "Training loss (for one batch) at step 60: 385.4933, Accuracy: 0.7947\n",
      "Training loss (for one batch) at step 70: 391.8000, Accuracy: 0.7883\n",
      "Training loss (for one batch) at step 80: 406.9586, Accuracy: 0.7761\n",
      "Training loss (for one batch) at step 90: 413.7238, Accuracy: 0.7688\n",
      "Training loss (for one batch) at step 100: 411.9395, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 110: 411.6112, Accuracy: 0.7676\n",
      "---- Training ----\n",
      "Training loss: 128.8578\n",
      "Training acc over epoch: 0.7675\n",
      "---- Validation ----\n",
      "Validation loss: 39.3065\n",
      "Validation acc: 0.7214\n",
      "Time taken: 11.96s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 440.1873, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 419.2584, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 20: 407.7451, Accuracy: 0.7277\n",
      "Training loss (for one batch) at step 30: 389.0633, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 40: 345.9179, Accuracy: 0.7712\n",
      "Training loss (for one batch) at step 50: 354.7307, Accuracy: 0.7849\n",
      "Training loss (for one batch) at step 60: 382.6637, Accuracy: 0.7935\n",
      "Training loss (for one batch) at step 70: 414.7982, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 80: 413.8222, Accuracy: 0.7740\n",
      "Training loss (for one batch) at step 90: 416.7604, Accuracy: 0.7679\n",
      "Training loss (for one batch) at step 100: 397.3931, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 110: 426.9441, Accuracy: 0.7663\n",
      "---- Training ----\n",
      "Training loss: 128.5603\n",
      "Training acc over epoch: 0.7662\n",
      "---- Validation ----\n",
      "Validation loss: 35.0891\n",
      "Validation acc: 0.7117\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 421.0482, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 423.4811, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 402.2513, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 30: 385.8128, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 40: 368.3745, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 50: 369.7436, Accuracy: 0.7875\n",
      "Training loss (for one batch) at step 60: 383.2156, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 70: 422.5779, Accuracy: 0.7909\n",
      "Training loss (for one batch) at step 80: 400.0587, Accuracy: 0.7803\n",
      "Training loss (for one batch) at step 90: 415.8077, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 100: 377.7731, Accuracy: 0.7754\n",
      "Training loss (for one batch) at step 110: 413.6821, Accuracy: 0.7746\n",
      "---- Training ----\n",
      "Training loss: 126.2168\n",
      "Training acc over epoch: 0.7728\n",
      "---- Validation ----\n",
      "Validation loss: 34.8483\n",
      "Validation acc: 0.7141\n",
      "Time taken: 15.93s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 421.5844, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 405.9717, Accuracy: 0.6896\n",
      "Training loss (for one batch) at step 20: 396.0665, Accuracy: 0.7158\n",
      "Training loss (for one batch) at step 30: 395.0077, Accuracy: 0.7427\n",
      "Training loss (for one batch) at step 40: 361.7485, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 50: 338.1930, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 60: 379.0245, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 70: 419.2695, Accuracy: 0.7865\n",
      "Training loss (for one batch) at step 80: 392.1982, Accuracy: 0.7736\n",
      "Training loss (for one batch) at step 90: 383.7910, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 100: 385.4427, Accuracy: 0.7707\n",
      "Training loss (for one batch) at step 110: 396.1522, Accuracy: 0.7721\n",
      "---- Training ----\n",
      "Training loss: 132.0401\n",
      "Training acc over epoch: 0.7706\n",
      "---- Validation ----\n",
      "Validation loss: 35.1243\n",
      "Validation acc: 0.7104\n",
      "Time taken: 11.58s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 435.9152, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 422.8407, Accuracy: 0.6911\n",
      "Training loss (for one batch) at step 20: 395.9290, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 30: 361.4838, Accuracy: 0.7465\n",
      "Training loss (for one batch) at step 40: 354.7596, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 50: 367.1342, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 60: 373.7865, Accuracy: 0.7947\n",
      "Training loss (for one batch) at step 70: 398.0801, Accuracy: 0.7903\n",
      "Training loss (for one batch) at step 80: 397.3962, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 90: 391.9901, Accuracy: 0.7712\n",
      "Training loss (for one batch) at step 100: 379.3191, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 110: 376.9024, Accuracy: 0.7736\n",
      "---- Training ----\n",
      "Training loss: 125.8677\n",
      "Training acc over epoch: 0.7727\n",
      "---- Validation ----\n",
      "Validation loss: 40.4057\n",
      "Validation acc: 0.7042\n",
      "Time taken: 12.78s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 417.9499, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 416.6375, Accuracy: 0.6896\n",
      "Training loss (for one batch) at step 20: 394.5193, Accuracy: 0.7013\n",
      "Training loss (for one batch) at step 30: 374.4037, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 40: 360.5655, Accuracy: 0.7586\n",
      "Training loss (for one batch) at step 50: 342.3600, Accuracy: 0.7754\n",
      "Training loss (for one batch) at step 60: 351.2702, Accuracy: 0.7878\n",
      "Training loss (for one batch) at step 70: 409.3083, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 80: 402.3318, Accuracy: 0.7704\n",
      "Training loss (for one batch) at step 90: 396.1715, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 100: 385.7481, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 110: 388.2892, Accuracy: 0.7694\n",
      "---- Training ----\n",
      "Training loss: 126.9857\n",
      "Training acc over epoch: 0.7678\n",
      "---- Validation ----\n",
      "Validation loss: 38.7080\n",
      "Validation acc: 0.7069\n",
      "Time taken: 10.81s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 415.2202, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 407.5665, Accuracy: 0.6761\n",
      "Training loss (for one batch) at step 20: 373.5815, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 30: 375.2279, Accuracy: 0.7402\n",
      "Training loss (for one batch) at step 40: 337.2336, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 50: 341.1032, Accuracy: 0.7829\n",
      "Training loss (for one batch) at step 60: 344.1282, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 70: 384.2662, Accuracy: 0.7862\n",
      "Training loss (for one batch) at step 80: 385.1323, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 90: 381.7648, Accuracy: 0.7686\n",
      "Training loss (for one batch) at step 100: 366.0575, Accuracy: 0.7717\n",
      "Training loss (for one batch) at step 110: 380.1078, Accuracy: 0.7715\n",
      "---- Training ----\n",
      "Training loss: 123.8572\n",
      "Training acc over epoch: 0.7695\n",
      "---- Validation ----\n",
      "Validation loss: 37.7583\n",
      "Validation acc: 0.6991\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 421.2160, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 399.3859, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 20: 385.8003, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 30: 346.5642, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 40: 347.2809, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 50: 323.9806, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 60: 343.3608, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 70: 401.1638, Accuracy: 0.7888\n",
      "Training loss (for one batch) at step 80: 399.5182, Accuracy: 0.7750\n",
      "Training loss (for one batch) at step 90: 393.5470, Accuracy: 0.7703\n",
      "Training loss (for one batch) at step 100: 361.2483, Accuracy: 0.7721\n",
      "Training loss (for one batch) at step 110: 379.9942, Accuracy: 0.7727\n",
      "---- Training ----\n",
      "Training loss: 112.6512\n",
      "Training acc over epoch: 0.7709\n",
      "---- Validation ----\n",
      "Validation loss: 39.0632\n",
      "Validation acc: 0.6905\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 411.7520, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 410.2581, Accuracy: 0.6619\n",
      "Training loss (for one batch) at step 20: 388.8372, Accuracy: 0.6998\n",
      "Training loss (for one batch) at step 30: 353.8897, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 40: 331.1227, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 50: 322.6233, Accuracy: 0.7785\n",
      "Training loss (for one batch) at step 60: 361.5883, Accuracy: 0.7893\n",
      "Training loss (for one batch) at step 70: 400.8362, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 80: 399.6411, Accuracy: 0.7712\n",
      "Training loss (for one batch) at step 90: 369.4434, Accuracy: 0.7659\n",
      "Training loss (for one batch) at step 100: 376.8473, Accuracy: 0.7698\n",
      "Training loss (for one batch) at step 110: 391.6672, Accuracy: 0.7718\n",
      "---- Training ----\n",
      "Training loss: 123.9569\n",
      "Training acc over epoch: 0.7711\n",
      "---- Validation ----\n",
      "Validation loss: 46.5123\n",
      "Validation acc: 0.6937\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 401.0088, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 403.0948, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 20: 389.6641, Accuracy: 0.7154\n",
      "Training loss (for one batch) at step 30: 352.7498, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 40: 321.9547, Accuracy: 0.7700\n",
      "Training loss (for one batch) at step 50: 332.3704, Accuracy: 0.7854\n",
      "Training loss (for one batch) at step 60: 330.4841, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 70: 379.7522, Accuracy: 0.7885\n",
      "Training loss (for one batch) at step 80: 385.1868, Accuracy: 0.7743\n",
      "Training loss (for one batch) at step 90: 357.1953, Accuracy: 0.7709\n",
      "Training loss (for one batch) at step 100: 361.9543, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 110: 357.3511, Accuracy: 0.7750\n",
      "---- Training ----\n",
      "Training loss: 123.3614\n",
      "Training acc over epoch: 0.7730\n",
      "---- Validation ----\n",
      "Validation loss: 40.5065\n",
      "Validation acc: 0.6983\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 395.3142, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 400.7091, Accuracy: 0.6705\n",
      "Training loss (for one batch) at step 20: 369.5339, Accuracy: 0.7080\n",
      "Training loss (for one batch) at step 30: 355.8280, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 40: 334.8867, Accuracy: 0.7647\n",
      "Training loss (for one batch) at step 50: 315.2949, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 60: 346.5624, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 70: 378.0087, Accuracy: 0.7849\n",
      "Training loss (for one batch) at step 80: 383.9700, Accuracy: 0.7702\n",
      "Training loss (for one batch) at step 90: 348.7685, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 100: 362.9443, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 110: 366.9510, Accuracy: 0.7683\n",
      "---- Training ----\n",
      "Training loss: 126.8236\n",
      "Training acc over epoch: 0.7664\n",
      "---- Validation ----\n",
      "Validation loss: 37.1248\n",
      "Validation acc: 0.6953\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 416.9904, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 382.3809, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 20: 363.9051, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 30: 326.3325, Accuracy: 0.7510\n",
      "Training loss (for one batch) at step 40: 334.3871, Accuracy: 0.7725\n",
      "Training loss (for one batch) at step 50: 331.1827, Accuracy: 0.7897\n",
      "Training loss (for one batch) at step 60: 338.3467, Accuracy: 0.7973\n",
      "Training loss (for one batch) at step 70: 361.5759, Accuracy: 0.7846\n",
      "Training loss (for one batch) at step 80: 398.3711, Accuracy: 0.7688\n",
      "Training loss (for one batch) at step 90: 388.3393, Accuracy: 0.7650\n",
      "Training loss (for one batch) at step 100: 346.7154, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 110: 372.7620, Accuracy: 0.7696\n",
      "---- Training ----\n",
      "Training loss: 122.2018\n",
      "Training acc over epoch: 0.7685\n",
      "---- Validation ----\n",
      "Validation loss: 47.0099\n",
      "Validation acc: 0.6865\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 394.8656, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 399.3026, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 20: 363.5687, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 340.3089, Accuracy: 0.7419\n",
      "Training loss (for one batch) at step 40: 330.0032, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 50: 319.1789, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 60: 352.1385, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 70: 357.8868, Accuracy: 0.7826\n",
      "Training loss (for one batch) at step 80: 396.1679, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 90: 350.2064, Accuracy: 0.7679\n",
      "Training loss (for one batch) at step 100: 353.3782, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 110: 370.5445, Accuracy: 0.7703\n",
      "---- Training ----\n",
      "Training loss: 113.9471\n",
      "Training acc over epoch: 0.7685\n",
      "---- Validation ----\n",
      "Validation loss: 42.3757\n",
      "Validation acc: 0.6891\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 402.6805, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 386.5683, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 20: 363.0912, Accuracy: 0.7132\n",
      "Training loss (for one batch) at step 30: 346.6015, Accuracy: 0.7442\n",
      "Training loss (for one batch) at step 40: 313.5156, Accuracy: 0.7658\n",
      "Training loss (for one batch) at step 50: 291.6361, Accuracy: 0.7854\n",
      "Training loss (for one batch) at step 60: 340.9846, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 70: 359.0753, Accuracy: 0.7844\n",
      "Training loss (for one batch) at step 80: 388.8905, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 90: 362.9405, Accuracy: 0.7646\n",
      "Training loss (for one batch) at step 100: 359.7375, Accuracy: 0.7687\n",
      "Training loss (for one batch) at step 110: 358.9996, Accuracy: 0.7684\n",
      "---- Training ----\n",
      "Training loss: 116.0425\n",
      "Training acc over epoch: 0.7666\n",
      "---- Validation ----\n",
      "Validation loss: 42.7111\n",
      "Validation acc: 0.6916\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 377.8638, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 388.6387, Accuracy: 0.6399\n",
      "Training loss (for one batch) at step 20: 361.5764, Accuracy: 0.6886\n",
      "Training loss (for one batch) at step 30: 337.2543, Accuracy: 0.7321\n",
      "Training loss (for one batch) at step 40: 315.5851, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 50: 313.9684, Accuracy: 0.7780\n",
      "Training loss (for one batch) at step 60: 336.1226, Accuracy: 0.7864\n",
      "Training loss (for one batch) at step 70: 344.1111, Accuracy: 0.7771\n",
      "Training loss (for one batch) at step 80: 369.9930, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 90: 361.7455, Accuracy: 0.7586\n",
      "Training loss (for one batch) at step 100: 346.4187, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 110: 346.2914, Accuracy: 0.7627\n",
      "---- Training ----\n",
      "Training loss: 108.7501\n",
      "Training acc over epoch: 0.7608\n",
      "---- Validation ----\n",
      "Validation loss: 46.4059\n",
      "Validation acc: 0.6977\n",
      "Time taken: 10.89s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7109\n",
      "Validation AUC: 0.7109\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 692.3328, Accuracy: 0.4609\n",
      "Training loss (for one batch) at step 10: 592.6229, Accuracy: 0.5107\n",
      "Training loss (for one batch) at step 20: 557.6901, Accuracy: 0.5119\n",
      "Training loss (for one batch) at step 30: 515.9312, Accuracy: 0.5146\n",
      "Training loss (for one batch) at step 40: 514.5300, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 50: 523.0180, Accuracy: 0.5165\n",
      "Training loss (for one batch) at step 60: 503.9198, Accuracy: 0.5163\n",
      "Training loss (for one batch) at step 70: 494.2060, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 80: 490.7760, Accuracy: 0.5194\n",
      "Training loss (for one batch) at step 90: 483.5898, Accuracy: 0.5215\n",
      "Training loss (for one batch) at step 100: 471.4867, Accuracy: 0.5211\n",
      "Training loss (for one batch) at step 110: 475.7660, Accuracy: 0.5222\n",
      "---- Training ----\n",
      "Training loss: 145.9804\n",
      "Training acc over epoch: 0.5208\n",
      "---- Validation ----\n",
      "Validation loss: 34.7388\n",
      "Validation acc: 0.5175\n",
      "Time taken: 12.52s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 466.6444, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 475.0717, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 20: 456.1279, Accuracy: 0.5260\n",
      "Training loss (for one batch) at step 30: 458.9342, Accuracy: 0.5315\n",
      "Training loss (for one batch) at step 40: 455.2592, Accuracy: 0.5263\n",
      "Training loss (for one batch) at step 50: 457.1685, Accuracy: 0.5251\n",
      "Training loss (for one batch) at step 60: 451.0939, Accuracy: 0.5266\n",
      "Training loss (for one batch) at step 70: 455.4778, Accuracy: 0.5290\n",
      "Training loss (for one batch) at step 80: 458.3040, Accuracy: 0.5288\n",
      "Training loss (for one batch) at step 90: 451.3488, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 100: 447.9788, Accuracy: 0.5304\n",
      "Training loss (for one batch) at step 110: 453.1193, Accuracy: 0.5296\n",
      "---- Training ----\n",
      "Training loss: 142.0072\n",
      "Training acc over epoch: 0.5288\n",
      "---- Validation ----\n",
      "Validation loss: 34.3978\n",
      "Validation acc: 0.5121\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 447.7134, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 448.8386, Accuracy: 0.5241\n",
      "Training loss (for one batch) at step 20: 447.0764, Accuracy: 0.5309\n",
      "Training loss (for one batch) at step 30: 451.3923, Accuracy: 0.5320\n",
      "Training loss (for one batch) at step 40: 445.1887, Accuracy: 0.5406\n",
      "Training loss (for one batch) at step 50: 445.8465, Accuracy: 0.5458\n",
      "Training loss (for one batch) at step 60: 447.5443, Accuracy: 0.5446\n",
      "Training loss (for one batch) at step 70: 454.0557, Accuracy: 0.5429\n",
      "Training loss (for one batch) at step 80: 445.3496, Accuracy: 0.5444\n",
      "Training loss (for one batch) at step 90: 447.9108, Accuracy: 0.5464\n",
      "Training loss (for one batch) at step 100: 446.3811, Accuracy: 0.5475\n",
      "Training loss (for one batch) at step 110: 446.3268, Accuracy: 0.5463\n",
      "---- Training ----\n",
      "Training loss: 139.4512\n",
      "Training acc over epoch: 0.5482\n",
      "---- Validation ----\n",
      "Validation loss: 34.1101\n",
      "Validation acc: 0.5202\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.5346, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 446.2010, Accuracy: 0.5426\n",
      "Training loss (for one batch) at step 20: 441.9044, Accuracy: 0.5487\n",
      "Training loss (for one batch) at step 30: 446.6242, Accuracy: 0.5542\n",
      "Training loss (for one batch) at step 40: 444.4970, Accuracy: 0.5646\n",
      "Training loss (for one batch) at step 50: 442.6375, Accuracy: 0.5651\n",
      "Training loss (for one batch) at step 60: 442.8299, Accuracy: 0.5619\n",
      "Training loss (for one batch) at step 70: 449.9101, Accuracy: 0.5665\n",
      "Training loss (for one batch) at step 80: 443.7802, Accuracy: 0.5691\n",
      "Training loss (for one batch) at step 90: 445.5034, Accuracy: 0.5673\n",
      "Training loss (for one batch) at step 100: 443.7740, Accuracy: 0.5690\n",
      "Training loss (for one batch) at step 110: 442.5492, Accuracy: 0.5704\n",
      "---- Training ----\n",
      "Training loss: 141.1110\n",
      "Training acc over epoch: 0.5709\n",
      "---- Validation ----\n",
      "Validation loss: 34.9667\n",
      "Validation acc: 0.5895\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 444.7764, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 445.0295, Accuracy: 0.5554\n",
      "Training loss (for one batch) at step 20: 442.2074, Accuracy: 0.5666\n",
      "Training loss (for one batch) at step 30: 442.7713, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 40: 439.6088, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 50: 442.3289, Accuracy: 0.5915\n",
      "Training loss (for one batch) at step 60: 443.8552, Accuracy: 0.5911\n",
      "Training loss (for one batch) at step 70: 441.6761, Accuracy: 0.5944\n",
      "Training loss (for one batch) at step 80: 444.4342, Accuracy: 0.5955\n",
      "Training loss (for one batch) at step 90: 443.6740, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 100: 443.6286, Accuracy: 0.5931\n",
      "Training loss (for one batch) at step 110: 445.0075, Accuracy: 0.5937\n",
      "---- Training ----\n",
      "Training loss: 139.7723\n",
      "Training acc over epoch: 0.5944\n",
      "---- Validation ----\n",
      "Validation loss: 34.6168\n",
      "Validation acc: 0.6300\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.2271, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 443.2550, Accuracy: 0.6009\n",
      "Training loss (for one batch) at step 20: 441.7053, Accuracy: 0.5949\n",
      "Training loss (for one batch) at step 30: 443.1700, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 40: 440.5984, Accuracy: 0.5873\n",
      "Training loss (for one batch) at step 50: 442.5370, Accuracy: 0.5944\n",
      "Training loss (for one batch) at step 60: 440.5106, Accuracy: 0.5987\n",
      "Training loss (for one batch) at step 70: 441.6458, Accuracy: 0.5998\n",
      "Training loss (for one batch) at step 80: 441.8824, Accuracy: 0.6034\n",
      "Training loss (for one batch) at step 90: 441.6969, Accuracy: 0.5999\n",
      "Training loss (for one batch) at step 100: 440.6781, Accuracy: 0.5988\n",
      "Training loss (for one batch) at step 110: 443.2455, Accuracy: 0.6009\n",
      "---- Training ----\n",
      "Training loss: 138.3859\n",
      "Training acc over epoch: 0.6010\n",
      "---- Validation ----\n",
      "Validation loss: 34.8892\n",
      "Validation acc: 0.6241\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 441.9584, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 445.0478, Accuracy: 0.5831\n",
      "Training loss (for one batch) at step 20: 441.9597, Accuracy: 0.5926\n",
      "Training loss (for one batch) at step 30: 440.3542, Accuracy: 0.5963\n",
      "Training loss (for one batch) at step 40: 438.3909, Accuracy: 0.6018\n",
      "Training loss (for one batch) at step 50: 436.0866, Accuracy: 0.6103\n",
      "Training loss (for one batch) at step 60: 444.3800, Accuracy: 0.6140\n",
      "Training loss (for one batch) at step 70: 443.2393, Accuracy: 0.6204\n",
      "Training loss (for one batch) at step 80: 444.7047, Accuracy: 0.6220\n",
      "Training loss (for one batch) at step 90: 440.4950, Accuracy: 0.6200\n",
      "Training loss (for one batch) at step 100: 436.6685, Accuracy: 0.6189\n",
      "Training loss (for one batch) at step 110: 441.1829, Accuracy: 0.6202\n",
      "---- Training ----\n",
      "Training loss: 138.5705\n",
      "Training acc over epoch: 0.6216\n",
      "---- Validation ----\n",
      "Validation loss: 34.7003\n",
      "Validation acc: 0.6413\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.0820, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 443.7317, Accuracy: 0.6314\n",
      "Training loss (for one batch) at step 20: 444.3564, Accuracy: 0.6116\n",
      "Training loss (for one batch) at step 30: 435.6479, Accuracy: 0.6222\n",
      "Training loss (for one batch) at step 40: 440.6567, Accuracy: 0.6254\n",
      "Training loss (for one batch) at step 50: 437.2301, Accuracy: 0.6374\n",
      "Training loss (for one batch) at step 60: 440.0610, Accuracy: 0.6401\n",
      "Training loss (for one batch) at step 70: 440.3114, Accuracy: 0.6415\n",
      "Training loss (for one batch) at step 80: 445.0471, Accuracy: 0.6420\n",
      "Training loss (for one batch) at step 90: 441.9899, Accuracy: 0.6404\n",
      "Training loss (for one batch) at step 100: 439.2536, Accuracy: 0.6395\n",
      "Training loss (for one batch) at step 110: 444.6159, Accuracy: 0.6412\n",
      "---- Training ----\n",
      "Training loss: 138.1734\n",
      "Training acc over epoch: 0.6433\n",
      "---- Validation ----\n",
      "Validation loss: 34.9898\n",
      "Validation acc: 0.6733\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 441.2258, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 442.8876, Accuracy: 0.6470\n",
      "Training loss (for one batch) at step 20: 441.0930, Accuracy: 0.6302\n",
      "Training loss (for one batch) at step 30: 432.6045, Accuracy: 0.6376\n",
      "Training loss (for one batch) at step 40: 437.4129, Accuracy: 0.6393\n",
      "Training loss (for one batch) at step 50: 441.7394, Accuracy: 0.6494\n",
      "Training loss (for one batch) at step 60: 442.3945, Accuracy: 0.6574\n",
      "Training loss (for one batch) at step 70: 441.1248, Accuracy: 0.6579\n",
      "Training loss (for one batch) at step 80: 445.4063, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 90: 438.3319, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 100: 439.9294, Accuracy: 0.6491\n",
      "Training loss (for one batch) at step 110: 442.7820, Accuracy: 0.6517\n",
      "---- Training ----\n",
      "Training loss: 138.9147\n",
      "Training acc over epoch: 0.6538\n",
      "---- Validation ----\n",
      "Validation loss: 34.2081\n",
      "Validation acc: 0.6663\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 443.5152, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 444.7141, Accuracy: 0.6513\n",
      "Training loss (for one batch) at step 20: 434.6345, Accuracy: 0.6391\n",
      "Training loss (for one batch) at step 30: 436.2387, Accuracy: 0.6447\n",
      "Training loss (for one batch) at step 40: 431.3975, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 50: 433.8599, Accuracy: 0.6589\n",
      "Training loss (for one batch) at step 60: 438.5006, Accuracy: 0.6689\n",
      "Training loss (for one batch) at step 70: 450.1143, Accuracy: 0.6742\n",
      "Training loss (for one batch) at step 80: 442.1103, Accuracy: 0.6713\n",
      "Training loss (for one batch) at step 90: 438.7158, Accuracy: 0.6660\n",
      "Training loss (for one batch) at step 100: 431.3943, Accuracy: 0.6679\n",
      "Training loss (for one batch) at step 110: 435.3657, Accuracy: 0.6700\n",
      "---- Training ----\n",
      "Training loss: 135.3925\n",
      "Training acc over epoch: 0.6705\n",
      "---- Validation ----\n",
      "Validation loss: 35.1884\n",
      "Validation acc: 0.6773\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 443.8766, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 440.6549, Accuracy: 0.6705\n",
      "Training loss (for one batch) at step 20: 433.5688, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 30: 436.1133, Accuracy: 0.6681\n",
      "Training loss (for one batch) at step 40: 432.5894, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 50: 424.6920, Accuracy: 0.6752\n",
      "Training loss (for one batch) at step 60: 437.5737, Accuracy: 0.6806\n",
      "Training loss (for one batch) at step 70: 439.4717, Accuracy: 0.6831\n",
      "Training loss (for one batch) at step 80: 439.5265, Accuracy: 0.6829\n",
      "Training loss (for one batch) at step 90: 432.4398, Accuracy: 0.6784\n",
      "Training loss (for one batch) at step 100: 433.9336, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 110: 440.7871, Accuracy: 0.6818\n",
      "---- Training ----\n",
      "Training loss: 138.2185\n",
      "Training acc over epoch: 0.6830\n",
      "---- Validation ----\n",
      "Validation loss: 34.0152\n",
      "Validation acc: 0.6937\n",
      "Time taken: 12.53s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 440.8954, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 437.0311, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 20: 434.9055, Accuracy: 0.6771\n",
      "Training loss (for one batch) at step 30: 429.8384, Accuracy: 0.6878\n",
      "Training loss (for one batch) at step 40: 418.0809, Accuracy: 0.6976\n",
      "Training loss (for one batch) at step 50: 430.7036, Accuracy: 0.7050\n",
      "Training loss (for one batch) at step 60: 444.1663, Accuracy: 0.7098\n",
      "Training loss (for one batch) at step 70: 444.7682, Accuracy: 0.7084\n",
      "Training loss (for one batch) at step 80: 440.2294, Accuracy: 0.7025\n",
      "Training loss (for one batch) at step 90: 441.1702, Accuracy: 0.6982\n",
      "Training loss (for one batch) at step 100: 439.0318, Accuracy: 0.6989\n",
      "Training loss (for one batch) at step 110: 444.3369, Accuracy: 0.7014\n",
      "---- Training ----\n",
      "Training loss: 134.4895\n",
      "Training acc over epoch: 0.7016\n",
      "---- Validation ----\n",
      "Validation loss: 38.4606\n",
      "Validation acc: 0.7155\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 440.4932, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 440.3255, Accuracy: 0.7145\n",
      "Training loss (for one batch) at step 20: 434.3020, Accuracy: 0.6949\n",
      "Training loss (for one batch) at step 30: 427.4297, Accuracy: 0.7044\n",
      "Training loss (for one batch) at step 40: 422.6768, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 50: 430.3653, Accuracy: 0.7250\n",
      "Training loss (for one batch) at step 60: 429.1811, Accuracy: 0.7305\n",
      "Training loss (for one batch) at step 70: 441.0962, Accuracy: 0.7303\n",
      "Training loss (for one batch) at step 80: 446.3179, Accuracy: 0.7211\n",
      "Training loss (for one batch) at step 90: 443.7123, Accuracy: 0.7149\n",
      "Training loss (for one batch) at step 100: 434.9619, Accuracy: 0.7147\n",
      "Training loss (for one batch) at step 110: 432.7883, Accuracy: 0.7161\n",
      "---- Training ----\n",
      "Training loss: 135.3421\n",
      "Training acc over epoch: 0.7158\n",
      "---- Validation ----\n",
      "Validation loss: 33.7260\n",
      "Validation acc: 0.7144\n",
      "Time taken: 10.81s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 443.2415, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 438.4252, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 20: 435.4008, Accuracy: 0.6827\n",
      "Training loss (for one batch) at step 30: 416.4066, Accuracy: 0.7014\n",
      "Training loss (for one batch) at step 40: 423.6305, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 50: 422.0073, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 60: 424.9243, Accuracy: 0.7253\n",
      "Training loss (for one batch) at step 70: 442.8739, Accuracy: 0.7271\n",
      "Training loss (for one batch) at step 80: 439.0823, Accuracy: 0.7224\n",
      "Training loss (for one batch) at step 90: 437.3429, Accuracy: 0.7167\n",
      "Training loss (for one batch) at step 100: 429.9640, Accuracy: 0.7181\n",
      "Training loss (for one batch) at step 110: 434.3905, Accuracy: 0.7169\n",
      "---- Training ----\n",
      "Training loss: 133.4912\n",
      "Training acc over epoch: 0.7170\n",
      "---- Validation ----\n",
      "Validation loss: 35.7117\n",
      "Validation acc: 0.6969\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 443.7077, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 437.0636, Accuracy: 0.7053\n",
      "Training loss (for one batch) at step 20: 433.2321, Accuracy: 0.7121\n",
      "Training loss (for one batch) at step 30: 430.2614, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 40: 417.9187, Accuracy: 0.7336\n",
      "Training loss (for one batch) at step 50: 428.2230, Accuracy: 0.7451\n",
      "Training loss (for one batch) at step 60: 437.4090, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 70: 441.3351, Accuracy: 0.7477\n",
      "Training loss (for one batch) at step 80: 443.4008, Accuracy: 0.7376\n",
      "Training loss (for one batch) at step 90: 431.9334, Accuracy: 0.7331\n",
      "Training loss (for one batch) at step 100: 428.5115, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 110: 435.6431, Accuracy: 0.7337\n",
      "---- Training ----\n",
      "Training loss: 136.3645\n",
      "Training acc over epoch: 0.7326\n",
      "---- Validation ----\n",
      "Validation loss: 33.3332\n",
      "Validation acc: 0.7037\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 441.3216, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 432.9950, Accuracy: 0.7244\n",
      "Training loss (for one batch) at step 20: 439.6461, Accuracy: 0.7039\n",
      "Training loss (for one batch) at step 30: 429.7086, Accuracy: 0.7155\n",
      "Training loss (for one batch) at step 40: 416.3550, Accuracy: 0.7264\n",
      "Training loss (for one batch) at step 50: 423.9598, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 60: 424.7636, Accuracy: 0.7441\n",
      "Training loss (for one batch) at step 70: 433.9419, Accuracy: 0.7438\n",
      "Training loss (for one batch) at step 80: 435.0202, Accuracy: 0.7405\n",
      "Training loss (for one batch) at step 90: 435.7957, Accuracy: 0.7359\n",
      "Training loss (for one batch) at step 100: 431.3843, Accuracy: 0.7362\n",
      "Training loss (for one batch) at step 110: 428.7049, Accuracy: 0.7371\n",
      "---- Training ----\n",
      "Training loss: 132.3455\n",
      "Training acc over epoch: 0.7370\n",
      "---- Validation ----\n",
      "Validation loss: 39.0472\n",
      "Validation acc: 0.7112\n",
      "Time taken: 10.79s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 442.6723, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 435.8038, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 20: 431.8639, Accuracy: 0.7143\n",
      "Training loss (for one batch) at step 30: 424.4576, Accuracy: 0.7253\n",
      "Training loss (for one batch) at step 40: 418.1275, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 50: 406.1874, Accuracy: 0.7477\n",
      "Training loss (for one batch) at step 60: 416.8372, Accuracy: 0.7546\n",
      "Training loss (for one batch) at step 70: 423.6835, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 80: 436.6841, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 90: 435.6421, Accuracy: 0.7421\n",
      "Training loss (for one batch) at step 100: 426.1441, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 110: 433.2916, Accuracy: 0.7394\n",
      "---- Training ----\n",
      "Training loss: 135.3620\n",
      "Training acc over epoch: 0.7381\n",
      "---- Validation ----\n",
      "Validation loss: 34.9862\n",
      "Validation acc: 0.6650\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 435.4596, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 433.4570, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 20: 434.2187, Accuracy: 0.7057\n",
      "Training loss (for one batch) at step 30: 421.8009, Accuracy: 0.7253\n",
      "Training loss (for one batch) at step 40: 422.5175, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 50: 392.7831, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 60: 411.8689, Accuracy: 0.7610\n",
      "Training loss (for one batch) at step 70: 440.5590, Accuracy: 0.7642\n",
      "Training loss (for one batch) at step 80: 443.8078, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 90: 433.7946, Accuracy: 0.7478\n",
      "Training loss (for one batch) at step 100: 428.7489, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 110: 423.9814, Accuracy: 0.7444\n",
      "---- Training ----\n",
      "Training loss: 136.0290\n",
      "Training acc over epoch: 0.7434\n",
      "---- Validation ----\n",
      "Validation loss: 41.2373\n",
      "Validation acc: 0.7260\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 429.0292, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 437.1329, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 20: 432.4673, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 30: 412.1296, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 40: 413.3063, Accuracy: 0.7475\n",
      "Training loss (for one batch) at step 50: 396.4350, Accuracy: 0.7616\n",
      "Training loss (for one batch) at step 60: 431.0848, Accuracy: 0.7683\n",
      "Training loss (for one batch) at step 70: 422.2372, Accuracy: 0.7688\n",
      "Training loss (for one batch) at step 80: 434.8479, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 90: 431.1548, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 100: 423.5531, Accuracy: 0.7571\n",
      "Training loss (for one batch) at step 110: 424.0679, Accuracy: 0.7561\n",
      "---- Training ----\n",
      "Training loss: 132.6224\n",
      "Training acc over epoch: 0.7550\n",
      "---- Validation ----\n",
      "Validation loss: 36.4598\n",
      "Validation acc: 0.7144\n",
      "Time taken: 10.94s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 442.5074, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 445.3687, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 428.1404, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 30: 416.3601, Accuracy: 0.7356\n",
      "Training loss (for one batch) at step 40: 409.6755, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 50: 385.1988, Accuracy: 0.7646\n",
      "Training loss (for one batch) at step 60: 417.3484, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 70: 428.9951, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 80: 434.8478, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 90: 418.7172, Accuracy: 0.7564\n",
      "Training loss (for one batch) at step 100: 424.8526, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 110: 426.0930, Accuracy: 0.7559\n",
      "---- Training ----\n",
      "Training loss: 135.7591\n",
      "Training acc over epoch: 0.7558\n",
      "---- Validation ----\n",
      "Validation loss: 31.9737\n",
      "Validation acc: 0.7082\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 437.3357, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 439.3024, Accuracy: 0.7251\n",
      "Training loss (for one batch) at step 20: 426.3905, Accuracy: 0.7295\n",
      "Training loss (for one batch) at step 30: 414.1566, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 40: 408.8722, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 50: 376.4549, Accuracy: 0.7679\n",
      "Training loss (for one batch) at step 60: 400.9646, Accuracy: 0.7780\n",
      "Training loss (for one batch) at step 70: 424.6870, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 80: 425.5247, Accuracy: 0.7668\n",
      "Training loss (for one batch) at step 90: 432.4095, Accuracy: 0.7616\n",
      "Training loss (for one batch) at step 100: 415.9540, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 110: 418.8559, Accuracy: 0.7601\n",
      "---- Training ----\n",
      "Training loss: 136.2161\n",
      "Training acc over epoch: 0.7601\n",
      "---- Validation ----\n",
      "Validation loss: 31.6745\n",
      "Validation acc: 0.7262\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 440.4328, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 428.3207, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 20: 418.4182, Accuracy: 0.7414\n",
      "Training loss (for one batch) at step 30: 413.9628, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 40: 399.0640, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 50: 378.9069, Accuracy: 0.7806\n",
      "Training loss (for one batch) at step 60: 411.9787, Accuracy: 0.7912\n",
      "Training loss (for one batch) at step 70: 430.1304, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 80: 422.0106, Accuracy: 0.7786\n",
      "Training loss (for one batch) at step 90: 415.3015, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 100: 408.3094, Accuracy: 0.7718\n",
      "Training loss (for one batch) at step 110: 427.1853, Accuracy: 0.7722\n",
      "---- Training ----\n",
      "Training loss: 138.4302\n",
      "Training acc over epoch: 0.7732\n",
      "---- Validation ----\n",
      "Validation loss: 37.4740\n",
      "Validation acc: 0.7249\n",
      "Time taken: 10.94s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 438.2897, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 421.4024, Accuracy: 0.7401\n",
      "Training loss (for one batch) at step 20: 419.8058, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 30: 414.6909, Accuracy: 0.7508\n",
      "Training loss (for one batch) at step 40: 386.2106, Accuracy: 0.7668\n",
      "Training loss (for one batch) at step 50: 387.0479, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 60: 398.0352, Accuracy: 0.7892\n",
      "Training loss (for one batch) at step 70: 429.6118, Accuracy: 0.7874\n",
      "Training loss (for one batch) at step 80: 432.9370, Accuracy: 0.7788\n",
      "Training loss (for one batch) at step 90: 410.2158, Accuracy: 0.7735\n",
      "Training loss (for one batch) at step 100: 411.3143, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 110: 413.4211, Accuracy: 0.7733\n",
      "---- Training ----\n",
      "Training loss: 124.3763\n",
      "Training acc over epoch: 0.7725\n",
      "---- Validation ----\n",
      "Validation loss: 35.4184\n",
      "Validation acc: 0.7268\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 437.3611, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 419.9536, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 417.0065, Accuracy: 0.7511\n",
      "Training loss (for one batch) at step 30: 409.3685, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 40: 391.5232, Accuracy: 0.7752\n",
      "Training loss (for one batch) at step 50: 348.9455, Accuracy: 0.7892\n",
      "Training loss (for one batch) at step 60: 404.3263, Accuracy: 0.7970\n",
      "Training loss (for one batch) at step 70: 410.4750, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 80: 440.7592, Accuracy: 0.7852\n",
      "Training loss (for one batch) at step 90: 410.7990, Accuracy: 0.7778\n",
      "Training loss (for one batch) at step 100: 412.4054, Accuracy: 0.7771\n",
      "Training loss (for one batch) at step 110: 413.0313, Accuracy: 0.7755\n",
      "---- Training ----\n",
      "Training loss: 124.5848\n",
      "Training acc over epoch: 0.7742\n",
      "---- Validation ----\n",
      "Validation loss: 36.0144\n",
      "Validation acc: 0.7270\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 439.5424, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 422.1448, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 407.3755, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 30: 395.6218, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 40: 403.4379, Accuracy: 0.7772\n",
      "Training loss (for one batch) at step 50: 383.4385, Accuracy: 0.7914\n",
      "Training loss (for one batch) at step 60: 374.9060, Accuracy: 0.7983\n",
      "Training loss (for one batch) at step 70: 417.1527, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 80: 414.6536, Accuracy: 0.7867\n",
      "Training loss (for one batch) at step 90: 405.7877, Accuracy: 0.7829\n",
      "Training loss (for one batch) at step 100: 410.4370, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 110: 422.5476, Accuracy: 0.7805\n",
      "---- Training ----\n",
      "Training loss: 128.4648\n",
      "Training acc over epoch: 0.7792\n",
      "---- Validation ----\n",
      "Validation loss: 35.8224\n",
      "Validation acc: 0.7047\n",
      "Time taken: 10.79s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 419.8072, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 418.8845, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 20: 410.0105, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 30: 405.8954, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 40: 362.3386, Accuracy: 0.7666\n",
      "Training loss (for one batch) at step 50: 356.7645, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 60: 409.2021, Accuracy: 0.7973\n",
      "Training loss (for one batch) at step 70: 419.5996, Accuracy: 0.7927\n",
      "Training loss (for one batch) at step 80: 437.2311, Accuracy: 0.7814\n",
      "Training loss (for one batch) at step 90: 409.4642, Accuracy: 0.7728\n",
      "Training loss (for one batch) at step 100: 402.9522, Accuracy: 0.7713\n",
      "Training loss (for one batch) at step 110: 416.5364, Accuracy: 0.7726\n",
      "---- Training ----\n",
      "Training loss: 135.4223\n",
      "Training acc over epoch: 0.7718\n",
      "---- Validation ----\n",
      "Validation loss: 37.0905\n",
      "Validation acc: 0.6883\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 433.8768, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 421.9839, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 20: 405.3517, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 30: 381.6493, Accuracy: 0.7634\n",
      "Training loss (for one batch) at step 40: 378.2807, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 50: 361.7820, Accuracy: 0.7927\n",
      "Training loss (for one batch) at step 60: 376.2006, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 70: 413.1870, Accuracy: 0.7979\n",
      "Training loss (for one batch) at step 80: 423.0612, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 90: 405.6017, Accuracy: 0.7819\n",
      "Training loss (for one batch) at step 100: 395.3863, Accuracy: 0.7809\n",
      "Training loss (for one batch) at step 110: 402.5171, Accuracy: 0.7793\n",
      "---- Training ----\n",
      "Training loss: 131.9323\n",
      "Training acc over epoch: 0.7772\n",
      "---- Validation ----\n",
      "Validation loss: 35.5778\n",
      "Validation acc: 0.7332\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 437.6581, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 424.4677, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 404.0846, Accuracy: 0.7615\n",
      "Training loss (for one batch) at step 30: 394.0666, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 40: 362.6115, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 50: 352.4835, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 60: 365.0535, Accuracy: 0.8160\n",
      "Training loss (for one batch) at step 70: 385.6844, Accuracy: 0.8097\n",
      "Training loss (for one batch) at step 80: 420.2133, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 90: 420.2203, Accuracy: 0.7940\n",
      "Training loss (for one batch) at step 100: 400.6817, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 110: 398.8232, Accuracy: 0.7891\n",
      "---- Training ----\n",
      "Training loss: 121.5919\n",
      "Training acc over epoch: 0.7872\n",
      "---- Validation ----\n",
      "Validation loss: 31.5585\n",
      "Validation acc: 0.7171\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 431.9474, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 428.6190, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 20: 394.3724, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 30: 372.3283, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 40: 364.7356, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 50: 337.9944, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 60: 387.2552, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 70: 414.4013, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 80: 407.9551, Accuracy: 0.7993\n",
      "Training loss (for one batch) at step 90: 388.0307, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 100: 390.1962, Accuracy: 0.7893\n",
      "Training loss (for one batch) at step 110: 396.1894, Accuracy: 0.7889\n",
      "---- Training ----\n",
      "Training loss: 124.8328\n",
      "Training acc over epoch: 0.7882\n",
      "---- Validation ----\n",
      "Validation loss: 39.2388\n",
      "Validation acc: 0.7166\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 443.9831, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 409.8454, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 381.0699, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 30: 374.5869, Accuracy: 0.7634\n",
      "Training loss (for one batch) at step 40: 369.1866, Accuracy: 0.7837\n",
      "Training loss (for one batch) at step 50: 332.5240, Accuracy: 0.7989\n",
      "Training loss (for one batch) at step 60: 353.6479, Accuracy: 0.8062\n",
      "Training loss (for one batch) at step 70: 389.1293, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 80: 396.5320, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 90: 394.0148, Accuracy: 0.7897\n",
      "Training loss (for one batch) at step 100: 399.9294, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 110: 389.4889, Accuracy: 0.7875\n",
      "---- Training ----\n",
      "Training loss: 127.6478\n",
      "Training acc over epoch: 0.7859\n",
      "---- Validation ----\n",
      "Validation loss: 34.7989\n",
      "Validation acc: 0.7117\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 408.1522, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 406.6933, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 389.4890, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 30: 388.4637, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 40: 372.1530, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 50: 336.0166, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 60: 352.9546, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 70: 383.2787, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 80: 426.2741, Accuracy: 0.7992\n",
      "Training loss (for one batch) at step 90: 383.4622, Accuracy: 0.7938\n",
      "Training loss (for one batch) at step 100: 382.3423, Accuracy: 0.7927\n",
      "Training loss (for one batch) at step 110: 375.7574, Accuracy: 0.7913\n",
      "---- Training ----\n",
      "Training loss: 125.0625\n",
      "Training acc over epoch: 0.7907\n",
      "---- Validation ----\n",
      "Validation loss: 38.4665\n",
      "Validation acc: 0.7055\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 411.8847, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 396.8606, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 20: 391.9912, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 30: 365.3215, Accuracy: 0.7598\n",
      "Training loss (for one batch) at step 40: 338.6503, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 50: 342.3348, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 60: 354.2521, Accuracy: 0.8103\n",
      "Training loss (for one batch) at step 70: 400.3311, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 80: 404.9892, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 90: 390.0019, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 100: 383.5936, Accuracy: 0.7899\n",
      "Training loss (for one batch) at step 110: 392.0356, Accuracy: 0.7900\n",
      "---- Training ----\n",
      "Training loss: 124.5899\n",
      "Training acc over epoch: 0.7886\n",
      "---- Validation ----\n",
      "Validation loss: 40.0001\n",
      "Validation acc: 0.7028\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 413.9631, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 405.4827, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 387.2868, Accuracy: 0.7459\n",
      "Training loss (for one batch) at step 30: 354.4301, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 40: 348.0403, Accuracy: 0.7906\n",
      "Training loss (for one batch) at step 50: 339.0326, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 60: 356.2677, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 70: 386.3665, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 80: 400.9327, Accuracy: 0.7968\n",
      "Training loss (for one batch) at step 90: 382.7049, Accuracy: 0.7909\n",
      "Training loss (for one batch) at step 100: 380.4409, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 110: 386.9320, Accuracy: 0.7910\n",
      "---- Training ----\n",
      "Training loss: 118.4192\n",
      "Training acc over epoch: 0.7891\n",
      "---- Validation ----\n",
      "Validation loss: 46.5382\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 409.2830, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 407.7095, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 20: 376.6819, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 30: 355.3876, Accuracy: 0.7674\n",
      "Training loss (for one batch) at step 40: 349.6709, Accuracy: 0.7875\n",
      "Training loss (for one batch) at step 50: 334.8932, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 60: 357.5853, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 70: 381.7075, Accuracy: 0.8078\n",
      "Training loss (for one batch) at step 80: 415.2934, Accuracy: 0.7965\n",
      "Training loss (for one batch) at step 90: 383.9626, Accuracy: 0.7907\n",
      "Training loss (for one batch) at step 100: 357.8392, Accuracy: 0.7935\n",
      "Training loss (for one batch) at step 110: 385.3020, Accuracy: 0.7921\n",
      "---- Training ----\n",
      "Training loss: 126.9477\n",
      "Training acc over epoch: 0.7910\n",
      "---- Validation ----\n",
      "Validation loss: 32.3821\n",
      "Validation acc: 0.7155\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 419.2576, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 382.8777, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 20: 366.4804, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 30: 339.3878, Accuracy: 0.7765\n",
      "Training loss (for one batch) at step 40: 334.3947, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 50: 330.3783, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 60: 363.5416, Accuracy: 0.8171\n",
      "Training loss (for one batch) at step 70: 382.7794, Accuracy: 0.8103\n",
      "Training loss (for one batch) at step 80: 381.9798, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 90: 367.4164, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 100: 379.8687, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 110: 380.1122, Accuracy: 0.7936\n",
      "---- Training ----\n",
      "Training loss: 115.9255\n",
      "Training acc over epoch: 0.7931\n",
      "---- Validation ----\n",
      "Validation loss: 38.4679\n",
      "Validation acc: 0.7112\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 410.2753, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 389.7931, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 20: 377.5142, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 30: 366.6384, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 40: 337.0401, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 50: 309.9903, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 60: 353.3470, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 70: 364.4896, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 80: 375.6818, Accuracy: 0.8008\n",
      "Training loss (for one batch) at step 90: 364.4336, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 100: 372.0485, Accuracy: 0.7959\n",
      "Training loss (for one batch) at step 110: 378.7832, Accuracy: 0.7943\n",
      "---- Training ----\n",
      "Training loss: 119.5551\n",
      "Training acc over epoch: 0.7931\n",
      "---- Validation ----\n",
      "Validation loss: 49.0423\n",
      "Validation acc: 0.7106\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 397.5488, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 394.3883, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 356.7415, Accuracy: 0.7571\n",
      "Training loss (for one batch) at step 30: 335.4659, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 40: 341.7085, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 50: 328.0933, Accuracy: 0.8172\n",
      "Training loss (for one batch) at step 60: 326.6657, Accuracy: 0.8256\n",
      "Training loss (for one batch) at step 70: 387.1322, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 80: 402.4720, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 90: 366.1719, Accuracy: 0.7995\n",
      "Training loss (for one batch) at step 100: 372.6773, Accuracy: 0.7992\n",
      "Training loss (for one batch) at step 110: 380.7167, Accuracy: 0.7988\n",
      "---- Training ----\n",
      "Training loss: 109.7091\n",
      "Training acc over epoch: 0.7972\n",
      "---- Validation ----\n",
      "Validation loss: 46.0994\n",
      "Validation acc: 0.7149\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 403.5094, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 388.9380, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 20: 367.0984, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 30: 330.2946, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 40: 322.8096, Accuracy: 0.7954\n",
      "Training loss (for one batch) at step 50: 302.2251, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 60: 329.4431, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 70: 391.6878, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 80: 377.0792, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 90: 371.4916, Accuracy: 0.7971\n",
      "Training loss (for one batch) at step 100: 369.3126, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 110: 361.6271, Accuracy: 0.7946\n",
      "---- Training ----\n",
      "Training loss: 126.5482\n",
      "Training acc over epoch: 0.7946\n",
      "---- Validation ----\n",
      "Validation loss: 41.7084\n",
      "Validation acc: 0.7120\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 406.8110, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 388.1335, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 20: 355.2832, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 339.6548, Accuracy: 0.7777\n",
      "Training loss (for one batch) at step 40: 340.8667, Accuracy: 0.7980\n",
      "Training loss (for one batch) at step 50: 328.3268, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 60: 361.0278, Accuracy: 0.8231\n",
      "Training loss (for one batch) at step 70: 373.8268, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 80: 366.7266, Accuracy: 0.7988\n",
      "Training loss (for one batch) at step 90: 380.7564, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 100: 355.9223, Accuracy: 0.7977\n",
      "Training loss (for one batch) at step 110: 368.9277, Accuracy: 0.7966\n",
      "---- Training ----\n",
      "Training loss: 104.8922\n",
      "Training acc over epoch: 0.7971\n",
      "---- Validation ----\n",
      "Validation loss: 46.1958\n",
      "Validation acc: 0.6910\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 383.2743, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 378.6840, Accuracy: 0.7060\n",
      "Training loss (for one batch) at step 20: 379.6017, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 30: 347.5965, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 40: 328.1163, Accuracy: 0.7957\n",
      "Training loss (for one batch) at step 50: 304.6185, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 60: 318.8397, Accuracy: 0.8197\n",
      "Training loss (for one batch) at step 70: 351.5680, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 80: 351.9195, Accuracy: 0.8002\n",
      "Training loss (for one batch) at step 90: 350.8292, Accuracy: 0.7964\n",
      "Training loss (for one batch) at step 100: 358.8259, Accuracy: 0.7976\n",
      "Training loss (for one batch) at step 110: 351.6603, Accuracy: 0.7972\n",
      "---- Training ----\n",
      "Training loss: 113.9372\n",
      "Training acc over epoch: 0.7957\n",
      "---- Validation ----\n",
      "Validation loss: 49.2100\n",
      "Validation acc: 0.7023\n",
      "Time taken: 10.60s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6939\n",
      "Validation AUC: 0.6948\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 614.4424, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 573.4257, Accuracy: 0.4950\n",
      "Training loss (for one batch) at step 20: 544.5297, Accuracy: 0.5041\n",
      "Training loss (for one batch) at step 30: 515.4956, Accuracy: 0.5045\n",
      "Training loss (for one batch) at step 40: 502.5837, Accuracy: 0.5011\n",
      "Training loss (for one batch) at step 50: 499.6024, Accuracy: 0.5089\n",
      "Training loss (for one batch) at step 60: 486.5208, Accuracy: 0.5097\n",
      "Training loss (for one batch) at step 70: 492.9364, Accuracy: 0.5106\n",
      "Training loss (for one batch) at step 80: 488.1162, Accuracy: 0.5147\n",
      "Training loss (for one batch) at step 90: 462.5721, Accuracy: 0.5157\n",
      "Training loss (for one batch) at step 100: 459.2767, Accuracy: 0.5165\n",
      "Training loss (for one batch) at step 110: 466.0947, Accuracy: 0.5174\n",
      "---- Training ----\n",
      "Training loss: 140.0311\n",
      "Training acc over epoch: 0.5179\n",
      "---- Validation ----\n",
      "Validation loss: 34.6263\n",
      "Validation acc: 0.4745\n",
      "Time taken: 12.63s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 454.7503, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 471.5258, Accuracy: 0.5263\n",
      "Training loss (for one batch) at step 20: 459.6754, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 30: 454.9411, Accuracy: 0.5272\n",
      "Training loss (for one batch) at step 40: 448.8008, Accuracy: 0.5267\n",
      "Training loss (for one batch) at step 50: 455.6448, Accuracy: 0.5297\n",
      "Training loss (for one batch) at step 60: 447.3376, Accuracy: 0.5304\n",
      "Training loss (for one batch) at step 70: 450.9501, Accuracy: 0.5351\n",
      "Training loss (for one batch) at step 80: 449.6305, Accuracy: 0.5383\n",
      "Training loss (for one batch) at step 90: 451.2389, Accuracy: 0.5371\n",
      "Training loss (for one batch) at step 100: 450.7656, Accuracy: 0.5362\n",
      "Training loss (for one batch) at step 110: 447.1181, Accuracy: 0.5353\n",
      "---- Training ----\n",
      "Training loss: 139.1144\n",
      "Training acc over epoch: 0.5344\n",
      "---- Validation ----\n",
      "Validation loss: 34.6218\n",
      "Validation acc: 0.5024\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 447.9759, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 448.6810, Accuracy: 0.5327\n",
      "Training loss (for one batch) at step 20: 443.1843, Accuracy: 0.5446\n",
      "Training loss (for one batch) at step 30: 442.4222, Accuracy: 0.5459\n",
      "Training loss (for one batch) at step 40: 443.0539, Accuracy: 0.5455\n",
      "Training loss (for one batch) at step 50: 449.8792, Accuracy: 0.5447\n",
      "Training loss (for one batch) at step 60: 445.7209, Accuracy: 0.5470\n",
      "Training loss (for one batch) at step 70: 447.4183, Accuracy: 0.5542\n",
      "Training loss (for one batch) at step 80: 444.1315, Accuracy: 0.5583\n",
      "Training loss (for one batch) at step 90: 443.9955, Accuracy: 0.5561\n",
      "Training loss (for one batch) at step 100: 446.0532, Accuracy: 0.5514\n",
      "Training loss (for one batch) at step 110: 443.6198, Accuracy: 0.5499\n",
      "---- Training ----\n",
      "Training loss: 140.9596\n",
      "Training acc over epoch: 0.5518\n",
      "---- Validation ----\n",
      "Validation loss: 34.6613\n",
      "Validation acc: 0.5352\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.9750, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 443.6568, Accuracy: 0.5554\n",
      "Training loss (for one batch) at step 20: 442.1938, Accuracy: 0.5666\n",
      "Training loss (for one batch) at step 30: 443.0811, Accuracy: 0.5698\n",
      "Training loss (for one batch) at step 40: 443.9186, Accuracy: 0.5711\n",
      "Training loss (for one batch) at step 50: 441.1105, Accuracy: 0.5797\n",
      "Training loss (for one batch) at step 60: 440.3170, Accuracy: 0.5771\n",
      "Training loss (for one batch) at step 70: 442.8865, Accuracy: 0.5813\n",
      "Training loss (for one batch) at step 80: 443.9726, Accuracy: 0.5828\n",
      "Training loss (for one batch) at step 90: 442.1442, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 100: 443.6998, Accuracy: 0.5774\n",
      "Training loss (for one batch) at step 110: 442.4591, Accuracy: 0.5774\n",
      "---- Training ----\n",
      "Training loss: 139.0678\n",
      "Training acc over epoch: 0.5754\n",
      "---- Validation ----\n",
      "Validation loss: 34.5353\n",
      "Validation acc: 0.5935\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 443.2771, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 445.4322, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 20: 441.1285, Accuracy: 0.5640\n",
      "Training loss (for one batch) at step 30: 441.8714, Accuracy: 0.5680\n",
      "Training loss (for one batch) at step 40: 442.6117, Accuracy: 0.5676\n",
      "Training loss (for one batch) at step 50: 440.3516, Accuracy: 0.5714\n",
      "Training loss (for one batch) at step 60: 441.2955, Accuracy: 0.5762\n",
      "Training loss (for one batch) at step 70: 441.8542, Accuracy: 0.5787\n",
      "Training loss (for one batch) at step 80: 445.1678, Accuracy: 0.5806\n",
      "Training loss (for one batch) at step 90: 443.6441, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 100: 442.3963, Accuracy: 0.5745\n",
      "Training loss (for one batch) at step 110: 446.7164, Accuracy: 0.5745\n",
      "---- Training ----\n",
      "Training loss: 139.0063\n",
      "Training acc over epoch: 0.5759\n",
      "---- Validation ----\n",
      "Validation loss: 35.5815\n",
      "Validation acc: 0.6034\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 439.8050, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 444.8028, Accuracy: 0.6222\n",
      "Training loss (for one batch) at step 20: 439.8922, Accuracy: 0.5964\n",
      "Training loss (for one batch) at step 30: 441.8141, Accuracy: 0.5993\n",
      "Training loss (for one batch) at step 40: 442.6689, Accuracy: 0.6027\n",
      "Training loss (for one batch) at step 50: 444.1345, Accuracy: 0.6052\n",
      "Training loss (for one batch) at step 60: 441.2864, Accuracy: 0.6059\n",
      "Training loss (for one batch) at step 70: 442.6536, Accuracy: 0.6074\n",
      "Training loss (for one batch) at step 80: 443.3091, Accuracy: 0.6114\n",
      "Training loss (for one batch) at step 90: 441.9636, Accuracy: 0.6099\n",
      "Training loss (for one batch) at step 100: 443.2858, Accuracy: 0.6067\n",
      "Training loss (for one batch) at step 110: 445.4154, Accuracy: 0.6046\n",
      "---- Training ----\n",
      "Training loss: 138.9017\n",
      "Training acc over epoch: 0.6044\n",
      "---- Validation ----\n",
      "Validation loss: 34.3291\n",
      "Validation acc: 0.6206\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 441.2746, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 443.0270, Accuracy: 0.6158\n",
      "Training loss (for one batch) at step 20: 440.3967, Accuracy: 0.6150\n",
      "Training loss (for one batch) at step 30: 439.4003, Accuracy: 0.6242\n",
      "Training loss (for one batch) at step 40: 437.9586, Accuracy: 0.6212\n",
      "Training loss (for one batch) at step 50: 438.3607, Accuracy: 0.6189\n",
      "Training loss (for one batch) at step 60: 443.5251, Accuracy: 0.6238\n",
      "Training loss (for one batch) at step 70: 444.6031, Accuracy: 0.6242\n",
      "Training loss (for one batch) at step 80: 445.2265, Accuracy: 0.6221\n",
      "Training loss (for one batch) at step 90: 442.3997, Accuracy: 0.6196\n",
      "Training loss (for one batch) at step 100: 440.0554, Accuracy: 0.6197\n",
      "Training loss (for one batch) at step 110: 441.3087, Accuracy: 0.6191\n",
      "---- Training ----\n",
      "Training loss: 138.7451\n",
      "Training acc over epoch: 0.6193\n",
      "---- Validation ----\n",
      "Validation loss: 35.4777\n",
      "Validation acc: 0.6445\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 444.4027, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 443.6941, Accuracy: 0.6207\n",
      "Training loss (for one batch) at step 20: 436.6981, Accuracy: 0.6157\n",
      "Training loss (for one batch) at step 30: 437.4747, Accuracy: 0.6184\n",
      "Training loss (for one batch) at step 40: 438.9149, Accuracy: 0.6273\n",
      "Training loss (for one batch) at step 50: 429.5913, Accuracy: 0.6320\n",
      "Training loss (for one batch) at step 60: 453.2049, Accuracy: 0.6351\n",
      "Training loss (for one batch) at step 70: 446.3192, Accuracy: 0.6383\n",
      "Training loss (for one batch) at step 80: 441.2688, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 90: 439.2070, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 100: 439.5585, Accuracy: 0.6297\n",
      "Training loss (for one batch) at step 110: 443.4893, Accuracy: 0.6318\n",
      "---- Training ----\n",
      "Training loss: 138.8828\n",
      "Training acc over epoch: 0.6333\n",
      "---- Validation ----\n",
      "Validation loss: 34.6929\n",
      "Validation acc: 0.6703\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 446.0436, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 443.2214, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 20: 442.3757, Accuracy: 0.6068\n",
      "Training loss (for one batch) at step 30: 434.4543, Accuracy: 0.6225\n",
      "Training loss (for one batch) at step 40: 434.5257, Accuracy: 0.6357\n",
      "Training loss (for one batch) at step 50: 433.8354, Accuracy: 0.6397\n",
      "Training loss (for one batch) at step 60: 436.5863, Accuracy: 0.6502\n",
      "Training loss (for one batch) at step 70: 447.6356, Accuracy: 0.6520\n",
      "Training loss (for one batch) at step 80: 440.3118, Accuracy: 0.6515\n",
      "Training loss (for one batch) at step 90: 441.4639, Accuracy: 0.6460\n",
      "Training loss (for one batch) at step 100: 438.5059, Accuracy: 0.6418\n",
      "Training loss (for one batch) at step 110: 440.9743, Accuracy: 0.6427\n",
      "---- Training ----\n",
      "Training loss: 136.3484\n",
      "Training acc over epoch: 0.6437\n",
      "---- Validation ----\n",
      "Validation loss: 34.1312\n",
      "Validation acc: 0.6010\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 443.2339, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 446.2236, Accuracy: 0.6001\n",
      "Training loss (for one batch) at step 20: 439.2650, Accuracy: 0.6257\n",
      "Training loss (for one batch) at step 30: 430.0502, Accuracy: 0.6346\n",
      "Training loss (for one batch) at step 40: 431.3305, Accuracy: 0.6414\n",
      "Training loss (for one batch) at step 50: 424.6157, Accuracy: 0.6564\n",
      "Training loss (for one batch) at step 60: 433.3231, Accuracy: 0.6610\n",
      "Training loss (for one batch) at step 70: 437.4772, Accuracy: 0.6645\n",
      "Training loss (for one batch) at step 80: 440.9841, Accuracy: 0.6614\n",
      "Training loss (for one batch) at step 90: 439.9245, Accuracy: 0.6587\n",
      "Training loss (for one batch) at step 100: 437.5032, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 110: 440.4006, Accuracy: 0.6553\n",
      "---- Training ----\n",
      "Training loss: 132.9187\n",
      "Training acc over epoch: 0.6568\n",
      "---- Validation ----\n",
      "Validation loss: 34.6273\n",
      "Validation acc: 0.6470\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 441.4113, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 441.5446, Accuracy: 0.6413\n",
      "Training loss (for one batch) at step 20: 437.9551, Accuracy: 0.6358\n",
      "Training loss (for one batch) at step 30: 431.2141, Accuracy: 0.6552\n",
      "Training loss (for one batch) at step 40: 423.7813, Accuracy: 0.6599\n",
      "Training loss (for one batch) at step 50: 415.8885, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 60: 428.0026, Accuracy: 0.6723\n",
      "Training loss (for one batch) at step 70: 442.0218, Accuracy: 0.6721\n",
      "Training loss (for one batch) at step 80: 440.2183, Accuracy: 0.6700\n",
      "Training loss (for one batch) at step 90: 433.2446, Accuracy: 0.6671\n",
      "Training loss (for one batch) at step 100: 444.1946, Accuracy: 0.6632\n",
      "Training loss (for one batch) at step 110: 439.8060, Accuracy: 0.6646\n",
      "---- Training ----\n",
      "Training loss: 135.4735\n",
      "Training acc over epoch: 0.6650\n",
      "---- Validation ----\n",
      "Validation loss: 33.9216\n",
      "Validation acc: 0.6502\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 441.7522, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 439.9630, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 20: 433.6354, Accuracy: 0.6350\n",
      "Training loss (for one batch) at step 30: 430.6098, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 40: 432.0996, Accuracy: 0.6709\n",
      "Training loss (for one batch) at step 50: 415.3811, Accuracy: 0.6824\n",
      "Training loss (for one batch) at step 60: 422.6786, Accuracy: 0.6908\n",
      "Training loss (for one batch) at step 70: 439.6198, Accuracy: 0.6971\n",
      "Training loss (for one batch) at step 80: 437.0645, Accuracy: 0.6901\n",
      "Training loss (for one batch) at step 90: 436.4893, Accuracy: 0.6814\n",
      "Training loss (for one batch) at step 100: 429.7737, Accuracy: 0.6785\n",
      "Training loss (for one batch) at step 110: 431.7633, Accuracy: 0.6783\n",
      "---- Training ----\n",
      "Training loss: 134.1137\n",
      "Training acc over epoch: 0.6787\n",
      "---- Validation ----\n",
      "Validation loss: 34.1944\n",
      "Validation acc: 0.6634\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 444.1765, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 433.8122, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 20: 435.7463, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 30: 428.3596, Accuracy: 0.6754\n",
      "Training loss (for one batch) at step 40: 421.7032, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 50: 417.7760, Accuracy: 0.6939\n",
      "Training loss (for one batch) at step 60: 420.5585, Accuracy: 0.7040\n",
      "Training loss (for one batch) at step 70: 446.8018, Accuracy: 0.7059\n",
      "Training loss (for one batch) at step 80: 440.4194, Accuracy: 0.7004\n",
      "Training loss (for one batch) at step 90: 433.0186, Accuracy: 0.6925\n",
      "Training loss (for one batch) at step 100: 431.5966, Accuracy: 0.6898\n",
      "Training loss (for one batch) at step 110: 435.9005, Accuracy: 0.6924\n",
      "---- Training ----\n",
      "Training loss: 136.8676\n",
      "Training acc over epoch: 0.6934\n",
      "---- Validation ----\n",
      "Validation loss: 34.9859\n",
      "Validation acc: 0.6765\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 438.4276, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 434.0860, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 20: 431.4019, Accuracy: 0.6652\n",
      "Training loss (for one batch) at step 30: 422.4753, Accuracy: 0.6817\n",
      "Training loss (for one batch) at step 40: 415.7988, Accuracy: 0.6839\n",
      "Training loss (for one batch) at step 50: 409.5578, Accuracy: 0.7011\n",
      "Training loss (for one batch) at step 60: 427.3936, Accuracy: 0.7086\n",
      "Training loss (for one batch) at step 70: 453.7822, Accuracy: 0.7075\n",
      "Training loss (for one batch) at step 80: 437.0346, Accuracy: 0.7005\n",
      "Training loss (for one batch) at step 90: 429.3655, Accuracy: 0.6951\n",
      "Training loss (for one batch) at step 100: 425.4898, Accuracy: 0.6934\n",
      "Training loss (for one batch) at step 110: 432.6049, Accuracy: 0.6941\n",
      "---- Training ----\n",
      "Training loss: 138.8168\n",
      "Training acc over epoch: 0.6935\n",
      "---- Validation ----\n",
      "Validation loss: 35.3742\n",
      "Validation acc: 0.6792\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 441.8020, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 432.6998, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 20: 434.5098, Accuracy: 0.6544\n",
      "Training loss (for one batch) at step 30: 420.6474, Accuracy: 0.6636\n",
      "Training loss (for one batch) at step 40: 419.3178, Accuracy: 0.6774\n",
      "Training loss (for one batch) at step 50: 415.3652, Accuracy: 0.6949\n",
      "Training loss (for one batch) at step 60: 424.1006, Accuracy: 0.7053\n",
      "Training loss (for one batch) at step 70: 426.6145, Accuracy: 0.7069\n",
      "Training loss (for one batch) at step 80: 443.7590, Accuracy: 0.7020\n",
      "Training loss (for one batch) at step 90: 435.8508, Accuracy: 0.6969\n",
      "Training loss (for one batch) at step 100: 430.4355, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 110: 434.7955, Accuracy: 0.6966\n",
      "---- Training ----\n",
      "Training loss: 135.8333\n",
      "Training acc over epoch: 0.6983\n",
      "---- Validation ----\n",
      "Validation loss: 33.4624\n",
      "Validation acc: 0.6491\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 446.1113, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 431.8753, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 434.2352, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 30: 423.8761, Accuracy: 0.6746\n",
      "Training loss (for one batch) at step 40: 418.4828, Accuracy: 0.6949\n",
      "Training loss (for one batch) at step 50: 411.2053, Accuracy: 0.7135\n",
      "Training loss (for one batch) at step 60: 409.2138, Accuracy: 0.7237\n",
      "Training loss (for one batch) at step 70: 421.9423, Accuracy: 0.7237\n",
      "Training loss (for one batch) at step 80: 438.7645, Accuracy: 0.7146\n",
      "Training loss (for one batch) at step 90: 431.4418, Accuracy: 0.7093\n",
      "Training loss (for one batch) at step 100: 424.5540, Accuracy: 0.7075\n",
      "Training loss (for one batch) at step 110: 435.0244, Accuracy: 0.7052\n",
      "---- Training ----\n",
      "Training loss: 138.0180\n",
      "Training acc over epoch: 0.7063\n",
      "---- Validation ----\n",
      "Validation loss: 34.8377\n",
      "Validation acc: 0.6808\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 442.9004, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 433.1343, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 20: 437.9099, Accuracy: 0.6763\n",
      "Training loss (for one batch) at step 30: 426.7462, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 40: 417.4693, Accuracy: 0.6898\n",
      "Training loss (for one batch) at step 50: 402.9800, Accuracy: 0.7070\n",
      "Training loss (for one batch) at step 60: 415.4429, Accuracy: 0.7213\n",
      "Training loss (for one batch) at step 70: 434.6338, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 80: 425.4937, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 90: 424.0548, Accuracy: 0.7099\n",
      "Training loss (for one batch) at step 100: 414.8953, Accuracy: 0.7071\n",
      "Training loss (for one batch) at step 110: 428.9987, Accuracy: 0.7102\n",
      "---- Training ----\n",
      "Training loss: 129.8649\n",
      "Training acc over epoch: 0.7101\n",
      "---- Validation ----\n",
      "Validation loss: 34.7495\n",
      "Validation acc: 0.6682\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 433.1777, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 429.6493, Accuracy: 0.6818\n",
      "Training loss (for one batch) at step 20: 427.3745, Accuracy: 0.6741\n",
      "Training loss (for one batch) at step 30: 410.9766, Accuracy: 0.6910\n",
      "Training loss (for one batch) at step 40: 402.9172, Accuracy: 0.7041\n",
      "Training loss (for one batch) at step 50: 396.7086, Accuracy: 0.7203\n",
      "Training loss (for one batch) at step 60: 407.3172, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 70: 428.5112, Accuracy: 0.7276\n",
      "Training loss (for one batch) at step 80: 435.7343, Accuracy: 0.7180\n",
      "Training loss (for one batch) at step 90: 427.6760, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 100: 434.5687, Accuracy: 0.7098\n",
      "Training loss (for one batch) at step 110: 416.3263, Accuracy: 0.7111\n",
      "---- Training ----\n",
      "Training loss: 133.1773\n",
      "Training acc over epoch: 0.7104\n",
      "---- Validation ----\n",
      "Validation loss: 36.1922\n",
      "Validation acc: 0.6937\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 440.4062, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 425.5942, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 20: 433.0103, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 30: 422.4950, Accuracy: 0.6872\n",
      "Training loss (for one batch) at step 40: 414.8487, Accuracy: 0.6987\n",
      "Training loss (for one batch) at step 50: 386.9843, Accuracy: 0.7134\n",
      "Training loss (for one batch) at step 60: 409.9746, Accuracy: 0.7275\n",
      "Training loss (for one batch) at step 70: 426.2465, Accuracy: 0.7268\n",
      "Training loss (for one batch) at step 80: 442.2625, Accuracy: 0.7171\n",
      "Training loss (for one batch) at step 90: 424.2307, Accuracy: 0.7121\n",
      "Training loss (for one batch) at step 100: 421.4006, Accuracy: 0.7144\n",
      "Training loss (for one batch) at step 110: 426.3643, Accuracy: 0.7156\n",
      "---- Training ----\n",
      "Training loss: 129.3640\n",
      "Training acc over epoch: 0.7155\n",
      "---- Validation ----\n",
      "Validation loss: 36.8087\n",
      "Validation acc: 0.6411\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 429.8445, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 435.7495, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 20: 423.2327, Accuracy: 0.6659\n",
      "Training loss (for one batch) at step 30: 415.8995, Accuracy: 0.6787\n",
      "Training loss (for one batch) at step 40: 394.7560, Accuracy: 0.6959\n",
      "Training loss (for one batch) at step 50: 383.0494, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 60: 408.1767, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 70: 430.6505, Accuracy: 0.7302\n",
      "Training loss (for one batch) at step 80: 427.3488, Accuracy: 0.7214\n",
      "Training loss (for one batch) at step 90: 424.0851, Accuracy: 0.7108\n",
      "Training loss (for one batch) at step 100: 412.0757, Accuracy: 0.7101\n",
      "Training loss (for one batch) at step 110: 418.6714, Accuracy: 0.7126\n",
      "---- Training ----\n",
      "Training loss: 137.2756\n",
      "Training acc over epoch: 0.7138\n",
      "---- Validation ----\n",
      "Validation loss: 37.6074\n",
      "Validation acc: 0.6736\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 430.1035, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 425.1469, Accuracy: 0.6634\n",
      "Training loss (for one batch) at step 20: 437.7084, Accuracy: 0.6674\n",
      "Training loss (for one batch) at step 30: 405.5901, Accuracy: 0.6918\n",
      "Training loss (for one batch) at step 40: 382.6431, Accuracy: 0.7083\n",
      "Training loss (for one batch) at step 50: 372.5886, Accuracy: 0.7247\n",
      "Training loss (for one batch) at step 60: 402.8411, Accuracy: 0.7355\n",
      "Training loss (for one batch) at step 70: 422.2735, Accuracy: 0.7331\n",
      "Training loss (for one batch) at step 80: 426.5808, Accuracy: 0.7246\n",
      "Training loss (for one batch) at step 90: 422.7020, Accuracy: 0.7197\n",
      "Training loss (for one batch) at step 100: 420.1453, Accuracy: 0.7178\n",
      "Training loss (for one batch) at step 110: 409.7464, Accuracy: 0.7184\n",
      "---- Training ----\n",
      "Training loss: 138.3374\n",
      "Training acc over epoch: 0.7177\n",
      "---- Validation ----\n",
      "Validation loss: 31.7589\n",
      "Validation acc: 0.6795\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 438.2351, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 421.0237, Accuracy: 0.6747\n",
      "Training loss (for one batch) at step 20: 419.8523, Accuracy: 0.6656\n",
      "Training loss (for one batch) at step 30: 394.5320, Accuracy: 0.6968\n",
      "Training loss (for one batch) at step 40: 386.1695, Accuracy: 0.7127\n",
      "Training loss (for one batch) at step 50: 363.3692, Accuracy: 0.7278\n",
      "Training loss (for one batch) at step 60: 387.4969, Accuracy: 0.7417\n",
      "Training loss (for one batch) at step 70: 408.1820, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 80: 422.5670, Accuracy: 0.7257\n",
      "Training loss (for one batch) at step 90: 416.4260, Accuracy: 0.7178\n",
      "Training loss (for one batch) at step 100: 392.1829, Accuracy: 0.7194\n",
      "Training loss (for one batch) at step 110: 418.2322, Accuracy: 0.7201\n",
      "---- Training ----\n",
      "Training loss: 130.7557\n",
      "Training acc over epoch: 0.7207\n",
      "---- Validation ----\n",
      "Validation loss: 34.5317\n",
      "Validation acc: 0.6642\n",
      "Time taken: 11.17s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 439.2939, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 435.8489, Accuracy: 0.6243\n",
      "Training loss (for one batch) at step 20: 416.6198, Accuracy: 0.6503\n",
      "Training loss (for one batch) at step 30: 410.3086, Accuracy: 0.6817\n",
      "Training loss (for one batch) at step 40: 383.9933, Accuracy: 0.7033\n",
      "Training loss (for one batch) at step 50: 349.1772, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 60: 390.3981, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 70: 390.6918, Accuracy: 0.7333\n",
      "Training loss (for one batch) at step 80: 406.7967, Accuracy: 0.7233\n",
      "Training loss (for one batch) at step 90: 417.9767, Accuracy: 0.7169\n",
      "Training loss (for one batch) at step 100: 421.7334, Accuracy: 0.7174\n",
      "Training loss (for one batch) at step 110: 413.1788, Accuracy: 0.7166\n",
      "---- Training ----\n",
      "Training loss: 128.4902\n",
      "Training acc over epoch: 0.7152\n",
      "---- Validation ----\n",
      "Validation loss: 41.4744\n",
      "Validation acc: 0.6655\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 428.9933, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 426.4902, Accuracy: 0.6463\n",
      "Training loss (for one batch) at step 20: 423.1470, Accuracy: 0.6618\n",
      "Training loss (for one batch) at step 30: 391.4269, Accuracy: 0.6883\n",
      "Training loss (for one batch) at step 40: 375.0250, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 50: 363.8180, Accuracy: 0.7267\n",
      "Training loss (for one batch) at step 60: 376.5494, Accuracy: 0.7408\n",
      "Training loss (for one batch) at step 70: 401.9422, Accuracy: 0.7331\n",
      "Training loss (for one batch) at step 80: 407.0279, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 90: 406.0571, Accuracy: 0.7175\n",
      "Training loss (for one batch) at step 100: 396.9295, Accuracy: 0.7194\n",
      "Training loss (for one batch) at step 110: 391.3963, Accuracy: 0.7192\n",
      "---- Training ----\n",
      "Training loss: 134.4227\n",
      "Training acc over epoch: 0.7178\n",
      "---- Validation ----\n",
      "Validation loss: 30.9394\n",
      "Validation acc: 0.6359\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 432.4281, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 416.1495, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 20: 422.5921, Accuracy: 0.6659\n",
      "Training loss (for one batch) at step 30: 400.7383, Accuracy: 0.6867\n",
      "Training loss (for one batch) at step 40: 360.4480, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 50: 337.6433, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 60: 358.4027, Accuracy: 0.7392\n",
      "Training loss (for one batch) at step 70: 409.5562, Accuracy: 0.7350\n",
      "Training loss (for one batch) at step 80: 403.7108, Accuracy: 0.7256\n",
      "Training loss (for one batch) at step 90: 392.0569, Accuracy: 0.7200\n",
      "Training loss (for one batch) at step 100: 390.3262, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 110: 403.8070, Accuracy: 0.7228\n",
      "---- Training ----\n",
      "Training loss: 131.9203\n",
      "Training acc over epoch: 0.7221\n",
      "---- Validation ----\n",
      "Validation loss: 36.9769\n",
      "Validation acc: 0.6510\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 435.9795, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 425.9702, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 20: 419.7590, Accuracy: 0.6589\n",
      "Training loss (for one batch) at step 30: 384.2842, Accuracy: 0.6885\n",
      "Training loss (for one batch) at step 40: 373.2835, Accuracy: 0.7121\n",
      "Training loss (for one batch) at step 50: 350.8477, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 60: 368.8251, Accuracy: 0.7373\n",
      "Training loss (for one batch) at step 70: 383.7719, Accuracy: 0.7310\n",
      "Training loss (for one batch) at step 80: 403.4806, Accuracy: 0.7171\n",
      "Training loss (for one batch) at step 90: 386.9007, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 100: 392.7435, Accuracy: 0.7143\n",
      "Training loss (for one batch) at step 110: 395.8464, Accuracy: 0.7167\n",
      "---- Training ----\n",
      "Training loss: 134.4062\n",
      "Training acc over epoch: 0.7160\n",
      "---- Validation ----\n",
      "Validation loss: 40.6970\n",
      "Validation acc: 0.6674\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 426.6617, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 418.0838, Accuracy: 0.6435\n",
      "Training loss (for one batch) at step 20: 398.6639, Accuracy: 0.6670\n",
      "Training loss (for one batch) at step 30: 379.9924, Accuracy: 0.6988\n",
      "Training loss (for one batch) at step 40: 374.7880, Accuracy: 0.7149\n",
      "Training loss (for one batch) at step 50: 337.4244, Accuracy: 0.7338\n",
      "Training loss (for one batch) at step 60: 356.8008, Accuracy: 0.7446\n",
      "Training loss (for one batch) at step 70: 380.7803, Accuracy: 0.7370\n",
      "Training loss (for one batch) at step 80: 394.1001, Accuracy: 0.7268\n",
      "Training loss (for one batch) at step 90: 378.5843, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 100: 381.2998, Accuracy: 0.7221\n",
      "Training loss (for one batch) at step 110: 403.4168, Accuracy: 0.7231\n",
      "---- Training ----\n",
      "Training loss: 127.4730\n",
      "Training acc over epoch: 0.7234\n",
      "---- Validation ----\n",
      "Validation loss: 44.7957\n",
      "Validation acc: 0.6513\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 430.4661, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 423.8897, Accuracy: 0.6449\n",
      "Training loss (for one batch) at step 20: 383.7795, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 30: 371.5169, Accuracy: 0.6976\n",
      "Training loss (for one batch) at step 40: 355.2396, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 50: 351.5219, Accuracy: 0.7371\n",
      "Training loss (for one batch) at step 60: 381.9248, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 70: 373.0796, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 80: 388.4008, Accuracy: 0.7206\n",
      "Training loss (for one batch) at step 90: 373.7276, Accuracy: 0.7169\n",
      "Training loss (for one batch) at step 100: 395.6172, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 110: 386.9754, Accuracy: 0.7223\n",
      "---- Training ----\n",
      "Training loss: 119.1347\n",
      "Training acc over epoch: 0.7219\n",
      "---- Validation ----\n",
      "Validation loss: 35.3877\n",
      "Validation acc: 0.6537\n",
      "Time taken: 10.83s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 411.6256, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 424.7746, Accuracy: 0.6300\n",
      "Training loss (for one batch) at step 20: 398.5536, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 30: 374.8668, Accuracy: 0.6885\n",
      "Training loss (for one batch) at step 40: 368.9839, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 50: 339.9554, Accuracy: 0.7267\n",
      "Training loss (for one batch) at step 60: 313.5970, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 70: 376.2758, Accuracy: 0.7283\n",
      "Training loss (for one batch) at step 80: 399.7108, Accuracy: 0.7153\n",
      "Training loss (for one batch) at step 90: 381.4696, Accuracy: 0.7124\n",
      "Training loss (for one batch) at step 100: 381.5374, Accuracy: 0.7151\n",
      "Training loss (for one batch) at step 110: 376.0124, Accuracy: 0.7180\n",
      "---- Training ----\n",
      "Training loss: 120.7113\n",
      "Training acc over epoch: 0.7187\n",
      "---- Validation ----\n",
      "Validation loss: 44.2506\n",
      "Validation acc: 0.6660\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 418.4622, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 409.8875, Accuracy: 0.6456\n",
      "Training loss (for one batch) at step 20: 376.3681, Accuracy: 0.6629\n",
      "Training loss (for one batch) at step 30: 357.7944, Accuracy: 0.6908\n",
      "Training loss (for one batch) at step 40: 342.5694, Accuracy: 0.7174\n",
      "Training loss (for one batch) at step 50: 343.1937, Accuracy: 0.7359\n",
      "Training loss (for one batch) at step 60: 354.3210, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 70: 380.7776, Accuracy: 0.7317\n",
      "Training loss (for one batch) at step 80: 396.5099, Accuracy: 0.7150\n",
      "Training loss (for one batch) at step 90: 382.1761, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 100: 374.5764, Accuracy: 0.7174\n",
      "Training loss (for one batch) at step 110: 377.1542, Accuracy: 0.7187\n",
      "---- Training ----\n",
      "Training loss: 121.3613\n",
      "Training acc over epoch: 0.7175\n",
      "---- Validation ----\n",
      "Validation loss: 37.3989\n",
      "Validation acc: 0.6789\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 404.8211, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 398.3256, Accuracy: 0.6371\n",
      "Training loss (for one batch) at step 20: 361.9821, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 30: 341.8137, Accuracy: 0.6943\n",
      "Training loss (for one batch) at step 40: 360.2225, Accuracy: 0.7136\n",
      "Training loss (for one batch) at step 50: 353.3731, Accuracy: 0.7328\n",
      "Training loss (for one batch) at step 60: 360.1199, Accuracy: 0.7400\n",
      "Training loss (for one batch) at step 70: 383.0479, Accuracy: 0.7306\n",
      "Training loss (for one batch) at step 80: 372.3451, Accuracy: 0.7160\n",
      "Training loss (for one batch) at step 90: 378.5269, Accuracy: 0.7137\n",
      "Training loss (for one batch) at step 100: 355.2303, Accuracy: 0.7177\n",
      "Training loss (for one batch) at step 110: 379.5898, Accuracy: 0.7209\n",
      "---- Training ----\n",
      "Training loss: 128.5406\n",
      "Training acc over epoch: 0.7190\n",
      "---- Validation ----\n",
      "Validation loss: 42.5983\n",
      "Validation acc: 0.6553\n",
      "Time taken: 10.87s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 411.1141, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 377.7108, Accuracy: 0.6193\n",
      "Training loss (for one batch) at step 20: 379.8109, Accuracy: 0.6477\n",
      "Training loss (for one batch) at step 30: 351.6285, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 40: 333.6231, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 50: 317.9284, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 60: 357.7262, Accuracy: 0.7325\n",
      "Training loss (for one batch) at step 70: 356.3586, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 80: 401.0388, Accuracy: 0.7096\n",
      "Training loss (for one batch) at step 90: 366.8097, Accuracy: 0.7072\n",
      "Training loss (for one batch) at step 100: 361.3386, Accuracy: 0.7113\n",
      "Training loss (for one batch) at step 110: 370.0761, Accuracy: 0.7128\n",
      "---- Training ----\n",
      "Training loss: 115.6167\n",
      "Training acc over epoch: 0.7109\n",
      "---- Validation ----\n",
      "Validation loss: 39.7179\n",
      "Validation acc: 0.6741\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 409.4191, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 405.5832, Accuracy: 0.6023\n",
      "Training loss (for one batch) at step 20: 367.4590, Accuracy: 0.6440\n",
      "Training loss (for one batch) at step 30: 361.4893, Accuracy: 0.6857\n",
      "Training loss (for one batch) at step 40: 338.0713, Accuracy: 0.7134\n",
      "Training loss (for one batch) at step 50: 335.2430, Accuracy: 0.7309\n",
      "Training loss (for one batch) at step 60: 343.7531, Accuracy: 0.7394\n",
      "Training loss (for one batch) at step 70: 371.9467, Accuracy: 0.7272\n",
      "Training loss (for one batch) at step 80: 382.8867, Accuracy: 0.7123\n",
      "Training loss (for one batch) at step 90: 381.1160, Accuracy: 0.7111\n",
      "Training loss (for one batch) at step 100: 347.5939, Accuracy: 0.7156\n",
      "Training loss (for one batch) at step 110: 370.7425, Accuracy: 0.7157\n",
      "---- Training ----\n",
      "Training loss: 114.9359\n",
      "Training acc over epoch: 0.7153\n",
      "---- Validation ----\n",
      "Validation loss: 42.5626\n",
      "Validation acc: 0.6671\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 390.6588, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 381.2948, Accuracy: 0.6143\n",
      "Training loss (for one batch) at step 20: 375.6276, Accuracy: 0.6525\n",
      "Training loss (for one batch) at step 30: 360.6646, Accuracy: 0.6847\n",
      "Training loss (for one batch) at step 40: 334.1682, Accuracy: 0.7111\n",
      "Training loss (for one batch) at step 50: 330.2900, Accuracy: 0.7292\n",
      "Training loss (for one batch) at step 60: 338.5684, Accuracy: 0.7400\n",
      "Training loss (for one batch) at step 70: 369.2850, Accuracy: 0.7280\n",
      "Training loss (for one batch) at step 80: 370.6794, Accuracy: 0.7142\n",
      "Training loss (for one batch) at step 90: 367.7813, Accuracy: 0.7114\n",
      "Training loss (for one batch) at step 100: 340.5003, Accuracy: 0.7161\n",
      "Training loss (for one batch) at step 110: 362.0656, Accuracy: 0.7166\n",
      "---- Training ----\n",
      "Training loss: 106.1945\n",
      "Training acc over epoch: 0.7148\n",
      "---- Validation ----\n",
      "Validation loss: 46.4610\n",
      "Validation acc: 0.6572\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 388.3928, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 397.1447, Accuracy: 0.6165\n",
      "Training loss (for one batch) at step 20: 365.2129, Accuracy: 0.6496\n",
      "Training loss (for one batch) at step 30: 338.2845, Accuracy: 0.6913\n",
      "Training loss (for one batch) at step 40: 332.3937, Accuracy: 0.7176\n",
      "Training loss (for one batch) at step 50: 326.0917, Accuracy: 0.7324\n",
      "Training loss (for one batch) at step 60: 349.9980, Accuracy: 0.7391\n",
      "Training loss (for one batch) at step 70: 373.9899, Accuracy: 0.7270\n",
      "Training loss (for one batch) at step 80: 379.0601, Accuracy: 0.7133\n",
      "Training loss (for one batch) at step 90: 380.8561, Accuracy: 0.7092\n",
      "Training loss (for one batch) at step 100: 340.8838, Accuracy: 0.7147\n",
      "Training loss (for one batch) at step 110: 358.0134, Accuracy: 0.7171\n",
      "---- Training ----\n",
      "Training loss: 118.5413\n",
      "Training acc over epoch: 0.7147\n",
      "---- Validation ----\n",
      "Validation loss: 56.9035\n",
      "Validation acc: 0.6636\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 380.6598, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 381.4987, Accuracy: 0.6030\n",
      "Training loss (for one batch) at step 20: 342.7349, Accuracy: 0.6388\n",
      "Training loss (for one batch) at step 30: 369.4901, Accuracy: 0.6787\n",
      "Training loss (for one batch) at step 40: 322.3359, Accuracy: 0.7041\n",
      "Training loss (for one batch) at step 50: 327.6868, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 60: 332.8424, Accuracy: 0.7340\n",
      "Training loss (for one batch) at step 70: 347.2775, Accuracy: 0.7232\n",
      "Training loss (for one batch) at step 80: 383.6296, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 90: 348.4078, Accuracy: 0.7066\n",
      "Training loss (for one batch) at step 100: 344.7196, Accuracy: 0.7120\n",
      "Training loss (for one batch) at step 110: 367.9070, Accuracy: 0.7127\n",
      "---- Training ----\n",
      "Training loss: 112.7115\n",
      "Training acc over epoch: 0.7114\n",
      "---- Validation ----\n",
      "Validation loss: 36.6415\n",
      "Validation acc: 0.6593\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 389.0072, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 380.3732, Accuracy: 0.6115\n",
      "Training loss (for one batch) at step 20: 352.7722, Accuracy: 0.6425\n",
      "Training loss (for one batch) at step 30: 345.6739, Accuracy: 0.6857\n",
      "Training loss (for one batch) at step 40: 339.9810, Accuracy: 0.7128\n",
      "Training loss (for one batch) at step 50: 317.0646, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 60: 330.7597, Accuracy: 0.7382\n",
      "Training loss (for one batch) at step 70: 353.3508, Accuracy: 0.7212\n",
      "Training loss (for one batch) at step 80: 364.0973, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 90: 348.9802, Accuracy: 0.7085\n",
      "Training loss (for one batch) at step 100: 351.9083, Accuracy: 0.7126\n",
      "Training loss (for one batch) at step 110: 339.8401, Accuracy: 0.7143\n",
      "---- Training ----\n",
      "Training loss: 110.0239\n",
      "Training acc over epoch: 0.7135\n",
      "---- Validation ----\n",
      "Validation loss: 48.3747\n",
      "Validation acc: 0.6480\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 382.8484, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 379.0190, Accuracy: 0.6037\n",
      "Training loss (for one batch) at step 20: 348.0681, Accuracy: 0.6403\n",
      "Training loss (for one batch) at step 30: 339.2968, Accuracy: 0.6850\n",
      "Training loss (for one batch) at step 40: 354.5465, Accuracy: 0.7142\n",
      "Training loss (for one batch) at step 50: 328.8941, Accuracy: 0.7305\n",
      "Training loss (for one batch) at step 60: 329.5267, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 70: 346.2559, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 80: 367.2036, Accuracy: 0.7107\n",
      "Training loss (for one batch) at step 90: 360.8281, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 100: 331.5789, Accuracy: 0.7136\n",
      "Training loss (for one batch) at step 110: 341.6282, Accuracy: 0.7159\n",
      "---- Training ----\n",
      "Training loss: 108.3201\n",
      "Training acc over epoch: 0.7146\n",
      "---- Validation ----\n",
      "Validation loss: 47.9192\n",
      "Validation acc: 0.6518\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 381.7994, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 375.7839, Accuracy: 0.6158\n",
      "Training loss (for one batch) at step 20: 347.9781, Accuracy: 0.6462\n",
      "Training loss (for one batch) at step 30: 333.0562, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 40: 321.6579, Accuracy: 0.7147\n",
      "Training loss (for one batch) at step 50: 295.9418, Accuracy: 0.7356\n",
      "Training loss (for one batch) at step 60: 330.3546, Accuracy: 0.7454\n",
      "Training loss (for one batch) at step 70: 336.6191, Accuracy: 0.7311\n",
      "Training loss (for one batch) at step 80: 397.8460, Accuracy: 0.7155\n",
      "Training loss (for one batch) at step 90: 330.9246, Accuracy: 0.7140\n",
      "Training loss (for one batch) at step 100: 349.8738, Accuracy: 0.7191\n",
      "Training loss (for one batch) at step 110: 372.4601, Accuracy: 0.7221\n",
      "---- Training ----\n",
      "Training loss: 101.0659\n",
      "Training acc over epoch: 0.7194\n",
      "---- Validation ----\n",
      "Validation loss: 42.9221\n",
      "Validation acc: 0.6655\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 379.1732, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 384.2704, Accuracy: 0.5852\n",
      "Training loss (for one batch) at step 20: 342.1740, Accuracy: 0.6388\n",
      "Training loss (for one batch) at step 30: 326.0038, Accuracy: 0.6822\n",
      "Training loss (for one batch) at step 40: 308.4509, Accuracy: 0.7115\n",
      "Training loss (for one batch) at step 50: 331.5838, Accuracy: 0.7295\n",
      "Training loss (for one batch) at step 60: 350.5656, Accuracy: 0.7390\n",
      "Training loss (for one batch) at step 70: 381.8873, Accuracy: 0.7251\n",
      "Training loss (for one batch) at step 80: 371.3694, Accuracy: 0.7107\n",
      "Training loss (for one batch) at step 90: 344.8663, Accuracy: 0.7087\n",
      "Training loss (for one batch) at step 100: 341.3883, Accuracy: 0.7131\n",
      "Training loss (for one batch) at step 110: 343.2452, Accuracy: 0.7141\n",
      "---- Training ----\n",
      "Training loss: 112.6133\n",
      "Training acc over epoch: 0.7133\n",
      "---- Validation ----\n",
      "Validation loss: 47.7301\n",
      "Validation acc: 0.6671\n",
      "Time taken: 10.75s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6558\n",
      "Validation AUC: 0.6568\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 616.6935, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 10: 598.1960, Accuracy: 0.5277\n",
      "Training loss (for one batch) at step 20: 558.0820, Accuracy: 0.5175\n",
      "Training loss (for one batch) at step 30: 506.7643, Accuracy: 0.5146\n",
      "Training loss (for one batch) at step 40: 505.8552, Accuracy: 0.5177\n",
      "Training loss (for one batch) at step 50: 495.4683, Accuracy: 0.5158\n",
      "Training loss (for one batch) at step 60: 495.2472, Accuracy: 0.5132\n",
      "Training loss (for one batch) at step 70: 501.5246, Accuracy: 0.5143\n",
      "Training loss (for one batch) at step 80: 494.3863, Accuracy: 0.5170\n",
      "Training loss (for one batch) at step 90: 494.4224, Accuracy: 0.5177\n",
      "Training loss (for one batch) at step 100: 473.4343, Accuracy: 0.5201\n",
      "Training loss (for one batch) at step 110: 458.2799, Accuracy: 0.5194\n",
      "---- Training ----\n",
      "Training loss: 145.2903\n",
      "Training acc over epoch: 0.5211\n",
      "---- Validation ----\n",
      "Validation loss: 34.7053\n",
      "Validation acc: 0.5145\n",
      "Time taken: 14.94s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 473.0479, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 457.0725, Accuracy: 0.5277\n",
      "Training loss (for one batch) at step 20: 464.3254, Accuracy: 0.5353\n",
      "Training loss (for one batch) at step 30: 467.8180, Accuracy: 0.5219\n",
      "Training loss (for one batch) at step 40: 453.2664, Accuracy: 0.5223\n",
      "Training loss (for one batch) at step 50: 456.2008, Accuracy: 0.5276\n",
      "Training loss (for one batch) at step 60: 460.7886, Accuracy: 0.5251\n",
      "Training loss (for one batch) at step 70: 462.1942, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 80: 455.9386, Accuracy: 0.5202\n",
      "Training loss (for one batch) at step 90: 454.3521, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 100: 447.6548, Accuracy: 0.5239\n",
      "Training loss (for one batch) at step 110: 448.8010, Accuracy: 0.5234\n",
      "---- Training ----\n",
      "Training loss: 141.5296\n",
      "Training acc over epoch: 0.5248\n",
      "---- Validation ----\n",
      "Validation loss: 34.6974\n",
      "Validation acc: 0.4925\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 450.4438, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 10: 449.5117, Accuracy: 0.5362\n",
      "Training loss (for one batch) at step 20: 453.0313, Accuracy: 0.5443\n",
      "Training loss (for one batch) at step 30: 447.3210, Accuracy: 0.5393\n",
      "Training loss (for one batch) at step 40: 446.5103, Accuracy: 0.5360\n",
      "Training loss (for one batch) at step 50: 447.6463, Accuracy: 0.5296\n",
      "Training loss (for one batch) at step 60: 451.0388, Accuracy: 0.5327\n",
      "Training loss (for one batch) at step 70: 448.1220, Accuracy: 0.5368\n",
      "Training loss (for one batch) at step 80: 451.3116, Accuracy: 0.5426\n",
      "Training loss (for one batch) at step 90: 449.7065, Accuracy: 0.5458\n",
      "Training loss (for one batch) at step 100: 442.6124, Accuracy: 0.5459\n",
      "Training loss (for one batch) at step 110: 444.1774, Accuracy: 0.5465\n",
      "---- Training ----\n",
      "Training loss: 139.4390\n",
      "Training acc over epoch: 0.5472\n",
      "---- Validation ----\n",
      "Validation loss: 34.5774\n",
      "Validation acc: 0.5656\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.3960, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 445.9949, Accuracy: 0.5788\n",
      "Training loss (for one batch) at step 20: 442.1534, Accuracy: 0.5766\n",
      "Training loss (for one batch) at step 30: 443.8875, Accuracy: 0.5804\n",
      "Training loss (for one batch) at step 40: 443.1559, Accuracy: 0.5776\n",
      "Training loss (for one batch) at step 50: 443.6911, Accuracy: 0.5784\n",
      "Training loss (for one batch) at step 60: 446.9748, Accuracy: 0.5800\n",
      "Training loss (for one batch) at step 70: 442.7631, Accuracy: 0.5770\n",
      "Training loss (for one batch) at step 80: 446.5969, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 90: 443.9056, Accuracy: 0.5738\n",
      "Training loss (for one batch) at step 100: 441.6164, Accuracy: 0.5726\n",
      "Training loss (for one batch) at step 110: 441.5451, Accuracy: 0.5705\n",
      "---- Training ----\n",
      "Training loss: 139.4547\n",
      "Training acc over epoch: 0.5698\n",
      "---- Validation ----\n",
      "Validation loss: 34.4917\n",
      "Validation acc: 0.5900\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 444.3485, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 444.0559, Accuracy: 0.5803\n",
      "Training loss (for one batch) at step 20: 441.4927, Accuracy: 0.5934\n",
      "Training loss (for one batch) at step 30: 440.5497, Accuracy: 0.5958\n",
      "Training loss (for one batch) at step 40: 442.9988, Accuracy: 0.5903\n",
      "Training loss (for one batch) at step 50: 442.9684, Accuracy: 0.5869\n",
      "Training loss (for one batch) at step 60: 442.7658, Accuracy: 0.5857\n",
      "Training loss (for one batch) at step 70: 445.3718, Accuracy: 0.5830\n",
      "Training loss (for one batch) at step 80: 445.3431, Accuracy: 0.5823\n",
      "Training loss (for one batch) at step 90: 442.3451, Accuracy: 0.5798\n",
      "Training loss (for one batch) at step 100: 441.7313, Accuracy: 0.5774\n",
      "Training loss (for one batch) at step 110: 441.8775, Accuracy: 0.5771\n",
      "---- Training ----\n",
      "Training loss: 140.6306\n",
      "Training acc over epoch: 0.5783\n",
      "---- Validation ----\n",
      "Validation loss: 34.5892\n",
      "Validation acc: 0.5911\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 444.6133, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 441.0524, Accuracy: 0.5717\n",
      "Training loss (for one batch) at step 20: 444.2675, Accuracy: 0.5778\n",
      "Training loss (for one batch) at step 30: 441.1632, Accuracy: 0.5935\n",
      "Training loss (for one batch) at step 40: 441.8226, Accuracy: 0.5985\n",
      "Training loss (for one batch) at step 50: 443.5999, Accuracy: 0.5953\n",
      "Training loss (for one batch) at step 60: 441.1212, Accuracy: 0.5976\n",
      "Training loss (for one batch) at step 70: 446.3277, Accuracy: 0.5942\n",
      "Training loss (for one batch) at step 80: 442.9141, Accuracy: 0.5908\n",
      "Training loss (for one batch) at step 90: 440.6548, Accuracy: 0.5883\n",
      "Training loss (for one batch) at step 100: 437.6379, Accuracy: 0.5844\n",
      "Training loss (for one batch) at step 110: 440.8016, Accuracy: 0.5848\n",
      "---- Training ----\n",
      "Training loss: 137.8199\n",
      "Training acc over epoch: 0.5846\n",
      "---- Validation ----\n",
      "Validation loss: 34.8531\n",
      "Validation acc: 0.5793\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 439.6518, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 442.6315, Accuracy: 0.6186\n",
      "Training loss (for one batch) at step 20: 440.8846, Accuracy: 0.5978\n",
      "Training loss (for one batch) at step 30: 441.0652, Accuracy: 0.6033\n",
      "Training loss (for one batch) at step 40: 444.6710, Accuracy: 0.6109\n",
      "Training loss (for one batch) at step 50: 442.0557, Accuracy: 0.6072\n",
      "Training loss (for one batch) at step 60: 441.3248, Accuracy: 0.6002\n",
      "Training loss (for one batch) at step 70: 439.6210, Accuracy: 0.6009\n",
      "Training loss (for one batch) at step 80: 444.9235, Accuracy: 0.6007\n",
      "Training loss (for one batch) at step 90: 441.9425, Accuracy: 0.5994\n",
      "Training loss (for one batch) at step 100: 440.6666, Accuracy: 0.5991\n",
      "Training loss (for one batch) at step 110: 439.6348, Accuracy: 0.5984\n",
      "---- Training ----\n",
      "Training loss: 137.1712\n",
      "Training acc over epoch: 0.5995\n",
      "---- Validation ----\n",
      "Validation loss: 33.7919\n",
      "Validation acc: 0.5927\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 438.1966, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 442.0111, Accuracy: 0.6001\n",
      "Training loss (for one batch) at step 20: 440.9421, Accuracy: 0.6060\n",
      "Training loss (for one batch) at step 30: 432.9317, Accuracy: 0.6184\n",
      "Training loss (for one batch) at step 40: 437.7333, Accuracy: 0.6197\n",
      "Training loss (for one batch) at step 50: 439.7036, Accuracy: 0.6178\n",
      "Training loss (for one batch) at step 60: 440.1634, Accuracy: 0.6171\n",
      "Training loss (for one batch) at step 70: 440.1717, Accuracy: 0.6163\n",
      "Training loss (for one batch) at step 80: 441.9779, Accuracy: 0.6160\n",
      "Training loss (for one batch) at step 90: 438.5505, Accuracy: 0.6130\n",
      "Training loss (for one batch) at step 100: 434.5306, Accuracy: 0.6141\n",
      "Training loss (for one batch) at step 110: 442.0471, Accuracy: 0.6156\n",
      "---- Training ----\n",
      "Training loss: 137.0621\n",
      "Training acc over epoch: 0.6148\n",
      "---- Validation ----\n",
      "Validation loss: 35.0554\n",
      "Validation acc: 0.6102\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 441.1826, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 441.1724, Accuracy: 0.6229\n",
      "Training loss (for one batch) at step 20: 439.8195, Accuracy: 0.6291\n",
      "Training loss (for one batch) at step 30: 436.3549, Accuracy: 0.6305\n",
      "Training loss (for one batch) at step 40: 439.5495, Accuracy: 0.6361\n",
      "Training loss (for one batch) at step 50: 439.4078, Accuracy: 0.6308\n",
      "Training loss (for one batch) at step 60: 442.8760, Accuracy: 0.6341\n",
      "Training loss (for one batch) at step 70: 451.9836, Accuracy: 0.6390\n",
      "Training loss (for one batch) at step 80: 441.3582, Accuracy: 0.6379\n",
      "Training loss (for one batch) at step 90: 439.8019, Accuracy: 0.6326\n",
      "Training loss (for one batch) at step 100: 436.2790, Accuracy: 0.6285\n",
      "Training loss (for one batch) at step 110: 436.3038, Accuracy: 0.6279\n",
      "---- Training ----\n",
      "Training loss: 137.4130\n",
      "Training acc over epoch: 0.6284\n",
      "---- Validation ----\n",
      "Validation loss: 34.8893\n",
      "Validation acc: 0.6126\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 441.1311, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 438.6801, Accuracy: 0.6385\n",
      "Training loss (for one batch) at step 20: 437.1169, Accuracy: 0.6283\n",
      "Training loss (for one batch) at step 30: 436.3055, Accuracy: 0.6361\n",
      "Training loss (for one batch) at step 40: 428.4427, Accuracy: 0.6401\n",
      "Training loss (for one batch) at step 50: 432.9600, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 60: 436.8192, Accuracy: 0.6504\n",
      "Training loss (for one batch) at step 70: 450.1027, Accuracy: 0.6479\n",
      "Training loss (for one batch) at step 80: 442.9019, Accuracy: 0.6444\n",
      "Training loss (for one batch) at step 90: 439.4601, Accuracy: 0.6393\n",
      "Training loss (for one batch) at step 100: 437.6257, Accuracy: 0.6370\n",
      "Training loss (for one batch) at step 110: 434.2671, Accuracy: 0.6351\n",
      "---- Training ----\n",
      "Training loss: 139.5327\n",
      "Training acc over epoch: 0.6355\n",
      "---- Validation ----\n",
      "Validation loss: 33.8436\n",
      "Validation acc: 0.5768\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 445.1830, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 440.3690, Accuracy: 0.6364\n",
      "Training loss (for one batch) at step 20: 442.5667, Accuracy: 0.6347\n",
      "Training loss (for one batch) at step 30: 431.6348, Accuracy: 0.6411\n",
      "Training loss (for one batch) at step 40: 425.4830, Accuracy: 0.6492\n",
      "Training loss (for one batch) at step 50: 431.6599, Accuracy: 0.6573\n",
      "Training loss (for one batch) at step 60: 445.3993, Accuracy: 0.6609\n",
      "Training loss (for one batch) at step 70: 447.7684, Accuracy: 0.6597\n",
      "Training loss (for one batch) at step 80: 442.0580, Accuracy: 0.6502\n",
      "Training loss (for one batch) at step 90: 439.5407, Accuracy: 0.6441\n",
      "Training loss (for one batch) at step 100: 434.8477, Accuracy: 0.6440\n",
      "Training loss (for one batch) at step 110: 439.4300, Accuracy: 0.6423\n",
      "---- Training ----\n",
      "Training loss: 138.6639\n",
      "Training acc over epoch: 0.6427\n",
      "---- Validation ----\n",
      "Validation loss: 35.5993\n",
      "Validation acc: 0.6196\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 439.9243, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 446.5306, Accuracy: 0.6541\n",
      "Training loss (for one batch) at step 20: 434.4100, Accuracy: 0.6477\n",
      "Training loss (for one batch) at step 30: 435.5755, Accuracy: 0.6507\n",
      "Training loss (for one batch) at step 40: 426.2556, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 50: 438.5942, Accuracy: 0.6608\n",
      "Training loss (for one batch) at step 60: 440.1716, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 70: 445.0934, Accuracy: 0.6667\n",
      "Training loss (for one batch) at step 80: 441.9833, Accuracy: 0.6592\n",
      "Training loss (for one batch) at step 90: 442.3532, Accuracy: 0.6469\n",
      "Training loss (for one batch) at step 100: 435.7410, Accuracy: 0.6441\n",
      "Training loss (for one batch) at step 110: 428.7120, Accuracy: 0.6441\n",
      "---- Training ----\n",
      "Training loss: 136.7167\n",
      "Training acc over epoch: 0.6441\n",
      "---- Validation ----\n",
      "Validation loss: 35.4588\n",
      "Validation acc: 0.6499\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 437.3810, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 439.0306, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 20: 434.3586, Accuracy: 0.6481\n",
      "Training loss (for one batch) at step 30: 433.0399, Accuracy: 0.6585\n",
      "Training loss (for one batch) at step 40: 426.8186, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 50: 429.4987, Accuracy: 0.6745\n",
      "Training loss (for one batch) at step 60: 440.3557, Accuracy: 0.6789\n",
      "Training loss (for one batch) at step 70: 442.2094, Accuracy: 0.6839\n",
      "Training loss (for one batch) at step 80: 441.8125, Accuracy: 0.6819\n",
      "Training loss (for one batch) at step 90: 435.5793, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 100: 437.6847, Accuracy: 0.6722\n",
      "Training loss (for one batch) at step 110: 423.7656, Accuracy: 0.6681\n",
      "---- Training ----\n",
      "Training loss: 134.1755\n",
      "Training acc over epoch: 0.6685\n",
      "---- Validation ----\n",
      "Validation loss: 36.9229\n",
      "Validation acc: 0.6848\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 445.3801, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 438.8952, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 20: 431.8408, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 30: 426.8743, Accuracy: 0.6724\n",
      "Training loss (for one batch) at step 40: 412.1302, Accuracy: 0.6881\n",
      "Training loss (for one batch) at step 50: 418.5478, Accuracy: 0.6975\n",
      "Training loss (for one batch) at step 60: 423.6362, Accuracy: 0.7027\n",
      "Training loss (for one batch) at step 70: 433.8036, Accuracy: 0.7024\n",
      "Training loss (for one batch) at step 80: 440.4341, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 90: 437.8572, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 100: 434.0922, Accuracy: 0.6858\n",
      "Training loss (for one batch) at step 110: 432.0482, Accuracy: 0.6869\n",
      "---- Training ----\n",
      "Training loss: 136.1778\n",
      "Training acc over epoch: 0.6877\n",
      "---- Validation ----\n",
      "Validation loss: 34.7781\n",
      "Validation acc: 0.7088\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 440.4658, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 440.6674, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 433.5442, Accuracy: 0.6849\n",
      "Training loss (for one batch) at step 30: 431.7520, Accuracy: 0.6845\n",
      "Training loss (for one batch) at step 40: 427.7717, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 50: 427.2786, Accuracy: 0.7048\n",
      "Training loss (for one batch) at step 60: 432.5891, Accuracy: 0.7136\n",
      "Training loss (for one batch) at step 70: 442.8377, Accuracy: 0.7167\n",
      "Training loss (for one batch) at step 80: 442.2131, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 90: 434.6124, Accuracy: 0.7050\n",
      "Training loss (for one batch) at step 100: 440.4659, Accuracy: 0.7028\n",
      "Training loss (for one batch) at step 110: 431.9291, Accuracy: 0.7044\n",
      "---- Training ----\n",
      "Training loss: 136.8522\n",
      "Training acc over epoch: 0.7044\n",
      "---- Validation ----\n",
      "Validation loss: 35.5649\n",
      "Validation acc: 0.7195\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 442.1568, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 442.0879, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 438.0503, Accuracy: 0.7214\n",
      "Training loss (for one batch) at step 30: 424.3300, Accuracy: 0.7334\n",
      "Training loss (for one batch) at step 40: 425.4297, Accuracy: 0.7401\n",
      "Training loss (for one batch) at step 50: 419.0841, Accuracy: 0.7512\n",
      "Training loss (for one batch) at step 60: 416.7627, Accuracy: 0.7554\n",
      "Training loss (for one batch) at step 70: 444.2698, Accuracy: 0.7525\n",
      "Training loss (for one batch) at step 80: 430.7357, Accuracy: 0.7419\n",
      "Training loss (for one batch) at step 90: 435.2961, Accuracy: 0.7343\n",
      "Training loss (for one batch) at step 100: 431.0568, Accuracy: 0.7309\n",
      "Training loss (for one batch) at step 110: 432.5956, Accuracy: 0.7309\n",
      "---- Training ----\n",
      "Training loss: 140.3428\n",
      "Training acc over epoch: 0.7314\n",
      "---- Validation ----\n",
      "Validation loss: 35.5649\n",
      "Validation acc: 0.7397\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 447.3416, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 435.9804, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 437.3178, Accuracy: 0.7292\n",
      "Training loss (for one batch) at step 30: 422.7714, Accuracy: 0.7424\n",
      "Training loss (for one batch) at step 40: 424.9321, Accuracy: 0.7475\n",
      "Training loss (for one batch) at step 50: 413.5835, Accuracy: 0.7567\n",
      "Training loss (for one batch) at step 60: 419.6744, Accuracy: 0.7617\n",
      "Training loss (for one batch) at step 70: 422.3072, Accuracy: 0.7601\n",
      "Training loss (for one batch) at step 80: 435.9897, Accuracy: 0.7502\n",
      "Training loss (for one batch) at step 90: 431.4669, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 100: 434.3433, Accuracy: 0.7441\n",
      "Training loss (for one batch) at step 110: 425.8716, Accuracy: 0.7456\n",
      "---- Training ----\n",
      "Training loss: 137.7922\n",
      "Training acc over epoch: 0.7443\n",
      "---- Validation ----\n",
      "Validation loss: 34.9191\n",
      "Validation acc: 0.7045\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 447.9163, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 434.8661, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 20: 433.0590, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 30: 419.2433, Accuracy: 0.7319\n",
      "Training loss (for one batch) at step 40: 404.4177, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 50: 412.9639, Accuracy: 0.7561\n",
      "Training loss (for one batch) at step 60: 428.7418, Accuracy: 0.7624\n",
      "Training loss (for one batch) at step 70: 431.1490, Accuracy: 0.7616\n",
      "Training loss (for one batch) at step 80: 424.5350, Accuracy: 0.7516\n",
      "Training loss (for one batch) at step 90: 432.8676, Accuracy: 0.7445\n",
      "Training loss (for one batch) at step 100: 418.0734, Accuracy: 0.7420\n",
      "Training loss (for one batch) at step 110: 428.0932, Accuracy: 0.7423\n",
      "---- Training ----\n",
      "Training loss: 133.3131\n",
      "Training acc over epoch: 0.7428\n",
      "---- Validation ----\n",
      "Validation loss: 36.6255\n",
      "Validation acc: 0.7235\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 437.2718, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 425.9458, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 433.0856, Accuracy: 0.7106\n",
      "Training loss (for one batch) at step 30: 423.7068, Accuracy: 0.7293\n",
      "Training loss (for one batch) at step 40: 410.1112, Accuracy: 0.7378\n",
      "Training loss (for one batch) at step 50: 388.7295, Accuracy: 0.7547\n",
      "Training loss (for one batch) at step 60: 420.9440, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 70: 434.3068, Accuracy: 0.7554\n",
      "Training loss (for one batch) at step 80: 435.2060, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 90: 433.3850, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 100: 428.1563, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 110: 427.7563, Accuracy: 0.7408\n",
      "---- Training ----\n",
      "Training loss: 130.7950\n",
      "Training acc over epoch: 0.7408\n",
      "---- Validation ----\n",
      "Validation loss: 34.9830\n",
      "Validation acc: 0.7397\n",
      "Time taken: 10.83s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 434.8342, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 429.1376, Accuracy: 0.7337\n",
      "Training loss (for one batch) at step 20: 428.6828, Accuracy: 0.7299\n",
      "Training loss (for one batch) at step 30: 414.6375, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 40: 393.7417, Accuracy: 0.7538\n",
      "Training loss (for one batch) at step 50: 384.5228, Accuracy: 0.7695\n",
      "Training loss (for one batch) at step 60: 408.2842, Accuracy: 0.7789\n",
      "Training loss (for one batch) at step 70: 435.7035, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 80: 428.6842, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 90: 423.2098, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 100: 421.9576, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 110: 425.7077, Accuracy: 0.7519\n",
      "---- Training ----\n",
      "Training loss: 135.8291\n",
      "Training acc over epoch: 0.7520\n",
      "---- Validation ----\n",
      "Validation loss: 35.8555\n",
      "Validation acc: 0.7289\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 440.3623, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 435.8879, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 421.9769, Accuracy: 0.7347\n",
      "Training loss (for one batch) at step 30: 417.2587, Accuracy: 0.7440\n",
      "Training loss (for one batch) at step 40: 401.6511, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 50: 395.4772, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 60: 402.4015, Accuracy: 0.7714\n",
      "Training loss (for one batch) at step 70: 415.7409, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 80: 440.9425, Accuracy: 0.7537\n",
      "Training loss (for one batch) at step 90: 415.4378, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 100: 423.5108, Accuracy: 0.7498\n",
      "Training loss (for one batch) at step 110: 420.6858, Accuracy: 0.7498\n",
      "---- Training ----\n",
      "Training loss: 131.8507\n",
      "Training acc over epoch: 0.7487\n",
      "---- Validation ----\n",
      "Validation loss: 38.3421\n",
      "Validation acc: 0.7367\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 440.3904, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 434.3238, Accuracy: 0.7507\n",
      "Training loss (for one batch) at step 20: 418.3323, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 30: 417.8126, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 40: 393.9969, Accuracy: 0.7569\n",
      "Training loss (for one batch) at step 50: 368.9238, Accuracy: 0.7718\n",
      "Training loss (for one batch) at step 60: 399.5640, Accuracy: 0.7798\n",
      "Training loss (for one batch) at step 70: 422.4206, Accuracy: 0.7740\n",
      "Training loss (for one batch) at step 80: 429.1440, Accuracy: 0.7639\n",
      "Training loss (for one batch) at step 90: 424.1262, Accuracy: 0.7565\n",
      "Training loss (for one batch) at step 100: 411.0957, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 110: 414.7399, Accuracy: 0.7543\n",
      "---- Training ----\n",
      "Training loss: 132.8234\n",
      "Training acc over epoch: 0.7540\n",
      "---- Validation ----\n",
      "Validation loss: 38.5545\n",
      "Validation acc: 0.7149\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 432.0266, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 428.9034, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 20: 419.8425, Accuracy: 0.7173\n",
      "Training loss (for one batch) at step 30: 390.2646, Accuracy: 0.7326\n",
      "Training loss (for one batch) at step 40: 377.5999, Accuracy: 0.7483\n",
      "Training loss (for one batch) at step 50: 383.5684, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 60: 393.8123, Accuracy: 0.7766\n",
      "Training loss (for one batch) at step 70: 401.3826, Accuracy: 0.7709\n",
      "Training loss (for one batch) at step 80: 414.1314, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 90: 407.5120, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 100: 414.6076, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 110: 419.8102, Accuracy: 0.7485\n",
      "---- Training ----\n",
      "Training loss: 130.5335\n",
      "Training acc over epoch: 0.7499\n",
      "---- Validation ----\n",
      "Validation loss: 37.0253\n",
      "Validation acc: 0.7171\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 439.6497, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 432.9264, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 20: 417.6054, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 30: 399.1720, Accuracy: 0.7374\n",
      "Training loss (for one batch) at step 40: 385.7563, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 50: 356.8387, Accuracy: 0.7724\n",
      "Training loss (for one batch) at step 60: 410.5070, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 70: 405.9761, Accuracy: 0.7774\n",
      "Training loss (for one batch) at step 80: 425.6968, Accuracy: 0.7633\n",
      "Training loss (for one batch) at step 90: 407.0643, Accuracy: 0.7561\n",
      "Training loss (for one batch) at step 100: 404.1245, Accuracy: 0.7570\n",
      "Training loss (for one batch) at step 110: 413.8607, Accuracy: 0.7570\n",
      "---- Training ----\n",
      "Training loss: 127.3013\n",
      "Training acc over epoch: 0.7548\n",
      "---- Validation ----\n",
      "Validation loss: 38.0292\n",
      "Validation acc: 0.7085\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 438.9405, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 422.8799, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 20: 401.4820, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 30: 395.3622, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 40: 383.2461, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 50: 362.5087, Accuracy: 0.7737\n",
      "Training loss (for one batch) at step 60: 403.5396, Accuracy: 0.7830\n",
      "Training loss (for one batch) at step 70: 422.9521, Accuracy: 0.7764\n",
      "Training loss (for one batch) at step 80: 411.8651, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 90: 410.3677, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 100: 410.1355, Accuracy: 0.7610\n",
      "Training loss (for one batch) at step 110: 412.2073, Accuracy: 0.7599\n",
      "---- Training ----\n",
      "Training loss: 134.3671\n",
      "Training acc over epoch: 0.7596\n",
      "---- Validation ----\n",
      "Validation loss: 48.1199\n",
      "Validation acc: 0.6816\n",
      "Time taken: 10.89s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 428.2376, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 418.0430, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 20: 399.9057, Accuracy: 0.7228\n",
      "Training loss (for one batch) at step 30: 378.6191, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 40: 366.1819, Accuracy: 0.7510\n",
      "Training loss (for one batch) at step 50: 362.0715, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 60: 390.6165, Accuracy: 0.7769\n",
      "Training loss (for one batch) at step 70: 398.7458, Accuracy: 0.7691\n",
      "Training loss (for one batch) at step 80: 406.5413, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 90: 396.3738, Accuracy: 0.7558\n",
      "Training loss (for one batch) at step 100: 400.4330, Accuracy: 0.7555\n",
      "Training loss (for one batch) at step 110: 407.6961, Accuracy: 0.7553\n",
      "---- Training ----\n",
      "Training loss: 128.6963\n",
      "Training acc over epoch: 0.7546\n",
      "---- Validation ----\n",
      "Validation loss: 36.3748\n",
      "Validation acc: 0.6881\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 424.7365, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 432.8747, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 20: 403.2009, Accuracy: 0.7161\n",
      "Training loss (for one batch) at step 30: 405.2551, Accuracy: 0.7394\n",
      "Training loss (for one batch) at step 40: 365.9915, Accuracy: 0.7595\n",
      "Training loss (for one batch) at step 50: 361.8954, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 60: 364.4862, Accuracy: 0.7851\n",
      "Training loss (for one batch) at step 70: 400.2100, Accuracy: 0.7748\n",
      "Training loss (for one batch) at step 80: 415.0763, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 90: 392.2386, Accuracy: 0.7602\n",
      "Training loss (for one batch) at step 100: 404.4983, Accuracy: 0.7591\n",
      "Training loss (for one batch) at step 110: 370.8770, Accuracy: 0.7602\n",
      "---- Training ----\n",
      "Training loss: 132.0395\n",
      "Training acc over epoch: 0.7601\n",
      "---- Validation ----\n",
      "Validation loss: 37.0389\n",
      "Validation acc: 0.6921\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 415.7745, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 404.1920, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 20: 413.1559, Accuracy: 0.7080\n",
      "Training loss (for one batch) at step 30: 375.7648, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 40: 349.6190, Accuracy: 0.7591\n",
      "Training loss (for one batch) at step 50: 350.8655, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 60: 363.2865, Accuracy: 0.7837\n",
      "Training loss (for one batch) at step 70: 394.1239, Accuracy: 0.7733\n",
      "Training loss (for one batch) at step 80: 421.3484, Accuracy: 0.7616\n",
      "Training loss (for one batch) at step 90: 394.9742, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 100: 401.8403, Accuracy: 0.7580\n",
      "Training loss (for one batch) at step 110: 386.0423, Accuracy: 0.7584\n",
      "---- Training ----\n",
      "Training loss: 120.6827\n",
      "Training acc over epoch: 0.7585\n",
      "---- Validation ----\n",
      "Validation loss: 45.2765\n",
      "Validation acc: 0.7015\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 429.3513, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 434.4718, Accuracy: 0.7074\n",
      "Training loss (for one batch) at step 20: 383.5649, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 30: 362.7423, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 40: 363.8133, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 50: 360.3572, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 60: 368.2904, Accuracy: 0.7875\n",
      "Training loss (for one batch) at step 70: 366.0718, Accuracy: 0.7770\n",
      "Training loss (for one batch) at step 80: 381.9332, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 90: 394.6499, Accuracy: 0.7570\n",
      "Training loss (for one batch) at step 100: 383.1149, Accuracy: 0.7586\n",
      "Training loss (for one batch) at step 110: 373.9211, Accuracy: 0.7594\n",
      "---- Training ----\n",
      "Training loss: 121.6572\n",
      "Training acc over epoch: 0.7585\n",
      "---- Validation ----\n",
      "Validation loss: 37.5363\n",
      "Validation acc: 0.6738\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 413.5936, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 401.9458, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 20: 368.7539, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 364.7624, Accuracy: 0.7311\n",
      "Training loss (for one batch) at step 40: 350.6248, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 50: 351.5127, Accuracy: 0.7737\n",
      "Training loss (for one batch) at step 60: 339.2434, Accuracy: 0.7838\n",
      "Training loss (for one batch) at step 70: 399.3239, Accuracy: 0.7767\n",
      "Training loss (for one batch) at step 80: 393.5477, Accuracy: 0.7625\n",
      "Training loss (for one batch) at step 90: 376.3004, Accuracy: 0.7567\n",
      "Training loss (for one batch) at step 100: 387.9096, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 110: 390.0892, Accuracy: 0.7566\n",
      "---- Training ----\n",
      "Training loss: 117.9499\n",
      "Training acc over epoch: 0.7556\n",
      "---- Validation ----\n",
      "Validation loss: 34.2978\n",
      "Validation acc: 0.6969\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 426.1739, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 399.0332, Accuracy: 0.6861\n",
      "Training loss (for one batch) at step 20: 374.3798, Accuracy: 0.7068\n",
      "Training loss (for one batch) at step 30: 364.2199, Accuracy: 0.7389\n",
      "Training loss (for one batch) at step 40: 353.4256, Accuracy: 0.7668\n",
      "Training loss (for one batch) at step 50: 341.0351, Accuracy: 0.7808\n",
      "Training loss (for one batch) at step 60: 357.0765, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 70: 373.6772, Accuracy: 0.7766\n",
      "Training loss (for one batch) at step 80: 393.5078, Accuracy: 0.7620\n",
      "Training loss (for one batch) at step 90: 385.7133, Accuracy: 0.7576\n",
      "Training loss (for one batch) at step 100: 385.3750, Accuracy: 0.7577\n",
      "Training loss (for one batch) at step 110: 367.7590, Accuracy: 0.7583\n",
      "---- Training ----\n",
      "Training loss: 112.8928\n",
      "Training acc over epoch: 0.7575\n",
      "---- Validation ----\n",
      "Validation loss: 35.6536\n",
      "Validation acc: 0.6867\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 424.7715, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 391.4185, Accuracy: 0.6861\n",
      "Training loss (for one batch) at step 20: 382.6035, Accuracy: 0.7054\n",
      "Training loss (for one batch) at step 30: 344.7494, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 40: 349.2183, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 50: 339.2855, Accuracy: 0.7728\n",
      "Training loss (for one batch) at step 60: 353.2903, Accuracy: 0.7825\n",
      "Training loss (for one batch) at step 70: 380.4801, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 80: 382.1251, Accuracy: 0.7591\n",
      "Training loss (for one batch) at step 90: 382.1582, Accuracy: 0.7544\n",
      "Training loss (for one batch) at step 100: 383.5331, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 110: 370.9605, Accuracy: 0.7577\n",
      "---- Training ----\n",
      "Training loss: 120.1247\n",
      "Training acc over epoch: 0.7556\n",
      "---- Validation ----\n",
      "Validation loss: 35.8741\n",
      "Validation acc: 0.6789\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 407.8040, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 394.4341, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 20: 370.7018, Accuracy: 0.6897\n",
      "Training loss (for one batch) at step 30: 358.7463, Accuracy: 0.7261\n",
      "Training loss (for one batch) at step 40: 341.1338, Accuracy: 0.7582\n",
      "Training loss (for one batch) at step 50: 316.8876, Accuracy: 0.7768\n",
      "Training loss (for one batch) at step 60: 357.2090, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 70: 377.8008, Accuracy: 0.7707\n",
      "Training loss (for one batch) at step 80: 395.5926, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 90: 383.5096, Accuracy: 0.7520\n",
      "Training loss (for one batch) at step 100: 359.8612, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 110: 383.8071, Accuracy: 0.7553\n",
      "---- Training ----\n",
      "Training loss: 119.0512\n",
      "Training acc over epoch: 0.7549\n",
      "---- Validation ----\n",
      "Validation loss: 39.4673\n",
      "Validation acc: 0.7034\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 406.1148, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 405.0472, Accuracy: 0.6747\n",
      "Training loss (for one batch) at step 20: 371.2697, Accuracy: 0.6942\n",
      "Training loss (for one batch) at step 30: 353.5722, Accuracy: 0.7324\n",
      "Training loss (for one batch) at step 40: 338.2708, Accuracy: 0.7555\n",
      "Training loss (for one batch) at step 50: 325.6699, Accuracy: 0.7759\n",
      "Training loss (for one batch) at step 60: 352.3788, Accuracy: 0.7832\n",
      "Training loss (for one batch) at step 70: 368.4399, Accuracy: 0.7746\n",
      "Training loss (for one batch) at step 80: 385.2793, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 90: 351.9464, Accuracy: 0.7547\n",
      "Training loss (for one batch) at step 100: 384.6660, Accuracy: 0.7558\n",
      "Training loss (for one batch) at step 110: 386.6248, Accuracy: 0.7561\n",
      "---- Training ----\n",
      "Training loss: 118.1927\n",
      "Training acc over epoch: 0.7571\n",
      "---- Validation ----\n",
      "Validation loss: 54.7896\n",
      "Validation acc: 0.6894\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 395.8232, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 387.6249, Accuracy: 0.6847\n",
      "Training loss (for one batch) at step 20: 352.1743, Accuracy: 0.7106\n",
      "Training loss (for one batch) at step 30: 357.8427, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 40: 348.7382, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 50: 328.7385, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 60: 324.6391, Accuracy: 0.7873\n",
      "Training loss (for one batch) at step 70: 382.4051, Accuracy: 0.7757\n",
      "Training loss (for one batch) at step 80: 404.1859, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 90: 367.0892, Accuracy: 0.7565\n",
      "Training loss (for one batch) at step 100: 379.4570, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 110: 364.4953, Accuracy: 0.7571\n",
      "---- Training ----\n",
      "Training loss: 117.7169\n",
      "Training acc over epoch: 0.7562\n",
      "---- Validation ----\n",
      "Validation loss: 38.7017\n",
      "Validation acc: 0.6875\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 400.4454, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 378.8763, Accuracy: 0.6655\n",
      "Training loss (for one batch) at step 20: 363.7851, Accuracy: 0.6908\n",
      "Training loss (for one batch) at step 30: 333.8701, Accuracy: 0.7225\n",
      "Training loss (for one batch) at step 40: 331.3180, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 50: 311.6726, Accuracy: 0.7745\n",
      "Training loss (for one batch) at step 60: 341.6155, Accuracy: 0.7811\n",
      "Training loss (for one batch) at step 70: 379.0770, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 80: 398.6470, Accuracy: 0.7534\n",
      "Training loss (for one batch) at step 90: 358.4930, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 100: 366.7733, Accuracy: 0.7511\n",
      "Training loss (for one batch) at step 110: 358.6108, Accuracy: 0.7522\n",
      "---- Training ----\n",
      "Training loss: 116.4243\n",
      "Training acc over epoch: 0.7514\n",
      "---- Validation ----\n",
      "Validation loss: 35.8243\n",
      "Validation acc: 0.6800\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 405.6025, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 384.2126, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 20: 363.1237, Accuracy: 0.6961\n",
      "Training loss (for one batch) at step 30: 350.1344, Accuracy: 0.7278\n",
      "Training loss (for one batch) at step 40: 326.5364, Accuracy: 0.7525\n",
      "Training loss (for one batch) at step 50: 329.1800, Accuracy: 0.7691\n",
      "Training loss (for one batch) at step 60: 335.4897, Accuracy: 0.7793\n",
      "Training loss (for one batch) at step 70: 361.6130, Accuracy: 0.7665\n",
      "Training loss (for one batch) at step 80: 377.8673, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 90: 366.7981, Accuracy: 0.7468\n",
      "Training loss (for one batch) at step 100: 348.2627, Accuracy: 0.7498\n",
      "Training loss (for one batch) at step 110: 371.3337, Accuracy: 0.7494\n",
      "---- Training ----\n",
      "Training loss: 111.9077\n",
      "Training acc over epoch: 0.7495\n",
      "---- Validation ----\n",
      "Validation loss: 38.8421\n",
      "Validation acc: 0.6800\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 415.0876, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 379.0087, Accuracy: 0.6491\n",
      "Training loss (for one batch) at step 20: 341.3399, Accuracy: 0.6838\n",
      "Training loss (for one batch) at step 30: 322.5186, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 40: 333.7507, Accuracy: 0.7555\n",
      "Training loss (for one batch) at step 50: 318.4964, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 60: 351.3430, Accuracy: 0.7833\n",
      "Training loss (for one batch) at step 70: 375.3771, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 80: 381.4159, Accuracy: 0.7549\n",
      "Training loss (for one batch) at step 90: 362.1877, Accuracy: 0.7499\n",
      "Training loss (for one batch) at step 100: 334.7611, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 110: 360.3802, Accuracy: 0.7539\n",
      "---- Training ----\n",
      "Training loss: 110.4973\n",
      "Training acc over epoch: 0.7524\n",
      "---- Validation ----\n",
      "Validation loss: 35.7634\n",
      "Validation acc: 0.7012\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 379.4591, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 376.2955, Accuracy: 0.6506\n",
      "Training loss (for one batch) at step 20: 334.4434, Accuracy: 0.6998\n",
      "Training loss (for one batch) at step 30: 328.5406, Accuracy: 0.7298\n",
      "Training loss (for one batch) at step 40: 324.7988, Accuracy: 0.7565\n",
      "Training loss (for one batch) at step 50: 308.6462, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 60: 335.7285, Accuracy: 0.7825\n",
      "Training loss (for one batch) at step 70: 333.0808, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 80: 366.4905, Accuracy: 0.7554\n",
      "Training loss (for one batch) at step 90: 334.3988, Accuracy: 0.7497\n",
      "Training loss (for one batch) at step 100: 333.9571, Accuracy: 0.7526\n",
      "Training loss (for one batch) at step 110: 343.7299, Accuracy: 0.7559\n",
      "---- Training ----\n",
      "Training loss: 110.4655\n",
      "Training acc over epoch: 0.7542\n",
      "---- Validation ----\n",
      "Validation loss: 48.2160\n",
      "Validation acc: 0.6832\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 385.5193, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 367.3944, Accuracy: 0.6456\n",
      "Training loss (for one batch) at step 20: 353.7444, Accuracy: 0.6827\n",
      "Training loss (for one batch) at step 30: 332.8009, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 40: 322.6817, Accuracy: 0.7517\n",
      "Training loss (for one batch) at step 50: 306.9264, Accuracy: 0.7704\n",
      "Training loss (for one batch) at step 60: 347.1927, Accuracy: 0.7797\n",
      "Training loss (for one batch) at step 70: 367.9600, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 80: 369.3104, Accuracy: 0.7502\n",
      "Training loss (for one batch) at step 90: 341.0733, Accuracy: 0.7461\n",
      "Training loss (for one batch) at step 100: 344.2676, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 110: 345.5571, Accuracy: 0.7511\n",
      "---- Training ----\n",
      "Training loss: 113.9445\n",
      "Training acc over epoch: 0.7501\n",
      "---- Validation ----\n",
      "Validation loss: 33.8472\n",
      "Validation acc: 0.6814\n",
      "Time taken: 10.69s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6728\n",
      "Validation AUC: 0.6742\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 655.1083, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 609.5258, Accuracy: 0.4964\n",
      "Training loss (for one batch) at step 20: 584.9594, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 30: 527.5427, Accuracy: 0.5063\n",
      "Training loss (for one batch) at step 40: 522.2303, Accuracy: 0.5147\n",
      "Training loss (for one batch) at step 50: 500.8808, Accuracy: 0.5210\n",
      "Training loss (for one batch) at step 60: 522.3798, Accuracy: 0.5158\n",
      "Training loss (for one batch) at step 70: 486.6430, Accuracy: 0.5172\n",
      "Training loss (for one batch) at step 80: 507.1162, Accuracy: 0.5195\n",
      "Training loss (for one batch) at step 90: 474.1584, Accuracy: 0.5222\n",
      "Training loss (for one batch) at step 100: 483.2015, Accuracy: 0.5238\n",
      "Training loss (for one batch) at step 110: 482.7535, Accuracy: 0.5216\n",
      "---- Training ----\n",
      "Training loss: 153.8320\n",
      "Training acc over epoch: 0.5214\n",
      "---- Validation ----\n",
      "Validation loss: 34.9612\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.38s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 482.7252, Accuracy: 0.3984\n",
      "Training loss (for one batch) at step 10: 474.2322, Accuracy: 0.5170\n",
      "Training loss (for one batch) at step 20: 458.5469, Accuracy: 0.5175\n",
      "Training loss (for one batch) at step 30: 459.0482, Accuracy: 0.5134\n",
      "Training loss (for one batch) at step 40: 453.4939, Accuracy: 0.5177\n",
      "Training loss (for one batch) at step 50: 450.2673, Accuracy: 0.5193\n",
      "Training loss (for one batch) at step 60: 451.1777, Accuracy: 0.5238\n",
      "Training loss (for one batch) at step 70: 464.1758, Accuracy: 0.5249\n",
      "Training loss (for one batch) at step 80: 450.2458, Accuracy: 0.5266\n",
      "Training loss (for one batch) at step 90: 454.0736, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 100: 447.0078, Accuracy: 0.5241\n",
      "Training loss (for one batch) at step 110: 449.8666, Accuracy: 0.5250\n",
      "---- Training ----\n",
      "Training loss: 137.4602\n",
      "Training acc over epoch: 0.5262\n",
      "---- Validation ----\n",
      "Validation loss: 34.6949\n",
      "Validation acc: 0.5073\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 450.2497, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 450.7068, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 20: 447.8996, Accuracy: 0.5134\n",
      "Training loss (for one batch) at step 30: 446.4604, Accuracy: 0.5300\n",
      "Training loss (for one batch) at step 40: 448.3263, Accuracy: 0.5316\n",
      "Training loss (for one batch) at step 50: 446.5029, Accuracy: 0.5302\n",
      "Training loss (for one batch) at step 60: 443.7567, Accuracy: 0.5301\n",
      "Training loss (for one batch) at step 70: 448.1917, Accuracy: 0.5354\n",
      "Training loss (for one batch) at step 80: 449.3867, Accuracy: 0.5425\n",
      "Training loss (for one batch) at step 90: 447.2762, Accuracy: 0.5432\n",
      "Training loss (for one batch) at step 100: 445.5681, Accuracy: 0.5429\n",
      "Training loss (for one batch) at step 110: 447.0595, Accuracy: 0.5423\n",
      "---- Training ----\n",
      "Training loss: 139.2996\n",
      "Training acc over epoch: 0.5412\n",
      "---- Validation ----\n",
      "Validation loss: 34.5607\n",
      "Validation acc: 0.5403\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 448.0530, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 446.9310, Accuracy: 0.5568\n",
      "Training loss (for one batch) at step 20: 445.6821, Accuracy: 0.5618\n",
      "Training loss (for one batch) at step 30: 445.9356, Accuracy: 0.5620\n",
      "Training loss (for one batch) at step 40: 443.4986, Accuracy: 0.5659\n",
      "Training loss (for one batch) at step 50: 443.7649, Accuracy: 0.5648\n",
      "Training loss (for one batch) at step 60: 446.3724, Accuracy: 0.5678\n",
      "Training loss (for one batch) at step 70: 446.7554, Accuracy: 0.5709\n",
      "Training loss (for one batch) at step 80: 445.8983, Accuracy: 0.5735\n",
      "Training loss (for one batch) at step 90: 443.9168, Accuracy: 0.5726\n",
      "Training loss (for one batch) at step 100: 441.6908, Accuracy: 0.5710\n",
      "Training loss (for one batch) at step 110: 444.4498, Accuracy: 0.5705\n",
      "---- Training ----\n",
      "Training loss: 139.1694\n",
      "Training acc over epoch: 0.5719\n",
      "---- Validation ----\n",
      "Validation loss: 34.5388\n",
      "Validation acc: 0.6064\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 445.1448, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 444.1074, Accuracy: 0.5795\n",
      "Training loss (for one batch) at step 20: 441.0981, Accuracy: 0.5830\n",
      "Training loss (for one batch) at step 30: 442.8265, Accuracy: 0.5902\n",
      "Training loss (for one batch) at step 40: 444.0487, Accuracy: 0.5913\n",
      "Training loss (for one batch) at step 50: 439.6148, Accuracy: 0.5924\n",
      "Training loss (for one batch) at step 60: 443.2449, Accuracy: 0.5889\n",
      "Training loss (for one batch) at step 70: 444.6509, Accuracy: 0.5928\n",
      "Training loss (for one batch) at step 80: 445.1758, Accuracy: 0.5992\n",
      "Training loss (for one batch) at step 90: 444.0050, Accuracy: 0.6005\n",
      "Training loss (for one batch) at step 100: 441.9503, Accuracy: 0.5963\n",
      "Training loss (for one batch) at step 110: 441.6855, Accuracy: 0.5960\n",
      "---- Training ----\n",
      "Training loss: 139.1675\n",
      "Training acc over epoch: 0.5963\n",
      "---- Validation ----\n",
      "Validation loss: 34.7157\n",
      "Validation acc: 0.6408\n",
      "Time taken: 10.93s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.0033, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 444.2480, Accuracy: 0.5966\n",
      "Training loss (for one batch) at step 20: 442.7067, Accuracy: 0.6008\n",
      "Training loss (for one batch) at step 30: 439.3786, Accuracy: 0.6038\n",
      "Training loss (for one batch) at step 40: 441.0304, Accuracy: 0.6067\n",
      "Training loss (for one batch) at step 50: 442.2788, Accuracy: 0.6097\n",
      "Training loss (for one batch) at step 60: 442.0178, Accuracy: 0.6119\n",
      "Training loss (for one batch) at step 70: 443.1569, Accuracy: 0.6164\n",
      "Training loss (for one batch) at step 80: 442.8440, Accuracy: 0.6194\n",
      "Training loss (for one batch) at step 90: 443.1532, Accuracy: 0.6178\n",
      "Training loss (for one batch) at step 100: 438.7806, Accuracy: 0.6153\n",
      "Training loss (for one batch) at step 110: 440.7628, Accuracy: 0.6146\n",
      "---- Training ----\n",
      "Training loss: 137.9819\n",
      "Training acc over epoch: 0.6170\n",
      "---- Validation ----\n",
      "Validation loss: 35.0214\n",
      "Validation acc: 0.6564\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 444.8964, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 443.0636, Accuracy: 0.6214\n",
      "Training loss (for one batch) at step 20: 442.8007, Accuracy: 0.6209\n",
      "Training loss (for one batch) at step 30: 439.3377, Accuracy: 0.6280\n",
      "Training loss (for one batch) at step 40: 439.8992, Accuracy: 0.6280\n",
      "Training loss (for one batch) at step 50: 437.0629, Accuracy: 0.6279\n",
      "Training loss (for one batch) at step 60: 443.3696, Accuracy: 0.6269\n",
      "Training loss (for one batch) at step 70: 442.4517, Accuracy: 0.6307\n",
      "Training loss (for one batch) at step 80: 444.7415, Accuracy: 0.6356\n",
      "Training loss (for one batch) at step 90: 440.9224, Accuracy: 0.6354\n",
      "Training loss (for one batch) at step 100: 440.3090, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 110: 443.7231, Accuracy: 0.6344\n",
      "---- Training ----\n",
      "Training loss: 136.9827\n",
      "Training acc over epoch: 0.6342\n",
      "---- Validation ----\n",
      "Validation loss: 34.3606\n",
      "Validation acc: 0.6518\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.0890, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 442.7571, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 20: 443.2162, Accuracy: 0.6518\n",
      "Training loss (for one batch) at step 30: 441.1786, Accuracy: 0.6580\n",
      "Training loss (for one batch) at step 40: 438.0181, Accuracy: 0.6620\n",
      "Training loss (for one batch) at step 50: 436.2500, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 60: 441.4398, Accuracy: 0.6603\n",
      "Training loss (for one batch) at step 70: 447.4944, Accuracy: 0.6646\n",
      "Training loss (for one batch) at step 80: 443.4436, Accuracy: 0.6616\n",
      "Training loss (for one batch) at step 90: 438.0673, Accuracy: 0.6602\n",
      "Training loss (for one batch) at step 100: 439.6555, Accuracy: 0.6602\n",
      "Training loss (for one batch) at step 110: 442.1499, Accuracy: 0.6591\n",
      "---- Training ----\n",
      "Training loss: 139.2828\n",
      "Training acc over epoch: 0.6590\n",
      "---- Validation ----\n",
      "Validation loss: 34.1951\n",
      "Validation acc: 0.6341\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 441.0038, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 445.1284, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 20: 437.1516, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 30: 432.8430, Accuracy: 0.6661\n",
      "Training loss (for one batch) at step 40: 438.1204, Accuracy: 0.6709\n",
      "Training loss (for one batch) at step 50: 436.0823, Accuracy: 0.6700\n",
      "Training loss (for one batch) at step 60: 440.8801, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 70: 443.8861, Accuracy: 0.6775\n",
      "Training loss (for one batch) at step 80: 444.2924, Accuracy: 0.6747\n",
      "Training loss (for one batch) at step 90: 438.1333, Accuracy: 0.6713\n",
      "Training loss (for one batch) at step 100: 440.8331, Accuracy: 0.6689\n",
      "Training loss (for one batch) at step 110: 435.6510, Accuracy: 0.6687\n",
      "---- Training ----\n",
      "Training loss: 139.2996\n",
      "Training acc over epoch: 0.6672\n",
      "---- Validation ----\n",
      "Validation loss: 34.9181\n",
      "Validation acc: 0.6502\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 443.0095, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 442.1661, Accuracy: 0.6541\n",
      "Training loss (for one batch) at step 20: 437.6146, Accuracy: 0.6834\n",
      "Training loss (for one batch) at step 30: 439.6659, Accuracy: 0.6757\n",
      "Training loss (for one batch) at step 40: 424.5541, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 50: 431.5096, Accuracy: 0.6832\n",
      "Training loss (for one batch) at step 60: 432.1054, Accuracy: 0.6888\n",
      "Training loss (for one batch) at step 70: 441.7839, Accuracy: 0.6881\n",
      "Training loss (for one batch) at step 80: 444.9549, Accuracy: 0.6854\n",
      "Training loss (for one batch) at step 90: 438.0300, Accuracy: 0.6837\n",
      "Training loss (for one batch) at step 100: 437.8253, Accuracy: 0.6848\n",
      "Training loss (for one batch) at step 110: 440.2465, Accuracy: 0.6857\n",
      "---- Training ----\n",
      "Training loss: 134.3957\n",
      "Training acc over epoch: 0.6863\n",
      "---- Validation ----\n",
      "Validation loss: 34.2358\n",
      "Validation acc: 0.6975\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 437.1685, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 436.2984, Accuracy: 0.7003\n",
      "Training loss (for one batch) at step 20: 437.2309, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 30: 437.2929, Accuracy: 0.6915\n",
      "Training loss (for one batch) at step 40: 430.0138, Accuracy: 0.6982\n",
      "Training loss (for one batch) at step 50: 434.3479, Accuracy: 0.7004\n",
      "Training loss (for one batch) at step 60: 431.2998, Accuracy: 0.7082\n",
      "Training loss (for one batch) at step 70: 447.6302, Accuracy: 0.7114\n",
      "Training loss (for one batch) at step 80: 442.6404, Accuracy: 0.7077\n",
      "Training loss (for one batch) at step 90: 437.0635, Accuracy: 0.7056\n",
      "Training loss (for one batch) at step 100: 435.9095, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 110: 433.0599, Accuracy: 0.7054\n",
      "---- Training ----\n",
      "Training loss: 136.3220\n",
      "Training acc over epoch: 0.7065\n",
      "---- Validation ----\n",
      "Validation loss: 34.1644\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 447.6630, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 441.3945, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 20: 435.6776, Accuracy: 0.6938\n",
      "Training loss (for one batch) at step 30: 431.7000, Accuracy: 0.7051\n",
      "Training loss (for one batch) at step 40: 421.4230, Accuracy: 0.7121\n",
      "Training loss (for one batch) at step 50: 422.4123, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 60: 439.7410, Accuracy: 0.7208\n",
      "Training loss (for one batch) at step 70: 445.5132, Accuracy: 0.7207\n",
      "Training loss (for one batch) at step 80: 437.5361, Accuracy: 0.7160\n",
      "Training loss (for one batch) at step 90: 436.2083, Accuracy: 0.7153\n",
      "Training loss (for one batch) at step 100: 434.1862, Accuracy: 0.7171\n",
      "Training loss (for one batch) at step 110: 441.8471, Accuracy: 0.7178\n",
      "---- Training ----\n",
      "Training loss: 134.1849\n",
      "Training acc over epoch: 0.7183\n",
      "---- Validation ----\n",
      "Validation loss: 36.1785\n",
      "Validation acc: 0.7337\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 449.4854, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 438.8075, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 20: 429.5754, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 30: 422.3572, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 40: 422.7248, Accuracy: 0.7367\n",
      "Training loss (for one batch) at step 50: 421.5580, Accuracy: 0.7463\n",
      "Training loss (for one batch) at step 60: 438.7286, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 70: 437.8129, Accuracy: 0.7454\n",
      "Training loss (for one batch) at step 80: 441.0353, Accuracy: 0.7397\n",
      "Training loss (for one batch) at step 90: 435.0269, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 100: 437.7112, Accuracy: 0.7342\n",
      "Training loss (for one batch) at step 110: 440.4930, Accuracy: 0.7376\n",
      "---- Training ----\n",
      "Training loss: 136.1395\n",
      "Training acc over epoch: 0.7393\n",
      "---- Validation ----\n",
      "Validation loss: 33.8650\n",
      "Validation acc: 0.7399\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 454.1792, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 440.0020, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 429.1388, Accuracy: 0.7340\n",
      "Training loss (for one batch) at step 30: 419.2559, Accuracy: 0.7427\n",
      "Training loss (for one batch) at step 40: 410.1525, Accuracy: 0.7464\n",
      "Training loss (for one batch) at step 50: 414.9760, Accuracy: 0.7537\n",
      "Training loss (for one batch) at step 60: 439.7307, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 70: 436.8145, Accuracy: 0.7513\n",
      "Training loss (for one batch) at step 80: 442.6349, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 90: 431.2799, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 100: 433.3100, Accuracy: 0.7448\n",
      "Training loss (for one batch) at step 110: 435.0003, Accuracy: 0.7449\n",
      "---- Training ----\n",
      "Training loss: 133.9571\n",
      "Training acc over epoch: 0.7464\n",
      "---- Validation ----\n",
      "Validation loss: 33.7932\n",
      "Validation acc: 0.7413\n",
      "Time taken: 12.46s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 447.7512, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 433.8958, Accuracy: 0.7514\n",
      "Training loss (for one batch) at step 20: 428.2785, Accuracy: 0.7459\n",
      "Training loss (for one batch) at step 30: 418.0861, Accuracy: 0.7596\n",
      "Training loss (for one batch) at step 40: 411.3960, Accuracy: 0.7633\n",
      "Training loss (for one batch) at step 50: 399.3837, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 60: 421.0718, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 70: 445.8911, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 80: 436.6073, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 90: 438.2259, Accuracy: 0.7636\n",
      "Training loss (for one batch) at step 100: 428.6879, Accuracy: 0.7629\n",
      "Training loss (for one batch) at step 110: 431.3634, Accuracy: 0.7625\n",
      "---- Training ----\n",
      "Training loss: 135.7492\n",
      "Training acc over epoch: 0.7612\n",
      "---- Validation ----\n",
      "Validation loss: 34.8824\n",
      "Validation acc: 0.7268\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 441.8326, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 438.4838, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 20: 428.9512, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 30: 419.4800, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 40: 405.8196, Accuracy: 0.7588\n",
      "Training loss (for one batch) at step 50: 392.3901, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 60: 422.0659, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 70: 443.9785, Accuracy: 0.7764\n",
      "Training loss (for one batch) at step 80: 436.4072, Accuracy: 0.7700\n",
      "Training loss (for one batch) at step 90: 435.1436, Accuracy: 0.7657\n",
      "Training loss (for one batch) at step 100: 427.7378, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 110: 431.8632, Accuracy: 0.7661\n",
      "---- Training ----\n",
      "Training loss: 135.8131\n",
      "Training acc over epoch: 0.7669\n",
      "---- Validation ----\n",
      "Validation loss: 34.5914\n",
      "Validation acc: 0.6905\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 453.3207, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 437.1949, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 20: 423.1328, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 30: 422.5781, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 40: 415.8045, Accuracy: 0.7466\n",
      "Training loss (for one batch) at step 50: 401.5978, Accuracy: 0.7572\n",
      "Training loss (for one batch) at step 60: 417.4270, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 70: 428.1497, Accuracy: 0.7713\n",
      "Training loss (for one batch) at step 80: 447.7888, Accuracy: 0.7677\n",
      "Training loss (for one batch) at step 90: 428.3351, Accuracy: 0.7625\n",
      "Training loss (for one batch) at step 100: 424.9019, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 110: 413.8022, Accuracy: 0.7637\n",
      "---- Training ----\n",
      "Training loss: 127.8375\n",
      "Training acc over epoch: 0.7641\n",
      "---- Validation ----\n",
      "Validation loss: 31.9668\n",
      "Validation acc: 0.7391\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 436.1857, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 431.9650, Accuracy: 0.7322\n",
      "Training loss (for one batch) at step 20: 428.2303, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 30: 421.1360, Accuracy: 0.7402\n",
      "Training loss (for one batch) at step 40: 411.2115, Accuracy: 0.7546\n",
      "Training loss (for one batch) at step 50: 408.9427, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 60: 416.2194, Accuracy: 0.7746\n",
      "Training loss (for one batch) at step 70: 427.7248, Accuracy: 0.7764\n",
      "Training loss (for one batch) at step 80: 439.2610, Accuracy: 0.7684\n",
      "Training loss (for one batch) at step 90: 432.0519, Accuracy: 0.7653\n",
      "Training loss (for one batch) at step 100: 418.5174, Accuracy: 0.7634\n",
      "Training loss (for one batch) at step 110: 420.2418, Accuracy: 0.7638\n",
      "---- Training ----\n",
      "Training loss: 131.7080\n",
      "Training acc over epoch: 0.7645\n",
      "---- Validation ----\n",
      "Validation loss: 39.4369\n",
      "Validation acc: 0.7004\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 453.0427, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 441.8227, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 20: 425.2040, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 30: 418.4249, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 40: 405.4594, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 50: 400.8889, Accuracy: 0.7817\n",
      "Training loss (for one batch) at step 60: 414.5137, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 70: 435.2426, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 80: 442.2491, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 90: 428.0016, Accuracy: 0.7752\n",
      "Training loss (for one batch) at step 100: 421.6624, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 110: 413.2260, Accuracy: 0.7741\n",
      "---- Training ----\n",
      "Training loss: 129.8472\n",
      "Training acc over epoch: 0.7741\n",
      "---- Validation ----\n",
      "Validation loss: 33.6713\n",
      "Validation acc: 0.7389\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 452.2182, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 434.2942, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 428.3275, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 30: 416.3383, Accuracy: 0.7581\n",
      "Training loss (for one batch) at step 40: 389.1708, Accuracy: 0.7704\n",
      "Training loss (for one batch) at step 50: 379.4084, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 60: 405.4737, Accuracy: 0.7953\n",
      "Training loss (for one batch) at step 70: 420.4279, Accuracy: 0.7953\n",
      "Training loss (for one batch) at step 80: 440.5455, Accuracy: 0.7854\n",
      "Training loss (for one batch) at step 90: 438.1042, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 100: 432.6052, Accuracy: 0.7786\n",
      "Training loss (for one batch) at step 110: 423.7582, Accuracy: 0.7791\n",
      "---- Training ----\n",
      "Training loss: 136.9239\n",
      "Training acc over epoch: 0.7783\n",
      "---- Validation ----\n",
      "Validation loss: 35.9436\n",
      "Validation acc: 0.7294\n",
      "Time taken: 12.46s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 445.2845, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 428.6062, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 20: 422.2239, Accuracy: 0.7470\n",
      "Training loss (for one batch) at step 30: 410.4004, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 40: 386.3268, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 50: 397.1377, Accuracy: 0.7904\n",
      "Training loss (for one batch) at step 60: 402.9839, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 70: 442.1606, Accuracy: 0.8000\n",
      "Training loss (for one batch) at step 80: 430.5797, Accuracy: 0.7919\n",
      "Training loss (for one batch) at step 90: 418.8666, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 100: 429.3305, Accuracy: 0.7847\n",
      "Training loss (for one batch) at step 110: 415.4791, Accuracy: 0.7852\n",
      "---- Training ----\n",
      "Training loss: 128.6954\n",
      "Training acc over epoch: 0.7843\n",
      "---- Validation ----\n",
      "Validation loss: 38.8548\n",
      "Validation acc: 0.7192\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 435.2336, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 435.9606, Accuracy: 0.7464\n",
      "Training loss (for one batch) at step 20: 422.0280, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 30: 400.7670, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 40: 391.2729, Accuracy: 0.7797\n",
      "Training loss (for one batch) at step 50: 373.8065, Accuracy: 0.7986\n",
      "Training loss (for one batch) at step 60: 403.9475, Accuracy: 0.8062\n",
      "Training loss (for one batch) at step 70: 431.7034, Accuracy: 0.8003\n",
      "Training loss (for one batch) at step 80: 438.5956, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 90: 433.9996, Accuracy: 0.7877\n",
      "Training loss (for one batch) at step 100: 415.1086, Accuracy: 0.7871\n",
      "Training loss (for one batch) at step 110: 422.0523, Accuracy: 0.7837\n",
      "---- Training ----\n",
      "Training loss: 139.2829\n",
      "Training acc over epoch: 0.7830\n",
      "---- Validation ----\n",
      "Validation loss: 40.7285\n",
      "Validation acc: 0.7273\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 447.3093, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 420.7408, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 20: 420.0187, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 30: 397.5143, Accuracy: 0.7636\n",
      "Training loss (for one batch) at step 40: 389.7418, Accuracy: 0.7772\n",
      "Training loss (for one batch) at step 50: 366.5474, Accuracy: 0.7955\n",
      "Training loss (for one batch) at step 60: 396.1248, Accuracy: 0.8052\n",
      "Training loss (for one batch) at step 70: 431.8966, Accuracy: 0.8062\n",
      "Training loss (for one batch) at step 80: 413.7657, Accuracy: 0.7967\n",
      "Training loss (for one batch) at step 90: 416.5589, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 100: 407.1442, Accuracy: 0.7903\n",
      "Training loss (for one batch) at step 110: 418.0968, Accuracy: 0.7900\n",
      "---- Training ----\n",
      "Training loss: 133.2614\n",
      "Training acc over epoch: 0.7897\n",
      "---- Validation ----\n",
      "Validation loss: 36.1917\n",
      "Validation acc: 0.7319\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 429.6591, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 432.5607, Accuracy: 0.7756\n",
      "Training loss (for one batch) at step 20: 412.8535, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 30: 386.7591, Accuracy: 0.7850\n",
      "Training loss (for one batch) at step 40: 374.4865, Accuracy: 0.7955\n",
      "Training loss (for one batch) at step 50: 371.4472, Accuracy: 0.8097\n",
      "Training loss (for one batch) at step 60: 398.1165, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 70: 418.3869, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 80: 433.0138, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 90: 407.6489, Accuracy: 0.7976\n",
      "Training loss (for one batch) at step 100: 393.3805, Accuracy: 0.7979\n",
      "Training loss (for one batch) at step 110: 410.9842, Accuracy: 0.7972\n",
      "---- Training ----\n",
      "Training loss: 127.9138\n",
      "Training acc over epoch: 0.7978\n",
      "---- Validation ----\n",
      "Validation loss: 34.2810\n",
      "Validation acc: 0.7147\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 435.0157, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 425.1942, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 411.5616, Accuracy: 0.7563\n",
      "Training loss (for one batch) at step 30: 408.3742, Accuracy: 0.7732\n",
      "Training loss (for one batch) at step 40: 383.7888, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 50: 369.2828, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 60: 374.2585, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 70: 424.0440, Accuracy: 0.8101\n",
      "Training loss (for one batch) at step 80: 414.6893, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 90: 393.1229, Accuracy: 0.7960\n",
      "Training loss (for one batch) at step 100: 399.0282, Accuracy: 0.7953\n",
      "Training loss (for one batch) at step 110: 419.2783, Accuracy: 0.7962\n",
      "---- Training ----\n",
      "Training loss: 127.8075\n",
      "Training acc over epoch: 0.7956\n",
      "---- Validation ----\n",
      "Validation loss: 37.8119\n",
      "Validation acc: 0.7316\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 422.1372, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 426.4007, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 409.6033, Accuracy: 0.7522\n",
      "Training loss (for one batch) at step 30: 387.4702, Accuracy: 0.7757\n",
      "Training loss (for one batch) at step 40: 375.3667, Accuracy: 0.7887\n",
      "Training loss (for one batch) at step 50: 350.8024, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 60: 396.2954, Accuracy: 0.8148\n",
      "Training loss (for one batch) at step 70: 419.1949, Accuracy: 0.8131\n",
      "Training loss (for one batch) at step 80: 431.6675, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 90: 411.3239, Accuracy: 0.7958\n",
      "Training loss (for one batch) at step 100: 402.3447, Accuracy: 0.7973\n",
      "Training loss (for one batch) at step 110: 415.1542, Accuracy: 0.7953\n",
      "---- Training ----\n",
      "Training loss: 141.7110\n",
      "Training acc over epoch: 0.7949\n",
      "---- Validation ----\n",
      "Validation loss: 43.7382\n",
      "Validation acc: 0.7351\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 430.7507, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 401.8447, Accuracy: 0.7628\n",
      "Training loss (for one batch) at step 20: 399.6539, Accuracy: 0.7641\n",
      "Training loss (for one batch) at step 30: 392.0990, Accuracy: 0.7823\n",
      "Training loss (for one batch) at step 40: 360.4857, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 50: 351.6416, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 60: 368.9517, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 70: 430.3844, Accuracy: 0.8205\n",
      "Training loss (for one batch) at step 80: 424.9450, Accuracy: 0.8114\n",
      "Training loss (for one batch) at step 90: 404.4915, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 100: 385.9219, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 110: 399.6807, Accuracy: 0.8029\n",
      "---- Training ----\n",
      "Training loss: 132.9209\n",
      "Training acc over epoch: 0.8026\n",
      "---- Validation ----\n",
      "Validation loss: 36.4468\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 425.8561, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 406.2055, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 396.6565, Accuracy: 0.7541\n",
      "Training loss (for one batch) at step 30: 389.6415, Accuracy: 0.7785\n",
      "Training loss (for one batch) at step 40: 368.4979, Accuracy: 0.7967\n",
      "Training loss (for one batch) at step 50: 350.0258, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 60: 368.1039, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 70: 405.2563, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 80: 423.6909, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 90: 384.1674, Accuracy: 0.8013\n",
      "Training loss (for one batch) at step 100: 382.6974, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 110: 385.8833, Accuracy: 0.7986\n",
      "---- Training ----\n",
      "Training loss: 123.4000\n",
      "Training acc over epoch: 0.7978\n",
      "---- Validation ----\n",
      "Validation loss: 47.1573\n",
      "Validation acc: 0.7370\n",
      "Time taken: 10.61s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 428.3491, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 419.8529, Accuracy: 0.7372\n",
      "Training loss (for one batch) at step 20: 407.0653, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 30: 372.1624, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 40: 364.9903, Accuracy: 0.7870\n",
      "Training loss (for one batch) at step 50: 352.0417, Accuracy: 0.8050\n",
      "Training loss (for one batch) at step 60: 372.9969, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 70: 393.5658, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 80: 414.3560, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 90: 390.4878, Accuracy: 0.7976\n",
      "Training loss (for one batch) at step 100: 389.9550, Accuracy: 0.7992\n",
      "Training loss (for one batch) at step 110: 393.2858, Accuracy: 0.8004\n",
      "---- Training ----\n",
      "Training loss: 127.1480\n",
      "Training acc over epoch: 0.7987\n",
      "---- Validation ----\n",
      "Validation loss: 45.1136\n",
      "Validation acc: 0.7230\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 443.5838, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 405.5055, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 20: 387.3962, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 30: 364.0921, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 40: 360.1060, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 50: 354.4433, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 60: 364.5540, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 70: 394.0359, Accuracy: 0.8105\n",
      "Training loss (for one batch) at step 80: 396.3188, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 90: 391.8167, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 100: 370.0583, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 110: 384.6539, Accuracy: 0.8013\n",
      "---- Training ----\n",
      "Training loss: 114.6895\n",
      "Training acc over epoch: 0.8002\n",
      "---- Validation ----\n",
      "Validation loss: 36.6678\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 433.8937, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 391.4851, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 390.7217, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 376.4236, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 40: 360.6783, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 50: 346.9026, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 60: 377.0366, Accuracy: 0.8171\n",
      "Training loss (for one batch) at step 70: 378.1028, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 80: 417.6110, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 90: 373.6856, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 100: 371.4099, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 110: 371.5853, Accuracy: 0.7998\n",
      "---- Training ----\n",
      "Training loss: 122.4087\n",
      "Training acc over epoch: 0.7980\n",
      "---- Validation ----\n",
      "Validation loss: 37.2562\n",
      "Validation acc: 0.7262\n",
      "Time taken: 10.75s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 439.5961, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 401.8034, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 20: 374.6824, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 30: 369.4273, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 344.8584, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 50: 337.5656, Accuracy: 0.8209\n",
      "Training loss (for one batch) at step 60: 344.9329, Accuracy: 0.8286\n",
      "Training loss (for one batch) at step 70: 413.6635, Accuracy: 0.8213\n",
      "Training loss (for one batch) at step 80: 407.6617, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 90: 371.4025, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 100: 372.8509, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 110: 384.6475, Accuracy: 0.8107\n",
      "---- Training ----\n",
      "Training loss: 122.5215\n",
      "Training acc over epoch: 0.8092\n",
      "---- Validation ----\n",
      "Validation loss: 37.4487\n",
      "Validation acc: 0.7268\n",
      "Time taken: 12.56s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 415.0444, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 406.5968, Accuracy: 0.7216\n",
      "Training loss (for one batch) at step 20: 372.8536, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 30: 341.8370, Accuracy: 0.7810\n",
      "Training loss (for one batch) at step 40: 352.3562, Accuracy: 0.7978\n",
      "Training loss (for one batch) at step 50: 336.3545, Accuracy: 0.8159\n",
      "Training loss (for one batch) at step 60: 361.4458, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 70: 405.1841, Accuracy: 0.8165\n",
      "Training loss (for one batch) at step 80: 401.8662, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 90: 363.3966, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 100: 370.7191, Accuracy: 0.8046\n",
      "Training loss (for one batch) at step 110: 389.6120, Accuracy: 0.8059\n",
      "---- Training ----\n",
      "Training loss: 118.4873\n",
      "Training acc over epoch: 0.8050\n",
      "---- Validation ----\n",
      "Validation loss: 30.1129\n",
      "Validation acc: 0.7176\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 429.6590, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 390.2790, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 366.5789, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 30: 350.0354, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 332.0368, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 50: 323.0862, Accuracy: 0.8194\n",
      "Training loss (for one batch) at step 60: 356.7593, Accuracy: 0.8274\n",
      "Training loss (for one batch) at step 70: 388.4622, Accuracy: 0.8201\n",
      "Training loss (for one batch) at step 80: 410.4521, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 90: 366.4599, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 100: 378.6440, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 110: 369.8721, Accuracy: 0.8050\n",
      "---- Training ----\n",
      "Training loss: 110.2773\n",
      "Training acc over epoch: 0.8034\n",
      "---- Validation ----\n",
      "Validation loss: 48.9193\n",
      "Validation acc: 0.7286\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 411.8974, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 414.5261, Accuracy: 0.7322\n",
      "Training loss (for one batch) at step 20: 368.4651, Accuracy: 0.7619\n",
      "Training loss (for one batch) at step 30: 346.5736, Accuracy: 0.7853\n",
      "Training loss (for one batch) at step 40: 355.4287, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 50: 329.8777, Accuracy: 0.8243\n",
      "Training loss (for one batch) at step 60: 345.5382, Accuracy: 0.8299\n",
      "Training loss (for one batch) at step 70: 364.9776, Accuracy: 0.8228\n",
      "Training loss (for one batch) at step 80: 399.3116, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 90: 360.8171, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 100: 344.7337, Accuracy: 0.8086\n",
      "Training loss (for one batch) at step 110: 352.3325, Accuracy: 0.8064\n",
      "---- Training ----\n",
      "Training loss: 118.4517\n",
      "Training acc over epoch: 0.8061\n",
      "---- Validation ----\n",
      "Validation loss: 41.7435\n",
      "Validation acc: 0.7131\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 404.7797, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 403.8197, Accuracy: 0.7322\n",
      "Training loss (for one batch) at step 20: 368.6252, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 30: 355.8151, Accuracy: 0.7870\n",
      "Training loss (for one batch) at step 40: 341.1833, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 50: 322.8364, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 60: 364.0788, Accuracy: 0.8304\n",
      "Training loss (for one batch) at step 70: 388.2164, Accuracy: 0.8215\n",
      "Training loss (for one batch) at step 80: 389.2873, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 90: 363.4937, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 100: 347.6428, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 110: 360.1483, Accuracy: 0.8095\n",
      "---- Training ----\n",
      "Training loss: 113.2594\n",
      "Training acc over epoch: 0.8071\n",
      "---- Validation ----\n",
      "Validation loss: 39.5197\n",
      "Validation acc: 0.7308\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 409.1014, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 390.0305, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 367.7281, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 334.2634, Accuracy: 0.7946\n",
      "Training loss (for one batch) at step 40: 317.2491, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 50: 338.3229, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 60: 355.0422, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 70: 370.0120, Accuracy: 0.8200\n",
      "Training loss (for one batch) at step 80: 404.2308, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 90: 337.7181, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 100: 344.9611, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 110: 366.7792, Accuracy: 0.8062\n",
      "---- Training ----\n",
      "Training loss: 116.8742\n",
      "Training acc over epoch: 0.8043\n",
      "---- Validation ----\n",
      "Validation loss: 30.9748\n",
      "Validation acc: 0.7190\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 404.9385, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 387.1899, Accuracy: 0.7237\n",
      "Training loss (for one batch) at step 20: 357.7023, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 30: 339.4079, Accuracy: 0.7790\n",
      "Training loss (for one batch) at step 40: 352.4058, Accuracy: 0.7980\n",
      "Training loss (for one batch) at step 50: 335.7376, Accuracy: 0.8165\n",
      "Training loss (for one batch) at step 60: 327.9401, Accuracy: 0.8271\n",
      "Training loss (for one batch) at step 70: 377.2526, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 80: 389.1378, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 90: 356.7821, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 100: 366.8426, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 110: 351.2496, Accuracy: 0.8038\n",
      "---- Training ----\n",
      "Training loss: 117.1639\n",
      "Training acc over epoch: 0.8027\n",
      "---- Validation ----\n",
      "Validation loss: 51.3008\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 410.4675, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 385.1001, Accuracy: 0.7244\n",
      "Training loss (for one batch) at step 20: 351.1231, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 30: 331.9989, Accuracy: 0.7840\n",
      "Training loss (for one batch) at step 40: 330.1603, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 50: 316.2574, Accuracy: 0.8223\n",
      "Training loss (for one batch) at step 60: 329.7324, Accuracy: 0.8321\n",
      "Training loss (for one batch) at step 70: 361.2680, Accuracy: 0.8221\n",
      "Training loss (for one batch) at step 80: 397.2712, Accuracy: 0.8048\n",
      "Training loss (for one batch) at step 90: 332.3679, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 100: 350.8473, Accuracy: 0.8027\n",
      "Training loss (for one batch) at step 110: 364.8702, Accuracy: 0.8029\n",
      "---- Training ----\n",
      "Training loss: 123.2861\n",
      "Training acc over epoch: 0.8018\n",
      "---- Validation ----\n",
      "Validation loss: 52.8184\n",
      "Validation acc: 0.7133\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 397.6103, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 388.4534, Accuracy: 0.7145\n",
      "Training loss (for one batch) at step 20: 354.5936, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 345.0961, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 40: 331.6949, Accuracy: 0.8005\n",
      "Training loss (for one batch) at step 50: 321.4789, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 60: 335.5969, Accuracy: 0.8258\n",
      "Training loss (for one batch) at step 70: 379.1642, Accuracy: 0.8167\n",
      "Training loss (for one batch) at step 80: 382.0144, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 90: 361.0851, Accuracy: 0.8010\n",
      "Training loss (for one batch) at step 100: 328.5019, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 110: 360.5078, Accuracy: 0.8045\n",
      "---- Training ----\n",
      "Training loss: 126.4740\n",
      "Training acc over epoch: 0.8035\n",
      "---- Validation ----\n",
      "Validation loss: 52.7943\n",
      "Validation acc: 0.7117\n",
      "Time taken: 10.76s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7283\n",
      "Validation AUC: 0.7285\n"
     ]
    }
   ],
   "source": [
    "#model = create_model()\n",
    "K=2\n",
    "R=5\n",
    "NUM_RUNS = 5\n",
    "N_EPOCHS = 40\n",
    "val_acc = np.zeros(NUM_RUNS)\n",
    "AUC= np.zeros(NUM_RUNS)\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "  MA = MultipleAnnotators_Classification(2, 5, 0.1)\n",
    "  model =  create_model()\n",
    "  model = MA.fit(model, train_batches_MA, val_batches_MA, N_EPOCHS)\n",
    "  #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n",
    "  val_acc[i] = MA.eval_model(test_batches_MA)\n",
    "  print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n",
    "    \n",
    " #AUC =======================\n",
    "  val_AUC_metric = tf.keras.metrics.AUC( from_logits = True)\n",
    "  for x_batch_val, y_batch_val in test_batches_MA:\n",
    "      val_logits = model(x_batch_val.numpy(), training=False)\n",
    "      # tf.print(y_batch_val)\n",
    "      val_AUC_metric.update_state(y_batch_val, val_logits[:,:K].numpy().argmax(axis=1).astype('float'))\n",
    "\n",
    "  val_AUC = val_AUC_metric.result()\n",
    "  val_AUC_metric.reset_states()\n",
    "  val_AUC = val_AUC.numpy()\n",
    "  print(\"Validation AUC: %.4f\" % (float(val_AUC),))\n",
    "  AUC[i] = val_AUC\n",
    "  #===================================================\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(val_acc)\n",
    "#df.to_csv('/content/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd3ca42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:47.967151Z",
     "iopub.status.busy": "2022-12-20T22:48:47.966774Z",
     "iopub.status.idle": "2022-12-20T22:48:47.971292Z",
     "shell.execute_reply": "2022-12-20T22:48:47.970260Z"
    },
    "id": "Uq3Ki4uQxcVj",
    "papermill": {
     "duration": 0.154511,
     "end_time": "2022-12-20T22:48:47.973403",
     "exception": false,
     "start_time": "2022-12-20T22:48:47.818892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sum(val_acc_MA) / len(val_acc_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ffa668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:48.269174Z",
     "iopub.status.busy": "2022-12-20T22:48:48.268412Z",
     "iopub.status.idle": "2022-12-20T22:48:48.273560Z",
     "shell.execute_reply": "2022-12-20T22:48:48.272649Z"
    },
    "id": "cxSh9vktxcVj",
    "papermill": {
     "duration": 0.155835,
     "end_time": "2022-12-20T22:48:48.275741",
     "exception": false,
     "start_time": "2022-12-20T22:48:48.119906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # accuracy\n",
    "# val_acc_GCCE  = np.zeros(NUM_RUNS)\n",
    "\n",
    "# for i in range(len(classification_report_r)):\n",
    "   \n",
    "#   val_acc_GCCE[i] = classification_report_r[i]['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba77f90d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:48.581521Z",
     "iopub.status.busy": "2022-12-20T22:48:48.581160Z",
     "iopub.status.idle": "2022-12-20T22:48:48.588188Z",
     "shell.execute_reply": "2022-12-20T22:48:48.587127Z"
    },
    "id": "Ak1z-BteyMF6",
    "outputId": "8b14abfb-4940-45fb-b50a-df0a4f7a731b",
    "papermill": {
     "duration": 0.161704,
     "end_time": "2022-12-20T22:48:48.590529",
     "exception": false,
     "start_time": "2022-12-20T22:48:48.428825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71087706, 0.6938951 , 0.65584695, 0.67282891, 0.72828889])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd2f9ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:48.896913Z",
     "iopub.status.busy": "2022-12-20T22:48:48.896520Z",
     "iopub.status.idle": "2022-12-20T22:48:48.904116Z",
     "shell.execute_reply": "2022-12-20T22:48:48.903097Z"
    },
    "id": "K-EeM9bqyI-w",
    "outputId": "b59f0070-7e4c-4480-cd00-da90044724ed",
    "papermill": {
     "duration": 0.164704,
     "end_time": "2022-12-20T22:48:48.906555",
     "exception": false,
     "start_time": "2022-12-20T22:48:48.741851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  69.23\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy: ', np.round(val_acc.mean(),4)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e23daa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:49.198432Z",
     "iopub.status.busy": "2022-12-20T22:48:49.197844Z",
     "iopub.status.idle": "2022-12-20T22:48:49.202604Z",
     "shell.execute_reply": "2022-12-20T22:48:49.201681Z"
    },
    "id": "I0E-qXsr1RFC",
    "papermill": {
     "duration": 0.153096,
     "end_time": "2022-12-20T22:48:49.204824",
     "exception": false,
     "start_time": "2022-12-20T22:48:49.051728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n",
    "# X_test = np.asarray([aux[0].numpy() for aux  in validation_data])\n",
    "# # N = len(y_true)\n",
    "# # #test_batches_MA\n",
    "# # aux1 = [test_batches_MA[i][0] for i in range(N)]\n",
    "# # aux2 = [test_batches_MA[i][1] for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae881dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:49.505699Z",
     "iopub.status.busy": "2022-12-20T22:48:49.505290Z",
     "iopub.status.idle": "2022-12-20T22:48:49.509829Z",
     "shell.execute_reply": "2022-12-20T22:48:49.508690Z"
    },
    "id": "9P-KeFKp2TEr",
    "outputId": "1998d331-5546-4bc4-c007-8180b58dd574",
    "papermill": {
     "duration": 0.158011,
     "end_time": "2022-12-20T22:48:49.512499",
     "exception": false,
     "start_time": "2022-12-20T22:48:49.354488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07788235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:49.812432Z",
     "iopub.status.busy": "2022-12-20T22:48:49.812066Z",
     "iopub.status.idle": "2022-12-20T22:48:49.816568Z",
     "shell.execute_reply": "2022-12-20T22:48:49.815529Z"
    },
    "id": "6pWXVQnK1GXo",
    "outputId": "89294013-e100-4cc0-9a9e-3f7bad8f7729",
    "papermill": {
     "duration": 0.157626,
     "end_time": "2022-12-20T22:48:49.819494",
     "exception": false,
     "start_time": "2022-12-20T22:48:49.661868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(X_test)\n",
    "# pred[:, :2].argmax(axis=1)\n",
    "# print(classification_report(pred[:, :2].argmax(axis=1), y_test ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21250891",
   "metadata": {
    "id": "STPfoIdfxcVj",
    "papermill": {
     "duration": 0.147122,
     "end_time": "2022-12-20T22:48:50.111100",
     "exception": false,
     "start_time": "2022-12-20T22:48:49.963978",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7b884b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:50.459505Z",
     "iopub.status.busy": "2022-12-20T22:48:50.459140Z",
     "iopub.status.idle": "2022-12-20T22:48:50.465279Z",
     "shell.execute_reply": "2022-12-20T22:48:50.464398Z"
    },
    "id": "z1b6tNcdxcVj",
    "outputId": "fcf6fada-a56b-45e9-ab8b-e3562b97621e",
    "papermill": {
     "duration": 0.206863,
     "end_time": "2022-12-20T22:48:50.467275",
     "exception": false,
     "start_time": "2022-12-20T22:48:50.260412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923473834991455"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7b0dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:50.765641Z",
     "iopub.status.busy": "2022-12-20T22:48:50.764583Z",
     "iopub.status.idle": "2022-12-20T22:48:50.772475Z",
     "shell.execute_reply": "2022-12-20T22:48:50.771097Z"
    },
    "papermill": {
     "duration": 0.159279,
     "end_time": "2022-12-20T22:48:50.775537",
     "exception": false,
     "start_time": "2022-12-20T22:48:50.616258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD Accuracy:  2.59\n"
     ]
    }
   ],
   "source": [
    "print('STD Accuracy: ', np.round(np.std(val_acc),4)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e46359",
   "metadata": {
    "id": "xxyE_WnFxcVj",
    "papermill": {
     "duration": 0.147264,
     "end_time": "2022-12-20T22:48:51.073443",
     "exception": false,
     "start_time": "2022-12-20T22:48:50.926179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "MC droput run this in a loop with training layer set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6515fc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:51.369993Z",
     "iopub.status.busy": "2022-12-20T22:48:51.368975Z",
     "iopub.status.idle": "2022-12-20T22:48:51.374119Z",
     "shell.execute_reply": "2022-12-20T22:48:51.373233Z"
    },
    "id": "I6R3im8_xcVk",
    "papermill": {
     "duration": 0.156799,
     "end_time": "2022-12-20T22:48:51.376233",
     "exception": false,
     "start_time": "2022-12-20T22:48:51.219434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_probas = np.stack([MA.eval_model((test_batches,training=True) # se activa training en True para que el Dropout se aplique\n",
    "#                    for sample in range(100)])\n",
    "\n",
    "# y_proba = y_probas.mean(axis=0)\n",
    "# y_std = y_probas.std(axis=0)\n",
    "# y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e42166a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:51.674003Z",
     "iopub.status.busy": "2022-12-20T22:48:51.672012Z",
     "iopub.status.idle": "2022-12-20T22:48:51.678071Z",
     "shell.execute_reply": "2022-12-20T22:48:51.677140Z"
    },
    "id": "uLKmvJlpxcVk",
    "papermill": {
     "duration": 0.157115,
     "end_time": "2022-12-20T22:48:51.680250",
     "exception": false,
     "start_time": "2022-12-20T22:48:51.523135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_ped =np.argmax(y_proba,axis=1)\n",
    "# accuracy=np.sum(y_pred==test_label)/len(test_label)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4007a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:51.974751Z",
     "iopub.status.busy": "2022-12-20T22:48:51.974367Z",
     "iopub.status.idle": "2022-12-20T22:48:51.978905Z",
     "shell.execute_reply": "2022-12-20T22:48:51.977824Z"
    },
    "id": "Jl1sFNOf1KgC",
    "papermill": {
     "duration": 0.154899,
     "end_time": "2022-12-20T22:48:51.981126",
     "exception": false,
     "start_time": "2022-12-20T22:48:51.826227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "# r1 = np.mean(val_acc)\n",
    "# print(\"\\nMean: \", r1)\n",
    "  \n",
    "# r2 = np.std(val_acc)\n",
    "# print(\"\\nstd: \", r2)\n",
    "  \n",
    "# r3 = np.var(val_acc)\n",
    "# print(\"\\nvariance: \", r3)\n",
    "# #MA.eval_model(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32222704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T22:48:52.302061Z",
     "iopub.status.busy": "2022-12-20T22:48:52.301687Z",
     "iopub.status.idle": "2022-12-20T22:48:52.306020Z",
     "shell.execute_reply": "2022-12-20T22:48:52.305038Z"
    },
    "id": "KqeZpkxuxcVk",
    "papermill": {
     "duration": 0.161229,
     "end_time": "2022-12-20T22:48:52.308071",
     "exception": false,
     "start_time": "2022-12-20T22:48:52.146842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dcabac",
   "metadata": {
    "id": "6cjM2VJJkuKK",
    "papermill": {
     "duration": 0.148914,
     "end_time": "2022-12-20T22:48:52.605656",
     "exception": false,
     "start_time": "2022-12-20T22:48:52.456742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "VGG19 --> acc:0.8613  --> 0.894454 --> 0.772356"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2365.644683,
   "end_time": "2022-12-20T22:48:55.851113",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-20T22:09:30.206430",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
