{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3245e02e",
   "metadata": {
    "id": "oAuRT75GdLFw",
    "papermill": {
     "duration": 0.009616,
     "end_time": "2022-12-20T23:04:56.550609",
     "exception": false,
     "start_time": "2022-12-20T23:04:56.540993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cats vs. Dogs Class dataset for multiple annotators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214a50f",
   "metadata": {
    "id": "9rK94t33nwDC",
    "papermill": {
     "duration": 0.00807,
     "end_time": "2022-12-20T23:04:56.567206",
     "exception": false,
     "start_time": "2022-12-20T23:04:56.559136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9bfebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:04:56.586337Z",
     "iopub.status.busy": "2022-12-20T23:04:56.585505Z",
     "iopub.status.idle": "2022-12-20T23:05:02.376015Z",
     "shell.execute_reply": "2022-12-20T23:05:02.375073Z"
    },
    "id": "zSyMHuCVys-O",
    "papermill": {
     "duration": 5.803129,
     "end_time": "2022-12-20T23:05:02.378603",
     "exception": false,
     "start_time": "2022-12-20T23:04:56.575474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec37472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:02.398404Z",
     "iopub.status.busy": "2022-12-20T23:05:02.397906Z",
     "iopub.status.idle": "2022-12-20T23:05:02.402103Z",
     "shell.execute_reply": "2022-12-20T23:05:02.401133Z"
    },
    "id": "-E1MJt8cxlwg",
    "outputId": "ea43c1c9-075f-44de-d2d8-e135799b6630",
    "papermill": {
     "duration": 0.015705,
     "end_time": "2022-12-20T23:05:02.404161",
     "exception": false,
     "start_time": "2022-12-20T23:05:02.388456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf5c06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:02.422093Z",
     "iopub.status.busy": "2022-12-20T23:05:02.421822Z",
     "iopub.status.idle": "2022-12-20T23:05:02.426195Z",
     "shell.execute_reply": "2022-12-20T23:05:02.425205Z"
    },
    "id": "QJPvjdZ-f8ca",
    "papermill": {
     "duration": 0.015496,
     "end_time": "2022-12-20T23:05:02.428118",
     "exception": false,
     "start_time": "2022-12-20T23:05:02.412622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/Shareddrives/Multiple Anotators/CrowdLayer/Notebooks')\n",
    "# cwd = os.getcwd()\n",
    "# sys.path.append(\"../Models\")\n",
    "\n",
    "\n",
    "# from Multiple_Annotators_C import MultipleAnnotators_Classification\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(1, '../input/multiple-annotators-c/')\n",
    "#os.chdir('/Multiple Anotators-c/')\n",
    "#cwd = os.getcwd()\n",
    "#sys.path.append('/input/multiple-annotators-c')\n",
    "#from Multiple_Annotators_C import MultipleAnnotators_Classification\n",
    "\n",
    "# seed_value= 12321 \n",
    "# from numpy.random import seed\n",
    "# seed(seed_value)\n",
    "# tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3e773",
   "metadata": {
    "id": "6Un5nFWgnyem",
    "papermill": {
     "duration": 0.008211,
     "end_time": "2022-12-20T23:05:02.445131",
     "exception": false,
     "start_time": "2022-12-20T23:05:02.436920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download and Prepare the Dataset\n",
    "\n",
    "We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset and we can load it via Tensorflow Datasets. The images are labeled 0 for cats and 1 for dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6dab4",
   "metadata": {
    "id": "Gw6K2Uey06kh",
    "papermill": {
     "duration": 0.007977,
     "end_time": "2022-12-20T23:05:02.461395",
     "exception": false,
     "start_time": "2022-12-20T23:05:02.453418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiple annotators model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3ef0cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:02.479575Z",
     "iopub.status.busy": "2022-12-20T23:05:02.478760Z",
     "iopub.status.idle": "2022-12-20T23:05:04.983550Z",
     "shell.execute_reply": "2022-12-20T23:05:04.982602Z"
    },
    "id": "xam4REp209Sd",
    "papermill": {
     "duration": 2.516173,
     "end_time": "2022-12-20T23:05:04.985936",
     "exception": false,
     "start_time": "2022-12-20T23:05:02.469763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 23:05:02.561131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:02.646979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:02.647863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:02.649089: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 23:05:02.657722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:02.658430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:02.659159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:04.588745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:04.589588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:04.590277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 23:05:04.590869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_data = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_Te')\n",
    "train_data_MA = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_MA_sin_Tr_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d743491f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:05.004977Z",
     "iopub.status.busy": "2022-12-20T23:05:05.004676Z",
     "iopub.status.idle": "2022-12-20T23:05:05.013599Z",
     "shell.execute_reply": "2022-12-20T23:05:05.012625Z"
    },
    "id": "D_S0EJ3mFdfK",
    "outputId": "9ed3c2c7-50b4-4445-a01e-c9a3d780c403",
    "papermill": {
     "duration": 0.020936,
     "end_time": "2022-12-20T23:05:05.015644",
     "exception": false,
     "start_time": "2022-12-20T23:05:04.994708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_data_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334e53c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:05.033990Z",
     "iopub.status.busy": "2022-12-20T23:05:05.033735Z",
     "iopub.status.idle": "2022-12-20T23:05:05.041781Z",
     "shell.execute_reply": "2022-12-20T23:05:05.040972Z"
    },
    "id": "ctjLei0TxcVh",
    "outputId": "6f578b73-ebdf-4465-91c7-2adb7d127174",
    "papermill": {
     "duration": 0.019645,
     "end_time": "2022-12-20T23:05:05.043724",
     "exception": false,
     "start_time": "2022-12-20T23:05:05.024079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4652"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count1 = tf.data.experimental.cardinality(validation_data).numpy() # los datos de training son 18610\n",
    "image_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1f941a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:05.061963Z",
     "iopub.status.busy": "2022-12-20T23:05:05.061301Z",
     "iopub.status.idle": "2022-12-20T23:05:20.830830Z",
     "shell.execute_reply": "2022-12-20T23:05:20.829829Z"
    },
    "id": "opk5MXl4IwjC",
    "papermill": {
     "duration": 15.781144,
     "end_time": "2022-12-20T23:05:20.833222",
     "exception": false,
     "start_time": "2022-12-20T23:05:05.052078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 23:05:05.085348: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "#X_test = [validation_data[i][0] for i in range(image_count1)]\n",
    "#Y_true_test = [validation_data[i][1] for i in range(image_count1)]\n",
    "Y_true_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n",
    "X_test = np.asarray([aux[0].numpy() for aux  in validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76c0363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:20.852777Z",
     "iopub.status.busy": "2022-12-20T23:05:20.852044Z",
     "iopub.status.idle": "2022-12-20T23:05:20.858747Z",
     "shell.execute_reply": "2022-12-20T23:05:20.857843Z"
    },
    "id": "-BydcVOQxcVh",
    "outputId": "8c1b4ed2-7c43-4675-f055-f9e4e3f5b3dd",
    "papermill": {
     "duration": 0.018582,
     "end_time": "2022-12-20T23:05:20.860936",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.842354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab545419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:20.880751Z",
     "iopub.status.busy": "2022-12-20T23:05:20.879222Z",
     "iopub.status.idle": "2022-12-20T23:05:20.887131Z",
     "shell.execute_reply": "2022-12-20T23:05:20.886272Z"
    },
    "id": "HdFme6fdxcVh",
    "papermill": {
     "duration": 0.019546,
     "end_time": "2022-12-20T23:05:20.889136",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.869590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds_MA = train_data_MA.skip(val_size)\n",
    "val_ds_MA = train_data_MA.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab8f6947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:20.908080Z",
     "iopub.status.busy": "2022-12-20T23:05:20.907348Z",
     "iopub.status.idle": "2022-12-20T23:05:20.917106Z",
     "shell.execute_reply": "2022-12-20T23:05:20.916292Z"
    },
    "id": "aVHIlFpgxcVi",
    "papermill": {
     "duration": 0.021169,
     "end_time": "2022-12-20T23:05:20.919083",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.897914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_batches_MA = train_ds_MA.shuffle(1024).batch(batch_size)\n",
    "val_batches_MA = val_ds_MA.shuffle(1024).batch(batch_size)\n",
    "test_batches_MA = validation_data.shuffle(1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8cb67bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:20.937464Z",
     "iopub.status.busy": "2022-12-20T23:05:20.937206Z",
     "iopub.status.idle": "2022-12-20T23:05:20.943502Z",
     "shell.execute_reply": "2022-12-20T23:05:20.942588Z"
    },
    "id": "GsB4EA2-xcVi",
    "outputId": "2d45809e-a9cc-408f-9a8b-745e8fe850e9",
    "papermill": {
     "duration": 0.017576,
     "end_time": "2022-12-20T23:05:20.945427",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.927851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62dd983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:20.964735Z",
     "iopub.status.busy": "2022-12-20T23:05:20.963894Z",
     "iopub.status.idle": "2022-12-20T23:05:20.970504Z",
     "shell.execute_reply": "2022-12-20T23:05:20.969548Z"
    },
    "id": "Hk33DzwkxcVi",
    "outputId": "aad91eec-842c-4995-de90-5bb715539b6a",
    "papermill": {
     "duration": 0.018329,
     "end_time": "2022-12-20T23:05:20.972450",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.954121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3722"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count_val = tf.data.experimental.cardinality(val_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996c1e9",
   "metadata": {
    "id": "UMeK3NG3xcVi",
    "papermill": {
     "duration": 0.008552,
     "end_time": "2022-12-20T23:05:20.989780",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.981228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41954ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:21.009081Z",
     "iopub.status.busy": "2022-12-20T23:05:21.008289Z",
     "iopub.status.idle": "2022-12-20T23:05:38.885747Z",
     "shell.execute_reply": "2022-12-20T23:05:38.884799Z"
    },
    "id": "uvwc7eixxcVi",
    "outputId": "d7766078-8c40-41ed-fb01-66b5f62a07f1",
    "papermill": {
     "duration": 17.889257,
     "end_time": "2022-12-20T23:05:38.887965",
     "exception": false,
     "start_time": "2022-12-20T23:05:20.998708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 23:05:32.608278: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n",
      "2022-12-20 23:05:36.413236: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89        78\n",
      "         1.0       0.80      0.88      0.84        50\n",
      "\n",
      "    accuracy                           0.87       128\n",
      "   macro avg       0.86      0.87      0.86       128\n",
      "weighted avg       0.87      0.87      0.87       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.55      0.60        78\n",
      "         1.0       0.44      0.54      0.48        50\n",
      "\n",
      "    accuracy                           0.55       128\n",
      "   macro avg       0.54      0.55      0.54       128\n",
      "weighted avg       0.57      0.55      0.55       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.71      0.72        78\n",
      "         1.0       0.57      0.60      0.58        50\n",
      "\n",
      "    accuracy                           0.66       128\n",
      "   macro avg       0.65      0.65      0.65       128\n",
      "weighted avg       0.67      0.66      0.67       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.54      0.59        78\n",
      "         1.0       0.43      0.54      0.48        50\n",
      "\n",
      "    accuracy                           0.54       128\n",
      "   macro avg       0.54      0.54      0.53       128\n",
      "weighted avg       0.56      0.54      0.54       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.27      0.30        78\n",
      "         1.0       0.16      0.22      0.19        50\n",
      "\n",
      "    accuracy                           0.25       128\n",
      "   macro avg       0.26      0.24      0.25       128\n",
      "weighted avg       0.28      0.25      0.26       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.85      0.82        65\n",
      "         1.0       0.83      0.78      0.80        63\n",
      "\n",
      "    accuracy                           0.81       128\n",
      "   macro avg       0.81      0.81      0.81       128\n",
      "weighted avg       0.81      0.81      0.81       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.46      0.50        65\n",
      "         1.0       0.53      0.62      0.57        63\n",
      "\n",
      "    accuracy                           0.54       128\n",
      "   macro avg       0.54      0.54      0.54       128\n",
      "weighted avg       0.54      0.54      0.54       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.60      0.61        65\n",
      "         1.0       0.60      0.62      0.61        63\n",
      "\n",
      "    accuracy                           0.61       128\n",
      "   macro avg       0.61      0.61      0.61       128\n",
      "weighted avg       0.61      0.61      0.61       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.51      0.52        65\n",
      "         1.0       0.51      0.52      0.52        63\n",
      "\n",
      "    accuracy                           0.52       128\n",
      "   macro avg       0.52      0.52      0.52       128\n",
      "weighted avg       0.52      0.52      0.52       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.29      0.29        65\n",
      "         1.0       0.26      0.25      0.26        63\n",
      "\n",
      "    accuracy                           0.27       128\n",
      "   macro avg       0.27      0.27      0.27       128\n",
      "weighted avg       0.27      0.27      0.27       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.82        55\n",
      "         1.0       0.86      0.89      0.87        73\n",
      "\n",
      "    accuracy                           0.85       128\n",
      "   macro avg       0.85      0.85      0.85       128\n",
      "weighted avg       0.85      0.85      0.85       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.62      0.55        55\n",
      "         1.0       0.65      0.53      0.59        73\n",
      "\n",
      "    accuracy                           0.57       128\n",
      "   macro avg       0.57      0.58      0.57       128\n",
      "weighted avg       0.59      0.57      0.57       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.65      0.57        55\n",
      "         1.0       0.66      0.51      0.57        73\n",
      "\n",
      "    accuracy                           0.57       128\n",
      "   macro avg       0.58      0.58      0.57       128\n",
      "weighted avg       0.59      0.57      0.57       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.58      0.50        55\n",
      "         1.0       0.57      0.42      0.49        73\n",
      "\n",
      "    accuracy                           0.49       128\n",
      "   macro avg       0.50      0.50      0.49       128\n",
      "weighted avg       0.51      0.49      0.49       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.25      0.22        55\n",
      "         1.0       0.29      0.23      0.26        73\n",
      "\n",
      "    accuracy                           0.24       128\n",
      "   macro avg       0.25      0.24      0.24       128\n",
      "weighted avg       0.25      0.24      0.24       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.75      0.76        55\n",
      "         1.0       0.81      0.84      0.82        73\n",
      "\n",
      "    accuracy                           0.80       128\n",
      "   macro avg       0.79      0.79      0.79       128\n",
      "weighted avg       0.80      0.80      0.80       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.67      0.59        55\n",
      "         1.0       0.68      0.53      0.60        73\n",
      "\n",
      "    accuracy                           0.59       128\n",
      "   macro avg       0.60      0.60      0.59       128\n",
      "weighted avg       0.61      0.59      0.59       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.60      0.58        55\n",
      "         1.0       0.69      0.66      0.67        73\n",
      "\n",
      "    accuracy                           0.63       128\n",
      "   macro avg       0.63      0.63      0.63       128\n",
      "weighted avg       0.64      0.63      0.63       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.60      0.53        55\n",
      "         1.0       0.62      0.49      0.55        73\n",
      "\n",
      "    accuracy                           0.54       128\n",
      "   macro avg       0.55      0.55      0.54       128\n",
      "weighted avg       0.56      0.54      0.54       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.16      0.18      0.17        55\n",
      "         1.0       0.30      0.26      0.28        73\n",
      "\n",
      "    accuracy                           0.23       128\n",
      "   macro avg       0.23      0.22      0.22       128\n",
      "weighted avg       0.24      0.23      0.23       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABXCAYAAACnZJZlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAC5qElEQVR4nOz917NkWZbeif22ONrl1aFFylJZuquruqq6CxhCj5FGozC+8pF/B/8FvvFhHoYESJADwKAHMyC60dWAdXfJzkpVGREZ+mqXR2/Bh+N+40ZkZGQhAtZ8YC6rrLjX3a/78X32Xnvtb33rW8J7zxf2hX1hX9gX9tdj8v/XF/CFfWFf2Bf2/0/2hdP9wr6wL+wL+2u0L5zuF/aFfWFf2F+jfeF0v7Av7Av7wv4a7Qun+4V9YV/YF/bXaF843S/sC/vCvrC/RtMvevKjjz5+ik8mhECI9c9Pv1Y884AQAu/96m/EC1/3rD39mECIz94bnvf3zz6+psV91muftWdpdOvfnXOfevzatSu/25s+x/6P//C/9YHTSN8nX05Io5SShnJxwmgrZtwbspwXSC1J+ilx0mc+X5C4BOkjvnPz75OXBXeLvySKJVpoXOUwoQbRUNkKbaDfGxBFmqqoWDY5lTtFS8XG4CZ1k7OcnhIGPbSHgR7inKJ1S7IsIg6HJD5jo7dFpFMen9yibGrSNMBLQVWVxFGGEGCcpWksTVkik5DG1uTlDCstoRoz7m+zyI95PL2PEZY0jQiDiABNrLZxGDQejUJYwUBf43/zg//DS43vjde2PaLGixoApRTWOkAgEJzdYQHehkih8DR4J5EiQSuNB5yv8L4G0Z69Hu9Jexlf/dY3ibMeRw/2+fjDD8F5kJ4gCPkbf/i/5Lvf/T7vfP179Me7iCDCe49SAqXU2XVKKfHe472nbbvPcM7hvccYw2/efY+f/oe/4N6HD9jdvsCDBxOuv36JRwcFi7wAPN6FSKkQsgUc3iucVUgpcb5CStldNw5BiDUCRMX/+K//zy81tlcuDbvh857zb3B+nQkpCKQgUALWPkD6s5EXiG7sAe8EdetoDaTJ+loFB5Maax17myGxlgghEcJ332f9OSs/U5Y1h1NDWbY47wiCkLZxZ+NrjHlqXf8ufujZ77T+d+0Hzr/fU++NoDXtZ47tC53u8y8C4NNO7NmLe/aCnn38d3GWv9v1+P/iv3nh+51732ev51Pf7RU/N/QZ440dFosDRqMRSkuq6ZIsHuONY7HIqcUSTYxbSGo7w1jL3ugttB/gbIWONtiMLrCsjjmdTVGhRVaaJOrjGtBKM1+c0nM9BoMdZscLIpVRlDn77S1iGSN9grOACmilI4wiMAFFsWRaz+gnY8rTJYNwC+9g2BtRmRLrPIEWREEAXhFqQRrAHCiaiiiKCXsheVPgvadupnjh2Yq3kQJa2TJfzmiEoDCWsrBEvYytfkasFbndf/nBFTUIe/artbZb6CtTQpP29vCBoMlPsW1LHA1xzlDVS4x3IDyebqGvvC3g8QiKouL2R+/RHyacHE8AgzGAdHhv+Tf/7h/xP//xP6E/3OIHP/gJ3/nWj/jy299kONqBOESIzvmen79CCKSUaK2x1iKl5Jvf/AZff+cd8uWSd3/9Ib/8xYf86t1fYk0fbyLCIEYqC7jVla3eS1qGo5jRxojHjx6xsbnF4f4Eay1KS4Lwv3jpn5n3neP7TId7Fpmtlog4P3bw9KrpHmmto7GQCokQmqpqkc7jkFgrQXebpRDPX/PedRsXopvz1lqMsSilSJLkKaf77Jpeb3rnr/13CdSe5+vA08tePLYvfNY596lI9dxHcv6zxGpgn91Nut/XFwdC+E89/uT1z/tMj/fnI8wnE3Q9UM8boCfXcd75v+jbPnm1X12M8E++z1ObCN0U53d4vxdZ6xu8s0iriJMEQ0koNMPxBoezR7QemrYmzUKiTGJaT6CHzJspcdRyZB5yJdvhcC4IdY8o8ZxM76O1wBpHnMYI6wmDHrgE7QSxiMnLJW1rsG1JEGj6yQYqDPFWUNPgbEOchMyXUwhgXk9oVE5rLcJ5nLF4KWhMi5KC3OSUVU0SpERBRNpLSV3CdDkjDBJa5aiqFq8ESZgQxD2KuiBWGyR6g3K5YLGseXB7yXLW8OVvhFy+AsYuXn5wRdvdHq8AjQotoTI0LVgjEVqQRAmoEHSOk54wkninqFvbRTNeAnZ1z7v5rYVHCU9jPUcHM+anS7yQWONx3oHzOCdQUlKVFXXzkH/xz/9v/Nt//Y/Y3b3C3/l7/1ve+fb3uLB9nUF/AxWEeDoHrHSAFALvPGfBsAchJf2NAd//8Xf5vT/4Jov8H/CrX37AL//yPT58/x5t5QhUDCrFCw0YtncGxLHga1+9zhtvXub99+5inV1tIJamNS89tM77DpdcXetnLgTPc5wsPPHG3fp1QNVYWuNxXoPztI0niyWtl5gWiORZZCxWn/3sNa0jUCEk1jaA78ZVqaf8xaeu5pwP+axisWd9zfNe61dfOA7Us3/+lP1O293znNvzr+15DvfskbN/n/8+n/1lnr6p8rmD9OnPe7IRPG3P7JDn/551vLD+pPVp8unP8qvX+Ff0urPjKea04eblmxBpjNEMt/osqglJoBA6Q9SwXDRI70nSPs4opkWJTiZgEjbdW9QlTOrbjDe3cRND6wReWJxvWRRLnGqRRlI3Q8rWIbSmJwZUdUwcD6iNRbuWKItQTqNkQF7mpNmI1uTk9ZJaVSiVkoYZJ8sJKggQUhF6aK1BBjBtpsQmwDUtvSxDa0vdLMiLKVJHBFKTFwVLb1FRQKQCXN0CCcvjmkcfLFicNPR1Q390gV6cvPTY9tIRzhvqpsJ6y42Lko2e5PGp4O5jR2tqJrO7aBlStwV4R9s2eO9xbj0nno5gtJfs6ohAOU5aQ2kF3hhab8F3x1+/mkV27QC86By2c+iw5IM7/xPv3f0PTB4UfOXN3+N7P/67XLv6OqPhNkporBTIQHVzbxV8WGvxXiC0QGuN1gF/+KPv8wc/+D3m8zm/+vkv+fUv3+e3v31MkQuUD6lKwc7WLhd2N1jkNRvjTaKwx507d85tKC9nxnqMNXhHN1bek8QaIVeBFecCHO8R0nVOcuUxhRDnDg6CpoWydCAkZQPWtORlA8LhncelET0U4mzrOwu9cL7zIcYL8B0UaYzHtJ3P0lr/Tifh86eN7rKf50te/PfOe5T0ZNGLP+t3PmM8DyI4fzHOdcex7nkA2x2XxJnrOrfbPHnPJ2H9ZzvQp7+wX0XMZ89+6pqevuZPPfrU6z9rkNcu9QxJeOYtxKcf/S+2K9vXCZymrwcs65okGrCYT9BasTfeQ0QZhe+hiBlk2zzcv42xJXtbe5zOD5kXJ9T9YxIRc28yYzkriKKQJI5o65ayqgjDAGtawjCgNI4kS6jqltlkzqDXRylBqGMCEWFtRRomuFbhfESWZpSVps4b0iQDC15YdKgxtOAdgc5QKIpiQRCtjs2RJq8LdBiSRikOT1VV1HUFGrwXGGORokAKw3R6yofvf8Jv/+oukYyojqFcDknj4KXHNhUxCEMgPXlT4nNoiGnzBu8FUlpMW9H4ArHKJzvf8mST1qs58SSSkwC+O8RvjhP2ro3A1rx/65TFwmHxSC8AgRcCcJy5YQOnRzPCSNFW8OjxMbd++zH/8t/8Yy7tXefrX/8OP/7x3+TS1S8x2rgIUqCUXEW9CinW2G93dUIJlJZsbW7yk//mJ/zwj37EYr7gZ//pZ/zVz97n8aNj8Lv883/zH9nZ2+ODj+5hjcGt1tuz+Yn/Equr9RpyPDkDeCRPn1Cd86C6634Scokz/4voYPDaGNzKLy+XFc557LkIumks1oI+t0+soQS3ghWc8wihUBqavD57Xdu2nxm9PvVevMgXPG3PhVDxIDxhKND6xWP7Qqf7eRfzrHO01mKdoWpr2qpES0Wc9IjC5Bz43U2cJ058DUs8/3M+HcGunTd0y+DFO9LTl/x8x/zU7+LJq56O0/2TqHflzMWL783n2s6lPUKnUT4gsZK2nlM0SyLZQweKRbWgbGcEMqRVAms6R2lrwcXtN5kvF5zOT9jafJMs30XKJaPBRRblKVmWUtU1eE+k+gjtCcKEtnYIEZP0LYfHj9jwYzZHKXEgmRcWFykcDePhiKZpUCokSzOiKEajsW2LVJKiWuC9YlqdEgmwLSQ+QWpNoAKsM6ha0JqGOO6j0FS01HWFigJsa2ltQVNa7nz8gJ/96a85fZgjnWdjs+Lr9hre2s8fxM+wPD/Fa0llG6yw3DlqkSc1rQO1mnee55yGRHefIyQCR+0dDgk4aiz7bYVuJG9dG3LhgkFVKUePc2yRk3gIpEZ5iRFQCE/pLdqGRFKi5xX77z9muTpVKQdGtNz55EPuPfyQf/Pv/nuuXnmdL731PX704/+Wy9dfpz/a6DDeFSwnhUAKDXikAC88OEEYBmxsjPhb/+B/wU/+9t/gdHLKb979iF/+5W95dOcDzNzQCokIQ7ASz8s7XdFFSGejto7Iz9bzM/jus4GP952TMsaxLCxls95MfAclrNCH9dI01mEtEDy5V082oLV/8F2A4aESDUGg8X7lk1b/Pfn8J8Hes4He8wK/z4tyz+d4gkBhP8cv/M7wwnl72jk+CfbrquTDd3/Fb9/7FW2xJI5jti9c5s2vfpOdi1fQqwzu2nGu3v3M4X6eU3/ewHzayT7fYT+F966ff+b3Jx766cj66Rd9+jpe1o4Wt9Eqox9tILyjrFq2ti9SNVMWbYUPKtrKo22MFjGRTpEyZevSNsLHSKUxTYFGY4qUWh9g/AGNqSh9QZpkbI92cdIxNzOqpsYsW9IsYdQbo3D0exlFuaBYzBj091gscqSs8YUhDEJAYjwUpxOSXg9bN/SjAbZpCXoRWkYsZycEOmLRzgnamFhGpFmGs4q8yJGDIUZL6sYwLSfYpWUj2yRfLLj78Iif//QDHt85xNUWhaF2Q/L6FFG9vNNduhLXAKqDo6xQGEAKh3PuLAg4fz9ZpaK08uzFFi3hsPTM2i4WFirAOI8V8MknE3QeIM2MYFrxNaUZeUUgJdJ5rJQ43+GVSylwwqOUoSBk31kWeIyEXjgk7m9T2yVFfsrHH7/PrVt3+Ff/5p9w+eo1vvqVb/KHP/5bXL35Fv3RJtZLpIgAgVQrZs/KGTvXwRoq1Gzv7vCTnW3+6A9/yMnRY977q0/4s//85zy4c0w+b0mz7KXHVog1wLZyoAIcoJ56zXNYS2dJtS7iLWvLdF7TQYYglCKOI6QAY8wKgxZdHkh6nAAtFcKvnb6nC4gl3guU9izmBYN+ivcOaz1N02Ad6ECfsULWDn6dV3oSxD0Ncb4o8j3vuNcmgShQWPdi6OaFTvfzaBQAXnQUlbop+cs//WP+4//4r5G2RojuiPDhu+/z8bvv8va3vsU73/sh/f74DEp4HqXs2Z3mxV/cAud22M/Aa4EV0vbE5Lnnz6Lb1bx4asj8ucj3OTjyq9j8aIFoS4qkwfgKbxz9SNO0Db1sm9l8jnIOKWsW9QlZFqG05cHt22zvXsRYy6I84lL0Dtd3vsz9CZi8QWmPk0uM8Dg5pDUSbzSYhkBbwkBTV5Y4GCFtRpRJFosjKjFFBALnJI2zOFshwpTdwWUWeUElanCSON1gO05QKqB1FcHQUZYFbWsYpjHCK+qm7u6xNkg1IBIh0kLFkloZqrairWp+/Z8+5KM//wRXCxCaKJJs7g5ptaX25UuPrZddIlScW0zrc9F5hwvPzi2Pd4KmlRjpMM7T15JYKgoUS29JjSFpDDz09LRnDPSdwqsAgSXEIq0jwBIZRy1AyQDdBHgcTWCZesFBILHDAU02pFwxSmzjAQOi5c6t3/DJ7Q/4V//i/8H162/y5a9+hx/95O9w/eqXGA5HGCtBKpACv3JoQgj06jt5QCrP9t4OP9zZ4Uc/+R4Hj474za/f58P3P3jpsV2PmVsHHk/iridQ7TP5nOeFM0JAFAUrSpsnDBRXL2+TFyWT2RIpwy6ylxAGGiUEWxsbmLZhsVhirVldS4fnFkWJEBIpoV0lQ6VcJejXjlZ01w3QMVE/HfzB0/TQ5z12fhzWppQk1LpLqL7APpe9sP7Qz3QwHhrbcPuDd/n1T/8DqfSk6YCmriiqhrKq+eSTu5xOZ8wmM/7w7/wD0t7gqfd8Ntx/PguBz3nN00ePT13zOQe7/nUNF9hzRyXpQT67S/Nph/uqUS7Al4ZX2DxRnC4bDnoe0YfGL6lMC4uCfNnQizRGGoQIWM5nVIsFr1/5EjQly0XO6SRnqqZYB+Z0yOP7JePtPnowZVEeU5S3GQ/7NI2jFwzBWYp8idABVTlHuxkiTXHGMZ8V9LM+ddEgXYwkxEpDIU6pZUkjc4Rv8bmh3x8TAdP5AqkAKciyMUJJmqbCCzCupTEVotQMoiHj3oh+2mdazZkupzgERx+VUGl0oBDCM9oI2L20jfWK9hw2919sLsC5BhU4nHVIqdZEx9ULnp4raxMerIf90nZOTCq+Ms7IvODUaYp8ybZ2bClIjIBWoJQmEB7pDAEW7WtCGaClAiFQ3oNou5O3s6Stpy8UFxvHfLrPUVVxC4tpcvCq8wbedoGCM1gEH9/6DR/f+g3/6l/8I25cf4OvffU7/OFP/hbXX3uHKOojpMBKELLLZmndLW3nuohPCYEIJBeu77J7bZuf/P0fv/zQOnf2H2uo5nyiZbUUO+d2HogFfy6aVAIG2Yq9EUh2xj2+8vou02XFvUcnVGWFcw6tJZHSxEnAzlYfaxvqpsRYj7WrAMF5TOuwXlJVFUKAVKvTgJddbkmE+NV1GzruLitKRPdVPp2kfx4E8TwTQiCkPEugvshe6HTtORhAnPswuR44AdZbpkcHvPef/oSdJKZ/cY+qqckXS4RcUM4WlHmFt44/+//8e5wQ/OTv/gPiJEMJuXKC4uydpXyaN7f+Qmf37TMGZE3tObsw1seIJzd9DYZAl+LAWeq6ZDadMDs9JhsM2Nq9SKDDs7h5/cnOn58u/ilH/LL28b3fIO4leARuoInf3iMO+ghbEPdiyuIUdIrXMY0NaP2cweYeC5Nz8vAhcTBk9jjjF/c+YmvnGsvDmPJUUk8MQa/P1uU+xu0z90u2NvZolzU7W9sc58c8PnyI95ZBvIOYJJi6z/zU8fFUUBchbWWo6xKtPUGkSUeKbDMhHSna0YzT6ohRbxsvPGVZkUWSprK0vsX5Gq88zoL1jnk5I9ABtm2pa4OzBmHg/Z/f4dGtGTKI0LEmCxWvvT7m6mt77F6/hDAvDy94F3T3zxuUFCgkLa67n16sHJsA70CsnYfvaIIInFrNFg8npsVKzbgsuNFalHIIA1J2dKTQQegMiQQtBE4kKzzRoIXojsutQSqFVBq/wnS1h2FtUe0EaRxaOY5DwdLQ8U5FB24Kv4rm8Fjb8ttb7/Lb2+/xL/7tP+bt17/F19/5fb71e9/j+htfIYgylASc7dgUQiGUxzu3SmB1YyBf4ZS25hPDkyD3ybpcOac1vCueXkdn98d7At2FoWEUMOz12dsdc+3qNd5IAi7sHvDg/mOWRcne3pi6LhBCsrU5QOKQOGbTJXHS4/7jA6bzLopSQj5J1K/8n8fjvT0rEhFSoBHoKGJdiOFXOIlznqpqVnCIR+BWRSYrn7TyK2vGcTdtVmNhHEXpSLMXj+2LE2nnfnpuUsl52rbh1q9/gV/MGQ8HhGlC29RIIQi0JgsjvPU0bYNE89P/8D+Rjfp887s/whpHVefEUYQQEqU0aZquaB7yU9Hw+Zt+/uY9+9h5EL6r0Fm9VoqzJJ5tK04P93n/17/ir37+lyzmx3znhz/kJ3/3f72CGzzSn8ObWXFzWSXQ/itEuq5uiKMeUnrCR1NOaBl85TI2aJjnJYP+kDBKka0jaEN2sutAjGlbrm9doV4GSB+ivCa0sNUbElGihceJAbP7BenIEV41tMUMIeD+6UOaQsP8NUK/yf7tknohWS5q2kbRGou1BttUNHVztlq01ggtiAchG3uSnet9Nl+PKatDrHAoMUSGnkCnVKWnLHIwhjCISMMebQtOt0ilqduSg/1Tfv6ntzGtYDAa0evHbI8S3n5nl/F2H+UlKnx5ypgjR8puIWqnCJXCe7qjnwhRjEB6nC9xDqR0OGq8MJxhSitHfDopSETERQyhFDgkSkoiqVHWEfiGUICSEi86WMMGAkEAxoN3HcVutcDlWZpAICT0vCUSjp6G4yziVq/P7LTsEqHO0QFjXdTYOV8JDmxdc/v2r3jw+H3+3Z/8Q7Y3L/H97/0hX//697j2+jvoIMX7FqU6GMI5h5JqlWl/6aEFziXJeF7y2p+dKD9l547wgdYkaY9Ll/bYHPdJswihAGrS2HHl0oi8SsmyhDQds1jmbI5HaCnAWQZZxmAwojI1x5OcMFAd5v28j/VPYIV1ULeGYPy57+C9PytaAdvNH62eer6j8D1J6K+duwBa4/i8VNnnwAtrzHT9lqs378IFnHUcH+xz/4N3ib3FeofwHtc0tHm36Jxp8dZiW4PDE0rFv/6n/5y/+Mtf4p1nNp8SRhE6CAh0yJtvvsnbX/oSWX/AeDQmiiK0DlArcEbw2SH+cx9fAfjed9fbGsN0csKtD9/lZ//pz7j13vvUZU3Sj4nS7Cwz271h93/rm/PkSMpZ5c+rmDEOoxW9JGU0qzn69T7zSUT/5gZxX7G9vUVRTHjn6pe5MnqTk3mFMwqpOsrVhBLzhmaal0itCYWid3VIf5hiBCxO5+wOJfeOD7mVP6IwNcvZgPljzfzIIn1NUzQ4YzArDL6qK6xpwViMc5i2RSlFKyVKS2wD5VQye6xY3HWML/fZvllRtkXHM3UCLwOUjOkPdBdhOUHbGsq2JIkSFm3B+z97yIOPFmT9HpvbY7IsYmdvwM61XZJ0QKJT1CuMsZRdJOK9wuDw3uHEehPtymWFUAivQIUYrQn9gu1hS21hOmuwQOjgipZclobYeZQXxEiEatG2JUISagiEQAchajxEjfeILl4ii2IWtz6mPj6AtkYah6lrrDBY73B4hPBI4ZBhwPZwi+GFq2xdvsy7dx9z+GAf1xY4n2OMxdqa9YnOoUAEDNIFb7yVEGaaj2/d4r//h7/if/hnCVcufokf/+Hf460vfYur119HKr2KyDoq2qtQxs7bZx25nxfZrh2XUorRaIQQgsEgY3urD6IhCBKsM0wOD4njhI10QFjUaBkQBIpIV7i2pjSO7e09jKlQQnD5wjYPHx7TNp6yPofZik+X7K7LgtfR+vPggCf+rvMd1j59il7/rZTyqdO4FKxOFK+QSHPOPsFvvAPvzyJQKSXeOe7f+pB2PiHWgnx2jDAV2hviMKQxFiVBCo+SoiOfawmm5aNf/orpbE7VVNSmBSnxCP70T/6Y7e1tBoMe129c58aN1/jK195he2eHNM1QMnzqyz7PnqKx0e1KzlmWyzkPbt3iL3/6Uz78za+YTSakUcy4nzHe3uT61ZtIFNKvExFPAIn1EWmNH796nAsntmbhWjgp0YFmrxdx771PSIuM8aUNNpeCb13/CntiEzcriCtFL+sTBoLWlARpQ15b2rwhC2CcSpLAkqQNxlmuXDBcu7bF282QX9/f5J/+6R0e7FvyosLWLaauEHTVRcZ1jggHTdVFWALRbZjO4aXEtRJcjgw081NLtdTcu+UYvm+49KZntGvoDUWnX5A6jvJDBIJA50QqJdSayemMX//0gD/9l+/S1g29cZ+tvW3Go4zxWJNt99CZJq8XDJL0pcfW245WJaTEozFO4qlWx0yB9XOsFBgVE8oQ6TV7ewnf+pLBmCE//fmMfFpzU4Rc9J7YW5STaASBFWjfzROlJKEEnWX0vvIltr/xLYK9a6h+HwRs/+gPUIslvmlolyXLo0PsYoI3BlZ8VLUxJLy6B4NNqnjEo+WEOhkx6m2yNY6ozZzf3rrNwYN7WLOG9gQ4R6A1cRiTRjtc2k0olnfJ8xkffviXvP/hXzDc2uHazbf49rd/yDtv/j7XrrwBQfC5juFzx3eF4bqzAGUFz6xOhWIN7J7Heumck1KaCxd22dvdBN/isVR1F5ErqdA6YdDfwDmPDjNca/DO0E9TTFsR6IDxaMR0PkULw+7mkHe+9BqPDk/5zW8f0zR+9dHPzwGd3yjk+hR7jrkk5fr3p3NO3c+dk+54wazKoTvAVcmuPLr4HNbNC51uWZYURcFiMWc2n7JYzPHeM+yPGY5GBFrz6M5thG0J04QgSdi9eBUVpCyKgul0in78GH86weY5TW3Iy5xhb8AwjambBiccrbOYVdi+XC4p8hwdKG7fvk0c/xm9Xp/XXrvJO9/4Jt/81vfY3d0lCMKnEmbPo3A552isIc9zbt++xQe/+As+evfXnOzvg7cMBwPGgwEKye7ONoONrc75P5UsexpYWc0weEHE/Ttb1udEeDidIJxiNB6RF0fc/fA31PUb1HkDTc3hw/ucznIIN/nKO+9w/cZF8rwmjQSn0wrfNHgNaRQRaUdTzGnLiuXiIbI6Ju4PuRZF/OTqgH939JCPFktKr5CrevQgUMRhhG0q8qLEtBaHQ6yOUVprlJRIAU2RI7VCBQG+0Thgclzz8I7g+tci3vhujZcF0knwiiAIqFqDcJYmD/jkA8fdX1u2t14j2FPoOGC8ucHezpDhRQcDh5BQ50sWtC89tEJEQLPioyo6N7ByNF4TJ4bXb0ZYC3c+OaGooF468klCbSCqLK97zRaSSDgCr0lWfy+AyEcoIYhkQLKxzcW/+YdkX38d0esRyAwXSpx0qEFKsLmJ954QiPE4Cd5YhAehFNYLrHMY4cBJBsJz8YIhlhIlc2QTEaUpQoRoGWCdRQuFs4bDoxKtYr7ypcsM0h43rkW898GvaNoJYS9kuJOyLI/5f//j/47/V/5/5drV1/iDP/zbfPMbP+T63rdeamyfmvfn4b8uKnnyFE+O7Z2mREC/3yNNE5xru1Jnr9BakyYZxhjqJicMY5JkgBcd7GPLmsVi0jERwgAlFc4Z0iRFCo9UmtdvwGAQc/veMd60WNvlm3gmOPusqHztfFlBL9Kvv8pnOGu5dsZP3tN1oDlV82K/8EKnO53OOJ0cs7//iLt373D/7l2csVzYu8iVGzfYGAyZT4+JpSQOQwbDITfeepNkuEORVxweHxCnGVrewVjDPM8p2xYpcsbjDUpjMM7ihKCsKtZojOhY33gHZV6xnOccHhzyi5//gj/76X/khz/+I9760lfY2rpAHMdo9QQ8N8bQNg3T2Yz5fM7dW7d491e/4PjwgPnpCbapGCQx436P4XBIGATUVcVge4MwTvCuw3PP09Ce4MasBhl4BXL52kwdchi09MeacN9g4oSt3V2a8gHzu7/h9kmfe39lccZR1Q1RlnB6/xab//v/FcZrJtOKvDTESUDrWuaLBdvjiD/5d/+eo7uPkFTs7m2wtbWNkAFSp3x9w3EpDfjPjzyzuaQxDc61SCK2NzcR/pT86JjWWXCeOI7PjmnOd07YGoO1LVaps2Tr4rji9p8r6rnnxrckcWaJ0hgvLVna5+C3gscfVhzdX5KohI2b1xmPhuTlkjSJiIaeYM/RhAW5ixj2R/j25Z1uJwLTIfGIVWIE3x2xvWW0obm0AYEJefy4pKwtJ1PHn/7KsNnmXBOOC0KisARIIhQRq7cUHq1B9zbZ/trXuP797+Gv7VCt9AGUBmRXoeXxtE+V4otVMqdbep4OA8Y4hLd4GsLQ088Syv6Av/rNhzy69y7FJMe0q/jRW7xXICUtEUeTioPje/SyTYrFBGMajLFEXmJbj0bijaFZTvnoN3/Be+//gvFwh3//P//ypcb2fJCzdi/Pk7J5ApiC1gG7uxe4dGmXONFI4aiqikE/RUiLwCFEl38ZDsf0+wOMMwhpWVYlQdCBTUqEREkf7w1KeLa29mhNw9HxPk0j+PbX3+begwOcE3xy/wDzGQU2L6p6fTaYe/a5Z2lin0r6u1dwuvP5nJPjEx4+fMid27c5OT4G68hnc5b5nIu7e7iypJ+k9JOMrcEQURVMpr+lKioO797hdP8R1XKJxpHFIVVdMZvnGAcKiRaSXpSA8zRmDQV0NJ+mbs6+qGscdVXz85/9ktsf3+LihQvsXb7Kt771LS7sXSDtZVRlxSef3OHD995j//E+JycntEV3w/AGaSy9KGR3OOTS3g5BEFAUBY0S7F1/HaUjhHNdIu05O+ITh/vqzAWAr3/jBpOjJeJCRionZMEmxikwiuzkMcv8lMVJzvSkRUjFeLePLaccHjymMCn3jgoWZc3WIKRqgdoQy4ZPPnqfg0/2mZ7M+dY7b1K3AUXpGAwTjIfIe/7Wzcv82SeC2wcFRVVR5jmuqbBtixbQ2K40s64r4jg5OxZ6KSnLAmuq7rEwYMWFom1y7vzScvLY8/Y3ruKEIk40tg04/OiEcZgyvBJTVg1SBehAs7s3ZPvCBsn2knm8j8dyvDhgIUL6Uf/lB9eHIDxBIHnrrbfZ2Njggw8+4PDgCITk+NDwoY1oywXLRYMSAoNl3CjeECEj1yIFxEJ1GXHfFSCsEyt6MGTnxz9h6/e/jhtkHWzGSuVrlXs4s2d80TMpkpUCVgff+bpBGYPWAUIEaNWjmAu0jDCquyYlU3rZNmEQUdU5eT7hl+99iJSdfGVrWpxTzCcVZX63u2+Noa8jlA6w0nN8cu/lh3YVAa6jWylWbIgVZeE8JOoALSVZmpKmEaNRRhhJTNNinWW+mNHLYpTW6EAikdimwdqKKI7x1rOzNeboxGDbllBnDMbbNM0CSYOQniTukSRDBgP41tdHvPHmVU5PluwfnbIsPRKHO5eH8b6DAdbFEuvHPnWrPoO6+iyr6ik2h3/6bPw8+5xId8Lx8SEPHz7g5OgY0zQIBIUtuHfvAU2+4GKg6I9HDHo9Uh2w3H9M09Rs7OwSXb+KbUom01Py+Yw8rxF0VJq6qhgO+vR9SFFbBoNBl63Fky8LrPeEWmOsIYgirLUUZUlrWiamZTmbcefjW3z4618x3tggimLyPOfg8JDlskTgCANNoBUBmu3hkGGaMB4OuLCzQy8OqYuKwjk2dne5+faXVwP3YujgWd7wq9jh4oB8WhOMYy7fvMSwSChayezwAKV7jDdTpHnMfLng0bQkFZukwzG37zxiyYDjeU0WS0ztOJzVTPD4ynLl2iVuffCAw9wSRl1k1HpPXhXYppu8ylt++ObbJKHhZx8VlGVFW5dkcYKzlrasEKFeIb5dMsHbDhs3xmLsKjKpLd7TUaFcQ9sYTh4pfrE8Jop6DHspbTvjK69fZNgLCIKAx4czqqpk98IWm1tjfG/BqTwi6wfUbUkgUqytIIxfYXQlWebZ2wu4fDlDqZA4jvBeI/C0bcCdx5ZAey5ciMhCSXFQcbFSDF2LVoIAifYS5en+Uwok6PEeV3/8I7Jvf5UgDrpIVnQUL61erDD1uVftuqOt0pZsEPDa69e4f/tdislJl0+RhiAU7Ozu4JwmNT2KckFrW1xT4bxDIJEiBicxJbSiIcDhnaTVjsJZiurlTxFrSqbWqsO0A0WgV1HvmfMSHXHDeEajARujDcajDO8NOEEUgLECZzTBSrs4CMMV1u0IpERJS1WU1E1FEGjCIACv6fX7aD2krWcoqTGtI0tTvK8RImRjPCYNNO+8fYn3fvuYouw4veehgGfX7nkoRMi1FkfH4f/Ut38eW8P7M/qY+By/8GKnO5tydHzE0eFhl1zxayk2gS0bqvkcO+xhfSfq7L0D2yKdYTk9YrGsqJczQuHZ3RrjdcHpMqdpW5xpaZqKJIqY5zVt69FaMhgMGPR65MscrTWL5ZJeL+sk2qaCuq7PdtowijpRlzzn4OCAxWLR4cRekMYRgRJE3rGzMeKt12+S+i75kAQBtmmZTmccz+d8+/e/T683BFwHGjjxqePH+QF+3k17GZvnNSIQ1FjuUfH94QZ2sqDKcxazhvHmCCl7zMtTZk0AvS32l3D8cI6KPShNVUseFBO8SpjNciaPTglkgu+PmT/OcWHGoKcpnOukGb3DSk++nFN+8j6/f+Mmt+857i+6ovdlvqQuKpqmIVxJ1BljOgZD2+CcpW27KAUMQnVTqDUtiJgojEBIymWOqRvevH6BO3dOCZQCFCcnE+7eu8fGaJPGLzgoDhA6Rw0FxsRolUAoODmcM0x3XnpspfJcv7nH9nZFefwBH9yqOV6uZUO75I2QAdlQ89XrKeEkpxCaCIiEJ8UCGuklodJoIVHe0SZ9st//NuG33kaNElrnkGIV8a0y2p9nnzl3PCit0E6hnCHthXg7Ikl6LCZHeB2AijB4Fst9IpUyX+Z4apTs2BjSScKox9bWa1inOTm5S1Ue0TjLxFXYxtKuJChfemylQGkIA9XRt9a82FWYJ4TAAtaBdZ7hcMxbb79OmiXdBlFX6EgSawiTGKUikl7arTnTMhwMieKIZbkgiRNcEFJXiw5GlBFJEhKGMUYLqqogjoOu6MGElEUn2j4eD/nu199gb2eXP/nzv2K2KFbKY0/fg+cl5J9XC/BZcgPPwhDdv68EL0w5OTlmuVh09LF14lRKlLPEUtLWFY+PjkhjzThOCYXlZHLMwf5D2tZ0OyEwqxukMwjv6GcZkVZUTUNednhbVVaoQJKalH6vj9bd0T/LMtI4xePZGG9QFiXee+q6RgrJ5uYmAsjznLruKpjSKCbSmlgpBlmIdpZmMmVzc4vx5hbGGlqrCKKI3uYmr335HZQMOi1UukjhRQ732Z9f1pqpIlSSalFxoBy33AnhyTHCF4ShoqpanO+EcWanAQ8XFndYsbPVYywrwkBzPDWIIGI8cCSpYFopHj/Icb1t4nHNX3zwgI3tTWIpmeYVvUSShn0irSiMYHMUMcgiOMypqxoFNE2zWkAdKLfmJlpnVxU9Fmct3tsumvFdlFfXNRLZwRHOUC5zPnjvAxb5kt/+VvHazSt8/PFtWm8oxSlzPeHKpT5xpqithtKDkhRNxTDcw+QvXxwxHA65cumbBFHNbz76S45PWqzyINyqQEDhnSRfCma3KsbzlqzQBBIiKQh9saInBsiVhsJxpBFfuc6VL98g6adIoBJdgkwgPvNc+VlzaU1FWkdK1nZaA0EQEDgLbYWnRGmHISLpXSDUmwhX8+joDpgjwKKU7Yj8XgOSMIjwwqBChdAesBhrMOKJ/u2rlLArqYijTseiexeHF7KjFHuJNaZjLmlFpBXeOvqDHq+/fhPvLQ8/uUMSa8piQdsavFTgBMYZoqBjneT5grqtUUKRJDHOlmglSbM+eEsUaHyrUVITBAGt1gQKGulwpmQ8voQUkrKyXL6wQRhGPHx0dPYdnuL/P1MPsEL/P3U7zzvYZ99nbc7bzy08eaHTLaqcfLmkrRtwT6rEJAKtJWEg2dwYsSgN795+wHakGEWwXEwJdUg/Scjrmn6WIHtgTqYY0VV4bI9GHC9yPnp4iAyis2xg27SoQUAYOaI4IgoitAo6DrCSTE5OAcjzJUkckSUp0+mUpunw316v1yk9OUMvChnGCbujEZv9Plk/Q2iBtQ4VBVQzw/U33mB7a/fckUA8UwryxP5rONrzlroQoSW19Szyx3yg5nxNpOxsjUmihqp22FJRhwP62ylbF3YZbozY3c7o6Zr5fMbJUUVvOMZFXauTKk3wQYpTFaQ9Pto/YuPXn/CDb77F4cmMHE2kLLVp8Drl3mHOw/1T5Op43DYNbVvTVWytCkFci7F2hYG5rnjCdvxeZKcjK+XqaBY62qbu+Nptw+NHj3DWcd9bBv2wk3QMaoaXJbuvbZKNAlpvkV7gfUtVGsIoJglSwvDlRVmKYsL9Bx+DbHl0kmOlWxOswXcVRlIY+qUlODCEKELlCNAIYRFCdZGVgwL4rah4QMT39nZQaYzVgsa15yhSnJWYPi/aXecq1q16zkdT6+fOc0kR/mxzk8jVNVVIVWDdEuFbnDXntHG7qivnYDGf0DadbkVV5AhUV6UmHCiBd+Lsfr2MdTTQ7udO/EbQGmgaR2s72EKrjlI3SGJeu3GF8ahHvpzhXEuUaOq6IusPMcZ0JykZrHSJoSgKdCgJ4w7rlUKiVUScRKRpRhyF5IsZ4BmNNrtxFIKmmSBkSF3VTE4PcE4xGvT4wXe+ws9+dZf9/QnO26ccp6ejgXnHpyLWF9mzzrZzyJ2WhP0cdbwXOl3TGpq66bo5nJskzjmMtVjneXQ6xTWGrUTRqIBpVZIGiijQRFoQDrbZnxYcHh4SxD1E0GC95Lg0PJrMqUyLt92Ey8IEpTXZoE9Qa6QUSKHI0h6l6SLikR3hgcFwgJaCum66DKWHJEmI45h62R1FQunJAkWgwAgDShPEKQbJdDaj9p43v/EdVBjx5LjwfExXfEZy7VUsGYZIq8jbiqSvOSkn+I1troz63P/oY5YnE05rhUk2efv6Dfq9lCyRvH55ROQXPPAN7e05jRIM9iI2hz28E6uCEIHDMmvhLz5+xNe+fI00iykrQ2O7nlIyjXn4aM4ib0Bo0iRlaToRER2olYygwK4Wt3OOtm0Rslu/HT5vEVj8qua/bTq9AykVeIc1pivmcJbFIqe0M9753hWuvb0DWcPR7ICgH4C0OC/Itvq0RY11UJlX0HxtSt5//0PA80R/5Dz9xzOUhq8Gil0fEUgDqsL7GOklSimc8MyE5SMDH2pDNhyTDkeoKMa6Ti4wCILnZr6fFw09S6Y/T9x/OhnjkEJgTItZ8aVF21DNjqjlKcIbpBNnFZLdIn8SNDhvKMrl+sM72EIpkqyjm9XlqynkrW411nUVdW3rqKvuBBHobgMWeEItuXH9Ehf3xti2YdkYNrfGHU5bGZp6jg66SrllvSSOUpx1hJEmCmOUBOEs2BYVdi2GoihE65DxuI9SiqZpcN6zubWNVJ623UcFGU4oqqrqoAcgiQRaClp3XoYS8A6/Wu/uXGB5/r69yJ6FHoIgIIperGL+Yqdr2rPeQn4tfiMlRjiU9+SNZ1aXDGjp9wdsJiFV5TmazRC6JQgjxLKhsZDXltlyxqSsyaua2nrmi0UXwQqBlgoXxVR5zuP794jikDiO6fd7WFeghCBOU5S36ChjY3ObKp9w8OiQ0/qUKAy7XXJZ0NaWKJNIb1A4Nvop2zu7WASPHj3iYHLCfJEz2tqiNx4jzonSdXPxHBHGd80MzxOl/2tZFI04uPcQ5wxxnIHU7OMomwaVhngkC59gVUA/VQwHKW9c2SAzE6gWyHaBtCUhMePEEJg5G/0BvSzh5FSwMcp4+PCI/Znhlx/e5fe++RXq4xmVE+i4R0XAvccz6tYRBB09TAKmaTrFfudW939VBbWaA846rFlBDK7tSOKum0pNW4OtV40gu5JKYy0yVBRmwtvf2+PNb14iCVMqNycOU+q2RHpD1TQ0JmccbZHqhKqtXml8neOMuC68J9QBXmjqxpJKw1sSdhqL0iCEOiuGkUpTaMGRc/xV6zhOBVk24vWbN9jZ20EG6oXRzHla0WcJpqz/3tFxdKWQOGfOoJrAgzKeh48fMp2dIoMAEXStbLASpEcHCmPsWaeL1ac/9VnrAielJE2jV/fVrpp0vpx1FZGOxoAxay53p+61FjKXeMaDAV/7ylv0shCtNEk6oKlrTGPp9Yc0TUVRLABPXVdIGaB1SJ5XCOHZ3ByglcTZFjRYZ2lbQ5polNIkaUYUtThn0WFEUfVorSXtj1A6hJPHJPGI8vCQt9++wt2HJ9x9eLBi7a2jWrmqM3FPUXqflSB4Flp4FmrsNtEO03avEula57DOdmrz6w9xjrXkzbzMUW2LDRVFCw0KHSpOi5qltzTNnDiM6GcpSdbn5HRB0xoWyyV53XQ0Drlq0CcExnnSfkbTGuaLGaPRiN0LuxyfnqBFSFMtKKqSNHYMsgFl3eKcQSvo93od11cI2rLqjuwtDJ3ndJmj84K6allMZyyqnLysuJhlBGH41Hd+2qk+cb5dBYp8agG9qg2yEYvxhMX8gIuX3yRJQ4Yb2zz+ZJ9NrfD3coLBEFkb4hAGiSQVJZk2qDQiEo7tcUYcOEQ1I02GiEDQy2Ia59FhQCjBOs29hzO+9naLk5p5bRj2IupW8OB4ifcCgWPYTzCJ7o6nrQdnsWYFuHiPkGIV5QikVDhavHNIpRDCYUwFwiKVoq0blOoSHGmcIgLD3pczdr6cYgOHVQ1YSehDBtGQvJhyOrvLcLOP8Zay8pRN8dJj6xEo4YgCUK4j4H/l+hvUMuZ0kbNx8ojr9ZIgAKG6jg9OpiAkSwn3XMAja1gmkjAO6KUp4/EYvKcsC6SUhGF4FrEK0bWGOY/NwhMZyXX56VpQe72Am/ZJYKNWr2nalkApkiCkqSoG4xFBFLKsqk6QpzXYxuCtRWuFc+d4s58RFFjrMHmzgkNeLXBojKUqu7J+pbtGmnLdpXe1MQdK887XvsZ4Y8D+8RG4OTeuh1hTIJUk7fdh6SjLLqCRSlO2Lco6XNs50uFgRBSF4Gqk1GgZdPQ0LHHSQXMKSVUVFGVJk8+weIz3xEFIlGT0egM8CnN4yM0blzidL5gtlp0m75PJ0uGwknOtmsSTUOss8j1jfq+feQYblijRVaa9yF7odOu67uAFaztt0rWn9x50yGyRo5xlr7dJlKU8OjlBtjVF1VJ6gZEBuYHj6RLrYV7U1M6joxjqrjXKevJ652jrksXUdt9RCObzJY/3T5jnS4ZpjKlq6tYRKpienlA3FUfHx5RNSRolOK3wzjPeHIEUiDhmVjv8NCfoLdgZbTAMI6LpKcu8Qvb6BEG8otmcIXPnRkCwVndaR8BPEcNfMeo9nd+hZUI41MzrA4L4IgenD7lw6To6jNh6yzJ5kLO4PyMSlgsjxU5fksgI01g0hn6s2Bxm9GPN5ighF5qLGwkPB32OjgqyNON4NqdoLbd++wnb165RNFAayayGeV7hXddTyrmW8bjPo4eKtjUdnigEfqW0hAAZ6E4Y2lqapoZVl13vukoyIXRX+7Xib1o8Qnt6FwTphZrSnDJroPUxrhE0piKoI4bxBmw6FuUSFxt0ICnLV4h0BWwGIXtxRC0UdTrkjW98l8F4E1cvOPpX/5zwqARt0KlGRT3auEd44SJiPOKaVKTTUw5OT6nqmksXLrC1tUVRFMRJTGMsdjpDmAbjWtIoIYkT4qyHjsKO3eFACo2nU1aTQlLXFa6ucNUSU+fMZ3NaY0h6A7auvo4R8iwZZeuWGxeuIB0cHB/RHB5S1zVOgNRdcYRzDi266NN7SV03K82UztaMCms7Za4uVewRr9AjrSwalJIESnYbseh6a0jR0cg8EEaSqi55+GCfzY0xTdPw8NEjNoYJURxg26KDntZaCCqiXC6p6wYpBUPZY5nn6EASxxFRmqFlF/zkyyUeSdwbYJuGpmkQUhKFMVKEnBxPKRNDEgaY1pAlKbtbm7zzla5j9f/8pz+naeynTiFriGcNMzzb8Xj1wid1qc9AC3J1Hz4vHnuh010zAtaY7vl+8851WFnTGCZlze3Hh1wbxvgg5uFiSukNDkfVGIRStNZSNQbruyNnEAS0xnT0ktXCba3F+abDyQDnaubTCUEYEIchlTUsipyiUsyWj6nyOUVRIISgKAuSJOkSaqLDd/uDAb20R1XMmRYFWRyjveR4nrMwDZdefx0QeNdpl346el3vYk8G+fy/r2pVYellF5jMjzjYf0QzcUSxYHxjG5EqsgsbHP7n9xhm23zt9Ut89cvXSFUD1Yz9R1O0aNke9+inAcI3pLEkwLCbGK6NFdUMojjCzSWts9T5hFhfQwzHLMuajx9PyIsC0DjRLc7NzS2U+hgwZxhusKKOOe/wlqc3nVX0FoYKj8O0ZlWUEJwxMFCOresDvKjIpwWNqVmEMaFICZWltEcUjSAIEgKV4hwEoafX+5wOfy8w6T1VK6iSDBcN+Mp3vs2Nt75MHGmcKOi/doNHTU5w+SZ2Y0yTJixsjdaay1e32bl0HRHEfPD+b/j1r/6K69dvsLm5iZSSJE4YBBGL6Zyjx/e4+9HPER76acZwc8h4vEWWbKGk7rrUWrMS45a0VUE5O+o459YyrwqCMKRazDFekWxt0+uNMMaglWKQZVy+coW8rZlPZ7RFhfDdMV5KiVed8w3UqhuxkFSl+9QcjYRnFGki0RVHL3j5bsBRGHXNJrFoKQm1Igg0g2GPLElpm4a9i1vEsSZJApp2gZDxOtWAtTVtU+FsJ6gklEaqCNySPC8QCrJeQlVVQB+Epj/YwDY53lqUEjjb0lYFCIWQHTRjLWTpgPnyGKW6xqnWGJbzBU1b4kzJhd0Bm+MhhydzoIMDnqzrJ5DLmUN9xrGuTwlPHlsHa6C0QGnxFFz5PHuh0z05OqZt2zOn6/FI0dXga6UghLwoeHBySt3vszUYU9c5VgryqqFqagSaUOqOoeAkdtVxVSnVUZDWC5hu0qwVqQRd4z1sizSC+WxOVdU0TUtQW+q26qhsq/cyzlLNpp2gdBAwnU4pik6Ue9zLcEZwfHJCUTQ8PJnS291g98KFMwB9PYZrubY1aeSzMpr/NRyvsRUnD5dU7ZJvf/UHLE+Oka7kcHKPcr6gnGqqZU2/57h+cUC+mPPw4B6DAJqqJQ4DNuII4Q1JpOnFIaWB1y5tEgUhxtQ8PpwSSIlvGm5ev4HQlvsHB8xLwb3D09WG5/Bes1zmKyqYW8nZ+ZXjNd0xFn+203tvV5FsV7rZtg6pBNa1Z1QiHwedZqrzpGlMGqRdlrotmVc5cQiZTIliRSUqRD2hMg0hEUfLA4x7+UhXeEGB4kEB169c4u2vv0WcgXANRZlzfHnAib9MYRU2n5NPD3k0nWDKivDXv+S1197gnXe+wRtvXqVp6i5SlF2CTSqF9Y4gjUHCoNcnDAK8g9lkwWIyYbc/Z9DLugISp/BCsixLThdTFq7pWAzekhcFgWkZBRGurlbMEXcmH7hcLJnlc6qyRChJ1M+ItGakFZQFhTdMy5quZU2Nc+YpaGONHUshSVVIZB3WtYjod+5J+ylTsjuNSq0YxAkXdgfs7m2zvXWB3mCElJLhIOmiervE1BVONAwGY8bjPlVdMjk97RgD+FXPOk9de45PCsYbMXVZYgc9zrRwvSTOejRlSRQqEGCcIYxjtId6WZIXOctiQX84JO2lVFVBuZxzdHiAjhN6vTEy6PHGzSv0eqecnk46nrPvtDnwbiV083RD23XUe55Otn5NF3d0zloJtfq7V5B2fHTv3iqq7UJxRSdOHEcxo0Ef1zZUyyVlWfLYOFrTcHFni+/8/ve493Cfj27fIS9rGuvBtXhvUercRFiJAyvVZTClUqsvvSJvW8VkNkcrRRLHXUJGaeazacdnVJqirhCqE9Owdo2bdWr5ZVl1R5VBj6K1lK3l8HRC5SzfeOttsmS0wmI6vLYbYOhgBc6Gdz3wT/59wl99FavKgijIwCfc39+ntTNceYKdhoz0Hk0w5OKlCzSN4d7H9zDxHnZaw7DpuiIoRWAL+lmPQHdc51t3DynbGB1lvPPaZT6+d8AHdx/TNIYwTXk4Kzhceu49muK9I5Ce1nVtbbSQeGvQWrAsagKlcc6ukmJPjqzWGaxp8K4F7Ar3F8jVkVWFgiQOCAOJ1IowC/BUECRkSR/pR8zyY5raUieeUTJAW01RluSTGWWwREUxTr58ssdLA6LByZyi3MdXBTaNmU0fcPvjj8gnhxTecjpfUtYleZ7jlMAKT2sM773/Gz786H2+/vWv8+br7/BXv/6Iza0RGxsbgCCJIvr9Ac3mEHecUOUNJgiZIxmmm5zO5jRVTpZleO9ZLHKqqqIFFkrRFDVbSpKkCUkgiYQlTWN0GuK9QYeKZQsVUDdNd9RVCiUDskAzwBBlMbUIKMspjbW0rV/RweQZy2htjfDs1yVKSRamwbcvn5OQsjuKKykZDFP29kb0Mk0aWzZHMcPRmPlizmDQpzXg0xhvJZvDEUIp+sOY5WJBWzu0jmjaEuPhweMTJrOGMA7wfsZgPMAJtZp/LW3rMbahqgChSPtx17TTdBK01sJimXPpyk4XnAUJNd1cqlvHsNcD6fjOd7/GYjZjMWv485//mv3jCU1rOq1h0zFBOlhmXdr82QnRp+CFFTvlc7r1vNjp7u/vszEed/Qf2SXW1r3FojBkXuSd89MaYwz7J1MOTqbcfnTEcDQgjGMaD0rq1bHCYlY4zrpVhpJP7ySwKiF0LevSuhpP1dYEOkBJ29FErF31a/WkaUoaJxRFQdu2VFVFEARdczvjmS1yyshQVzWLvOD6jau88+3f77KcSq0ityeUm892tuvHeOo1L2tVYVFhQxYlCJNj6iUWTxRnNC3kreU73/0ydz78hJOl50/+80cE9RHffh12BmoVXbWEoaa1NXnZMp073rt7TFM+5PJ2yGamwBka13I4mXNaa6oqoSkNcaJRgcTVXdFAEGqgK37wntU94ixR9GQsONPH8DypYwfQKiBNU7a2R4TS0VYFG0PFaDsG7altjnIR/TAjr0sOJydEwlMWCyCiL7eZVge0dUMS9156bD0SnMGbnPpkn/nhCZPjfe7d/gXSt+g4o1USEQcU5YxFW6GcIgpD0jhhuVwymy549PCIK5cL5stj6rpmMBiQpBmB1rS2i0hda8h0QJxlXOolRFmCrlMe339EFEVY6xCiYDweE6Qp4yDEtA6xnOIpO76z893m1RbMZlM2xhfIooTN0ZjW1Dw+3GeZLxFWMC2XbN/cIIgaenLIg5OSuskRPkJKhRBrTvWTuWst1ELR1C2d6snLlyuv8U/nLJPJktkwY3dzE2dr2nbB6XFBmPTZ2NjEuJjlfNbJYgpJkvYBgw4CiuUcHWjiKGO6aMgrS20sp5OCqszY3oGmtV2rJW+p6xZnG6xzRFH2JBnZ1DgHYRjj7EqtcLEkjnssq5baepC6K9hQilBEKBURp4KsFxMtO7kBZ9fUPbGivXVJx6dYDatk4doF+BVE0WlyaLTWNJ9TYv078XTDKOpk6BAIBXVVsVwuGQwHpHEMrqsQWxY5eZ5T1jXN8UmXJAs6zl1vMKCuaxazKc67zlG0hrU+b0f7CDrc1z7hL3YlqLJrd4KgdaY7ejmPlgopBU3TEIcd/tc0DR4o664csDEG4x2+aSiKJdLDjZtvsLN7kSgKn6oeeVLC92mhi+exGl410u0PhvQGA0LiTqDaOMJss2sX0obMThv6N8d8//e+xGDzIttHD/ngZ/dpb15FsKQ3GlOdTPE6oCpzjm494N/+yR1O9VVCJRlnFRuR4sZuj91xzMb2Du/+8jYL6xCipZ9ENIGiLEuQ0DYVh4cHFHmBRK0Emdetys8GBL86+awnnmlNV6WoNMPRkJ2dbYbDkMC3GG0Zb4akPUVRTpG9BkeCakP6UUY46NHkS3Sa4oyhWS4IEkVbNTj78uyFCMeGVoyAxJY8vPUzlsIRa0USJQTZEJ0YdrY6LLpYFoQqYWM4ZmNjk8eP79M0lsnpgsePH1OVS37zm99w48YN+oMhAG3b4h1IFdCYhtgZlLXga6p6jg66+eFcx1/WISRhj0Q6WtdSBZYEybIVBL0Bmxd2UVnMqZwjhSTSCdl2TJpEVG2DM5aj42O0VjQ4EqmZzWcY2yWShHKd9KPpbpjQclXIYjs+qgBW1Xjn5/jLWLcRO7wQpNmQ0eYOtl1QFnNCnZH1Ioq8BAFBkNIs5xzMHjAyWygtaaoGJSV61Ylj0E947foljk9m3Ll7l9m8IkwEb9y4iAhCwjjGG03TeLww6CBCIpHOIpzFC0lvNGLnwgWWecFsWXB8OmO+OEGIgMFggPMBRblESEOcROR5TVO3BEIQB5rGdywSfTY0a7iBsw5PXcUQCNcVhUgEXnSnXuM8bWMJglcRMbeOuq7Rq8TWOpRu25bJdIozLWkSMxgPEULSLwpOT09p2pY0SVBKUdc1gQow1nZJnSalNl3BxaDXIwoCwiDE41gsF0Sho6xq/Ir3uQbf27aladoV/trttFZ4RoMBpmnJ8/zsCCykwJmu+ieMQvr9Pm3bkmUZ/SyjKAuqssQNO/rbmewfT6LYJ5nJNXPhvJPt4IVXVd+flceMN0ZIYWlczWhjg5aCZdEi2gojNvAy4vKFMckg4/e/9w4XLn0JZh+RDVPSfh+9rEl7Q5rGMT+ecOfU0bh9fvz9t7lxU7M1nTHe26CXZbTOg9Is8xqlYNRPOTktELJLkknpu1beKw5ux0ZQ+JXeq191BvHGdLKLvhtn6LLWw+GAjc0h4/GAYjGhsRXStwwv7RJKiUj6hAmgPb7wLKcLtoaXaIKAliVKBqhen4P5EaQe+3nntBfYN5Wgj0SFmuTKHsE4JnEtO9tXSOM+Ku3gKt9aHj16jPQBUiQs5g2DvidOMnBzxuMdxqNtzFXP0eExx8fHOC/Y3Bx3GgSqS+RsbW8zHo6w3lI3NZNphbMKITRKWqJIcvHSNhu7F/EqZpnn3LvTUi9ywiijd3GHbGebpm0JoxatArTWBKHkQryN0gpvLXVbEAaaXrzNyWTOwePHWGcJtEArTdO0oDRS+jPuqTUWpTvWSTenHf6VtIqfwAtBGHDp0iWsFUiRIJSnNxizmC9omiOGwx7D4SatavCy4PTkgF6vDwiUVigdsrW1y3y+JAymnC4m5EVFFqXk0wVF2SXLrPUkUXpGW0ziBCUCmqZTw4vTHo8PjnC2JQgisizjuDjEewiCECk1zapDtTUWa1rqumQ+n3cnZ2fPij68XyfQBUqt+M7nNBuEYBV9rx3DelwgDAPC4BXKgJ30NKYlXtFd1sfItjGdEtJQk6Y9lAwIwgDnPBcvXaZpWyYnJ5RFcVb84EuDDTRhHBK4AKUVEs+o1+Pm9etIqZgvFzw+OOT49JS6qXHWsSwK3Iq6tSZ1a92pEmVJ2lW+qa43lbUKHBhn0VKjhEIrsQLrFT7oqDxRnHadO609VwW0dqhPsEt/xuXz55zxuVF+RUuiIdPpjCTWIAxF3dK2AlMaFrNjqrljsRyhgq41+V7PkA8sy8IQ9gegNVKFBFFCmClq5Xj7y9+gN4h552ZCFueEyQ7DxtO2LR8/2OfgaEHje2wMA9IkZqoKuqa1gqqsmU7vd4sTtSLs21WCwWCt6fp/NS12VSGoVDept7e32LuwA8LRVAuioLsnQZBiMzjK9xlFI6gSpnZJL5Fk44zKFNRNSZRoIh1gK89OusP+4nHHFX5Ju+kSjAB7eZfotRuoLEFWc6DB+wbpoZf0WIqWojRYo/EBtG3Nvft3cN6wtb3FH/zg+wyGCWmmsMYxm81Ik5SmnxEEgjgICaOIoimxJx3cor3HFYYgTAl0hi8rtA+YHOdU9T5R1Ellhl6gw5C4P2AwuIwQCU1TEWjNcDDEGkFZLvDQFQMkCaPhGKkCcjxL2yLShAtpyiCQmMpyJ2+Y1zVi1QnE1O6M9ri283zzlzHnXKdjrQWBDphMJnhn2dncpL8xIM8XzKcTTFtgmgmBUgw2RiAr6uWSuixxzhGEEQ6Jl4q2tZwezinzljBOqb3ABX1OJyV4SRjEWA9hkhEEEomiNV1kaQ2IQNGalvnpCVF/E4RAKmialjB40sFYB5K6FuTFAiE8SRxTN21HfZTr3o+CJ8Mj1v87N36rbhPnYoIOA+4YDP5zgoUXO106eTNjup10XTu+vmmLxbJjMaygN9sYRoMh4SCi38s4PDigLiuUkmit2NzcQApJ2zRUZUXdVMxmU06Ojrlx4yZhGHFyOiFLE7yzGAyhDiib9iwTe74yJJACLWBnb5vN7S0Wi5zT0xlVUzGfzVFKIpxlMZ0hpcZ6sNoTJfGZRuyztfLPwgnPlng+7+eXtaqq2b10hVBLjGupyjkur2jsnNp6AtfneFmBUtR5QYznxoZmvwjxTtDUhjjrYYTCuABpDa/tRIyGEaPQIVE4LQmTmNPTE04mUx4fzUmHCWkcs1zMUOtKIi3J87JrqeR9x0RYbUpSCrxtaKtOb7etalSgkFISRJrRqM+NG1eIY01Z5dRliWkrTFsS90aMxkOO233mbcmVvUtIEg6nB/i+JwoaEIbZtCROBjhhkXR6suN09NJjq1CoUKN3NgnHIzwSZ1bNHqVkeXpEGPYQukdZVoRhhBAdHjgYDrl8+TI/+MEPuHDhIqenJ+zvHzAajRgMBmRZ1jVTVZ7Rhav4KGY5eYydLmiLJdYqZNCVEbe2xgoQWmMtlMuS+ens7BQm4oBocxMRhXgLUZCQNw7vPJPJESeTA4x1LIqcxeQYYVqOj44wQhCqhCDqkylJT5hObKU1CKcQrcG0FmssWndaB0+I/K92QgsCRRRq8rygqQ2PDk+7Vu/GUVlD0yyZT2fga/AhBwf3CSNPuZx33zHLulZMwtG2lkgHDLKMm9cu0xjPPM9prSHRgsPDQ9raYqQmwOBaAzKmahratiVfzLrS9CLvhHgGA+aLnPm8YDZZsshbBDlFnrO9e6HjBuORMuTu/U+YLpY0thPnEawq+OCsorJj90AXcHUY75peKgEvuqIhITqectMYougV4AXpu5bG4M8WYFem6LGtwzQ13nbi4qPRCCkk82JJhiWMQobDISYMSeIIqTsydRxEJMMRRVWyf7BPXVfcv3+Xpq6Iez2atiVaJTLW1DIp3crhStadUYOVpkIYKKIooJ+lZEkKzlFWIWkc0TZt12SxQ6OpTI3WAc6as5LPbhKucFy/6mIqzth453Y8z7mezq8KiQEw2hhTuBmKjDhLiZMepjhClFP6w4RY96iMJOyNafbvICPBRm+EGQ3Q2hNGGh2mIBTzYk5bN1zfikkSj2tK4sGA2eKEJFXMJzP+/BefUFawvacItCRJYmrbRaxJGJD2Mo5OqjOaIELgnEAqQVNXlIscawz9XkK/F7EoShINFy9uEoUKU1cEOPK6E0pyQG+nB5khYkAS9MjzJS5u0TpiXi/RBGgt0X1N5SoSFSNax6A/YL6cvNL4yiRE91OUFuAl21t7RHGAUpKynlAWFW0JBkeQxFy6eIGvf+1rvP7aa2T9BCkFbZujdcCbb36Zti3I85L+YEAYRrSmxkch40uXGV28RCA0ddWQH5+yOL7P7OiQaT5DCoEeDBHRCqZTmiAIScdD1PaYMBvhpe4WsggQKOaLCUU1ozUFQmqUd0RSsdHrURclkzxHqQFCR0yNZ+kj2qamlRVR0CDpURmBizVNVa7u53olSF6ly59AUhQV1nVAxcHJlOPjCVkUc/X6HsLVVFVFLwsQWJQOOD46JAw0zguGoy3irMdscsSgnyHwpFnCzZtXGQz6TKZTwBGFkqZZUi6nOHsBLxymWeHoUnWccFat7qViNp8xHG5SVKe07YLZfMkyX+JM14U6TJZI4UiSkDjudacN3QVwWknSJFkpI3ZJsSJvaBrZ1RP4DsMVQnbJNTyo1U+rQLDTUhZY8wrwgvSrN1pl6c7qxrFIoNOZ8ZRludJf7bQu26YgjlN6SYLVkiDoyiN7cUikBVo5BoNNNjdHlHlOPl8wnU6YzafE/TFBnHB6crw6Etiu6FiK1XG3YzyEumuM6RAUjWEynXcTQgpGoyFlWVCVFaaRHWG8NRSTOa6NEUKiVhU9HYKwqu9jTbx74lPPB7QC8YTH5/8rNKd0kjyfImtLvliyuX0VEUnCaMCNCz/g+u7XuKg36IUOu51TFqcoBWESdo5Kd3hrXde0piGOI7I0RCpP2ZoO5jk9pljO+ejjW9x5cEQYjxkOekShJo5j/KJzumkaEcdBJ8+4aiIq5QpQN45yucC2JVIFRHHIqJ8wTARbFza5dn2X05OcqihomiVN3WCMI8p67FzbZJafIBJLlDVI4WltS+OXXacDpwhFd3RvaoNXglRGWFPjbP3SQytCIAsobIVcnpImA0ajHYIgRCBIkoQjd8piURNlGXEv4A9+9EO+9MabdFO+S6oIGXdt5auGvMwJWoG1NdYGeN+itEEIjbchUgdEqSa6mpLtbjHKF2BqoihARwmVM7iywVQ1QRSSDYbIsNORNaZLeFVVhZBdAUF3hN/Be8kgFfT7FVWVc3A4w/sCFSiU07TSkjcNRniU12xvjLh88css64I7Dx5w99ZHnSqYEEit6A+Hn9nG5nexpu64wI21OCyHxxOiIKCJLb3TGYF0qy4PkmAlR6aUJk1TrOkqt0xd0u/1EQiCQGHaljjqE4YRYRR0jjG0FEVBvphSLhfoJFqVWjuMWau2SaqqQjvbdQ5XEUmckaQl4+1NjGmJo4QwzdBRTKglaS9BVw2jUZ8sC4mMJMsSsjQ8dy8MvaxjnjR1Q2O6qNysCoaM7ehkQmma1q5oql3T06IuXzh+L3S6SimU7nZgsZLwE6uF6PBoqcl6PcJVzbmxjsYYhAHlDIau/j8KQgIh6KcRdnFKL0sxGvobW1y8foMiz5keHXKy/5hHRxPqyekZOdw7S7TKBratQcgAIR3SdwmCqqoQsxmiNexs77C5d4H5fErtu7+Lg5iqNdBaAuU7JgSKybygqLumi4FSZ9xDL59wfY3pjtpRFCGFRHjwrsN9hH91ZDcQASoYoYMU7VrMSY5uevy9eIc/kDfZDfYQxzPqf/kn8I0B/TfHLKsKHSqyXr9LLBqHdZ44Dsh6CYju595wh2VRY5qGpsh58GhCaQS7l4ckcbhKTnaONYqilYhJs6LfdKcJ0VX+UhY5dhXFDvuSt24MuLwzROuAjQuXKVtBUx8SRQHLpaUsGoRU3Lj5BslYsbHTRwjFbLqPCCSmbRmlYybTkv3JATs7A4RtQUh64z7OeqbHU5bV4qXHNkwtTQpVXdFMLWVZM94YEQabZ51epVK41lLPlly7fpMLuyNQBV4ESBF20YxwWDqN257qcefObZxv2Nneo9/vI5BY23ScZBHCSos5imKiJMVLQSgVSEFoLTYzlHmBUgodx2eLtW3bToS/rknTBK0ytILK15RFRVWV5MUSaw1HR0fIJFyVZiuk82ccUQEMBiG9LUlohhycnq4CiS7LngxjopEm1S/faRkJZd2xIbRSOOdxeBrvaJ2gbW3nkHREayxZkrGzvUeWJQigKDq4ME0ymqYljhNa1SXK035G1jRoJQhDi1SS6WxBvpgSiD79Xg/rLIvlbCVK7qiKJbLWqLhPWbcUVc3m9ha9QR/vHNOTCePNjubXKZNZWmcQ3rC72aMxlsGwTxwFeO9XtNOatm3RQYRpA9q2O/mtyyPKylBULY1xiKKhKFuqukEK82qY7vjiNYTrGrZY6I4nK4oX3uJsy+ODA7IoIg5jEBAnMc4IvBV460mzlM3tIaJq+dZXv8QbFwLC1PM//OYD5kLwd//e3+enP/v3VCzpzxO2xpamyJn5qKM2ya46SgaKWnetPgQOLQVaBQRasZGlXL5ymYuXLhOEMVmaoZXm9OSApjVds0knEDLCW8HHdx7yYPlvzwoz1huJEAKhFGZVfWTbFilW/a5ERydbO91AaaSU/MEf/N5Lz90s3SBv5sggo/ZLTh4ecmWS8aNJy6WDf4rwAdpawqMT9sPXiN76JqZtSbMBOtDULRhrECiyOKVWBd51O3sySBFRghKe5bLk4/unEAQM0wyMwxuJVQ6hFIEWZGlCYzuFLd9atBL00pRlMceZijjUXN4d8PUvXeTKpW2ctah4RJCkLKslcRyRLyvKwuFw7O5cYe/KZdr+EUhHHA6ZHGsiH6FNiMsbxklCU6RMjk8ZjEaYtsFgWE4npL0MJ14+0tWjFJ9EJL7DVpNwgGs1zhsQBmcs3jomixllXZPEMWBpm4Yg8AjVcTGl9AjdVXGZoqWua05OThgMBoSRXkExnnAU4CgwrptvSmYd5rdqcbROxjjjVq2nZrQmItCdZvCZQpWv8UISR0MEAUVZMlkekM9OOTmc8PGt+zzeP2KwPaA/2EKrTqhFKIE0oFxD+2DBwbJm6uD+R/cQq352OGgWJYGXNM3Lb2jWGVoniKOAeCVj2JXtw3JZEEhWfc8gDiKUkjhrEHT5gzRLSdMeRVEQBAHew3A4Wv0eEehN2qaiKmeEUUSaGqpygRj2O4aS6NT/pOwcfmssynviIGBZr+hzQhDHMVevXSONU1pjaU1LWXQb3mzykKZcEmlJlsYEkcZ7u+L4h/QHGWVREYYhVVXjXMf993T89V4WEsUhi7xrDda0BmPEE6jyRXPzRU/GvQxbd3q3SjxJKnV0EY2tLHnRUFUNo74gS6JVrX7QaR/0+4yGfSIdULmCaDBi69plkmDO5dMTfvp4yv/9P/4zvvvOBf7WWz/g1h//gj9+9w7zWYAQHRbmvVtlbxVRd+7qSNZRwDDL6Pcy0kFGrUM+Lmo43OfLQ0m2EZDPU+blnGVe0BiHVgFCKUpvqfIFUnbJIOs7YrqUEinUuYTDGjbvEopPaaQ6f8bhe1kLREybH1AXJbPTE5J5wB/5TS41ltD6biGFCvvaLpf/d3+DaVDijmbEiaaoW4rGUxc1mJpASSSOKNIMh302djapCscdq/j1vSMWS8mFnR2G/R6BkkRRRBhrfFmgdVdx1tQGYxvCUJIlMYNeRqgMl3Z6CF/w1be3eOfGVUKdcDxdMK8aRNzt6oPBkNOTBWmaInRCNtpCbnii7bo7+rZTtrZ3qKsShyPQmjjOSC6Meby8Q+FzoiBjNj1mlp/Q+i0CFX7OCH62eaCczBleuEi2NQa65KnzjiJfYK1jMplQ1TWbm5u8/vobhKsmm3Yl2L6eB93v3fx46623qKoKpdQZTVGvioOaVcJXyWD1e3eSWKuRrZOSaZrivaNpDN41q79vQUAUZl3A4j3GFkxOH3F6uM/p3fuc/PYW5bwkCqKOO78Ss1FKY6ztYKayonU55ekp02WOMRItY6TSOGtpKktblXjxCtKOssOEO1gqXZXDdrBb1x5eYpoSbyQiiCnKJVVVrmQ+DXHcZ2MjJoo6f6F1x8ywzhGHAWmkmM1rtM5QMsSsWnuVZUGgg07rWUqkCmidIu0NcbbTbLFFcybIlGUZQRAgtaaqKryRKNHlJ5rlBExDsBLsMW3Vnd4DgdIeKR1JGq/SOB4dyK4cWatu7ZuWQHadaSLdsS8WS7einL3YL7zQ6QZRDN5j2uasxLODGjpfLsMIHRlcU2OMRSlNv5d1O0aZU4eaUiu0SAnimE8+uUOm4I1Lmu9f3cVVJTIwfEMo9pqSk61NjH9AkoG3Fmc9izxHqE6aTyqJaw3CtQwHfUa9kO+8tUn/jTf5f/7lfR7cucP3Ng3/4I9+wHQeU7gPCU9O+ejWHfKyIolDZBiACrAIWmvwxhNovUoSdloCWgeraiy50oSVZ05ZeA+uw3TV58kJfY7N5sdoApyp2ewP+Zu9q3ztvRly2eLbjnzeyhD5lauIN/bQj/cJowSlFW3jqY0nrxp6Uccn7A9StjcHxElIHCfwz/6M79/XuHqDD7IGM+rhfYMQAUpBFIW0ZoaUijAMaawnDDX9XszNa5dALtB9xWA7RdLw2uaI7d4ObWORyxqhO0qOVorHJyc450nihDCJGO3FVMldivIxiU7Jq0MubF/Fh540zUiSIYvFlEBnZGqEcgHedzh1Gm0SmJREv3xjyrKsGG9eZLSxg9/aJtAROlDMFlOW5ZLJbMLh0SlB1Me0FVkWIQjOmDHn9TiMMbRte8b1Hg1HKBVRlDnQrtgBNU3TdLii1njf4lyLR5AXHf0xiiPKssSajvYYBhFCdGwg0xqc67izzgZY65nNJ5weH9HOF4y8QNaGkRJMArBKd/rAOBTgGkNVVngL08pS1eYsoSNEgLeyK/wRFQjzinng7tRXNw3GGkbDIc5ayqZGak0QSbA1trWEw6DDbcMYGYRnya/Hj+8xGm+ilCZLIhACpQOk79aflB6BIsl6GFdRty1VVXSO2nYqeE1d0TiPCiO06zo2tKbl5OSY8XjzTLDJWNtBC0Jh2oq2mtMUy04lbSUzWdYVfiXa6IE0TellA2az5ZlI/HpexFFEKzvtmEgrAh1gjMO2nrJ5RXghiuNODs5bvFlFfiun46QApQiShNoaUF1lGD4hTWOUEpi2oa4rAq1I05jDo0OCIOb0RHJlLPjR7kWiKKA8mPPTO0f88S8fcfuTx7x2/QJRHKPysuPzKkUchd0g0mGsYagZDYd8+809dq8HbG++we279/i969u0RvLu7X2KssLUFYKOo1c0lsFohJIhQioEqzbMrPBqAAX2rHqny1QiVNcOVvgVhmdgVRP+Kvbb+39BqnoM0wGXJpIfTY4Z//YQ6TSiaLBFg7hwlbK19GSIaSxBkuBRLIuColZd+0StMXXLxsaAOA1xxuDefUDvP7zHxSsXeO3i23z/yjv8d0d3+bWrGIz7hFrRNhXGtAjV3Z/T6ZR+P+WN1y5z/caYeVhw9Z2LzJscaftkboNMb1IvlwRhgTQtRbnkZFJyeHRCnMSoUDEcD7n4Rkyze8zkuEW1JYvZKZ6QXjpCywaNYdEuGSQp2/1dHjx4QNhXVE3Lha09RGuIxOilx3bn2z/G6wDX38DFERKFbTxB1KdazDmczPBSs7W5wb1P7vGzX/wFcfxHpFlEHIedAxRPytODIDiLgOM4QckUrUKqpkDK1eI+VzbdaUQ3eN817ezyERkd0UhgXY2pC6KwD+jVkT0H3zkH7xz4LjdS339AeHhKr3UIr+kXLfPH+5RJQt0fo5xiFEVkW3scHj5iauYYYxFK4IzH+QYpFM43CNyqvOpV3G5HkxoMhizzJ1IAUkmiMKSpl13XBxRxkqKCEGMFQZgSeYnSIUW+5PDgIRsbW9gkpqgaHIJAWVCqozHKoDvq98eIfI5xltq0RFJT5CVVVVG1lu2dHaT3HJ+e8vjRKcvlnCztU5YlZVliTEc91UohFHjRMBz2qKqS2hjKqsBaR5x0m7zFo3VAaxqquljRStUTHWQHoAgCibNdpVqWxBSp6ZKL7hXgBaDLeAqJWfUvWr+dWE0uLwVBHNOs+G3WdVoIznvmy5yyrKlbS1HXpFHAvYd3mfVHnMwy3IfHKGcBiYpi3rx0ge0sQSQRh4eH4H3Xa2nVJ8mv+kYp1VWYHM8cf/rzx9x8dMzuxU2+uTHg7oen3D8+4cG8oWlbhJDEcUbWl4Q7lwhGW7SqOyogBB2U1v0bKA1ilUQSneqQkuBdJ9Tj6TBdqQO86Mj/r2LehkxPJ0Q7Idcqz/YHFfrWMWR95MYQqoLi6JT8k5CsbnHGEwQReWOYzRoKoxFNhQ0DvHWEadcOu1hWnP7xL7neVpjbd6DX441LF/g/7Vzi/zJ/zL7qJOiWRUNdGeLU07Q1Ogz4xo23ef1Kj0X/hDYs2C8PCESPyeSUq5sXyJKEBAX+iMl0xmJhefBoCkqgg5goi3nj+i5XY8u+77FMLQ8efEKoQsrSMNQBdWNALdgcj8mnFW1juXLtBh/e/hmDnS2kUNSmpFEvTxnrffO7qBCcq0BKlIrJ0gF4x9HslH5/i8cPHxKGEVvbG/SyHkoFxGGftqlXUqFdy3ilNXEcEccxRVF0fbaoUIEnQHTCPatIVymFWUmWdi2LBFL4rnOu7roHx7FCSUVZ5TQmJ4tHhCqgXtSUyxO0iInHO9hFjsrnpLOcaJojaTFS0zhJXBS09z+hvaLQyYjRqA8uxFrL/v5+B4ety7V9s6ruW+ONr853FEKspBc909mMOI4Y9wcI57vOz96slAQ73QPrRNelO+11zBs1Zjk7xJqKRZEzn8xIsz7GV2zvRGjd6Qp3gZ4giVNqaxA6pDH2rAmtXjGjnHVnMq9xnNC2Lfv7+4RhyMbGRleqjgdj0bFChAOWS4luavKiPGNnSSk7XY22papLgkAiRERTt2f4bvc6QZYlNE0nZ6pk1z1DCPe5+9mLI920t9Kq9DhbIb0/62fmjFtxdgEV0Fo4XSxxAsIoYri5SRwkCNNSrmhI3lqaWrBYFsz7A+IwZDQYMBiP0Vp1NdDb20wnE4rqAVXbEAUBQdzRvGxtMTiM9+xdvMh4Y8SiafnlkaF9NKGuDbXz1NYRxAnLqmEyXdKKkGx3Az8YoZQgCrsspQXMSo9UeM7U74XoqGHOdRGvtRaPxllBV0dnEfJJNdvLWmAHxP0AQsUQh8wNMgyRSmGWBRiDWBYEdYNdFEgrEDJgWSx49HhC0UJPl0TGkQYSPcgwVUE7q9i5M8HP54jGINMYX0y4ohP+9saYfyIKjA6wc4lCszWMCaRhdyvjtTeHhMMFBQWbW1eZzibk+YLtzS0iJwi1xK1kAYtlw9HRAq0VGztjlIp547ULvH21j3n0CdfCTU6FYWM4pq5bru1eoSfHTOYTTo9P2BiOiMOQJpDMmgWbF7ZZ5gX/3/b+JNjSLT3Pw57V/d3uTp993rxN9VUAARFNASABhAAQbAUTJMImg5QlWwrKGmjkiYeeOzzzzCMrbIciKIdJmZQIk6LYmCT6QlXdum3eJjNPnn73f7c6D9Z/zq0ChCwqU8HRXRG3y+bmPuvsvf5vfd/7Pi9WMqkKNv3Lox0PHr2GxuO7BqPL4coq6Potu7szqqrEdj0XF5fkecmXv/JFdvYKtPKY3BDiiLOzC6Y7E6ZTc5PuIKWkrusUla5SMXBj1jFmMA9dg+5DAtsIQ0qYtli3IZKBGOFCQKuADoF+27F5/2O2z58wOrpD3Wyo51c0Hx/DokX7nKAkMQhUSBFSk0WD1xes9wOh30DUnJw+JYQGIf0gsUm235uK6X8GM2UIYFRyMAohyPMMJUCLSFUYbG+Jfc96s+aIAzprKaqKUTXBZBLnWvq6x1vLYjHn/GJJrpM5Rceatp6gVYbzaZajc4OzmsxIOtuzXS8RUmCyMcI7vAs09Zqmqdk2HUU5orctzjlGo0mSVgbPdr2kkIG8zPFWEPMMoxJzNwoIQqKkTnD4GMhVho2OKAN5PuQoDo7X3tnUz1eKvos4b5mMC5arDd0PiUJ64aFbjXfIshytDa3Z0NcNfdMiBQPEPKQDi3TFbbuW52fnrDcb9uZzJuMxZZZRZBnT8YimrqljZHf/gMZ6etvgoyCfzKgmM+rtBhtgVbdcLTe0NjCezJjsptRQO58T6gaPIkTJJx99RNP0ZFmBi4Gm72i2W3QxYvfI0PlIHwVhMkWM9xBZaqoHJZEhYERSWMghHTXK62GHJFiLG4ZlQmoEEqUSPPr6A/WqkT13dh+wbs8YNTXVeYVRFl0G3LZFBkHnoW02FCGynV9Rr9YsGsfV2tPZ9GYTmWa1uWTTbjiYPUDmhnBZs318ykGREdtIvNgQbSAear6+FPyrOzmP1zXz1ZqilLz56JDpuIRMYA5rPvCPqYodsFu0b6l9Qy52KYMkeguDf72pG7T0jMdjpAxMZhlff+uA1+/tcuJWXJ4sELclo52MSayoFw02V5SzgoojyvGU+eqMJtaMqwluBWU5IrjkwNpsX6x3fNEqhmt8VszSwSglxIAxmjt3brPdJm35t771B3z1q1/jtdceYIxJuXDW8+477/A7v/cditmEX/7Fn+HurV3CAHaCdMtrmg25NgSjKMuSLM/ITGqDJaKex2hJjJK2bQgR8rwgOkFzcUa9XkEhWDXHtI+fMv/W78F2jX/8lEVIgyNrBZnTQ3HqwCXTElKiHMjlklYLzs+SqWW1WoP0A4zoOuXg2vwzbM4rFroxynToimsOA+Rasbc7RclIHyPVeEwkcHl1xb4+5OrqkrKo2N2bIog02zlIydXVgjwbMd4f0XYbTOxYbWpG0xmm0EQEOi+RGtreY22dKGPlCBc1hC7tC5HgI531HBxOaZqGENMN9vj4mFxHRGhoXQvSU+Q5ZV6gTGTb1LRtg1AQlEbLFAOU64wYwAnL9eZlOsUG2a1Ng3iR+ssQKQuDVpLOvsKha4oCaRRRJY6ukgKCo+t7iBGFwA+Yv76tU45931HXWzabDXmWMZ1O2ZvNGI1GTMdj6vWGy4tLJtMxZZHsfMvlEpNlhJgC787OzrlaLBmNSsazMUU1HvzOkr61CBHpg+Xk7BwlFZmzBBR1Z5kva0zd45XEO09vKvLdI7zWBAFu8JMonQ+IQkeQYfBzp729CaIbnG/JLgxKmpSeYEPq27ziofvJxXc4mB1Qnbf8jL+N7J5BjCkOvW/xZgz0cLVlfnzMs+Njsr17bEOGzDPyHMzuhKkuaZ+8R7QRYTT5ssMstvg9g840OAedJzhHZiYcTCd8vGnxEe7eGfPlrzxECsfj9cectCcEemq/ZjoqmU5GXCwu8K5DxiSpCq0lBkehAzKHvq8Rmefw3oyLxQesK8H9N94kfPqYqljx6SdLZrtjeiEoJcRNgalGnD97TmsXmKoihDXzq1O0zhBCYSgZly+PdszMdb/9urwLIEFFxWy6T1U6inxEWRY8ePAQrZNyIU3FI7t7O3R9w+q8Zj6fc/tw98Y2nmVZMurQ4/o+DayGB7YaDvjrCXbihEhG2RiFoKl7NqslzfkF28UlWW/pnjzDnZxQrFbpwK7nCDylcxiyYa6QDlAtAiFI+ggRiXeRrq7pnB2kTZ7rU1WKNBxOEe1iaJ35m4r9pVdMLlGtIcsyijxnMh3DYCzIsgxlNNNJhVCkg8m1XF6dMptN6ftAXo0plKGa7tF1nsnOLt53tJsrgsrQxQSpBF3XooVCSnOjmJDKEFSGrVu0SeDw8XjCZNKhl4HVNvVxjSm5vLxAxZbNesXh/oQYRUoYxlFNZ4guDT9NpmlaS2dTykeWZWRZRgDaARdbliVd2yKNRkmTTDGRwTUrETIynlQ0P0SO98JD99q5lZclUgi6oTL0YYn1fYrb8JZmu6apNwTnb+Qj63rLtm2o+45NXbNcrrh/9w47symZ0RRZznQ8YTSdUpYVdduhs4zTy3M+efaEKCVCa9q+J2y3AFjniFLQdi2XizlN65Aq4mK6upmsIMtzVJbhbaANATGb4HRGGMTw3ntEFIhrWpmUKCUGPXJSNFzrd6UQ4EMyiMSIjEm1IKXC/VtIQ37YausW77b8NbfL7YsVQxYOwvZEZ8kKQRCS2Pa4rk9T0dGMi1rSFBohJAs1pu1gf7TDctMQMPTf+ojd3tMvAmbXEEWEvsOvPMs/91P0zWNcFIwLxTe+8pD7j25xsjzmsplzur7ioLyNqyxNaFhfbrl994h+3WLGBoDFcknTt4wKzXRc0FnH/p0ZK3PJs9MryjbyRQRowdnlM/LRmM02UFUNq8sVmTjA1T3ONtw6uMumXvPdt9+hbZYc3bqFUSNGRYP/IRXDi9+7P4AoAZJHQFCgZQ7asb+fs7c/wft4Q7OLMQVMPnh4hx/5+hfYPbjFF956I022BwCS0hqlFX2jiDYVH0IqvHU0IQzUqoBSGj3OIEqkzJAikqtALyMhNwSl6M4/xT75lLheQ9enNtfQf40YnMyBZOGNIUWoBwFegI+R3ju2W4tTCmv7m9aGEGJoL0g++5hfJ1vHVxoChygJBJRID7O8yMnznPFohLNbptMxpyfnvP7GIy6vzlivt0x3pqw3K67ml0zGI/Lxfpr+K0VeBKazQ4SIbExOlk/I8hEIWG9rXOjouy1N1+K8xYdIvdkSnUPKDGVyxqMJV2WN659zOXeMypLTkyfU60vu354ynhQc7h2wml8iQmA0mZBPdmCzZdSMsN6RV4qzs0uANEQTAu8jRhuEbHE+3eyd8/S9u1GegECp9BArywz1Q55nLz50FcQgk2BZ5khlMCbHRui6M7rtkrreJEhKuGaHkr7ZJC2rr2tsb3FdTzmq0EXJRCU6liwKVJaTVVUaVoVAdKml0DqPjZHoAlmZtJM+pkjw6WwHIZOsxnmXYqWJGGVQRYXtWlarc/K9Q4rs2nmTgvvUAM6JImVQKTUQ4mEYjEmi8whpyKS6uYlJmRKRffCpp6U18hWvaXeOHvLWacNPrEqwW3AWulSLB2Fo+5D64CdXVEGzc+sWH20NtZzhypZcZbRR88nzcx5IybQQhGdrJu+eMSpLslyDMkQ07uCQ7j/6m6z/9BfZ/t1vs6k7ZiPDwwcHmEpjW8lot+Lh/gOaEJB9wHcwznfQ1pBlhqJK4OjeOoQUVJVhNCopihwOJOdmw9mq47tnn5AJxcGdO1Rih+erZ0gm9K5nOs24Wl0xzW6xu3+LPJviuoiKYyaFYf3phlDWjN/cA1O+2gb/kXV91RYSjNSplRA6Ygx8vys2tQccP/XTfxqtM2JwSJ0CN5VU2L7HeYXMDfl4hPMO5z3WOSpTYkXy4/uY0KhFLtHSErxC64osr/DhBHt+yubjT1CrFb1NbZvIEDLpQyJwAQibanWvsRH64byMMdCEwKoPCHndc1ZUVUnwCTEZ8SBSBuFNBYxE8PKONKkzQvAYlRwfSkq0MvTW8uYbb+B9T9v0rDdbdnd3sdZSllNGlWG1nlOVhsl0j4inrpPmOUbBqBqjlKZpW5arJSrTdL0j4tjWG/rOJltub7G2pygKbB+wAjqlUZmmysB1keOnT2naNV94dJtH947YLC9SBFBwCVo026PzKSJsPJ3Sti3bukYASpm0ZwqMMvQ+MBqPqbctQcRB2qhJktJkcVZKoKSglpYif7G+/IfagG96nJmkLE1Kcfh4xXa5ILRNEgzLZAv+o4VfjBEfItZZ1vWW47NTrHPsj0cUMhKFZ3F1yf7+fuqVaIU0kp39XequxXtPUZaYLMMAddOAEExGY+Znlym8T2u63hKUYLtcEkgTxCAFQWlMUeKlRESJ8+GGf5qA7BohJdroG/SbEJAXSczufXqzXwdnGq1Qqa4hCjE86V9+3d/P+V+6Q0YfnCKu5sh1g/Ag0DidEfseHTvswiGfbRFfnvHhBwuWLlVl637NxekVFyfn7Nzu2Gae29++5M0Htwh7Le5yg/3yFwk/9iOYX/l53Ne/wPv//B+wrXtUlvP6nR0mh3usfM9Vt+J0fkFmNB89fYbRnnKsceuKvdkIOZthhUF3KQ47xIDrWqISzA53OMkb6i7Qh8ATv+Lh4oq9o1sY07G/d0Q/t2x9B4XDL1vycp/N5inLJazmHa89eJ312TF+VJDfKtFGsm2Xr7S/f2x9/0Mypg8P0SBEZL1e3VTHySra3xDo1AAycSEQJXjnKFxM7Aofca3FNg1aK3QGo6xIlWgIGKkwURE2lvXqDNf32PML6ve+Q/32+8jlhmADSipccMNLS4AepE2HqUghsCFEolQEKfAxshaRrYMYPWFguB4eHvLaw0eEEPje977Hdru9+bqvb2ZBaP7cX/xrL72NRVHR1g3jKsdkOX3XJccnCqJiZ2cPItT1FqMnCCFYr9eMyn28i8wXG6Q2aJXhY4LIrOstxaii6S3bpma73VCUJV2XHopd1+J9oOuS8aEockJwbDabYU50BAiKTLGuW1arJYd7FXf2ZkTbIqJns17gfE/f5XjnEULRdx15Zuj7Huc8ZVnhg8BkGba3KYk4y4jWEWODMRm2d+R5Tl03SKGHoi2xhYUQaPPiW8QLD9049Lgg5cL3nWX+/IT58acQ0uROqhznLNa5AXTNkDKRlpSSKCVkGicEy/WGkUnxGEpet5kcyki6riM3ijI3TMZjrHOMxxOq0Qjbdylhtshp64bVfE6WZ4wnY9quZ75t2G43ybk2qhLzoarwMFQpqccbRUSqBCAOyFSZW5swkOkF37RVfBhYZENWUpA62YJ9QISUSvoq60sfL/iRb29Riy00PSKA85FYGDovcds1mRTUSLbvnSO+esgnj9+h8Ts39uT3vvsO8WoNO3fZ/aDm/rJF3BqRMSXeuoP/z/63dH/2pzmxnpOPvsX88XeoraCQjjfvzWjaSz5ezPne6dt0SFTl2d3LWTzx5KNdTOnZtsmt88R9zH4v6IJgMim5/LhBoFBFpA0d+wf3+fTj32MjBG6UdI/dyrHeLmiuWkLW0awzDqoZ7737be4/3MXFyOzgNsG23Hl0m5PjEzb1FdGUrwyJ/x9b34/uTEnlGUI4xuMx2+325rCNMd7kmwmR2k9+XaNiIJNpGt7WKdmirdvBOSmgdxhjyLUiGoEIAlyfuLjBopTAE+nnS2LT0juXDlOX6H2QgPJJDCoBA0EOaqFE/CMkBPmVkjy3CXQj4zDUIhBDTWd7XPDp98fEkEAk7e/e3i3+4l/49Zfew6IoaWqFlpKqzKlbx9PjY958/RHbuqG3DUeHBwgBTdtycJCq3W3dsre3hxCS3nk22w3X8fBDhjvWOi4uLthsluR5BiRmb9e3iJi8ACEGYrQJZC6h3WzZbjfErCD4nsXFCfiWvfEettuiMCnaynr2Dm4TkYmtcB2RFBTrzSYhIsWQB+hASTUUZRn9ZosPHtv0dK1NtMIQUGaglOkkAxRA/iqHLjpLbQPv08ApwmJ5SfADk0CmtKUghgGCAmE02mSU1QRtcqrxONF7jKSpO3IUk4PdBDGWivF0QlUVtF3DjW3ZebQQ2ADT2R6j8Ziu2YD3ZEpRrzdEIpPZCJ1lGKkYCcW2aZJ+NkSC86BLlFDJQaYlVZbsmknmQ5pWx2umQqo2kCkcMwqJzpLuUV0DfYYm+3XfunsFUhPAL59XZE0P1iG0wmPRKsM2lixYsqKkJvL0J36Mw1//DynuWfbLd/l//tf/DTs7e2jr+fT4OV/Y2eErZ2O+cLKk2hthTIm3nqBBFBX/r//u/80kc3SnH/L06RPqdc/t3YK8ELz79Lt8FGsaG6nKHB0068U5b37pTUSmCeYC5caUecbJ8gJRKw5377I/G/F2W1OVgg+2p3wa5tzZe5N7t/bZnF3QhWSBNWbEdKdgf++Izarh9PklfVEz3RnRu47WdhTlPaTOOK3PMZUg2Mh2s6Esdl96b/0f+d5cV7Gf2XuvH5gDBFtIqmqE1pqmaW56o1JKMqVxXcrlCyEB3ZWLBCWTvMhaRAwQHV0ryOQoSR2FwOOJRPIyT+0ZF7h8/AnubIFramIUqUcaAlKlataFwGDZIcoCZ5Pg3knwWDov2JCx8A43zAmvv77zkwXryy09HmsVIiq4mb4HlMr5tb/8N3hw782X3ts8V0kv6x07RrNbFpxeLHh2dsrh0S7ee5rGkhcZy+WS+XzB3bt3yIoS6yI7O6OkbdWCvu9YLlcgJPP5nLIsOT09o2nrBMjXZUqUJimHBDCajMlzTWEUUWkI4JH0jU3W5FKwP51wMMspckNAYG0kywvKcoL1nm6zprc9+EDTNCghGY3GtC7iXU+RV6nNFBJdsDQ5LnfJFevXdF2P1mm4J6UgM4oQk7qhzF7h0BUMlUEEnRcEqSiqSZr+qx90ZE2mUw7uP2Q02cH2jmbbML845+r5c9aZoppOmE13sF3Hx0+eEI6OiOEpX3jz0WBPFLgAre3J8hLXXnB1ccHpyTl5UaT+UfSMxiMuLi7SwExp6rqhd57leovWmjxPej+Zl5hqB6mT7i450MTQwx2ujMOgTChDwBOEQF7/NVT411fMGDxaXw9kPHlhiOHVdLpfXEikG8DMmSYqzXaxoXWBcm8XX07ofukXePC//0+5qHKs2/KXfvzf46PvfMTjdz8lP1vyc2bMN0Pkz57VHNzax338MX3skVYSfY4XgUd7Pc3lE86Xz9nWlq6p2T+a0TYN337+Hk3MiVKyWl8y2hklmJF1yCJgG0toFaWZcNyeU9gRU99ibUMWHSd2A1nBqBizujqnbRuWl2tquUJKuL2/y+XlCV5Hnnx4Rt/2bKctR/f26VpPiDvUK9jfN1wtIahIPlKsVx3TycsPe6y1P3Dw/nF533B7iUDMQHqcbxPIZ3AfrdbrQQ4X8YsterXF21TJegFWgVMR3zcIZ5ECrGww2w6ZV7RdT73ZoI0mrzL8fMniex9y/J23sfOLdPMiMaKlurYe5ygBjhYvFdIl2aKT0IqId5G1jDzBceoswaQ5xbWkyQvL1tvUwRU3s7/hK5a8/uiL/Mov/2WUNC+9t7lR6Kyg6dZY6zmYTOinls26YTFfcv/ObWL07O4eUNc1MUqsDVTlmPV6xagaE6LHW0eeZ3Rdi3XJ3HAd8WVtj5CRTEfUuBpUC5JRNeL27TsJ6VjPEaZIvJeiol5tCN4zKXN2piOKIh+qV4ExmuAj52fnaCmpt0vapqEYT5KNWGdEQMdA06dkDOdcohiSzkE9hN0i0rD12q2Y53nCgfpEoyuKV2AvWNsneYzR6Y0YHEf37nP+4fvo4CjLEqU1Esnk7kOO3vxqirM+OaFuLsF27E8rVFGyaVpOnj5BCzBa8enpCXVbc3zynIODfQ4ODglAMSoZVxWHd25hqpzvfe9dtps1d+4cQYTH779P21km0x0Wi5raOdAZWTbC+R6TaazrUWWFHhVEbdJDQyYgTCYF0SfrKyR1QDdgBdMbM10rkg7ZJQu0UAShiMOHscpzJAH7ipWuvtoSnEOtOoK0hHVHdJ6OQHQdq2/8NKv/4j/hg8UFl+9+xPHpb/E3v3XOf3HV8sE2Munhdi54Y3dCWQrCdoHIFLqzIA3BaC4NNOdnXJ5ecnG+Yr2t2ZtqDncrzuQps4cT9sQun3x4xsXiijv37jEpx4zHBcdXZ7TLmtgvWNY1vWxoyhFVNaJQhqPDGet9zSd96vHv39ojZi37kzHTYkK92HC1fc4nF8fkY0G5W9CdOrLCsLtzRN2uadcRWQbWl5eY3rEJa6rDESE0fPzR81fa3+vk6evi4Ho+cW1njzGmgMEYcQ5izNHBIZ0nOIMPAb3puXz2GPfkmM0Hx9jlBlkVmLt7mElFdbBDdrCP6zWuWaI2F8xXDaerDduLc8LVVYLLRAi2x24bvE+VrEBD/IzSJQEnBF5FiBVKSHwIWBmpVbpZRaXZSMl56HAmFSLh+2LXk5Py+z0QQ1aazBAU/NKv/nXGB7cTWe8lVzKfC6yHpu3ZrFdoKdndmfDJJ58yGU0YjQ3OBg4PDplfLSjyEV1n6fqezbZG6wSRWa1WxAiLxZLlconSirIoGI0nyYodk1wsz7Oh8DG0bQMExqMZFxdX5NUIpTNETCoUrdKDSEqFNoYyzxhPZizXW4RW1MsVfdOQlzm998Q6pdsUZYFvLbHe3ACM0vtG4UPADzbva3iRtZaiKBACnPOsN8lO/MOUIS/u6SpDEDrBKKLEZCWj3X12bt9ie3aC7Xu6vqNrLGLniFGb+LPVaASzKcK2rJeX9JsFIgpylUwS1d6MbLLHyZOnrOcX5McnQEQLSZYZjg6PmM6m9H1P4wNZZvjo2XMuLi4J3jMeVciuxeQZ27olkjR0ifCUMW9qjh7dSu0RkTzhXgh8FBQmp6gUvQuECCKGZEW+dhVpc7OxzpN+jUzgZEECwoiUG0/k5dGDANIF3HyN3HSEFFmBRDDKS45lwfKv/Apn/Ybf/Ef/V067DziUUOy8wZve8gUliDIlQIjFghB76LqkF60t8dFDml/8JebZkn6zYLGo2TaBPCt4dH+H4mCHd87fpW1z3v/0XeoLx+xWRd96lqsNzbJDKE1Z7nJx9ZzlZk3PltcePiAQmFYjDvem7B6NOPbP6FpJvQwYY7jz8ICJ3OX51XO+e/EOq3DFQbHLrdu32d33qLJnvdmgdGA0KQlxQ+8Fbb9lsUgP2HuPJNt689J7+/0OMeDm8L3mNKcPTkTpQIwOFSQhKIyqEFonPONiy9W/+D3mv/d7uM2C6HWSDS4k3dljhNBsy5LZFx5Si4jbbLEXK/rlBmEdwjtkCAQBYdD4+uBvyHUQEKK/ec2pMo24kKLCY5CEOAxtERQRtiJy4S3N0Ae9/po+W4HrSKu0D8MhERxf+vKX+TO/+Ksg1SsdutY14FOS92pbY11NVVQURUlZZbz3wfuMRl9jfjVnf3+fohrhY6DtW0KIXF6eMx6P0EZxeXVB1zlOTs+x1lGUhvl8yf5+oCgylFTUtWU0mtJ2W3rr6ZoebRQ2wLbesl57Zjt7ROcI3g2BmWnWpDHDwDR9tpSQ7BwdUDdrfO9TXh2pElaZwUuDWF7Rti1uiDryISC1wjcepTOkSEPPaxMMwiDEwBUO17K8P3m9uL2gFVIl04CSCdVho8SMp9SffowSMfU7SdfR6WSK1Io2y/HeJetksOiupq1rgrWEIMlGU8ppyfnVKZqYLIExIrSiv2x4dnaOznKUlDhv0ZmibXuijezOJgOAJvVQur5jMpkOvmfFcr3CjMeMd28N/KXEg8jynKgUlpgoT8rgXXKVFFli5yabn0uKhRBASIwyhEGbKwFjNN7ZFGypfzi64kUrnC/R20RQckIRpURnGluVLH7jr3D6lfv8y3/1f0dO5/TLK370Cz9NudgnZO9Q4AnSI+o1wWvoPNIYnN0QqjH2iz+C/I2/wvM/+LtcXs7pbXrDvHZ3h7uHu7zXnvJ4sUDbikk1ozdz3njtDYzS6KCJIR1S40mFm3asa8t0XGE97Ex2Ec7y8NHrnLs5wkpmO5NUdemes3bOJ3LMerMgHmbE0xGr1Zbt6n1++mf+DB89+xZCdSitcZ2n61Ml1gXL3f03yOKIeb8gKvfyexvCIOv5wQP3s57utUtLIER6nwuhkYNW2m22LH7nOyx++w+J6w02OIyKBBET07kTgMN3Dd1vrVIaAknlcp2k5aPHD74MpeRNj/h6UJeklZ99jcm1G0EFkIHgFRENCEQMeKE4BZ6HDi8EejhYr/MDr/Wi19Uu6XeCEBSm5K//+t9mMjlI7stX0Jgn/Kehd5Gu3yJFQMSW8Xh8M+j68PFjRuOK1SZBqzrbc/voiLqumU3HdF3Hat1Rtz3bTcNqtR4oYYaT56c8fXrMeDRhf/8Wk/EErQ0mkwQDbdOjvcaGDUZrVnWd+vBDEME1VrbeLBA+iQBOTk7RxqCDx9VblNFgkwxUDq3GruvpekuMCWAE4ua21LZ9SsqJnq6zN9VuSplI6TlpoKaHSvxPXi88NaaFuUl/FcJgQ0RkBXt37rM6Oaadnww6Xo0hiYZFBJWPmN59xGg8Qx8d8Oz4Ke7kOaXWmJ0DQtQ8e+8DXNui85wwiI5DFLg46HvbGq0N2uSM9+8itlvEesGkzMmUwHtH33QQI8ZoynJ0MwAx5RShMvIYCVIidE4UqToNQFZUBO+woUdrldKGjR4kcokLamTC7Vkf0TofBisOVJL0CJlYEa+yNr5D+4DUBrRCesUqkxz/1De5+rVf4d98+//Dv/6d/5av/eiXeH32iPujHbyqCHt7qOcbhN0mF1ptCdkWt7vPRu9T/PVfQ/7v/mOeyJrJaEQfDetmi2u3lLOCzAjeO/6QKBym8oDlzu09qklFEXLETsF6u2K92uDslv39HUYTS682HI0mTEYT6osLqsmUxx99jMsj5TTn/NkVRS7Y0PFuPCZ6hQiKL731FRaLE5aXWy4uTzk7nXN7/w65LlktrxBGMZrm3Lk7pakjl4tLYiwoy9Er7e/13CEOHI0fVENcD9Nkus4w3DOkQG07nv7j32TzO28Te7CEJIuMw68fKlIR1WA+CPjoh8N2OEvDkG4SYnKORUGMyTx0fUim5/qQRh18KjyUQQ1VsSNFfwcEmwDnMfIkBKLRZN83PANuHjDXA0BEonzFqIHIV77+U/zpn/wFMp3hSajCl11dW6P1LibLsb0nxJYQAheXFyglKIsxi9UKFwN1mwDqJiuoyprl4mpIm3BcLea4GDk+PqHZbri8vGRnZ4Jzlqbp2GxWNG3D4d5tnOu5f/8OIRdcXM2pRiUqN+xOK7quZzFfkA8uskJLRlVF7/qUBuzTDSzLU3Lz/OycerVmNJqCNnRNh/ISlWUpzknIFNeOoMgL+t7ihuRh63r63mNMehiGEOlah/eQD0D3BAL6k9eLdbq6JIZAVpXpsJKSymRkRcls95B3f/efszw5xgZPNp6gtE6eFyEYj8dUOzNWixmHkyOOXmto6zUieOzilO18QaaSV31UjRiPK7QxrObzGzBzWRbIcsLkzW+wXm949vv/Ml3xjUrJCQHG+ThdAbzDhyTaL6qcWBa0IaUFl0WBUBrbp15ulBKtc8zQHI8hIoRKFU5whBiQSGRWokIkICDEBEGXKTnUO494RUnTotRw1WKiRhu4nFZsfvxrfPq//lX+2Xf/Piq/4NabR1ha4nZL5QXc22N7b5/i8Yr4xgj77JRYt9Q+kr/5BfL//D9E//k/wyeu4R/8g/+Sr8ySW6jMMw6qXXYmhnl9ztK1NEtLoOfuW/eow4a6q/n229/j7p3XKUzOujlnWXtcJznan2FXgS/evUu32rC6vOK97SWfBosUGVoHimKE69ukq55W+K0kSIft1+QF3H/zLot6yajcpW0E282cUbaL8wHX9ugZzKa71NuE12xW25fe2+u2wnVqq5Lp+xvidSRpSgCRQ9bdjXECSX96xead93HOkdp4ImmnbTpklZYI2Q8QJCD2IBIAyQeHjiJxkr0liIhHEYP6ARtuagFoQsghQu9bnLYooQlRYZ3DikgvIlspeOYFz1zLWoGIcnBCpXWdVhCCvzl8048riIbMZPy1v/63MNUYZDJHXJuZXmaF0KMzRVbOkEYSu0tCqMGDc4IQ1kihWS09e3t7tF3Lxx9/hFHQ9y0IRdNsOTs7QxvFyckxMThsb1mvNkiVXKLGGJpmQ9NtyRrDar1O38MQOD45Y3dvxtHeLkTJ/PwcEQOz6QgZLH1bI7VBDvrmrusGN1vA+j4pQ0Sa9WidJKwyejJTDUO0FdZGpFaEgaWMFGS5oesszicqofc9XTvwOJSgbXra9hXYC61Q5CZHIJAyvYH7vicvcnR5my//3J9ncXpM39ccHd4jK0uUNhhdEBU0tkdUM3ZGE0QMTKcTlpfnuPY+1f23+OSdt2kvT9DeIYFRnjO9d496m5whWZYhy4rxdI9y7w6r50/p588YCYGUmt42xCGKeTydUBQ5Xd/Tty1SSKhyJuPxzZWyMFnadGvxN/HUBuc8UqZqQQqZrM4+2S21TtV+GN7c3npEdGQiwqvhdPlnP7PLnX/tMXWOeuMem1/+Wb7zesU7z/4uZ9un7Ko7ZKVi0Z0yCYpcGta+p/v5b/DoP/3PyWrF8T/+H/iH/+Af8fbJOX/6p/89fuMv/SJP+5q//8/+b/z2x/8dX/rSL7IzyihuTdGhJ9JzYZdMdne5GzWxjazOV6gCiJ5bD27TbJfYVmByQ7twLNyG2WjKF3ff4rXxbTZXlzyvV/yTT77NRgQeju8wMgXqQLPu0sB1c7Vm92iK1AXryyX37t5nvuhowoaHDx5QlYYPPvggTbItqEmD67Ysnl+m6BZ/xsHh9JX2V0oJEWQQqAhR6eQous65C5AN6a7Be+JQlTYXl/i6wYZ0VU4fE4NUPd4FYsgRIiPGFJwaYkDIwfUVIjYKXJTIqNAhYoLCy4hTgRCvq88ESYEkBYsysUCsEPTBEYSgj55aRM6d5an31EqhZDqMIN7wez8bon0WNJBWerT81Dd/nq9+/ceRevha4wCretnlA65vkGZGkY+wocfZFj0EyQIIfDIc+B4hPCFEvvdOTVnmXM0v6bqWzWaTvg7foqVgmG3ffF77vmc8npBlGV3Xsd1uU6CCVCyu5ggReapE+vGupTSSMs+wfUPT9TgUo2pCYQwheDabNfWmJriePC8wJgehiLEnBE/TeIIIEOWAh+zYDsOxpA0OSJks4Na6lGwysGdijIQupYE49+IB+4ubkkIgjB50gGmCF4RGZCXOO/RIcfhoRIp6TNd0kxUYU6RETJ2hUWglMbmmsZZsdotsRzC6r9h9+Cbf/id/H+ZnbDZblJTs7u5SliXbzYa2bcmVoYgd1dEDzg/vsl2eI4Xm6mpJykpKf9V1zXg8RqtE8ZchBWdmg7MkxLRxST5i8F1AC4mKApllWJfYoypKlJL0fZ+i5p1PvaJBvK0pUTLZkuUrthf+y92Ot379PrmuaMcZi+w7XLz9JOVzScXz9THHx09548u3me3s4aNjtV1zvt3y5KPf46s/8+cov/q3uawk//K/+q94/L3f5vb3fotvv/8tThbfxUjYme1iVU8dLH3TYaVm4R2t73jw4DabZc3x4oxuvaHbruhaQTUq0VnF3viQh7cynp0948HogF94/evkUnIZLN9qnjF6OMbXa05OTwifKqZHOdnEoLWgi5onH58z3kkuv0+PHc1ScXi/4J133uHR60fcfbhHTsHivMW30PWO1bLm6uQCOXI0P6Q39qJ1jVi8vkbH4f2MACMEKkBQKftPhxQ/hUhVlF1eIpxN+m4RUjspaQuGiCcAnQAsCKAb3ocgRY73iY4VEDCkUQRxDaIZXHCohA0V4AZofggKb9NrssFRi8AVgk9dZIlBh2RbVzLxj9P67Gu89v9/NsdxVFXFf/BX/xY6H9/8hEDctDVeZmmpaG2DyiNCGLJ8RhNWiNByzTXzISAQtG2HlGm4tFxeUTdDYgYxJTpkCq0lSkIIaaC13WwJMTCZTMnznKurqzQUlTAaVQhSL3WzWdO3W6qq4uDoNtFbPAKkwoVIFII8r7B9g3eOqixxrWVTb8mLkjwv6fp+wLkmCl1KSZYIYZAi2ZStTX3edIsQ2N7SO5fOAZcYDDFGuqbH2jBEsb9g/170k5nO05tDMshqHGVVJhhNAKklwSqQBmkyyqKgqWu6tkGIiJIKXWaUZYkTkcatKTKT2JRKsrOzw+VXf5TT3/rnCYs2ZE1dU8pijExi5Oq9PyBmFRHPuDLkuWaqprRdosf3fU/v7KCRy2nWC+rFOTuTKc4l8EgmJK1th6wzOTAJJA55k20VSAoHozVZaQg+9eCIcYhXlikjyacD/VWBN0sXaF7f4aJpudo8Z3vVcfV8iYiaw9sjqvGIH/vJH8PGC/rY0dEBI3Ij+fDxb/M7J39IMxlzEp4y/sKCrV3xf/l//B+YzQrWTcePP3pElZWsY09wPvXMgbP1ij541vWaZdfQtg2jYpf51ZLp7gRp4Nn5MaYPFNUtvnr4iF949BUOTMm6WfPbx2/zXK9RmaCZ1wgKdC44P79iJsYoKYneQBOY3rpPGxZIIdjdK5gWM5pxy+WiZyYF54tj9spbONvS1Fv2d/fp1IaD+/t8dPbykrFrnbUQKQXXk5CIcbhWhmHWlP45RPPIpGQQLqlJfEgOxrRrDu0DkeRujDBgPwUypGGr9xIRs5tjPopIkAGiTnpZIRJsKYZUMCBw1786RrwGi8eLSBc9l0LykZcsRVLZJFm5ox0i0AUifU0xHd43krGbJfizf+aX+PKXv5EUNyL1jkHg3ctXut5DDD0y9kQUqByjJmjRDt3igB4SvIMHlRrMQ/hmxPZt4hXIiFYpeTv6mIozJTAm7SXA5eUFUijGkwmbbU2Rl9i+oe/blC5RFMhKUYymeLvC9x2963AxUE0PCCJ9v6112L4n14qyHEwTPqkdeufpowCZWo0xBqIX9L0lRkEMgt5asgxsD11nIQq8AudBDA/r66HbdezPn7ReeOjqvEz9lUGnFmUPSuNs6j1FqTBV8k4bo+msBa3Iy4LoAlJIyqqkzAxdsOxlWUrR1YpMGwiRu299lavvfY9JCUZJFosF6/Ua2yUpzXazJfQdav9pqhvMMDAYJpXOJelGDEkQT4Q8COYfvM30zi1ELAGBzDRG5ik2BYWVSWxtB8fZdTzzdYhg27ZJ9ZBlhJCkZI5A23tGxsAg63mVdf9H7/Fk/imzapf7D+7y0fufsnMwJh9DnmtGOxVXm+cs1s9oskPe40P6osY2njyT5GHLh+fvs7VzWnnF0cEeB3cmyCBZ2zW3ywrXJtWIFIKsLLmq5yzWG7Z9j+4Eq3lLMS7o7SV7e7sc3r/N85NjcmEwfeRoVvDNt77BUV7igQ+ffsyHzHHRYcKYkZlSHVRIJTn9RPD8nRUPvnpIVmiunsDlSct4Z8RqPuf23XSDUToSXI9rYDrdY1Rp6k0kq0uU0OiywoWI7l9+f68fkpHBIDCcRYJh0PX9/w2posWDSNfIEOOgQwCEQ8ZIFgVWCFxMltpwwxswiHgdomq5xjAiPInsJW/+zIhIfd7YI4QkhGQn9SpiZcRZQRsFT4TiY2vZiICSgklmKIyi6RxeCGIUjIsqSRyVYDSb0HUdp2dnQEQF2Jkd8lf/2t9GqBwh0wuQMvV+rXt5uWNWCqKNeLtFZQYpDGQTlF+hYv+Z1ZqI1gOrOibFkFRxuCHGFKhp42Cc0AMq8fo2qlJKR0hxYVMp2Ww2TMdTqrKksy1N2yKl4rAo2dRbVLQI7/FBkakcCbRNTV+nnDOpNWiNkSJxWHRSdqhBAlqWFZeXC5zztG1CG5hBItZ2DdaG9ONDwng22JRB3EjzjNFDdt6fvF546I5nM0BgraVrOopqnITHWcoMUgDRkxUp314bhzF6gMVElBCI6JFKURlzU03mZUGRZ2w2G3YOHzDav0vWnrGtt2zWW7q2J4b0xve+pe8j+fFjiqMHhAhFpllerllvt3R9j3UOBPhwBUISfGBab5h//Bj95Rn5aIIpRxRKsF6tU7icSCSg66eTyVIGllEKo3VqQSBw3iNDSNo/JQg+UBhNdIl49CqrVBV+vMNYjSn1hJAFtPQILXDRo3WGVhn0UzZR8s7VFbrU3J/dZm9/H7ld897ZY9Ztw9HdPabTCav2Eq1zRoXkFmOMV4iQdI1BalbREo2mXi2pbYKJFOUEXRbc2jvCtRYTDA/MPv/Rz/0VdnUOrocguFxc8Q++97t86M/RVUW9ueTB/btczM9ZbTeMDkrCVhFFR1ZIHrx2l2AUvvOcf9IRskt2J/t4qTg/vWD22pfpQ8dVf4kqA1949Cb1ZU+74+g3LXb18jeJ709wYFAMECJ6CFRgUBpEIVBRENGpaoseLYcBjEgjtzQASwobhh6wjC0agRc5MXZEaRE36ERIMi+IyHToR5Ni74XAavDOoIUiCk8QPlWrTrASgtPgOXaeFlBRUhrFg72SqhDMF55FEwlBUuUzQpYz3SkZTQqc67mYX+GtpZQ5v/rnf527D95AanHzsmJMrrZ/9k/+kB//0hsvtbepGgQpAkZFYnTIvMLWBZVOPe7r/fcuEPCJYSCGvi0MEr148yC6Tmzp+i4hAowe1B7phbdti3eR3vbcf3APYQTL5QplMrKyIvoW10Zk8FTjPbLMEJzDBZ8q2pDsKEJElBhCCpCEGFNqs0pt1DzLsLah7zqcTRVt1zmkMPSdvYkoats0mJvNJjeDOmPk4IB7cevmxXE9eTV80R0mqyhygyTggkcKSa40fddiyoLVpiHLMoxONr5MC0xmcL2ld55IqjysCyiT0YnUDujnn9Asz8Bucd5hrcMPiQ2pwkxXsHaz5P5Xf5zHj99F1S3r9Zq667EhIR8lAmGHXCafGvrrk6fc+uqPg0g24N5alMkQPpAXFcRUHX9mlVREKdBFiRfDm8TZBK42JsV+xDSICVrDKx66rvO4VrDsNqxtg4oCI3PW9ZrxqERKT2/X7Gb7PD+94ulE8cYMTJlTZDnFpiVfj1icPOPo0QFPnpwxmkFlJjyc7nJ3to/veqIP6Dxj3fZcNC2Xqzkx85iqxLae4Ets6BLAxToyJH/xKz/JbTNiWy/SbYKOf/zOH/Cs3yLyHBkyoKOtHYSSceEpiylf+sUf450PfwvFGItlb2eHrofDhw337k9ZnzUEGZhWU7arDXu3Z7RtpEXiJxmvvXnE997/Dlle8sbX3nrpvf2BW0hMB4VSCowkwKAhjzffexUgufsZJIzJkBB8gKiIGKxM8i0ZBdpCFJIgFUoVw1vhejg2/LFCEjB4FF5CVGrg5abUaTsAmKwUWCFZBsFT6XkWe7phhiCVREuwIVC7iJcerSXBKVy7QUXL1emc5VLTtpbQpVnD/u37/NJf/nWUSRS1695vjJbLyw3/5l+9Df/Zr73U3oqgkVgUFhklTghAE+SUQDscphHnQtI+E4fUFW4KFSFC0sdC4rZESZ5rIkkDbPuAHFpARku26w15MQIhWG+2jKoJ3iUR9Gq1YjIaIaShaxbowtE4R5YNoBsJxhRYn2LubfBEIenrFiFUaqEOdv8sN+Q2B9kQScCerk1tlHrb0NsOHywoh4+BummBRDC8Vo543/+P7Npn64WHrpQGkxmyrBgazulbV2hNkec3IHCkIs+y1BcTiemZqeQA6WKiKoUQ8F2HkIrlYpGC50Lge//6f2D+7H0ufAJ8+OAHsXKqpPOiIM8UZVkx3jtk57Uvsnr/9+hDT1QiGRi0SQfpNUjZWfrOUi8u6OoN04PbA/82IduapkUOqgW0wWhFCJ7CZImNGgXVeErX1uQqOU0yo5FKoKSksw4RBfqH0Yp/yPral77KH779Nn1f42k5Gu9wcrpFyYLl6gJjYLNawcYzO5yxmtecbxraI6hdz6resFNUvHX7iI9PLmhDj6QCbdmvxmQusnXr9KCQsKbnk+1zZrMZqu/QxYjHzx+jes/+/h6zvR0+/vhDvlg+4PZ4h8639IMt73cfv8P76wsmtw5xi0u2q4Z79/bIi5wnxye41vHFLx7SDw/Z6WhGs2zYrDqc7JjtjQh9zrQs6VmwthtG+SHPPjnh6N492nbNsyfH1OMrgo/IEYxm//PydGNMbq8Y441kjPhZi+HGKRaHXq9P7rHgBDFeI/wEChAyR/oIKKyUqXnJMH4f/icJNq4TF1ekKvhaPdArcDGivKCXkhWRJwSeB0s9mCiUkMgUQsjllUMohZAGJT06C2SyJhMNIURWc09vJZARRcaf/wt/k8ODhze97ch1P9XwT//JH7BYvMqQMrUCfWipSkWLou0FIhvj45oipuQEHzxSJ5SgUoJks5I3uunPsuQiSgraukFniX2CkljhBhlexAeHUuImAPQ6mUYp0ErRNCl13IakRDGZweSK1fqKYDu0qQYN7qCjFUk2WpQjlqslWW4IAbwL9F1gs2nZbjog0jQtQmq6vsf7FJwgBEmdYSNlOUo4UPuZIuVF68WHrlLkeYH3jhD8TTibECJNWL1FmZwYAlpp4mA/rMYVBEemFdL0KV7ZgwiS4HuiCFgLfdfirMMoTT7K8dYhvSfLspterXcOn0lEXtG6QMwryComo8h8s8YoTVVW2EE61tueUVEwG40IeY7OcqTJ0XlGLgTbpkfqgiI3iDKnswnGLEixy22fbIS5UQSfoXRG2/QD/xOc92SmoLfuj/GD/6euxclzdvZHPFteMtYTdseG3pZElbFqBEIEui4g8dya7rLz2hu0oWElGiqXMTaKw1wh8z1Wfc+onPD+dz7i/v09vja7S9/1KaG2GtH1lvfnz3naXqJWClNqunrD0YMdwkXPrKqYr+ZMJntsu8CJ3dDMO5p6zTvPP+H3nz3GVYL7d15DZYG6bjn96BI5Mkx3CrQvuZwvELnm9uFdmnVPrjTlpGCxXGJjh4qBSlWIULBf3Uu9aa2YX12lSmMcCXXGxOU8fX5B9K/e0/3+wdL1LeX6cA1imOQPXYSEPoxpNhHC8PGRSCUgRvoOIBKVRBNuDu/oHQo90Ok+O7gBvARiSLejGPAxJFekiAmaIwMthmfB8onraGRAi+H6LSXaGHyIdM4iQgJrpwBIhckNKgq07xkbQUOk6R2vv/Z1fv6X/yJKZp+1WILAdz3Pnsz51u9/yK2D/Zfe20iCPwkfqKpI7CH6ZLmVYYQxhrbtwfT46DDSEINPmn+lE8LRJ7mbGoIEtFG0bUdZ5EQfkCFSZQaEYNuGFH6pk6mkazts16V8ughN2xCsZ/9wn3KyS14UxBjwLuI9BAfKOIwZ0Xc9mSnTwy9IQpT0PuJbS1nleA8+WEJ09NZitME6T98PsHWGwd8g2dOD01Hr1A6JA//hReuFh25Zljcl82QyudGjxZiuauPRiLpt0mTPlKlnNigQpJEgoSrGeNHgeoe3FqU0PrpEFrKO0eEhi48rhPfYARaRQv3SU04rDUEi8hI1GnH45ls8PnuCPE38WSkT6zT5oBNVXhAY3b7LrR//eWb33qDMRyiZ+kN5nqOGZNgwVOptn9jAymhCcAklJwSTyYSmTVcF5wMmL+m7LUoG8iwnvIKrB+DJs6fM3ZLRrOTxh884nGU00eGsZ33h2J1WGLeL1JrV6oxJLqiN5tPLE3q5pug1k6LkfNuwe2uPt997l0lR8s37X2ZXjWhWG1AS6WDdRj48vaTfwnQ0IYiWXCqUjuR3JmzkguOTC+7s3MMdKP7hJ7/NxAoW3YaT5ZxYwp2DHebrC66uzrh1cJd+6tBasrdzwOJqw7reIC8lXWvZ3dlF5ZL1dk7dbJkcOJQxZLoin2jmn7Z0dsPkTkG/kpw/X0I5Ze1qZij2Z0dDC+Pllvd/fNB5PeC5GZBd//jw69HXbQj9Gf4xChBJ/pRlRWpdeQ8yEnTECUd03/9/E9/3f031sxACQqAPLpHJBqVBEIGt8jzzjk/xODFE/6jPlBc+Blz0oLhRTfjgMULjZE7fO2obUVJTashNxl//jf8Vk70Dovnsa5YyEqPmD37nu9w63ONrX/niy+9tkOAD1kf6rkZ4RSaSxiNKSd0VRDEiRIcQcQBK9SgxZCsKh1aSIOJgIQ4E6zGZprOe4ANCRHxMuYRaByKKtm0ZVRZjJJnMsX1LJg1GS+q+wwVPNd5HCqibJS5GimKMqWZY2+F6NwSKNiAkyhQs1xus8yA0ddPS9R0+Bsajgq7tcQ5667EuIIUYYu0TG04rifeWtt2S5UW6Ow1KkxetFzvSjCYSUQNvYLttKcucEMF1FiWHyZ/VGKMZDaT3ENJkUMpr1Bl4ky50ydfcEYUiyo4HX/9x3GbB1bvfwdoeLVKsjgvJ4puXJfuvvcn+l3+MarKLj4Iv/MSf5dm/+k1mKqJCwAaHdoK8KsjznGo0Yve113nrJ34WsglGScq8AKGgackMGC1o2h4bHGVuGFVj6i4Jr7OsADwIRZ6XeMTwwIEsy5NOUwxSmFdY20VHbnYRe5GdW4Z2bXjj1pu0ak4/UbTzDULBeH+X8/lTTj8+4Wd+4ZucvfM21i/Yjzv0feCq3jI3K8pqxL6Y8pWjr9LbQBcbolbAiuf9ioW/5N7BfS6OT/jiN97g7PkJwQby/YoQM0K7wHWSs8Ul0Qc22uILQakrRn1OqyTnF3O6voPYsn9vilIt66uW2eQWk6pkfn7BtBiTGUc5ucVmc0GzqiEUHN6P1LYhtwqRR8ZhiiRimxZlIlokopucTpmogq1/+Qh2+OzAgR+0zN78GKBCUikIrZKRgpysmBK/X4IVDM5JQmhvJGh1UKQWgkeIobUQf7DdlA7MBBgPMaY0ExLZrIuOWsOxlTz1gjYmpKTR6nrEl2zLQ5pJaoPEm1dedzYdBC6mmYmCDMWf+tEf42d/9t8fUIWfhVRG4OR8wdvvfsSte7dx1C+9r2FwaSpdsa17QhCEFOuKj4EYkvVYiBTKiSgRwiJ0SFFJeUO3uUIoPTApQkKvhkAILv27SM0I5x1KR7reY60jL7KU9CI9oU+STu9dav14T9f2NC7xg73vUSZPkk883nYYUwwoRkNejfnk6TF1W1OURRrIDw/L8XhMXffMF5skDyTiXE/wbhjMpsguoicSaJsWZbLEqvkhMKEXHrrXFP1s6NdqnYhj1/pGZTQiBGzfMhoVN972LMsG8EOLVhKtU++lKEqatsH61A7QdY0Ljnt/6ueIQiMef4dQb5FZgdQKlGb02uvsf+ObjG+9hslyCqWZfXFGNR5z/t53WT37CNsuKZxnlEvMaIfduw/50k//HNPpBIfG+UjrIlIGlDF0XYvwKfEzCEmZGbRSZMYglSKI1FoxOqNtutRWIQ1A+r5PoPMQyV4ReKPHBWFbIzxU5RQRC+6/douzraM4nHD82DE2u2yaFTuTGXVX853Hv8fm6piH1RFtCyorOKkXLENPHyL1Zs76/Iq96YR8OmG5mtP4jvefPaENG+7eecjqief45BOmuwW7+S1s6bh6vuaN197i6vwSkQWiCFyebfjqV7/GPH7CxdWCaXXAtCyQumW52HD08BFX62d4EYm2hxqcCrjYc/FJzf0vTZiNRxSvvcHyckVXZ6yXLfdGE7LSMt3fRUnFzmuKxXzDW4/ucjV3XLVLDiuN+iFc0hcta+0PYB3/mKZ6+Fz44aovEJiQqtuNjDd29vh9vzeKdtD0KkIshyl1HKRhDij4AYAt3FCn0gGf1BK9iiyi4FMnOSfQRwNeEIS9SYC4boHcPCx+4B9DZqDzqZYWIkkYy31+7Tf+DtloZziov6+1EiLtpmNaTfC2Zf9w8tJ7i4hoVSDNiM6lnnOIqZr2UQ0vUgymqvRXQJPrHB8FjRUU2YYYPMEPNl0CWsZB8RHoO4HKkhwVATGmmY0xhrZLV/3Z7g4yhgQ/z3NWi0uKokTrnCwriLG/0VObrEDIHuIQXhBIMe3fx+RIvWY/OM8SOOfkNJENiT7FKd0Q6pJVO4SkatFGp6QOAVr+kGyIF/1kHJQAQipElGRlslF66zFKkxlDb3uqMkMKBplHSkONMaTGNSoJzoeq18UIztF3PWU1pul7Rrce8tpPjtl97S3WTx7TbZbo0ZjZ3dcpju4y2T1iNp2hREQYgxCS3ekeR699hXY9x3ZrNpcnLE4+5ctf+RHuvvYaWZljMsGmDwilafqkFarKHCkiwjtMXhBil5rkzg0cBo9zlhglETlISSLaaLRSSUJmDH3XJV7DKyw1rTmZX5CfFHROoVjx9HGGlZLT5mNOr654ePQA5SO5GfGz3/wVfvOf/tcEG1j4jlporA8875dMd0eEdSQ3GrTFSE+zWYMQPF6csa03xLbj00/fx5YBa3vC+ZaDqeb82RolcvIJHB7lfPjsUyaTffZu3cHpDpuBUJIsKOw4cpTdRdicbmPxXjKaGdrFkm7pqPZK9m/N0GLMvDlndWwxMufiZMXd8YTDWxNW8yVKRub9nLGZ0W5X/Nw3f4n1ZsH4TcmTTx1GG9arl0c7XmP3rmljf7TSjQNH13ufpOxRYCMYAtnBDK1KgpSEkL7PSQSfDa0Jgbg+xAXEqG+q0Gt/mBUQpETGgIhgY8BJRyfhBPgwCFYigoRMeKIGqdJ7DCGG9+ALHjqBQb7GoIFT/MRP/jw/8qd+Zkg/GSpkIkTJ7//O+/yLf/otdndmfOELdzk9Pn3pvVUqo6gm2CCRMSUn9D7iPgsbTv1xIQCHRJGZjN4lKdhm5QhZpFAC69Lr1INlGxKSkxiRKpkaIoKY3LlIVLplFxLb9SnKp+sxSmH7Ducc4zEQA0rHpPdWGaiMIivomy15lrPZ1KxWa4QI5LlJ4brx2gSWzoCu6xOzQ4hhbqUG2FV6b/kQUcYQSanoPia1S/YqjjQXPM67weqWnjjBB4LtqcYTOuvpOgcy2Qo76+j6hEuMCPTgUS6KDCETPf46iaEqq/RUU5LeWmYHR4wODpg8+jLb+RU7u1NGkz2cF2RZghiH4AgixVkbLdB5yf7tW9Rty4Mv/xjebpEBirFBiUgXNVZInAuUeQ4y5bwZpVAmXfWyPEcIBvuvQHpFphRdn7TCSil836dEY+nIiyIliJZFegK+whIo7rx5n8UnW6pcoQrLxnf0c4cynv3ZDnZbg7IUuxlNfUUuSqo7Y/o20FpJ62yyj25ABsUX79zhTqXZbudcrtZkh4cc1yvO3Zb1SlJfrRjvpDZPJgp6GVg8W6HGI9rQcnt3zDSf0q87ij2JKgOL5xv2Dg/YndwhXErOLxdkpiNThvWy5t7t1zhZXbD/aJem75mf9zR2BdqTixJTVtx+pBiXhmbdoETF1fGS3R3JNvMEJ/jk0ydUuyNmqgSVswkdyr18T7fv+xvKmLX2hjb2A/s/DH7FkIXniMgYGR3cwU92CNtzrNB0ElbS4VHkUjAKgs9yFwQi6pvDJgJOppuglxEXRSoyRORSaU6C5dgpthJC7JExaUelHLSq/xac22vAzfCnE6NgNDnk13/jbyF0qr6vHzICQdM63n//Qw4O9nj9/i2++qUHfPrs5ZMjqtEurU2J2ilpxQ8AGTE0GcLQSgStNJm2KJUTg6HvO6wL9FKQyZBmJUbRtx5jQBtF19lhMJWyx5LKLJlM1usN0/EYKdJQLdMZeV6gtabv3DA8hbbbIqzA6IDWER8jSgbEcKgqk9F0F7S9JS9LurphtpuihrquYbXqaZsOhCDEQJ5p3GAo0YP+7ZqNLFVClCql0QO680XrxZVuDGhjaPuezBgylbJw8yJFMNsg2LQ9o6rER5BCok2KyEhPoBYpA8bk9PY6UTc5NjKT4X3yL2pjyKWhtZa8FBSmYDKuyPICZHKv5UZRFhl176ibHm2GfhEiKSdQZNUUkLQikBuFC5K2bZNURYBSApEZYki2Se+Hb7oU5Fl6E1ZlQddZwhDvgyClFA8ViA9pEj2qSvru1XqOXkr0uORq+ZyHbx4gRo7F1Zz6suXW3g6zWcnHl8/QBChz/t7f+3s8uv2ATBnMTsl8dYWQmv18TJaN2Dus+Mm7D3kw2uH47IyxnPJ0Oedb7z3mvFuyP5mSR8F6uWDn1i7lLGe7sJhJgdCW/bu3OX7yFEPOaJyz3TbsXB5hujXTO2Ns03K7mnG1PKYNhmy3YGcyxtYOicY7z97+jO26w20cIovI1nG4v0tdr2i2lqvlnN3JPuVsn717+2QThbQ5G5a0yzXj0X32pxMun9cUOn/pvd1s1jjnMTpHG43R1xFM38+yTYdXjKQUkAjRC9x0h+Ln/jTP/uVvcX5+wcdtzZWUeK8wveWuzniQCw69oPLpwPbiugURsSqVZS2RJZ6NtlwGyUknWAlAphDXBMqRnykM4Oa6+ydVuXGw/SYnXLqKC5Hx7//iX+H1t75GGPSw1wAc7wWP3z/m8NYusZX8/u9+h973gx345VbnIMoE/Mkzg7WWTCmsT4e8MgFIh6XCsTfLWNYe20E7zHxikGRZSgtXSuL6FIPjfbxpCV3vgwvp2o/zWGvJixypJE3Tslqu0UqQ6emNPM57z3K5oigzeuGRsqeuJWWRIQfjRuM8Lgh66wiklPE8z1mtVrRteo1t2ySZne2JBLSWmEzR9w5vfWpdhAQPikGATjE+6ofIF17cfPAJfO196l+GQYYTgkBpRYyePNPkWpDplDfVWZ+caBKUFmTaIMVAR9ISaXvMZIwdNll5TVUUOOvwXUthDOOdGVrIBEW2FiUVVW7IjMYGScThIhADMkbKfMhCiqma6QFTFERvqcqctmmIJGdJGKrXqihp6h4lk6YvDEmjGT61EFTCR9b19cAhJo1v50AqfEyH8auscVlRFCNu3dqlqHIW25qzJxcUOqOWikxL9g/GeBcJC8sXHr7FYrXkXnXEyZNjltsVqsrRpufOvduYTcfPfuMbFK2nFZJwteLdy49ox57dyYxQB5qmI1aGroPLVQMuUu5qimLC+UdX7O/cQhUZHsf++ID7u7e5uHyGUoH55pKLbUtWZIx2c6rRLtu8pW42zHYPcV3AW81sqmi6DU0tkEow3yy4Or9iujvl6N4OrvFEF1N+mNqhMBW+3JBJxbxZsTudUC8y2vXLtxcuztc4uwI008mM6XRKnhsiFiHjkHf32YfDOot1Dc5GTk+f86zu6L74BS6kwjYb6Fqa9RZvNM+l5Ol2w22dc09kVDqklOmh39cR2QTJqYBtH7FC0SqotU95fcGjRKoCU/tT3LQ6rtf3H8R/dAU/oCqHl39wcI//xa/9DbTOE1gnftYLPj9b8w//m3/DvYd7/OHvv8f+/hGzw7v85j/67/k7L7m3CfCibjLDsqxIV3ytCCFQ5MOPG0OVpR6p0grvr3Pr4kBb8ylFVwhUrjDGYHubeBciDreTgNYBa5M71PswJEwMQ/OypGlq2q6jyDPKoqRtG5y1eKOIqkdpTW87hAgIJL1tWG7WA6UtabfrukEgWK3XTCYTiOkGXjftTesoGak8QpgkG4sC7wXWW7yLKBcwI00Ur0AZ821A6B6lE00HIbC2R6kUyhYGuG/dWIKJGJPdtA/63qZDUWr6vkPqHB9SoKP3Ee9gUmXkRmKMIZaGnWmZNHVaQ0zhcIhrFj/01iZ9bAhkWTqovz+11Xs/YO+grpubfp4ZLMje+5tff11RCJkGak3dpgO77zHG0HXpKnFTMYSAcA7nHQJo+g4jX1GoWyua7ZKdLGc0nvHBux9RZSN27o4xY0vTtCxO5swO9pDBcevOEVWpmJVTzrvn7FRTNqJnvVrz4be/w9/5tb/Bw3uv8ezxR6AVbz9/zuPtFe1li+oEvXAc3jlEC08dLc0adN9zdDAhGsftu2Nu3T7EisjTp2dsmo7n6lOmOxXreYPUgs4EhFGsFxsunnyK2e0QtUC0lq9/5Utcra+o6ciN5tb+fazoOD1+zutfeIvzi0+RokIVEoFiZ7egEGPeuPeI9y/e5mq9wiwb9icS2wTM6OXRjj/69Z/n0WuvoZQiBHj3ve/y3be/xcXFOaNxwXa7pSpHaCPIDAh6nl9c4Mn4N//mn9Ns1oyKivVqlYa64bo367FDJMxHruOp8pg+qWiCjHgJFoGXgRAFj4xmLDI+cBGvLDKEdHtCIoeEX/gTDlnxff62m58TQyWYZuoCxV/4S3+NowevEUW44QMnTbLkX/yz3+XZkzlKwd37h9y5s8tHH77NG/fuvPTeekRKWPES5yMhOiIS5z15rul6R64zEuVMsmkUbZMAMiE4RIx0NtD3MXFzVWKa0A95ZN4RYkwSvhiAiJDpcmKdxXrParVhPB4TYwLNKD1YtAOJmy1SlP2orAgIMp2wr8754Ywa5HwyfbZDgOfPzwDBepMKLT/wXKSIKC2JQQ9uV3czTGNoqwjhiQ42m2awjf/J68WSMQVCioEnaemsR4aeoigSyqzrUNrQtR3t8ETIjEn2Xu9ToqdIjvRoPSF4prJKk9oQiMGR54nmlZn09Oijo287tFE45wfosMd5idaGznmyPKNuUwXsu44gNFkuB+hIun9lxgwNcE+QIAgUA9k9hEDXWOquZVKlxAmdKfKipO/ThiqjkwPPSTZNS5Zn9H36eoyUaJlRNy/v6gEQSjM/vWBzsqb0lpHIySc5t+4dsL6c08w7Dkb7HE3uMJdzLpYnPJg8wLc99x69ThSK3/6dP+DAT/mVP/PT/Lmf/4V0YS4K5pstf+/3f5t6P1BOcoqdDCstUluW5xse/qmH2DawOlvQiJpcKuRUcdFcsVn21KvIzoNdLtpPkcEgfM5icUVUoPNIbkrefPNNLA1P+xPEyHC6PWHTN0zMGK0i58unFNkIaSWfvvuUoGrkbsH+/hFmqlDa8fT0I7JR5NNPnrJ7sEO/3uLrjPFswtnF8Uvv7Td/+udu/t1Zx/43D7h/7zX+T//n/yNPn3+P9WpLjD02Rr72aJ9xrvjeu+csrWTb1UBkvdmCjzeVaCCiPBgH+xJe14axztjiWcfIOno2eJo8A2WoVh17MrAUgSY4zKBiSFldqVU1vBPS38W1vCveMCOux3M+DLbY4BFCJt6Bgkevf4lf/tVfu7HUJs1xMnl8/NExv/NbbxNi5OOPn6dCw2nK0vDk009fem+tC2Qq/TkJ2uOI0SAlKT4+Crrec7Arhzj5grpt8MGm140ghhSvhQiYLLn2pFSsVw3aaIRIvVepAt4rfBA3sTh1XVPkOV3XcX3Z7PueRkhcZ4mEFM81DPWVNihjkDKgtRhQjenGfp38fQ2/2qxb6nZLURQ0TYPt0+2+aR3Xyehpq+NQvA0txxjph0q8GhUv3L8XHrrzqytMlg3fzGSxK1XSGXrjkyV2u0UMEhbrLIxSXnx6qgUatmmolqUWwIaI7ZLUJTOS7aah6zqqqrjJIooBTMhu4MHJry1Q1cCt7FsyneFsT5Gla0Ac7JnEiBSSvutJlCOVUIMxfcPKskzDwCFq2zlHU9dUowrnGjJjsNHR2R4pU7/YGJP84eK6f0wCXvwQWPEPW8enT6GH588v2SsVmcw4eLjP6mzF4kmLtIE7r4/xsWc6mfLsfEkTtnTOcuVbruZb9KLnb/wHf4E/9bW3KJTGWsemafm9jx/ztF9R9RW3dndwsWMyKfjKaw/5znc+wLuObh2ZzGbM5wtKVWDKGbZvODyakPmei7NPKSYGFzR70xkpIyawbOeM9qbMuws28yWz/Vvk5Yj5+ccc3r5LX/c06xqKQLNuabstO7Nddm4d0UlLsD3LdYPb19gs8Hx9AgaKSrKzc5+T81Nirrhwi5fe28/SGUTSdYbAgwcP+Y//N/8J3/7O/4/3Pngb29d02xX7lWS+uKKLHSJGSuFv7OhZObiXvIfOsacC97RgV0ZKIjLALpIoHD56NkjOPLS9YypTqGGLQAjIkBgpETIN7VKV+4PV7Y0GQiRSmJYgDTRR4gM3Q7c0yyj5q7/2N9ndO/jMkhFJ85Y+8t//f3+XZhuGbC9BCIKT50ustdTNy793R7mg6T1CmmHYrLE2VY/OpVsnyiJVTiCnaTs6Z4lD/lwgQkj8ZC0jGy9TWsugwFMygkiM28xEhIkEF9JQX2qiD3gfsb3Dy/R5b9s2/RrbM92ZokmDtbZtMJmlyEv6vkdnmqZpUjJx26G0IitSTE/fr5gv1gQ81sfUZ46CvvdJLIBIWZEymbKapkMOeyCFxBiF0orwQ7CZLzx06ycfoHVBF1MPF2lwWrIkUI5GSUYDaKMTs7Yo2W4bRIxDz0rioscjhkMw0Lc1bWsREbwd0/Z90hDWDVmRpZwyBLbraNuaUVkQnaNLkzogEqwjCpXoQCEdgp4hTNKk17PdNOS5RmBou4TRa7se59MQJTMZIvghSC8OOUgWJQRSKVwAFQXOdkQhkzi766hGxeAKinSveOg6D87XvP4Td2j0kqk5woeasw8uuHXvFldPTmlzT786oZATfGM575Y41+EPptQfLPnFN97kQApU61ifXeK04smzZ3zr+COqaaoy93emZKOM88sznl8ec+f1Ay6eXnC0d49Q9ayfMYClS9p6Q4gjwDI5KFidNhzsHJCrEiGvUAV8+ejLXC7W9GrLaDfn6viC2w9yprs7rK7mrJYr6pXjaz/2ZZq15fz0Ocootscrdu/OQMoE3dkdIzLF5WLJzmjGdrXk+eKCb3zlSyzqBQ+/8uCl9/b6wL1uPV1rdr/+lZ/izUdfZ7Wa8/FH73F++gmb5TNu12v2d465PP6E0aSEfMTuwSH7h7ewzuH7jnh6gjo7Y3P6BH+1RgYFNsmznNcoqZkK0MFjRaBTgQ7JgczY9AGbpX6fF5E2BpxIutQ/ImZLfx/mfHcOJhwcTTi56Hh2Mr9xQcYo+OIXf4Q/+wu/euOgS0zXNLB+9+0nvPPdUwglakgYJgQWixVSRUJ4+XmEIFlrUUkN0A9J2dYOagMbyEtYrT0hStYbm8JcBxs2hMGCrRAx0IeA8A5hNDuzgiyXbLYWFyN9H9AajFFkPtCFgLOeptsggyTgKIyCQYGCUggpyXROWyfWi3c9Is8SKN17gku38N72qKBApCj47aam6TqUElibLL7Bp/ZikSV4vfOp4g1uCDiViaYYI4xKSYywXL84UFW8Koj78/X5+nx9vj5f//br1TBZn6/P1+fr8/X5+p+0Pj90P1+fr8/X5+vf4fr80P18fb4+X5+vf4fr80P38/X5+nx9vv4drs8P3c/X5+vz9fn6d7g+P3Q/X5+vz9fn69/h+v8D6zfC43MORFQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "i = 0\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for image, label, label2 in train_batches_MA.take(4):\n",
    "   # predictedLabel = int(predictions[i] >= 0.5)\n",
    "   # print(label2)\n",
    "    ax[i].axis('off')\n",
    "   # ax[i].set_title(classNames[label[i]])\n",
    "    ax[i].imshow(image[0])\n",
    "    i += 1\n",
    "    for j in range(label2.shape[1]):\n",
    "      print('annotator',j+1)\n",
    "      print(classification_report(label ,label2[:,j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a41a5",
   "metadata": {
    "id": "9AgOHREc1bmd",
    "papermill": {
     "duration": 0.010604,
     "end_time": "2022-12-20T23:05:38.909098",
     "exception": false,
     "start_time": "2022-12-20T23:05:38.898494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the classifier from multiple annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "203a785f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:38.931626Z",
     "iopub.status.busy": "2022-12-20T23:05:38.931307Z",
     "iopub.status.idle": "2022-12-20T23:05:38.957270Z",
     "shell.execute_reply": "2022-12-20T23:05:38.956225Z"
    },
    "id": "k-ePr0-fxcVi",
    "papermill": {
     "duration": 0.040454,
     "end_time": "2022-12-20T23:05:38.959833",
     "exception": false,
     "start_time": "2022-12-20T23:05:38.919379",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "class MultipleAnnotators_Classification():\n",
    "    def __init__(self, output_dim, num_annotators, q= 0.0001):\n",
    "        self.K = output_dim\n",
    "        self.R = num_annotators\n",
    "        self.q = q\n",
    "        #self.callbacks #=callbacks\n",
    "        #self.l1_param=l1_param \n",
    "        #self.l2_param=l1_param\n",
    "\n",
    "    def CrowdLayer(self, input):\n",
    "       #x = keras.layers.Dense(self.R + self.K, kernel_regularizer=regularizers.L1L2(l1= 1e-2, l2=1e-3),  activation='tanh')(input)\n",
    "        output_cla = keras.layers.Dense(self.K,  activation='softmax')(input)\n",
    "        output_ann = keras.layers.Dense(self.R,  activation='sigmoid')(input)\n",
    "        output = keras.layers.Concatenate()([output_cla, output_ann])\n",
    "        \n",
    "        return output\n",
    "#RCDNN   \n",
    "    def loss(self):\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            # print(y_true,y_pred)\n",
    "            pred = y_pred[:, :self.K]\n",
    "            pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1-1e-9) #estabilidad numerica de la funcion de costo\n",
    "            ann_ = y_pred[:, self.K:]\n",
    "            Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n",
    "            Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n",
    "            p_logreg = tf.math.reduce_prod(tf.math.pow(Y_hat, Y_true), axis=1)\n",
    "            temp1 = ann_*tf.math.log(p_logreg)  \n",
    "            temp2 = (1 - ann_)*tf.math.log(1/self.K)*tf.reduce_sum(Y_true,axis=1)\n",
    "            # temp2 = (tf.ones(tf.shape(ann_)) - ann_)*tf.math.log(1/K)\n",
    "            # print(tf.reduce_mean(Y_true,axis=1).numpy())\n",
    "            return -tf.math.reduce_sum((temp1 + temp2))\n",
    "        return custom_loss\n",
    "    \n",
    "#     def loss(self):\n",
    "#         def custom_loss(y_true, y_pred):\n",
    "#                # print(y_true,y_pred)\n",
    "#            # q = 0.1\n",
    "#             pred = y_pred[:, :self.K]\n",
    "#             pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n",
    "#             ann_ = y_pred[:, self.K:]\n",
    "#             # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n",
    "#             Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n",
    "#             Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n",
    "\n",
    "#             p_gcce = Y_true*(1 - Y_hat**self.q)/self.q\n",
    "#             temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n",
    "#             temp2 = (1 - ann_)*(1-(1/self.K)**self.q)/self.q*tf.reduce_sum(Y_true,axis=1)\n",
    "#             return tf.math.reduce_sum((temp1 + temp2))\n",
    "#         return custom_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x, Y, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(x, training=True)\n",
    "            loss_value = self.loss_fn(Y, logits)\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        self.train_acc_metric.update_state(y, logits[:, :self.K])\n",
    "        return loss_value\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, x, y):\n",
    "        val_logits = self.model(x, training=False)\n",
    "        self.val_acc_metric.update_state(y, val_logits[:,:self.K])\n",
    "\n",
    "    def fit(self, model, Data_tr, Data_Val, epochs):\n",
    "        self.model = model\n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # Instantiate an optimizer.\n",
    "        #self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "        self.optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        #self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, clipnorm=1.0)\n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # Instantiate a loss function.\n",
    "        self.loss_fn = self.loss()\n",
    "        self.train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        train_loss = np.zeros(epochs)\n",
    "        train_accur = np.zeros(epochs)\n",
    "        val_accur = np.zeros(epochs)\n",
    "        val_loss = np.zeros(epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train, Y_batch_train) in enumerate(Data_tr):\n",
    "                # print(y_batch_train, Y_batch_train)\n",
    "                loss_value = self.train_step(x_batch_train, Y_batch_train, y_batch_train)\n",
    "\n",
    "                # Log every 200 batches.\n",
    "                if step % 10 == 0:\n",
    "                    train_acc = self.train_acc_metric.result()\n",
    "                    print(\n",
    "                      \"Training loss (for one batch) at step %d: %.4f, Accuracy: %.4f\"\n",
    "                      % (step, float(loss_value), float(train_acc))\n",
    "                            )\n",
    "                # print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "\n",
    "\n",
    "            # Run a validation loop at the end of each epoch.\n",
    "            for x_batch_val, y_batch_val,Y_batch_val in Data_Val:\n",
    "\n",
    "                val_logits = model(x_batch_val, training=False)\n",
    "\n",
    "                val_loss_value = self.loss_fn(Y_batch_val, val_logits)\n",
    "\n",
    "                self.val_acc_metric.update_state(y_batch_val, val_logits[:,:self.K])\n",
    "                \n",
    "               # np.round(np.mean([model(x_batch_val, training= True) for sample in range(100)]), 2)\n",
    "\n",
    "\n",
    "             # Display metrics at the end of each epoch.\n",
    "            train_acc = self.train_acc_metric.result()\n",
    "            val_acc = self.val_acc_metric.result()\n",
    "\n",
    "\n",
    "            print('---- Training ----')\n",
    "            print(\"Training loss: %.4f\" % (float(loss_value),))\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            self.train_acc_metric.reset_states()\n",
    "            self.val_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "            train_loss[epoch] = float(loss_value)\n",
    "            train_accur[epoch] = float(train_acc)\n",
    "\n",
    "            val_accur[epoch] = float(val_acc)\n",
    "            val_loss[epoch] = float(val_loss_value) \n",
    "\n",
    "\n",
    "            print('---- Validation ----')\n",
    "            print(\"Validation loss: %.4f\" % (float(val_loss_value),))\n",
    "            print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "\n",
    "            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Loss and accuracy')\n",
    "        ax1.plot(range(1,epochs+1),train_loss)\n",
    "        ax1.plot(range(1,epochs+1), val_loss)\n",
    "        ax2.plot(range(1,epochs+1),train_accur)\n",
    "        ax2.plot(range(1,epochs+1),val_accur)\n",
    "        #plt.figure(figsize=(16,9))\n",
    "        ax1.set(xlabel= 'Epoch', ylabel=\"Loss\")\n",
    "        ax2.set(xlabel= 'Epoch',ylabel=\"Accuracy\")\n",
    "        ax1.legend(['Training_loss', 'Validation_loss'])\n",
    "        ax2.legend(['Training', 'Validation'])\n",
    "        ax1.grid()\n",
    "        ax2.grid()\n",
    "        plt.show()\n",
    "        return self.model\n",
    "\n",
    "    def eval_model(self, Data):\n",
    "        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "        for x_batch_val, y_batch_val in Data:\n",
    "            self.test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        val_acc = self.val_acc_metric.result()\n",
    "        self.val_acc_metric.reset_states()\n",
    "        return val_acc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a76daade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:38.981526Z",
     "iopub.status.busy": "2022-12-20T23:05:38.981245Z",
     "iopub.status.idle": "2022-12-20T23:05:38.988456Z",
     "shell.execute_reply": "2022-12-20T23:05:38.987629Z"
    },
    "id": "4l-_pkpaBkSv",
    "papermill": {
     "duration": 0.020314,
     "end_time": "2022-12-20T23:05:38.990441",
     "exception": false,
     "start_time": "2022-12-20T23:05:38.970127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # print(y_true,y_pred)\n",
    "  K = 2 #len(np.unique(y_true))\n",
    "  R = 5\n",
    "  q = 0.1\n",
    "  pred = y_pred[:, K]\n",
    "  pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n",
    "  ann_ = y_pred[:,  K:]\n",
    "  # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n",
    "  Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=K, axis=1)\n",
    "  Y_hat = tf.repeat(tf.expand_dims(pred,-1), R, axis = -1)\n",
    "\n",
    "  p_gcce = Y_true*(1 - Y_hat**q)/q\n",
    "  temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n",
    "  temp2 = (1 - ann_)*(1-(1/K)**q)/q*tf.reduce_sum(Y_true,axis=1)\n",
    "  return tf.math.reduce_sum((temp1 + temp2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2436f7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:39.014370Z",
     "iopub.status.busy": "2022-12-20T23:05:39.013922Z",
     "iopub.status.idle": "2022-12-20T23:05:39.034712Z",
     "shell.execute_reply": "2022-12-20T23:05:39.033868Z"
    },
    "id": "0I4Rrc5TxcVj",
    "papermill": {
     "duration": 0.035914,
     "end_time": "2022-12-20T23:05:39.036646",
     "exception": false,
     "start_time": "2022-12-20T23:05:39.000732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MA = MultipleAnnotators_Classification(2, 5, 0.001)\n",
    " \n",
    "def create_model():\n",
    "   \n",
    "    l1 = 1e-2\n",
    "    # Block 1\n",
    "    inputs = keras.layers.Input(shape=(150, 150, 3), name='entrada')\n",
    "    x = keras.layers.BatchNormalization()(inputs)\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\" , name=\"block1_conv1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "\n",
    "\n",
    "    # Block 2\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", name=\"block2_conv1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block3_conv1\" )(x)             \n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "   # x = keras.layers.Dropout(0.2)(x)\n",
    "   \n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "    \n",
    "    # Block 4\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block4_conv1\")(x)            \n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    #x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "   \n",
    "    x = keras.layers.Flatten()(x)\n",
    "    #x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    output = MA.CrowdLayer(x)\n",
    "    model = keras.Model(inputs=inputs,outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527e695d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:39.059953Z",
     "iopub.status.busy": "2022-12-20T23:05:39.058514Z",
     "iopub.status.idle": "2022-12-20T23:05:39.063363Z",
     "shell.execute_reply": "2022-12-20T23:05:39.062490Z"
    },
    "id": "iZAxrNF3_hE_",
    "papermill": {
     "duration": 0.018039,
     "end_time": "2022-12-20T23:05:39.065355",
     "exception": false,
     "start_time": "2022-12-20T23:05:39.047316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# callbacks = [\n",
    "#     EarlyStopping(patience=10, verbose=1),\n",
    "#     ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "#     ModelCheckpoint('model1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ebe6a",
   "metadata": {
    "id": "Z-fV95n3GEqa",
    "papermill": {
     "duration": 0.010017,
     "end_time": "2022-12-20T23:05:39.085349",
     "exception": false,
     "start_time": "2022-12-20T23:05:39.075332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c31f6957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:39.107057Z",
     "iopub.status.busy": "2022-12-20T23:05:39.106751Z",
     "iopub.status.idle": "2022-12-20T23:05:39.111783Z",
     "shell.execute_reply": "2022-12-20T23:05:39.110803Z"
    },
    "id": "_H_sb1cl1FC_",
    "outputId": "59d957da-9223-4a01-e4d9-33933f7a2f4a",
    "papermill": {
     "duration": 0.018606,
     "end_time": "2022-12-20T23:05:39.113830",
     "exception": false,
     "start_time": "2022-12-20T23:05:39.095224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classification_report_r= []\n",
    "# model = create_model()\n",
    "# K=2\n",
    "# R=5\n",
    "# NUM_RUNS = 5\n",
    "# N_EPOCHS = 30\n",
    "# val_acc = np.zeros(NUM_RUNS)\n",
    "# for i in range(NUM_RUNS):\n",
    "#   MA = MultipleAnnotators_Classification(K, R, 0.1)\n",
    "#   model = create_model()\n",
    "#   optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "#   model.compile(optimizer=optimizer, loss= MA.loss())\n",
    "#   history_model = model.fit(train_batches_MA, validation_data=val_batches_MA, epochs= N_EPOCHS, callbacks=callbacks, verbose=0)\n",
    "#   #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n",
    "#   pred_2 = model.predict(X_test)\n",
    "\n",
    "#   lambda_R_ = pred_2[:, K:] #annotators reliability prediction N x R   \n",
    "#   classification_report_r += [classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel(),output_dict=True)]\n",
    "#   print(classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel()))\n",
    "#   #val_acc[i] = MA.eval_model(test_batches_MA)\n",
    "#   #print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n",
    "#   # Create the history figure\n",
    "#   plt.figure(figsize=(16,9))\n",
    "#   for i in  history_model.history:\n",
    "#       plt.plot(history_model.history[i],label=i)\n",
    "#   plt.title('Model history')\n",
    "#   plt.legend()\n",
    "#   plt.grid()\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(val_acc)\n",
    "# #df.to_csimport pandas as pddf = pd.DataFrame(val_acc)#df.to_csv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output​v('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33cebc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T23:05:39.135873Z",
     "iopub.status.busy": "2022-12-20T23:05:39.135505Z",
     "iopub.status.idle": "2022-12-21T00:20:22.938381Z",
     "shell.execute_reply": "2022-12-21T00:20:22.936934Z"
    },
    "id": "Mu0lyAUIGSTB",
    "outputId": "cb82872d-c3ba-4d76-a28c-237eb266e78b",
    "papermill": {
     "duration": 4483.818212,
     "end_time": "2022-12-21T00:20:22.942464",
     "exception": false,
     "start_time": "2022-12-20T23:05:39.124252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 23:05:42.412353: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 669.5278, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 625.1125, Accuracy: 0.5291\n",
      "Training loss (for one batch) at step 20: 577.6470, Accuracy: 0.5205\n",
      "Training loss (for one batch) at step 30: 530.0370, Accuracy: 0.5149\n",
      "Training loss (for one batch) at step 40: 486.0093, Accuracy: 0.5171\n",
      "Training loss (for one batch) at step 50: 514.8376, Accuracy: 0.5161\n",
      "Training loss (for one batch) at step 60: 489.0508, Accuracy: 0.5120\n",
      "Training loss (for one batch) at step 70: 482.8087, Accuracy: 0.5119\n",
      "Training loss (for one batch) at step 80: 482.7073, Accuracy: 0.5148\n",
      "Training loss (for one batch) at step 90: 477.0648, Accuracy: 0.5154\n",
      "Training loss (for one batch) at step 100: 455.6863, Accuracy: 0.5158\n",
      "Training loss (for one batch) at step 110: 470.5728, Accuracy: 0.5144\n",
      "---- Training ----\n",
      "Training loss: 144.5166\n",
      "Training acc over epoch: 0.5135\n",
      "---- Validation ----\n",
      "Validation loss: 34.6372\n",
      "Validation acc: 0.5134\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 460.4556, Accuracy: 0.4531\n",
      "Training loss (for one batch) at step 10: 461.8884, Accuracy: 0.4915\n",
      "Training loss (for one batch) at step 20: 459.2676, Accuracy: 0.5175\n",
      "Training loss (for one batch) at step 30: 462.5443, Accuracy: 0.5176\n",
      "Training loss (for one batch) at step 40: 456.5180, Accuracy: 0.5164\n",
      "Training loss (for one batch) at step 50: 456.5778, Accuracy: 0.5152\n",
      "Training loss (for one batch) at step 60: 455.1344, Accuracy: 0.5183\n",
      "Training loss (for one batch) at step 70: 451.9124, Accuracy: 0.5185\n",
      "Training loss (for one batch) at step 80: 457.5478, Accuracy: 0.5214\n",
      "Training loss (for one batch) at step 90: 453.4850, Accuracy: 0.5224\n",
      "Training loss (for one batch) at step 100: 450.7061, Accuracy: 0.5216\n",
      "Training loss (for one batch) at step 110: 444.2813, Accuracy: 0.5207\n",
      "---- Training ----\n",
      "Training loss: 141.4814\n",
      "Training acc over epoch: 0.5197\n",
      "---- Validation ----\n",
      "Validation loss: 34.7881\n",
      "Validation acc: 0.4979\n",
      "Time taken: 14.21s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 450.4339, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 452.4042, Accuracy: 0.5589\n",
      "Training loss (for one batch) at step 20: 446.0417, Accuracy: 0.5472\n",
      "Training loss (for one batch) at step 30: 447.5036, Accuracy: 0.5544\n",
      "Training loss (for one batch) at step 40: 449.4044, Accuracy: 0.5463\n",
      "Training loss (for one batch) at step 50: 447.2918, Accuracy: 0.5432\n",
      "Training loss (for one batch) at step 60: 449.0576, Accuracy: 0.5475\n",
      "Training loss (for one batch) at step 70: 445.5304, Accuracy: 0.5501\n",
      "Training loss (for one batch) at step 80: 447.7245, Accuracy: 0.5508\n",
      "Training loss (for one batch) at step 90: 452.2500, Accuracy: 0.5518\n",
      "Training loss (for one batch) at step 100: 446.4571, Accuracy: 0.5527\n",
      "Training loss (for one batch) at step 110: 448.4377, Accuracy: 0.5524\n",
      "---- Training ----\n",
      "Training loss: 138.6011\n",
      "Training acc over epoch: 0.5533\n",
      "---- Validation ----\n",
      "Validation loss: 35.1225\n",
      "Validation acc: 0.5210\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.0322, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 445.1149, Accuracy: 0.5540\n",
      "Training loss (for one batch) at step 20: 446.7988, Accuracy: 0.5606\n",
      "Training loss (for one batch) at step 30: 442.5533, Accuracy: 0.5691\n",
      "Training loss (for one batch) at step 40: 442.1512, Accuracy: 0.5686\n",
      "Training loss (for one batch) at step 50: 444.0324, Accuracy: 0.5679\n",
      "Training loss (for one batch) at step 60: 444.4320, Accuracy: 0.5716\n",
      "Training loss (for one batch) at step 70: 443.9484, Accuracy: 0.5779\n",
      "Training loss (for one batch) at step 80: 444.5483, Accuracy: 0.5811\n",
      "Training loss (for one batch) at step 90: 445.4871, Accuracy: 0.5799\n",
      "Training loss (for one batch) at step 100: 443.3350, Accuracy: 0.5774\n",
      "Training loss (for one batch) at step 110: 442.8063, Accuracy: 0.5793\n",
      "---- Training ----\n",
      "Training loss: 138.9937\n",
      "Training acc over epoch: 0.5810\n",
      "---- Validation ----\n",
      "Validation loss: 35.2796\n",
      "Validation acc: 0.6088\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 444.6520, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 442.9791, Accuracy: 0.6023\n",
      "Training loss (for one batch) at step 20: 443.1294, Accuracy: 0.5919\n",
      "Training loss (for one batch) at step 30: 443.8355, Accuracy: 0.5890\n",
      "Training loss (for one batch) at step 40: 441.9332, Accuracy: 0.5968\n",
      "Training loss (for one batch) at step 50: 441.6118, Accuracy: 0.6032\n",
      "Training loss (for one batch) at step 60: 442.6235, Accuracy: 0.6039\n",
      "Training loss (for one batch) at step 70: 442.2546, Accuracy: 0.6107\n",
      "Training loss (for one batch) at step 80: 448.8045, Accuracy: 0.6098\n",
      "Training loss (for one batch) at step 90: 442.3058, Accuracy: 0.6099\n",
      "Training loss (for one batch) at step 100: 441.9215, Accuracy: 0.6118\n",
      "Training loss (for one batch) at step 110: 443.3560, Accuracy: 0.6120\n",
      "---- Training ----\n",
      "Training loss: 138.2466\n",
      "Training acc over epoch: 0.6126\n",
      "---- Validation ----\n",
      "Validation loss: 34.3669\n",
      "Validation acc: 0.6625\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.0407, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 442.3141, Accuracy: 0.6506\n",
      "Training loss (for one batch) at step 20: 442.0391, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 30: 441.6092, Accuracy: 0.6414\n",
      "Training loss (for one batch) at step 40: 440.3513, Accuracy: 0.6442\n",
      "Training loss (for one batch) at step 50: 439.0797, Accuracy: 0.6425\n",
      "Training loss (for one batch) at step 60: 443.6534, Accuracy: 0.6440\n",
      "Training loss (for one batch) at step 70: 442.5183, Accuracy: 0.6458\n",
      "Training loss (for one batch) at step 80: 442.6622, Accuracy: 0.6439\n",
      "Training loss (for one batch) at step 90: 443.0442, Accuracy: 0.6403\n",
      "Training loss (for one batch) at step 100: 443.8633, Accuracy: 0.6368\n",
      "Training loss (for one batch) at step 110: 444.5997, Accuracy: 0.6364\n",
      "---- Training ----\n",
      "Training loss: 138.5651\n",
      "Training acc over epoch: 0.6377\n",
      "---- Validation ----\n",
      "Validation loss: 34.4871\n",
      "Validation acc: 0.6789\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.2371, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 441.3951, Accuracy: 0.6655\n",
      "Training loss (for one batch) at step 20: 441.7382, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 30: 439.7217, Accuracy: 0.6628\n",
      "Training loss (for one batch) at step 40: 442.5228, Accuracy: 0.6663\n",
      "Training loss (for one batch) at step 50: 435.0679, Accuracy: 0.6685\n",
      "Training loss (for one batch) at step 60: 443.7356, Accuracy: 0.6709\n",
      "Training loss (for one batch) at step 70: 439.0153, Accuracy: 0.6707\n",
      "Training loss (for one batch) at step 80: 441.0839, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 90: 446.7157, Accuracy: 0.6681\n",
      "Training loss (for one batch) at step 100: 439.5028, Accuracy: 0.6699\n",
      "Training loss (for one batch) at step 110: 438.0777, Accuracy: 0.6696\n",
      "---- Training ----\n",
      "Training loss: 137.1038\n",
      "Training acc over epoch: 0.6709\n",
      "---- Validation ----\n",
      "Validation loss: 34.6232\n",
      "Validation acc: 0.7069\n",
      "Time taken: 10.88s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.9299, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 442.6167, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 20: 441.5139, Accuracy: 0.7024\n",
      "Training loss (for one batch) at step 30: 441.1182, Accuracy: 0.6978\n",
      "Training loss (for one batch) at step 40: 437.1293, Accuracy: 0.6997\n",
      "Training loss (for one batch) at step 50: 434.1751, Accuracy: 0.7014\n",
      "Training loss (for one batch) at step 60: 451.9171, Accuracy: 0.7033\n",
      "Training loss (for one batch) at step 70: 446.4353, Accuracy: 0.6995\n",
      "Training loss (for one batch) at step 80: 441.0216, Accuracy: 0.6952\n",
      "Training loss (for one batch) at step 90: 441.4449, Accuracy: 0.6886\n",
      "Training loss (for one batch) at step 100: 438.1988, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 110: 443.6730, Accuracy: 0.6888\n",
      "---- Training ----\n",
      "Training loss: 138.2387\n",
      "Training acc over epoch: 0.6889\n",
      "---- Validation ----\n",
      "Validation loss: 35.8917\n",
      "Validation acc: 0.6797\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 439.5551, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 441.2307, Accuracy: 0.7003\n",
      "Training loss (for one batch) at step 20: 440.1059, Accuracy: 0.6771\n",
      "Training loss (for one batch) at step 30: 435.2256, Accuracy: 0.6893\n",
      "Training loss (for one batch) at step 40: 433.8902, Accuracy: 0.6926\n",
      "Training loss (for one batch) at step 50: 433.5675, Accuracy: 0.6922\n",
      "Training loss (for one batch) at step 60: 432.7331, Accuracy: 0.6986\n",
      "Training loss (for one batch) at step 70: 438.0814, Accuracy: 0.6994\n",
      "Training loss (for one batch) at step 80: 439.1325, Accuracy: 0.6950\n",
      "Training loss (for one batch) at step 90: 437.8618, Accuracy: 0.6954\n",
      "Training loss (for one batch) at step 100: 438.6944, Accuracy: 0.6954\n",
      "Training loss (for one batch) at step 110: 436.6594, Accuracy: 0.6986\n",
      "---- Training ----\n",
      "Training loss: 135.6242\n",
      "Training acc over epoch: 0.6983\n",
      "---- Validation ----\n",
      "Validation loss: 34.6145\n",
      "Validation acc: 0.6891\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 441.8756, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 442.3936, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 20: 438.1844, Accuracy: 0.6860\n",
      "Training loss (for one batch) at step 30: 428.0336, Accuracy: 0.6933\n",
      "Training loss (for one batch) at step 40: 430.7794, Accuracy: 0.7029\n",
      "Training loss (for one batch) at step 50: 430.6302, Accuracy: 0.7050\n",
      "Training loss (for one batch) at step 60: 437.0571, Accuracy: 0.7090\n",
      "Training loss (for one batch) at step 70: 440.3540, Accuracy: 0.7120\n",
      "Training loss (for one batch) at step 80: 443.7386, Accuracy: 0.7127\n",
      "Training loss (for one batch) at step 90: 439.2933, Accuracy: 0.7110\n",
      "Training loss (for one batch) at step 100: 431.8226, Accuracy: 0.7119\n",
      "Training loss (for one batch) at step 110: 436.0501, Accuracy: 0.7141\n",
      "---- Training ----\n",
      "Training loss: 136.1023\n",
      "Training acc over epoch: 0.7138\n",
      "---- Validation ----\n",
      "Validation loss: 33.9120\n",
      "Validation acc: 0.6335\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 442.9285, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 442.5127, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 20: 438.1836, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 429.8396, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 40: 430.0651, Accuracy: 0.7163\n",
      "Training loss (for one batch) at step 50: 435.8242, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 60: 444.9096, Accuracy: 0.7232\n",
      "Training loss (for one batch) at step 70: 441.7380, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 80: 436.2803, Accuracy: 0.7216\n",
      "Training loss (for one batch) at step 90: 436.3403, Accuracy: 0.7204\n",
      "Training loss (for one batch) at step 100: 425.4491, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 110: 443.0890, Accuracy: 0.7245\n",
      "---- Training ----\n",
      "Training loss: 139.3352\n",
      "Training acc over epoch: 0.7243\n",
      "---- Validation ----\n",
      "Validation loss: 37.3361\n",
      "Validation acc: 0.6881\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 446.9457, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 440.3903, Accuracy: 0.6790\n",
      "Training loss (for one batch) at step 20: 434.1504, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 30: 432.9991, Accuracy: 0.7021\n",
      "Training loss (for one batch) at step 40: 425.3416, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 50: 424.9614, Accuracy: 0.7168\n",
      "Training loss (for one batch) at step 60: 423.4071, Accuracy: 0.7252\n",
      "Training loss (for one batch) at step 70: 436.4491, Accuracy: 0.7248\n",
      "Training loss (for one batch) at step 80: 436.2498, Accuracy: 0.7232\n",
      "Training loss (for one batch) at step 90: 437.0830, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 100: 433.6682, Accuracy: 0.7216\n",
      "Training loss (for one batch) at step 110: 430.5201, Accuracy: 0.7234\n",
      "---- Training ----\n",
      "Training loss: 134.5099\n",
      "Training acc over epoch: 0.7254\n",
      "---- Validation ----\n",
      "Validation loss: 34.9546\n",
      "Validation acc: 0.7343\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 433.5256, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 438.7190, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 20: 435.6917, Accuracy: 0.7310\n",
      "Training loss (for one batch) at step 30: 428.2971, Accuracy: 0.7377\n",
      "Training loss (for one batch) at step 40: 440.4673, Accuracy: 0.7382\n",
      "Training loss (for one batch) at step 50: 417.6539, Accuracy: 0.7460\n",
      "Training loss (for one batch) at step 60: 442.1224, Accuracy: 0.7531\n",
      "Training loss (for one batch) at step 70: 440.9340, Accuracy: 0.7499\n",
      "Training loss (for one batch) at step 80: 438.3124, Accuracy: 0.7400\n",
      "Training loss (for one batch) at step 90: 430.8405, Accuracy: 0.7404\n",
      "Training loss (for one batch) at step 100: 428.1399, Accuracy: 0.7420\n",
      "Training loss (for one batch) at step 110: 435.0085, Accuracy: 0.7423\n",
      "---- Training ----\n",
      "Training loss: 135.3681\n",
      "Training acc over epoch: 0.7408\n",
      "---- Validation ----\n",
      "Validation loss: 34.7788\n",
      "Validation acc: 0.7415\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 444.4262, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 431.5231, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 20: 434.9649, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 30: 428.0276, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 40: 418.9302, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 50: 430.5130, Accuracy: 0.7463\n",
      "Training loss (for one batch) at step 60: 427.2386, Accuracy: 0.7551\n",
      "Training loss (for one batch) at step 70: 448.1176, Accuracy: 0.7577\n",
      "Training loss (for one batch) at step 80: 439.0251, Accuracy: 0.7538\n",
      "Training loss (for one batch) at step 90: 430.7573, Accuracy: 0.7503\n",
      "Training loss (for one batch) at step 100: 433.6567, Accuracy: 0.7488\n",
      "Training loss (for one batch) at step 110: 425.7775, Accuracy: 0.7506\n",
      "---- Training ----\n",
      "Training loss: 135.0256\n",
      "Training acc over epoch: 0.7513\n",
      "---- Validation ----\n",
      "Validation loss: 34.5217\n",
      "Validation acc: 0.7453\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 439.7853, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 443.0060, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 20: 430.6366, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 30: 427.4764, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 40: 421.9964, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 50: 396.8853, Accuracy: 0.7581\n",
      "Training loss (for one batch) at step 60: 428.0941, Accuracy: 0.7582\n",
      "Training loss (for one batch) at step 70: 427.9125, Accuracy: 0.7587\n",
      "Training loss (for one batch) at step 80: 437.9464, Accuracy: 0.7506\n",
      "Training loss (for one batch) at step 90: 439.3610, Accuracy: 0.7468\n",
      "Training loss (for one batch) at step 100: 426.9486, Accuracy: 0.7475\n",
      "Training loss (for one batch) at step 110: 429.2431, Accuracy: 0.7480\n",
      "---- Training ----\n",
      "Training loss: 130.9624\n",
      "Training acc over epoch: 0.7487\n",
      "---- Validation ----\n",
      "Validation loss: 32.2777\n",
      "Validation acc: 0.7526\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 441.1762, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 434.6736, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 20: 437.3394, Accuracy: 0.7381\n",
      "Training loss (for one batch) at step 30: 426.6293, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 40: 412.9890, Accuracy: 0.7567\n",
      "Training loss (for one batch) at step 50: 405.8097, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 60: 419.1575, Accuracy: 0.7764\n",
      "Training loss (for one batch) at step 70: 433.8503, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 80: 438.2689, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 90: 430.7866, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 100: 416.5673, Accuracy: 0.7619\n",
      "Training loss (for one batch) at step 110: 438.9550, Accuracy: 0.7634\n",
      "---- Training ----\n",
      "Training loss: 133.6552\n",
      "Training acc over epoch: 0.7632\n",
      "---- Validation ----\n",
      "Validation loss: 32.6320\n",
      "Validation acc: 0.7410\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 436.7112, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 433.7726, Accuracy: 0.7514\n",
      "Training loss (for one batch) at step 20: 425.4642, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 30: 416.6186, Accuracy: 0.7659\n",
      "Training loss (for one batch) at step 40: 418.4915, Accuracy: 0.7700\n",
      "Training loss (for one batch) at step 50: 396.5062, Accuracy: 0.7819\n",
      "Training loss (for one batch) at step 60: 415.5659, Accuracy: 0.7892\n",
      "Training loss (for one batch) at step 70: 423.1639, Accuracy: 0.7839\n",
      "Training loss (for one batch) at step 80: 434.7136, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 90: 433.1215, Accuracy: 0.7694\n",
      "Training loss (for one batch) at step 100: 426.2701, Accuracy: 0.7666\n",
      "Training loss (for one batch) at step 110: 412.2486, Accuracy: 0.7655\n",
      "---- Training ----\n",
      "Training loss: 129.5331\n",
      "Training acc over epoch: 0.7656\n",
      "---- Validation ----\n",
      "Validation loss: 33.8761\n",
      "Validation acc: 0.7684\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 448.6859, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 427.8958, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 20: 418.4382, Accuracy: 0.7440\n",
      "Training loss (for one batch) at step 30: 417.7278, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 40: 411.8452, Accuracy: 0.7643\n",
      "Training loss (for one batch) at step 50: 394.1302, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 60: 412.4672, Accuracy: 0.7832\n",
      "Training loss (for one batch) at step 70: 434.0413, Accuracy: 0.7808\n",
      "Training loss (for one batch) at step 80: 434.4098, Accuracy: 0.7718\n",
      "Training loss (for one batch) at step 90: 433.8197, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 100: 430.7228, Accuracy: 0.7650\n",
      "Training loss (for one batch) at step 110: 425.4647, Accuracy: 0.7670\n",
      "---- Training ----\n",
      "Training loss: 133.8897\n",
      "Training acc over epoch: 0.7654\n",
      "---- Validation ----\n",
      "Validation loss: 35.9340\n",
      "Validation acc: 0.7391\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 441.5568, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 429.4432, Accuracy: 0.7514\n",
      "Training loss (for one batch) at step 20: 436.4228, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 30: 415.5688, Accuracy: 0.7613\n",
      "Training loss (for one batch) at step 40: 404.9444, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 50: 392.4556, Accuracy: 0.7796\n",
      "Training loss (for one batch) at step 60: 410.9997, Accuracy: 0.7866\n",
      "Training loss (for one batch) at step 70: 433.7054, Accuracy: 0.7865\n",
      "Training loss (for one batch) at step 80: 421.2348, Accuracy: 0.7761\n",
      "Training loss (for one batch) at step 90: 430.6224, Accuracy: 0.7697\n",
      "Training loss (for one batch) at step 100: 418.1515, Accuracy: 0.7687\n",
      "Training loss (for one batch) at step 110: 430.4093, Accuracy: 0.7677\n",
      "---- Training ----\n",
      "Training loss: 134.7271\n",
      "Training acc over epoch: 0.7684\n",
      "---- Validation ----\n",
      "Validation loss: 34.9748\n",
      "Validation acc: 0.7450\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 448.0991, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 430.9233, Accuracy: 0.7464\n",
      "Training loss (for one batch) at step 20: 430.9537, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 415.6505, Accuracy: 0.7626\n",
      "Training loss (for one batch) at step 40: 411.7841, Accuracy: 0.7725\n",
      "Training loss (for one batch) at step 50: 389.0749, Accuracy: 0.7840\n",
      "Training loss (for one batch) at step 60: 415.5363, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 70: 423.5682, Accuracy: 0.7892\n",
      "Training loss (for one batch) at step 80: 427.7573, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 90: 425.6400, Accuracy: 0.7770\n",
      "Training loss (for one batch) at step 100: 413.9004, Accuracy: 0.7743\n",
      "Training loss (for one batch) at step 110: 402.4121, Accuracy: 0.7723\n",
      "---- Training ----\n",
      "Training loss: 143.1194\n",
      "Training acc over epoch: 0.7734\n",
      "---- Validation ----\n",
      "Validation loss: 35.9110\n",
      "Validation acc: 0.7563\n",
      "Time taken: 17.59s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 453.6543, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 433.2834, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 20: 434.6751, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 30: 421.6432, Accuracy: 0.7596\n",
      "Training loss (for one batch) at step 40: 400.0856, Accuracy: 0.7738\n",
      "Training loss (for one batch) at step 50: 390.6250, Accuracy: 0.7845\n",
      "Training loss (for one batch) at step 60: 403.7513, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 70: 431.3882, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 80: 429.4294, Accuracy: 0.7840\n",
      "Training loss (for one batch) at step 90: 418.5554, Accuracy: 0.7752\n",
      "Training loss (for one batch) at step 100: 406.9036, Accuracy: 0.7758\n",
      "Training loss (for one batch) at step 110: 421.7303, Accuracy: 0.7761\n",
      "---- Training ----\n",
      "Training loss: 129.7441\n",
      "Training acc over epoch: 0.7763\n",
      "---- Validation ----\n",
      "Validation loss: 38.4669\n",
      "Validation acc: 0.7480\n",
      "Time taken: 12.70s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 447.9399, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 431.1475, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 20: 420.1141, Accuracy: 0.7582\n",
      "Training loss (for one batch) at step 30: 405.8647, Accuracy: 0.7674\n",
      "Training loss (for one batch) at step 40: 397.3419, Accuracy: 0.7746\n",
      "Training loss (for one batch) at step 50: 385.6807, Accuracy: 0.7907\n",
      "Training loss (for one batch) at step 60: 410.3794, Accuracy: 0.7984\n",
      "Training loss (for one batch) at step 70: 419.1878, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 80: 434.5511, Accuracy: 0.7813\n",
      "Training loss (for one batch) at step 90: 418.9474, Accuracy: 0.7693\n",
      "Training loss (for one batch) at step 100: 416.1568, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 110: 410.8584, Accuracy: 0.7706\n",
      "---- Training ----\n",
      "Training loss: 133.1376\n",
      "Training acc over epoch: 0.7704\n",
      "---- Validation ----\n",
      "Validation loss: 35.6814\n",
      "Validation acc: 0.7448\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 436.3887, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 428.8177, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 20: 420.6329, Accuracy: 0.7448\n",
      "Training loss (for one batch) at step 30: 405.9905, Accuracy: 0.7631\n",
      "Training loss (for one batch) at step 40: 386.3996, Accuracy: 0.7752\n",
      "Training loss (for one batch) at step 50: 366.5612, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 60: 393.8208, Accuracy: 0.7988\n",
      "Training loss (for one batch) at step 70: 425.9347, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 80: 432.8391, Accuracy: 0.7869\n",
      "Training loss (for one batch) at step 90: 416.5924, Accuracy: 0.7778\n",
      "Training loss (for one batch) at step 100: 407.8292, Accuracy: 0.7775\n",
      "Training loss (for one batch) at step 110: 412.1475, Accuracy: 0.7806\n",
      "---- Training ----\n",
      "Training loss: 125.8136\n",
      "Training acc over epoch: 0.7810\n",
      "---- Validation ----\n",
      "Validation loss: 37.2880\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 435.9901, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 431.6589, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 20: 415.9776, Accuracy: 0.7470\n",
      "Training loss (for one batch) at step 30: 411.0865, Accuracy: 0.7601\n",
      "Training loss (for one batch) at step 40: 369.5970, Accuracy: 0.7736\n",
      "Training loss (for one batch) at step 50: 365.0454, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 60: 386.2640, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 70: 418.3675, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 80: 416.4370, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 90: 411.9083, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 100: 413.5462, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 110: 418.9821, Accuracy: 0.7755\n",
      "---- Training ----\n",
      "Training loss: 129.3325\n",
      "Training acc over epoch: 0.7747\n",
      "---- Validation ----\n",
      "Validation loss: 44.9702\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.75s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 430.5828, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 426.1126, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 407.2665, Accuracy: 0.7463\n",
      "Training loss (for one batch) at step 30: 381.6718, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 40: 396.7899, Accuracy: 0.7792\n",
      "Training loss (for one batch) at step 50: 361.5449, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 60: 399.4577, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 70: 428.2944, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 80: 424.1445, Accuracy: 0.7867\n",
      "Training loss (for one batch) at step 90: 411.5706, Accuracy: 0.7796\n",
      "Training loss (for one batch) at step 100: 405.2090, Accuracy: 0.7769\n",
      "Training loss (for one batch) at step 110: 414.7533, Accuracy: 0.7786\n",
      "---- Training ----\n",
      "Training loss: 122.3981\n",
      "Training acc over epoch: 0.7783\n",
      "---- Validation ----\n",
      "Validation loss: 32.6165\n",
      "Validation acc: 0.7397\n",
      "Time taken: 18.66s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 428.1935, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 420.2794, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 414.3643, Accuracy: 0.7414\n",
      "Training loss (for one batch) at step 30: 397.7783, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 40: 374.4720, Accuracy: 0.7755\n",
      "Training loss (for one batch) at step 50: 362.5080, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 60: 388.8197, Accuracy: 0.8016\n",
      "Training loss (for one batch) at step 70: 415.7328, Accuracy: 0.7998\n",
      "Training loss (for one batch) at step 80: 410.1078, Accuracy: 0.7899\n",
      "Training loss (for one batch) at step 90: 416.9993, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 100: 408.1041, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 110: 415.5088, Accuracy: 0.7821\n",
      "---- Training ----\n",
      "Training loss: 120.3929\n",
      "Training acc over epoch: 0.7816\n",
      "---- Validation ----\n",
      "Validation loss: 37.0726\n",
      "Validation acc: 0.7257\n",
      "Time taken: 17.71s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 420.0457, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 422.3411, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 20: 405.8299, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 30: 388.1642, Accuracy: 0.7669\n",
      "Training loss (for one batch) at step 40: 372.4759, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 50: 349.1378, Accuracy: 0.7973\n",
      "Training loss (for one batch) at step 60: 406.9819, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 70: 422.9164, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 80: 431.6552, Accuracy: 0.7899\n",
      "Training loss (for one batch) at step 90: 418.8297, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 100: 395.8941, Accuracy: 0.7793\n",
      "Training loss (for one batch) at step 110: 390.5455, Accuracy: 0.7810\n",
      "---- Training ----\n",
      "Training loss: 129.5533\n",
      "Training acc over epoch: 0.7808\n",
      "---- Validation ----\n",
      "Validation loss: 41.2774\n",
      "Validation acc: 0.7389\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 435.4634, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 411.6304, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 20: 398.2078, Accuracy: 0.7426\n",
      "Training loss (for one batch) at step 30: 376.6347, Accuracy: 0.7646\n",
      "Training loss (for one batch) at step 40: 367.6015, Accuracy: 0.7799\n",
      "Training loss (for one batch) at step 50: 346.4876, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 60: 372.3462, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 70: 410.5881, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 80: 420.2928, Accuracy: 0.7877\n",
      "Training loss (for one batch) at step 90: 408.1055, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 100: 387.0228, Accuracy: 0.7799\n",
      "Training loss (for one batch) at step 110: 409.5602, Accuracy: 0.7810\n",
      "---- Training ----\n",
      "Training loss: 129.7270\n",
      "Training acc over epoch: 0.7814\n",
      "---- Validation ----\n",
      "Validation loss: 35.6213\n",
      "Validation acc: 0.7407\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 422.5569, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 408.4251, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 392.9830, Accuracy: 0.7563\n",
      "Training loss (for one batch) at step 30: 390.1034, Accuracy: 0.7729\n",
      "Training loss (for one batch) at step 40: 377.5985, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 50: 350.8174, Accuracy: 0.8076\n",
      "Training loss (for one batch) at step 60: 364.4321, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 70: 383.6492, Accuracy: 0.8106\n",
      "Training loss (for one batch) at step 80: 405.4946, Accuracy: 0.7982\n",
      "Training loss (for one batch) at step 90: 408.6808, Accuracy: 0.7914\n",
      "Training loss (for one batch) at step 100: 381.2163, Accuracy: 0.7902\n",
      "Training loss (for one batch) at step 110: 402.6836, Accuracy: 0.7889\n",
      "---- Training ----\n",
      "Training loss: 119.9210\n",
      "Training acc over epoch: 0.7888\n",
      "---- Validation ----\n",
      "Validation loss: 37.3354\n",
      "Validation acc: 0.7399\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 411.6558, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 418.1713, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 20: 391.5395, Accuracy: 0.7526\n",
      "Training loss (for one batch) at step 30: 373.2639, Accuracy: 0.7714\n",
      "Training loss (for one batch) at step 40: 362.9178, Accuracy: 0.7856\n",
      "Training loss (for one batch) at step 50: 340.5784, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 60: 370.3712, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 70: 403.2747, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 80: 398.6287, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 90: 396.5057, Accuracy: 0.7869\n",
      "Training loss (for one batch) at step 100: 372.6013, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 110: 382.9715, Accuracy: 0.7877\n",
      "---- Training ----\n",
      "Training loss: 120.9731\n",
      "Training acc over epoch: 0.7863\n",
      "---- Validation ----\n",
      "Validation loss: 35.5687\n",
      "Validation acc: 0.7359\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 404.0967, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 416.7188, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 392.0373, Accuracy: 0.7556\n",
      "Training loss (for one batch) at step 30: 381.9949, Accuracy: 0.7704\n",
      "Training loss (for one batch) at step 40: 361.8613, Accuracy: 0.7864\n",
      "Training loss (for one batch) at step 50: 336.4366, Accuracy: 0.7979\n",
      "Training loss (for one batch) at step 60: 366.6187, Accuracy: 0.8071\n",
      "Training loss (for one batch) at step 70: 387.6322, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 80: 422.7195, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 90: 398.4558, Accuracy: 0.7825\n",
      "Training loss (for one batch) at step 100: 383.4857, Accuracy: 0.7838\n",
      "Training loss (for one batch) at step 110: 391.4085, Accuracy: 0.7839\n",
      "---- Training ----\n",
      "Training loss: 122.1395\n",
      "Training acc over epoch: 0.7828\n",
      "---- Validation ----\n",
      "Validation loss: 38.6745\n",
      "Validation acc: 0.7214\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 418.7255, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 408.7563, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 20: 380.5822, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 30: 366.2287, Accuracy: 0.7797\n",
      "Training loss (for one batch) at step 40: 340.1650, Accuracy: 0.7929\n",
      "Training loss (for one batch) at step 50: 337.6434, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 60: 360.1729, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 70: 397.0205, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 80: 411.4868, Accuracy: 0.7895\n",
      "Training loss (for one batch) at step 90: 388.4076, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 100: 380.9471, Accuracy: 0.7853\n",
      "Training loss (for one batch) at step 110: 387.0085, Accuracy: 0.7856\n",
      "---- Training ----\n",
      "Training loss: 125.4296\n",
      "Training acc over epoch: 0.7855\n",
      "---- Validation ----\n",
      "Validation loss: 34.7804\n",
      "Validation acc: 0.7015\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 422.2732, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 407.0992, Accuracy: 0.7251\n",
      "Training loss (for one batch) at step 20: 375.0520, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 30: 355.6695, Accuracy: 0.7686\n",
      "Training loss (for one batch) at step 40: 352.7515, Accuracy: 0.7851\n",
      "Training loss (for one batch) at step 50: 337.6121, Accuracy: 0.7986\n",
      "Training loss (for one batch) at step 60: 364.9946, Accuracy: 0.8106\n",
      "Training loss (for one batch) at step 70: 389.2255, Accuracy: 0.8026\n",
      "Training loss (for one batch) at step 80: 395.6480, Accuracy: 0.7903\n",
      "Training loss (for one batch) at step 90: 367.7040, Accuracy: 0.7834\n",
      "Training loss (for one batch) at step 100: 359.1030, Accuracy: 0.7850\n",
      "Training loss (for one batch) at step 110: 400.0591, Accuracy: 0.7853\n",
      "---- Training ----\n",
      "Training loss: 124.4522\n",
      "Training acc over epoch: 0.7843\n",
      "---- Validation ----\n",
      "Validation loss: 34.7213\n",
      "Validation acc: 0.7311\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 421.1603, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 414.8254, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 388.5074, Accuracy: 0.7347\n",
      "Training loss (for one batch) at step 30: 367.6935, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 40: 337.7101, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 50: 323.9232, Accuracy: 0.7966\n",
      "Training loss (for one batch) at step 60: 363.2812, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 70: 371.8476, Accuracy: 0.7980\n",
      "Training loss (for one batch) at step 80: 412.0637, Accuracy: 0.7872\n",
      "Training loss (for one batch) at step 90: 382.0876, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 100: 357.0367, Accuracy: 0.7844\n",
      "Training loss (for one batch) at step 110: 377.7864, Accuracy: 0.7855\n",
      "---- Training ----\n",
      "Training loss: 119.6141\n",
      "Training acc over epoch: 0.7847\n",
      "---- Validation ----\n",
      "Validation loss: 39.6023\n",
      "Validation acc: 0.7053\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 401.8097, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 405.8177, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 20: 361.1069, Accuracy: 0.7314\n",
      "Training loss (for one batch) at step 30: 343.6499, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 40: 320.4709, Accuracy: 0.7853\n",
      "Training loss (for one batch) at step 50: 329.3636, Accuracy: 0.8006\n",
      "Training loss (for one batch) at step 60: 347.7570, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 70: 396.4033, Accuracy: 0.8005\n",
      "Training loss (for one batch) at step 80: 414.6629, Accuracy: 0.7896\n",
      "Training loss (for one batch) at step 90: 384.4401, Accuracy: 0.7843\n",
      "Training loss (for one batch) at step 100: 357.0579, Accuracy: 0.7864\n",
      "Training loss (for one batch) at step 110: 362.3966, Accuracy: 0.7882\n",
      "---- Training ----\n",
      "Training loss: 113.6863\n",
      "Training acc over epoch: 0.7870\n",
      "---- Validation ----\n",
      "Validation loss: 44.4301\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 394.4842, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 404.0217, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 20: 353.9816, Accuracy: 0.7411\n",
      "Training loss (for one batch) at step 30: 359.2743, Accuracy: 0.7636\n",
      "Training loss (for one batch) at step 40: 327.5431, Accuracy: 0.7839\n",
      "Training loss (for one batch) at step 50: 328.0696, Accuracy: 0.7992\n",
      "Training loss (for one batch) at step 60: 332.6017, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 70: 375.0946, Accuracy: 0.7970\n",
      "Training loss (for one batch) at step 80: 392.2954, Accuracy: 0.7842\n",
      "Training loss (for one batch) at step 90: 368.6356, Accuracy: 0.7822\n",
      "Training loss (for one batch) at step 100: 361.0760, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 110: 358.4202, Accuracy: 0.7855\n",
      "---- Training ----\n",
      "Training loss: 115.8471\n",
      "Training acc over epoch: 0.7861\n",
      "---- Validation ----\n",
      "Validation loss: 42.5624\n",
      "Validation acc: 0.7192\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 399.5450, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 400.8225, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 20: 362.9198, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 30: 351.3727, Accuracy: 0.7702\n",
      "Training loss (for one batch) at step 40: 323.9282, Accuracy: 0.7877\n",
      "Training loss (for one batch) at step 50: 333.0298, Accuracy: 0.8027\n",
      "Training loss (for one batch) at step 60: 338.3647, Accuracy: 0.8099\n",
      "Training loss (for one batch) at step 70: 371.0743, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 80: 388.3581, Accuracy: 0.7893\n",
      "Training loss (for one batch) at step 90: 358.6269, Accuracy: 0.7847\n",
      "Training loss (for one batch) at step 100: 356.2435, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 110: 372.4116, Accuracy: 0.7872\n",
      "---- Training ----\n",
      "Training loss: 122.8820\n",
      "Training acc over epoch: 0.7849\n",
      "---- Validation ----\n",
      "Validation loss: 44.4130\n",
      "Validation acc: 0.7090\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 416.1183, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 380.8394, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 356.7314, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 30: 353.8408, Accuracy: 0.7692\n",
      "Training loss (for one batch) at step 40: 343.5271, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 50: 303.7879, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 60: 331.7042, Accuracy: 0.8138\n",
      "Training loss (for one batch) at step 70: 377.0909, Accuracy: 0.8033\n",
      "Training loss (for one batch) at step 80: 407.7101, Accuracy: 0.7878\n",
      "Training loss (for one batch) at step 90: 358.4726, Accuracy: 0.7837\n",
      "Training loss (for one batch) at step 100: 338.3273, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 110: 345.7333, Accuracy: 0.7871\n",
      "---- Training ----\n",
      "Training loss: 109.3881\n",
      "Training acc over epoch: 0.7858\n",
      "---- Validation ----\n",
      "Validation loss: 48.6329\n",
      "Validation acc: 0.7144\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 375.8171, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 387.1584, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 349.9817, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 30: 350.4741, Accuracy: 0.7608\n",
      "Training loss (for one batch) at step 40: 311.8624, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 50: 317.5220, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 60: 337.8648, Accuracy: 0.8026\n",
      "Training loss (for one batch) at step 70: 365.2851, Accuracy: 0.7926\n",
      "Training loss (for one batch) at step 80: 388.2657, Accuracy: 0.7811\n",
      "Training loss (for one batch) at step 90: 377.0960, Accuracy: 0.7769\n",
      "Training loss (for one batch) at step 100: 341.2544, Accuracy: 0.7799\n",
      "Training loss (for one batch) at step 110: 364.5019, Accuracy: 0.7807\n",
      "---- Training ----\n",
      "Training loss: 111.8166\n",
      "Training acc over epoch: 0.7805\n",
      "---- Validation ----\n",
      "Validation loss: 44.1393\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 397.6552, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 400.3717, Accuracy: 0.7017\n",
      "Training loss (for one batch) at step 20: 353.0718, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 30: 345.5680, Accuracy: 0.7641\n",
      "Training loss (for one batch) at step 40: 317.2539, Accuracy: 0.7877\n",
      "Training loss (for one batch) at step 50: 309.1374, Accuracy: 0.8038\n",
      "Training loss (for one batch) at step 60: 344.7244, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 70: 372.7743, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 80: 374.4262, Accuracy: 0.7865\n",
      "Training loss (for one batch) at step 90: 354.9067, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 100: 339.9322, Accuracy: 0.7852\n",
      "Training loss (for one batch) at step 110: 360.8455, Accuracy: 0.7865\n",
      "---- Training ----\n",
      "Training loss: 112.2253\n",
      "Training acc over epoch: 0.7867\n",
      "---- Validation ----\n",
      "Validation loss: 40.8861\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.50s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7143\n",
      "Validation AUC: 0.7135\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 677.5103, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 569.6272, Accuracy: 0.4964\n",
      "Training loss (for one batch) at step 20: 546.0714, Accuracy: 0.5089\n",
      "Training loss (for one batch) at step 30: 528.5034, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 40: 538.5873, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 50: 504.8705, Accuracy: 0.5092\n",
      "Training loss (for one batch) at step 60: 486.8099, Accuracy: 0.5093\n",
      "Training loss (for one batch) at step 70: 468.4012, Accuracy: 0.5076\n",
      "Training loss (for one batch) at step 80: 464.0652, Accuracy: 0.5106\n",
      "Training loss (for one batch) at step 90: 469.8365, Accuracy: 0.5108\n",
      "Training loss (for one batch) at step 100: 460.2120, Accuracy: 0.5103\n",
      "Training loss (for one batch) at step 110: 458.7607, Accuracy: 0.5099\n",
      "---- Training ----\n",
      "Training loss: 147.0685\n",
      "Training acc over epoch: 0.5098\n",
      "---- Validation ----\n",
      "Validation loss: 34.5020\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.67s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 449.2959, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 448.2222, Accuracy: 0.5213\n",
      "Training loss (for one batch) at step 20: 445.5485, Accuracy: 0.5260\n",
      "Training loss (for one batch) at step 30: 446.8927, Accuracy: 0.5335\n",
      "Training loss (for one batch) at step 40: 448.9678, Accuracy: 0.5282\n",
      "Training loss (for one batch) at step 50: 445.3790, Accuracy: 0.5279\n",
      "Training loss (for one batch) at step 60: 444.6938, Accuracy: 0.5239\n",
      "Training loss (for one batch) at step 70: 446.6050, Accuracy: 0.5287\n",
      "Training loss (for one batch) at step 80: 445.3026, Accuracy: 0.5309\n",
      "Training loss (for one batch) at step 90: 443.6794, Accuracy: 0.5305\n",
      "Training loss (for one batch) at step 100: 450.0143, Accuracy: 0.5287\n",
      "Training loss (for one batch) at step 110: 451.1838, Accuracy: 0.5279\n",
      "---- Training ----\n",
      "Training loss: 139.9128\n",
      "Training acc over epoch: 0.5292\n",
      "---- Validation ----\n",
      "Validation loss: 34.7557\n",
      "Validation acc: 0.5148\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.5110, Accuracy: 0.4844\n",
      "Training loss (for one batch) at step 10: 445.8500, Accuracy: 0.5327\n",
      "Training loss (for one batch) at step 20: 445.4606, Accuracy: 0.5320\n",
      "Training loss (for one batch) at step 30: 445.9263, Accuracy: 0.5421\n",
      "Training loss (for one batch) at step 40: 446.0974, Accuracy: 0.5406\n",
      "Training loss (for one batch) at step 50: 444.0892, Accuracy: 0.5368\n",
      "Training loss (for one batch) at step 60: 447.7199, Accuracy: 0.5393\n",
      "Training loss (for one batch) at step 70: 445.0828, Accuracy: 0.5447\n",
      "Training loss (for one batch) at step 80: 445.2615, Accuracy: 0.5448\n",
      "Training loss (for one batch) at step 90: 445.9769, Accuracy: 0.5454\n",
      "Training loss (for one batch) at step 100: 444.2251, Accuracy: 0.5424\n",
      "Training loss (for one batch) at step 110: 442.5018, Accuracy: 0.5438\n",
      "---- Training ----\n",
      "Training loss: 140.0523\n",
      "Training acc over epoch: 0.5444\n",
      "---- Validation ----\n",
      "Validation loss: 34.4958\n",
      "Validation acc: 0.5234\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.7251, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 443.6814, Accuracy: 0.5661\n",
      "Training loss (for one batch) at step 20: 443.1633, Accuracy: 0.5588\n",
      "Training loss (for one batch) at step 30: 443.0780, Accuracy: 0.5650\n",
      "Training loss (for one batch) at step 40: 442.9691, Accuracy: 0.5657\n",
      "Training loss (for one batch) at step 50: 443.9238, Accuracy: 0.5677\n",
      "Training loss (for one batch) at step 60: 442.3718, Accuracy: 0.5674\n",
      "Training loss (for one batch) at step 70: 441.8710, Accuracy: 0.5695\n",
      "Training loss (for one batch) at step 80: 443.5451, Accuracy: 0.5719\n",
      "Training loss (for one batch) at step 90: 443.3103, Accuracy: 0.5734\n",
      "Training loss (for one batch) at step 100: 444.8618, Accuracy: 0.5707\n",
      "Training loss (for one batch) at step 110: 444.7805, Accuracy: 0.5681\n",
      "---- Training ----\n",
      "Training loss: 138.8111\n",
      "Training acc over epoch: 0.5674\n",
      "---- Validation ----\n",
      "Validation loss: 34.6959\n",
      "Validation acc: 0.5717\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 442.0941, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 445.0134, Accuracy: 0.5675\n",
      "Training loss (for one batch) at step 20: 442.7517, Accuracy: 0.5673\n",
      "Training loss (for one batch) at step 30: 442.0829, Accuracy: 0.5776\n",
      "Training loss (for one batch) at step 40: 442.3559, Accuracy: 0.5745\n",
      "Training loss (for one batch) at step 50: 441.8072, Accuracy: 0.5778\n",
      "Training loss (for one batch) at step 60: 442.6984, Accuracy: 0.5825\n",
      "Training loss (for one batch) at step 70: 443.5895, Accuracy: 0.5854\n",
      "Training loss (for one batch) at step 80: 440.5201, Accuracy: 0.5875\n",
      "Training loss (for one batch) at step 90: 443.8230, Accuracy: 0.5889\n",
      "Training loss (for one batch) at step 100: 447.0288, Accuracy: 0.5881\n",
      "Training loss (for one batch) at step 110: 445.7506, Accuracy: 0.5870\n",
      "---- Training ----\n",
      "Training loss: 138.4695\n",
      "Training acc over epoch: 0.5881\n",
      "---- Validation ----\n",
      "Validation loss: 34.5131\n",
      "Validation acc: 0.5854\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.8264, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 444.3154, Accuracy: 0.5838\n",
      "Training loss (for one batch) at step 20: 440.7709, Accuracy: 0.5911\n",
      "Training loss (for one batch) at step 30: 441.4036, Accuracy: 0.6031\n",
      "Training loss (for one batch) at step 40: 442.4785, Accuracy: 0.6023\n",
      "Training loss (for one batch) at step 50: 440.2058, Accuracy: 0.6072\n",
      "Training loss (for one batch) at step 60: 443.0146, Accuracy: 0.6046\n",
      "Training loss (for one batch) at step 70: 439.8913, Accuracy: 0.6072\n",
      "Training loss (for one batch) at step 80: 442.0999, Accuracy: 0.6066\n",
      "Training loss (for one batch) at step 90: 441.0636, Accuracy: 0.6068\n",
      "Training loss (for one batch) at step 100: 445.1197, Accuracy: 0.6065\n",
      "Training loss (for one batch) at step 110: 443.4053, Accuracy: 0.6064\n",
      "---- Training ----\n",
      "Training loss: 138.5802\n",
      "Training acc over epoch: 0.6053\n",
      "---- Validation ----\n",
      "Validation loss: 34.5548\n",
      "Validation acc: 0.6104\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.3935, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 444.6048, Accuracy: 0.6165\n",
      "Training loss (for one batch) at step 20: 437.7439, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 30: 437.0794, Accuracy: 0.6207\n",
      "Training loss (for one batch) at step 40: 440.6097, Accuracy: 0.6223\n",
      "Training loss (for one batch) at step 50: 440.9604, Accuracy: 0.6301\n",
      "Training loss (for one batch) at step 60: 433.4399, Accuracy: 0.6322\n",
      "Training loss (for one batch) at step 70: 447.7809, Accuracy: 0.6345\n",
      "Training loss (for one batch) at step 80: 441.4071, Accuracy: 0.6352\n",
      "Training loss (for one batch) at step 90: 440.0096, Accuracy: 0.6344\n",
      "Training loss (for one batch) at step 100: 441.3138, Accuracy: 0.6346\n",
      "Training loss (for one batch) at step 110: 439.8247, Accuracy: 0.6344\n",
      "---- Training ----\n",
      "Training loss: 136.8309\n",
      "Training acc over epoch: 0.6341\n",
      "---- Validation ----\n",
      "Validation loss: 35.0066\n",
      "Validation acc: 0.6784\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 441.5824, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 441.7650, Accuracy: 0.6335\n",
      "Training loss (for one batch) at step 20: 441.0843, Accuracy: 0.6458\n",
      "Training loss (for one batch) at step 30: 437.3026, Accuracy: 0.6530\n",
      "Training loss (for one batch) at step 40: 435.9730, Accuracy: 0.6599\n",
      "Training loss (for one batch) at step 50: 440.6143, Accuracy: 0.6630\n",
      "Training loss (for one batch) at step 60: 439.9786, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 70: 446.1757, Accuracy: 0.6649\n",
      "Training loss (for one batch) at step 80: 438.8351, Accuracy: 0.6661\n",
      "Training loss (for one batch) at step 90: 439.0207, Accuracy: 0.6616\n",
      "Training loss (for one batch) at step 100: 435.9644, Accuracy: 0.6603\n",
      "Training loss (for one batch) at step 110: 444.4922, Accuracy: 0.6607\n",
      "---- Training ----\n",
      "Training loss: 136.0740\n",
      "Training acc over epoch: 0.6616\n",
      "---- Validation ----\n",
      "Validation loss: 33.6743\n",
      "Validation acc: 0.6607\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 444.3477, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 440.8040, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 20: 445.0352, Accuracy: 0.6618\n",
      "Training loss (for one batch) at step 30: 430.1568, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 40: 434.3967, Accuracy: 0.6799\n",
      "Training loss (for one batch) at step 50: 432.8887, Accuracy: 0.6878\n",
      "Training loss (for one batch) at step 60: 439.2565, Accuracy: 0.6897\n",
      "Training loss (for one batch) at step 70: 440.8568, Accuracy: 0.6909\n",
      "Training loss (for one batch) at step 80: 443.6107, Accuracy: 0.6839\n",
      "Training loss (for one batch) at step 90: 440.7526, Accuracy: 0.6767\n",
      "Training loss (for one batch) at step 100: 444.8387, Accuracy: 0.6762\n",
      "Training loss (for one batch) at step 110: 438.8812, Accuracy: 0.6798\n",
      "---- Training ----\n",
      "Training loss: 139.2857\n",
      "Training acc over epoch: 0.6811\n",
      "---- Validation ----\n",
      "Validation loss: 34.7392\n",
      "Validation acc: 0.6824\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 440.1508, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 442.1155, Accuracy: 0.6790\n",
      "Training loss (for one batch) at step 20: 432.2595, Accuracy: 0.6849\n",
      "Training loss (for one batch) at step 30: 426.5977, Accuracy: 0.6860\n",
      "Training loss (for one batch) at step 40: 439.6926, Accuracy: 0.6848\n",
      "Training loss (for one batch) at step 50: 429.9794, Accuracy: 0.6967\n",
      "Training loss (for one batch) at step 60: 434.6217, Accuracy: 0.7021\n",
      "Training loss (for one batch) at step 70: 439.4014, Accuracy: 0.7051\n",
      "Training loss (for one batch) at step 80: 441.1381, Accuracy: 0.6997\n",
      "Training loss (for one batch) at step 90: 440.4016, Accuracy: 0.6969\n",
      "Training loss (for one batch) at step 100: 433.2380, Accuracy: 0.6980\n",
      "Training loss (for one batch) at step 110: 436.6110, Accuracy: 0.7000\n",
      "---- Training ----\n",
      "Training loss: 134.7710\n",
      "Training acc over epoch: 0.7015\n",
      "---- Validation ----\n",
      "Validation loss: 35.0386\n",
      "Validation acc: 0.7098\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 445.0287, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 437.0969, Accuracy: 0.7095\n",
      "Training loss (for one batch) at step 20: 436.2368, Accuracy: 0.7221\n",
      "Training loss (for one batch) at step 30: 429.8409, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 40: 432.7627, Accuracy: 0.7243\n",
      "Training loss (for one batch) at step 50: 424.7943, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 60: 429.2215, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 70: 432.2394, Accuracy: 0.7272\n",
      "Training loss (for one batch) at step 80: 438.1992, Accuracy: 0.7211\n",
      "Training loss (for one batch) at step 90: 435.1910, Accuracy: 0.7184\n",
      "Training loss (for one batch) at step 100: 432.0484, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 110: 441.1236, Accuracy: 0.7197\n",
      "---- Training ----\n",
      "Training loss: 136.1073\n",
      "Training acc over epoch: 0.7192\n",
      "---- Validation ----\n",
      "Validation loss: 35.3623\n",
      "Validation acc: 0.6865\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 447.6832, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 438.8366, Accuracy: 0.6982\n",
      "Training loss (for one batch) at step 20: 437.3286, Accuracy: 0.7016\n",
      "Training loss (for one batch) at step 30: 429.0130, Accuracy: 0.7193\n",
      "Training loss (for one batch) at step 40: 426.4736, Accuracy: 0.7205\n",
      "Training loss (for one batch) at step 50: 418.9203, Accuracy: 0.7333\n",
      "Training loss (for one batch) at step 60: 427.6616, Accuracy: 0.7374\n",
      "Training loss (for one batch) at step 70: 455.3755, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 80: 432.7312, Accuracy: 0.7289\n",
      "Training loss (for one batch) at step 90: 434.0985, Accuracy: 0.7222\n",
      "Training loss (for one batch) at step 100: 426.3814, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 110: 428.6472, Accuracy: 0.7246\n",
      "---- Training ----\n",
      "Training loss: 131.1549\n",
      "Training acc over epoch: 0.7253\n",
      "---- Validation ----\n",
      "Validation loss: 36.1082\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 429.1455, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 434.2756, Accuracy: 0.7152\n",
      "Training loss (for one batch) at step 20: 430.1102, Accuracy: 0.7169\n",
      "Training loss (for one batch) at step 30: 420.8265, Accuracy: 0.7276\n",
      "Training loss (for one batch) at step 40: 418.0793, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 50: 417.8404, Accuracy: 0.7443\n",
      "Training loss (for one batch) at step 60: 430.5710, Accuracy: 0.7495\n",
      "Training loss (for one batch) at step 70: 440.7270, Accuracy: 0.7524\n",
      "Training loss (for one batch) at step 80: 438.9029, Accuracy: 0.7470\n",
      "Training loss (for one batch) at step 90: 434.3676, Accuracy: 0.7400\n",
      "Training loss (for one batch) at step 100: 430.2358, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 110: 430.7998, Accuracy: 0.7351\n",
      "---- Training ----\n",
      "Training loss: 134.0626\n",
      "Training acc over epoch: 0.7348\n",
      "---- Validation ----\n",
      "Validation loss: 34.8821\n",
      "Validation acc: 0.7343\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 435.7939, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 437.9143, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 425.0039, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 30: 411.8641, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 40: 407.6313, Accuracy: 0.7468\n",
      "Training loss (for one batch) at step 50: 419.4894, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 60: 422.8138, Accuracy: 0.7613\n",
      "Training loss (for one batch) at step 70: 432.6259, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 80: 440.9344, Accuracy: 0.7498\n",
      "Training loss (for one batch) at step 90: 434.0338, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 100: 423.8345, Accuracy: 0.7413\n",
      "Training loss (for one batch) at step 110: 434.3014, Accuracy: 0.7444\n",
      "---- Training ----\n",
      "Training loss: 129.3510\n",
      "Training acc over epoch: 0.7436\n",
      "---- Validation ----\n",
      "Validation loss: 34.9591\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 436.9841, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 433.6265, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 419.4749, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 30: 409.8889, Accuracy: 0.7311\n",
      "Training loss (for one batch) at step 40: 413.9338, Accuracy: 0.7431\n",
      "Training loss (for one batch) at step 50: 402.0064, Accuracy: 0.7601\n",
      "Training loss (for one batch) at step 60: 409.5020, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 70: 427.5449, Accuracy: 0.7629\n",
      "Training loss (for one batch) at step 80: 438.5552, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 90: 426.8063, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 100: 423.9463, Accuracy: 0.7390\n",
      "Training loss (for one batch) at step 110: 428.1549, Accuracy: 0.7411\n",
      "---- Training ----\n",
      "Training loss: 143.5961\n",
      "Training acc over epoch: 0.7403\n",
      "---- Validation ----\n",
      "Validation loss: 33.7553\n",
      "Validation acc: 0.7260\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 430.1792, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 428.8528, Accuracy: 0.7514\n",
      "Training loss (for one batch) at step 20: 427.7238, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 30: 418.5258, Accuracy: 0.7573\n",
      "Training loss (for one batch) at step 40: 400.1929, Accuracy: 0.7652\n",
      "Training loss (for one batch) at step 50: 391.9232, Accuracy: 0.7771\n",
      "Training loss (for one batch) at step 60: 406.5761, Accuracy: 0.7804\n",
      "Training loss (for one batch) at step 70: 436.6953, Accuracy: 0.7740\n",
      "Training loss (for one batch) at step 80: 440.6949, Accuracy: 0.7670\n",
      "Training loss (for one batch) at step 90: 426.0060, Accuracy: 0.7613\n",
      "Training loss (for one batch) at step 100: 414.2305, Accuracy: 0.7572\n",
      "Training loss (for one batch) at step 110: 425.5959, Accuracy: 0.7564\n",
      "---- Training ----\n",
      "Training loss: 135.1863\n",
      "Training acc over epoch: 0.7562\n",
      "---- Validation ----\n",
      "Validation loss: 36.3028\n",
      "Validation acc: 0.7077\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 432.4582, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 431.2043, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 20: 427.2807, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 30: 405.7480, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 40: 391.8230, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 50: 381.6380, Accuracy: 0.7718\n",
      "Training loss (for one batch) at step 60: 415.2829, Accuracy: 0.7786\n",
      "Training loss (for one batch) at step 70: 424.6524, Accuracy: 0.7748\n",
      "Training loss (for one batch) at step 80: 439.1027, Accuracy: 0.7640\n",
      "Training loss (for one batch) at step 90: 429.3028, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 100: 419.5737, Accuracy: 0.7512\n",
      "Training loss (for one batch) at step 110: 431.4242, Accuracy: 0.7509\n",
      "---- Training ----\n",
      "Training loss: 134.4604\n",
      "Training acc over epoch: 0.7509\n",
      "---- Validation ----\n",
      "Validation loss: 33.5955\n",
      "Validation acc: 0.7389\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 444.6620, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 428.8441, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 20: 422.2842, Accuracy: 0.7176\n",
      "Training loss (for one batch) at step 30: 402.0063, Accuracy: 0.7341\n",
      "Training loss (for one batch) at step 40: 405.9575, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 50: 388.7225, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 60: 409.8296, Accuracy: 0.7787\n",
      "Training loss (for one batch) at step 70: 426.7726, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 80: 436.7698, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 90: 426.6978, Accuracy: 0.7539\n",
      "Training loss (for one batch) at step 100: 419.0079, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 110: 419.8005, Accuracy: 0.7513\n",
      "---- Training ----\n",
      "Training loss: 129.2260\n",
      "Training acc over epoch: 0.7526\n",
      "---- Validation ----\n",
      "Validation loss: 35.3952\n",
      "Validation acc: 0.7233\n",
      "Time taken: 12.48s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 424.6970, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 427.8130, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 423.0079, Accuracy: 0.7347\n",
      "Training loss (for one batch) at step 30: 411.1443, Accuracy: 0.7480\n",
      "Training loss (for one batch) at step 40: 396.6768, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 50: 371.0739, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 60: 396.8906, Accuracy: 0.7852\n",
      "Training loss (for one batch) at step 70: 438.8366, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 80: 430.0615, Accuracy: 0.7709\n",
      "Training loss (for one batch) at step 90: 416.4814, Accuracy: 0.7631\n",
      "Training loss (for one batch) at step 100: 404.4627, Accuracy: 0.7625\n",
      "Training loss (for one batch) at step 110: 422.3275, Accuracy: 0.7619\n",
      "---- Training ----\n",
      "Training loss: 128.5621\n",
      "Training acc over epoch: 0.7616\n",
      "---- Validation ----\n",
      "Validation loss: 36.3916\n",
      "Validation acc: 0.7222\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 450.8949, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 424.9047, Accuracy: 0.7017\n",
      "Training loss (for one batch) at step 20: 408.6933, Accuracy: 0.7206\n",
      "Training loss (for one batch) at step 30: 398.2390, Accuracy: 0.7397\n",
      "Training loss (for one batch) at step 40: 396.0688, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 50: 374.4660, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 60: 385.5092, Accuracy: 0.7804\n",
      "Training loss (for one batch) at step 70: 414.5964, Accuracy: 0.7735\n",
      "Training loss (for one batch) at step 80: 435.1409, Accuracy: 0.7637\n",
      "Training loss (for one batch) at step 90: 425.6286, Accuracy: 0.7605\n",
      "Training loss (for one batch) at step 100: 406.1413, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 110: 422.6123, Accuracy: 0.7593\n",
      "---- Training ----\n",
      "Training loss: 128.6322\n",
      "Training acc over epoch: 0.7596\n",
      "---- Validation ----\n",
      "Validation loss: 34.6314\n",
      "Validation acc: 0.7120\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 432.9309, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 431.2826, Accuracy: 0.6996\n",
      "Training loss (for one batch) at step 20: 422.0323, Accuracy: 0.7228\n",
      "Training loss (for one batch) at step 30: 404.8144, Accuracy: 0.7442\n",
      "Training loss (for one batch) at step 40: 368.6834, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 50: 377.8858, Accuracy: 0.7736\n",
      "Training loss (for one batch) at step 60: 391.9043, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 70: 420.7330, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 80: 425.7231, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 90: 415.7708, Accuracy: 0.7587\n",
      "Training loss (for one batch) at step 100: 409.4513, Accuracy: 0.7584\n",
      "Training loss (for one batch) at step 110: 413.6631, Accuracy: 0.7582\n",
      "---- Training ----\n",
      "Training loss: 130.8392\n",
      "Training acc over epoch: 0.7576\n",
      "---- Validation ----\n",
      "Validation loss: 37.6226\n",
      "Validation acc: 0.6988\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 434.6593, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 433.7639, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 20: 408.7945, Accuracy: 0.7236\n",
      "Training loss (for one batch) at step 30: 389.4851, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 40: 385.7718, Accuracy: 0.7590\n",
      "Training loss (for one batch) at step 50: 354.5004, Accuracy: 0.7730\n",
      "Training loss (for one batch) at step 60: 380.2007, Accuracy: 0.7804\n",
      "Training loss (for one batch) at step 70: 419.3866, Accuracy: 0.7721\n",
      "Training loss (for one batch) at step 80: 425.9493, Accuracy: 0.7606\n",
      "Training loss (for one batch) at step 90: 413.6655, Accuracy: 0.7540\n",
      "Training loss (for one batch) at step 100: 413.4439, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 110: 394.7772, Accuracy: 0.7572\n",
      "---- Training ----\n",
      "Training loss: 124.2206\n",
      "Training acc over epoch: 0.7569\n",
      "---- Validation ----\n",
      "Validation loss: 37.0507\n",
      "Validation acc: 0.7144\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 421.4325, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 421.1061, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 405.6200, Accuracy: 0.7292\n",
      "Training loss (for one batch) at step 30: 385.0853, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 40: 381.6465, Accuracy: 0.7681\n",
      "Training loss (for one batch) at step 50: 330.5272, Accuracy: 0.7854\n",
      "Training loss (for one batch) at step 60: 392.0948, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 70: 393.1548, Accuracy: 0.7860\n",
      "Training loss (for one batch) at step 80: 415.4726, Accuracy: 0.7732\n",
      "Training loss (for one batch) at step 90: 409.8342, Accuracy: 0.7637\n",
      "Training loss (for one batch) at step 100: 415.4911, Accuracy: 0.7625\n",
      "Training loss (for one batch) at step 110: 407.5167, Accuracy: 0.7623\n",
      "---- Training ----\n",
      "Training loss: 126.7534\n",
      "Training acc over epoch: 0.7606\n",
      "---- Validation ----\n",
      "Validation loss: 37.6959\n",
      "Validation acc: 0.6900\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 435.4278, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 413.9039, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 20: 396.5054, Accuracy: 0.7147\n",
      "Training loss (for one batch) at step 30: 379.6110, Accuracy: 0.7462\n",
      "Training loss (for one batch) at step 40: 352.5762, Accuracy: 0.7637\n",
      "Training loss (for one batch) at step 50: 345.2083, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 60: 376.1996, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 70: 432.2554, Accuracy: 0.7851\n",
      "Training loss (for one batch) at step 80: 412.8140, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 90: 401.0282, Accuracy: 0.7634\n",
      "Training loss (for one batch) at step 100: 403.9512, Accuracy: 0.7644\n",
      "Training loss (for one batch) at step 110: 395.2939, Accuracy: 0.7650\n",
      "---- Training ----\n",
      "Training loss: 123.5116\n",
      "Training acc over epoch: 0.7649\n",
      "---- Validation ----\n",
      "Validation loss: 35.2124\n",
      "Validation acc: 0.7104\n",
      "Time taken: 10.81s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 421.0517, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 407.0216, Accuracy: 0.6974\n",
      "Training loss (for one batch) at step 20: 394.8802, Accuracy: 0.7154\n",
      "Training loss (for one batch) at step 30: 377.8614, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 40: 356.7884, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 50: 337.9833, Accuracy: 0.7776\n",
      "Training loss (for one batch) at step 60: 376.2432, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 70: 428.4713, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 80: 422.0198, Accuracy: 0.7672\n",
      "Training loss (for one batch) at step 90: 398.6725, Accuracy: 0.7577\n",
      "Training loss (for one batch) at step 100: 386.0092, Accuracy: 0.7581\n",
      "Training loss (for one batch) at step 110: 402.9911, Accuracy: 0.7601\n",
      "---- Training ----\n",
      "Training loss: 117.3408\n",
      "Training acc over epoch: 0.7600\n",
      "---- Validation ----\n",
      "Validation loss: 35.6652\n",
      "Validation acc: 0.7010\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 421.4706, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 404.4580, Accuracy: 0.6967\n",
      "Training loss (for one batch) at step 20: 386.0846, Accuracy: 0.7128\n",
      "Training loss (for one batch) at step 30: 367.6071, Accuracy: 0.7414\n",
      "Training loss (for one batch) at step 40: 356.1255, Accuracy: 0.7679\n",
      "Training loss (for one batch) at step 50: 339.3050, Accuracy: 0.7829\n",
      "Training loss (for one batch) at step 60: 377.3601, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 70: 418.5160, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 80: 407.7260, Accuracy: 0.7687\n",
      "Training loss (for one batch) at step 90: 403.4888, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 100: 387.1969, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 110: 383.7628, Accuracy: 0.7648\n",
      "---- Training ----\n",
      "Training loss: 118.0886\n",
      "Training acc over epoch: 0.7641\n",
      "---- Validation ----\n",
      "Validation loss: 38.2452\n",
      "Validation acc: 0.6924\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 442.2121, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 418.7305, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 379.2147, Accuracy: 0.6901\n",
      "Training loss (for one batch) at step 30: 367.9292, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 40: 359.8366, Accuracy: 0.7513\n",
      "Training loss (for one batch) at step 50: 335.4044, Accuracy: 0.7739\n",
      "Training loss (for one batch) at step 60: 371.8765, Accuracy: 0.7845\n",
      "Training loss (for one batch) at step 70: 396.4037, Accuracy: 0.7765\n",
      "Training loss (for one batch) at step 80: 403.4608, Accuracy: 0.7587\n",
      "Training loss (for one batch) at step 90: 391.9605, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 100: 385.5780, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 110: 411.1453, Accuracy: 0.7566\n",
      "---- Training ----\n",
      "Training loss: 127.2209\n",
      "Training acc over epoch: 0.7565\n",
      "---- Validation ----\n",
      "Validation loss: 42.6976\n",
      "Validation acc: 0.6916\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 408.6646, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 402.5239, Accuracy: 0.6754\n",
      "Training loss (for one batch) at step 20: 383.5590, Accuracy: 0.6987\n",
      "Training loss (for one batch) at step 30: 367.9956, Accuracy: 0.7303\n",
      "Training loss (for one batch) at step 40: 344.1020, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 50: 328.2573, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 60: 362.2624, Accuracy: 0.7846\n",
      "Training loss (for one batch) at step 70: 409.2598, Accuracy: 0.7733\n",
      "Training loss (for one batch) at step 80: 397.8857, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 90: 380.5891, Accuracy: 0.7531\n",
      "Training loss (for one batch) at step 100: 374.9587, Accuracy: 0.7561\n",
      "Training loss (for one batch) at step 110: 399.9112, Accuracy: 0.7562\n",
      "---- Training ----\n",
      "Training loss: 123.4431\n",
      "Training acc over epoch: 0.7556\n",
      "---- Validation ----\n",
      "Validation loss: 31.9275\n",
      "Validation acc: 0.6967\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 430.1028, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 402.6400, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 370.7599, Accuracy: 0.7054\n",
      "Training loss (for one batch) at step 30: 374.7894, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 40: 340.9510, Accuracy: 0.7576\n",
      "Training loss (for one batch) at step 50: 347.6147, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 60: 365.8521, Accuracy: 0.7819\n",
      "Training loss (for one batch) at step 70: 398.4968, Accuracy: 0.7702\n",
      "Training loss (for one batch) at step 80: 415.5237, Accuracy: 0.7569\n",
      "Training loss (for one batch) at step 90: 388.1129, Accuracy: 0.7519\n",
      "Training loss (for one batch) at step 100: 380.4465, Accuracy: 0.7556\n",
      "Training loss (for one batch) at step 110: 385.4543, Accuracy: 0.7565\n",
      "---- Training ----\n",
      "Training loss: 121.6647\n",
      "Training acc over epoch: 0.7552\n",
      "---- Validation ----\n",
      "Validation loss: 37.7167\n",
      "Validation acc: 0.6768\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 408.7659, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 393.6280, Accuracy: 0.6513\n",
      "Training loss (for one batch) at step 20: 364.3802, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 350.4586, Accuracy: 0.7303\n",
      "Training loss (for one batch) at step 40: 361.1980, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 50: 326.5090, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 60: 340.8203, Accuracy: 0.7795\n",
      "Training loss (for one batch) at step 70: 374.0480, Accuracy: 0.7675\n",
      "Training loss (for one batch) at step 80: 403.4821, Accuracy: 0.7531\n",
      "Training loss (for one batch) at step 90: 372.8173, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 100: 378.6438, Accuracy: 0.7510\n",
      "Training loss (for one batch) at step 110: 369.8847, Accuracy: 0.7527\n",
      "---- Training ----\n",
      "Training loss: 124.1279\n",
      "Training acc over epoch: 0.7522\n",
      "---- Validation ----\n",
      "Validation loss: 34.7833\n",
      "Validation acc: 0.6752\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 411.2904, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 378.9567, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 20: 374.7490, Accuracy: 0.6823\n",
      "Training loss (for one batch) at step 30: 357.1276, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 40: 326.4115, Accuracy: 0.7477\n",
      "Training loss (for one batch) at step 50: 326.3334, Accuracy: 0.7702\n",
      "Training loss (for one batch) at step 60: 332.6859, Accuracy: 0.7807\n",
      "Training loss (for one batch) at step 70: 380.5154, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 80: 407.6127, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 90: 359.4963, Accuracy: 0.7495\n",
      "Training loss (for one batch) at step 100: 358.4946, Accuracy: 0.7547\n",
      "Training loss (for one batch) at step 110: 390.5162, Accuracy: 0.7566\n",
      "---- Training ----\n",
      "Training loss: 123.2138\n",
      "Training acc over epoch: 0.7552\n",
      "---- Validation ----\n",
      "Validation loss: 46.8792\n",
      "Validation acc: 0.6752\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 396.7055, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 379.4595, Accuracy: 0.6357\n",
      "Training loss (for one batch) at step 20: 368.7375, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 30: 347.4949, Accuracy: 0.7185\n",
      "Training loss (for one batch) at step 40: 329.1168, Accuracy: 0.7437\n",
      "Training loss (for one batch) at step 50: 359.6593, Accuracy: 0.7636\n",
      "Training loss (for one batch) at step 60: 342.6989, Accuracy: 0.7733\n",
      "Training loss (for one batch) at step 70: 368.6599, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 80: 373.8074, Accuracy: 0.7476\n",
      "Training loss (for one batch) at step 90: 362.6635, Accuracy: 0.7438\n",
      "Training loss (for one batch) at step 100: 357.2402, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 110: 374.9886, Accuracy: 0.7506\n",
      "---- Training ----\n",
      "Training loss: 113.8497\n",
      "Training acc over epoch: 0.7498\n",
      "---- Validation ----\n",
      "Validation loss: 35.8052\n",
      "Validation acc: 0.6862\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 419.9877, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 408.3164, Accuracy: 0.6442\n",
      "Training loss (for one batch) at step 20: 352.3538, Accuracy: 0.6834\n",
      "Training loss (for one batch) at step 30: 331.6057, Accuracy: 0.7248\n",
      "Training loss (for one batch) at step 40: 334.6322, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 50: 331.1236, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 60: 344.0249, Accuracy: 0.7787\n",
      "Training loss (for one batch) at step 70: 374.3836, Accuracy: 0.7698\n",
      "Training loss (for one batch) at step 80: 366.5320, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 90: 369.2837, Accuracy: 0.7496\n",
      "Training loss (for one batch) at step 100: 358.4213, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 110: 360.7039, Accuracy: 0.7546\n",
      "---- Training ----\n",
      "Training loss: 124.7181\n",
      "Training acc over epoch: 0.7533\n",
      "---- Validation ----\n",
      "Validation loss: 43.6430\n",
      "Validation acc: 0.6897\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 386.2110, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 407.7549, Accuracy: 0.6470\n",
      "Training loss (for one batch) at step 20: 331.0865, Accuracy: 0.6830\n",
      "Training loss (for one batch) at step 30: 336.6095, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 40: 344.3409, Accuracy: 0.7473\n",
      "Training loss (for one batch) at step 50: 315.2088, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 60: 327.8675, Accuracy: 0.7770\n",
      "Training loss (for one batch) at step 70: 370.6626, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 80: 386.5026, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 90: 356.5583, Accuracy: 0.7488\n",
      "Training loss (for one batch) at step 100: 352.3389, Accuracy: 0.7520\n",
      "Training loss (for one batch) at step 110: 367.3239, Accuracy: 0.7539\n",
      "---- Training ----\n",
      "Training loss: 115.8564\n",
      "Training acc over epoch: 0.7523\n",
      "---- Validation ----\n",
      "Validation loss: 43.0161\n",
      "Validation acc: 0.6771\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 393.6700, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 373.1480, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 20: 345.0873, Accuracy: 0.6819\n",
      "Training loss (for one batch) at step 30: 342.8749, Accuracy: 0.7271\n",
      "Training loss (for one batch) at step 40: 329.3104, Accuracy: 0.7555\n",
      "Training loss (for one batch) at step 50: 319.4566, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 60: 326.9270, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 70: 366.9055, Accuracy: 0.7651\n",
      "Training loss (for one batch) at step 80: 384.7185, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 90: 362.6730, Accuracy: 0.7446\n",
      "Training loss (for one batch) at step 100: 340.0013, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 110: 369.5152, Accuracy: 0.7530\n",
      "---- Training ----\n",
      "Training loss: 114.9804\n",
      "Training acc over epoch: 0.7505\n",
      "---- Validation ----\n",
      "Validation loss: 45.4406\n",
      "Validation acc: 0.6757\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 386.5802, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 366.5732, Accuracy: 0.6555\n",
      "Training loss (for one batch) at step 20: 332.3712, Accuracy: 0.6830\n",
      "Training loss (for one batch) at step 30: 315.4349, Accuracy: 0.7198\n",
      "Training loss (for one batch) at step 40: 322.4626, Accuracy: 0.7468\n",
      "Training loss (for one batch) at step 50: 309.1070, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 60: 322.3687, Accuracy: 0.7756\n",
      "Training loss (for one batch) at step 70: 359.7528, Accuracy: 0.7638\n",
      "Training loss (for one batch) at step 80: 360.8471, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 90: 344.1809, Accuracy: 0.7426\n",
      "Training loss (for one batch) at step 100: 372.8177, Accuracy: 0.7477\n",
      "Training loss (for one batch) at step 110: 376.6520, Accuracy: 0.7486\n",
      "---- Training ----\n",
      "Training loss: 118.3694\n",
      "Training acc over epoch: 0.7485\n",
      "---- Validation ----\n",
      "Validation loss: 45.0703\n",
      "Validation acc: 0.6762\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 377.8166, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 362.9738, Accuracy: 0.6342\n",
      "Training loss (for one batch) at step 20: 365.7786, Accuracy: 0.6786\n",
      "Training loss (for one batch) at step 30: 340.3127, Accuracy: 0.7225\n",
      "Training loss (for one batch) at step 40: 305.0730, Accuracy: 0.7494\n",
      "Training loss (for one batch) at step 50: 311.5225, Accuracy: 0.7707\n",
      "Training loss (for one batch) at step 60: 318.3856, Accuracy: 0.7819\n",
      "Training loss (for one batch) at step 70: 359.7926, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 80: 383.9117, Accuracy: 0.7506\n",
      "Training loss (for one batch) at step 90: 359.3991, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 100: 326.3626, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 110: 345.6475, Accuracy: 0.7512\n",
      "---- Training ----\n",
      "Training loss: 116.6646\n",
      "Training acc over epoch: 0.7495\n",
      "---- Validation ----\n",
      "Validation loss: 47.2605\n",
      "Validation acc: 0.6752\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 387.1320, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 375.9289, Accuracy: 0.6342\n",
      "Training loss (for one batch) at step 20: 340.3629, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 30: 329.4391, Accuracy: 0.7132\n",
      "Training loss (for one batch) at step 40: 316.6678, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 50: 300.9329, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 60: 315.8975, Accuracy: 0.7765\n",
      "Training loss (for one batch) at step 70: 352.8746, Accuracy: 0.7624\n",
      "Training loss (for one batch) at step 80: 370.9690, Accuracy: 0.7471\n",
      "Training loss (for one batch) at step 90: 349.6889, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 100: 326.7939, Accuracy: 0.7495\n",
      "Training loss (for one batch) at step 110: 352.3219, Accuracy: 0.7513\n",
      "---- Training ----\n",
      "Training loss: 109.5956\n",
      "Training acc over epoch: 0.7497\n",
      "---- Validation ----\n",
      "Validation loss: 50.9963\n",
      "Validation acc: 0.6658\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 394.6021, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 394.1048, Accuracy: 0.6278\n",
      "Training loss (for one batch) at step 20: 339.1411, Accuracy: 0.6756\n",
      "Training loss (for one batch) at step 30: 331.3849, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 40: 337.8116, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 50: 283.3171, Accuracy: 0.7676\n",
      "Training loss (for one batch) at step 60: 346.2593, Accuracy: 0.7752\n",
      "Training loss (for one batch) at step 70: 355.5461, Accuracy: 0.7651\n",
      "Training loss (for one batch) at step 80: 366.5927, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 90: 338.5510, Accuracy: 0.7430\n",
      "Training loss (for one batch) at step 100: 339.7446, Accuracy: 0.7459\n",
      "Training loss (for one batch) at step 110: 351.0985, Accuracy: 0.7475\n",
      "---- Training ----\n",
      "Training loss: 101.5575\n",
      "Training acc over epoch: 0.7461\n",
      "---- Validation ----\n",
      "Validation loss: 58.8097\n",
      "Validation acc: 0.6773\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 382.6988, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 369.5655, Accuracy: 0.6378\n",
      "Training loss (for one batch) at step 20: 318.4180, Accuracy: 0.6722\n",
      "Training loss (for one batch) at step 30: 316.0448, Accuracy: 0.7145\n",
      "Training loss (for one batch) at step 40: 315.5963, Accuracy: 0.7494\n",
      "Training loss (for one batch) at step 50: 293.5105, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 60: 332.9857, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 70: 343.1050, Accuracy: 0.7655\n",
      "Training loss (for one batch) at step 80: 370.5005, Accuracy: 0.7461\n",
      "Training loss (for one batch) at step 90: 314.2403, Accuracy: 0.7421\n",
      "Training loss (for one batch) at step 100: 330.5533, Accuracy: 0.7461\n",
      "Training loss (for one batch) at step 110: 357.6652, Accuracy: 0.7481\n",
      "---- Training ----\n",
      "Training loss: 102.5338\n",
      "Training acc over epoch: 0.7481\n",
      "---- Validation ----\n",
      "Validation loss: 55.4427\n",
      "Validation acc: 0.6668\n",
      "Time taken: 10.55s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6795\n",
      "Validation AUC: 0.6786\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 650.3488, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 612.3619, Accuracy: 0.5178\n",
      "Training loss (for one batch) at step 20: 537.9216, Accuracy: 0.5004\n",
      "Training loss (for one batch) at step 30: 524.0143, Accuracy: 0.5040\n",
      "Training loss (for one batch) at step 40: 530.3773, Accuracy: 0.5050\n",
      "Training loss (for one batch) at step 50: 487.2259, Accuracy: 0.5061\n",
      "Training loss (for one batch) at step 60: 487.5928, Accuracy: 0.5044\n",
      "Training loss (for one batch) at step 70: 494.3624, Accuracy: 0.5041\n",
      "Training loss (for one batch) at step 80: 464.5866, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 90: 472.6304, Accuracy: 0.5075\n",
      "Training loss (for one batch) at step 100: 477.0949, Accuracy: 0.5097\n",
      "Training loss (for one batch) at step 110: 459.3673, Accuracy: 0.5105\n",
      "---- Training ----\n",
      "Training loss: 150.6078\n",
      "Training acc over epoch: 0.5095\n",
      "---- Validation ----\n",
      "Validation loss: 34.0810\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.14s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 452.3332, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 461.3416, Accuracy: 0.5163\n",
      "Training loss (for one batch) at step 20: 456.2613, Accuracy: 0.5104\n",
      "Training loss (for one batch) at step 30: 445.8677, Accuracy: 0.5154\n",
      "Training loss (for one batch) at step 40: 448.3412, Accuracy: 0.5240\n",
      "Training loss (for one batch) at step 50: 447.5236, Accuracy: 0.5276\n",
      "Training loss (for one batch) at step 60: 452.1848, Accuracy: 0.5298\n",
      "Training loss (for one batch) at step 70: 451.2856, Accuracy: 0.5278\n",
      "Training loss (for one batch) at step 80: 448.3128, Accuracy: 0.5284\n",
      "Training loss (for one batch) at step 90: 447.4314, Accuracy: 0.5277\n",
      "Training loss (for one batch) at step 100: 448.1790, Accuracy: 0.5278\n",
      "Training loss (for one batch) at step 110: 448.9627, Accuracy: 0.5273\n",
      "---- Training ----\n",
      "Training loss: 139.2128\n",
      "Training acc over epoch: 0.5252\n",
      "---- Validation ----\n",
      "Validation loss: 34.8401\n",
      "Validation acc: 0.5263\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.8015, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 449.2863, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 20: 444.2512, Accuracy: 0.5316\n",
      "Training loss (for one batch) at step 30: 443.3244, Accuracy: 0.5373\n",
      "Training loss (for one batch) at step 40: 447.1995, Accuracy: 0.5364\n",
      "Training loss (for one batch) at step 50: 446.3931, Accuracy: 0.5388\n",
      "Training loss (for one batch) at step 60: 443.4076, Accuracy: 0.5397\n",
      "Training loss (for one batch) at step 70: 449.4878, Accuracy: 0.5426\n",
      "Training loss (for one batch) at step 80: 443.8954, Accuracy: 0.5409\n",
      "Training loss (for one batch) at step 90: 447.7523, Accuracy: 0.5445\n",
      "Training loss (for one batch) at step 100: 444.6946, Accuracy: 0.5454\n",
      "Training loss (for one batch) at step 110: 446.1913, Accuracy: 0.5462\n",
      "---- Training ----\n",
      "Training loss: 142.9175\n",
      "Training acc over epoch: 0.5453\n",
      "---- Validation ----\n",
      "Validation loss: 34.6481\n",
      "Validation acc: 0.5309\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.1850, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 446.1153, Accuracy: 0.5433\n",
      "Training loss (for one batch) at step 20: 444.6243, Accuracy: 0.5539\n",
      "Training loss (for one batch) at step 30: 443.9352, Accuracy: 0.5635\n",
      "Training loss (for one batch) at step 40: 445.2505, Accuracy: 0.5675\n",
      "Training loss (for one batch) at step 50: 443.9607, Accuracy: 0.5660\n",
      "Training loss (for one batch) at step 60: 446.9766, Accuracy: 0.5706\n",
      "Training loss (for one batch) at step 70: 442.3096, Accuracy: 0.5693\n",
      "Training loss (for one batch) at step 80: 445.2220, Accuracy: 0.5704\n",
      "Training loss (for one batch) at step 90: 444.8340, Accuracy: 0.5675\n",
      "Training loss (for one batch) at step 100: 443.7996, Accuracy: 0.5654\n",
      "Training loss (for one batch) at step 110: 441.9691, Accuracy: 0.5659\n",
      "---- Training ----\n",
      "Training loss: 137.8559\n",
      "Training acc over epoch: 0.5659\n",
      "---- Validation ----\n",
      "Validation loss: 35.0900\n",
      "Validation acc: 0.5725\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 443.4966, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 441.7469, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 20: 443.2084, Accuracy: 0.5592\n",
      "Training loss (for one batch) at step 30: 440.8393, Accuracy: 0.5600\n",
      "Training loss (for one batch) at step 40: 441.9457, Accuracy: 0.5675\n",
      "Training loss (for one batch) at step 50: 444.2289, Accuracy: 0.5754\n",
      "Training loss (for one batch) at step 60: 441.2904, Accuracy: 0.5809\n",
      "Training loss (for one batch) at step 70: 443.1433, Accuracy: 0.5826\n",
      "Training loss (for one batch) at step 80: 441.7833, Accuracy: 0.5825\n",
      "Training loss (for one batch) at step 90: 438.4849, Accuracy: 0.5811\n",
      "Training loss (for one batch) at step 100: 441.8455, Accuracy: 0.5780\n",
      "Training loss (for one batch) at step 110: 444.4243, Accuracy: 0.5772\n",
      "---- Training ----\n",
      "Training loss: 138.1776\n",
      "Training acc over epoch: 0.5776\n",
      "---- Validation ----\n",
      "Validation loss: 34.7927\n",
      "Validation acc: 0.6123\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.0355, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 442.3972, Accuracy: 0.5888\n",
      "Training loss (for one batch) at step 20: 442.5413, Accuracy: 0.5844\n",
      "Training loss (for one batch) at step 30: 437.5009, Accuracy: 0.5975\n",
      "Training loss (for one batch) at step 40: 439.6602, Accuracy: 0.5964\n",
      "Training loss (for one batch) at step 50: 442.0449, Accuracy: 0.6051\n",
      "Training loss (for one batch) at step 60: 445.7794, Accuracy: 0.6068\n",
      "Training loss (for one batch) at step 70: 442.4973, Accuracy: 0.6049\n",
      "Training loss (for one batch) at step 80: 443.4415, Accuracy: 0.6030\n",
      "Training loss (for one batch) at step 90: 442.8897, Accuracy: 0.6017\n",
      "Training loss (for one batch) at step 100: 440.1481, Accuracy: 0.6019\n",
      "Training loss (for one batch) at step 110: 442.9357, Accuracy: 0.6019\n",
      "---- Training ----\n",
      "Training loss: 138.2303\n",
      "Training acc over epoch: 0.6010\n",
      "---- Validation ----\n",
      "Validation loss: 34.6482\n",
      "Validation acc: 0.6123\n",
      "Time taken: 10.87s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 442.7155, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 440.0901, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 20: 440.5071, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 30: 438.5857, Accuracy: 0.6253\n",
      "Training loss (for one batch) at step 40: 441.0960, Accuracy: 0.6258\n",
      "Training loss (for one batch) at step 50: 440.7181, Accuracy: 0.6343\n",
      "Training loss (for one batch) at step 60: 443.7649, Accuracy: 0.6364\n",
      "Training loss (for one batch) at step 70: 445.9387, Accuracy: 0.6378\n",
      "Training loss (for one batch) at step 80: 443.9460, Accuracy: 0.6346\n",
      "Training loss (for one batch) at step 90: 442.2288, Accuracy: 0.6335\n",
      "Training loss (for one batch) at step 100: 439.8789, Accuracy: 0.6312\n",
      "Training loss (for one batch) at step 110: 442.7272, Accuracy: 0.6325\n",
      "---- Training ----\n",
      "Training loss: 138.3748\n",
      "Training acc over epoch: 0.6325\n",
      "---- Validation ----\n",
      "Validation loss: 34.7948\n",
      "Validation acc: 0.6459\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 446.3894, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 442.7171, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 437.7934, Accuracy: 0.6310\n",
      "Training loss (for one batch) at step 30: 437.0053, Accuracy: 0.6429\n",
      "Training loss (for one batch) at step 40: 434.8835, Accuracy: 0.6482\n",
      "Training loss (for one batch) at step 50: 432.6404, Accuracy: 0.6535\n",
      "Training loss (for one batch) at step 60: 443.7893, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 70: 443.5884, Accuracy: 0.6545\n",
      "Training loss (for one batch) at step 80: 436.3523, Accuracy: 0.6531\n",
      "Training loss (for one batch) at step 90: 440.3760, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 100: 438.1214, Accuracy: 0.6504\n",
      "Training loss (for one batch) at step 110: 442.7164, Accuracy: 0.6516\n",
      "---- Training ----\n",
      "Training loss: 137.7968\n",
      "Training acc over epoch: 0.6535\n",
      "---- Validation ----\n",
      "Validation loss: 33.6359\n",
      "Validation acc: 0.6814\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 444.3773, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 439.6638, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 20: 442.7258, Accuracy: 0.6510\n",
      "Training loss (for one batch) at step 30: 436.0595, Accuracy: 0.6620\n",
      "Training loss (for one batch) at step 40: 434.8260, Accuracy: 0.6627\n",
      "Training loss (for one batch) at step 50: 425.9868, Accuracy: 0.6700\n",
      "Training loss (for one batch) at step 60: 439.8526, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 70: 442.5954, Accuracy: 0.6741\n",
      "Training loss (for one batch) at step 80: 435.6798, Accuracy: 0.6718\n",
      "Training loss (for one batch) at step 90: 436.6250, Accuracy: 0.6692\n",
      "Training loss (for one batch) at step 100: 435.4663, Accuracy: 0.6717\n",
      "Training loss (for one batch) at step 110: 442.3970, Accuracy: 0.6731\n",
      "---- Training ----\n",
      "Training loss: 138.4961\n",
      "Training acc over epoch: 0.6745\n",
      "---- Validation ----\n",
      "Validation loss: 34.1814\n",
      "Validation acc: 0.6405\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 444.6245, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 441.0177, Accuracy: 0.6918\n",
      "Training loss (for one batch) at step 20: 440.1242, Accuracy: 0.6860\n",
      "Training loss (for one batch) at step 30: 439.7518, Accuracy: 0.6880\n",
      "Training loss (for one batch) at step 40: 437.0141, Accuracy: 0.6877\n",
      "Training loss (for one batch) at step 50: 430.6158, Accuracy: 0.6959\n",
      "Training loss (for one batch) at step 60: 425.3625, Accuracy: 0.7008\n",
      "Training loss (for one batch) at step 70: 442.8912, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 80: 441.0479, Accuracy: 0.6971\n",
      "Training loss (for one batch) at step 90: 439.4999, Accuracy: 0.6933\n",
      "Training loss (for one batch) at step 100: 437.4998, Accuracy: 0.6917\n",
      "Training loss (for one batch) at step 110: 440.6904, Accuracy: 0.6971\n",
      "---- Training ----\n",
      "Training loss: 137.0447\n",
      "Training acc over epoch: 0.6969\n",
      "---- Validation ----\n",
      "Validation loss: 34.2335\n",
      "Validation acc: 0.6754\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 438.8949, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 440.1456, Accuracy: 0.7045\n",
      "Training loss (for one batch) at step 20: 434.2189, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 30: 432.9843, Accuracy: 0.7059\n",
      "Training loss (for one batch) at step 40: 431.8635, Accuracy: 0.7087\n",
      "Training loss (for one batch) at step 50: 422.8077, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 60: 433.6471, Accuracy: 0.7158\n",
      "Training loss (for one batch) at step 70: 435.1265, Accuracy: 0.7190\n",
      "Training loss (for one batch) at step 80: 433.1410, Accuracy: 0.7136\n",
      "Training loss (for one batch) at step 90: 435.9981, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 100: 431.2325, Accuracy: 0.7085\n",
      "Training loss (for one batch) at step 110: 433.3536, Accuracy: 0.7113\n",
      "---- Training ----\n",
      "Training loss: 133.6612\n",
      "Training acc over epoch: 0.7118\n",
      "---- Validation ----\n",
      "Validation loss: 35.6229\n",
      "Validation acc: 0.7203\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 439.4163, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 443.6522, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 20: 434.7712, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 30: 424.0363, Accuracy: 0.7180\n",
      "Training loss (for one batch) at step 40: 427.6982, Accuracy: 0.7176\n",
      "Training loss (for one batch) at step 50: 417.0491, Accuracy: 0.7267\n",
      "Training loss (for one batch) at step 60: 425.9784, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 70: 441.2962, Accuracy: 0.7320\n",
      "Training loss (for one batch) at step 80: 433.9523, Accuracy: 0.7239\n",
      "Training loss (for one batch) at step 90: 438.5170, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 100: 433.9894, Accuracy: 0.7143\n",
      "Training loss (for one batch) at step 110: 437.6260, Accuracy: 0.7145\n",
      "---- Training ----\n",
      "Training loss: 134.5906\n",
      "Training acc over epoch: 0.7146\n",
      "---- Validation ----\n",
      "Validation loss: 35.2121\n",
      "Validation acc: 0.6910\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 447.2536, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 435.2253, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 20: 438.1934, Accuracy: 0.7128\n",
      "Training loss (for one batch) at step 30: 427.4667, Accuracy: 0.7122\n",
      "Training loss (for one batch) at step 40: 424.5458, Accuracy: 0.7212\n",
      "Training loss (for one batch) at step 50: 416.9315, Accuracy: 0.7312\n",
      "Training loss (for one batch) at step 60: 422.5329, Accuracy: 0.7376\n",
      "Training loss (for one batch) at step 70: 441.5356, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 80: 440.0040, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 90: 437.3692, Accuracy: 0.7310\n",
      "Training loss (for one batch) at step 100: 428.0630, Accuracy: 0.7302\n",
      "Training loss (for one batch) at step 110: 431.5143, Accuracy: 0.7309\n",
      "---- Training ----\n",
      "Training loss: 135.7294\n",
      "Training acc over epoch: 0.7323\n",
      "---- Validation ----\n",
      "Validation loss: 33.8549\n",
      "Validation acc: 0.7114\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 434.2933, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 436.2251, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 20: 424.7928, Accuracy: 0.7228\n",
      "Training loss (for one batch) at step 30: 424.6127, Accuracy: 0.7316\n",
      "Training loss (for one batch) at step 40: 425.3478, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 50: 410.5061, Accuracy: 0.7483\n",
      "Training loss (for one batch) at step 60: 427.8550, Accuracy: 0.7520\n",
      "Training loss (for one batch) at step 70: 435.5373, Accuracy: 0.7535\n",
      "Training loss (for one batch) at step 80: 434.9056, Accuracy: 0.7470\n",
      "Training loss (for one batch) at step 90: 429.8526, Accuracy: 0.7448\n",
      "Training loss (for one batch) at step 100: 431.4977, Accuracy: 0.7463\n",
      "Training loss (for one batch) at step 110: 427.6201, Accuracy: 0.7470\n",
      "---- Training ----\n",
      "Training loss: 141.3521\n",
      "Training acc over epoch: 0.7469\n",
      "---- Validation ----\n",
      "Validation loss: 33.8921\n",
      "Validation acc: 0.7123\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 441.8301, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 434.0775, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 20: 431.4962, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 30: 430.2448, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 40: 419.6767, Accuracy: 0.7519\n",
      "Training loss (for one batch) at step 50: 421.1085, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 60: 422.7474, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 70: 434.7746, Accuracy: 0.7677\n",
      "Training loss (for one batch) at step 80: 434.2729, Accuracy: 0.7641\n",
      "Training loss (for one batch) at step 90: 425.6900, Accuracy: 0.7617\n",
      "Training loss (for one batch) at step 100: 425.5728, Accuracy: 0.7626\n",
      "Training loss (for one batch) at step 110: 442.5432, Accuracy: 0.7631\n",
      "---- Training ----\n",
      "Training loss: 132.6345\n",
      "Training acc over epoch: 0.7640\n",
      "---- Validation ----\n",
      "Validation loss: 36.2502\n",
      "Validation acc: 0.7367\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 452.9943, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 430.5409, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 20: 420.2148, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 30: 415.3108, Accuracy: 0.7571\n",
      "Training loss (for one batch) at step 40: 416.9926, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 50: 416.2302, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 60: 421.8362, Accuracy: 0.7750\n",
      "Training loss (for one batch) at step 70: 441.3632, Accuracy: 0.7774\n",
      "Training loss (for one batch) at step 80: 437.5228, Accuracy: 0.7673\n",
      "Training loss (for one batch) at step 90: 430.1184, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 100: 423.8273, Accuracy: 0.7627\n",
      "Training loss (for one batch) at step 110: 437.4412, Accuracy: 0.7629\n",
      "---- Training ----\n",
      "Training loss: 128.8112\n",
      "Training acc over epoch: 0.7632\n",
      "---- Validation ----\n",
      "Validation loss: 32.3013\n",
      "Validation acc: 0.7174\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 437.2573, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 436.8944, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 20: 426.9150, Accuracy: 0.7511\n",
      "Training loss (for one batch) at step 30: 417.6265, Accuracy: 0.7586\n",
      "Training loss (for one batch) at step 40: 401.0634, Accuracy: 0.7639\n",
      "Training loss (for one batch) at step 50: 396.8575, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 60: 421.8942, Accuracy: 0.7851\n",
      "Training loss (for one batch) at step 70: 428.9047, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 80: 427.8033, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 90: 430.3479, Accuracy: 0.7655\n",
      "Training loss (for one batch) at step 100: 429.7380, Accuracy: 0.7643\n",
      "Training loss (for one batch) at step 110: 438.9180, Accuracy: 0.7633\n",
      "---- Training ----\n",
      "Training loss: 135.5178\n",
      "Training acc over epoch: 0.7623\n",
      "---- Validation ----\n",
      "Validation loss: 34.8419\n",
      "Validation acc: 0.7192\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 440.9803, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 436.7473, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 20: 433.7931, Accuracy: 0.7470\n",
      "Training loss (for one batch) at step 30: 412.5130, Accuracy: 0.7631\n",
      "Training loss (for one batch) at step 40: 408.6725, Accuracy: 0.7748\n",
      "Training loss (for one batch) at step 50: 395.9678, Accuracy: 0.7851\n",
      "Training loss (for one batch) at step 60: 413.2595, Accuracy: 0.7929\n",
      "Training loss (for one batch) at step 70: 432.7561, Accuracy: 0.7896\n",
      "Training loss (for one batch) at step 80: 424.7903, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 90: 430.8931, Accuracy: 0.7713\n",
      "Training loss (for one batch) at step 100: 424.3600, Accuracy: 0.7718\n",
      "Training loss (for one batch) at step 110: 421.9834, Accuracy: 0.7724\n",
      "---- Training ----\n",
      "Training loss: 130.6399\n",
      "Training acc over epoch: 0.7730\n",
      "---- Validation ----\n",
      "Validation loss: 35.6701\n",
      "Validation acc: 0.7340\n",
      "Time taken: 10.75s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 441.3002, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 431.9034, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 422.6296, Accuracy: 0.7608\n",
      "Training loss (for one batch) at step 30: 409.7434, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 40: 398.5626, Accuracy: 0.7887\n",
      "Training loss (for one batch) at step 50: 398.3047, Accuracy: 0.7995\n",
      "Training loss (for one batch) at step 60: 414.8357, Accuracy: 0.8074\n",
      "Training loss (for one batch) at step 70: 423.9386, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 80: 438.3293, Accuracy: 0.7913\n",
      "Training loss (for one batch) at step 90: 428.4460, Accuracy: 0.7843\n",
      "Training loss (for one batch) at step 100: 412.3567, Accuracy: 0.7821\n",
      "Training loss (for one batch) at step 110: 418.4894, Accuracy: 0.7818\n",
      "---- Training ----\n",
      "Training loss: 135.3499\n",
      "Training acc over epoch: 0.7817\n",
      "---- Validation ----\n",
      "Validation loss: 35.1741\n",
      "Validation acc: 0.7327\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 441.5496, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 431.7376, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 420.8456, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 30: 403.2538, Accuracy: 0.7747\n",
      "Training loss (for one batch) at step 40: 399.7293, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 50: 373.7255, Accuracy: 0.7978\n",
      "Training loss (for one batch) at step 60: 397.8243, Accuracy: 0.8029\n",
      "Training loss (for one batch) at step 70: 435.1667, Accuracy: 0.7962\n",
      "Training loss (for one batch) at step 80: 438.5768, Accuracy: 0.7858\n",
      "Training loss (for one batch) at step 90: 428.8572, Accuracy: 0.7777\n",
      "Training loss (for one batch) at step 100: 418.0946, Accuracy: 0.7768\n",
      "Training loss (for one batch) at step 110: 412.9211, Accuracy: 0.7773\n",
      "---- Training ----\n",
      "Training loss: 140.0016\n",
      "Training acc over epoch: 0.7774\n",
      "---- Validation ----\n",
      "Validation loss: 34.2156\n",
      "Validation acc: 0.7550\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 439.8235, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 426.8321, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 20: 423.2555, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 30: 400.9012, Accuracy: 0.7641\n",
      "Training loss (for one batch) at step 40: 396.4893, Accuracy: 0.7780\n",
      "Training loss (for one batch) at step 50: 370.0548, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 60: 418.4195, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 70: 427.9132, Accuracy: 0.7980\n",
      "Training loss (for one batch) at step 80: 433.9503, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 90: 426.7508, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 100: 414.8471, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 110: 417.2444, Accuracy: 0.7827\n",
      "---- Training ----\n",
      "Training loss: 135.1091\n",
      "Training acc over epoch: 0.7832\n",
      "---- Validation ----\n",
      "Validation loss: 34.5028\n",
      "Validation acc: 0.7405\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 437.6016, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 431.3612, Accuracy: 0.7415\n",
      "Training loss (for one batch) at step 20: 415.2931, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 30: 398.8694, Accuracy: 0.7666\n",
      "Training loss (for one batch) at step 40: 387.4300, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 50: 365.1202, Accuracy: 0.7979\n",
      "Training loss (for one batch) at step 60: 400.3873, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 70: 428.3203, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 80: 431.9925, Accuracy: 0.7916\n",
      "Training loss (for one batch) at step 90: 425.1044, Accuracy: 0.7876\n",
      "Training loss (for one batch) at step 100: 404.6986, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 110: 419.5526, Accuracy: 0.7846\n",
      "---- Training ----\n",
      "Training loss: 129.7801\n",
      "Training acc over epoch: 0.7834\n",
      "---- Validation ----\n",
      "Validation loss: 39.9198\n",
      "Validation acc: 0.7582\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 436.9228, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 427.8903, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 20: 413.7533, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 30: 396.8622, Accuracy: 0.7757\n",
      "Training loss (for one batch) at step 40: 386.4576, Accuracy: 0.7946\n",
      "Training loss (for one batch) at step 50: 364.9724, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 60: 408.6046, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 70: 407.3907, Accuracy: 0.8136\n",
      "Training loss (for one batch) at step 80: 435.9260, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 90: 423.9799, Accuracy: 0.7949\n",
      "Training loss (for one batch) at step 100: 427.5441, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 110: 400.0823, Accuracy: 0.7887\n",
      "---- Training ----\n",
      "Training loss: 133.1355\n",
      "Training acc over epoch: 0.7879\n",
      "---- Validation ----\n",
      "Validation loss: 35.8497\n",
      "Validation acc: 0.7356\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 437.5206, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 422.6650, Accuracy: 0.7564\n",
      "Training loss (for one batch) at step 20: 419.0451, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 30: 396.5283, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 40: 371.9214, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 50: 361.8076, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 60: 383.9268, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 70: 418.3597, Accuracy: 0.8158\n",
      "Training loss (for one batch) at step 80: 426.3543, Accuracy: 0.8050\n",
      "Training loss (for one batch) at step 90: 419.0171, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 100: 409.1454, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 110: 418.5212, Accuracy: 0.7917\n",
      "---- Training ----\n",
      "Training loss: 141.0913\n",
      "Training acc over epoch: 0.7908\n",
      "---- Validation ----\n",
      "Validation loss: 38.6828\n",
      "Validation acc: 0.7410\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 447.1784, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 414.4323, Accuracy: 0.7642\n",
      "Training loss (for one batch) at step 20: 413.2526, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 30: 397.7505, Accuracy: 0.7855\n",
      "Training loss (for one batch) at step 40: 385.0328, Accuracy: 0.7963\n",
      "Training loss (for one batch) at step 50: 359.5264, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 60: 388.7818, Accuracy: 0.8192\n",
      "Training loss (for one batch) at step 70: 436.2536, Accuracy: 0.8155\n",
      "Training loss (for one batch) at step 80: 416.6158, Accuracy: 0.8038\n",
      "Training loss (for one batch) at step 90: 408.0490, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 100: 411.4401, Accuracy: 0.7922\n",
      "Training loss (for one batch) at step 110: 398.9246, Accuracy: 0.7919\n",
      "---- Training ----\n",
      "Training loss: 127.1364\n",
      "Training acc over epoch: 0.7905\n",
      "---- Validation ----\n",
      "Validation loss: 36.3255\n",
      "Validation acc: 0.7276\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 416.5136, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 423.2853, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 409.6011, Accuracy: 0.7563\n",
      "Training loss (for one batch) at step 30: 401.2822, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 40: 379.8186, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 50: 362.9381, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 60: 403.7099, Accuracy: 0.8231\n",
      "Training loss (for one batch) at step 70: 415.9865, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 80: 415.8323, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 90: 407.2762, Accuracy: 0.7988\n",
      "Training loss (for one batch) at step 100: 401.1068, Accuracy: 0.7972\n",
      "Training loss (for one batch) at step 110: 404.3593, Accuracy: 0.7979\n",
      "---- Training ----\n",
      "Training loss: 130.3400\n",
      "Training acc over epoch: 0.7963\n",
      "---- Validation ----\n",
      "Validation loss: 38.6284\n",
      "Validation acc: 0.7246\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 425.0969, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 426.9528, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 20: 402.4210, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 384.2692, Accuracy: 0.7855\n",
      "Training loss (for one batch) at step 40: 365.1859, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 50: 373.1552, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 60: 371.4739, Accuracy: 0.8193\n",
      "Training loss (for one batch) at step 70: 399.7301, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 80: 413.9871, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 90: 402.7326, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 100: 398.4323, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 110: 401.8911, Accuracy: 0.7925\n",
      "---- Training ----\n",
      "Training loss: 135.4791\n",
      "Training acc over epoch: 0.7924\n",
      "---- Validation ----\n",
      "Validation loss: 44.1823\n",
      "Validation acc: 0.7284\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 418.7491, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 410.9747, Accuracy: 0.7443\n",
      "Training loss (for one batch) at step 20: 390.1223, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 30: 375.5953, Accuracy: 0.7737\n",
      "Training loss (for one batch) at step 40: 359.2394, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 50: 343.0844, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 60: 404.5138, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 70: 406.9590, Accuracy: 0.8106\n",
      "Training loss (for one batch) at step 80: 420.3759, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 90: 403.3669, Accuracy: 0.7940\n",
      "Training loss (for one batch) at step 100: 385.9344, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 110: 408.0328, Accuracy: 0.7955\n",
      "---- Training ----\n",
      "Training loss: 127.1797\n",
      "Training acc over epoch: 0.7925\n",
      "---- Validation ----\n",
      "Validation loss: 35.6229\n",
      "Validation acc: 0.7147\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 435.7477, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 417.7975, Accuracy: 0.7372\n",
      "Training loss (for one batch) at step 20: 404.6571, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 30: 372.5514, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 40: 359.8996, Accuracy: 0.8014\n",
      "Training loss (for one batch) at step 50: 348.6260, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 60: 375.0722, Accuracy: 0.8218\n",
      "Training loss (for one batch) at step 70: 397.7756, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 80: 412.8216, Accuracy: 0.8048\n",
      "Training loss (for one batch) at step 90: 388.9650, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 100: 390.2291, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 110: 372.8077, Accuracy: 0.7995\n",
      "---- Training ----\n",
      "Training loss: 118.9076\n",
      "Training acc over epoch: 0.7998\n",
      "---- Validation ----\n",
      "Validation loss: 36.3988\n",
      "Validation acc: 0.7235\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 414.9107, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 413.9159, Accuracy: 0.7564\n",
      "Training loss (for one batch) at step 20: 397.5722, Accuracy: 0.7638\n",
      "Training loss (for one batch) at step 30: 372.1890, Accuracy: 0.7870\n",
      "Training loss (for one batch) at step 40: 348.0566, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 50: 331.3556, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 60: 395.1515, Accuracy: 0.8252\n",
      "Training loss (for one batch) at step 70: 417.3027, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 80: 404.0840, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 90: 400.6901, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 100: 398.1267, Accuracy: 0.8004\n",
      "Training loss (for one batch) at step 110: 386.2647, Accuracy: 0.8003\n",
      "---- Training ----\n",
      "Training loss: 133.2115\n",
      "Training acc over epoch: 0.7999\n",
      "---- Validation ----\n",
      "Validation loss: 36.1734\n",
      "Validation acc: 0.7123\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 414.3790, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 410.9064, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 383.7596, Accuracy: 0.7634\n",
      "Training loss (for one batch) at step 30: 368.0709, Accuracy: 0.7863\n",
      "Training loss (for one batch) at step 40: 361.6374, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 50: 328.9434, Accuracy: 0.8172\n",
      "Training loss (for one batch) at step 60: 354.8563, Accuracy: 0.8272\n",
      "Training loss (for one batch) at step 70: 404.3080, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 80: 399.2287, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 90: 378.2973, Accuracy: 0.8029\n",
      "Training loss (for one batch) at step 100: 365.6656, Accuracy: 0.8016\n",
      "Training loss (for one batch) at step 110: 379.4058, Accuracy: 0.8009\n",
      "---- Training ----\n",
      "Training loss: 114.4078\n",
      "Training acc over epoch: 0.8000\n",
      "---- Validation ----\n",
      "Validation loss: 37.2324\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 425.8208, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 403.6951, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 20: 375.6562, Accuracy: 0.7653\n",
      "Training loss (for one batch) at step 30: 371.9266, Accuracy: 0.7876\n",
      "Training loss (for one batch) at step 40: 362.3719, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 50: 350.6016, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 60: 360.9421, Accuracy: 0.8249\n",
      "Training loss (for one batch) at step 70: 392.8453, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 80: 405.8281, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 90: 388.7240, Accuracy: 0.7985\n",
      "Training loss (for one batch) at step 100: 375.3643, Accuracy: 0.7998\n",
      "Training loss (for one batch) at step 110: 374.2161, Accuracy: 0.8007\n",
      "---- Training ----\n",
      "Training loss: 115.8907\n",
      "Training acc over epoch: 0.7991\n",
      "---- Validation ----\n",
      "Validation loss: 40.5456\n",
      "Validation acc: 0.7071\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 413.8345, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 387.4944, Accuracy: 0.7372\n",
      "Training loss (for one batch) at step 20: 375.2318, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 30: 363.6872, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 40: 348.0218, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 50: 357.6276, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 60: 376.3907, Accuracy: 0.8244\n",
      "Training loss (for one batch) at step 70: 395.8024, Accuracy: 0.8156\n",
      "Training loss (for one batch) at step 80: 393.0357, Accuracy: 0.8027\n",
      "Training loss (for one batch) at step 90: 376.0513, Accuracy: 0.7956\n",
      "Training loss (for one batch) at step 100: 365.8615, Accuracy: 0.7968\n",
      "Training loss (for one batch) at step 110: 383.6572, Accuracy: 0.7978\n",
      "---- Training ----\n",
      "Training loss: 122.4237\n",
      "Training acc over epoch: 0.7965\n",
      "---- Validation ----\n",
      "Validation loss: 44.2421\n",
      "Validation acc: 0.7155\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 405.3786, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 392.7219, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 20: 372.1567, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 30: 344.8054, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 40: 350.0424, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 50: 340.6844, Accuracy: 0.8258\n",
      "Training loss (for one batch) at step 60: 387.0044, Accuracy: 0.8321\n",
      "Training loss (for one batch) at step 70: 390.0850, Accuracy: 0.8209\n",
      "Training loss (for one batch) at step 80: 405.5272, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 90: 374.0388, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 100: 352.2768, Accuracy: 0.8038\n",
      "Training loss (for one batch) at step 110: 378.7376, Accuracy: 0.8025\n",
      "---- Training ----\n",
      "Training loss: 112.8366\n",
      "Training acc over epoch: 0.8013\n",
      "---- Validation ----\n",
      "Validation loss: 41.1117\n",
      "Validation acc: 0.7077\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 409.4297, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 411.4802, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 20: 354.4948, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 30: 336.7211, Accuracy: 0.7830\n",
      "Training loss (for one batch) at step 40: 353.9619, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 50: 339.3836, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 60: 372.1050, Accuracy: 0.8242\n",
      "Training loss (for one batch) at step 70: 389.3025, Accuracy: 0.8123\n",
      "Training loss (for one batch) at step 80: 394.2216, Accuracy: 0.8016\n",
      "Training loss (for one batch) at step 90: 373.4020, Accuracy: 0.7970\n",
      "Training loss (for one batch) at step 100: 365.4587, Accuracy: 0.7987\n",
      "Training loss (for one batch) at step 110: 365.6243, Accuracy: 0.7988\n",
      "---- Training ----\n",
      "Training loss: 113.5968\n",
      "Training acc over epoch: 0.7980\n",
      "---- Validation ----\n",
      "Validation loss: 40.1064\n",
      "Validation acc: 0.7066\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 401.4587, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 388.8851, Accuracy: 0.7322\n",
      "Training loss (for one batch) at step 20: 370.1047, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 30: 350.0861, Accuracy: 0.7785\n",
      "Training loss (for one batch) at step 40: 331.3669, Accuracy: 0.7988\n",
      "Training loss (for one batch) at step 50: 327.6965, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 60: 358.4916, Accuracy: 0.8271\n",
      "Training loss (for one batch) at step 70: 386.7698, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 80: 379.8446, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 90: 364.9288, Accuracy: 0.7945\n",
      "Training loss (for one batch) at step 100: 352.1614, Accuracy: 0.7972\n",
      "Training loss (for one batch) at step 110: 353.2646, Accuracy: 0.7979\n",
      "---- Training ----\n",
      "Training loss: 128.7091\n",
      "Training acc over epoch: 0.7963\n",
      "---- Validation ----\n",
      "Validation loss: 52.0382\n",
      "Validation acc: 0.7058\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 410.8276, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 403.6877, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 20: 364.0850, Accuracy: 0.7526\n",
      "Training loss (for one batch) at step 30: 348.3442, Accuracy: 0.7850\n",
      "Training loss (for one batch) at step 40: 325.6550, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 50: 316.8404, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 60: 366.0500, Accuracy: 0.8284\n",
      "Training loss (for one batch) at step 70: 377.7839, Accuracy: 0.8173\n",
      "Training loss (for one batch) at step 80: 400.2290, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 90: 351.2344, Accuracy: 0.8031\n",
      "Training loss (for one batch) at step 100: 368.5762, Accuracy: 0.8052\n",
      "Training loss (for one batch) at step 110: 359.4856, Accuracy: 0.8026\n",
      "---- Training ----\n",
      "Training loss: 121.7356\n",
      "Training acc over epoch: 0.8022\n",
      "---- Validation ----\n",
      "Validation loss: 41.8808\n",
      "Validation acc: 0.7074\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 393.7845, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 395.8135, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 20: 357.6714, Accuracy: 0.7511\n",
      "Training loss (for one batch) at step 30: 352.2033, Accuracy: 0.7815\n",
      "Training loss (for one batch) at step 40: 311.8219, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 50: 313.2527, Accuracy: 0.8223\n",
      "Training loss (for one batch) at step 60: 349.7346, Accuracy: 0.8279\n",
      "Training loss (for one batch) at step 70: 368.6059, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 80: 393.2828, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 90: 351.0294, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 100: 361.1481, Accuracy: 0.8005\n",
      "Training loss (for one batch) at step 110: 373.1439, Accuracy: 0.8008\n",
      "---- Training ----\n",
      "Training loss: 115.9411\n",
      "Training acc over epoch: 0.7981\n",
      "---- Validation ----\n",
      "Validation loss: 41.4372\n",
      "Validation acc: 0.6959\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 396.1877, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 396.3203, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 20: 337.8923, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 30: 344.3663, Accuracy: 0.7833\n",
      "Training loss (for one batch) at step 40: 329.5484, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 50: 314.0395, Accuracy: 0.8223\n",
      "Training loss (for one batch) at step 60: 348.1422, Accuracy: 0.8279\n",
      "Training loss (for one batch) at step 70: 391.0961, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 80: 391.9098, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 90: 345.8177, Accuracy: 0.7982\n",
      "Training loss (for one batch) at step 100: 341.7019, Accuracy: 0.7998\n",
      "Training loss (for one batch) at step 110: 354.0118, Accuracy: 0.8007\n",
      "---- Training ----\n",
      "Training loss: 113.8133\n",
      "Training acc over epoch: 0.7994\n",
      "---- Validation ----\n",
      "Validation loss: 58.0600\n",
      "Validation acc: 0.6991\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 394.6247, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 371.8371, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 20: 373.1121, Accuracy: 0.7396\n",
      "Training loss (for one batch) at step 30: 333.7855, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 40: 317.9045, Accuracy: 0.7954\n",
      "Training loss (for one batch) at step 50: 316.7105, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 60: 367.7180, Accuracy: 0.8210\n",
      "Training loss (for one batch) at step 70: 385.5884, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 80: 387.3216, Accuracy: 0.7947\n",
      "Training loss (for one batch) at step 90: 364.2508, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 100: 337.5861, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 110: 368.5754, Accuracy: 0.7941\n",
      "---- Training ----\n",
      "Training loss: 113.4172\n",
      "Training acc over epoch: 0.7924\n",
      "---- Validation ----\n",
      "Validation loss: 49.7032\n",
      "Validation acc: 0.7114\n",
      "Time taken: 10.55s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7156\n",
      "Validation AUC: 0.7163\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 590.9806, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 612.6804, Accuracy: 0.4766\n",
      "Training loss (for one batch) at step 20: 536.7659, Accuracy: 0.5004\n",
      "Training loss (for one batch) at step 30: 529.4578, Accuracy: 0.4937\n",
      "Training loss (for one batch) at step 40: 512.0072, Accuracy: 0.5025\n",
      "Training loss (for one batch) at step 50: 497.3249, Accuracy: 0.5054\n",
      "Training loss (for one batch) at step 60: 516.9852, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 70: 513.7872, Accuracy: 0.5112\n",
      "Training loss (for one batch) at step 80: 475.9846, Accuracy: 0.5100\n",
      "Training loss (for one batch) at step 90: 483.3800, Accuracy: 0.5144\n",
      "Training loss (for one batch) at step 100: 474.0994, Accuracy: 0.5125\n",
      "Training loss (for one batch) at step 110: 469.3043, Accuracy: 0.5136\n",
      "---- Training ----\n",
      "Training loss: 148.2733\n",
      "Training acc over epoch: 0.5153\n",
      "---- Validation ----\n",
      "Validation loss: 34.1749\n",
      "Validation acc: 0.5134\n",
      "Time taken: 11.99s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 457.8422, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 467.3499, Accuracy: 0.5036\n",
      "Training loss (for one batch) at step 20: 456.8844, Accuracy: 0.5097\n",
      "Training loss (for one batch) at step 30: 459.5992, Accuracy: 0.5252\n",
      "Training loss (for one batch) at step 40: 459.8513, Accuracy: 0.5261\n",
      "Training loss (for one batch) at step 50: 459.9030, Accuracy: 0.5259\n",
      "Training loss (for one batch) at step 60: 455.1327, Accuracy: 0.5288\n",
      "Training loss (for one batch) at step 70: 449.0002, Accuracy: 0.5321\n",
      "Training loss (for one batch) at step 80: 452.8076, Accuracy: 0.5304\n",
      "Training loss (for one batch) at step 90: 447.6461, Accuracy: 0.5300\n",
      "Training loss (for one batch) at step 100: 454.9882, Accuracy: 0.5313\n",
      "Training loss (for one batch) at step 110: 447.5146, Accuracy: 0.5328\n",
      "---- Training ----\n",
      "Training loss: 139.0391\n",
      "Training acc over epoch: 0.5319\n",
      "---- Validation ----\n",
      "Validation loss: 34.9568\n",
      "Validation acc: 0.5116\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 448.5587, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 444.8167, Accuracy: 0.5263\n",
      "Training loss (for one batch) at step 20: 445.1352, Accuracy: 0.5238\n",
      "Training loss (for one batch) at step 30: 445.8220, Accuracy: 0.5297\n",
      "Training loss (for one batch) at step 40: 449.5708, Accuracy: 0.5349\n",
      "Training loss (for one batch) at step 50: 449.9367, Accuracy: 0.5386\n",
      "Training loss (for one batch) at step 60: 445.8608, Accuracy: 0.5450\n",
      "Training loss (for one batch) at step 70: 448.8903, Accuracy: 0.5451\n",
      "Training loss (for one batch) at step 80: 447.2278, Accuracy: 0.5432\n",
      "Training loss (for one batch) at step 90: 444.4756, Accuracy: 0.5452\n",
      "Training loss (for one batch) at step 100: 444.2178, Accuracy: 0.5456\n",
      "Training loss (for one batch) at step 110: 442.4128, Accuracy: 0.5461\n",
      "---- Training ----\n",
      "Training loss: 139.7403\n",
      "Training acc over epoch: 0.5461\n",
      "---- Validation ----\n",
      "Validation loss: 34.6764\n",
      "Validation acc: 0.5390\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.1165, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 445.5357, Accuracy: 0.5440\n",
      "Training loss (for one batch) at step 20: 447.3430, Accuracy: 0.5491\n",
      "Training loss (for one batch) at step 30: 446.1381, Accuracy: 0.5476\n",
      "Training loss (for one batch) at step 40: 444.7079, Accuracy: 0.5532\n",
      "Training loss (for one batch) at step 50: 444.4178, Accuracy: 0.5555\n",
      "Training loss (for one batch) at step 60: 441.7223, Accuracy: 0.5585\n",
      "Training loss (for one batch) at step 70: 444.9538, Accuracy: 0.5633\n",
      "Training loss (for one batch) at step 80: 443.9700, Accuracy: 0.5652\n",
      "Training loss (for one batch) at step 90: 443.3198, Accuracy: 0.5667\n",
      "Training loss (for one batch) at step 100: 443.1144, Accuracy: 0.5689\n",
      "Training loss (for one batch) at step 110: 444.3182, Accuracy: 0.5684\n",
      "---- Training ----\n",
      "Training loss: 139.8243\n",
      "Training acc over epoch: 0.5673\n",
      "---- Validation ----\n",
      "Validation loss: 34.6966\n",
      "Validation acc: 0.6085\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 442.7115, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 445.2376, Accuracy: 0.5895\n",
      "Training loss (for one batch) at step 20: 444.1219, Accuracy: 0.5629\n",
      "Training loss (for one batch) at step 30: 444.7624, Accuracy: 0.5708\n",
      "Training loss (for one batch) at step 40: 443.5057, Accuracy: 0.5766\n",
      "Training loss (for one batch) at step 50: 444.5533, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 60: 444.7562, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 70: 441.4882, Accuracy: 0.5769\n",
      "Training loss (for one batch) at step 80: 443.2824, Accuracy: 0.5787\n",
      "Training loss (for one batch) at step 90: 443.3892, Accuracy: 0.5787\n",
      "Training loss (for one batch) at step 100: 441.3858, Accuracy: 0.5801\n",
      "Training loss (for one batch) at step 110: 445.1519, Accuracy: 0.5830\n",
      "---- Training ----\n",
      "Training loss: 138.6898\n",
      "Training acc over epoch: 0.5830\n",
      "---- Validation ----\n",
      "Validation loss: 34.4560\n",
      "Validation acc: 0.6445\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 445.8128, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 444.6820, Accuracy: 0.5973\n",
      "Training loss (for one batch) at step 20: 443.2544, Accuracy: 0.6012\n",
      "Training loss (for one batch) at step 30: 442.9162, Accuracy: 0.6018\n",
      "Training loss (for one batch) at step 40: 444.5615, Accuracy: 0.5966\n",
      "Training loss (for one batch) at step 50: 443.5630, Accuracy: 0.6017\n",
      "Training loss (for one batch) at step 60: 444.1172, Accuracy: 0.6041\n",
      "Training loss (for one batch) at step 70: 443.8044, Accuracy: 0.6061\n",
      "Training loss (for one batch) at step 80: 442.2415, Accuracy: 0.6078\n",
      "Training loss (for one batch) at step 90: 442.7360, Accuracy: 0.6095\n",
      "Training loss (for one batch) at step 100: 443.4306, Accuracy: 0.6101\n",
      "Training loss (for one batch) at step 110: 443.2444, Accuracy: 0.6120\n",
      "---- Training ----\n",
      "Training loss: 139.1157\n",
      "Training acc over epoch: 0.6122\n",
      "---- Validation ----\n",
      "Validation loss: 34.6223\n",
      "Validation acc: 0.6599\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 446.5711, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 443.4491, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 20: 443.1848, Accuracy: 0.6269\n",
      "Training loss (for one batch) at step 30: 441.9511, Accuracy: 0.6318\n",
      "Training loss (for one batch) at step 40: 443.4944, Accuracy: 0.6324\n",
      "Training loss (for one batch) at step 50: 444.3359, Accuracy: 0.6382\n",
      "Training loss (for one batch) at step 60: 443.6274, Accuracy: 0.6396\n",
      "Training loss (for one batch) at step 70: 443.1362, Accuracy: 0.6426\n",
      "Training loss (for one batch) at step 80: 440.9352, Accuracy: 0.6421\n",
      "Training loss (for one batch) at step 90: 443.0115, Accuracy: 0.6444\n",
      "Training loss (for one batch) at step 100: 440.9921, Accuracy: 0.6453\n",
      "Training loss (for one batch) at step 110: 440.3156, Accuracy: 0.6467\n",
      "---- Training ----\n",
      "Training loss: 139.3211\n",
      "Training acc over epoch: 0.6449\n",
      "---- Validation ----\n",
      "Validation loss: 34.2687\n",
      "Validation acc: 0.6577\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 443.2998, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 439.5122, Accuracy: 0.6463\n",
      "Training loss (for one batch) at step 20: 441.2483, Accuracy: 0.6417\n",
      "Training loss (for one batch) at step 30: 443.1199, Accuracy: 0.6373\n",
      "Training loss (for one batch) at step 40: 441.2189, Accuracy: 0.6380\n",
      "Training loss (for one batch) at step 50: 439.3810, Accuracy: 0.6429\n",
      "Training loss (for one batch) at step 60: 443.8942, Accuracy: 0.6436\n",
      "Training loss (for one batch) at step 70: 442.7914, Accuracy: 0.6445\n",
      "Training loss (for one batch) at step 80: 445.9494, Accuracy: 0.6447\n",
      "Training loss (for one batch) at step 90: 443.5739, Accuracy: 0.6464\n",
      "Training loss (for one batch) at step 100: 440.3706, Accuracy: 0.6474\n",
      "Training loss (for one batch) at step 110: 444.6785, Accuracy: 0.6460\n",
      "---- Training ----\n",
      "Training loss: 136.6871\n",
      "Training acc over epoch: 0.6456\n",
      "---- Validation ----\n",
      "Validation loss: 34.1750\n",
      "Validation acc: 0.6714\n",
      "Time taken: 11.00s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 440.5478, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 441.2717, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 20: 441.8074, Accuracy: 0.6469\n",
      "Training loss (for one batch) at step 30: 442.0294, Accuracy: 0.6512\n",
      "Training loss (for one batch) at step 40: 438.8692, Accuracy: 0.6555\n",
      "Training loss (for one batch) at step 50: 438.6332, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 60: 434.2400, Accuracy: 0.6721\n",
      "Training loss (for one batch) at step 70: 439.1129, Accuracy: 0.6752\n",
      "Training loss (for one batch) at step 80: 446.9138, Accuracy: 0.6699\n",
      "Training loss (for one batch) at step 90: 439.9997, Accuracy: 0.6639\n",
      "Training loss (for one batch) at step 100: 444.0903, Accuracy: 0.6631\n",
      "Training loss (for one batch) at step 110: 436.6801, Accuracy: 0.6657\n",
      "---- Training ----\n",
      "Training loss: 139.2090\n",
      "Training acc over epoch: 0.6658\n",
      "---- Validation ----\n",
      "Validation loss: 34.1852\n",
      "Validation acc: 0.6805\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 447.8593, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 444.0914, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 20: 443.6183, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 30: 443.4604, Accuracy: 0.6613\n",
      "Training loss (for one batch) at step 40: 435.4237, Accuracy: 0.6684\n",
      "Training loss (for one batch) at step 50: 430.6156, Accuracy: 0.6746\n",
      "Training loss (for one batch) at step 60: 434.2340, Accuracy: 0.6775\n",
      "Training loss (for one batch) at step 70: 445.3344, Accuracy: 0.6841\n",
      "Training loss (for one batch) at step 80: 441.9481, Accuracy: 0.6774\n",
      "Training loss (for one batch) at step 90: 441.8017, Accuracy: 0.6755\n",
      "Training loss (for one batch) at step 100: 437.0897, Accuracy: 0.6764\n",
      "Training loss (for one batch) at step 110: 434.8954, Accuracy: 0.6779\n",
      "---- Training ----\n",
      "Training loss: 139.4994\n",
      "Training acc over epoch: 0.6804\n",
      "---- Validation ----\n",
      "Validation loss: 32.8880\n",
      "Validation acc: 0.6408\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 445.7281, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 443.8495, Accuracy: 0.6712\n",
      "Training loss (for one batch) at step 20: 436.6116, Accuracy: 0.6763\n",
      "Training loss (for one batch) at step 30: 434.0525, Accuracy: 0.6782\n",
      "Training loss (for one batch) at step 40: 434.4482, Accuracy: 0.6791\n",
      "Training loss (for one batch) at step 50: 432.1878, Accuracy: 0.6818\n",
      "Training loss (for one batch) at step 60: 439.6937, Accuracy: 0.6881\n",
      "Training loss (for one batch) at step 70: 447.5366, Accuracy: 0.6866\n",
      "Training loss (for one batch) at step 80: 442.8658, Accuracy: 0.6839\n",
      "Training loss (for one batch) at step 90: 439.5426, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 100: 434.0305, Accuracy: 0.6806\n",
      "Training loss (for one batch) at step 110: 441.4008, Accuracy: 0.6839\n",
      "---- Training ----\n",
      "Training loss: 137.8485\n",
      "Training acc over epoch: 0.6848\n",
      "---- Validation ----\n",
      "Validation loss: 36.7806\n",
      "Validation acc: 0.7152\n",
      "Time taken: 10.99s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 442.3493, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 439.9789, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 20: 437.9362, Accuracy: 0.6853\n",
      "Training loss (for one batch) at step 30: 438.2097, Accuracy: 0.6895\n",
      "Training loss (for one batch) at step 40: 437.4323, Accuracy: 0.6966\n",
      "Training loss (for one batch) at step 50: 423.2592, Accuracy: 0.7077\n",
      "Training loss (for one batch) at step 60: 437.9939, Accuracy: 0.7125\n",
      "Training loss (for one batch) at step 70: 436.6817, Accuracy: 0.7143\n",
      "Training loss (for one batch) at step 80: 442.6323, Accuracy: 0.7090\n",
      "Training loss (for one batch) at step 90: 434.7228, Accuracy: 0.7045\n",
      "Training loss (for one batch) at step 100: 433.3758, Accuracy: 0.7053\n",
      "Training loss (for one batch) at step 110: 438.3299, Accuracy: 0.7083\n",
      "---- Training ----\n",
      "Training loss: 139.2338\n",
      "Training acc over epoch: 0.7083\n",
      "---- Validation ----\n",
      "Validation loss: 34.4019\n",
      "Validation acc: 0.7389\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 444.9891, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 441.9841, Accuracy: 0.7060\n",
      "Training loss (for one batch) at step 20: 432.8302, Accuracy: 0.6894\n",
      "Training loss (for one batch) at step 30: 436.1022, Accuracy: 0.7041\n",
      "Training loss (for one batch) at step 40: 428.1496, Accuracy: 0.7083\n",
      "Training loss (for one batch) at step 50: 432.3562, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 60: 439.2042, Accuracy: 0.7261\n",
      "Training loss (for one batch) at step 70: 443.4857, Accuracy: 0.7248\n",
      "Training loss (for one batch) at step 80: 438.4233, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 90: 432.1342, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 100: 430.3469, Accuracy: 0.7211\n",
      "Training loss (for one batch) at step 110: 433.4820, Accuracy: 0.7219\n",
      "---- Training ----\n",
      "Training loss: 133.5105\n",
      "Training acc over epoch: 0.7222\n",
      "---- Validation ----\n",
      "Validation loss: 36.8724\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 443.6774, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 439.3293, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 434.1300, Accuracy: 0.7232\n",
      "Training loss (for one batch) at step 30: 427.0477, Accuracy: 0.7321\n",
      "Training loss (for one batch) at step 40: 428.3653, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 50: 422.3274, Accuracy: 0.7465\n",
      "Training loss (for one batch) at step 60: 417.8754, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 70: 444.1783, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 80: 438.1966, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 90: 434.0888, Accuracy: 0.7425\n",
      "Training loss (for one batch) at step 100: 428.2711, Accuracy: 0.7420\n",
      "Training loss (for one batch) at step 110: 432.8264, Accuracy: 0.7406\n",
      "---- Training ----\n",
      "Training loss: 135.4550\n",
      "Training acc over epoch: 0.7397\n",
      "---- Validation ----\n",
      "Validation loss: 33.7150\n",
      "Validation acc: 0.7316\n",
      "Time taken: 10.61s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 441.7824, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 433.8909, Accuracy: 0.6996\n",
      "Training loss (for one batch) at step 20: 434.0274, Accuracy: 0.7039\n",
      "Training loss (for one batch) at step 30: 423.4855, Accuracy: 0.7235\n",
      "Training loss (for one batch) at step 40: 420.1851, Accuracy: 0.7340\n",
      "Training loss (for one batch) at step 50: 413.5802, Accuracy: 0.7482\n",
      "Training loss (for one batch) at step 60: 429.9161, Accuracy: 0.7509\n",
      "Training loss (for one batch) at step 70: 436.6460, Accuracy: 0.7504\n",
      "Training loss (for one batch) at step 80: 440.1618, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 90: 432.4027, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 100: 426.6580, Accuracy: 0.7458\n",
      "Training loss (for one batch) at step 110: 435.3345, Accuracy: 0.7456\n",
      "---- Training ----\n",
      "Training loss: 138.5829\n",
      "Training acc over epoch: 0.7463\n",
      "---- Validation ----\n",
      "Validation loss: 36.2881\n",
      "Validation acc: 0.7590\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 441.3950, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 441.7419, Accuracy: 0.7337\n",
      "Training loss (for one batch) at step 20: 441.8243, Accuracy: 0.7314\n",
      "Training loss (for one batch) at step 30: 428.8418, Accuracy: 0.7341\n",
      "Training loss (for one batch) at step 40: 408.0222, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 50: 406.3180, Accuracy: 0.7639\n",
      "Training loss (for one batch) at step 60: 425.3493, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 70: 436.0744, Accuracy: 0.7691\n",
      "Training loss (for one batch) at step 80: 438.9314, Accuracy: 0.7636\n",
      "Training loss (for one batch) at step 90: 434.4102, Accuracy: 0.7587\n",
      "Training loss (for one batch) at step 100: 421.9367, Accuracy: 0.7588\n",
      "Training loss (for one batch) at step 110: 430.4668, Accuracy: 0.7594\n",
      "---- Training ----\n",
      "Training loss: 135.4441\n",
      "Training acc over epoch: 0.7599\n",
      "---- Validation ----\n",
      "Validation loss: 35.8992\n",
      "Validation acc: 0.7450\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 445.3384, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 434.4900, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 20: 423.1378, Accuracy: 0.7299\n",
      "Training loss (for one batch) at step 30: 417.3636, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 40: 415.3780, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 50: 408.0869, Accuracy: 0.7659\n",
      "Training loss (for one batch) at step 60: 414.1685, Accuracy: 0.7748\n",
      "Training loss (for one batch) at step 70: 436.1154, Accuracy: 0.7700\n",
      "Training loss (for one batch) at step 80: 435.5489, Accuracy: 0.7650\n",
      "Training loss (for one batch) at step 90: 434.0231, Accuracy: 0.7627\n",
      "Training loss (for one batch) at step 100: 422.2509, Accuracy: 0.7633\n",
      "Training loss (for one batch) at step 110: 437.9796, Accuracy: 0.7625\n",
      "---- Training ----\n",
      "Training loss: 133.8678\n",
      "Training acc over epoch: 0.7622\n",
      "---- Validation ----\n",
      "Validation loss: 36.2198\n",
      "Validation acc: 0.7448\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 442.9222, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 429.9803, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 429.2784, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 30: 408.8144, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 40: 397.9931, Accuracy: 0.7565\n",
      "Training loss (for one batch) at step 50: 385.8349, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 60: 404.3140, Accuracy: 0.7789\n",
      "Training loss (for one batch) at step 70: 435.2432, Accuracy: 0.7790\n",
      "Training loss (for one batch) at step 80: 428.9273, Accuracy: 0.7739\n",
      "Training loss (for one batch) at step 90: 434.3619, Accuracy: 0.7694\n",
      "Training loss (for one batch) at step 100: 422.7991, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 110: 419.8333, Accuracy: 0.7703\n",
      "---- Training ----\n",
      "Training loss: 132.1525\n",
      "Training acc over epoch: 0.7699\n",
      "---- Validation ----\n",
      "Validation loss: 35.6822\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 437.2768, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 432.5934, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 20: 428.9500, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 30: 418.6473, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 40: 399.4665, Accuracy: 0.7651\n",
      "Training loss (for one batch) at step 50: 374.7267, Accuracy: 0.7793\n",
      "Training loss (for one batch) at step 60: 414.6743, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 70: 432.7062, Accuracy: 0.7829\n",
      "Training loss (for one batch) at step 80: 430.6988, Accuracy: 0.7740\n",
      "Training loss (for one batch) at step 90: 422.7294, Accuracy: 0.7694\n",
      "Training loss (for one batch) at step 100: 419.5981, Accuracy: 0.7694\n",
      "Training loss (for one batch) at step 110: 422.8560, Accuracy: 0.7694\n",
      "---- Training ----\n",
      "Training loss: 128.1919\n",
      "Training acc over epoch: 0.7695\n",
      "---- Validation ----\n",
      "Validation loss: 32.8389\n",
      "Validation acc: 0.7504\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 437.1287, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 430.7585, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 421.6541, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 30: 402.1998, Accuracy: 0.7757\n",
      "Training loss (for one batch) at step 40: 399.1018, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 50: 389.7835, Accuracy: 0.7956\n",
      "Training loss (for one batch) at step 60: 401.5279, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 70: 436.0200, Accuracy: 0.8003\n",
      "Training loss (for one batch) at step 80: 424.5718, Accuracy: 0.7933\n",
      "Training loss (for one batch) at step 90: 411.1191, Accuracy: 0.7874\n",
      "Training loss (for one batch) at step 100: 413.4867, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 110: 430.3327, Accuracy: 0.7874\n",
      "---- Training ----\n",
      "Training loss: 133.5911\n",
      "Training acc over epoch: 0.7867\n",
      "---- Validation ----\n",
      "Validation loss: 37.4753\n",
      "Validation acc: 0.7203\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 439.2948, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 429.6024, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 419.9776, Accuracy: 0.7619\n",
      "Training loss (for one batch) at step 30: 405.8359, Accuracy: 0.7765\n",
      "Training loss (for one batch) at step 40: 394.5733, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 50: 385.2234, Accuracy: 0.7989\n",
      "Training loss (for one batch) at step 60: 400.0611, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 70: 432.4462, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 80: 429.1272, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 90: 427.6433, Accuracy: 0.7906\n",
      "Training loss (for one batch) at step 100: 423.5944, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 110: 410.0810, Accuracy: 0.7889\n",
      "---- Training ----\n",
      "Training loss: 134.3350\n",
      "Training acc over epoch: 0.7890\n",
      "---- Validation ----\n",
      "Validation loss: 37.3381\n",
      "Validation acc: 0.7378\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 438.2841, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 427.7778, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 407.2597, Accuracy: 0.7567\n",
      "Training loss (for one batch) at step 30: 401.6100, Accuracy: 0.7714\n",
      "Training loss (for one batch) at step 40: 387.6454, Accuracy: 0.7902\n",
      "Training loss (for one batch) at step 50: 371.7992, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 60: 397.6228, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 70: 421.5623, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 80: 436.2509, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 90: 408.1863, Accuracy: 0.7885\n",
      "Training loss (for one batch) at step 100: 406.1157, Accuracy: 0.7874\n",
      "Training loss (for one batch) at step 110: 413.9117, Accuracy: 0.7865\n",
      "---- Training ----\n",
      "Training loss: 125.8335\n",
      "Training acc over epoch: 0.7876\n",
      "---- Validation ----\n",
      "Validation loss: 39.1016\n",
      "Validation acc: 0.7474\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 430.3264, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 423.2971, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 20: 416.3958, Accuracy: 0.7675\n",
      "Training loss (for one batch) at step 30: 399.6127, Accuracy: 0.7755\n",
      "Training loss (for one batch) at step 40: 376.1400, Accuracy: 0.7885\n",
      "Training loss (for one batch) at step 50: 373.0898, Accuracy: 0.8009\n",
      "Training loss (for one batch) at step 60: 367.5054, Accuracy: 0.8101\n",
      "Training loss (for one batch) at step 70: 426.2416, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 80: 417.8890, Accuracy: 0.7979\n",
      "Training loss (for one batch) at step 90: 416.2426, Accuracy: 0.7949\n",
      "Training loss (for one batch) at step 100: 397.4804, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 110: 407.5916, Accuracy: 0.7930\n",
      "---- Training ----\n",
      "Training loss: 123.7518\n",
      "Training acc over epoch: 0.7913\n",
      "---- Validation ----\n",
      "Validation loss: 38.0094\n",
      "Validation acc: 0.7477\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 434.9301, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 418.6766, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 413.0572, Accuracy: 0.7608\n",
      "Training loss (for one batch) at step 30: 385.4950, Accuracy: 0.7714\n",
      "Training loss (for one batch) at step 40: 377.5947, Accuracy: 0.7845\n",
      "Training loss (for one batch) at step 50: 369.8908, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 60: 412.7711, Accuracy: 0.8057\n",
      "Training loss (for one batch) at step 70: 422.3334, Accuracy: 0.8000\n",
      "Training loss (for one batch) at step 80: 420.9830, Accuracy: 0.7935\n",
      "Training loss (for one batch) at step 90: 414.8909, Accuracy: 0.7892\n",
      "Training loss (for one batch) at step 100: 399.7771, Accuracy: 0.7900\n",
      "Training loss (for one batch) at step 110: 408.5513, Accuracy: 0.7893\n",
      "---- Training ----\n",
      "Training loss: 133.2196\n",
      "Training acc over epoch: 0.7894\n",
      "---- Validation ----\n",
      "Validation loss: 34.5755\n",
      "Validation acc: 0.7332\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 428.5490, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 423.8926, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 20: 400.7789, Accuracy: 0.7507\n",
      "Training loss (for one batch) at step 30: 377.7748, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 40: 369.0138, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 50: 355.7797, Accuracy: 0.8027\n",
      "Training loss (for one batch) at step 60: 376.2594, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 70: 406.4789, Accuracy: 0.8101\n",
      "Training loss (for one batch) at step 80: 414.0150, Accuracy: 0.8005\n",
      "Training loss (for one batch) at step 90: 410.0089, Accuracy: 0.7966\n",
      "Training loss (for one batch) at step 100: 388.7690, Accuracy: 0.7963\n",
      "Training loss (for one batch) at step 110: 386.3311, Accuracy: 0.7961\n",
      "---- Training ----\n",
      "Training loss: 122.5588\n",
      "Training acc over epoch: 0.7944\n",
      "---- Validation ----\n",
      "Validation loss: 38.0587\n",
      "Validation acc: 0.7222\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 421.0504, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 408.4487, Accuracy: 0.7607\n",
      "Training loss (for one batch) at step 20: 395.1961, Accuracy: 0.7623\n",
      "Training loss (for one batch) at step 30: 390.5377, Accuracy: 0.7765\n",
      "Training loss (for one batch) at step 40: 368.3665, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 50: 351.7340, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 60: 369.2450, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 70: 397.1644, Accuracy: 0.8100\n",
      "Training loss (for one batch) at step 80: 388.7402, Accuracy: 0.8004\n",
      "Training loss (for one batch) at step 90: 401.2016, Accuracy: 0.7965\n",
      "Training loss (for one batch) at step 100: 385.5312, Accuracy: 0.7975\n",
      "Training loss (for one batch) at step 110: 411.2865, Accuracy: 0.7972\n",
      "---- Training ----\n",
      "Training loss: 120.6661\n",
      "Training acc over epoch: 0.7972\n",
      "---- Validation ----\n",
      "Validation loss: 34.7798\n",
      "Validation acc: 0.7303\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 401.3291, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 425.3759, Accuracy: 0.7507\n",
      "Training loss (for one batch) at step 20: 400.1880, Accuracy: 0.7615\n",
      "Training loss (for one batch) at step 30: 395.9412, Accuracy: 0.7792\n",
      "Training loss (for one batch) at step 40: 362.3454, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 50: 356.0498, Accuracy: 0.8117\n",
      "Training loss (for one batch) at step 60: 374.5256, Accuracy: 0.8194\n",
      "Training loss (for one batch) at step 70: 404.8315, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 80: 412.0103, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 90: 399.4435, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 100: 384.2924, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 110: 399.2210, Accuracy: 0.8021\n",
      "---- Training ----\n",
      "Training loss: 122.2198\n",
      "Training acc over epoch: 0.8012\n",
      "---- Validation ----\n",
      "Validation loss: 42.7904\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 431.5636, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 402.1010, Accuracy: 0.7415\n",
      "Training loss (for one batch) at step 20: 407.6585, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 30: 378.6926, Accuracy: 0.7767\n",
      "Training loss (for one batch) at step 40: 362.1971, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 50: 335.1922, Accuracy: 0.8053\n",
      "Training loss (for one batch) at step 60: 366.2653, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 70: 400.1008, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 80: 435.0693, Accuracy: 0.8003\n",
      "Training loss (for one batch) at step 90: 373.2152, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 100: 373.0218, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 110: 374.1260, Accuracy: 0.7971\n",
      "---- Training ----\n",
      "Training loss: 131.4646\n",
      "Training acc over epoch: 0.7951\n",
      "---- Validation ----\n",
      "Validation loss: 39.4498\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 422.0432, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 403.8464, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 20: 392.1107, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 30: 373.5340, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 40: 350.9951, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 50: 331.2067, Accuracy: 0.8081\n",
      "Training loss (for one batch) at step 60: 353.0500, Accuracy: 0.8181\n",
      "Training loss (for one batch) at step 70: 416.0483, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 80: 410.3313, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 90: 387.9373, Accuracy: 0.7971\n",
      "Training loss (for one batch) at step 100: 366.5867, Accuracy: 0.7987\n",
      "Training loss (for one batch) at step 110: 377.5756, Accuracy: 0.8005\n",
      "---- Training ----\n",
      "Training loss: 123.6953\n",
      "Training acc over epoch: 0.7983\n",
      "---- Validation ----\n",
      "Validation loss: 41.4083\n",
      "Validation acc: 0.7289\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 411.5052, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 417.6468, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 383.0163, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 30: 372.1321, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 40: 368.6823, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 50: 348.2635, Accuracy: 0.8199\n",
      "Training loss (for one batch) at step 60: 348.6861, Accuracy: 0.8299\n",
      "Training loss (for one batch) at step 70: 373.7890, Accuracy: 0.8228\n",
      "Training loss (for one batch) at step 80: 398.0775, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 90: 385.5490, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 100: 372.5292, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 110: 370.9783, Accuracy: 0.8041\n",
      "---- Training ----\n",
      "Training loss: 119.0991\n",
      "Training acc over epoch: 0.8039\n",
      "---- Validation ----\n",
      "Validation loss: 44.1994\n",
      "Validation acc: 0.7211\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 421.5145, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 390.7736, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 379.4463, Accuracy: 0.7638\n",
      "Training loss (for one batch) at step 30: 362.8858, Accuracy: 0.7870\n",
      "Training loss (for one batch) at step 40: 361.5240, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 50: 354.2225, Accuracy: 0.8165\n",
      "Training loss (for one batch) at step 60: 359.2765, Accuracy: 0.8227\n",
      "Training loss (for one batch) at step 70: 393.7801, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 80: 411.3913, Accuracy: 0.8038\n",
      "Training loss (for one batch) at step 90: 375.1975, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 100: 357.2929, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 110: 379.4857, Accuracy: 0.8022\n",
      "---- Training ----\n",
      "Training loss: 121.3572\n",
      "Training acc over epoch: 0.8006\n",
      "---- Validation ----\n",
      "Validation loss: 51.0493\n",
      "Validation acc: 0.7149\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 412.2182, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 391.1904, Accuracy: 0.7401\n",
      "Training loss (for one batch) at step 20: 380.6103, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 30: 370.3076, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 40: 347.4598, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 50: 336.1746, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 60: 337.7761, Accuracy: 0.8261\n",
      "Training loss (for one batch) at step 70: 392.6432, Accuracy: 0.8158\n",
      "Training loss (for one batch) at step 80: 397.5949, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 90: 380.8237, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 100: 372.1498, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 110: 375.5059, Accuracy: 0.8021\n",
      "---- Training ----\n",
      "Training loss: 127.5447\n",
      "Training acc over epoch: 0.8008\n",
      "---- Validation ----\n",
      "Validation loss: 31.7579\n",
      "Validation acc: 0.7061\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 400.8638, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 371.9696, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 369.4072, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 30: 360.5990, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 40: 338.4295, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 50: 335.0065, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 60: 351.3212, Accuracy: 0.8251\n",
      "Training loss (for one batch) at step 70: 399.2756, Accuracy: 0.8160\n",
      "Training loss (for one batch) at step 80: 377.6358, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 90: 370.4087, Accuracy: 0.8027\n",
      "Training loss (for one batch) at step 100: 352.7073, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 110: 364.8710, Accuracy: 0.8037\n",
      "---- Training ----\n",
      "Training loss: 111.4972\n",
      "Training acc over epoch: 0.8034\n",
      "---- Validation ----\n",
      "Validation loss: 53.1647\n",
      "Validation acc: 0.7187\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 385.6445, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 391.9330, Accuracy: 0.7408\n",
      "Training loss (for one batch) at step 20: 380.3712, Accuracy: 0.7556\n",
      "Training loss (for one batch) at step 30: 343.4995, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 40: 332.1866, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 50: 329.0421, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 60: 359.9266, Accuracy: 0.8247\n",
      "Training loss (for one batch) at step 70: 387.9688, Accuracy: 0.8177\n",
      "Training loss (for one batch) at step 80: 369.0953, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 90: 353.3229, Accuracy: 0.8013\n",
      "Training loss (for one batch) at step 100: 346.6967, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 110: 388.2346, Accuracy: 0.8048\n",
      "---- Training ----\n",
      "Training loss: 122.0044\n",
      "Training acc over epoch: 0.8030\n",
      "---- Validation ----\n",
      "Validation loss: 33.5707\n",
      "Validation acc: 0.7093\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 393.7629, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 395.6083, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 20: 384.9003, Accuracy: 0.7526\n",
      "Training loss (for one batch) at step 30: 357.0564, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 40: 342.5117, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 50: 340.3594, Accuracy: 0.8165\n",
      "Training loss (for one batch) at step 60: 329.4594, Accuracy: 0.8268\n",
      "Training loss (for one batch) at step 70: 358.6734, Accuracy: 0.8171\n",
      "Training loss (for one batch) at step 80: 380.8792, Accuracy: 0.8048\n",
      "Training loss (for one batch) at step 90: 369.8683, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 100: 360.9893, Accuracy: 0.8031\n",
      "Training loss (for one batch) at step 110: 368.3382, Accuracy: 0.8035\n",
      "---- Training ----\n",
      "Training loss: 113.9069\n",
      "Training acc over epoch: 0.8020\n",
      "---- Validation ----\n",
      "Validation loss: 49.2100\n",
      "Validation acc: 0.7176\n",
      "Time taken: 10.87s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 420.8458, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 391.1712, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 20: 348.7272, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 30: 349.9490, Accuracy: 0.7810\n",
      "Training loss (for one batch) at step 40: 325.5787, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 50: 330.4807, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 60: 343.0356, Accuracy: 0.8275\n",
      "Training loss (for one batch) at step 70: 371.0218, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 80: 380.8117, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 90: 354.9312, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 100: 353.0189, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 110: 355.9560, Accuracy: 0.8076\n",
      "---- Training ----\n",
      "Training loss: 119.0675\n",
      "Training acc over epoch: 0.8058\n",
      "---- Validation ----\n",
      "Validation loss: 51.2272\n",
      "Validation acc: 0.7166\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 381.3092, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 393.6017, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 20: 359.1592, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 30: 340.5922, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 40: 328.1808, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 50: 327.4200, Accuracy: 0.8197\n",
      "Training loss (for one batch) at step 60: 337.0984, Accuracy: 0.8322\n",
      "Training loss (for one batch) at step 70: 377.4011, Accuracy: 0.8205\n",
      "Training loss (for one batch) at step 80: 389.5185, Accuracy: 0.8067\n",
      "Training loss (for one batch) at step 90: 342.2692, Accuracy: 0.8015\n",
      "Training loss (for one batch) at step 100: 346.7592, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 110: 373.7496, Accuracy: 0.8041\n",
      "---- Training ----\n",
      "Training loss: 112.1777\n",
      "Training acc over epoch: 0.8037\n",
      "---- Validation ----\n",
      "Validation loss: 33.0247\n",
      "Validation acc: 0.7265\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 403.0371, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 403.5769, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 20: 351.7813, Accuracy: 0.7556\n",
      "Training loss (for one batch) at step 30: 342.0994, Accuracy: 0.7845\n",
      "Training loss (for one batch) at step 40: 333.2729, Accuracy: 0.8041\n",
      "Training loss (for one batch) at step 50: 321.2133, Accuracy: 0.8200\n",
      "Training loss (for one batch) at step 60: 337.9633, Accuracy: 0.8299\n",
      "Training loss (for one batch) at step 70: 354.3907, Accuracy: 0.8195\n",
      "Training loss (for one batch) at step 80: 383.1501, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 90: 345.9506, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 100: 327.4698, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 110: 351.9056, Accuracy: 0.8060\n",
      "---- Training ----\n",
      "Training loss: 114.4672\n",
      "Training acc over epoch: 0.8038\n",
      "---- Validation ----\n",
      "Validation loss: 36.8069\n",
      "Validation acc: 0.7117\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 391.6429, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 379.8075, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 344.3240, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 30: 345.7611, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 40: 333.1313, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 50: 309.4279, Accuracy: 0.8257\n",
      "Training loss (for one batch) at step 60: 334.6467, Accuracy: 0.8329\n",
      "Training loss (for one batch) at step 70: 375.4244, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 80: 369.3669, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 90: 347.5423, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 100: 335.1284, Accuracy: 0.8069\n",
      "Training loss (for one batch) at step 110: 352.2372, Accuracy: 0.8062\n",
      "---- Training ----\n",
      "Training loss: 114.0463\n",
      "Training acc over epoch: 0.8054\n",
      "---- Validation ----\n",
      "Validation loss: 35.8300\n",
      "Validation acc: 0.7136\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 382.4568, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 382.4816, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 20: 336.4193, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 30: 330.5630, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 40: 320.4333, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 50: 309.8287, Accuracy: 0.8234\n",
      "Training loss (for one batch) at step 60: 331.9564, Accuracy: 0.8312\n",
      "Training loss (for one batch) at step 70: 350.9425, Accuracy: 0.8217\n",
      "Training loss (for one batch) at step 80: 366.6114, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 90: 345.2596, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 100: 331.4723, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 110: 330.2293, Accuracy: 0.8081\n",
      "---- Training ----\n",
      "Training loss: 110.1368\n",
      "Training acc over epoch: 0.8056\n",
      "---- Validation ----\n",
      "Validation loss: 45.0165\n",
      "Validation acc: 0.7200\n",
      "Time taken: 10.58s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7272\n",
      "Validation AUC: 0.7276\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 673.2273, Accuracy: 0.4609\n",
      "Training loss (for one batch) at step 10: 632.9545, Accuracy: 0.5071\n",
      "Training loss (for one batch) at step 20: 538.3162, Accuracy: 0.5182\n",
      "Training loss (for one batch) at step 30: 511.1765, Accuracy: 0.5101\n",
      "Training loss (for one batch) at step 40: 516.5939, Accuracy: 0.5124\n",
      "Training loss (for one batch) at step 50: 494.7975, Accuracy: 0.5139\n",
      "Training loss (for one batch) at step 60: 477.2519, Accuracy: 0.5169\n",
      "Training loss (for one batch) at step 70: 467.4175, Accuracy: 0.5165\n",
      "Training loss (for one batch) at step 80: 479.9352, Accuracy: 0.5195\n",
      "Training loss (for one batch) at step 90: 462.2975, Accuracy: 0.5188\n",
      "Training loss (for one batch) at step 100: 476.7609, Accuracy: 0.5159\n",
      "Training loss (for one batch) at step 110: 451.4594, Accuracy: 0.5146\n",
      "---- Training ----\n",
      "Training loss: 138.4600\n",
      "Training acc over epoch: 0.5146\n",
      "---- Validation ----\n",
      "Validation loss: 34.6541\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.13s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 456.3791, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 456.7364, Accuracy: 0.5199\n",
      "Training loss (for one batch) at step 20: 456.8438, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 30: 457.9973, Accuracy: 0.5139\n",
      "Training loss (for one batch) at step 40: 453.7580, Accuracy: 0.5147\n",
      "Training loss (for one batch) at step 50: 450.7667, Accuracy: 0.5191\n",
      "Training loss (for one batch) at step 60: 448.3691, Accuracy: 0.5195\n",
      "Training loss (for one batch) at step 70: 450.1999, Accuracy: 0.5201\n",
      "Training loss (for one batch) at step 80: 454.0090, Accuracy: 0.5220\n",
      "Training loss (for one batch) at step 90: 450.8301, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 100: 451.3562, Accuracy: 0.5254\n",
      "Training loss (for one batch) at step 110: 453.0262, Accuracy: 0.5252\n",
      "---- Training ----\n",
      "Training loss: 139.7150\n",
      "Training acc over epoch: 0.5253\n",
      "---- Validation ----\n",
      "Validation loss: 35.4668\n",
      "Validation acc: 0.5137\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 445.3414, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 448.7036, Accuracy: 0.5462\n",
      "Training loss (for one batch) at step 20: 445.8082, Accuracy: 0.5309\n",
      "Training loss (for one batch) at step 30: 446.0545, Accuracy: 0.5340\n",
      "Training loss (for one batch) at step 40: 449.9952, Accuracy: 0.5394\n",
      "Training loss (for one batch) at step 50: 445.7773, Accuracy: 0.5420\n",
      "Training loss (for one batch) at step 60: 443.7183, Accuracy: 0.5420\n",
      "Training loss (for one batch) at step 70: 446.6285, Accuracy: 0.5408\n",
      "Training loss (for one batch) at step 80: 445.7801, Accuracy: 0.5416\n",
      "Training loss (for one batch) at step 90: 445.9744, Accuracy: 0.5434\n",
      "Training loss (for one batch) at step 100: 446.4440, Accuracy: 0.5433\n",
      "Training loss (for one batch) at step 110: 442.4761, Accuracy: 0.5417\n",
      "---- Training ----\n",
      "Training loss: 139.2911\n",
      "Training acc over epoch: 0.5418\n",
      "---- Validation ----\n",
      "Validation loss: 34.7736\n",
      "Validation acc: 0.5199\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 447.3130, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 444.7505, Accuracy: 0.5504\n",
      "Training loss (for one batch) at step 20: 443.5533, Accuracy: 0.5499\n",
      "Training loss (for one batch) at step 30: 443.9357, Accuracy: 0.5567\n",
      "Training loss (for one batch) at step 40: 444.1546, Accuracy: 0.5562\n",
      "Training loss (for one batch) at step 50: 443.7103, Accuracy: 0.5556\n",
      "Training loss (for one batch) at step 60: 445.4112, Accuracy: 0.5572\n",
      "Training loss (for one batch) at step 70: 444.8805, Accuracy: 0.5642\n",
      "Training loss (for one batch) at step 80: 443.1617, Accuracy: 0.5667\n",
      "Training loss (for one batch) at step 90: 443.1962, Accuracy: 0.5683\n",
      "Training loss (for one batch) at step 100: 444.1977, Accuracy: 0.5666\n",
      "Training loss (for one batch) at step 110: 442.5092, Accuracy: 0.5676\n",
      "---- Training ----\n",
      "Training loss: 139.5640\n",
      "Training acc over epoch: 0.5676\n",
      "---- Validation ----\n",
      "Validation loss: 34.3288\n",
      "Validation acc: 0.5664\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 443.5314, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 442.1050, Accuracy: 0.5895\n",
      "Training loss (for one batch) at step 20: 443.6036, Accuracy: 0.5811\n",
      "Training loss (for one batch) at step 30: 443.7917, Accuracy: 0.5771\n",
      "Training loss (for one batch) at step 40: 442.4975, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 50: 443.4685, Accuracy: 0.5755\n",
      "Training loss (for one batch) at step 60: 441.3005, Accuracy: 0.5786\n",
      "Training loss (for one batch) at step 70: 444.7446, Accuracy: 0.5831\n",
      "Training loss (for one batch) at step 80: 443.8187, Accuracy: 0.5874\n",
      "Training loss (for one batch) at step 90: 444.3674, Accuracy: 0.5889\n",
      "Training loss (for one batch) at step 100: 443.4750, Accuracy: 0.5886\n",
      "Training loss (for one batch) at step 110: 442.3744, Accuracy: 0.5899\n",
      "---- Training ----\n",
      "Training loss: 138.9267\n",
      "Training acc over epoch: 0.5895\n",
      "---- Validation ----\n",
      "Validation loss: 34.8677\n",
      "Validation acc: 0.6005\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 442.8409, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 442.0586, Accuracy: 0.5881\n",
      "Training loss (for one batch) at step 20: 442.0088, Accuracy: 0.5978\n",
      "Training loss (for one batch) at step 30: 442.9318, Accuracy: 0.6003\n",
      "Training loss (for one batch) at step 40: 443.2719, Accuracy: 0.5978\n",
      "Training loss (for one batch) at step 50: 444.7281, Accuracy: 0.6052\n",
      "Training loss (for one batch) at step 60: 440.3415, Accuracy: 0.6107\n",
      "Training loss (for one batch) at step 70: 444.9260, Accuracy: 0.6131\n",
      "Training loss (for one batch) at step 80: 442.5599, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 90: 443.4619, Accuracy: 0.6174\n",
      "Training loss (for one batch) at step 100: 443.8799, Accuracy: 0.6137\n",
      "Training loss (for one batch) at step 110: 441.2029, Accuracy: 0.6147\n",
      "---- Training ----\n",
      "Training loss: 137.3192\n",
      "Training acc over epoch: 0.6146\n",
      "---- Validation ----\n",
      "Validation loss: 34.6291\n",
      "Validation acc: 0.6220\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 442.8421, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 443.3587, Accuracy: 0.6321\n",
      "Training loss (for one batch) at step 20: 443.7449, Accuracy: 0.6291\n",
      "Training loss (for one batch) at step 30: 439.7508, Accuracy: 0.6210\n",
      "Training loss (for one batch) at step 40: 443.3507, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 50: 439.6646, Accuracy: 0.6207\n",
      "Training loss (for one batch) at step 60: 440.9939, Accuracy: 0.6262\n",
      "Training loss (for one batch) at step 70: 443.6632, Accuracy: 0.6290\n",
      "Training loss (for one batch) at step 80: 439.6512, Accuracy: 0.6318\n",
      "Training loss (for one batch) at step 90: 440.9285, Accuracy: 0.6294\n",
      "Training loss (for one batch) at step 100: 439.8340, Accuracy: 0.6279\n",
      "Training loss (for one batch) at step 110: 440.4433, Accuracy: 0.6249\n",
      "---- Training ----\n",
      "Training loss: 138.6667\n",
      "Training acc over epoch: 0.6240\n",
      "---- Validation ----\n",
      "Validation loss: 34.5959\n",
      "Validation acc: 0.5997\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 440.2278, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 440.3221, Accuracy: 0.6385\n",
      "Training loss (for one batch) at step 20: 441.3226, Accuracy: 0.6466\n",
      "Training loss (for one batch) at step 30: 441.9175, Accuracy: 0.6535\n",
      "Training loss (for one batch) at step 40: 436.2621, Accuracy: 0.6452\n",
      "Training loss (for one batch) at step 50: 438.7096, Accuracy: 0.6449\n",
      "Training loss (for one batch) at step 60: 440.1206, Accuracy: 0.6469\n",
      "Training loss (for one batch) at step 70: 443.2023, Accuracy: 0.6511\n",
      "Training loss (for one batch) at step 80: 439.7111, Accuracy: 0.6469\n",
      "Training loss (for one batch) at step 90: 446.1130, Accuracy: 0.6452\n",
      "Training loss (for one batch) at step 100: 439.8728, Accuracy: 0.6452\n",
      "Training loss (for one batch) at step 110: 440.9138, Accuracy: 0.6465\n",
      "---- Training ----\n",
      "Training loss: 139.3036\n",
      "Training acc over epoch: 0.6466\n",
      "---- Validation ----\n",
      "Validation loss: 33.3088\n",
      "Validation acc: 0.6107\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 439.5602, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 443.1906, Accuracy: 0.6499\n",
      "Training loss (for one batch) at step 20: 435.0903, Accuracy: 0.6417\n",
      "Training loss (for one batch) at step 30: 440.9619, Accuracy: 0.6457\n",
      "Training loss (for one batch) at step 40: 436.0021, Accuracy: 0.6515\n",
      "Training loss (for one batch) at step 50: 435.8578, Accuracy: 0.6601\n",
      "Training loss (for one batch) at step 60: 439.6096, Accuracy: 0.6609\n",
      "Training loss (for one batch) at step 70: 443.2616, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 80: 436.8795, Accuracy: 0.6574\n",
      "Training loss (for one batch) at step 90: 435.8711, Accuracy: 0.6546\n",
      "Training loss (for one batch) at step 100: 433.8494, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 110: 440.7942, Accuracy: 0.6546\n",
      "---- Training ----\n",
      "Training loss: 137.5711\n",
      "Training acc over epoch: 0.6555\n",
      "---- Validation ----\n",
      "Validation loss: 35.4024\n",
      "Validation acc: 0.6459\n",
      "Time taken: 10.89s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 443.6806, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 439.8384, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 20: 446.6996, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 30: 441.9204, Accuracy: 0.6668\n",
      "Training loss (for one batch) at step 40: 434.4066, Accuracy: 0.6604\n",
      "Training loss (for one batch) at step 50: 426.2134, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 60: 436.8828, Accuracy: 0.6661\n",
      "Training loss (for one batch) at step 70: 434.1796, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 80: 437.1355, Accuracy: 0.6703\n",
      "Training loss (for one batch) at step 90: 433.7011, Accuracy: 0.6693\n",
      "Training loss (for one batch) at step 100: 434.1093, Accuracy: 0.6692\n",
      "Training loss (for one batch) at step 110: 445.9619, Accuracy: 0.6695\n",
      "---- Training ----\n",
      "Training loss: 134.2621\n",
      "Training acc over epoch: 0.6697\n",
      "---- Validation ----\n",
      "Validation loss: 36.7907\n",
      "Validation acc: 0.6376\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 433.2171, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 439.2548, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 20: 437.4789, Accuracy: 0.6678\n",
      "Training loss (for one batch) at step 30: 437.1913, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 40: 422.9400, Accuracy: 0.6778\n",
      "Training loss (for one batch) at step 50: 426.8002, Accuracy: 0.6858\n",
      "Training loss (for one batch) at step 60: 442.7442, Accuracy: 0.6902\n",
      "Training loss (for one batch) at step 70: 440.0108, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 80: 440.0369, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 90: 435.0329, Accuracy: 0.6800\n",
      "Training loss (for one batch) at step 100: 429.4350, Accuracy: 0.6802\n",
      "Training loss (for one batch) at step 110: 437.0482, Accuracy: 0.6807\n",
      "---- Training ----\n",
      "Training loss: 136.0840\n",
      "Training acc over epoch: 0.6814\n",
      "---- Validation ----\n",
      "Validation loss: 32.8188\n",
      "Validation acc: 0.6808\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 436.8250, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 429.1163, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 20: 433.9193, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 30: 429.0488, Accuracy: 0.6782\n",
      "Training loss (for one batch) at step 40: 431.1612, Accuracy: 0.6814\n",
      "Training loss (for one batch) at step 50: 421.7968, Accuracy: 0.6916\n",
      "Training loss (for one batch) at step 60: 430.1268, Accuracy: 0.6970\n",
      "Training loss (for one batch) at step 70: 431.9972, Accuracy: 0.6978\n",
      "Training loss (for one batch) at step 80: 436.2623, Accuracy: 0.6906\n",
      "Training loss (for one batch) at step 90: 442.8460, Accuracy: 0.6866\n",
      "Training loss (for one batch) at step 100: 428.5466, Accuracy: 0.6873\n",
      "Training loss (for one batch) at step 110: 437.8150, Accuracy: 0.6882\n",
      "---- Training ----\n",
      "Training loss: 140.2577\n",
      "Training acc over epoch: 0.6893\n",
      "---- Validation ----\n",
      "Validation loss: 34.9746\n",
      "Validation acc: 0.6572\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 441.8292, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 430.9097, Accuracy: 0.6847\n",
      "Training loss (for one batch) at step 20: 436.0219, Accuracy: 0.6760\n",
      "Training loss (for one batch) at step 30: 431.4127, Accuracy: 0.6867\n",
      "Training loss (for one batch) at step 40: 427.6025, Accuracy: 0.6926\n",
      "Training loss (for one batch) at step 50: 406.0829, Accuracy: 0.7047\n",
      "Training loss (for one batch) at step 60: 432.5880, Accuracy: 0.7094\n",
      "Training loss (for one batch) at step 70: 436.3145, Accuracy: 0.7121\n",
      "Training loss (for one batch) at step 80: 444.8001, Accuracy: 0.7021\n",
      "Training loss (for one batch) at step 90: 428.1396, Accuracy: 0.6962\n",
      "Training loss (for one batch) at step 100: 423.0797, Accuracy: 0.6972\n",
      "Training loss (for one batch) at step 110: 424.2960, Accuracy: 0.6993\n",
      "---- Training ----\n",
      "Training loss: 135.7259\n",
      "Training acc over epoch: 0.7004\n",
      "---- Validation ----\n",
      "Validation loss: 33.8480\n",
      "Validation acc: 0.7004\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 439.9732, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 441.7973, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 20: 435.4352, Accuracy: 0.6830\n",
      "Training loss (for one batch) at step 30: 425.1786, Accuracy: 0.6850\n",
      "Training loss (for one batch) at step 40: 426.7731, Accuracy: 0.6911\n",
      "Training loss (for one batch) at step 50: 449.5735, Accuracy: 0.7019\n",
      "Training loss (for one batch) at step 60: 432.6428, Accuracy: 0.7054\n",
      "Training loss (for one batch) at step 70: 440.5231, Accuracy: 0.7101\n",
      "Training loss (for one batch) at step 80: 444.8045, Accuracy: 0.7052\n",
      "Training loss (for one batch) at step 90: 436.2862, Accuracy: 0.7036\n",
      "Training loss (for one batch) at step 100: 419.7714, Accuracy: 0.7062\n",
      "Training loss (for one batch) at step 110: 435.3003, Accuracy: 0.7088\n",
      "---- Training ----\n",
      "Training loss: 137.2052\n",
      "Training acc over epoch: 0.7092\n",
      "---- Validation ----\n",
      "Validation loss: 31.8418\n",
      "Validation acc: 0.6499\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 439.6396, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 435.4191, Accuracy: 0.6911\n",
      "Training loss (for one batch) at step 20: 429.3813, Accuracy: 0.6972\n",
      "Training loss (for one batch) at step 30: 429.6670, Accuracy: 0.7049\n",
      "Training loss (for one batch) at step 40: 431.9800, Accuracy: 0.7052\n",
      "Training loss (for one batch) at step 50: 424.3566, Accuracy: 0.7151\n",
      "Training loss (for one batch) at step 60: 412.3895, Accuracy: 0.7226\n",
      "Training loss (for one batch) at step 70: 435.2741, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 80: 434.1835, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 90: 431.9993, Accuracy: 0.7089\n",
      "Training loss (for one batch) at step 100: 420.2566, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 110: 426.9299, Accuracy: 0.7125\n",
      "---- Training ----\n",
      "Training loss: 136.5665\n",
      "Training acc over epoch: 0.7134\n",
      "---- Validation ----\n",
      "Validation loss: 33.8866\n",
      "Validation acc: 0.7020\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 435.4562, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 426.7490, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 20: 430.8906, Accuracy: 0.7054\n",
      "Training loss (for one batch) at step 30: 421.7233, Accuracy: 0.7124\n",
      "Training loss (for one batch) at step 40: 424.0231, Accuracy: 0.7142\n",
      "Training loss (for one batch) at step 50: 413.9963, Accuracy: 0.7261\n",
      "Training loss (for one batch) at step 60: 424.4608, Accuracy: 0.7334\n",
      "Training loss (for one batch) at step 70: 432.2912, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 80: 436.8100, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 90: 429.5644, Accuracy: 0.7168\n",
      "Training loss (for one batch) at step 100: 415.4930, Accuracy: 0.7164\n",
      "Training loss (for one batch) at step 110: 425.9292, Accuracy: 0.7180\n",
      "---- Training ----\n",
      "Training loss: 135.6133\n",
      "Training acc over epoch: 0.7196\n",
      "---- Validation ----\n",
      "Validation loss: 33.5235\n",
      "Validation acc: 0.7039\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 439.3646, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 431.0662, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 20: 433.6353, Accuracy: 0.7221\n",
      "Training loss (for one batch) at step 30: 427.1199, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 40: 410.5973, Accuracy: 0.7342\n",
      "Training loss (for one batch) at step 50: 415.4694, Accuracy: 0.7446\n",
      "Training loss (for one batch) at step 60: 421.9639, Accuracy: 0.7501\n",
      "Training loss (for one batch) at step 70: 438.2788, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 80: 425.0236, Accuracy: 0.7430\n",
      "Training loss (for one batch) at step 90: 423.9757, Accuracy: 0.7382\n",
      "Training loss (for one batch) at step 100: 429.3355, Accuracy: 0.7378\n",
      "Training loss (for one batch) at step 110: 426.2669, Accuracy: 0.7380\n",
      "---- Training ----\n",
      "Training loss: 136.6136\n",
      "Training acc over epoch: 0.7376\n",
      "---- Validation ----\n",
      "Validation loss: 35.3873\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 445.6291, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 434.1559, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 20: 441.5516, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 30: 427.0247, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 40: 414.1328, Accuracy: 0.7380\n",
      "Training loss (for one batch) at step 50: 408.7945, Accuracy: 0.7509\n",
      "Training loss (for one batch) at step 60: 422.4814, Accuracy: 0.7572\n",
      "Training loss (for one batch) at step 70: 425.0914, Accuracy: 0.7537\n",
      "Training loss (for one batch) at step 80: 425.4897, Accuracy: 0.7497\n",
      "Training loss (for one batch) at step 90: 421.8392, Accuracy: 0.7448\n",
      "Training loss (for one batch) at step 100: 418.0289, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 110: 406.3018, Accuracy: 0.7445\n",
      "---- Training ----\n",
      "Training loss: 133.2354\n",
      "Training acc over epoch: 0.7453\n",
      "---- Validation ----\n",
      "Validation loss: 35.7930\n",
      "Validation acc: 0.7190\n",
      "Time taken: 10.88s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 438.7087, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 426.4422, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 20: 434.2659, Accuracy: 0.7303\n",
      "Training loss (for one batch) at step 30: 412.7336, Accuracy: 0.7326\n",
      "Training loss (for one batch) at step 40: 409.7482, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 50: 397.2141, Accuracy: 0.7572\n",
      "Training loss (for one batch) at step 60: 415.7007, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 70: 431.8504, Accuracy: 0.7591\n",
      "Training loss (for one batch) at step 80: 429.9760, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 90: 420.9791, Accuracy: 0.7512\n",
      "Training loss (for one batch) at step 100: 427.2852, Accuracy: 0.7471\n",
      "Training loss (for one batch) at step 110: 413.0866, Accuracy: 0.7461\n",
      "---- Training ----\n",
      "Training loss: 135.9107\n",
      "Training acc over epoch: 0.7468\n",
      "---- Validation ----\n",
      "Validation loss: 34.4987\n",
      "Validation acc: 0.7195\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 429.7807, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 421.5210, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 20: 421.5804, Accuracy: 0.7262\n",
      "Training loss (for one batch) at step 30: 418.3746, Accuracy: 0.7324\n",
      "Training loss (for one batch) at step 40: 403.0866, Accuracy: 0.7441\n",
      "Training loss (for one batch) at step 50: 384.7744, Accuracy: 0.7555\n",
      "Training loss (for one batch) at step 60: 415.1606, Accuracy: 0.7610\n",
      "Training loss (for one batch) at step 70: 431.2188, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 80: 427.2700, Accuracy: 0.7523\n",
      "Training loss (for one batch) at step 90: 423.2827, Accuracy: 0.7506\n",
      "Training loss (for one batch) at step 100: 417.5040, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 110: 417.2521, Accuracy: 0.7498\n",
      "---- Training ----\n",
      "Training loss: 129.4603\n",
      "Training acc over epoch: 0.7504\n",
      "---- Validation ----\n",
      "Validation loss: 38.8694\n",
      "Validation acc: 0.6607\n",
      "Time taken: 10.84s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 430.9729, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 423.3969, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 20: 428.6269, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 30: 413.1535, Accuracy: 0.7523\n",
      "Training loss (for one batch) at step 40: 409.1181, Accuracy: 0.7591\n",
      "Training loss (for one batch) at step 50: 398.6386, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 60: 395.4237, Accuracy: 0.7746\n",
      "Training loss (for one batch) at step 70: 417.5865, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 80: 423.7544, Accuracy: 0.7675\n",
      "Training loss (for one batch) at step 90: 426.0424, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 100: 408.3051, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 110: 409.6862, Accuracy: 0.7637\n",
      "---- Training ----\n",
      "Training loss: 138.5140\n",
      "Training acc over epoch: 0.7636\n",
      "---- Validation ----\n",
      "Validation loss: 35.2408\n",
      "Validation acc: 0.6967\n",
      "Time taken: 10.89s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 432.6553, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 422.8799, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 20: 420.3810, Accuracy: 0.7414\n",
      "Training loss (for one batch) at step 30: 412.9432, Accuracy: 0.7540\n",
      "Training loss (for one batch) at step 40: 398.0016, Accuracy: 0.7588\n",
      "Training loss (for one batch) at step 50: 391.2502, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 60: 411.4295, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 70: 422.3723, Accuracy: 0.7726\n",
      "Training loss (for one batch) at step 80: 428.4553, Accuracy: 0.7684\n",
      "Training loss (for one batch) at step 90: 424.4993, Accuracy: 0.7624\n",
      "Training loss (for one batch) at step 100: 410.4314, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 110: 404.8319, Accuracy: 0.7617\n",
      "---- Training ----\n",
      "Training loss: 128.2800\n",
      "Training acc over epoch: 0.7611\n",
      "---- Validation ----\n",
      "Validation loss: 35.4100\n",
      "Validation acc: 0.6996\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 424.2805, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 427.6921, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 420.6041, Accuracy: 0.7340\n",
      "Training loss (for one batch) at step 30: 409.3627, Accuracy: 0.7445\n",
      "Training loss (for one batch) at step 40: 397.6245, Accuracy: 0.7508\n",
      "Training loss (for one batch) at step 50: 368.3664, Accuracy: 0.7650\n",
      "Training loss (for one batch) at step 60: 404.0106, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 70: 426.3662, Accuracy: 0.7739\n",
      "Training loss (for one batch) at step 80: 415.4705, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 90: 416.4622, Accuracy: 0.7617\n",
      "Training loss (for one batch) at step 100: 417.2975, Accuracy: 0.7591\n",
      "Training loss (for one batch) at step 110: 415.6627, Accuracy: 0.7580\n",
      "---- Training ----\n",
      "Training loss: 123.3608\n",
      "Training acc over epoch: 0.7579\n",
      "---- Validation ----\n",
      "Validation loss: 33.6676\n",
      "Validation acc: 0.6913\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 445.2668, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 420.1591, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 410.7226, Accuracy: 0.7619\n",
      "Training loss (for one batch) at step 30: 410.0178, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 40: 401.7217, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 50: 384.4438, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 60: 395.9465, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 70: 417.0207, Accuracy: 0.7829\n",
      "Training loss (for one batch) at step 80: 423.3825, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 90: 411.1726, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 100: 418.2871, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 110: 407.2799, Accuracy: 0.7701\n",
      "---- Training ----\n",
      "Training loss: 127.1727\n",
      "Training acc over epoch: 0.7695\n",
      "---- Validation ----\n",
      "Validation loss: 34.1280\n",
      "Validation acc: 0.7147\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 432.8116, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 419.4887, Accuracy: 0.7607\n",
      "Training loss (for one batch) at step 20: 407.7722, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 30: 393.6370, Accuracy: 0.7616\n",
      "Training loss (for one batch) at step 40: 379.7012, Accuracy: 0.7710\n",
      "Training loss (for one batch) at step 50: 378.3450, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 60: 379.3396, Accuracy: 0.7859\n",
      "Training loss (for one batch) at step 70: 407.6428, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 80: 405.1458, Accuracy: 0.7762\n",
      "Training loss (for one batch) at step 90: 408.0210, Accuracy: 0.7724\n",
      "Training loss (for one batch) at step 100: 398.4305, Accuracy: 0.7724\n",
      "Training loss (for one batch) at step 110: 410.0439, Accuracy: 0.7733\n",
      "---- Training ----\n",
      "Training loss: 125.7832\n",
      "Training acc over epoch: 0.7730\n",
      "---- Validation ----\n",
      "Validation loss: 34.4065\n",
      "Validation acc: 0.7187\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 410.3247, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 426.0948, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 20: 410.8600, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 30: 397.9705, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 40: 383.6266, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 50: 366.4194, Accuracy: 0.7842\n",
      "Training loss (for one batch) at step 60: 401.7650, Accuracy: 0.7878\n",
      "Training loss (for one batch) at step 70: 410.1183, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 80: 408.1049, Accuracy: 0.7788\n",
      "Training loss (for one batch) at step 90: 399.5641, Accuracy: 0.7769\n",
      "Training loss (for one batch) at step 100: 400.6605, Accuracy: 0.7793\n",
      "Training loss (for one batch) at step 110: 378.8099, Accuracy: 0.7779\n",
      "---- Training ----\n",
      "Training loss: 127.9656\n",
      "Training acc over epoch: 0.7770\n",
      "---- Validation ----\n",
      "Validation loss: 36.2071\n",
      "Validation acc: 0.7262\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 413.6915, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 413.9745, Accuracy: 0.7372\n",
      "Training loss (for one batch) at step 20: 403.0585, Accuracy: 0.7392\n",
      "Training loss (for one batch) at step 30: 396.7433, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 40: 383.6606, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 50: 366.5514, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 60: 386.6046, Accuracy: 0.7862\n",
      "Training loss (for one batch) at step 70: 405.8318, Accuracy: 0.7859\n",
      "Training loss (for one batch) at step 80: 403.1099, Accuracy: 0.7795\n",
      "Training loss (for one batch) at step 90: 391.5747, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 100: 391.3703, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 110: 401.3687, Accuracy: 0.7773\n",
      "---- Training ----\n",
      "Training loss: 132.3858\n",
      "Training acc over epoch: 0.7767\n",
      "---- Validation ----\n",
      "Validation loss: 36.5697\n",
      "Validation acc: 0.7155\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 418.1769, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 398.3801, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 20: 396.6600, Accuracy: 0.7541\n",
      "Training loss (for one batch) at step 30: 403.1535, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 40: 389.6132, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 50: 358.0021, Accuracy: 0.7826\n",
      "Training loss (for one batch) at step 60: 392.0717, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 70: 391.5977, Accuracy: 0.7887\n",
      "Training loss (for one batch) at step 80: 405.4630, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 90: 387.3339, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 100: 392.6043, Accuracy: 0.7788\n",
      "Training loss (for one batch) at step 110: 392.5064, Accuracy: 0.7783\n",
      "---- Training ----\n",
      "Training loss: 128.9025\n",
      "Training acc over epoch: 0.7775\n",
      "---- Validation ----\n",
      "Validation loss: 40.8147\n",
      "Validation acc: 0.7053\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 413.1409, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 410.3947, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 391.8803, Accuracy: 0.7582\n",
      "Training loss (for one batch) at step 30: 396.9505, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 40: 378.9360, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 50: 362.0334, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 60: 374.7625, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 70: 390.9774, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 80: 413.2372, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 90: 388.4741, Accuracy: 0.7869\n",
      "Training loss (for one batch) at step 100: 370.9189, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 110: 391.8703, Accuracy: 0.7853\n",
      "---- Training ----\n",
      "Training loss: 122.4851\n",
      "Training acc over epoch: 0.7847\n",
      "---- Validation ----\n",
      "Validation loss: 44.7972\n",
      "Validation acc: 0.7028\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 424.2936, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 403.6156, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 389.4046, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 383.7380, Accuracy: 0.7707\n",
      "Training loss (for one batch) at step 40: 381.1536, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 50: 368.1190, Accuracy: 0.7964\n",
      "Training loss (for one batch) at step 60: 362.7986, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 70: 381.7095, Accuracy: 0.7981\n",
      "Training loss (for one batch) at step 80: 405.9481, Accuracy: 0.7916\n",
      "Training loss (for one batch) at step 90: 389.7178, Accuracy: 0.7878\n",
      "Training loss (for one batch) at step 100: 397.0526, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 110: 394.3173, Accuracy: 0.7896\n",
      "---- Training ----\n",
      "Training loss: 121.3109\n",
      "Training acc over epoch: 0.7889\n",
      "---- Validation ----\n",
      "Validation loss: 40.0840\n",
      "Validation acc: 0.7160\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 412.9378, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 406.9643, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 20: 372.9971, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 30: 375.5010, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 40: 372.8015, Accuracy: 0.7902\n",
      "Training loss (for one batch) at step 50: 361.0094, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 60: 398.1082, Accuracy: 0.8067\n",
      "Training loss (for one batch) at step 70: 389.1958, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 80: 386.7775, Accuracy: 0.7967\n",
      "Training loss (for one batch) at step 90: 407.8330, Accuracy: 0.7927\n",
      "Training loss (for one batch) at step 100: 373.8884, Accuracy: 0.7946\n",
      "Training loss (for one batch) at step 110: 390.4841, Accuracy: 0.7938\n",
      "---- Training ----\n",
      "Training loss: 123.8352\n",
      "Training acc over epoch: 0.7936\n",
      "---- Validation ----\n",
      "Validation loss: 49.8958\n",
      "Validation acc: 0.6983\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 408.3546, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 408.5825, Accuracy: 0.7564\n",
      "Training loss (for one batch) at step 20: 391.9331, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 30: 375.8261, Accuracy: 0.7833\n",
      "Training loss (for one batch) at step 40: 363.1951, Accuracy: 0.7913\n",
      "Training loss (for one batch) at step 50: 353.0927, Accuracy: 0.7989\n",
      "Training loss (for one batch) at step 60: 359.4978, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 70: 392.2147, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 80: 391.7343, Accuracy: 0.7978\n",
      "Training loss (for one batch) at step 90: 380.7877, Accuracy: 0.7938\n",
      "Training loss (for one batch) at step 100: 360.9712, Accuracy: 0.7929\n",
      "Training loss (for one batch) at step 110: 382.5118, Accuracy: 0.7925\n",
      "---- Training ----\n",
      "Training loss: 118.4395\n",
      "Training acc over epoch: 0.7919\n",
      "---- Validation ----\n",
      "Validation loss: 34.1441\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 399.1223, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 404.1400, Accuracy: 0.7571\n",
      "Training loss (for one batch) at step 20: 384.9554, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 30: 365.5497, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 40: 366.1874, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 50: 374.6294, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 60: 372.8944, Accuracy: 0.8099\n",
      "Training loss (for one batch) at step 70: 375.9159, Accuracy: 0.8029\n",
      "Training loss (for one batch) at step 80: 398.4739, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 90: 367.6290, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 100: 370.3765, Accuracy: 0.7940\n",
      "Training loss (for one batch) at step 110: 368.2733, Accuracy: 0.7936\n",
      "---- Training ----\n",
      "Training loss: 123.8157\n",
      "Training acc over epoch: 0.7938\n",
      "---- Validation ----\n",
      "Validation loss: 44.4464\n",
      "Validation acc: 0.7136\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 407.3552, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 392.8962, Accuracy: 0.7628\n",
      "Training loss (for one batch) at step 20: 393.3233, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 30: 365.6352, Accuracy: 0.7825\n",
      "Training loss (for one batch) at step 40: 353.1513, Accuracy: 0.7934\n",
      "Training loss (for one batch) at step 50: 345.6324, Accuracy: 0.8050\n",
      "Training loss (for one batch) at step 60: 347.6489, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 70: 390.5570, Accuracy: 0.8059\n",
      "Training loss (for one batch) at step 80: 385.2084, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 90: 367.7136, Accuracy: 0.7953\n",
      "Training loss (for one batch) at step 100: 368.9287, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 110: 375.2042, Accuracy: 0.7956\n",
      "---- Training ----\n",
      "Training loss: 120.7064\n",
      "Training acc over epoch: 0.7942\n",
      "---- Validation ----\n",
      "Validation loss: 36.5788\n",
      "Validation acc: 0.7039\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 407.2733, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 379.3918, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 364.3611, Accuracy: 0.7615\n",
      "Training loss (for one batch) at step 30: 377.7132, Accuracy: 0.7785\n",
      "Training loss (for one batch) at step 40: 369.6188, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 50: 350.1053, Accuracy: 0.8038\n",
      "Training loss (for one batch) at step 60: 359.3338, Accuracy: 0.8084\n",
      "Training loss (for one batch) at step 70: 406.5550, Accuracy: 0.8008\n",
      "Training loss (for one batch) at step 80: 389.5894, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 90: 385.3188, Accuracy: 0.7927\n",
      "Training loss (for one batch) at step 100: 361.1872, Accuracy: 0.7930\n",
      "Training loss (for one batch) at step 110: 379.0240, Accuracy: 0.7929\n",
      "---- Training ----\n",
      "Training loss: 117.0762\n",
      "Training acc over epoch: 0.7922\n",
      "---- Validation ----\n",
      "Validation loss: 47.0488\n",
      "Validation acc: 0.7217\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 406.4581, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 375.3742, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 20: 361.9120, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 30: 367.3242, Accuracy: 0.7787\n",
      "Training loss (for one batch) at step 40: 357.5832, Accuracy: 0.7938\n",
      "Training loss (for one batch) at step 50: 357.4009, Accuracy: 0.8074\n",
      "Training loss (for one batch) at step 60: 361.4462, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 70: 380.7271, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 80: 371.8760, Accuracy: 0.8003\n",
      "Training loss (for one batch) at step 90: 379.6342, Accuracy: 0.7973\n",
      "Training loss (for one batch) at step 100: 366.8744, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 110: 365.2514, Accuracy: 0.7982\n",
      "---- Training ----\n",
      "Training loss: 119.8499\n",
      "Training acc over epoch: 0.7974\n",
      "---- Validation ----\n",
      "Validation loss: 45.4854\n",
      "Validation acc: 0.7289\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 388.8871, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 386.9016, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 381.0688, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 30: 355.8572, Accuracy: 0.7863\n",
      "Training loss (for one batch) at step 40: 346.4977, Accuracy: 0.7992\n",
      "Training loss (for one batch) at step 50: 329.2347, Accuracy: 0.8091\n",
      "Training loss (for one batch) at step 60: 343.4638, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 70: 368.0228, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 80: 375.8720, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 90: 367.5728, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 100: 379.1177, Accuracy: 0.8005\n",
      "Training loss (for one batch) at step 110: 364.1612, Accuracy: 0.7999\n",
      "---- Training ----\n",
      "Training loss: 119.2330\n",
      "Training acc over epoch: 0.7979\n",
      "---- Validation ----\n",
      "Validation loss: 39.9503\n",
      "Validation acc: 0.7227\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 392.2177, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 368.3115, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 20: 363.9914, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 352.5081, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 40: 348.3288, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 50: 361.9636, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 60: 351.6726, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 70: 372.5592, Accuracy: 0.8105\n",
      "Training loss (for one batch) at step 80: 369.0617, Accuracy: 0.8043\n",
      "Training loss (for one batch) at step 90: 363.2688, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 100: 362.4199, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 110: 355.7703, Accuracy: 0.8016\n",
      "---- Training ----\n",
      "Training loss: 114.5746\n",
      "Training acc over epoch: 0.8006\n",
      "---- Validation ----\n",
      "Validation loss: 48.1645\n",
      "Validation acc: 0.7198\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 377.5089, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 370.6593, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 363.5410, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 30: 353.9960, Accuracy: 0.7860\n",
      "Training loss (for one batch) at step 40: 346.6400, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 50: 358.5381, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 60: 372.3798, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 70: 370.3632, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 80: 380.1111, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 90: 385.7486, Accuracy: 0.8013\n",
      "Training loss (for one batch) at step 100: 362.3351, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 110: 354.2376, Accuracy: 0.8020\n",
      "---- Training ----\n",
      "Training loss: 111.7475\n",
      "Training acc over epoch: 0.8012\n",
      "---- Validation ----\n",
      "Validation loss: 43.0925\n",
      "Validation acc: 0.7117\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 395.4905, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 374.0870, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 20: 351.9620, Accuracy: 0.7693\n",
      "Training loss (for one batch) at step 30: 346.5001, Accuracy: 0.7858\n",
      "Training loss (for one batch) at step 40: 338.2655, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 50: 334.1177, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 60: 368.4984, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 70: 371.7209, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 80: 365.5786, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 90: 345.8377, Accuracy: 0.8031\n",
      "Training loss (for one batch) at step 100: 371.4329, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 110: 387.7988, Accuracy: 0.8026\n",
      "---- Training ----\n",
      "Training loss: 117.1926\n",
      "Training acc over epoch: 0.8019\n",
      "---- Validation ----\n",
      "Validation loss: 39.7929\n",
      "Validation acc: 0.7147\n",
      "Time taken: 10.40s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7291\n",
      "Validation AUC: 0.7301\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 605.0251, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 544.5667, Accuracy: 0.5114\n",
      "Training loss (for one batch) at step 20: 551.0334, Accuracy: 0.5104\n",
      "Training loss (for one batch) at step 30: 513.0886, Accuracy: 0.5073\n",
      "Training loss (for one batch) at step 40: 520.7128, Accuracy: 0.5082\n",
      "Training loss (for one batch) at step 50: 501.7031, Accuracy: 0.5106\n",
      "Training loss (for one batch) at step 60: 480.0063, Accuracy: 0.5092\n",
      "Training loss (for one batch) at step 70: 466.2759, Accuracy: 0.5153\n",
      "Training loss (for one batch) at step 80: 481.4038, Accuracy: 0.5129\n",
      "Training loss (for one batch) at step 90: 460.3466, Accuracy: 0.5134\n",
      "Training loss (for one batch) at step 100: 463.9949, Accuracy: 0.5123\n",
      "Training loss (for one batch) at step 110: 473.1273, Accuracy: 0.5108\n",
      "---- Training ----\n",
      "Training loss: 145.4581\n",
      "Training acc over epoch: 0.5099\n",
      "---- Validation ----\n",
      "Validation loss: 34.8530\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.44s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 466.6808, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 449.3246, Accuracy: 0.5320\n",
      "Training loss (for one batch) at step 20: 453.1985, Accuracy: 0.5219\n",
      "Training loss (for one batch) at step 30: 450.7321, Accuracy: 0.5227\n",
      "Training loss (for one batch) at step 40: 449.2645, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 50: 456.2874, Accuracy: 0.5187\n",
      "Training loss (for one batch) at step 60: 447.2719, Accuracy: 0.5192\n",
      "Training loss (for one batch) at step 70: 449.9562, Accuracy: 0.5207\n",
      "Training loss (for one batch) at step 80: 453.9806, Accuracy: 0.5217\n",
      "Training loss (for one batch) at step 90: 449.3394, Accuracy: 0.5204\n",
      "Training loss (for one batch) at step 100: 445.3478, Accuracy: 0.5190\n",
      "Training loss (for one batch) at step 110: 445.4092, Accuracy: 0.5196\n",
      "---- Training ----\n",
      "Training loss: 143.6037\n",
      "Training acc over epoch: 0.5195\n",
      "---- Validation ----\n",
      "Validation loss: 34.7499\n",
      "Validation acc: 0.5320\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.0492, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 442.5712, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 20: 444.9673, Accuracy: 0.5350\n",
      "Training loss (for one batch) at step 30: 447.8469, Accuracy: 0.5239\n",
      "Training loss (for one batch) at step 40: 447.9520, Accuracy: 0.5272\n",
      "Training loss (for one batch) at step 50: 449.6424, Accuracy: 0.5296\n",
      "Training loss (for one batch) at step 60: 447.5179, Accuracy: 0.5310\n",
      "Training loss (for one batch) at step 70: 445.6644, Accuracy: 0.5321\n",
      "Training loss (for one batch) at step 80: 442.5732, Accuracy: 0.5347\n",
      "Training loss (for one batch) at step 90: 444.6058, Accuracy: 0.5355\n",
      "Training loss (for one batch) at step 100: 444.2971, Accuracy: 0.5332\n",
      "Training loss (for one batch) at step 110: 445.2523, Accuracy: 0.5348\n",
      "---- Training ----\n",
      "Training loss: 141.2129\n",
      "Training acc over epoch: 0.5334\n",
      "---- Validation ----\n",
      "Validation loss: 34.4743\n",
      "Validation acc: 0.5204\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 445.0464, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 444.5000, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 20: 446.5576, Accuracy: 0.5517\n",
      "Training loss (for one batch) at step 30: 445.8015, Accuracy: 0.5368\n",
      "Training loss (for one batch) at step 40: 443.8031, Accuracy: 0.5408\n",
      "Training loss (for one batch) at step 50: 444.7977, Accuracy: 0.5363\n",
      "Training loss (for one batch) at step 60: 444.9520, Accuracy: 0.5332\n",
      "Training loss (for one batch) at step 70: 442.8688, Accuracy: 0.5383\n",
      "Training loss (for one batch) at step 80: 443.4659, Accuracy: 0.5424\n",
      "Training loss (for one batch) at step 90: 443.5365, Accuracy: 0.5457\n",
      "Training loss (for one batch) at step 100: 443.2845, Accuracy: 0.5459\n",
      "Training loss (for one batch) at step 110: 444.0018, Accuracy: 0.5453\n",
      "---- Training ----\n",
      "Training loss: 138.9465\n",
      "Training acc over epoch: 0.5449\n",
      "---- Validation ----\n",
      "Validation loss: 34.9262\n",
      "Validation acc: 0.5508\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 444.8136, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 444.0764, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 20: 443.2575, Accuracy: 0.5610\n",
      "Training loss (for one batch) at step 30: 442.7341, Accuracy: 0.5633\n",
      "Training loss (for one batch) at step 40: 442.3358, Accuracy: 0.5631\n",
      "Training loss (for one batch) at step 50: 442.5011, Accuracy: 0.5657\n",
      "Training loss (for one batch) at step 60: 443.8582, Accuracy: 0.5688\n",
      "Training loss (for one batch) at step 70: 443.6063, Accuracy: 0.5727\n",
      "Training loss (for one batch) at step 80: 444.4873, Accuracy: 0.5738\n",
      "Training loss (for one batch) at step 90: 444.5341, Accuracy: 0.5748\n",
      "Training loss (for one batch) at step 100: 444.0406, Accuracy: 0.5759\n",
      "Training loss (for one batch) at step 110: 443.5557, Accuracy: 0.5752\n",
      "---- Training ----\n",
      "Training loss: 137.6463\n",
      "Training acc over epoch: 0.5758\n",
      "---- Validation ----\n",
      "Validation loss: 34.2939\n",
      "Validation acc: 0.5916\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 441.7565, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 442.6701, Accuracy: 0.6122\n",
      "Training loss (for one batch) at step 20: 442.5141, Accuracy: 0.6023\n",
      "Training loss (for one batch) at step 30: 443.4738, Accuracy: 0.5968\n",
      "Training loss (for one batch) at step 40: 440.7192, Accuracy: 0.6035\n",
      "Training loss (for one batch) at step 50: 444.1694, Accuracy: 0.6065\n",
      "Training loss (for one batch) at step 60: 442.9859, Accuracy: 0.6043\n",
      "Training loss (for one batch) at step 70: 443.2065, Accuracy: 0.6035\n",
      "Training loss (for one batch) at step 80: 446.3236, Accuracy: 0.6052\n",
      "Training loss (for one batch) at step 90: 443.8695, Accuracy: 0.6048\n",
      "Training loss (for one batch) at step 100: 441.2282, Accuracy: 0.6033\n",
      "Training loss (for one batch) at step 110: 443.2810, Accuracy: 0.6026\n",
      "---- Training ----\n",
      "Training loss: 137.4885\n",
      "Training acc over epoch: 0.6025\n",
      "---- Validation ----\n",
      "Validation loss: 34.6854\n",
      "Validation acc: 0.6419\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.6264, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 443.7756, Accuracy: 0.6506\n",
      "Training loss (for one batch) at step 20: 442.7784, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 30: 443.8924, Accuracy: 0.6245\n",
      "Training loss (for one batch) at step 40: 439.1091, Accuracy: 0.6311\n",
      "Training loss (for one batch) at step 50: 440.0261, Accuracy: 0.6317\n",
      "Training loss (for one batch) at step 60: 440.1801, Accuracy: 0.6301\n",
      "Training loss (for one batch) at step 70: 443.5501, Accuracy: 0.6273\n",
      "Training loss (for one batch) at step 80: 442.2708, Accuracy: 0.6277\n",
      "Training loss (for one batch) at step 90: 440.3801, Accuracy: 0.6300\n",
      "Training loss (for one batch) at step 100: 437.2092, Accuracy: 0.6300\n",
      "Training loss (for one batch) at step 110: 441.4358, Accuracy: 0.6306\n",
      "---- Training ----\n",
      "Training loss: 137.9424\n",
      "Training acc over epoch: 0.6312\n",
      "---- Validation ----\n",
      "Validation loss: 34.4084\n",
      "Validation acc: 0.6464\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 441.6128, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 439.3462, Accuracy: 0.6335\n",
      "Training loss (for one batch) at step 20: 441.5895, Accuracy: 0.6332\n",
      "Training loss (for one batch) at step 30: 442.2762, Accuracy: 0.6275\n",
      "Training loss (for one batch) at step 40: 438.2638, Accuracy: 0.6292\n",
      "Training loss (for one batch) at step 50: 440.0585, Accuracy: 0.6314\n",
      "Training loss (for one batch) at step 60: 440.5039, Accuracy: 0.6327\n",
      "Training loss (for one batch) at step 70: 447.1926, Accuracy: 0.6352\n",
      "Training loss (for one batch) at step 80: 444.2116, Accuracy: 0.6345\n",
      "Training loss (for one batch) at step 90: 440.5771, Accuracy: 0.6375\n",
      "Training loss (for one batch) at step 100: 441.1624, Accuracy: 0.6412\n",
      "Training loss (for one batch) at step 110: 438.3698, Accuracy: 0.6410\n",
      "---- Training ----\n",
      "Training loss: 137.7931\n",
      "Training acc over epoch: 0.6422\n",
      "---- Validation ----\n",
      "Validation loss: 34.6107\n",
      "Validation acc: 0.6445\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 439.0265, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 440.6082, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 439.4775, Accuracy: 0.6514\n",
      "Training loss (for one batch) at step 30: 439.0267, Accuracy: 0.6547\n",
      "Training loss (for one batch) at step 40: 439.3684, Accuracy: 0.6561\n",
      "Training loss (for one batch) at step 50: 439.3394, Accuracy: 0.6558\n",
      "Training loss (for one batch) at step 60: 440.0454, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 70: 443.2005, Accuracy: 0.6565\n",
      "Training loss (for one batch) at step 80: 438.8755, Accuracy: 0.6560\n",
      "Training loss (for one batch) at step 90: 439.0042, Accuracy: 0.6522\n",
      "Training loss (for one batch) at step 100: 442.6147, Accuracy: 0.6530\n",
      "Training loss (for one batch) at step 110: 431.3370, Accuracy: 0.6527\n",
      "---- Training ----\n",
      "Training loss: 140.2979\n",
      "Training acc over epoch: 0.6540\n",
      "---- Validation ----\n",
      "Validation loss: 34.8549\n",
      "Validation acc: 0.6249\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 445.6483, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 441.8634, Accuracy: 0.6570\n",
      "Training loss (for one batch) at step 20: 444.1332, Accuracy: 0.6663\n",
      "Training loss (for one batch) at step 30: 438.8226, Accuracy: 0.6699\n",
      "Training loss (for one batch) at step 40: 434.0734, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 50: 436.5216, Accuracy: 0.6762\n",
      "Training loss (for one batch) at step 60: 437.7603, Accuracy: 0.6760\n",
      "Training loss (for one batch) at step 70: 434.8879, Accuracy: 0.6776\n",
      "Training loss (for one batch) at step 80: 444.0449, Accuracy: 0.6742\n",
      "Training loss (for one batch) at step 90: 441.3304, Accuracy: 0.6715\n",
      "Training loss (for one batch) at step 100: 439.6101, Accuracy: 0.6716\n",
      "Training loss (for one batch) at step 110: 439.8416, Accuracy: 0.6716\n",
      "---- Training ----\n",
      "Training loss: 136.5632\n",
      "Training acc over epoch: 0.6713\n",
      "---- Validation ----\n",
      "Validation loss: 34.7367\n",
      "Validation acc: 0.6408\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 442.7203, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 445.3193, Accuracy: 0.6832\n",
      "Training loss (for one batch) at step 20: 439.7805, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 30: 435.0955, Accuracy: 0.6885\n",
      "Training loss (for one batch) at step 40: 437.2281, Accuracy: 0.6904\n",
      "Training loss (for one batch) at step 50: 444.2565, Accuracy: 0.6922\n",
      "Training loss (for one batch) at step 60: 429.8965, Accuracy: 0.6979\n",
      "Training loss (for one batch) at step 70: 441.2644, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 80: 442.2682, Accuracy: 0.6931\n",
      "Training loss (for one batch) at step 90: 441.7881, Accuracy: 0.6916\n",
      "Training loss (for one batch) at step 100: 435.7354, Accuracy: 0.6938\n",
      "Training loss (for one batch) at step 110: 437.9857, Accuracy: 0.6938\n",
      "---- Training ----\n",
      "Training loss: 133.7813\n",
      "Training acc over epoch: 0.6943\n",
      "---- Validation ----\n",
      "Validation loss: 35.8579\n",
      "Validation acc: 0.6840\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 441.9413, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 438.3977, Accuracy: 0.7053\n",
      "Training loss (for one batch) at step 20: 435.6586, Accuracy: 0.6972\n",
      "Training loss (for one batch) at step 30: 428.5862, Accuracy: 0.7026\n",
      "Training loss (for one batch) at step 40: 428.3530, Accuracy: 0.7079\n",
      "Training loss (for one batch) at step 50: 427.7107, Accuracy: 0.7129\n",
      "Training loss (for one batch) at step 60: 445.4165, Accuracy: 0.7163\n",
      "Training loss (for one batch) at step 70: 445.4236, Accuracy: 0.7181\n",
      "Training loss (for one batch) at step 80: 439.8085, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 90: 439.5867, Accuracy: 0.7030\n",
      "Training loss (for one batch) at step 100: 433.2953, Accuracy: 0.7066\n",
      "Training loss (for one batch) at step 110: 433.1398, Accuracy: 0.7091\n",
      "---- Training ----\n",
      "Training loss: 137.3374\n",
      "Training acc over epoch: 0.7097\n",
      "---- Validation ----\n",
      "Validation loss: 34.6461\n",
      "Validation acc: 0.6709\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 441.9243, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 439.0939, Accuracy: 0.7067\n",
      "Training loss (for one batch) at step 20: 434.0100, Accuracy: 0.7009\n",
      "Training loss (for one batch) at step 30: 435.8661, Accuracy: 0.7006\n",
      "Training loss (for one batch) at step 40: 428.2717, Accuracy: 0.7113\n",
      "Training loss (for one batch) at step 50: 423.0454, Accuracy: 0.7215\n",
      "Training loss (for one batch) at step 60: 441.8419, Accuracy: 0.7267\n",
      "Training loss (for one batch) at step 70: 436.1181, Accuracy: 0.7312\n",
      "Training loss (for one batch) at step 80: 434.9467, Accuracy: 0.7297\n",
      "Training loss (for one batch) at step 90: 432.0206, Accuracy: 0.7277\n",
      "Training loss (for one batch) at step 100: 428.5531, Accuracy: 0.7306\n",
      "Training loss (for one batch) at step 110: 441.5598, Accuracy: 0.7321\n",
      "---- Training ----\n",
      "Training loss: 134.3213\n",
      "Training acc over epoch: 0.7316\n",
      "---- Validation ----\n",
      "Validation loss: 35.1431\n",
      "Validation acc: 0.7319\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 436.9554, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 438.9192, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 433.7158, Accuracy: 0.7184\n",
      "Training loss (for one batch) at step 30: 431.1545, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 40: 416.7839, Accuracy: 0.7309\n",
      "Training loss (for one batch) at step 50: 427.6765, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 60: 431.9368, Accuracy: 0.7512\n",
      "Training loss (for one batch) at step 70: 433.6118, Accuracy: 0.7468\n",
      "Training loss (for one batch) at step 80: 439.5134, Accuracy: 0.7446\n",
      "Training loss (for one batch) at step 90: 429.7159, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 100: 433.4646, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 110: 432.9151, Accuracy: 0.7457\n",
      "---- Training ----\n",
      "Training loss: 136.4098\n",
      "Training acc over epoch: 0.7466\n",
      "---- Validation ----\n",
      "Validation loss: 32.5486\n",
      "Validation acc: 0.7251\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 447.5649, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 436.8383, Accuracy: 0.6932\n",
      "Training loss (for one batch) at step 20: 428.6530, Accuracy: 0.7009\n",
      "Training loss (for one batch) at step 30: 431.0487, Accuracy: 0.7152\n",
      "Training loss (for one batch) at step 40: 414.1715, Accuracy: 0.7298\n",
      "Training loss (for one batch) at step 50: 414.1793, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 60: 419.2191, Accuracy: 0.7495\n",
      "Training loss (for one batch) at step 70: 434.2700, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 80: 442.0850, Accuracy: 0.7447\n",
      "Training loss (for one batch) at step 90: 429.7233, Accuracy: 0.7430\n",
      "Training loss (for one batch) at step 100: 426.1918, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 110: 426.2373, Accuracy: 0.7455\n",
      "---- Training ----\n",
      "Training loss: 133.0829\n",
      "Training acc over epoch: 0.7472\n",
      "---- Validation ----\n",
      "Validation loss: 34.9435\n",
      "Validation acc: 0.7182\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 445.5475, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 431.4007, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 20: 434.2342, Accuracy: 0.7336\n",
      "Training loss (for one batch) at step 30: 423.5677, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 40: 410.3152, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 50: 410.2487, Accuracy: 0.7626\n",
      "Training loss (for one batch) at step 60: 424.8706, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 70: 434.2668, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 80: 441.0482, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 90: 427.5070, Accuracy: 0.7572\n",
      "Training loss (for one batch) at step 100: 432.5474, Accuracy: 0.7554\n",
      "Training loss (for one batch) at step 110: 431.6598, Accuracy: 0.7561\n",
      "---- Training ----\n",
      "Training loss: 139.1720\n",
      "Training acc over epoch: 0.7569\n",
      "---- Validation ----\n",
      "Validation loss: 37.8874\n",
      "Validation acc: 0.7474\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 446.2230, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 430.6662, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 20: 425.8503, Accuracy: 0.7299\n",
      "Training loss (for one batch) at step 30: 422.6122, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 40: 401.1754, Accuracy: 0.7540\n",
      "Training loss (for one batch) at step 50: 392.2582, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 60: 420.2725, Accuracy: 0.7747\n",
      "Training loss (for one batch) at step 70: 434.1396, Accuracy: 0.7728\n",
      "Training loss (for one batch) at step 80: 444.4399, Accuracy: 0.7616\n",
      "Training loss (for one batch) at step 90: 434.4425, Accuracy: 0.7579\n",
      "Training loss (for one batch) at step 100: 430.1036, Accuracy: 0.7573\n",
      "Training loss (for one batch) at step 110: 431.1755, Accuracy: 0.7580\n",
      "---- Training ----\n",
      "Training loss: 141.0591\n",
      "Training acc over epoch: 0.7582\n",
      "---- Validation ----\n",
      "Validation loss: 36.3844\n",
      "Validation acc: 0.7418\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 437.6491, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 435.7327, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 434.0615, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 30: 418.0869, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 40: 401.2924, Accuracy: 0.7700\n",
      "Training loss (for one batch) at step 50: 405.7189, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 60: 429.1207, Accuracy: 0.7909\n",
      "Training loss (for one batch) at step 70: 445.5611, Accuracy: 0.7844\n",
      "Training loss (for one batch) at step 80: 437.4283, Accuracy: 0.7756\n",
      "Training loss (for one batch) at step 90: 433.5261, Accuracy: 0.7684\n",
      "Training loss (for one batch) at step 100: 418.6404, Accuracy: 0.7698\n",
      "Training loss (for one batch) at step 110: 425.8020, Accuracy: 0.7703\n",
      "---- Training ----\n",
      "Training loss: 135.5797\n",
      "Training acc over epoch: 0.7713\n",
      "---- Validation ----\n",
      "Validation loss: 36.1228\n",
      "Validation acc: 0.7217\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 445.3947, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 436.0132, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 20: 425.1625, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 30: 411.2798, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 40: 409.1453, Accuracy: 0.7651\n",
      "Training loss (for one batch) at step 50: 401.5023, Accuracy: 0.7814\n",
      "Training loss (for one batch) at step 60: 405.5381, Accuracy: 0.7915\n",
      "Training loss (for one batch) at step 70: 437.2940, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 80: 431.0583, Accuracy: 0.7798\n",
      "Training loss (for one batch) at step 90: 434.0247, Accuracy: 0.7751\n",
      "Training loss (for one batch) at step 100: 423.3697, Accuracy: 0.7733\n",
      "Training loss (for one batch) at step 110: 417.9587, Accuracy: 0.7718\n",
      "---- Training ----\n",
      "Training loss: 133.5462\n",
      "Training acc over epoch: 0.7716\n",
      "---- Validation ----\n",
      "Validation loss: 34.4167\n",
      "Validation acc: 0.7544\n",
      "Time taken: 10.91s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 436.4363, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 425.1180, Accuracy: 0.7592\n",
      "Training loss (for one batch) at step 20: 424.5480, Accuracy: 0.7545\n",
      "Training loss (for one batch) at step 30: 421.5117, Accuracy: 0.7644\n",
      "Training loss (for one batch) at step 40: 400.6258, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 50: 388.7424, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 60: 424.0260, Accuracy: 0.7946\n",
      "Training loss (for one batch) at step 70: 463.2023, Accuracy: 0.7940\n",
      "Training loss (for one batch) at step 80: 438.1499, Accuracy: 0.7864\n",
      "Training loss (for one batch) at step 90: 424.1879, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 100: 421.8504, Accuracy: 0.7779\n",
      "Training loss (for one batch) at step 110: 423.2937, Accuracy: 0.7795\n",
      "---- Training ----\n",
      "Training loss: 131.1021\n",
      "Training acc over epoch: 0.7782\n",
      "---- Validation ----\n",
      "Validation loss: 39.6825\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 447.0135, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 427.8215, Accuracy: 0.7564\n",
      "Training loss (for one batch) at step 20: 423.7841, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 30: 413.3716, Accuracy: 0.7583\n",
      "Training loss (for one batch) at step 40: 400.6579, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 50: 393.4052, Accuracy: 0.7823\n",
      "Training loss (for one batch) at step 60: 425.1663, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 70: 412.3115, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 80: 426.2906, Accuracy: 0.7844\n",
      "Training loss (for one batch) at step 90: 439.7326, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 100: 418.8139, Accuracy: 0.7795\n",
      "Training loss (for one batch) at step 110: 420.8085, Accuracy: 0.7799\n",
      "---- Training ----\n",
      "Training loss: 133.3708\n",
      "Training acc over epoch: 0.7799\n",
      "---- Validation ----\n",
      "Validation loss: 33.3948\n",
      "Validation acc: 0.7426\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 445.8486, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 423.9804, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 20: 411.3629, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 30: 400.5061, Accuracy: 0.7752\n",
      "Training loss (for one batch) at step 40: 387.2231, Accuracy: 0.7832\n",
      "Training loss (for one batch) at step 50: 388.9752, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 60: 404.3869, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 70: 414.5607, Accuracy: 0.8026\n",
      "Training loss (for one batch) at step 80: 425.9395, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 90: 420.9582, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 100: 418.1498, Accuracy: 0.7872\n",
      "Training loss (for one batch) at step 110: 410.8361, Accuracy: 0.7883\n",
      "---- Training ----\n",
      "Training loss: 131.6875\n",
      "Training acc over epoch: 0.7889\n",
      "---- Validation ----\n",
      "Validation loss: 34.2615\n",
      "Validation acc: 0.7520\n",
      "Time taken: 11.03s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 434.0688, Accuracy: 0.8672\n",
      "Training loss (for one batch) at step 10: 427.9867, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 20: 405.2159, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 30: 401.4566, Accuracy: 0.7853\n",
      "Training loss (for one batch) at step 40: 386.7697, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 50: 372.1672, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 60: 398.5629, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 70: 416.5367, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 80: 429.7616, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 90: 425.3032, Accuracy: 0.7970\n",
      "Training loss (for one batch) at step 100: 415.3462, Accuracy: 0.7967\n",
      "Training loss (for one batch) at step 110: 422.6098, Accuracy: 0.7955\n",
      "---- Training ----\n",
      "Training loss: 130.3506\n",
      "Training acc over epoch: 0.7943\n",
      "---- Validation ----\n",
      "Validation loss: 36.5691\n",
      "Validation acc: 0.7018\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 439.2560, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 426.8430, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 417.5359, Accuracy: 0.7686\n",
      "Training loss (for one batch) at step 30: 407.7787, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 40: 375.9506, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 50: 379.8923, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 60: 408.0451, Accuracy: 0.8172\n",
      "Training loss (for one batch) at step 70: 416.3535, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 80: 427.5470, Accuracy: 0.8074\n",
      "Training loss (for one batch) at step 90: 413.9370, Accuracy: 0.8029\n",
      "Training loss (for one batch) at step 100: 400.6057, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 110: 420.0811, Accuracy: 0.8000\n",
      "---- Training ----\n",
      "Training loss: 122.4077\n",
      "Training acc over epoch: 0.7992\n",
      "---- Validation ----\n",
      "Validation loss: 33.4064\n",
      "Validation acc: 0.7512\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 431.2809, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 423.2160, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 20: 404.4092, Accuracy: 0.7876\n",
      "Training loss (for one batch) at step 30: 399.4912, Accuracy: 0.7979\n",
      "Training loss (for one batch) at step 40: 391.9259, Accuracy: 0.8060\n",
      "Training loss (for one batch) at step 50: 362.2813, Accuracy: 0.8176\n",
      "Training loss (for one batch) at step 60: 377.2164, Accuracy: 0.8254\n",
      "Training loss (for one batch) at step 70: 412.4375, Accuracy: 0.8233\n",
      "Training loss (for one batch) at step 80: 434.1812, Accuracy: 0.8136\n",
      "Training loss (for one batch) at step 90: 402.8332, Accuracy: 0.8082\n",
      "Training loss (for one batch) at step 100: 398.1114, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 110: 400.0960, Accuracy: 0.8038\n",
      "---- Training ----\n",
      "Training loss: 136.4016\n",
      "Training acc over epoch: 0.8030\n",
      "---- Validation ----\n",
      "Validation loss: 33.8335\n",
      "Validation acc: 0.7351\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 422.1262, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 406.8513, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 404.6250, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 30: 388.6205, Accuracy: 0.7855\n",
      "Training loss (for one batch) at step 40: 367.5413, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 50: 366.4842, Accuracy: 0.8183\n",
      "Training loss (for one batch) at step 60: 390.8729, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 70: 407.4579, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 80: 411.9883, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 90: 408.7465, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 100: 386.2556, Accuracy: 0.8048\n",
      "Training loss (for one batch) at step 110: 411.2588, Accuracy: 0.8054\n",
      "---- Training ----\n",
      "Training loss: 122.5199\n",
      "Training acc over epoch: 0.8035\n",
      "---- Validation ----\n",
      "Validation loss: 38.4862\n",
      "Validation acc: 0.7410\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 426.6489, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 422.4477, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 397.5128, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 30: 401.0722, Accuracy: 0.7873\n",
      "Training loss (for one batch) at step 40: 382.8876, Accuracy: 0.7973\n",
      "Training loss (for one batch) at step 50: 354.8028, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 60: 380.0027, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 70: 412.4085, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 80: 431.8705, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 90: 390.0551, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 100: 390.8743, Accuracy: 0.8055\n",
      "Training loss (for one batch) at step 110: 384.4714, Accuracy: 0.8042\n",
      "---- Training ----\n",
      "Training loss: 122.1733\n",
      "Training acc over epoch: 0.8047\n",
      "---- Validation ----\n",
      "Validation loss: 37.4417\n",
      "Validation acc: 0.7230\n",
      "Time taken: 10.84s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 411.4111, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 406.5557, Accuracy: 0.7791\n",
      "Training loss (for one batch) at step 20: 400.0865, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 30: 383.0764, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 40: 369.4900, Accuracy: 0.8205\n",
      "Training loss (for one batch) at step 50: 355.8024, Accuracy: 0.8324\n",
      "Training loss (for one batch) at step 60: 379.2039, Accuracy: 0.8368\n",
      "Training loss (for one batch) at step 70: 400.2866, Accuracy: 0.8305\n",
      "Training loss (for one batch) at step 80: 411.2896, Accuracy: 0.8207\n",
      "Training loss (for one batch) at step 90: 402.0723, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 100: 385.9766, Accuracy: 0.8123\n",
      "Training loss (for one batch) at step 110: 392.3585, Accuracy: 0.8126\n",
      "---- Training ----\n",
      "Training loss: 123.1152\n",
      "Training acc over epoch: 0.8111\n",
      "---- Validation ----\n",
      "Validation loss: 35.8657\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 420.3652, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 417.3871, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 20: 377.9095, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 30: 374.2176, Accuracy: 0.7933\n",
      "Training loss (for one batch) at step 40: 363.9987, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 50: 357.2139, Accuracy: 0.8200\n",
      "Training loss (for one batch) at step 60: 365.8658, Accuracy: 0.8291\n",
      "Training loss (for one batch) at step 70: 404.3935, Accuracy: 0.8252\n",
      "Training loss (for one batch) at step 80: 394.4685, Accuracy: 0.8183\n",
      "Training loss (for one batch) at step 90: 397.5382, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 100: 375.6259, Accuracy: 0.8138\n",
      "Training loss (for one batch) at step 110: 383.3957, Accuracy: 0.8136\n",
      "---- Training ----\n",
      "Training loss: 126.3962\n",
      "Training acc over epoch: 0.8131\n",
      "---- Validation ----\n",
      "Validation loss: 36.0746\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 423.7576, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 397.1777, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 20: 382.9898, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 30: 384.2648, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 40: 358.1967, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 50: 351.3383, Accuracy: 0.8306\n",
      "Training loss (for one batch) at step 60: 359.7140, Accuracy: 0.8362\n",
      "Training loss (for one batch) at step 70: 401.5033, Accuracy: 0.8316\n",
      "Training loss (for one batch) at step 80: 401.9575, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 90: 382.0766, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 100: 380.5016, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 110: 392.1866, Accuracy: 0.8174\n",
      "---- Training ----\n",
      "Training loss: 125.0869\n",
      "Training acc over epoch: 0.8170\n",
      "---- Validation ----\n",
      "Validation loss: 39.3798\n",
      "Validation acc: 0.7254\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 406.3901, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 402.5932, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 20: 376.3224, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 30: 371.1720, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 40: 354.4432, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 50: 354.5007, Accuracy: 0.8309\n",
      "Training loss (for one batch) at step 60: 375.8773, Accuracy: 0.8367\n",
      "Training loss (for one batch) at step 70: 398.3705, Accuracy: 0.8290\n",
      "Training loss (for one batch) at step 80: 399.7961, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 90: 394.7622, Accuracy: 0.8127\n",
      "Training loss (for one batch) at step 100: 377.3488, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 110: 389.2733, Accuracy: 0.8120\n",
      "---- Training ----\n",
      "Training loss: 114.0843\n",
      "Training acc over epoch: 0.8104\n",
      "---- Validation ----\n",
      "Validation loss: 37.7346\n",
      "Validation acc: 0.7200\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 411.4616, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 396.0085, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 379.8495, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 30: 376.8321, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 40: 373.9049, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 50: 330.3309, Accuracy: 0.8283\n",
      "Training loss (for one batch) at step 60: 371.4907, Accuracy: 0.8347\n",
      "Training loss (for one batch) at step 70: 394.3704, Accuracy: 0.8289\n",
      "Training loss (for one batch) at step 80: 400.2009, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 90: 376.2346, Accuracy: 0.8132\n",
      "Training loss (for one batch) at step 100: 366.4696, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 110: 388.3105, Accuracy: 0.8137\n",
      "---- Training ----\n",
      "Training loss: 121.9330\n",
      "Training acc over epoch: 0.8125\n",
      "---- Validation ----\n",
      "Validation loss: 43.0912\n",
      "Validation acc: 0.7131\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 396.5355, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 380.5101, Accuracy: 0.7642\n",
      "Training loss (for one batch) at step 20: 362.6929, Accuracy: 0.7772\n",
      "Training loss (for one batch) at step 30: 361.6545, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 40: 339.5781, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 50: 352.4515, Accuracy: 0.8199\n",
      "Training loss (for one batch) at step 60: 373.6047, Accuracy: 0.8295\n",
      "Training loss (for one batch) at step 70: 389.0308, Accuracy: 0.8233\n",
      "Training loss (for one batch) at step 80: 404.1152, Accuracy: 0.8164\n",
      "Training loss (for one batch) at step 90: 369.7225, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 100: 358.5318, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 110: 374.5391, Accuracy: 0.8131\n",
      "---- Training ----\n",
      "Training loss: 120.9813\n",
      "Training acc over epoch: 0.8117\n",
      "---- Validation ----\n",
      "Validation loss: 37.8169\n",
      "Validation acc: 0.7174\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 393.2806, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 409.5759, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 20: 368.0469, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 30: 367.4323, Accuracy: 0.7933\n",
      "Training loss (for one batch) at step 40: 334.6405, Accuracy: 0.8138\n",
      "Training loss (for one batch) at step 50: 346.1645, Accuracy: 0.8258\n",
      "Training loss (for one batch) at step 60: 345.8766, Accuracy: 0.8335\n",
      "Training loss (for one batch) at step 70: 376.9778, Accuracy: 0.8256\n",
      "Training loss (for one batch) at step 80: 387.6056, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 90: 363.1199, Accuracy: 0.8127\n",
      "Training loss (for one batch) at step 100: 343.3693, Accuracy: 0.8143\n",
      "Training loss (for one batch) at step 110: 373.0147, Accuracy: 0.8134\n",
      "---- Training ----\n",
      "Training loss: 109.1754\n",
      "Training acc over epoch: 0.8128\n",
      "---- Validation ----\n",
      "Validation loss: 35.4497\n",
      "Validation acc: 0.7139\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 401.9246, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 382.5367, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 20: 372.5509, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 30: 375.1065, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 40: 360.6491, Accuracy: 0.8148\n",
      "Training loss (for one batch) at step 50: 335.4209, Accuracy: 0.8309\n",
      "Training loss (for one batch) at step 60: 344.9911, Accuracy: 0.8364\n",
      "Training loss (for one batch) at step 70: 361.7440, Accuracy: 0.8320\n",
      "Training loss (for one batch) at step 80: 392.9461, Accuracy: 0.8221\n",
      "Training loss (for one batch) at step 90: 360.1574, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 100: 365.4151, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 110: 376.2176, Accuracy: 0.8174\n",
      "---- Training ----\n",
      "Training loss: 115.0920\n",
      "Training acc over epoch: 0.8158\n",
      "---- Validation ----\n",
      "Validation loss: 38.4949\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 406.3312, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 374.0073, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 368.4926, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 30: 370.2546, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 40: 348.5561, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 50: 331.9090, Accuracy: 0.8297\n",
      "Training loss (for one batch) at step 60: 351.7119, Accuracy: 0.8363\n",
      "Training loss (for one batch) at step 70: 385.8696, Accuracy: 0.8274\n",
      "Training loss (for one batch) at step 80: 380.6523, Accuracy: 0.8187\n",
      "Training loss (for one batch) at step 90: 365.4491, Accuracy: 0.8143\n",
      "Training loss (for one batch) at step 100: 350.3808, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 110: 362.1810, Accuracy: 0.8183\n",
      "---- Training ----\n",
      "Training loss: 118.5357\n",
      "Training acc over epoch: 0.8170\n",
      "---- Validation ----\n",
      "Validation loss: 43.7415\n",
      "Validation acc: 0.7214\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 375.1987, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 394.9555, Accuracy: 0.7670\n",
      "Training loss (for one batch) at step 20: 347.6628, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 30: 349.6873, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 40: 343.4295, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 50: 338.3223, Accuracy: 0.8278\n",
      "Training loss (for one batch) at step 60: 360.6999, Accuracy: 0.8345\n",
      "Training loss (for one batch) at step 70: 375.2159, Accuracy: 0.8290\n",
      "Training loss (for one batch) at step 80: 379.7241, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 90: 351.5938, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 100: 339.6473, Accuracy: 0.8145\n",
      "Training loss (for one batch) at step 110: 376.5532, Accuracy: 0.8137\n",
      "---- Training ----\n",
      "Training loss: 116.6582\n",
      "Training acc over epoch: 0.8127\n",
      "---- Validation ----\n",
      "Validation loss: 42.9811\n",
      "Validation acc: 0.7222\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 387.8147, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 385.8049, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 364.6839, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 30: 347.2667, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 40: 327.9448, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 50: 350.1699, Accuracy: 0.8284\n",
      "Training loss (for one batch) at step 60: 337.8544, Accuracy: 0.8339\n",
      "Training loss (for one batch) at step 70: 402.1813, Accuracy: 0.8269\n",
      "Training loss (for one batch) at step 80: 380.7544, Accuracy: 0.8187\n",
      "Training loss (for one batch) at step 90: 354.8441, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 100: 352.9258, Accuracy: 0.8158\n",
      "Training loss (for one batch) at step 110: 364.4528, Accuracy: 0.8176\n",
      "---- Training ----\n",
      "Training loss: 109.7576\n",
      "Training acc over epoch: 0.8160\n",
      "---- Validation ----\n",
      "Validation loss: 35.6992\n",
      "Validation acc: 0.7106\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 393.8276, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 392.8583, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 377.7556, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 30: 334.1411, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 40: 344.2741, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 50: 328.5920, Accuracy: 0.8297\n",
      "Training loss (for one batch) at step 60: 361.5602, Accuracy: 0.8349\n",
      "Training loss (for one batch) at step 70: 369.8655, Accuracy: 0.8253\n",
      "Training loss (for one batch) at step 80: 363.6108, Accuracy: 0.8154\n",
      "Training loss (for one batch) at step 90: 342.0778, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 100: 322.3803, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 110: 336.8695, Accuracy: 0.8150\n",
      "---- Training ----\n",
      "Training loss: 121.4897\n",
      "Training acc over epoch: 0.8147\n",
      "---- Validation ----\n",
      "Validation loss: 63.4259\n",
      "Validation acc: 0.7149\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 381.3017, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 385.5363, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 20: 372.6531, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 30: 342.5046, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 40: 328.0392, Accuracy: 0.8222\n",
      "Training loss (for one batch) at step 50: 315.3336, Accuracy: 0.8358\n",
      "Training loss (for one batch) at step 60: 346.5051, Accuracy: 0.8427\n",
      "Training loss (for one batch) at step 70: 366.3350, Accuracy: 0.8342\n",
      "Training loss (for one batch) at step 80: 390.5283, Accuracy: 0.8227\n",
      "Training loss (for one batch) at step 90: 349.5359, Accuracy: 0.8189\n",
      "Training loss (for one batch) at step 100: 340.2331, Accuracy: 0.8216\n",
      "Training loss (for one batch) at step 110: 360.3285, Accuracy: 0.8214\n",
      "---- Training ----\n",
      "Training loss: 112.6701\n",
      "Training acc over epoch: 0.8203\n",
      "---- Validation ----\n",
      "Validation loss: 32.3828\n",
      "Validation acc: 0.7104\n",
      "Time taken: 10.61s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7096\n",
      "Validation AUC: 0.7099\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 664.8752, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 592.2138, Accuracy: 0.5142\n",
      "Training loss (for one batch) at step 20: 550.4189, Accuracy: 0.5153\n",
      "Training loss (for one batch) at step 30: 539.2861, Accuracy: 0.5169\n",
      "Training loss (for one batch) at step 40: 518.4673, Accuracy: 0.5120\n",
      "Training loss (for one batch) at step 50: 482.0505, Accuracy: 0.5110\n",
      "Training loss (for one batch) at step 60: 485.7870, Accuracy: 0.5137\n",
      "Training loss (for one batch) at step 70: 502.2236, Accuracy: 0.5132\n",
      "Training loss (for one batch) at step 80: 473.2771, Accuracy: 0.5149\n",
      "Training loss (for one batch) at step 90: 479.2753, Accuracy: 0.5132\n",
      "Training loss (for one batch) at step 100: 465.5141, Accuracy: 0.5159\n",
      "Training loss (for one batch) at step 110: 476.8719, Accuracy: 0.5158\n",
      "---- Training ----\n",
      "Training loss: 145.3076\n",
      "Training acc over epoch: 0.5164\n",
      "---- Validation ----\n",
      "Validation loss: 34.7737\n",
      "Validation acc: 0.4823\n",
      "Time taken: 12.48s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 462.6722, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 10: 456.1337, Accuracy: 0.4993\n",
      "Training loss (for one batch) at step 20: 447.8215, Accuracy: 0.5130\n",
      "Training loss (for one batch) at step 30: 454.0995, Accuracy: 0.5151\n",
      "Training loss (for one batch) at step 40: 460.1528, Accuracy: 0.5213\n",
      "Training loss (for one batch) at step 50: 447.6617, Accuracy: 0.5218\n",
      "Training loss (for one batch) at step 60: 454.4113, Accuracy: 0.5251\n",
      "Training loss (for one batch) at step 70: 451.4519, Accuracy: 0.5294\n",
      "Training loss (for one batch) at step 80: 447.0461, Accuracy: 0.5263\n",
      "Training loss (for one batch) at step 90: 447.0905, Accuracy: 0.5252\n",
      "Training loss (for one batch) at step 100: 446.4719, Accuracy: 0.5261\n",
      "Training loss (for one batch) at step 110: 445.3889, Accuracy: 0.5267\n",
      "---- Training ----\n",
      "Training loss: 140.7891\n",
      "Training acc over epoch: 0.5247\n",
      "---- Validation ----\n",
      "Validation loss: 34.5971\n",
      "Validation acc: 0.4946\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.0553, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 446.6615, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 20: 453.4505, Accuracy: 0.5246\n",
      "Training loss (for one batch) at step 30: 445.4477, Accuracy: 0.5282\n",
      "Training loss (for one batch) at step 40: 445.7000, Accuracy: 0.5309\n",
      "Training loss (for one batch) at step 50: 444.0070, Accuracy: 0.5309\n",
      "Training loss (for one batch) at step 60: 444.4765, Accuracy: 0.5339\n",
      "Training loss (for one batch) at step 70: 449.4399, Accuracy: 0.5327\n",
      "Training loss (for one batch) at step 80: 445.9156, Accuracy: 0.5366\n",
      "Training loss (for one batch) at step 90: 444.8301, Accuracy: 0.5363\n",
      "Training loss (for one batch) at step 100: 444.3482, Accuracy: 0.5375\n",
      "Training loss (for one batch) at step 110: 443.6009, Accuracy: 0.5386\n",
      "---- Training ----\n",
      "Training loss: 143.2457\n",
      "Training acc over epoch: 0.5411\n",
      "---- Validation ----\n",
      "Validation loss: 34.9345\n",
      "Validation acc: 0.5266\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.3035, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 446.9204, Accuracy: 0.5362\n",
      "Training loss (for one batch) at step 20: 443.6778, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 30: 447.0322, Accuracy: 0.5456\n",
      "Training loss (for one batch) at step 40: 443.6756, Accuracy: 0.5572\n",
      "Training loss (for one batch) at step 50: 445.9760, Accuracy: 0.5578\n",
      "Training loss (for one batch) at step 60: 441.7666, Accuracy: 0.5589\n",
      "Training loss (for one batch) at step 70: 444.1532, Accuracy: 0.5613\n",
      "Training loss (for one batch) at step 80: 443.9149, Accuracy: 0.5639\n",
      "Training loss (for one batch) at step 90: 444.5410, Accuracy: 0.5608\n",
      "Training loss (for one batch) at step 100: 442.7641, Accuracy: 0.5584\n",
      "Training loss (for one batch) at step 110: 443.9928, Accuracy: 0.5598\n",
      "---- Training ----\n",
      "Training loss: 138.5845\n",
      "Training acc over epoch: 0.5631\n",
      "---- Validation ----\n",
      "Validation loss: 34.7584\n",
      "Validation acc: 0.6096\n",
      "Time taken: 10.83s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 443.3685, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 445.5789, Accuracy: 0.5909\n",
      "Training loss (for one batch) at step 20: 443.0704, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 30: 441.0078, Accuracy: 0.5819\n",
      "Training loss (for one batch) at step 40: 445.0511, Accuracy: 0.5854\n",
      "Training loss (for one batch) at step 50: 443.3945, Accuracy: 0.5893\n",
      "Training loss (for one batch) at step 60: 443.9000, Accuracy: 0.5863\n",
      "Training loss (for one batch) at step 70: 441.6709, Accuracy: 0.5884\n",
      "Training loss (for one batch) at step 80: 442.3729, Accuracy: 0.5905\n",
      "Training loss (for one batch) at step 90: 441.8354, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 100: 442.6367, Accuracy: 0.5874\n",
      "Training loss (for one batch) at step 110: 444.1716, Accuracy: 0.5885\n",
      "---- Training ----\n",
      "Training loss: 137.8516\n",
      "Training acc over epoch: 0.5886\n",
      "---- Validation ----\n",
      "Validation loss: 35.1466\n",
      "Validation acc: 0.6389\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 444.5758, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 444.2919, Accuracy: 0.6165\n",
      "Training loss (for one batch) at step 20: 442.9360, Accuracy: 0.6146\n",
      "Training loss (for one batch) at step 30: 441.1891, Accuracy: 0.6184\n",
      "Training loss (for one batch) at step 40: 442.6982, Accuracy: 0.6181\n",
      "Training loss (for one batch) at step 50: 440.1593, Accuracy: 0.6209\n",
      "Training loss (for one batch) at step 60: 440.5863, Accuracy: 0.6232\n",
      "Training loss (for one batch) at step 70: 446.0535, Accuracy: 0.6256\n",
      "Training loss (for one batch) at step 80: 443.4307, Accuracy: 0.6264\n",
      "Training loss (for one batch) at step 90: 442.6270, Accuracy: 0.6217\n",
      "Training loss (for one batch) at step 100: 441.0293, Accuracy: 0.6184\n",
      "Training loss (for one batch) at step 110: 444.8906, Accuracy: 0.6191\n",
      "---- Training ----\n",
      "Training loss: 138.6834\n",
      "Training acc over epoch: 0.6202\n",
      "---- Validation ----\n",
      "Validation loss: 35.8966\n",
      "Validation acc: 0.6432\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.3764, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 442.7349, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 440.5302, Accuracy: 0.6168\n",
      "Training loss (for one batch) at step 30: 440.6398, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 40: 439.6502, Accuracy: 0.6216\n",
      "Training loss (for one batch) at step 50: 437.0140, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 60: 441.5758, Accuracy: 0.6282\n",
      "Training loss (for one batch) at step 70: 443.9268, Accuracy: 0.6331\n",
      "Training loss (for one batch) at step 80: 444.2858, Accuracy: 0.6324\n",
      "Training loss (for one batch) at step 90: 439.7667, Accuracy: 0.6320\n",
      "Training loss (for one batch) at step 100: 439.7296, Accuracy: 0.6307\n",
      "Training loss (for one batch) at step 110: 439.7950, Accuracy: 0.6326\n",
      "---- Training ----\n",
      "Training loss: 138.5431\n",
      "Training acc over epoch: 0.6353\n",
      "---- Validation ----\n",
      "Validation loss: 34.9611\n",
      "Validation acc: 0.6695\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 439.7572, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 443.5789, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 20: 443.2185, Accuracy: 0.6451\n",
      "Training loss (for one batch) at step 30: 437.1320, Accuracy: 0.6525\n",
      "Training loss (for one batch) at step 40: 435.6010, Accuracy: 0.6572\n",
      "Training loss (for one batch) at step 50: 433.1204, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 60: 445.2348, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 70: 440.1209, Accuracy: 0.6613\n",
      "Training loss (for one batch) at step 80: 449.4854, Accuracy: 0.6588\n",
      "Training loss (for one batch) at step 90: 442.2517, Accuracy: 0.6575\n",
      "Training loss (for one batch) at step 100: 437.0480, Accuracy: 0.6590\n",
      "Training loss (for one batch) at step 110: 448.5390, Accuracy: 0.6597\n",
      "---- Training ----\n",
      "Training loss: 136.5373\n",
      "Training acc over epoch: 0.6607\n",
      "---- Validation ----\n",
      "Validation loss: 34.2128\n",
      "Validation acc: 0.6322\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 444.4416, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 442.1899, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 20: 438.9082, Accuracy: 0.6715\n",
      "Training loss (for one batch) at step 30: 435.2053, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 40: 449.3118, Accuracy: 0.6707\n",
      "Training loss (for one batch) at step 50: 435.6909, Accuracy: 0.6785\n",
      "Training loss (for one batch) at step 60: 448.2294, Accuracy: 0.6799\n",
      "Training loss (for one batch) at step 70: 441.6412, Accuracy: 0.6828\n",
      "Training loss (for one batch) at step 80: 440.1066, Accuracy: 0.6820\n",
      "Training loss (for one batch) at step 90: 440.1858, Accuracy: 0.6780\n",
      "Training loss (for one batch) at step 100: 434.5666, Accuracy: 0.6788\n",
      "Training loss (for one batch) at step 110: 432.8119, Accuracy: 0.6784\n",
      "---- Training ----\n",
      "Training loss: 136.8670\n",
      "Training acc over epoch: 0.6800\n",
      "---- Validation ----\n",
      "Validation loss: 35.1553\n",
      "Validation acc: 0.6566\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 441.5677, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 442.7509, Accuracy: 0.7003\n",
      "Training loss (for one batch) at step 20: 435.1504, Accuracy: 0.7080\n",
      "Training loss (for one batch) at step 30: 440.5209, Accuracy: 0.7029\n",
      "Training loss (for one batch) at step 40: 429.0982, Accuracy: 0.7014\n",
      "Training loss (for one batch) at step 50: 427.6992, Accuracy: 0.7053\n",
      "Training loss (for one batch) at step 60: 442.8503, Accuracy: 0.7048\n",
      "Training loss (for one batch) at step 70: 441.6680, Accuracy: 0.7050\n",
      "Training loss (for one batch) at step 80: 441.3833, Accuracy: 0.6963\n",
      "Training loss (for one batch) at step 90: 435.1112, Accuracy: 0.6929\n",
      "Training loss (for one batch) at step 100: 439.6152, Accuracy: 0.6933\n",
      "Training loss (for one batch) at step 110: 436.5261, Accuracy: 0.6979\n",
      "---- Training ----\n",
      "Training loss: 138.3499\n",
      "Training acc over epoch: 0.6978\n",
      "---- Validation ----\n",
      "Validation loss: 35.7817\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 437.5728, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 441.2169, Accuracy: 0.7095\n",
      "Training loss (for one batch) at step 20: 437.4015, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 430.9543, Accuracy: 0.7072\n",
      "Training loss (for one batch) at step 40: 435.2029, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 50: 430.5414, Accuracy: 0.7154\n",
      "Training loss (for one batch) at step 60: 443.2711, Accuracy: 0.7180\n",
      "Training loss (for one batch) at step 70: 440.9451, Accuracy: 0.7204\n",
      "Training loss (for one batch) at step 80: 437.2419, Accuracy: 0.7174\n",
      "Training loss (for one batch) at step 90: 442.2598, Accuracy: 0.7130\n",
      "Training loss (for one batch) at step 100: 435.1487, Accuracy: 0.7140\n",
      "Training loss (for one batch) at step 110: 440.2018, Accuracy: 0.7161\n",
      "---- Training ----\n",
      "Training loss: 136.5765\n",
      "Training acc over epoch: 0.7165\n",
      "---- Validation ----\n",
      "Validation loss: 37.0062\n",
      "Validation acc: 0.6948\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 442.4453, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 443.7776, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 436.5981, Accuracy: 0.7094\n",
      "Training loss (for one batch) at step 30: 430.5673, Accuracy: 0.7177\n",
      "Training loss (for one batch) at step 40: 425.3446, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 50: 425.2560, Accuracy: 0.7233\n",
      "Training loss (for one batch) at step 60: 433.2055, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 70: 438.2960, Accuracy: 0.7245\n",
      "Training loss (for one batch) at step 80: 443.1509, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 90: 434.2520, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 100: 428.2458, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 110: 435.3442, Accuracy: 0.7204\n",
      "---- Training ----\n",
      "Training loss: 138.4379\n",
      "Training acc over epoch: 0.7204\n",
      "---- Validation ----\n",
      "Validation loss: 37.2526\n",
      "Validation acc: 0.7437\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 438.3528, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 437.7057, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 20: 433.6045, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 30: 427.9201, Accuracy: 0.7261\n",
      "Training loss (for one batch) at step 40: 421.4573, Accuracy: 0.7323\n",
      "Training loss (for one batch) at step 50: 426.5123, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 60: 423.3708, Accuracy: 0.7405\n",
      "Training loss (for one batch) at step 70: 433.8416, Accuracy: 0.7413\n",
      "Training loss (for one batch) at step 80: 440.5645, Accuracy: 0.7356\n",
      "Training loss (for one batch) at step 90: 440.9187, Accuracy: 0.7265\n",
      "Training loss (for one batch) at step 100: 430.7695, Accuracy: 0.7256\n",
      "Training loss (for one batch) at step 110: 432.4962, Accuracy: 0.7279\n",
      "---- Training ----\n",
      "Training loss: 134.3962\n",
      "Training acc over epoch: 0.7280\n",
      "---- Validation ----\n",
      "Validation loss: 35.3829\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 445.3474, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 441.3410, Accuracy: 0.7067\n",
      "Training loss (for one batch) at step 20: 436.4948, Accuracy: 0.7057\n",
      "Training loss (for one batch) at step 30: 420.1600, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 40: 422.1048, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 50: 414.6499, Accuracy: 0.7391\n",
      "Training loss (for one batch) at step 60: 437.1123, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 70: 440.4374, Accuracy: 0.7452\n",
      "Training loss (for one batch) at step 80: 446.5319, Accuracy: 0.7378\n",
      "Training loss (for one batch) at step 90: 432.2483, Accuracy: 0.7307\n",
      "Training loss (for one batch) at step 100: 432.0631, Accuracy: 0.7311\n",
      "Training loss (for one batch) at step 110: 429.0186, Accuracy: 0.7349\n",
      "---- Training ----\n",
      "Training loss: 135.4982\n",
      "Training acc over epoch: 0.7354\n",
      "---- Validation ----\n",
      "Validation loss: 33.2809\n",
      "Validation acc: 0.7254\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 443.9818, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 439.0425, Accuracy: 0.7116\n",
      "Training loss (for one batch) at step 20: 420.9042, Accuracy: 0.7184\n",
      "Training loss (for one batch) at step 30: 419.2347, Accuracy: 0.7296\n",
      "Training loss (for one batch) at step 40: 421.9843, Accuracy: 0.7391\n",
      "Training loss (for one batch) at step 50: 408.1635, Accuracy: 0.7483\n",
      "Training loss (for one batch) at step 60: 422.5936, Accuracy: 0.7531\n",
      "Training loss (for one batch) at step 70: 442.0568, Accuracy: 0.7499\n",
      "Training loss (for one batch) at step 80: 446.4880, Accuracy: 0.7413\n",
      "Training loss (for one batch) at step 90: 434.6925, Accuracy: 0.7360\n",
      "Training loss (for one batch) at step 100: 430.7504, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 110: 431.9802, Accuracy: 0.7363\n",
      "---- Training ----\n",
      "Training loss: 124.8967\n",
      "Training acc over epoch: 0.7368\n",
      "---- Validation ----\n",
      "Validation loss: 34.7194\n",
      "Validation acc: 0.7426\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 438.5467, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 437.6817, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 20: 427.6863, Accuracy: 0.7184\n",
      "Training loss (for one batch) at step 30: 413.2344, Accuracy: 0.7243\n",
      "Training loss (for one batch) at step 40: 411.1715, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 50: 409.9918, Accuracy: 0.7494\n",
      "Training loss (for one batch) at step 60: 419.6385, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 70: 433.6684, Accuracy: 0.7562\n",
      "Training loss (for one batch) at step 80: 441.0134, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 90: 437.0188, Accuracy: 0.7373\n",
      "Training loss (for one batch) at step 100: 425.4835, Accuracy: 0.7343\n",
      "Training loss (for one batch) at step 110: 432.9605, Accuracy: 0.7337\n",
      "---- Training ----\n",
      "Training loss: 128.2828\n",
      "Training acc over epoch: 0.7341\n",
      "---- Validation ----\n",
      "Validation loss: 35.4215\n",
      "Validation acc: 0.7090\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 436.7854, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 437.4153, Accuracy: 0.6967\n",
      "Training loss (for one batch) at step 20: 430.4157, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 30: 411.0272, Accuracy: 0.7233\n",
      "Training loss (for one batch) at step 40: 416.2127, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 50: 393.0589, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 60: 415.3989, Accuracy: 0.7570\n",
      "Training loss (for one batch) at step 70: 433.5651, Accuracy: 0.7558\n",
      "Training loss (for one batch) at step 80: 432.2287, Accuracy: 0.7471\n",
      "Training loss (for one batch) at step 90: 436.9319, Accuracy: 0.7406\n",
      "Training loss (for one batch) at step 100: 427.2003, Accuracy: 0.7405\n",
      "Training loss (for one batch) at step 110: 433.7949, Accuracy: 0.7426\n",
      "---- Training ----\n",
      "Training loss: 127.1750\n",
      "Training acc over epoch: 0.7432\n",
      "---- Validation ----\n",
      "Validation loss: 36.0171\n",
      "Validation acc: 0.7346\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 446.1385, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 437.6226, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 429.5894, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 30: 415.4229, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 40: 393.8719, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 50: 387.4261, Accuracy: 0.7658\n",
      "Training loss (for one batch) at step 60: 397.3211, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 70: 422.1885, Accuracy: 0.7695\n",
      "Training loss (for one batch) at step 80: 432.3732, Accuracy: 0.7577\n",
      "Training loss (for one batch) at step 90: 425.8148, Accuracy: 0.7523\n",
      "Training loss (for one batch) at step 100: 422.7432, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 110: 437.0349, Accuracy: 0.7531\n",
      "---- Training ----\n",
      "Training loss: 129.7019\n",
      "Training acc over epoch: 0.7519\n",
      "---- Validation ----\n",
      "Validation loss: 36.9618\n",
      "Validation acc: 0.7300\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 446.5122, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 441.0876, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 20: 427.5863, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 30: 416.8376, Accuracy: 0.7392\n",
      "Training loss (for one batch) at step 40: 394.3506, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 50: 395.5141, Accuracy: 0.7655\n",
      "Training loss (for one batch) at step 60: 406.2337, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 70: 427.7642, Accuracy: 0.7644\n",
      "Training loss (for one batch) at step 80: 441.6388, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 90: 427.3559, Accuracy: 0.7496\n",
      "Training loss (for one batch) at step 100: 429.5698, Accuracy: 0.7498\n",
      "Training loss (for one batch) at step 110: 440.7952, Accuracy: 0.7493\n",
      "---- Training ----\n",
      "Training loss: 134.7700\n",
      "Training acc over epoch: 0.7492\n",
      "---- Validation ----\n",
      "Validation loss: 33.5905\n",
      "Validation acc: 0.7208\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 440.6076, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 438.8674, Accuracy: 0.7095\n",
      "Training loss (for one batch) at step 20: 427.2495, Accuracy: 0.7087\n",
      "Training loss (for one batch) at step 30: 409.1422, Accuracy: 0.7283\n",
      "Training loss (for one batch) at step 40: 412.6169, Accuracy: 0.7441\n",
      "Training loss (for one batch) at step 50: 390.4819, Accuracy: 0.7583\n",
      "Training loss (for one batch) at step 60: 419.1012, Accuracy: 0.7647\n",
      "Training loss (for one batch) at step 70: 411.5190, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 80: 429.5935, Accuracy: 0.7505\n",
      "Training loss (for one batch) at step 90: 424.9609, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 100: 422.0719, Accuracy: 0.7437\n",
      "Training loss (for one batch) at step 110: 425.4673, Accuracy: 0.7444\n",
      "---- Training ----\n",
      "Training loss: 132.8837\n",
      "Training acc over epoch: 0.7452\n",
      "---- Validation ----\n",
      "Validation loss: 33.6408\n",
      "Validation acc: 0.7243\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 447.6194, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 438.4723, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 20: 421.5439, Accuracy: 0.7225\n",
      "Training loss (for one batch) at step 30: 411.6275, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 40: 411.0224, Accuracy: 0.7458\n",
      "Training loss (for one batch) at step 50: 416.9838, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 60: 394.3875, Accuracy: 0.7674\n",
      "Training loss (for one batch) at step 70: 433.8736, Accuracy: 0.7634\n",
      "Training loss (for one batch) at step 80: 414.3885, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 90: 423.7879, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 100: 412.5447, Accuracy: 0.7453\n",
      "Training loss (for one batch) at step 110: 427.7038, Accuracy: 0.7460\n",
      "---- Training ----\n",
      "Training loss: 129.2034\n",
      "Training acc over epoch: 0.7445\n",
      "---- Validation ----\n",
      "Validation loss: 35.7228\n",
      "Validation acc: 0.7235\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 439.4444, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 430.2196, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 20: 420.9207, Accuracy: 0.7262\n",
      "Training loss (for one batch) at step 30: 401.1396, Accuracy: 0.7432\n",
      "Training loss (for one batch) at step 40: 388.4626, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 50: 367.6805, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 60: 422.9058, Accuracy: 0.7757\n",
      "Training loss (for one batch) at step 70: 423.6990, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 80: 427.7694, Accuracy: 0.7576\n",
      "Training loss (for one batch) at step 90: 417.6970, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 100: 413.6094, Accuracy: 0.7531\n",
      "Training loss (for one batch) at step 110: 436.3321, Accuracy: 0.7542\n",
      "---- Training ----\n",
      "Training loss: 138.1702\n",
      "Training acc over epoch: 0.7527\n",
      "---- Validation ----\n",
      "Validation loss: 36.4625\n",
      "Validation acc: 0.7026\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 434.0162, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 434.8284, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 20: 432.5695, Accuracy: 0.7225\n",
      "Training loss (for one batch) at step 30: 394.4127, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 40: 383.9927, Accuracy: 0.7540\n",
      "Training loss (for one batch) at step 50: 355.4052, Accuracy: 0.7728\n",
      "Training loss (for one batch) at step 60: 385.2287, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 70: 424.1416, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 80: 428.9774, Accuracy: 0.7617\n",
      "Training loss (for one batch) at step 90: 416.8539, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 100: 404.1821, Accuracy: 0.7535\n",
      "Training loss (for one batch) at step 110: 417.6481, Accuracy: 0.7523\n",
      "---- Training ----\n",
      "Training loss: 131.4097\n",
      "Training acc over epoch: 0.7514\n",
      "---- Validation ----\n",
      "Validation loss: 38.0590\n",
      "Validation acc: 0.7028\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 434.5672, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 428.2437, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 20: 415.9323, Accuracy: 0.7150\n",
      "Training loss (for one batch) at step 30: 411.5389, Accuracy: 0.7331\n",
      "Training loss (for one batch) at step 40: 380.6901, Accuracy: 0.7511\n",
      "Training loss (for one batch) at step 50: 365.9692, Accuracy: 0.7675\n",
      "Training loss (for one batch) at step 60: 384.9506, Accuracy: 0.7743\n",
      "Training loss (for one batch) at step 70: 411.9223, Accuracy: 0.7697\n",
      "Training loss (for one batch) at step 80: 422.6642, Accuracy: 0.7584\n",
      "Training loss (for one batch) at step 90: 423.0677, Accuracy: 0.7542\n",
      "Training loss (for one batch) at step 100: 407.5482, Accuracy: 0.7564\n",
      "Training loss (for one batch) at step 110: 394.8026, Accuracy: 0.7558\n",
      "---- Training ----\n",
      "Training loss: 125.6655\n",
      "Training acc over epoch: 0.7541\n",
      "---- Validation ----\n",
      "Validation loss: 36.2658\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 443.6035, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 441.5706, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 20: 410.9883, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 30: 405.8642, Accuracy: 0.7427\n",
      "Training loss (for one batch) at step 40: 369.3301, Accuracy: 0.7561\n",
      "Training loss (for one batch) at step 50: 365.4028, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 60: 376.3998, Accuracy: 0.7796\n",
      "Training loss (for one batch) at step 70: 425.5468, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 80: 413.0559, Accuracy: 0.7602\n",
      "Training loss (for one batch) at step 90: 407.4743, Accuracy: 0.7541\n",
      "Training loss (for one batch) at step 100: 404.1748, Accuracy: 0.7538\n",
      "Training loss (for one batch) at step 110: 419.8187, Accuracy: 0.7534\n",
      "---- Training ----\n",
      "Training loss: 131.3392\n",
      "Training acc over epoch: 0.7536\n",
      "---- Validation ----\n",
      "Validation loss: 44.3876\n",
      "Validation acc: 0.7112\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 426.5288, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 425.0154, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 20: 408.9620, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 30: 380.0359, Accuracy: 0.7417\n",
      "Training loss (for one batch) at step 40: 381.3408, Accuracy: 0.7574\n",
      "Training loss (for one batch) at step 50: 356.2658, Accuracy: 0.7721\n",
      "Training loss (for one batch) at step 60: 379.2345, Accuracy: 0.7807\n",
      "Training loss (for one batch) at step 70: 394.0926, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 80: 404.6287, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 90: 404.5467, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 100: 397.9684, Accuracy: 0.7569\n",
      "Training loss (for one batch) at step 110: 412.8856, Accuracy: 0.7552\n",
      "---- Training ----\n",
      "Training loss: 121.8271\n",
      "Training acc over epoch: 0.7552\n",
      "---- Validation ----\n",
      "Validation loss: 36.3377\n",
      "Validation acc: 0.7230\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 420.9198, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 421.6215, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 385.6909, Accuracy: 0.7169\n",
      "Training loss (for one batch) at step 30: 385.1735, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 40: 359.8353, Accuracy: 0.7609\n",
      "Training loss (for one batch) at step 50: 361.7225, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 60: 368.3080, Accuracy: 0.7836\n",
      "Training loss (for one batch) at step 70: 401.7480, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 80: 402.8211, Accuracy: 0.7627\n",
      "Training loss (for one batch) at step 90: 393.9646, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 100: 385.3849, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 110: 398.7884, Accuracy: 0.7569\n",
      "---- Training ----\n",
      "Training loss: 138.5089\n",
      "Training acc over epoch: 0.7553\n",
      "---- Validation ----\n",
      "Validation loss: 38.8218\n",
      "Validation acc: 0.6964\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 420.9798, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 410.9018, Accuracy: 0.6939\n",
      "Training loss (for one batch) at step 20: 391.8006, Accuracy: 0.7061\n",
      "Training loss (for one batch) at step 30: 377.8460, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 40: 355.3031, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 50: 338.1803, Accuracy: 0.7688\n",
      "Training loss (for one batch) at step 60: 341.6161, Accuracy: 0.7755\n",
      "Training loss (for one batch) at step 70: 408.8849, Accuracy: 0.7677\n",
      "Training loss (for one batch) at step 80: 413.8942, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 90: 392.4721, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 100: 385.6933, Accuracy: 0.7505\n",
      "Training loss (for one batch) at step 110: 410.4435, Accuracy: 0.7489\n",
      "---- Training ----\n",
      "Training loss: 117.1533\n",
      "Training acc over epoch: 0.7494\n",
      "---- Validation ----\n",
      "Validation loss: 35.4784\n",
      "Validation acc: 0.6972\n",
      "Time taken: 10.88s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 411.6230, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 403.9492, Accuracy: 0.6790\n",
      "Training loss (for one batch) at step 20: 395.3340, Accuracy: 0.7065\n",
      "Training loss (for one batch) at step 30: 374.3643, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 40: 362.2722, Accuracy: 0.7569\n",
      "Training loss (for one batch) at step 50: 335.3622, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 60: 361.3968, Accuracy: 0.7804\n",
      "Training loss (for one batch) at step 70: 399.1210, Accuracy: 0.7718\n",
      "Training loss (for one batch) at step 80: 402.1765, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 90: 407.1193, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 100: 391.5109, Accuracy: 0.7529\n",
      "Training loss (for one batch) at step 110: 381.3918, Accuracy: 0.7531\n",
      "---- Training ----\n",
      "Training loss: 122.6650\n",
      "Training acc over epoch: 0.7505\n",
      "---- Validation ----\n",
      "Validation loss: 40.6319\n",
      "Validation acc: 0.6851\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 421.6938, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 427.6012, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 20: 387.9784, Accuracy: 0.7083\n",
      "Training loss (for one batch) at step 30: 360.0798, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 40: 348.4940, Accuracy: 0.7590\n",
      "Training loss (for one batch) at step 50: 328.1708, Accuracy: 0.7739\n",
      "Training loss (for one batch) at step 60: 359.7750, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 70: 378.6408, Accuracy: 0.7721\n",
      "Training loss (for one batch) at step 80: 408.2483, Accuracy: 0.7609\n",
      "Training loss (for one batch) at step 90: 397.0011, Accuracy: 0.7544\n",
      "Training loss (for one batch) at step 100: 377.9302, Accuracy: 0.7565\n",
      "Training loss (for one batch) at step 110: 363.0260, Accuracy: 0.7549\n",
      "---- Training ----\n",
      "Training loss: 117.8741\n",
      "Training acc over epoch: 0.7545\n",
      "---- Validation ----\n",
      "Validation loss: 36.7732\n",
      "Validation acc: 0.6741\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 405.6959, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 409.9191, Accuracy: 0.6939\n",
      "Training loss (for one batch) at step 20: 383.7222, Accuracy: 0.7128\n",
      "Training loss (for one batch) at step 30: 361.8720, Accuracy: 0.7397\n",
      "Training loss (for one batch) at step 40: 326.6329, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 50: 335.5991, Accuracy: 0.7695\n",
      "Training loss (for one batch) at step 60: 348.7675, Accuracy: 0.7761\n",
      "Training loss (for one batch) at step 70: 396.1248, Accuracy: 0.7642\n",
      "Training loss (for one batch) at step 80: 414.2661, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 90: 376.1295, Accuracy: 0.7484\n",
      "Training loss (for one batch) at step 100: 368.1883, Accuracy: 0.7510\n",
      "Training loss (for one batch) at step 110: 400.4747, Accuracy: 0.7525\n",
      "---- Training ----\n",
      "Training loss: 123.8999\n",
      "Training acc over epoch: 0.7505\n",
      "---- Validation ----\n",
      "Validation loss: 42.2540\n",
      "Validation acc: 0.6867\n",
      "Time taken: 10.74s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 406.4096, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 389.7965, Accuracy: 0.6634\n",
      "Training loss (for one batch) at step 20: 377.9820, Accuracy: 0.7046\n",
      "Training loss (for one batch) at step 30: 343.3099, Accuracy: 0.7336\n",
      "Training loss (for one batch) at step 40: 359.6754, Accuracy: 0.7540\n",
      "Training loss (for one batch) at step 50: 325.0660, Accuracy: 0.7695\n",
      "Training loss (for one batch) at step 60: 337.2123, Accuracy: 0.7778\n",
      "Training loss (for one batch) at step 70: 391.2385, Accuracy: 0.7661\n",
      "Training loss (for one batch) at step 80: 392.0083, Accuracy: 0.7522\n",
      "Training loss (for one batch) at step 90: 384.6562, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 100: 369.0393, Accuracy: 0.7509\n",
      "Training loss (for one batch) at step 110: 382.4041, Accuracy: 0.7518\n",
      "---- Training ----\n",
      "Training loss: 126.9601\n",
      "Training acc over epoch: 0.7494\n",
      "---- Validation ----\n",
      "Validation loss: 36.0989\n",
      "Validation acc: 0.6945\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 421.1818, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 406.2705, Accuracy: 0.6456\n",
      "Training loss (for one batch) at step 20: 372.4451, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 344.9075, Accuracy: 0.7261\n",
      "Training loss (for one batch) at step 40: 343.5460, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 50: 345.8281, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 60: 350.6984, Accuracy: 0.7768\n",
      "Training loss (for one batch) at step 70: 378.1778, Accuracy: 0.7668\n",
      "Training loss (for one batch) at step 80: 384.4451, Accuracy: 0.7548\n",
      "Training loss (for one batch) at step 90: 362.6749, Accuracy: 0.7503\n",
      "Training loss (for one batch) at step 100: 373.3808, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 110: 375.1473, Accuracy: 0.7525\n",
      "---- Training ----\n",
      "Training loss: 118.2789\n",
      "Training acc over epoch: 0.7500\n",
      "---- Validation ----\n",
      "Validation loss: 34.9132\n",
      "Validation acc: 0.6776\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 392.7941, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 391.9038, Accuracy: 0.6342\n",
      "Training loss (for one batch) at step 20: 362.1490, Accuracy: 0.6741\n",
      "Training loss (for one batch) at step 30: 359.5858, Accuracy: 0.7177\n",
      "Training loss (for one batch) at step 40: 330.1271, Accuracy: 0.7454\n",
      "Training loss (for one batch) at step 50: 322.4635, Accuracy: 0.7610\n",
      "Training loss (for one batch) at step 60: 349.9713, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 70: 361.0316, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 80: 388.8445, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 90: 371.0269, Accuracy: 0.7412\n",
      "Training loss (for one batch) at step 100: 361.5251, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 110: 380.2110, Accuracy: 0.7439\n",
      "---- Training ----\n",
      "Training loss: 110.4240\n",
      "Training acc over epoch: 0.7435\n",
      "---- Validation ----\n",
      "Validation loss: 45.3259\n",
      "Validation acc: 0.6943\n",
      "Time taken: 10.74s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 393.7906, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 390.6277, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 20: 358.9482, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 30: 343.3095, Accuracy: 0.7248\n",
      "Training loss (for one batch) at step 40: 335.3079, Accuracy: 0.7504\n",
      "Training loss (for one batch) at step 50: 322.0449, Accuracy: 0.7658\n",
      "Training loss (for one batch) at step 60: 339.9146, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 70: 377.1296, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 80: 383.7349, Accuracy: 0.7453\n",
      "Training loss (for one batch) at step 90: 382.5710, Accuracy: 0.7434\n",
      "Training loss (for one batch) at step 100: 348.8158, Accuracy: 0.7459\n",
      "Training loss (for one batch) at step 110: 357.1158, Accuracy: 0.7455\n",
      "---- Training ----\n",
      "Training loss: 123.9504\n",
      "Training acc over epoch: 0.7436\n",
      "---- Validation ----\n",
      "Validation loss: 36.7266\n",
      "Validation acc: 0.6768\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 385.6021, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 389.4556, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 20: 350.8413, Accuracy: 0.6730\n",
      "Training loss (for one batch) at step 30: 338.0869, Accuracy: 0.7150\n",
      "Training loss (for one batch) at step 40: 329.3853, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 50: 351.9091, Accuracy: 0.7549\n",
      "Training loss (for one batch) at step 60: 332.4395, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 70: 390.5099, Accuracy: 0.7529\n",
      "Training loss (for one batch) at step 80: 389.7132, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 90: 371.9250, Accuracy: 0.7339\n",
      "Training loss (for one batch) at step 100: 358.6263, Accuracy: 0.7367\n",
      "Training loss (for one batch) at step 110: 378.6272, Accuracy: 0.7378\n",
      "---- Training ----\n",
      "Training loss: 117.1176\n",
      "Training acc over epoch: 0.7367\n",
      "---- Validation ----\n",
      "Validation loss: 44.7777\n",
      "Validation acc: 0.6639\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 390.9860, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 373.2518, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 20: 353.2331, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 30: 331.4777, Accuracy: 0.7137\n",
      "Training loss (for one batch) at step 40: 327.5663, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 50: 325.2109, Accuracy: 0.7580\n",
      "Training loss (for one batch) at step 60: 329.2314, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 70: 348.9618, Accuracy: 0.7542\n",
      "Training loss (for one batch) at step 80: 356.7884, Accuracy: 0.7377\n",
      "Training loss (for one batch) at step 90: 349.9354, Accuracy: 0.7347\n",
      "Training loss (for one batch) at step 100: 342.5056, Accuracy: 0.7386\n",
      "Training loss (for one batch) at step 110: 369.1949, Accuracy: 0.7370\n",
      "---- Training ----\n",
      "Training loss: 112.3722\n",
      "Training acc over epoch: 0.7370\n",
      "---- Validation ----\n",
      "Validation loss: 46.4590\n",
      "Validation acc: 0.6722\n",
      "Time taken: 10.88s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 387.3372, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 373.5328, Accuracy: 0.6413\n",
      "Training loss (for one batch) at step 20: 339.6911, Accuracy: 0.6849\n",
      "Training loss (for one batch) at step 30: 340.5097, Accuracy: 0.7160\n",
      "Training loss (for one batch) at step 40: 313.7238, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 50: 321.1288, Accuracy: 0.7610\n",
      "Training loss (for one batch) at step 60: 344.6168, Accuracy: 0.7693\n",
      "Training loss (for one batch) at step 70: 352.2184, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 80: 386.2355, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 90: 364.5014, Accuracy: 0.7388\n",
      "Training loss (for one batch) at step 100: 342.2535, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 110: 345.3056, Accuracy: 0.7431\n",
      "---- Training ----\n",
      "Training loss: 117.8471\n",
      "Training acc over epoch: 0.7416\n",
      "---- Validation ----\n",
      "Validation loss: 43.0917\n",
      "Validation acc: 0.6690\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 382.1996, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 378.8479, Accuracy: 0.6293\n",
      "Training loss (for one batch) at step 20: 347.2827, Accuracy: 0.6752\n",
      "Training loss (for one batch) at step 30: 331.3109, Accuracy: 0.7165\n",
      "Training loss (for one batch) at step 40: 323.9068, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 50: 330.7124, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 60: 342.7446, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 70: 375.0719, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 80: 354.1950, Accuracy: 0.7396\n",
      "Training loss (for one batch) at step 90: 347.4016, Accuracy: 0.7378\n",
      "Training loss (for one batch) at step 100: 331.6689, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 110: 378.2297, Accuracy: 0.7423\n",
      "---- Training ----\n",
      "Training loss: 124.4421\n",
      "Training acc over epoch: 0.7415\n",
      "---- Validation ----\n",
      "Validation loss: 42.8650\n",
      "Validation acc: 0.6843\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 377.7804, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 363.2108, Accuracy: 0.6065\n",
      "Training loss (for one batch) at step 20: 355.7803, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 30: 328.2934, Accuracy: 0.7056\n",
      "Training loss (for one batch) at step 40: 319.6705, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 50: 308.4284, Accuracy: 0.7554\n",
      "Training loss (for one batch) at step 60: 321.9646, Accuracy: 0.7620\n",
      "Training loss (for one batch) at step 70: 352.4004, Accuracy: 0.7504\n",
      "Training loss (for one batch) at step 80: 390.2350, Accuracy: 0.7364\n",
      "Training loss (for one batch) at step 90: 368.9859, Accuracy: 0.7320\n",
      "Training loss (for one batch) at step 100: 342.0890, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 110: 360.0305, Accuracy: 0.7375\n",
      "---- Training ----\n",
      "Training loss: 113.1578\n",
      "Training acc over epoch: 0.7380\n",
      "---- Validation ----\n",
      "Validation loss: 41.4392\n",
      "Validation acc: 0.6768\n",
      "Time taken: 10.95s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6593\n",
      "Validation AUC: 0.6596\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 656.0494, Accuracy: 0.4531\n",
      "Training loss (for one batch) at step 10: 614.5276, Accuracy: 0.4964\n",
      "Training loss (for one batch) at step 20: 551.6365, Accuracy: 0.4974\n",
      "Training loss (for one batch) at step 30: 557.6484, Accuracy: 0.5020\n",
      "Training loss (for one batch) at step 40: 543.0197, Accuracy: 0.5050\n",
      "Training loss (for one batch) at step 50: 537.8841, Accuracy: 0.5075\n",
      "Training loss (for one batch) at step 60: 498.4554, Accuracy: 0.5076\n",
      "Training loss (for one batch) at step 70: 483.8275, Accuracy: 0.5110\n",
      "Training loss (for one batch) at step 80: 482.6880, Accuracy: 0.5084\n",
      "Training loss (for one batch) at step 90: 477.4174, Accuracy: 0.5082\n",
      "Training loss (for one batch) at step 100: 468.9812, Accuracy: 0.5089\n",
      "Training loss (for one batch) at step 110: 468.6293, Accuracy: 0.5073\n",
      "---- Training ----\n",
      "Training loss: 142.1354\n",
      "Training acc over epoch: 0.5077\n",
      "---- Validation ----\n",
      "Validation loss: 34.8333\n",
      "Validation acc: 0.4925\n",
      "Time taken: 12.28s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 462.7859, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 469.5328, Accuracy: 0.5369\n",
      "Training loss (for one batch) at step 20: 455.0990, Accuracy: 0.5290\n",
      "Training loss (for one batch) at step 30: 455.1598, Accuracy: 0.5260\n",
      "Training loss (for one batch) at step 40: 459.6665, Accuracy: 0.5250\n",
      "Training loss (for one batch) at step 50: 454.3512, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 60: 454.9180, Accuracy: 0.5223\n",
      "Training loss (for one batch) at step 70: 443.1630, Accuracy: 0.5249\n",
      "Training loss (for one batch) at step 80: 450.3169, Accuracy: 0.5228\n",
      "Training loss (for one batch) at step 90: 448.3652, Accuracy: 0.5233\n",
      "Training loss (for one batch) at step 100: 450.8668, Accuracy: 0.5233\n",
      "Training loss (for one batch) at step 110: 447.2980, Accuracy: 0.5244\n",
      "---- Training ----\n",
      "Training loss: 140.6968\n",
      "Training acc over epoch: 0.5232\n",
      "---- Validation ----\n",
      "Validation loss: 34.8099\n",
      "Validation acc: 0.5134\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 448.4721, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 445.7711, Accuracy: 0.5135\n",
      "Training loss (for one batch) at step 20: 454.2345, Accuracy: 0.5223\n",
      "Training loss (for one batch) at step 30: 450.1187, Accuracy: 0.5204\n",
      "Training loss (for one batch) at step 40: 447.5348, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 50: 447.0532, Accuracy: 0.5290\n",
      "Training loss (for one batch) at step 60: 449.6468, Accuracy: 0.5288\n",
      "Training loss (for one batch) at step 70: 449.7573, Accuracy: 0.5266\n",
      "Training loss (for one batch) at step 80: 445.5941, Accuracy: 0.5275\n",
      "Training loss (for one batch) at step 90: 443.4985, Accuracy: 0.5277\n",
      "Training loss (for one batch) at step 100: 446.1064, Accuracy: 0.5299\n",
      "Training loss (for one batch) at step 110: 444.5315, Accuracy: 0.5310\n",
      "---- Training ----\n",
      "Training loss: 139.4206\n",
      "Training acc over epoch: 0.5324\n",
      "---- Validation ----\n",
      "Validation loss: 34.5484\n",
      "Validation acc: 0.5583\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.2268, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 448.2816, Accuracy: 0.5426\n",
      "Training loss (for one batch) at step 20: 443.0392, Accuracy: 0.5409\n",
      "Training loss (for one batch) at step 30: 447.4886, Accuracy: 0.5403\n",
      "Training loss (for one batch) at step 40: 444.8572, Accuracy: 0.5452\n",
      "Training loss (for one batch) at step 50: 444.3777, Accuracy: 0.5483\n",
      "Training loss (for one batch) at step 60: 444.0162, Accuracy: 0.5488\n",
      "Training loss (for one batch) at step 70: 444.1398, Accuracy: 0.5498\n",
      "Training loss (for one batch) at step 80: 444.4893, Accuracy: 0.5523\n",
      "Training loss (for one batch) at step 90: 444.8697, Accuracy: 0.5542\n",
      "Training loss (for one batch) at step 100: 442.7291, Accuracy: 0.5524\n",
      "Training loss (for one batch) at step 110: 445.1496, Accuracy: 0.5512\n",
      "---- Training ----\n",
      "Training loss: 138.3678\n",
      "Training acc over epoch: 0.5519\n",
      "---- Validation ----\n",
      "Validation loss: 34.9738\n",
      "Validation acc: 0.5712\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 443.1671, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 443.2102, Accuracy: 0.5376\n",
      "Training loss (for one batch) at step 20: 444.9233, Accuracy: 0.5588\n",
      "Training loss (for one batch) at step 30: 444.5503, Accuracy: 0.5622\n",
      "Training loss (for one batch) at step 40: 445.6557, Accuracy: 0.5593\n",
      "Training loss (for one batch) at step 50: 441.9072, Accuracy: 0.5633\n",
      "Training loss (for one batch) at step 60: 442.4619, Accuracy: 0.5644\n",
      "Training loss (for one batch) at step 70: 441.8751, Accuracy: 0.5672\n",
      "Training loss (for one batch) at step 80: 446.5723, Accuracy: 0.5720\n",
      "Training loss (for one batch) at step 90: 443.3836, Accuracy: 0.5713\n",
      "Training loss (for one batch) at step 100: 443.2153, Accuracy: 0.5722\n",
      "Training loss (for one batch) at step 110: 443.2843, Accuracy: 0.5717\n",
      "---- Training ----\n",
      "Training loss: 138.5823\n",
      "Training acc over epoch: 0.5707\n",
      "---- Validation ----\n",
      "Validation loss: 34.3636\n",
      "Validation acc: 0.5865\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 442.6833, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 444.2616, Accuracy: 0.5476\n",
      "Training loss (for one batch) at step 20: 443.4872, Accuracy: 0.5610\n",
      "Training loss (for one batch) at step 30: 443.9359, Accuracy: 0.5670\n",
      "Training loss (for one batch) at step 40: 443.4881, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 50: 441.7958, Accuracy: 0.5790\n",
      "Training loss (for one batch) at step 60: 442.7142, Accuracy: 0.5812\n",
      "Training loss (for one batch) at step 70: 445.7268, Accuracy: 0.5791\n",
      "Training loss (for one batch) at step 80: 444.2238, Accuracy: 0.5801\n",
      "Training loss (for one batch) at step 90: 442.7352, Accuracy: 0.5780\n",
      "Training loss (for one batch) at step 100: 442.6803, Accuracy: 0.5784\n",
      "Training loss (for one batch) at step 110: 441.9988, Accuracy: 0.5785\n",
      "---- Training ----\n",
      "Training loss: 139.4984\n",
      "Training acc over epoch: 0.5774\n",
      "---- Validation ----\n",
      "Validation loss: 34.7132\n",
      "Validation acc: 0.5938\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.2551, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 443.3499, Accuracy: 0.5646\n",
      "Training loss (for one batch) at step 20: 444.5913, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 30: 443.4366, Accuracy: 0.5905\n",
      "Training loss (for one batch) at step 40: 441.6098, Accuracy: 0.5962\n",
      "Training loss (for one batch) at step 50: 443.5952, Accuracy: 0.5983\n",
      "Training loss (for one batch) at step 60: 443.5599, Accuracy: 0.5978\n",
      "Training loss (for one batch) at step 70: 445.3015, Accuracy: 0.6009\n",
      "Training loss (for one batch) at step 80: 443.0957, Accuracy: 0.6012\n",
      "Training loss (for one batch) at step 90: 443.3723, Accuracy: 0.6015\n",
      "Training loss (for one batch) at step 100: 444.1518, Accuracy: 0.5992\n",
      "Training loss (for one batch) at step 110: 443.6368, Accuracy: 0.5995\n",
      "---- Training ----\n",
      "Training loss: 138.7071\n",
      "Training acc over epoch: 0.5999\n",
      "---- Validation ----\n",
      "Validation loss: 35.2271\n",
      "Validation acc: 0.6311\n",
      "Time taken: 11.37s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 441.0608, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 444.0819, Accuracy: 0.5987\n",
      "Training loss (for one batch) at step 20: 442.2654, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 30: 439.4400, Accuracy: 0.6134\n",
      "Training loss (for one batch) at step 40: 440.9872, Accuracy: 0.6191\n",
      "Training loss (for one batch) at step 50: 439.4904, Accuracy: 0.6238\n",
      "Training loss (for one batch) at step 60: 439.1179, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 70: 445.8478, Accuracy: 0.6317\n",
      "Training loss (for one batch) at step 80: 443.2103, Accuracy: 0.6287\n",
      "Training loss (for one batch) at step 90: 442.4010, Accuracy: 0.6262\n",
      "Training loss (for one batch) at step 100: 441.6064, Accuracy: 0.6238\n",
      "Training loss (for one batch) at step 110: 442.2744, Accuracy: 0.6260\n",
      "---- Training ----\n",
      "Training loss: 137.6717\n",
      "Training acc over epoch: 0.6276\n",
      "---- Validation ----\n",
      "Validation loss: 33.9674\n",
      "Validation acc: 0.6574\n",
      "Time taken: 14.99s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 441.1918, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 444.1998, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 440.5162, Accuracy: 0.6488\n",
      "Training loss (for one batch) at step 30: 442.2018, Accuracy: 0.6431\n",
      "Training loss (for one batch) at step 40: 435.9956, Accuracy: 0.6509\n",
      "Training loss (for one batch) at step 50: 440.2705, Accuracy: 0.6564\n",
      "Training loss (for one batch) at step 60: 440.1424, Accuracy: 0.6587\n",
      "Training loss (for one batch) at step 70: 440.6247, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 80: 444.9498, Accuracy: 0.6586\n",
      "Training loss (for one batch) at step 90: 436.6928, Accuracy: 0.6596\n",
      "Training loss (for one batch) at step 100: 437.7646, Accuracy: 0.6594\n",
      "Training loss (for one batch) at step 110: 443.9948, Accuracy: 0.6620\n",
      "---- Training ----\n",
      "Training loss: 137.2667\n",
      "Training acc over epoch: 0.6628\n",
      "---- Validation ----\n",
      "Validation loss: 34.9303\n",
      "Validation acc: 0.6703\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 443.1400, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 439.1246, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 20: 439.9379, Accuracy: 0.6927\n",
      "Training loss (for one batch) at step 30: 439.2973, Accuracy: 0.6978\n",
      "Training loss (for one batch) at step 40: 438.9611, Accuracy: 0.6989\n",
      "Training loss (for one batch) at step 50: 438.6049, Accuracy: 0.6930\n",
      "Training loss (for one batch) at step 60: 435.7928, Accuracy: 0.6939\n",
      "Training loss (for one batch) at step 70: 441.4711, Accuracy: 0.6977\n",
      "Training loss (for one batch) at step 80: 443.0696, Accuracy: 0.6945\n",
      "Training loss (for one batch) at step 90: 442.8776, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 100: 438.4604, Accuracy: 0.6839\n",
      "Training loss (for one batch) at step 110: 433.9515, Accuracy: 0.6850\n",
      "---- Training ----\n",
      "Training loss: 133.9485\n",
      "Training acc over epoch: 0.6858\n",
      "---- Validation ----\n",
      "Validation loss: 35.1640\n",
      "Validation acc: 0.6685\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 442.2040, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 438.2782, Accuracy: 0.6918\n",
      "Training loss (for one batch) at step 20: 439.8032, Accuracy: 0.6823\n",
      "Training loss (for one batch) at step 30: 432.5829, Accuracy: 0.6880\n",
      "Training loss (for one batch) at step 40: 432.9673, Accuracy: 0.6930\n",
      "Training loss (for one batch) at step 50: 434.6386, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 60: 441.4535, Accuracy: 0.6990\n",
      "Training loss (for one batch) at step 70: 442.6839, Accuracy: 0.6987\n",
      "Training loss (for one batch) at step 80: 437.7804, Accuracy: 0.6943\n",
      "Training loss (for one batch) at step 90: 438.1074, Accuracy: 0.6899\n",
      "Training loss (for one batch) at step 100: 434.5711, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 110: 434.4448, Accuracy: 0.6900\n",
      "---- Training ----\n",
      "Training loss: 136.5837\n",
      "Training acc over epoch: 0.6918\n",
      "---- Validation ----\n",
      "Validation loss: 33.8129\n",
      "Validation acc: 0.7257\n",
      "Time taken: 11.66s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 443.5808, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 440.7037, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 20: 442.4578, Accuracy: 0.7076\n",
      "Training loss (for one batch) at step 30: 434.1105, Accuracy: 0.7132\n",
      "Training loss (for one batch) at step 40: 427.0551, Accuracy: 0.7186\n",
      "Training loss (for one batch) at step 50: 422.3517, Accuracy: 0.7232\n",
      "Training loss (for one batch) at step 60: 435.9500, Accuracy: 0.7261\n",
      "Training loss (for one batch) at step 70: 451.6158, Accuracy: 0.7271\n",
      "Training loss (for one batch) at step 80: 439.4310, Accuracy: 0.7236\n",
      "Training loss (for one batch) at step 90: 441.0574, Accuracy: 0.7193\n",
      "Training loss (for one batch) at step 100: 435.0054, Accuracy: 0.7190\n",
      "Training loss (for one batch) at step 110: 425.7124, Accuracy: 0.7184\n",
      "---- Training ----\n",
      "Training loss: 134.1471\n",
      "Training acc over epoch: 0.7185\n",
      "---- Validation ----\n",
      "Validation loss: 34.3075\n",
      "Validation acc: 0.7133\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 440.3661, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 436.4173, Accuracy: 0.7337\n",
      "Training loss (for one batch) at step 20: 433.1289, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 30: 431.8063, Accuracy: 0.7286\n",
      "Training loss (for one batch) at step 40: 421.5808, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 50: 411.1080, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 60: 430.9573, Accuracy: 0.7410\n",
      "Training loss (for one batch) at step 70: 439.2641, Accuracy: 0.7383\n",
      "Training loss (for one batch) at step 80: 440.9062, Accuracy: 0.7343\n",
      "Training loss (for one batch) at step 90: 435.3781, Accuracy: 0.7274\n",
      "Training loss (for one batch) at step 100: 435.5493, Accuracy: 0.7276\n",
      "Training loss (for one batch) at step 110: 437.0842, Accuracy: 0.7269\n",
      "---- Training ----\n",
      "Training loss: 137.3598\n",
      "Training acc over epoch: 0.7268\n",
      "---- Validation ----\n",
      "Validation loss: 34.5629\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 442.9731, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 440.1117, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 20: 439.9186, Accuracy: 0.7106\n",
      "Training loss (for one batch) at step 30: 430.1099, Accuracy: 0.7175\n",
      "Training loss (for one batch) at step 40: 439.7890, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 50: 412.7542, Accuracy: 0.7414\n",
      "Training loss (for one batch) at step 60: 419.8752, Accuracy: 0.7465\n",
      "Training loss (for one batch) at step 70: 440.0814, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 80: 441.3271, Accuracy: 0.7423\n",
      "Training loss (for one batch) at step 90: 436.7435, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 100: 427.7796, Accuracy: 0.7372\n",
      "Training loss (for one batch) at step 110: 436.4134, Accuracy: 0.7378\n",
      "---- Training ----\n",
      "Training loss: 134.9753\n",
      "Training acc over epoch: 0.7393\n",
      "---- Validation ----\n",
      "Validation loss: 36.6744\n",
      "Validation acc: 0.6306\n",
      "Time taken: 11.96s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 444.5135, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 434.7246, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 20: 436.0309, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 30: 423.8435, Accuracy: 0.7339\n",
      "Training loss (for one batch) at step 40: 415.0153, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 50: 414.9156, Accuracy: 0.7531\n",
      "Training loss (for one batch) at step 60: 425.9341, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 70: 434.6559, Accuracy: 0.7575\n",
      "Training loss (for one batch) at step 80: 441.0266, Accuracy: 0.7505\n",
      "Training loss (for one batch) at step 90: 437.1376, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 100: 429.8241, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 110: 437.4254, Accuracy: 0.7406\n",
      "---- Training ----\n",
      "Training loss: 131.9634\n",
      "Training acc over epoch: 0.7414\n",
      "---- Validation ----\n",
      "Validation loss: 37.1699\n",
      "Validation acc: 0.6983\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 443.2879, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 440.2770, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 20: 436.6598, Accuracy: 0.7281\n",
      "Training loss (for one batch) at step 30: 420.5025, Accuracy: 0.7301\n",
      "Training loss (for one batch) at step 40: 412.8046, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 50: 409.5562, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 60: 420.8390, Accuracy: 0.7605\n",
      "Training loss (for one batch) at step 70: 438.4441, Accuracy: 0.7603\n",
      "Training loss (for one batch) at step 80: 436.9500, Accuracy: 0.7559\n",
      "Training loss (for one batch) at step 90: 433.3779, Accuracy: 0.7496\n",
      "Training loss (for one batch) at step 100: 432.6310, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 110: 435.7337, Accuracy: 0.7486\n",
      "---- Training ----\n",
      "Training loss: 139.0241\n",
      "Training acc over epoch: 0.7479\n",
      "---- Validation ----\n",
      "Validation loss: 34.6449\n",
      "Validation acc: 0.6792\n",
      "Time taken: 10.83s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 445.5148, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 436.0074, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 427.6635, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 30: 413.1680, Accuracy: 0.7434\n",
      "Training loss (for one batch) at step 40: 410.3568, Accuracy: 0.7544\n",
      "Training loss (for one batch) at step 50: 413.0256, Accuracy: 0.7672\n",
      "Training loss (for one batch) at step 60: 424.1010, Accuracy: 0.7746\n",
      "Training loss (for one batch) at step 70: 436.5486, Accuracy: 0.7759\n",
      "Training loss (for one batch) at step 80: 435.7727, Accuracy: 0.7669\n",
      "Training loss (for one batch) at step 90: 432.8372, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 100: 425.7848, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 110: 430.1158, Accuracy: 0.7625\n",
      "---- Training ----\n",
      "Training loss: 139.8029\n",
      "Training acc over epoch: 0.7630\n",
      "---- Validation ----\n",
      "Validation loss: 33.1260\n",
      "Validation acc: 0.7569\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 441.4604, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 439.0804, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 426.3888, Accuracy: 0.7463\n",
      "Training loss (for one batch) at step 30: 418.9087, Accuracy: 0.7563\n",
      "Training loss (for one batch) at step 40: 418.4695, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 50: 407.3281, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 60: 422.0092, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 70: 442.8141, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 80: 436.4363, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 90: 431.7020, Accuracy: 0.7691\n",
      "Training loss (for one batch) at step 100: 435.1955, Accuracy: 0.7672\n",
      "Training loss (for one batch) at step 110: 435.4242, Accuracy: 0.7676\n",
      "---- Training ----\n",
      "Training loss: 130.5732\n",
      "Training acc over epoch: 0.7664\n",
      "---- Validation ----\n",
      "Validation loss: 37.4780\n",
      "Validation acc: 0.7141\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 447.1915, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 439.7256, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 20: 427.7759, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 30: 412.6355, Accuracy: 0.7576\n",
      "Training loss (for one batch) at step 40: 407.6981, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 50: 400.5528, Accuracy: 0.7793\n",
      "Training loss (for one batch) at step 60: 427.4243, Accuracy: 0.7893\n",
      "Training loss (for one batch) at step 70: 429.2474, Accuracy: 0.7893\n",
      "Training loss (for one batch) at step 80: 431.7454, Accuracy: 0.7832\n",
      "Training loss (for one batch) at step 90: 425.7632, Accuracy: 0.7766\n",
      "Training loss (for one batch) at step 100: 426.3984, Accuracy: 0.7737\n",
      "Training loss (for one batch) at step 110: 425.7715, Accuracy: 0.7744\n",
      "---- Training ----\n",
      "Training loss: 131.6385\n",
      "Training acc over epoch: 0.7736\n",
      "---- Validation ----\n",
      "Validation loss: 34.8387\n",
      "Validation acc: 0.7491\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 445.3397, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 435.6927, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 428.8933, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 418.7050, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 40: 403.8822, Accuracy: 0.7748\n",
      "Training loss (for one batch) at step 50: 394.6950, Accuracy: 0.7907\n",
      "Training loss (for one batch) at step 60: 418.5846, Accuracy: 0.8002\n",
      "Training loss (for one batch) at step 70: 438.4670, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 80: 440.3401, Accuracy: 0.7870\n",
      "Training loss (for one batch) at step 90: 437.1102, Accuracy: 0.7788\n",
      "Training loss (for one batch) at step 100: 417.1312, Accuracy: 0.7785\n",
      "Training loss (for one batch) at step 110: 428.8111, Accuracy: 0.7769\n",
      "---- Training ----\n",
      "Training loss: 133.9216\n",
      "Training acc over epoch: 0.7762\n",
      "---- Validation ----\n",
      "Validation loss: 36.7852\n",
      "Validation acc: 0.7313\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 437.9703, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 439.8600, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 432.7196, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 30: 413.6238, Accuracy: 0.7755\n",
      "Training loss (for one batch) at step 40: 395.9093, Accuracy: 0.7856\n",
      "Training loss (for one batch) at step 50: 393.8458, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 60: 411.4254, Accuracy: 0.8046\n",
      "Training loss (for one batch) at step 70: 441.7053, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 80: 439.8371, Accuracy: 0.7934\n",
      "Training loss (for one batch) at step 90: 426.8663, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 100: 430.6924, Accuracy: 0.7840\n",
      "Training loss (for one batch) at step 110: 419.0571, Accuracy: 0.7832\n",
      "---- Training ----\n",
      "Training loss: 132.3046\n",
      "Training acc over epoch: 0.7824\n",
      "---- Validation ----\n",
      "Validation loss: 36.3620\n",
      "Validation acc: 0.7566\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 443.8723, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 427.0885, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 20: 425.4727, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 30: 409.0988, Accuracy: 0.7853\n",
      "Training loss (for one batch) at step 40: 392.3079, Accuracy: 0.7938\n",
      "Training loss (for one batch) at step 50: 384.0636, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 60: 432.1922, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 70: 417.1082, Accuracy: 0.8131\n",
      "Training loss (for one batch) at step 80: 443.5731, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 90: 433.0611, Accuracy: 0.7938\n",
      "Training loss (for one batch) at step 100: 425.6448, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 110: 414.9929, Accuracy: 0.7920\n",
      "---- Training ----\n",
      "Training loss: 133.6204\n",
      "Training acc over epoch: 0.7925\n",
      "---- Validation ----\n",
      "Validation loss: 34.1352\n",
      "Validation acc: 0.7552\n",
      "Time taken: 10.97s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 431.2433, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 438.3873, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 20: 417.9083, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 30: 400.6995, Accuracy: 0.7777\n",
      "Training loss (for one batch) at step 40: 389.2921, Accuracy: 0.7906\n",
      "Training loss (for one batch) at step 50: 389.4698, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 60: 393.7633, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 70: 425.3018, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 80: 430.4729, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 90: 429.5806, Accuracy: 0.7982\n",
      "Training loss (for one batch) at step 100: 431.7855, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 110: 427.5197, Accuracy: 0.7918\n",
      "---- Training ----\n",
      "Training loss: 128.8574\n",
      "Training acc over epoch: 0.7916\n",
      "---- Validation ----\n",
      "Validation loss: 34.5994\n",
      "Validation acc: 0.7321\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 440.3697, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 430.1874, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 20: 420.2962, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 30: 410.8581, Accuracy: 0.7780\n",
      "Training loss (for one batch) at step 40: 379.9836, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 50: 382.0355, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 60: 396.6286, Accuracy: 0.8160\n",
      "Training loss (for one batch) at step 70: 423.7382, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 80: 419.9505, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 90: 428.6825, Accuracy: 0.8004\n",
      "Training loss (for one batch) at step 100: 413.0534, Accuracy: 0.7963\n",
      "Training loss (for one batch) at step 110: 419.6775, Accuracy: 0.7945\n",
      "---- Training ----\n",
      "Training loss: 129.9763\n",
      "Training acc over epoch: 0.7939\n",
      "---- Validation ----\n",
      "Validation loss: 34.2902\n",
      "Validation acc: 0.7477\n",
      "Time taken: 12.53s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 439.3649, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 435.8565, Accuracy: 0.7777\n",
      "Training loss (for one batch) at step 20: 408.3589, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 30: 400.7588, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 40: 386.5840, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 50: 359.7721, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 60: 403.1518, Accuracy: 0.8253\n",
      "Training loss (for one batch) at step 70: 432.6954, Accuracy: 0.8222\n",
      "Training loss (for one batch) at step 80: 419.0098, Accuracy: 0.8145\n",
      "Training loss (for one batch) at step 90: 420.3278, Accuracy: 0.8053\n",
      "Training loss (for one batch) at step 100: 415.8834, Accuracy: 0.8028\n",
      "Training loss (for one batch) at step 110: 425.8122, Accuracy: 0.8024\n",
      "---- Training ----\n",
      "Training loss: 134.5796\n",
      "Training acc over epoch: 0.8014\n",
      "---- Validation ----\n",
      "Validation loss: 38.9165\n",
      "Validation acc: 0.7517\n",
      "Time taken: 12.11s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 425.2694, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 424.6388, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 403.8895, Accuracy: 0.7790\n",
      "Training loss (for one batch) at step 30: 395.0938, Accuracy: 0.7931\n",
      "Training loss (for one batch) at step 40: 379.4510, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 50: 365.9213, Accuracy: 0.8172\n",
      "Training loss (for one batch) at step 60: 395.6897, Accuracy: 0.8277\n",
      "Training loss (for one batch) at step 70: 404.3574, Accuracy: 0.8253\n",
      "Training loss (for one batch) at step 80: 426.3456, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 90: 409.1920, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 100: 426.5851, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 110: 415.1917, Accuracy: 0.8017\n",
      "---- Training ----\n",
      "Training loss: 130.7062\n",
      "Training acc over epoch: 0.8015\n",
      "---- Validation ----\n",
      "Validation loss: 35.0702\n",
      "Validation acc: 0.7128\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 419.1867, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 435.5117, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 20: 410.2748, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 30: 385.7863, Accuracy: 0.7893\n",
      "Training loss (for one batch) at step 40: 371.4255, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 50: 367.6799, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 60: 368.1765, Accuracy: 0.8275\n",
      "Training loss (for one batch) at step 70: 381.2031, Accuracy: 0.8252\n",
      "Training loss (for one batch) at step 80: 430.4240, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 90: 414.9895, Accuracy: 0.8098\n",
      "Training loss (for one batch) at step 100: 402.7193, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 110: 414.2774, Accuracy: 0.8071\n",
      "---- Training ----\n",
      "Training loss: 125.0384\n",
      "Training acc over epoch: 0.8060\n",
      "---- Validation ----\n",
      "Validation loss: 35.5685\n",
      "Validation acc: 0.7442\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 434.0541, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 410.4391, Accuracy: 0.7855\n",
      "Training loss (for one batch) at step 20: 401.6593, Accuracy: 0.7790\n",
      "Training loss (for one batch) at step 30: 382.3183, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 40: 366.6669, Accuracy: 0.8106\n",
      "Training loss (for one batch) at step 50: 358.9942, Accuracy: 0.8266\n",
      "Training loss (for one batch) at step 60: 367.4811, Accuracy: 0.8335\n",
      "Training loss (for one batch) at step 70: 406.2432, Accuracy: 0.8279\n",
      "Training loss (for one batch) at step 80: 410.9196, Accuracy: 0.8213\n",
      "Training loss (for one batch) at step 90: 401.9027, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 100: 385.6328, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 110: 413.0593, Accuracy: 0.8133\n",
      "---- Training ----\n",
      "Training loss: 122.7768\n",
      "Training acc over epoch: 0.8117\n",
      "---- Validation ----\n",
      "Validation loss: 35.8572\n",
      "Validation acc: 0.7340\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 432.6758, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 413.9873, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 20: 393.3831, Accuracy: 0.7712\n",
      "Training loss (for one batch) at step 30: 380.6022, Accuracy: 0.7888\n",
      "Training loss (for one batch) at step 40: 363.1048, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 50: 344.7364, Accuracy: 0.8217\n",
      "Training loss (for one batch) at step 60: 388.2936, Accuracy: 0.8308\n",
      "Training loss (for one batch) at step 70: 401.1421, Accuracy: 0.8259\n",
      "Training loss (for one batch) at step 80: 419.4017, Accuracy: 0.8176\n",
      "Training loss (for one batch) at step 90: 407.6698, Accuracy: 0.8117\n",
      "Training loss (for one batch) at step 100: 378.1339, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 110: 405.0064, Accuracy: 0.8073\n",
      "---- Training ----\n",
      "Training loss: 121.7004\n",
      "Training acc over epoch: 0.8067\n",
      "---- Validation ----\n",
      "Validation loss: 34.8932\n",
      "Validation acc: 0.7206\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 424.2859, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 410.6442, Accuracy: 0.7408\n",
      "Training loss (for one batch) at step 20: 390.4670, Accuracy: 0.7563\n",
      "Training loss (for one batch) at step 30: 373.6012, Accuracy: 0.7853\n",
      "Training loss (for one batch) at step 40: 372.2469, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 50: 348.6292, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 60: 382.7747, Accuracy: 0.8279\n",
      "Training loss (for one batch) at step 70: 382.3883, Accuracy: 0.8243\n",
      "Training loss (for one batch) at step 80: 405.4688, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 90: 390.0324, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 100: 397.7844, Accuracy: 0.8081\n",
      "Training loss (for one batch) at step 110: 395.8462, Accuracy: 0.8082\n",
      "---- Training ----\n",
      "Training loss: 128.8412\n",
      "Training acc over epoch: 0.8075\n",
      "---- Validation ----\n",
      "Validation loss: 34.8467\n",
      "Validation acc: 0.7354\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 416.8498, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 422.3748, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 20: 390.7745, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 30: 375.8677, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 40: 352.1149, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 50: 333.0334, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 60: 368.4456, Accuracy: 0.8290\n",
      "Training loss (for one batch) at step 70: 394.8422, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 80: 403.0420, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 90: 378.7164, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 100: 367.1774, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 110: 392.2551, Accuracy: 0.8085\n",
      "---- Training ----\n",
      "Training loss: 116.6799\n",
      "Training acc over epoch: 0.8075\n",
      "---- Validation ----\n",
      "Validation loss: 38.7600\n",
      "Validation acc: 0.7319\n",
      "Time taken: 11.90s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 422.1687, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 401.9340, Accuracy: 0.7670\n",
      "Training loss (for one batch) at step 20: 383.4495, Accuracy: 0.7786\n",
      "Training loss (for one batch) at step 30: 369.2438, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 40: 347.7687, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 50: 345.1371, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 60: 363.4445, Accuracy: 0.8349\n",
      "Training loss (for one batch) at step 70: 397.8102, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 80: 380.6879, Accuracy: 0.8191\n",
      "Training loss (for one batch) at step 90: 389.2123, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 100: 381.5055, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 110: 382.1377, Accuracy: 0.8145\n",
      "---- Training ----\n",
      "Training loss: 127.7260\n",
      "Training acc over epoch: 0.8129\n",
      "---- Validation ----\n",
      "Validation loss: 39.5933\n",
      "Validation acc: 0.7270\n",
      "Time taken: 11.14s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 426.6589, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 407.3852, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 384.5306, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 30: 371.4790, Accuracy: 0.7926\n",
      "Training loss (for one batch) at step 40: 384.3951, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 50: 334.1671, Accuracy: 0.8260\n",
      "Training loss (for one batch) at step 60: 351.4997, Accuracy: 0.8341\n",
      "Training loss (for one batch) at step 70: 399.1466, Accuracy: 0.8279\n",
      "Training loss (for one batch) at step 80: 395.5832, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 90: 364.6873, Accuracy: 0.8114\n",
      "Training loss (for one batch) at step 100: 352.2718, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 110: 378.3212, Accuracy: 0.8086\n",
      "---- Training ----\n",
      "Training loss: 132.0957\n",
      "Training acc over epoch: 0.8066\n",
      "---- Validation ----\n",
      "Validation loss: 42.2191\n",
      "Validation acc: 0.7241\n",
      "Time taken: 11.28s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 405.5942, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 405.2328, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 20: 370.7889, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 30: 362.5730, Accuracy: 0.7959\n",
      "Training loss (for one batch) at step 40: 373.0000, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 50: 330.9655, Accuracy: 0.8294\n",
      "Training loss (for one batch) at step 60: 362.9780, Accuracy: 0.8367\n",
      "Training loss (for one batch) at step 70: 385.8837, Accuracy: 0.8299\n",
      "Training loss (for one batch) at step 80: 392.2147, Accuracy: 0.8177\n",
      "Training loss (for one batch) at step 90: 360.8465, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 100: 351.5646, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 110: 377.5311, Accuracy: 0.8142\n",
      "---- Training ----\n",
      "Training loss: 126.6937\n",
      "Training acc over epoch: 0.8130\n",
      "---- Validation ----\n",
      "Validation loss: 44.8421\n",
      "Validation acc: 0.7219\n",
      "Time taken: 11.59s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 428.8673, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 387.7474, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 366.2759, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 30: 366.1632, Accuracy: 0.7913\n",
      "Training loss (for one batch) at step 40: 337.7092, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 50: 345.8808, Accuracy: 0.8290\n",
      "Training loss (for one batch) at step 60: 348.8452, Accuracy: 0.8348\n",
      "Training loss (for one batch) at step 70: 377.6808, Accuracy: 0.8289\n",
      "Training loss (for one batch) at step 80: 384.6905, Accuracy: 0.8190\n",
      "Training loss (for one batch) at step 90: 375.7457, Accuracy: 0.8154\n",
      "Training loss (for one batch) at step 100: 369.3173, Accuracy: 0.8168\n",
      "Training loss (for one batch) at step 110: 397.7676, Accuracy: 0.8156\n",
      "---- Training ----\n",
      "Training loss: 122.5127\n",
      "Training acc over epoch: 0.8145\n",
      "---- Validation ----\n",
      "Validation loss: 37.7523\n",
      "Validation acc: 0.7270\n",
      "Time taken: 11.07s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 409.6483, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 395.2761, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 20: 373.2584, Accuracy: 0.7686\n",
      "Training loss (for one batch) at step 30: 350.6099, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 357.9174, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 50: 327.4652, Accuracy: 0.8283\n",
      "Training loss (for one batch) at step 60: 360.8545, Accuracy: 0.8379\n",
      "Training loss (for one batch) at step 70: 373.1777, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 80: 395.7588, Accuracy: 0.8195\n",
      "Training loss (for one batch) at step 90: 364.5452, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 100: 349.4002, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 110: 380.6440, Accuracy: 0.8145\n",
      "---- Training ----\n",
      "Training loss: 115.5026\n",
      "Training acc over epoch: 0.8137\n",
      "---- Validation ----\n",
      "Validation loss: 40.4474\n",
      "Validation acc: 0.7235\n",
      "Time taken: 13.92s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 397.9482, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 396.4099, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 371.5573, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 30: 359.7933, Accuracy: 0.7954\n",
      "Training loss (for one batch) at step 40: 344.0032, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 50: 318.2077, Accuracy: 0.8332\n",
      "Training loss (for one batch) at step 60: 372.5025, Accuracy: 0.8405\n",
      "Training loss (for one batch) at step 70: 383.0294, Accuracy: 0.8313\n",
      "Training loss (for one batch) at step 80: 390.3031, Accuracy: 0.8227\n",
      "Training loss (for one batch) at step 90: 350.6776, Accuracy: 0.8198\n",
      "Training loss (for one batch) at step 100: 370.5031, Accuracy: 0.8201\n",
      "Training loss (for one batch) at step 110: 366.3982, Accuracy: 0.8195\n",
      "---- Training ----\n",
      "Training loss: 114.7965\n",
      "Training acc over epoch: 0.8180\n",
      "---- Validation ----\n",
      "Validation loss: 41.5572\n",
      "Validation acc: 0.7273\n",
      "Time taken: 11.01s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 406.1173, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 380.4349, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 20: 349.9816, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 30: 337.2396, Accuracy: 0.7876\n",
      "Training loss (for one batch) at step 40: 336.6321, Accuracy: 0.8123\n",
      "Training loss (for one batch) at step 50: 340.2081, Accuracy: 0.8272\n",
      "Training loss (for one batch) at step 60: 341.8701, Accuracy: 0.8364\n",
      "Training loss (for one batch) at step 70: 379.4507, Accuracy: 0.8285\n",
      "Training loss (for one batch) at step 80: 396.0346, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 90: 357.1245, Accuracy: 0.8148\n",
      "Training loss (for one batch) at step 100: 372.8618, Accuracy: 0.8136\n",
      "Training loss (for one batch) at step 110: 361.0366, Accuracy: 0.8138\n",
      "---- Training ----\n",
      "Training loss: 111.1575\n",
      "Training acc over epoch: 0.8120\n",
      "---- Validation ----\n",
      "Validation loss: 36.8191\n",
      "Validation acc: 0.7160\n",
      "Time taken: 11.18s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 393.6806, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 391.8409, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 20: 384.8108, Accuracy: 0.7571\n",
      "Training loss (for one batch) at step 30: 341.5053, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 40: 329.6732, Accuracy: 0.8077\n",
      "Training loss (for one batch) at step 50: 337.0614, Accuracy: 0.8238\n",
      "Training loss (for one batch) at step 60: 374.7625, Accuracy: 0.8344\n",
      "Training loss (for one batch) at step 70: 378.1358, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 80: 385.7484, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 90: 367.5565, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 100: 364.9907, Accuracy: 0.8160\n",
      "Training loss (for one batch) at step 110: 368.1220, Accuracy: 0.8148\n",
      "---- Training ----\n",
      "Training loss: 113.5277\n",
      "Training acc over epoch: 0.8141\n",
      "---- Validation ----\n",
      "Validation loss: 46.2859\n",
      "Validation acc: 0.7364\n",
      "Time taken: 11.25s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 403.1532, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 376.6108, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 356.4637, Accuracy: 0.7630\n",
      "Training loss (for one batch) at step 30: 359.7801, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 325.0472, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 50: 319.0875, Accuracy: 0.8286\n",
      "Training loss (for one batch) at step 60: 347.5446, Accuracy: 0.8368\n",
      "Training loss (for one batch) at step 70: 387.1815, Accuracy: 0.8278\n",
      "Training loss (for one batch) at step 80: 362.2436, Accuracy: 0.8172\n",
      "Training loss (for one batch) at step 90: 350.9899, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 100: 346.3244, Accuracy: 0.8181\n",
      "Training loss (for one batch) at step 110: 394.5130, Accuracy: 0.8177\n",
      "---- Training ----\n",
      "Training loss: 114.7026\n",
      "Training acc over epoch: 0.8160\n",
      "---- Validation ----\n",
      "Validation loss: 37.5784\n",
      "Validation acc: 0.7243\n",
      "Time taken: 11.00s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7270\n",
      "Validation AUC: 0.7273\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 711.5188, Accuracy: 0.4531\n",
      "Training loss (for one batch) at step 10: 633.2187, Accuracy: 0.5028\n",
      "Training loss (for one batch) at step 20: 587.0336, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 30: 546.2847, Accuracy: 0.5071\n",
      "Training loss (for one batch) at step 40: 518.2297, Accuracy: 0.5091\n",
      "Training loss (for one batch) at step 50: 509.8709, Accuracy: 0.5130\n",
      "Training loss (for one batch) at step 60: 510.5669, Accuracy: 0.5093\n",
      "Training loss (for one batch) at step 70: 513.0913, Accuracy: 0.5067\n",
      "Training loss (for one batch) at step 80: 523.1541, Accuracy: 0.5053\n",
      "Training loss (for one batch) at step 90: 491.9187, Accuracy: 0.5037\n",
      "Training loss (for one batch) at step 100: 488.1905, Accuracy: 0.5064\n",
      "Training loss (for one batch) at step 110: 468.4233, Accuracy: 0.5068\n",
      "---- Training ----\n",
      "Training loss: 149.3179\n",
      "Training acc over epoch: 0.5078\n",
      "---- Validation ----\n",
      "Validation loss: 34.2710\n",
      "Validation acc: 0.5016\n",
      "Time taken: 13.28s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 461.2493, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 473.4629, Accuracy: 0.5206\n",
      "Training loss (for one batch) at step 20: 468.8585, Accuracy: 0.5182\n",
      "Training loss (for one batch) at step 30: 463.4505, Accuracy: 0.5232\n",
      "Training loss (for one batch) at step 40: 460.6743, Accuracy: 0.5265\n",
      "Training loss (for one batch) at step 50: 448.6054, Accuracy: 0.5286\n",
      "Training loss (for one batch) at step 60: 463.3206, Accuracy: 0.5229\n",
      "Training loss (for one batch) at step 70: 463.5748, Accuracy: 0.5233\n",
      "Training loss (for one batch) at step 80: 448.7911, Accuracy: 0.5226\n",
      "Training loss (for one batch) at step 90: 460.2608, Accuracy: 0.5203\n",
      "Training loss (for one batch) at step 100: 458.7607, Accuracy: 0.5188\n",
      "Training loss (for one batch) at step 110: 454.2337, Accuracy: 0.5201\n",
      "---- Training ----\n",
      "Training loss: 139.9885\n",
      "Training acc over epoch: 0.5189\n",
      "---- Validation ----\n",
      "Validation loss: 35.1008\n",
      "Validation acc: 0.5030\n",
      "Time taken: 10.95s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 454.2708, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 454.1189, Accuracy: 0.5298\n",
      "Training loss (for one batch) at step 20: 447.3141, Accuracy: 0.5260\n",
      "Training loss (for one batch) at step 30: 449.4681, Accuracy: 0.5340\n",
      "Training loss (for one batch) at step 40: 445.8838, Accuracy: 0.5366\n",
      "Training loss (for one batch) at step 50: 448.1833, Accuracy: 0.5358\n",
      "Training loss (for one batch) at step 60: 450.0459, Accuracy: 0.5356\n",
      "Training loss (for one batch) at step 70: 445.0338, Accuracy: 0.5373\n",
      "Training loss (for one batch) at step 80: 446.4937, Accuracy: 0.5371\n",
      "Training loss (for one batch) at step 90: 445.3576, Accuracy: 0.5385\n",
      "Training loss (for one batch) at step 100: 445.8605, Accuracy: 0.5408\n",
      "Training loss (for one batch) at step 110: 446.9231, Accuracy: 0.5425\n",
      "---- Training ----\n",
      "Training loss: 138.2979\n",
      "Training acc over epoch: 0.5431\n",
      "---- Validation ----\n",
      "Validation loss: 34.5022\n",
      "Validation acc: 0.5750\n",
      "Time taken: 11.12s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 443.1398, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 447.5710, Accuracy: 0.5774\n",
      "Training loss (for one batch) at step 20: 444.7386, Accuracy: 0.5740\n",
      "Training loss (for one batch) at step 30: 444.7543, Accuracy: 0.5691\n",
      "Training loss (for one batch) at step 40: 443.0313, Accuracy: 0.5696\n",
      "Training loss (for one batch) at step 50: 445.3861, Accuracy: 0.5654\n",
      "Training loss (for one batch) at step 60: 442.0616, Accuracy: 0.5634\n",
      "Training loss (for one batch) at step 70: 443.8576, Accuracy: 0.5656\n",
      "Training loss (for one batch) at step 80: 443.7088, Accuracy: 0.5613\n",
      "Training loss (for one batch) at step 90: 442.5771, Accuracy: 0.5610\n",
      "Training loss (for one batch) at step 100: 442.3928, Accuracy: 0.5610\n",
      "Training loss (for one batch) at step 110: 442.1919, Accuracy: 0.5599\n",
      "---- Training ----\n",
      "Training loss: 138.1880\n",
      "Training acc over epoch: 0.5613\n",
      "---- Validation ----\n",
      "Validation loss: 34.4536\n",
      "Validation acc: 0.5895\n",
      "Time taken: 11.21s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 442.9949, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 446.7689, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 20: 442.0957, Accuracy: 0.5573\n",
      "Training loss (for one batch) at step 30: 444.9668, Accuracy: 0.5643\n",
      "Training loss (for one batch) at step 40: 438.9362, Accuracy: 0.5705\n",
      "Training loss (for one batch) at step 50: 443.5803, Accuracy: 0.5767\n",
      "Training loss (for one batch) at step 60: 442.9091, Accuracy: 0.5800\n",
      "Training loss (for one batch) at step 70: 444.6109, Accuracy: 0.5826\n",
      "Training loss (for one batch) at step 80: 444.5389, Accuracy: 0.5802\n",
      "Training loss (for one batch) at step 90: 442.7348, Accuracy: 0.5792\n",
      "Training loss (for one batch) at step 100: 440.3677, Accuracy: 0.5838\n",
      "Training loss (for one batch) at step 110: 440.9582, Accuracy: 0.5861\n",
      "---- Training ----\n",
      "Training loss: 137.2827\n",
      "Training acc over epoch: 0.5868\n",
      "---- Validation ----\n",
      "Validation loss: 34.7805\n",
      "Validation acc: 0.6333\n",
      "Time taken: 10.93s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 441.5864, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 443.5042, Accuracy: 0.5916\n",
      "Training loss (for one batch) at step 20: 443.7455, Accuracy: 0.5677\n",
      "Training loss (for one batch) at step 30: 441.2116, Accuracy: 0.5822\n",
      "Training loss (for one batch) at step 40: 439.9866, Accuracy: 0.5905\n",
      "Training loss (for one batch) at step 50: 442.3250, Accuracy: 0.5925\n",
      "Training loss (for one batch) at step 60: 444.4009, Accuracy: 0.5976\n",
      "Training loss (for one batch) at step 70: 445.3329, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 80: 443.7309, Accuracy: 0.5882\n",
      "Training loss (for one batch) at step 90: 440.5323, Accuracy: 0.5840\n",
      "Training loss (for one batch) at step 100: 442.9278, Accuracy: 0.5869\n",
      "Training loss (for one batch) at step 110: 443.6451, Accuracy: 0.5903\n",
      "---- Training ----\n",
      "Training loss: 138.2076\n",
      "Training acc over epoch: 0.5908\n",
      "---- Validation ----\n",
      "Validation loss: 35.0511\n",
      "Validation acc: 0.6319\n",
      "Time taken: 11.10s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 440.4106, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 443.8586, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 20: 439.6962, Accuracy: 0.6079\n",
      "Training loss (for one batch) at step 30: 439.6036, Accuracy: 0.6116\n",
      "Training loss (for one batch) at step 40: 438.5043, Accuracy: 0.6139\n",
      "Training loss (for one batch) at step 50: 439.3901, Accuracy: 0.6175\n",
      "Training loss (for one batch) at step 60: 443.1707, Accuracy: 0.6160\n",
      "Training loss (for one batch) at step 70: 439.9915, Accuracy: 0.6167\n",
      "Training loss (for one batch) at step 80: 443.3922, Accuracy: 0.6076\n",
      "Training loss (for one batch) at step 90: 439.4283, Accuracy: 0.6052\n",
      "Training loss (for one batch) at step 100: 440.6949, Accuracy: 0.6030\n",
      "Training loss (for one batch) at step 110: 439.8747, Accuracy: 0.6048\n",
      "---- Training ----\n",
      "Training loss: 137.8536\n",
      "Training acc over epoch: 0.6053\n",
      "---- Validation ----\n",
      "Validation loss: 34.2426\n",
      "Validation acc: 0.6354\n",
      "Time taken: 11.18s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.3566, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 444.4886, Accuracy: 0.6243\n",
      "Training loss (for one batch) at step 20: 440.1477, Accuracy: 0.6027\n",
      "Training loss (for one batch) at step 30: 438.9648, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 40: 436.4963, Accuracy: 0.6138\n",
      "Training loss (for one batch) at step 50: 437.4359, Accuracy: 0.6180\n",
      "Training loss (for one batch) at step 60: 436.8884, Accuracy: 0.6185\n",
      "Training loss (for one batch) at step 70: 441.0657, Accuracy: 0.6173\n",
      "Training loss (for one batch) at step 80: 444.8862, Accuracy: 0.6128\n",
      "Training loss (for one batch) at step 90: 441.3678, Accuracy: 0.6104\n",
      "Training loss (for one batch) at step 100: 439.6072, Accuracy: 0.6125\n",
      "Training loss (for one batch) at step 110: 444.8708, Accuracy: 0.6156\n",
      "---- Training ----\n",
      "Training loss: 139.7141\n",
      "Training acc over epoch: 0.6173\n",
      "---- Validation ----\n",
      "Validation loss: 36.2712\n",
      "Validation acc: 0.6596\n",
      "Time taken: 10.98s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 441.2754, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 444.8401, Accuracy: 0.6214\n",
      "Training loss (for one batch) at step 20: 442.3770, Accuracy: 0.6127\n",
      "Training loss (for one batch) at step 30: 439.7508, Accuracy: 0.6157\n",
      "Training loss (for one batch) at step 40: 441.2661, Accuracy: 0.6254\n",
      "Training loss (for one batch) at step 50: 433.9776, Accuracy: 0.6311\n",
      "Training loss (for one batch) at step 60: 440.9119, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 70: 444.5721, Accuracy: 0.6348\n",
      "Training loss (for one batch) at step 80: 443.5177, Accuracy: 0.6273\n",
      "Training loss (for one batch) at step 90: 440.7466, Accuracy: 0.6237\n",
      "Training loss (for one batch) at step 100: 437.8237, Accuracy: 0.6245\n",
      "Training loss (for one batch) at step 110: 442.5408, Accuracy: 0.6261\n",
      "---- Training ----\n",
      "Training loss: 138.6592\n",
      "Training acc over epoch: 0.6282\n",
      "---- Validation ----\n",
      "Validation loss: 34.5218\n",
      "Validation acc: 0.6609\n",
      "Time taken: 11.01s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 447.6708, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 442.5533, Accuracy: 0.6087\n",
      "Training loss (for one batch) at step 20: 443.9866, Accuracy: 0.6086\n",
      "Training loss (for one batch) at step 30: 439.8886, Accuracy: 0.6313\n",
      "Training loss (for one batch) at step 40: 429.8211, Accuracy: 0.6387\n",
      "Training loss (for one batch) at step 50: 432.0988, Accuracy: 0.6405\n",
      "Training loss (for one batch) at step 60: 435.4330, Accuracy: 0.6433\n",
      "Training loss (for one batch) at step 70: 442.1709, Accuracy: 0.6463\n",
      "Training loss (for one batch) at step 80: 445.3371, Accuracy: 0.6437\n",
      "Training loss (for one batch) at step 90: 438.1002, Accuracy: 0.6385\n",
      "Training loss (for one batch) at step 100: 442.0222, Accuracy: 0.6392\n",
      "Training loss (for one batch) at step 110: 441.2939, Accuracy: 0.6399\n",
      "---- Training ----\n",
      "Training loss: 136.5810\n",
      "Training acc over epoch: 0.6413\n",
      "---- Validation ----\n",
      "Validation loss: 36.1799\n",
      "Validation acc: 0.6652\n",
      "Time taken: 11.11s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 440.3135, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 444.4999, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 20: 441.2707, Accuracy: 0.6347\n",
      "Training loss (for one batch) at step 30: 435.1065, Accuracy: 0.6389\n",
      "Training loss (for one batch) at step 40: 433.4874, Accuracy: 0.6477\n",
      "Training loss (for one batch) at step 50: 439.0832, Accuracy: 0.6546\n",
      "Training loss (for one batch) at step 60: 429.3362, Accuracy: 0.6639\n",
      "Training loss (for one batch) at step 70: 438.1301, Accuracy: 0.6670\n",
      "Training loss (for one batch) at step 80: 443.9599, Accuracy: 0.6631\n",
      "Training loss (for one batch) at step 90: 439.7346, Accuracy: 0.6546\n",
      "Training loss (for one batch) at step 100: 436.0316, Accuracy: 0.6535\n",
      "Training loss (for one batch) at step 110: 436.5485, Accuracy: 0.6555\n",
      "---- Training ----\n",
      "Training loss: 137.3394\n",
      "Training acc over epoch: 0.6562\n",
      "---- Validation ----\n",
      "Validation loss: 34.1079\n",
      "Validation acc: 0.6701\n",
      "Time taken: 10.90s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 442.3202, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 444.0002, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 20: 436.7650, Accuracy: 0.6778\n",
      "Training loss (for one batch) at step 30: 426.8786, Accuracy: 0.6900\n",
      "Training loss (for one batch) at step 40: 425.9885, Accuracy: 0.6925\n",
      "Training loss (for one batch) at step 50: 417.2542, Accuracy: 0.6978\n",
      "Training loss (for one batch) at step 60: 436.5386, Accuracy: 0.6985\n",
      "Training loss (for one batch) at step 70: 438.5764, Accuracy: 0.6976\n",
      "Training loss (for one batch) at step 80: 439.9471, Accuracy: 0.6944\n",
      "Training loss (for one batch) at step 90: 440.0110, Accuracy: 0.6894\n",
      "Training loss (for one batch) at step 100: 432.9958, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 110: 442.7189, Accuracy: 0.6885\n",
      "---- Training ----\n",
      "Training loss: 135.2740\n",
      "Training acc over epoch: 0.6879\n",
      "---- Validation ----\n",
      "Validation loss: 33.2365\n",
      "Validation acc: 0.7071\n",
      "Time taken: 13.74s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 440.1645, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 439.6741, Accuracy: 0.6996\n",
      "Training loss (for one batch) at step 20: 435.0945, Accuracy: 0.6793\n",
      "Training loss (for one batch) at step 30: 431.8693, Accuracy: 0.6769\n",
      "Training loss (for one batch) at step 40: 436.9377, Accuracy: 0.6829\n",
      "Training loss (for one batch) at step 50: 422.0307, Accuracy: 0.6907\n",
      "Training loss (for one batch) at step 60: 441.2482, Accuracy: 0.6984\n",
      "Training loss (for one batch) at step 70: 442.7556, Accuracy: 0.7011\n",
      "Training loss (for one batch) at step 80: 438.6578, Accuracy: 0.6952\n",
      "Training loss (for one batch) at step 90: 437.5431, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 100: 427.6252, Accuracy: 0.6949\n",
      "Training loss (for one batch) at step 110: 433.6463, Accuracy: 0.6968\n",
      "---- Training ----\n",
      "Training loss: 137.6810\n",
      "Training acc over epoch: 0.6965\n",
      "---- Validation ----\n",
      "Validation loss: 35.9807\n",
      "Validation acc: 0.7010\n",
      "Time taken: 11.03s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 443.2635, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 438.2275, Accuracy: 0.7074\n",
      "Training loss (for one batch) at step 20: 437.6420, Accuracy: 0.6957\n",
      "Training loss (for one batch) at step 30: 428.3126, Accuracy: 0.7024\n",
      "Training loss (for one batch) at step 40: 415.6287, Accuracy: 0.7077\n",
      "Training loss (for one batch) at step 50: 419.5071, Accuracy: 0.7197\n",
      "Training loss (for one batch) at step 60: 418.9855, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 70: 446.8165, Accuracy: 0.7276\n",
      "Training loss (for one batch) at step 80: 445.0919, Accuracy: 0.7194\n",
      "Training loss (for one batch) at step 90: 433.0831, Accuracy: 0.7133\n",
      "Training loss (for one batch) at step 100: 436.5045, Accuracy: 0.7123\n",
      "Training loss (for one batch) at step 110: 441.7469, Accuracy: 0.7126\n",
      "---- Training ----\n",
      "Training loss: 138.3368\n",
      "Training acc over epoch: 0.7118\n",
      "---- Validation ----\n",
      "Validation loss: 35.3203\n",
      "Validation acc: 0.7077\n",
      "Time taken: 11.09s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 440.4173, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 439.2665, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 20: 434.2603, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 30: 430.6339, Accuracy: 0.7278\n",
      "Training loss (for one batch) at step 40: 416.6180, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 50: 411.6897, Accuracy: 0.7373\n",
      "Training loss (for one batch) at step 60: 429.6070, Accuracy: 0.7395\n",
      "Training loss (for one batch) at step 70: 430.1782, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 80: 437.6202, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 90: 438.0434, Accuracy: 0.7356\n",
      "Training loss (for one batch) at step 100: 421.4307, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 110: 436.1025, Accuracy: 0.7349\n",
      "---- Training ----\n",
      "Training loss: 135.4515\n",
      "Training acc over epoch: 0.7355\n",
      "---- Validation ----\n",
      "Validation loss: 34.0061\n",
      "Validation acc: 0.7300\n",
      "Time taken: 11.39s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 445.5800, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 437.6153, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 20: 435.0889, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 30: 420.4051, Accuracy: 0.7324\n",
      "Training loss (for one batch) at step 40: 420.9291, Accuracy: 0.7401\n",
      "Training loss (for one batch) at step 50: 416.6458, Accuracy: 0.7480\n",
      "Training loss (for one batch) at step 60: 423.8449, Accuracy: 0.7538\n",
      "Training loss (for one batch) at step 70: 430.7255, Accuracy: 0.7509\n",
      "Training loss (for one batch) at step 80: 432.6541, Accuracy: 0.7458\n",
      "Training loss (for one batch) at step 90: 430.6204, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 100: 432.5576, Accuracy: 0.7406\n",
      "Training loss (for one batch) at step 110: 422.0868, Accuracy: 0.7421\n",
      "---- Training ----\n",
      "Training loss: 128.0206\n",
      "Training acc over epoch: 0.7421\n",
      "---- Validation ----\n",
      "Validation loss: 35.8436\n",
      "Validation acc: 0.7241\n",
      "Time taken: 10.92s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 442.5306, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 432.0494, Accuracy: 0.7280\n",
      "Training loss (for one batch) at step 20: 433.0330, Accuracy: 0.7325\n",
      "Training loss (for one batch) at step 30: 425.7737, Accuracy: 0.7339\n",
      "Training loss (for one batch) at step 40: 415.2627, Accuracy: 0.7376\n",
      "Training loss (for one batch) at step 50: 409.2507, Accuracy: 0.7488\n",
      "Training loss (for one batch) at step 60: 423.2115, Accuracy: 0.7542\n",
      "Training loss (for one batch) at step 70: 430.9500, Accuracy: 0.7547\n",
      "Training loss (for one batch) at step 80: 437.2772, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 90: 432.6761, Accuracy: 0.7467\n",
      "Training loss (for one batch) at step 100: 416.3618, Accuracy: 0.7467\n",
      "Training loss (for one batch) at step 110: 425.4904, Accuracy: 0.7468\n",
      "---- Training ----\n",
      "Training loss: 139.8959\n",
      "Training acc over epoch: 0.7456\n",
      "---- Validation ----\n",
      "Validation loss: 36.3762\n",
      "Validation acc: 0.7045\n",
      "Time taken: 10.97s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 445.8271, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 431.2056, Accuracy: 0.7642\n",
      "Training loss (for one batch) at step 20: 436.4421, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 428.1974, Accuracy: 0.7588\n",
      "Training loss (for one batch) at step 40: 405.0725, Accuracy: 0.7633\n",
      "Training loss (for one batch) at step 50: 399.1268, Accuracy: 0.7696\n",
      "Training loss (for one batch) at step 60: 427.5666, Accuracy: 0.7743\n",
      "Training loss (for one batch) at step 70: 424.4852, Accuracy: 0.7717\n",
      "Training loss (for one batch) at step 80: 432.9362, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 90: 429.5792, Accuracy: 0.7620\n",
      "Training loss (for one batch) at step 100: 420.2164, Accuracy: 0.7601\n",
      "Training loss (for one batch) at step 110: 429.1848, Accuracy: 0.7592\n",
      "---- Training ----\n",
      "Training loss: 130.8246\n",
      "Training acc over epoch: 0.7593\n",
      "---- Validation ----\n",
      "Validation loss: 34.7265\n",
      "Validation acc: 0.7141\n",
      "Time taken: 11.22s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 439.9858, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 433.8595, Accuracy: 0.7280\n",
      "Training loss (for one batch) at step 20: 426.8152, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 30: 425.7947, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 40: 415.0616, Accuracy: 0.7529\n",
      "Training loss (for one batch) at step 50: 395.5515, Accuracy: 0.7658\n",
      "Training loss (for one batch) at step 60: 425.3650, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 70: 425.7272, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 80: 433.7608, Accuracy: 0.7681\n",
      "Training loss (for one batch) at step 90: 427.0151, Accuracy: 0.7673\n",
      "Training loss (for one batch) at step 100: 411.5044, Accuracy: 0.7655\n",
      "Training loss (for one batch) at step 110: 421.1603, Accuracy: 0.7659\n",
      "---- Training ----\n",
      "Training loss: 136.9110\n",
      "Training acc over epoch: 0.7661\n",
      "---- Validation ----\n",
      "Validation loss: 36.4456\n",
      "Validation acc: 0.7386\n",
      "Time taken: 10.98s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 428.0733, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 442.5845, Accuracy: 0.7514\n",
      "Training loss (for one batch) at step 20: 432.4359, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 409.7757, Accuracy: 0.7566\n",
      "Training loss (for one batch) at step 40: 407.1814, Accuracy: 0.7601\n",
      "Training loss (for one batch) at step 50: 402.0628, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 60: 432.7872, Accuracy: 0.7809\n",
      "Training loss (for one batch) at step 70: 414.6672, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 80: 429.0254, Accuracy: 0.7768\n",
      "Training loss (for one batch) at step 90: 430.3145, Accuracy: 0.7740\n",
      "Training loss (for one batch) at step 100: 407.7257, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 110: 423.1593, Accuracy: 0.7743\n",
      "---- Training ----\n",
      "Training loss: 136.3479\n",
      "Training acc over epoch: 0.7740\n",
      "---- Validation ----\n",
      "Validation loss: 37.4625\n",
      "Validation acc: 0.7413\n",
      "Time taken: 11.03s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 437.5242, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 427.5396, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 20: 428.9212, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 30: 413.9425, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 40: 408.6682, Accuracy: 0.7792\n",
      "Training loss (for one batch) at step 50: 401.0273, Accuracy: 0.7904\n",
      "Training loss (for one batch) at step 60: 409.6602, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 70: 435.1204, Accuracy: 0.7937\n",
      "Training loss (for one batch) at step 80: 434.2874, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 90: 434.5317, Accuracy: 0.7843\n",
      "Training loss (for one batch) at step 100: 422.7270, Accuracy: 0.7821\n",
      "Training loss (for one batch) at step 110: 404.4855, Accuracy: 0.7793\n",
      "---- Training ----\n",
      "Training loss: 129.4648\n",
      "Training acc over epoch: 0.7785\n",
      "---- Validation ----\n",
      "Validation loss: 39.6730\n",
      "Validation acc: 0.7192\n",
      "Time taken: 11.20s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 433.5824, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 435.4330, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 20: 425.2394, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 30: 409.7702, Accuracy: 0.7729\n",
      "Training loss (for one batch) at step 40: 388.6418, Accuracy: 0.7809\n",
      "Training loss (for one batch) at step 50: 391.9476, Accuracy: 0.7901\n",
      "Training loss (for one batch) at step 60: 398.7355, Accuracy: 0.7956\n",
      "Training loss (for one batch) at step 70: 416.4216, Accuracy: 0.7989\n",
      "Training loss (for one batch) at step 80: 426.3865, Accuracy: 0.7915\n",
      "Training loss (for one batch) at step 90: 408.7621, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 100: 413.0088, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 110: 410.1303, Accuracy: 0.7860\n",
      "---- Training ----\n",
      "Training loss: 124.1116\n",
      "Training acc over epoch: 0.7854\n",
      "---- Validation ----\n",
      "Validation loss: 38.7019\n",
      "Validation acc: 0.6857\n",
      "Time taken: 10.98s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 438.3176, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 415.7913, Accuracy: 0.7692\n",
      "Training loss (for one batch) at step 20: 417.2355, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 30: 408.5139, Accuracy: 0.7747\n",
      "Training loss (for one batch) at step 40: 404.7341, Accuracy: 0.7790\n",
      "Training loss (for one batch) at step 50: 387.4770, Accuracy: 0.7911\n",
      "Training loss (for one batch) at step 60: 415.8234, Accuracy: 0.7912\n",
      "Training loss (for one batch) at step 70: 416.8596, Accuracy: 0.7930\n",
      "Training loss (for one batch) at step 80: 417.6255, Accuracy: 0.7920\n",
      "Training loss (for one batch) at step 90: 428.1654, Accuracy: 0.7899\n",
      "Training loss (for one batch) at step 100: 433.5150, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 110: 414.8753, Accuracy: 0.7872\n",
      "---- Training ----\n",
      "Training loss: 133.5961\n",
      "Training acc over epoch: 0.7862\n",
      "---- Validation ----\n",
      "Validation loss: 34.5931\n",
      "Validation acc: 0.6814\n",
      "Time taken: 11.02s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 413.8288, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 412.7633, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 422.1388, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 30: 398.4481, Accuracy: 0.7631\n",
      "Training loss (for one batch) at step 40: 411.3416, Accuracy: 0.7742\n",
      "Training loss (for one batch) at step 50: 380.7572, Accuracy: 0.7883\n",
      "Training loss (for one batch) at step 60: 399.3636, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 70: 417.0296, Accuracy: 0.7959\n",
      "Training loss (for one batch) at step 80: 409.5387, Accuracy: 0.7942\n",
      "Training loss (for one batch) at step 90: 402.5013, Accuracy: 0.7919\n",
      "Training loss (for one batch) at step 100: 416.7482, Accuracy: 0.7902\n",
      "Training loss (for one batch) at step 110: 409.4386, Accuracy: 0.7896\n",
      "---- Training ----\n",
      "Training loss: 132.4982\n",
      "Training acc over epoch: 0.7893\n",
      "---- Validation ----\n",
      "Validation loss: 33.6943\n",
      "Validation acc: 0.6814\n",
      "Time taken: 11.25s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 418.1541, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 403.8991, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 20: 408.4326, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 30: 409.1528, Accuracy: 0.7810\n",
      "Training loss (for one batch) at step 40: 401.4615, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 50: 364.0735, Accuracy: 0.7981\n",
      "Training loss (for one batch) at step 60: 381.3207, Accuracy: 0.8057\n",
      "Training loss (for one batch) at step 70: 407.2191, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 80: 403.2501, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 90: 415.3195, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 100: 402.1968, Accuracy: 0.7922\n",
      "Training loss (for one batch) at step 110: 409.8289, Accuracy: 0.7907\n",
      "---- Training ----\n",
      "Training loss: 124.7552\n",
      "Training acc over epoch: 0.7900\n",
      "---- Validation ----\n",
      "Validation loss: 38.1481\n",
      "Validation acc: 0.7380\n",
      "Time taken: 11.06s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 415.8253, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 401.6572, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 20: 404.8879, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 389.1734, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 40: 385.2114, Accuracy: 0.7934\n",
      "Training loss (for one batch) at step 50: 376.3564, Accuracy: 0.8033\n",
      "Training loss (for one batch) at step 60: 392.1206, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 70: 406.8683, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 80: 413.7441, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 90: 404.4204, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 100: 389.8563, Accuracy: 0.7983\n",
      "Training loss (for one batch) at step 110: 404.4338, Accuracy: 0.7964\n",
      "---- Training ----\n",
      "Training loss: 129.8154\n",
      "Training acc over epoch: 0.7952\n",
      "---- Validation ----\n",
      "Validation loss: 37.6323\n",
      "Validation acc: 0.7246\n",
      "Time taken: 11.03s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 414.2136, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 418.2741, Accuracy: 0.7692\n",
      "Training loss (for one batch) at step 20: 407.0908, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 30: 402.2123, Accuracy: 0.7860\n",
      "Training loss (for one batch) at step 40: 382.5211, Accuracy: 0.7971\n",
      "Training loss (for one batch) at step 50: 375.9240, Accuracy: 0.8084\n",
      "Training loss (for one batch) at step 60: 386.6206, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 70: 417.1058, Accuracy: 0.8081\n",
      "Training loss (for one batch) at step 80: 406.4987, Accuracy: 0.8038\n",
      "Training loss (for one batch) at step 90: 392.5591, Accuracy: 0.8014\n",
      "Training loss (for one batch) at step 100: 386.1057, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 110: 397.6884, Accuracy: 0.7980\n",
      "---- Training ----\n",
      "Training loss: 116.8601\n",
      "Training acc over epoch: 0.7972\n",
      "---- Validation ----\n",
      "Validation loss: 32.0644\n",
      "Validation acc: 0.6975\n",
      "Time taken: 10.96s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 410.5000, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 404.5963, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 20: 406.5926, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 398.4612, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 40: 385.8539, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 50: 385.5151, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 60: 383.7594, Accuracy: 0.8090\n",
      "Training loss (for one batch) at step 70: 395.6030, Accuracy: 0.8052\n",
      "Training loss (for one batch) at step 80: 416.6035, Accuracy: 0.8009\n",
      "Training loss (for one batch) at step 90: 374.9989, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 100: 385.7133, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 110: 411.7631, Accuracy: 0.7967\n",
      "---- Training ----\n",
      "Training loss: 135.1904\n",
      "Training acc over epoch: 0.7968\n",
      "---- Validation ----\n",
      "Validation loss: 35.3004\n",
      "Validation acc: 0.7214\n",
      "Time taken: 11.00s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 395.3887, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 385.7564, Accuracy: 0.7933\n",
      "Training loss (for one batch) at step 20: 398.8687, Accuracy: 0.7846\n",
      "Training loss (for one batch) at step 30: 374.5681, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 40: 384.2463, Accuracy: 0.8014\n",
      "Training loss (for one batch) at step 50: 389.6696, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 60: 374.0056, Accuracy: 0.8198\n",
      "Training loss (for one batch) at step 70: 394.4939, Accuracy: 0.8156\n",
      "Training loss (for one batch) at step 80: 412.5533, Accuracy: 0.8105\n",
      "Training loss (for one batch) at step 90: 391.6389, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 100: 376.4248, Accuracy: 0.8069\n",
      "Training loss (for one batch) at step 110: 388.6480, Accuracy: 0.8056\n",
      "---- Training ----\n",
      "Training loss: 120.7800\n",
      "Training acc over epoch: 0.8047\n",
      "---- Validation ----\n",
      "Validation loss: 32.8822\n",
      "Validation acc: 0.7026\n",
      "Time taken: 13.78s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 408.6471, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 396.2835, Accuracy: 0.7670\n",
      "Training loss (for one batch) at step 20: 388.0591, Accuracy: 0.7798\n",
      "Training loss (for one batch) at step 30: 385.9990, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 40: 363.8516, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 50: 362.3946, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 60: 374.5389, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 70: 408.1240, Accuracy: 0.8105\n",
      "Training loss (for one batch) at step 80: 401.6994, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 90: 375.8785, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 100: 392.4182, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 110: 387.7214, Accuracy: 0.8067\n",
      "---- Training ----\n",
      "Training loss: 122.3881\n",
      "Training acc over epoch: 0.8044\n",
      "---- Validation ----\n",
      "Validation loss: 39.1960\n",
      "Validation acc: 0.7055\n",
      "Time taken: 10.89s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 398.4457, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 395.4835, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 20: 397.4921, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 30: 382.3550, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 40: 390.5670, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 50: 360.8623, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 60: 361.6628, Accuracy: 0.8184\n",
      "Training loss (for one batch) at step 70: 397.9634, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 80: 378.5999, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 90: 382.6791, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 100: 382.6556, Accuracy: 0.8036\n",
      "Training loss (for one batch) at step 110: 392.2143, Accuracy: 0.8023\n",
      "---- Training ----\n",
      "Training loss: 129.0776\n",
      "Training acc over epoch: 0.8020\n",
      "---- Validation ----\n",
      "Validation loss: 45.7088\n",
      "Validation acc: 0.7225\n",
      "Time taken: 11.16s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 396.5471, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 380.6440, Accuracy: 0.7834\n",
      "Training loss (for one batch) at step 20: 380.9094, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 30: 369.2520, Accuracy: 0.7916\n",
      "Training loss (for one batch) at step 40: 352.1711, Accuracy: 0.7992\n",
      "Training loss (for one batch) at step 50: 356.9866, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 60: 372.1752, Accuracy: 0.8210\n",
      "Training loss (for one batch) at step 70: 407.9650, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 80: 388.4681, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 90: 382.4539, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 100: 387.3796, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 110: 395.2207, Accuracy: 0.8075\n",
      "---- Training ----\n",
      "Training loss: 125.5774\n",
      "Training acc over epoch: 0.8054\n",
      "---- Validation ----\n",
      "Validation loss: 38.3122\n",
      "Validation acc: 0.7120\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 413.8289, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 377.6540, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 20: 370.0510, Accuracy: 0.7831\n",
      "Training loss (for one batch) at step 30: 383.3327, Accuracy: 0.7931\n",
      "Training loss (for one batch) at step 40: 374.2354, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 50: 342.2955, Accuracy: 0.8166\n",
      "Training loss (for one batch) at step 60: 362.7184, Accuracy: 0.8210\n",
      "Training loss (for one batch) at step 70: 400.6522, Accuracy: 0.8167\n",
      "Training loss (for one batch) at step 80: 385.2958, Accuracy: 0.8103\n",
      "Training loss (for one batch) at step 90: 377.3630, Accuracy: 0.8078\n",
      "Training loss (for one batch) at step 100: 374.3428, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 110: 374.3471, Accuracy: 0.8050\n",
      "---- Training ----\n",
      "Training loss: 114.8222\n",
      "Training acc over epoch: 0.8055\n",
      "---- Validation ----\n",
      "Validation loss: 49.5780\n",
      "Validation acc: 0.7114\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 418.3683, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 391.0768, Accuracy: 0.7770\n",
      "Training loss (for one batch) at step 20: 374.8776, Accuracy: 0.7850\n",
      "Training loss (for one batch) at step 30: 360.1115, Accuracy: 0.7981\n",
      "Training loss (for one batch) at step 40: 360.6192, Accuracy: 0.8062\n",
      "Training loss (for one batch) at step 50: 351.9189, Accuracy: 0.8156\n",
      "Training loss (for one batch) at step 60: 362.2065, Accuracy: 0.8235\n",
      "Training loss (for one batch) at step 70: 378.5234, Accuracy: 0.8167\n",
      "Training loss (for one batch) at step 80: 380.8474, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 90: 365.8285, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 100: 367.3297, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 110: 381.0873, Accuracy: 0.8060\n",
      "---- Training ----\n",
      "Training loss: 117.9355\n",
      "Training acc over epoch: 0.8043\n",
      "---- Validation ----\n",
      "Validation loss: 43.0153\n",
      "Validation acc: 0.6940\n",
      "Time taken: 10.74s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 380.0802, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 376.9274, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 375.5134, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 30: 372.9480, Accuracy: 0.7984\n",
      "Training loss (for one batch) at step 40: 351.2606, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 50: 353.3040, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 60: 349.0392, Accuracy: 0.8249\n",
      "Training loss (for one batch) at step 70: 358.3503, Accuracy: 0.8193\n",
      "Training loss (for one batch) at step 80: 387.4345, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 90: 361.0799, Accuracy: 0.8076\n",
      "Training loss (for one batch) at step 100: 369.8721, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 110: 381.4620, Accuracy: 0.8086\n",
      "---- Training ----\n",
      "Training loss: 122.8457\n",
      "Training acc over epoch: 0.8090\n",
      "---- Validation ----\n",
      "Validation loss: 41.7581\n",
      "Validation acc: 0.7080\n",
      "Time taken: 10.80s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 385.0953, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 374.8143, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 20: 375.3706, Accuracy: 0.7909\n",
      "Training loss (for one batch) at step 30: 366.8141, Accuracy: 0.7971\n",
      "Training loss (for one batch) at step 40: 344.3923, Accuracy: 0.8112\n",
      "Training loss (for one batch) at step 50: 345.4123, Accuracy: 0.8222\n",
      "Training loss (for one batch) at step 60: 344.6052, Accuracy: 0.8272\n",
      "Training loss (for one batch) at step 70: 368.7646, Accuracy: 0.8236\n",
      "Training loss (for one batch) at step 80: 381.6664, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 90: 372.8572, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 100: 361.0404, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 110: 368.3917, Accuracy: 0.8107\n",
      "---- Training ----\n",
      "Training loss: 115.9975\n",
      "Training acc over epoch: 0.8098\n",
      "---- Validation ----\n",
      "Validation loss: 37.9955\n",
      "Validation acc: 0.7198\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 370.6330, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 372.3428, Accuracy: 0.7947\n",
      "Training loss (for one batch) at step 20: 363.4987, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 30: 341.9676, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 40: 346.8088, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 50: 346.7238, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 60: 352.0015, Accuracy: 0.8320\n",
      "Training loss (for one batch) at step 70: 367.8622, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 80: 403.1303, Accuracy: 0.8196\n",
      "Training loss (for one batch) at step 90: 353.0316, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 100: 342.9721, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 110: 355.7655, Accuracy: 0.8154\n",
      "---- Training ----\n",
      "Training loss: 122.2274\n",
      "Training acc over epoch: 0.8148\n",
      "---- Validation ----\n",
      "Validation loss: 43.9090\n",
      "Validation acc: 0.7262\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 396.3958, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 376.0209, Accuracy: 0.7798\n",
      "Training loss (for one batch) at step 20: 353.4166, Accuracy: 0.7917\n",
      "Training loss (for one batch) at step 30: 349.4619, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 40: 348.9594, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 50: 340.9517, Accuracy: 0.8225\n",
      "Training loss (for one batch) at step 60: 364.6041, Accuracy: 0.8284\n",
      "Training loss (for one batch) at step 70: 368.2076, Accuracy: 0.8247\n",
      "Training loss (for one batch) at step 80: 375.6805, Accuracy: 0.8159\n",
      "Training loss (for one batch) at step 90: 344.0073, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 100: 371.7059, Accuracy: 0.8117\n",
      "Training loss (for one batch) at step 110: 360.3939, Accuracy: 0.8120\n",
      "---- Training ----\n",
      "Training loss: 115.3676\n",
      "Training acc over epoch: 0.8113\n",
      "---- Validation ----\n",
      "Validation loss: 46.5632\n",
      "Validation acc: 0.7174\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 397.3727, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 358.1047, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 20: 364.9606, Accuracy: 0.7902\n",
      "Training loss (for one batch) at step 30: 366.4370, Accuracy: 0.8014\n",
      "Training loss (for one batch) at step 40: 333.5806, Accuracy: 0.8131\n",
      "Training loss (for one batch) at step 50: 330.5818, Accuracy: 0.8208\n",
      "Training loss (for one batch) at step 60: 352.3262, Accuracy: 0.8265\n",
      "Training loss (for one batch) at step 70: 370.6880, Accuracy: 0.8197\n",
      "Training loss (for one batch) at step 80: 368.3208, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 90: 352.3875, Accuracy: 0.8092\n",
      "Training loss (for one batch) at step 100: 365.0931, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 110: 368.9441, Accuracy: 0.8136\n",
      "---- Training ----\n",
      "Training loss: 120.5912\n",
      "Training acc over epoch: 0.8125\n",
      "---- Validation ----\n",
      "Validation loss: 42.5146\n",
      "Validation acc: 0.7208\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 351.6316, Accuracy: 0.8594\n",
      "Training loss (for one batch) at step 10: 366.5417, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 20: 351.0460, Accuracy: 0.7965\n",
      "Training loss (for one batch) at step 30: 339.2436, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 40: 353.7374, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 50: 336.1398, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 60: 371.2822, Accuracy: 0.8315\n",
      "Training loss (for one batch) at step 70: 347.9457, Accuracy: 0.8245\n",
      "Training loss (for one batch) at step 80: 375.9569, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 90: 355.9823, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 100: 343.1296, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 110: 350.5733, Accuracy: 0.8143\n",
      "---- Training ----\n",
      "Training loss: 107.7628\n",
      "Training acc over epoch: 0.8135\n",
      "---- Validation ----\n",
      "Validation loss: 40.2849\n",
      "Validation acc: 0.7082\n",
      "Time taken: 10.65s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7246\n",
      "Validation AUC: 0.7226\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 697.8135, Accuracy: 0.4219\n",
      "Training loss (for one batch) at step 10: 576.8466, Accuracy: 0.5405\n",
      "Training loss (for one batch) at step 20: 538.4303, Accuracy: 0.5260\n",
      "Training loss (for one batch) at step 30: 526.2433, Accuracy: 0.5217\n",
      "Training loss (for one batch) at step 40: 493.0319, Accuracy: 0.5191\n",
      "Training loss (for one batch) at step 50: 490.2648, Accuracy: 0.5207\n",
      "Training loss (for one batch) at step 60: 465.5396, Accuracy: 0.5169\n",
      "Training loss (for one batch) at step 70: 475.9409, Accuracy: 0.5173\n",
      "Training loss (for one batch) at step 80: 471.1580, Accuracy: 0.5203\n",
      "Training loss (for one batch) at step 90: 465.5093, Accuracy: 0.5215\n",
      "Training loss (for one batch) at step 100: 463.8578, Accuracy: 0.5179\n",
      "Training loss (for one batch) at step 110: 453.1556, Accuracy: 0.5160\n",
      "---- Training ----\n",
      "Training loss: 142.7048\n",
      "Training acc over epoch: 0.5180\n",
      "---- Validation ----\n",
      "Validation loss: 34.3172\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.18s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 457.2537, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 450.7738, Accuracy: 0.5099\n",
      "Training loss (for one batch) at step 20: 449.6497, Accuracy: 0.5190\n",
      "Training loss (for one batch) at step 30: 454.5968, Accuracy: 0.5126\n",
      "Training loss (for one batch) at step 40: 453.6440, Accuracy: 0.5111\n",
      "Training loss (for one batch) at step 50: 451.5750, Accuracy: 0.5101\n",
      "Training loss (for one batch) at step 60: 449.4153, Accuracy: 0.5128\n",
      "Training loss (for one batch) at step 70: 447.5769, Accuracy: 0.5163\n",
      "Training loss (for one batch) at step 80: 455.2739, Accuracy: 0.5144\n",
      "Training loss (for one batch) at step 90: 449.9302, Accuracy: 0.5197\n",
      "Training loss (for one batch) at step 100: 443.2635, Accuracy: 0.5207\n",
      "Training loss (for one batch) at step 110: 450.6999, Accuracy: 0.5196\n",
      "---- Training ----\n",
      "Training loss: 141.3340\n",
      "Training acc over epoch: 0.5190\n",
      "---- Validation ----\n",
      "Validation loss: 34.8369\n",
      "Validation acc: 0.5333\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.3146, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 447.6156, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 20: 447.7290, Accuracy: 0.5435\n",
      "Training loss (for one batch) at step 30: 445.6896, Accuracy: 0.5474\n",
      "Training loss (for one batch) at step 40: 446.7715, Accuracy: 0.5412\n",
      "Training loss (for one batch) at step 50: 445.6082, Accuracy: 0.5432\n",
      "Training loss (for one batch) at step 60: 444.3878, Accuracy: 0.5410\n",
      "Training loss (for one batch) at step 70: 448.2299, Accuracy: 0.5406\n",
      "Training loss (for one batch) at step 80: 443.7961, Accuracy: 0.5424\n",
      "Training loss (for one batch) at step 90: 446.6395, Accuracy: 0.5458\n",
      "Training loss (for one batch) at step 100: 450.7477, Accuracy: 0.5456\n",
      "Training loss (for one batch) at step 110: 446.6668, Accuracy: 0.5419\n",
      "---- Training ----\n",
      "Training loss: 140.0827\n",
      "Training acc over epoch: 0.5399\n",
      "---- Validation ----\n",
      "Validation loss: 34.6543\n",
      "Validation acc: 0.5253\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 443.8556, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 442.6518, Accuracy: 0.5426\n",
      "Training loss (for one batch) at step 20: 444.0516, Accuracy: 0.5465\n",
      "Training loss (for one batch) at step 30: 440.9785, Accuracy: 0.5496\n",
      "Training loss (for one batch) at step 40: 446.2881, Accuracy: 0.5455\n",
      "Training loss (for one batch) at step 50: 445.2905, Accuracy: 0.5522\n",
      "Training loss (for one batch) at step 60: 442.8232, Accuracy: 0.5567\n",
      "Training loss (for one batch) at step 70: 444.3175, Accuracy: 0.5597\n",
      "Training loss (for one batch) at step 80: 442.5272, Accuracy: 0.5597\n",
      "Training loss (for one batch) at step 90: 443.2070, Accuracy: 0.5622\n",
      "Training loss (for one batch) at step 100: 444.3228, Accuracy: 0.5616\n",
      "Training loss (for one batch) at step 110: 445.5170, Accuracy: 0.5624\n",
      "---- Training ----\n",
      "Training loss: 141.2944\n",
      "Training acc over epoch: 0.5606\n",
      "---- Validation ----\n",
      "Validation loss: 34.7648\n",
      "Validation acc: 0.5656\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 441.4565, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 442.9360, Accuracy: 0.5653\n",
      "Training loss (for one batch) at step 20: 443.4434, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 30: 443.1503, Accuracy: 0.5885\n",
      "Training loss (for one batch) at step 40: 443.2565, Accuracy: 0.5837\n",
      "Training loss (for one batch) at step 50: 442.2686, Accuracy: 0.5861\n",
      "Training loss (for one batch) at step 60: 443.0743, Accuracy: 0.5894\n",
      "Training loss (for one batch) at step 70: 444.8787, Accuracy: 0.5920\n",
      "Training loss (for one batch) at step 80: 442.6175, Accuracy: 0.5917\n",
      "Training loss (for one batch) at step 90: 438.0050, Accuracy: 0.5896\n",
      "Training loss (for one batch) at step 100: 444.5044, Accuracy: 0.5877\n",
      "Training loss (for one batch) at step 110: 442.6934, Accuracy: 0.5864\n",
      "---- Training ----\n",
      "Training loss: 137.8756\n",
      "Training acc over epoch: 0.5857\n",
      "---- Validation ----\n",
      "Validation loss: 35.2539\n",
      "Validation acc: 0.5793\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 445.4191, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 444.7224, Accuracy: 0.5795\n",
      "Training loss (for one batch) at step 20: 439.5741, Accuracy: 0.5822\n",
      "Training loss (for one batch) at step 30: 438.6049, Accuracy: 0.5867\n",
      "Training loss (for one batch) at step 40: 440.7367, Accuracy: 0.5926\n",
      "Training loss (for one batch) at step 50: 440.9190, Accuracy: 0.6036\n",
      "Training loss (for one batch) at step 60: 443.6240, Accuracy: 0.6034\n",
      "Training loss (for one batch) at step 70: 445.4031, Accuracy: 0.6072\n",
      "Training loss (for one batch) at step 80: 445.6694, Accuracy: 0.6079\n",
      "Training loss (for one batch) at step 90: 442.6035, Accuracy: 0.6077\n",
      "Training loss (for one batch) at step 100: 442.3975, Accuracy: 0.6074\n",
      "Training loss (for one batch) at step 110: 440.9213, Accuracy: 0.6060\n",
      "---- Training ----\n",
      "Training loss: 138.7064\n",
      "Training acc over epoch: 0.6044\n",
      "---- Validation ----\n",
      "Validation loss: 34.9577\n",
      "Validation acc: 0.6354\n",
      "Time taken: 10.83s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 441.9284, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 441.9296, Accuracy: 0.6001\n",
      "Training loss (for one batch) at step 20: 437.5130, Accuracy: 0.6194\n",
      "Training loss (for one batch) at step 30: 440.0310, Accuracy: 0.6182\n",
      "Training loss (for one batch) at step 40: 439.5712, Accuracy: 0.6174\n",
      "Training loss (for one batch) at step 50: 436.5843, Accuracy: 0.6218\n",
      "Training loss (for one batch) at step 60: 438.8282, Accuracy: 0.6232\n",
      "Training loss (for one batch) at step 70: 442.5315, Accuracy: 0.6274\n",
      "Training loss (for one batch) at step 80: 446.8146, Accuracy: 0.6281\n",
      "Training loss (for one batch) at step 90: 437.6792, Accuracy: 0.6246\n",
      "Training loss (for one batch) at step 100: 441.7320, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 110: 443.0915, Accuracy: 0.6168\n",
      "---- Training ----\n",
      "Training loss: 138.7652\n",
      "Training acc over epoch: 0.6175\n",
      "---- Validation ----\n",
      "Validation loss: 34.8621\n",
      "Validation acc: 0.6507\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 441.0190, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 441.2450, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 20: 437.7405, Accuracy: 0.6291\n",
      "Training loss (for one batch) at step 30: 433.0359, Accuracy: 0.6373\n",
      "Training loss (for one batch) at step 40: 438.3596, Accuracy: 0.6357\n",
      "Training loss (for one batch) at step 50: 434.9249, Accuracy: 0.6371\n",
      "Training loss (for one batch) at step 60: 443.2908, Accuracy: 0.6368\n",
      "Training loss (for one batch) at step 70: 441.6089, Accuracy: 0.6370\n",
      "Training loss (for one batch) at step 80: 444.1671, Accuracy: 0.6363\n",
      "Training loss (for one batch) at step 90: 439.1512, Accuracy: 0.6344\n",
      "Training loss (for one batch) at step 100: 442.6546, Accuracy: 0.6288\n",
      "Training loss (for one batch) at step 110: 443.7276, Accuracy: 0.6267\n",
      "---- Training ----\n",
      "Training loss: 137.1329\n",
      "Training acc over epoch: 0.6262\n",
      "---- Validation ----\n",
      "Validation loss: 34.9000\n",
      "Validation acc: 0.6376\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 442.3945, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 442.8264, Accuracy: 0.6513\n",
      "Training loss (for one batch) at step 20: 443.1167, Accuracy: 0.6514\n",
      "Training loss (for one batch) at step 30: 436.6353, Accuracy: 0.6517\n",
      "Training loss (for one batch) at step 40: 439.1812, Accuracy: 0.6502\n",
      "Training loss (for one batch) at step 50: 435.2585, Accuracy: 0.6518\n",
      "Training loss (for one batch) at step 60: 436.5515, Accuracy: 0.6534\n",
      "Training loss (for one batch) at step 70: 442.1159, Accuracy: 0.6533\n",
      "Training loss (for one batch) at step 80: 440.7983, Accuracy: 0.6504\n",
      "Training loss (for one batch) at step 90: 439.2415, Accuracy: 0.6482\n",
      "Training loss (for one batch) at step 100: 436.3131, Accuracy: 0.6469\n",
      "Training loss (for one batch) at step 110: 436.2650, Accuracy: 0.6453\n",
      "---- Training ----\n",
      "Training loss: 137.1490\n",
      "Training acc over epoch: 0.6449\n",
      "---- Validation ----\n",
      "Validation loss: 33.4715\n",
      "Validation acc: 0.6118\n",
      "Time taken: 11.07s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 439.5945, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 443.5115, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 20: 436.1840, Accuracy: 0.6667\n",
      "Training loss (for one batch) at step 30: 435.8591, Accuracy: 0.6590\n",
      "Training loss (for one batch) at step 40: 434.3954, Accuracy: 0.6553\n",
      "Training loss (for one batch) at step 50: 433.1724, Accuracy: 0.6573\n",
      "Training loss (for one batch) at step 60: 438.4034, Accuracy: 0.6555\n",
      "Training loss (for one batch) at step 70: 442.8651, Accuracy: 0.6575\n",
      "Training loss (for one batch) at step 80: 443.0602, Accuracy: 0.6574\n",
      "Training loss (for one batch) at step 90: 437.6137, Accuracy: 0.6550\n",
      "Training loss (for one batch) at step 100: 443.3067, Accuracy: 0.6546\n",
      "Training loss (for one batch) at step 110: 434.5340, Accuracy: 0.6541\n",
      "---- Training ----\n",
      "Training loss: 136.1089\n",
      "Training acc over epoch: 0.6560\n",
      "---- Validation ----\n",
      "Validation loss: 34.9962\n",
      "Validation acc: 0.6625\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 439.8550, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 441.4956, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 20: 434.4017, Accuracy: 0.6778\n",
      "Training loss (for one batch) at step 30: 433.8380, Accuracy: 0.6792\n",
      "Training loss (for one batch) at step 40: 427.2477, Accuracy: 0.6909\n",
      "Training loss (for one batch) at step 50: 425.1508, Accuracy: 0.6918\n",
      "Training loss (for one batch) at step 60: 430.8891, Accuracy: 0.6916\n",
      "Training loss (for one batch) at step 70: 439.8023, Accuracy: 0.6931\n",
      "Training loss (for one batch) at step 80: 438.3912, Accuracy: 0.6904\n",
      "Training loss (for one batch) at step 90: 435.7900, Accuracy: 0.6879\n",
      "Training loss (for one batch) at step 100: 430.1454, Accuracy: 0.6863\n",
      "Training loss (for one batch) at step 110: 439.2998, Accuracy: 0.6881\n",
      "---- Training ----\n",
      "Training loss: 134.5421\n",
      "Training acc over epoch: 0.6876\n",
      "---- Validation ----\n",
      "Validation loss: 34.7380\n",
      "Validation acc: 0.6435\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 438.7516, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 433.2636, Accuracy: 0.6911\n",
      "Training loss (for one batch) at step 20: 430.9527, Accuracy: 0.7050\n",
      "Training loss (for one batch) at step 30: 432.6147, Accuracy: 0.7011\n",
      "Training loss (for one batch) at step 40: 430.9196, Accuracy: 0.7062\n",
      "Training loss (for one batch) at step 50: 416.9561, Accuracy: 0.7161\n",
      "Training loss (for one batch) at step 60: 435.6820, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 70: 440.9773, Accuracy: 0.7196\n",
      "Training loss (for one batch) at step 80: 440.8759, Accuracy: 0.7154\n",
      "Training loss (for one batch) at step 90: 432.1308, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 100: 432.0982, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 110: 437.3047, Accuracy: 0.7102\n",
      "---- Training ----\n",
      "Training loss: 137.2987\n",
      "Training acc over epoch: 0.7102\n",
      "---- Validation ----\n",
      "Validation loss: 33.7106\n",
      "Validation acc: 0.6969\n",
      "Time taken: 11.01s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 433.8918, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 436.4926, Accuracy: 0.7152\n",
      "Training loss (for one batch) at step 20: 429.2963, Accuracy: 0.7225\n",
      "Training loss (for one batch) at step 30: 425.4758, Accuracy: 0.7293\n",
      "Training loss (for one batch) at step 40: 423.9513, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 50: 424.1049, Accuracy: 0.7321\n",
      "Training loss (for one batch) at step 60: 434.3836, Accuracy: 0.7368\n",
      "Training loss (for one batch) at step 70: 443.5792, Accuracy: 0.7392\n",
      "Training loss (for one batch) at step 80: 440.9557, Accuracy: 0.7323\n",
      "Training loss (for one batch) at step 90: 434.1646, Accuracy: 0.7260\n",
      "Training loss (for one batch) at step 100: 435.3253, Accuracy: 0.7242\n",
      "Training loss (for one batch) at step 110: 432.9716, Accuracy: 0.7245\n",
      "---- Training ----\n",
      "Training loss: 135.7849\n",
      "Training acc over epoch: 0.7245\n",
      "---- Validation ----\n",
      "Validation loss: 33.4378\n",
      "Validation acc: 0.7383\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 435.7095, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 434.2108, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 433.6832, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 30: 423.4601, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 40: 414.5341, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 50: 421.4641, Accuracy: 0.7463\n",
      "Training loss (for one batch) at step 60: 424.1776, Accuracy: 0.7512\n",
      "Training loss (for one batch) at step 70: 430.9357, Accuracy: 0.7501\n",
      "Training loss (for one batch) at step 80: 435.4979, Accuracy: 0.7439\n",
      "Training loss (for one batch) at step 90: 441.8971, Accuracy: 0.7388\n",
      "Training loss (for one batch) at step 100: 426.1166, Accuracy: 0.7401\n",
      "Training loss (for one batch) at step 110: 432.9876, Accuracy: 0.7426\n",
      "---- Training ----\n",
      "Training loss: 137.4593\n",
      "Training acc over epoch: 0.7427\n",
      "---- Validation ----\n",
      "Validation loss: 32.1975\n",
      "Validation acc: 0.7329\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 429.9266, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 434.4829, Accuracy: 0.7337\n",
      "Training loss (for one batch) at step 20: 425.5129, Accuracy: 0.7292\n",
      "Training loss (for one batch) at step 30: 417.8863, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 40: 423.7079, Accuracy: 0.7426\n",
      "Training loss (for one batch) at step 50: 422.4859, Accuracy: 0.7506\n",
      "Training loss (for one batch) at step 60: 433.4543, Accuracy: 0.7600\n",
      "Training loss (for one batch) at step 70: 433.0429, Accuracy: 0.7569\n",
      "Training loss (for one batch) at step 80: 439.3689, Accuracy: 0.7476\n",
      "Training loss (for one batch) at step 90: 435.9568, Accuracy: 0.7448\n",
      "Training loss (for one batch) at step 100: 429.7459, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 110: 434.6227, Accuracy: 0.7447\n",
      "---- Training ----\n",
      "Training loss: 133.6827\n",
      "Training acc over epoch: 0.7456\n",
      "---- Validation ----\n",
      "Validation loss: 31.7991\n",
      "Validation acc: 0.7480\n",
      "Time taken: 10.96s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 431.5132, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 422.8322, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 20: 426.3844, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 30: 430.1773, Accuracy: 0.7364\n",
      "Training loss (for one batch) at step 40: 420.3803, Accuracy: 0.7443\n",
      "Training loss (for one batch) at step 50: 416.5424, Accuracy: 0.7572\n",
      "Training loss (for one batch) at step 60: 430.0901, Accuracy: 0.7602\n",
      "Training loss (for one batch) at step 70: 422.6759, Accuracy: 0.7602\n",
      "Training loss (for one batch) at step 80: 429.9230, Accuracy: 0.7569\n",
      "Training loss (for one batch) at step 90: 425.5498, Accuracy: 0.7533\n",
      "Training loss (for one batch) at step 100: 425.5674, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 110: 435.8284, Accuracy: 0.7558\n",
      "---- Training ----\n",
      "Training loss: 138.5010\n",
      "Training acc over epoch: 0.7548\n",
      "---- Validation ----\n",
      "Validation loss: 33.4647\n",
      "Validation acc: 0.7359\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 444.2392, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 432.8923, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 433.7624, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 30: 432.1833, Accuracy: 0.7603\n",
      "Training loss (for one batch) at step 40: 416.7087, Accuracy: 0.7639\n",
      "Training loss (for one batch) at step 50: 390.4470, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 60: 407.3211, Accuracy: 0.7836\n",
      "Training loss (for one batch) at step 70: 418.3231, Accuracy: 0.7792\n",
      "Training loss (for one batch) at step 80: 429.7936, Accuracy: 0.7707\n",
      "Training loss (for one batch) at step 90: 431.5605, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 100: 421.6887, Accuracy: 0.7669\n",
      "Training loss (for one batch) at step 110: 429.7024, Accuracy: 0.7659\n",
      "---- Training ----\n",
      "Training loss: 133.4916\n",
      "Training acc over epoch: 0.7650\n",
      "---- Validation ----\n",
      "Validation loss: 35.0632\n",
      "Validation acc: 0.7356\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 438.7102, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 419.5440, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 420.5127, Accuracy: 0.7608\n",
      "Training loss (for one batch) at step 30: 424.1035, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 40: 410.1028, Accuracy: 0.7704\n",
      "Training loss (for one batch) at step 50: 401.9906, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 60: 418.5452, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 70: 428.6125, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 80: 435.2227, Accuracy: 0.7758\n",
      "Training loss (for one batch) at step 90: 421.2253, Accuracy: 0.7711\n",
      "Training loss (for one batch) at step 100: 413.1986, Accuracy: 0.7710\n",
      "Training loss (for one batch) at step 110: 424.6345, Accuracy: 0.7701\n",
      "---- Training ----\n",
      "Training loss: 132.5435\n",
      "Training acc over epoch: 0.7693\n",
      "---- Validation ----\n",
      "Validation loss: 33.9846\n",
      "Validation acc: 0.6926\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 421.1574, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 434.8085, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 420.1735, Accuracy: 0.7604\n",
      "Training loss (for one batch) at step 30: 414.2015, Accuracy: 0.7694\n",
      "Training loss (for one batch) at step 40: 404.1088, Accuracy: 0.7761\n",
      "Training loss (for one batch) at step 50: 402.8876, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 60: 404.4984, Accuracy: 0.7937\n",
      "Training loss (for one batch) at step 70: 416.6734, Accuracy: 0.7926\n",
      "Training loss (for one batch) at step 80: 428.2368, Accuracy: 0.7849\n",
      "Training loss (for one batch) at step 90: 408.7256, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 100: 410.7509, Accuracy: 0.7769\n",
      "Training loss (for one batch) at step 110: 425.6493, Accuracy: 0.7770\n",
      "---- Training ----\n",
      "Training loss: 131.5208\n",
      "Training acc over epoch: 0.7776\n",
      "---- Validation ----\n",
      "Validation loss: 33.2948\n",
      "Validation acc: 0.7512\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 443.7422, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 425.7451, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 20: 423.8368, Accuracy: 0.7660\n",
      "Training loss (for one batch) at step 30: 405.7295, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 40: 389.5828, Accuracy: 0.7822\n",
      "Training loss (for one batch) at step 50: 370.4370, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 60: 394.0762, Accuracy: 0.7989\n",
      "Training loss (for one batch) at step 70: 426.2953, Accuracy: 0.7964\n",
      "Training loss (for one batch) at step 80: 427.1268, Accuracy: 0.7849\n",
      "Training loss (for one batch) at step 90: 426.4097, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 100: 405.9987, Accuracy: 0.7797\n",
      "Training loss (for one batch) at step 110: 411.4382, Accuracy: 0.7796\n",
      "---- Training ----\n",
      "Training loss: 135.0164\n",
      "Training acc over epoch: 0.7786\n",
      "---- Validation ----\n",
      "Validation loss: 39.3308\n",
      "Validation acc: 0.7335\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 428.5990, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 418.9287, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 20: 412.7088, Accuracy: 0.7772\n",
      "Training loss (for one batch) at step 30: 406.3242, Accuracy: 0.7833\n",
      "Training loss (for one batch) at step 40: 399.3617, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 50: 385.0725, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 60: 414.6282, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 70: 427.6120, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 80: 432.1583, Accuracy: 0.7926\n",
      "Training loss (for one batch) at step 90: 426.4946, Accuracy: 0.7897\n",
      "Training loss (for one batch) at step 100: 409.8254, Accuracy: 0.7871\n",
      "Training loss (for one batch) at step 110: 412.9770, Accuracy: 0.7874\n",
      "---- Training ----\n",
      "Training loss: 131.1814\n",
      "Training acc over epoch: 0.7864\n",
      "---- Validation ----\n",
      "Validation loss: 36.8610\n",
      "Validation acc: 0.7370\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 445.9054, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 413.8710, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 20: 409.5961, Accuracy: 0.7619\n",
      "Training loss (for one batch) at step 30: 400.3171, Accuracy: 0.7697\n",
      "Training loss (for one batch) at step 40: 380.3166, Accuracy: 0.7803\n",
      "Training loss (for one batch) at step 50: 376.2313, Accuracy: 0.7956\n",
      "Training loss (for one batch) at step 60: 411.0711, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 70: 422.3620, Accuracy: 0.7968\n",
      "Training loss (for one batch) at step 80: 424.6458, Accuracy: 0.7861\n",
      "Training loss (for one batch) at step 90: 425.9104, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 100: 408.0128, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 110: 413.1606, Accuracy: 0.7806\n",
      "---- Training ----\n",
      "Training loss: 125.4328\n",
      "Training acc over epoch: 0.7810\n",
      "---- Validation ----\n",
      "Validation loss: 40.5559\n",
      "Validation acc: 0.7337\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 426.8834, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 400.0052, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 419.6403, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 30: 401.3498, Accuracy: 0.7807\n",
      "Training loss (for one batch) at step 40: 400.8409, Accuracy: 0.7944\n",
      "Training loss (for one batch) at step 50: 368.9952, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 60: 397.5495, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 70: 409.1954, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 80: 417.7279, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 90: 420.6185, Accuracy: 0.7929\n",
      "Training loss (for one batch) at step 100: 400.8351, Accuracy: 0.7916\n",
      "Training loss (for one batch) at step 110: 397.0251, Accuracy: 0.7914\n",
      "---- Training ----\n",
      "Training loss: 123.4270\n",
      "Training acc over epoch: 0.7908\n",
      "---- Validation ----\n",
      "Validation loss: 36.5909\n",
      "Validation acc: 0.7372\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 423.5560, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 424.0158, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 405.9241, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 391.2586, Accuracy: 0.7747\n",
      "Training loss (for one batch) at step 40: 383.2296, Accuracy: 0.7906\n",
      "Training loss (for one batch) at step 50: 362.3910, Accuracy: 0.8013\n",
      "Training loss (for one batch) at step 60: 376.3312, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 70: 395.7529, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 80: 416.2057, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 90: 408.9882, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 100: 409.4677, Accuracy: 0.7888\n",
      "Training loss (for one batch) at step 110: 412.5713, Accuracy: 0.7892\n",
      "---- Training ----\n",
      "Training loss: 130.7039\n",
      "Training acc over epoch: 0.7877\n",
      "---- Validation ----\n",
      "Validation loss: 36.9869\n",
      "Validation acc: 0.7351\n",
      "Time taken: 10.85s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 412.2319, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 411.9314, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 390.1776, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 30: 375.2685, Accuracy: 0.7807\n",
      "Training loss (for one batch) at step 40: 374.4311, Accuracy: 0.7946\n",
      "Training loss (for one batch) at step 50: 368.7826, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 60: 385.3060, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 70: 412.9139, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 80: 409.9779, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 90: 414.2543, Accuracy: 0.7967\n",
      "Training loss (for one batch) at step 100: 389.5921, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 110: 403.7888, Accuracy: 0.7940\n",
      "---- Training ----\n",
      "Training loss: 125.5104\n",
      "Training acc over epoch: 0.7926\n",
      "---- Validation ----\n",
      "Validation loss: 38.5282\n",
      "Validation acc: 0.7319\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 403.1622, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 410.5560, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 20: 383.9961, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 30: 382.5794, Accuracy: 0.7815\n",
      "Training loss (for one batch) at step 40: 375.2596, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 50: 360.3582, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 60: 372.7838, Accuracy: 0.8199\n",
      "Training loss (for one batch) at step 70: 414.3839, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 80: 398.1258, Accuracy: 0.8071\n",
      "Training loss (for one batch) at step 90: 404.7896, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 100: 392.6123, Accuracy: 0.8000\n",
      "Training loss (for one batch) at step 110: 408.4240, Accuracy: 0.7984\n",
      "---- Training ----\n",
      "Training loss: 122.7682\n",
      "Training acc over epoch: 0.7964\n",
      "---- Validation ----\n",
      "Validation loss: 30.2961\n",
      "Validation acc: 0.7200\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 412.1391, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 416.8533, Accuracy: 0.7443\n",
      "Training loss (for one batch) at step 20: 398.4398, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 30: 373.7036, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 40: 385.0439, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 50: 367.3502, Accuracy: 0.8036\n",
      "Training loss (for one batch) at step 60: 370.1833, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 70: 415.1568, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 80: 403.5708, Accuracy: 0.8021\n",
      "Training loss (for one batch) at step 90: 393.3990, Accuracy: 0.7975\n",
      "Training loss (for one batch) at step 100: 391.5997, Accuracy: 0.7980\n",
      "Training loss (for one batch) at step 110: 386.7072, Accuracy: 0.7965\n",
      "---- Training ----\n",
      "Training loss: 122.9341\n",
      "Training acc over epoch: 0.7961\n",
      "---- Validation ----\n",
      "Validation loss: 41.3201\n",
      "Validation acc: 0.7168\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 397.1414, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 399.0491, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 379.0316, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 30: 373.4470, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 40: 374.4195, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 50: 360.5219, Accuracy: 0.8159\n",
      "Training loss (for one batch) at step 60: 370.0508, Accuracy: 0.8221\n",
      "Training loss (for one batch) at step 70: 398.1943, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 80: 408.4089, Accuracy: 0.8081\n",
      "Training loss (for one batch) at step 90: 422.3185, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 100: 391.2114, Accuracy: 0.8027\n",
      "Training loss (for one batch) at step 110: 386.2412, Accuracy: 0.8009\n",
      "---- Training ----\n",
      "Training loss: 131.3665\n",
      "Training acc over epoch: 0.8008\n",
      "---- Validation ----\n",
      "Validation loss: 35.5469\n",
      "Validation acc: 0.7286\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 402.2333, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 393.3546, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 383.5503, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 30: 364.1756, Accuracy: 0.7911\n",
      "Training loss (for one batch) at step 40: 365.6602, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 50: 368.8350, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 60: 371.8665, Accuracy: 0.8224\n",
      "Training loss (for one batch) at step 70: 383.7533, Accuracy: 0.8134\n",
      "Training loss (for one batch) at step 80: 405.3870, Accuracy: 0.8059\n",
      "Training loss (for one batch) at step 90: 393.4183, Accuracy: 0.8014\n",
      "Training loss (for one batch) at step 100: 375.3581, Accuracy: 0.8004\n",
      "Training loss (for one batch) at step 110: 382.2590, Accuracy: 0.8019\n",
      "---- Training ----\n",
      "Training loss: 130.6469\n",
      "Training acc over epoch: 0.7992\n",
      "---- Validation ----\n",
      "Validation loss: 34.4255\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 386.3572, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 401.7931, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 20: 398.6577, Accuracy: 0.7686\n",
      "Training loss (for one batch) at step 30: 356.0586, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 40: 352.7321, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 50: 339.6514, Accuracy: 0.8214\n",
      "Training loss (for one batch) at step 60: 375.8098, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 70: 379.7293, Accuracy: 0.8176\n",
      "Training loss (for one batch) at step 80: 400.1019, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 90: 379.6397, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 100: 380.6378, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 110: 370.3950, Accuracy: 0.8029\n",
      "---- Training ----\n",
      "Training loss: 119.8060\n",
      "Training acc over epoch: 0.8004\n",
      "---- Validation ----\n",
      "Validation loss: 50.2557\n",
      "Validation acc: 0.7246\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 385.9086, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 391.4232, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 386.0124, Accuracy: 0.7772\n",
      "Training loss (for one batch) at step 30: 370.9183, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 40: 356.7164, Accuracy: 0.8098\n",
      "Training loss (for one batch) at step 50: 334.5100, Accuracy: 0.8252\n",
      "Training loss (for one batch) at step 60: 368.2597, Accuracy: 0.8295\n",
      "Training loss (for one batch) at step 70: 382.2795, Accuracy: 0.8211\n",
      "Training loss (for one batch) at step 80: 403.4013, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 90: 376.9508, Accuracy: 0.8086\n",
      "Training loss (for one batch) at step 100: 382.3215, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 110: 378.6585, Accuracy: 0.8073\n",
      "---- Training ----\n",
      "Training loss: 122.5164\n",
      "Training acc over epoch: 0.8053\n",
      "---- Validation ----\n",
      "Validation loss: 41.7192\n",
      "Validation acc: 0.7270\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 392.0684, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 398.6476, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 372.2254, Accuracy: 0.7772\n",
      "Training loss (for one batch) at step 30: 365.3660, Accuracy: 0.7926\n",
      "Training loss (for one batch) at step 40: 346.3019, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 50: 335.2126, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 60: 367.8160, Accuracy: 0.8312\n",
      "Training loss (for one batch) at step 70: 403.9293, Accuracy: 0.8206\n",
      "Training loss (for one batch) at step 80: 375.1391, Accuracy: 0.8095\n",
      "Training loss (for one batch) at step 90: 371.1493, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 100: 362.4446, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 110: 377.1470, Accuracy: 0.8069\n",
      "---- Training ----\n",
      "Training loss: 129.6068\n",
      "Training acc over epoch: 0.8054\n",
      "---- Validation ----\n",
      "Validation loss: 38.0736\n",
      "Validation acc: 0.7206\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 398.3499, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 390.2021, Accuracy: 0.7464\n",
      "Training loss (for one batch) at step 20: 353.7157, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 30: 354.7123, Accuracy: 0.7949\n",
      "Training loss (for one batch) at step 40: 351.2009, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 50: 328.2798, Accuracy: 0.8231\n",
      "Training loss (for one batch) at step 60: 376.7524, Accuracy: 0.8265\n",
      "Training loss (for one batch) at step 70: 402.9940, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 80: 367.1472, Accuracy: 0.8100\n",
      "Training loss (for one batch) at step 90: 369.9608, Accuracy: 0.8071\n",
      "Training loss (for one batch) at step 100: 358.4261, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 110: 390.0837, Accuracy: 0.8072\n",
      "---- Training ----\n",
      "Training loss: 119.6767\n",
      "Training acc over epoch: 0.8055\n",
      "---- Validation ----\n",
      "Validation loss: 49.5600\n",
      "Validation acc: 0.7346\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 383.4797, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 390.7132, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 360.8048, Accuracy: 0.7775\n",
      "Training loss (for one batch) at step 30: 373.1813, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 40: 333.9741, Accuracy: 0.8098\n",
      "Training loss (for one batch) at step 50: 336.4325, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 60: 346.0593, Accuracy: 0.8283\n",
      "Training loss (for one batch) at step 70: 380.9587, Accuracy: 0.8201\n",
      "Training loss (for one batch) at step 80: 406.5428, Accuracy: 0.8101\n",
      "Training loss (for one batch) at step 90: 367.5766, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 100: 357.1839, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 110: 378.8119, Accuracy: 0.8069\n",
      "---- Training ----\n",
      "Training loss: 126.2174\n",
      "Training acc over epoch: 0.8045\n",
      "---- Validation ----\n",
      "Validation loss: 43.6751\n",
      "Validation acc: 0.7066\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 369.3074, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 398.4928, Accuracy: 0.7372\n",
      "Training loss (for one batch) at step 20: 359.9558, Accuracy: 0.7645\n",
      "Training loss (for one batch) at step 30: 350.3833, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 339.4775, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 50: 328.3308, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 60: 343.9564, Accuracy: 0.8280\n",
      "Training loss (for one batch) at step 70: 381.0037, Accuracy: 0.8187\n",
      "Training loss (for one batch) at step 80: 376.0115, Accuracy: 0.8086\n",
      "Training loss (for one batch) at step 90: 353.9957, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 100: 361.2623, Accuracy: 0.8076\n",
      "Training loss (for one batch) at step 110: 365.0334, Accuracy: 0.8073\n",
      "---- Training ----\n",
      "Training loss: 117.0521\n",
      "Training acc over epoch: 0.8051\n",
      "---- Validation ----\n",
      "Validation loss: 47.5126\n",
      "Validation acc: 0.7305\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 377.7786, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 365.5923, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 20: 358.1929, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 30: 353.7164, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 40: 346.3959, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 50: 318.1103, Accuracy: 0.8264\n",
      "Training loss (for one batch) at step 60: 358.7424, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 70: 373.9393, Accuracy: 0.8190\n",
      "Training loss (for one batch) at step 80: 364.5672, Accuracy: 0.8078\n",
      "Training loss (for one batch) at step 90: 372.8159, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 100: 347.6575, Accuracy: 0.8077\n",
      "Training loss (for one batch) at step 110: 370.1706, Accuracy: 0.8072\n",
      "---- Training ----\n",
      "Training loss: 121.9292\n",
      "Training acc over epoch: 0.8060\n",
      "---- Validation ----\n",
      "Validation loss: 38.0027\n",
      "Validation acc: 0.7147\n",
      "Time taken: 10.74s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 387.1965, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 388.9825, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 20: 349.9787, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 30: 352.5151, Accuracy: 0.7951\n",
      "Training loss (for one batch) at step 40: 328.7508, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 50: 324.5506, Accuracy: 0.8264\n",
      "Training loss (for one batch) at step 60: 339.8532, Accuracy: 0.8329\n",
      "Training loss (for one batch) at step 70: 391.8339, Accuracy: 0.8211\n",
      "Training loss (for one batch) at step 80: 356.0970, Accuracy: 0.8112\n",
      "Training loss (for one batch) at step 90: 366.1788, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 100: 363.7365, Accuracy: 0.8082\n",
      "Training loss (for one batch) at step 110: 359.9847, Accuracy: 0.8089\n",
      "---- Training ----\n",
      "Training loss: 121.4980\n",
      "Training acc over epoch: 0.8074\n",
      "---- Validation ----\n",
      "Validation loss: 42.7661\n",
      "Validation acc: 0.7227\n",
      "Time taken: 12.49s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 375.2419, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 367.6228, Accuracy: 0.7834\n",
      "Training loss (for one batch) at step 20: 345.8517, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 30: 339.9432, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 40: 376.7486, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 50: 337.8068, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 60: 345.7985, Accuracy: 0.8325\n",
      "Training loss (for one batch) at step 70: 366.8150, Accuracy: 0.8227\n",
      "Training loss (for one batch) at step 80: 376.9227, Accuracy: 0.8132\n",
      "Training loss (for one batch) at step 90: 356.8623, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 100: 351.0957, Accuracy: 0.8127\n",
      "Training loss (for one batch) at step 110: 373.7868, Accuracy: 0.8105\n",
      "---- Training ----\n",
      "Training loss: 122.2103\n",
      "Training acc over epoch: 0.8088\n",
      "---- Validation ----\n",
      "Validation loss: 42.2153\n",
      "Validation acc: 0.7179\n",
      "Time taken: 10.82s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 379.6794, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 367.2063, Accuracy: 0.7507\n",
      "Training loss (for one batch) at step 20: 335.5447, Accuracy: 0.7697\n",
      "Training loss (for one batch) at step 30: 339.5617, Accuracy: 0.7916\n",
      "Training loss (for one batch) at step 40: 338.8288, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 50: 319.3397, Accuracy: 0.8229\n",
      "Training loss (for one batch) at step 60: 337.5418, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 70: 358.7373, Accuracy: 0.8177\n",
      "Training loss (for one batch) at step 80: 356.3888, Accuracy: 0.8092\n",
      "Training loss (for one batch) at step 90: 363.8508, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 100: 341.0361, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 110: 366.6461, Accuracy: 0.8078\n",
      "---- Training ----\n",
      "Training loss: 116.7739\n",
      "Training acc over epoch: 0.8062\n",
      "---- Validation ----\n",
      "Validation loss: 43.2915\n",
      "Validation acc: 0.7217\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 383.4796, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 359.4904, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 20: 356.5038, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 30: 336.4758, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 40: 334.7669, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 50: 316.1481, Accuracy: 0.8255\n",
      "Training loss (for one batch) at step 60: 346.2460, Accuracy: 0.8294\n",
      "Training loss (for one batch) at step 70: 379.0823, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 80: 365.2594, Accuracy: 0.8112\n",
      "Training loss (for one batch) at step 90: 337.6502, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 100: 354.5269, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 110: 362.3181, Accuracy: 0.8110\n",
      "---- Training ----\n",
      "Training loss: 108.2208\n",
      "Training acc over epoch: 0.8100\n",
      "---- Validation ----\n",
      "Validation loss: 46.6236\n",
      "Validation acc: 0.7219\n",
      "Time taken: 10.48s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7171\n",
      "Validation AUC: 0.7176\n"
     ]
    }
   ],
   "source": [
    "#model = create_model()\n",
    "K=2\n",
    "R=5\n",
    "NUM_RUNS = 10\n",
    "N_EPOCHS = 40\n",
    "val_acc = np.zeros(NUM_RUNS)\n",
    "AUC= np.zeros(NUM_RUNS)\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "  MA = MultipleAnnotators_Classification(2, 5, 0.1)\n",
    "  model =  create_model()\n",
    "  model = MA.fit(model, train_batches_MA, val_batches_MA, N_EPOCHS)\n",
    "  #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n",
    "  val_acc[i] = MA.eval_model(test_batches_MA)\n",
    "  print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n",
    "    \n",
    " #AUC =======================\n",
    "  val_AUC_metric = tf.keras.metrics.AUC( from_logits = True)\n",
    "  for x_batch_val, y_batch_val in test_batches_MA:\n",
    "      val_logits = model(x_batch_val.numpy(), training=False)\n",
    "      # tf.print(y_batch_val)\n",
    "      val_AUC_metric.update_state(y_batch_val, val_logits[:,:K].numpy().argmax(axis=1).astype('float'))\n",
    "\n",
    "  val_AUC = val_AUC_metric.result()\n",
    "  val_AUC_metric.reset_states()\n",
    "  val_AUC = val_AUC.numpy()\n",
    "  print(\"Validation AUC: %.4f\" % (float(val_AUC),))\n",
    "  AUC[i] = val_AUC\n",
    "  #===================================================\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(val_acc)\n",
    "#df.to_csv('/content/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af4b6f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:23.501060Z",
     "iopub.status.busy": "2022-12-21T00:20:23.500414Z",
     "iopub.status.idle": "2022-12-21T00:20:23.507714Z",
     "shell.execute_reply": "2022-12-21T00:20:23.506739Z"
    },
    "papermill": {
     "duration": 0.292375,
     "end_time": "2022-12-21T00:20:23.509836",
     "exception": false,
     "start_time": "2022-12-21T00:20:23.217461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71431643, 0.67949271, 0.71560621, 0.7272141 , 0.72914875,\n",
       "       0.70958728, 0.65928632, 0.72699916, 0.72463459, 0.71711093])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9183dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:24.190460Z",
     "iopub.status.busy": "2022-12-21T00:20:24.189893Z",
     "iopub.status.idle": "2022-12-21T00:20:24.196997Z",
     "shell.execute_reply": "2022-12-21T00:20:24.196116Z"
    },
    "id": "Uq3Ki4uQxcVj",
    "papermill": {
     "duration": 0.407467,
     "end_time": "2022-12-21T00:20:24.202993",
     "exception": false,
     "start_time": "2022-12-21T00:20:23.795526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71354544, 0.67855501, 0.71630722, 0.72757941, 0.73014003,\n",
       "       0.70987767, 0.65959108, 0.72730917, 0.72257483, 0.71764666])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8383722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:25.052008Z",
     "iopub.status.busy": "2022-12-21T00:20:25.051580Z",
     "iopub.status.idle": "2022-12-21T00:20:25.061460Z",
     "shell.execute_reply": "2022-12-21T00:20:25.060588Z"
    },
    "papermill": {
     "duration": 0.437668,
     "end_time": "2022-12-21T00:20:25.066757",
     "exception": false,
     "start_time": "2022-12-21T00:20:24.629089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  71.03\n",
      "Average std:  2.18\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy: ', np.round(val_acc.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std(val_acc),4)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00cee060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:25.697389Z",
     "iopub.status.busy": "2022-12-21T00:20:25.697050Z",
     "iopub.status.idle": "2022-12-21T00:20:25.703316Z",
     "shell.execute_reply": "2022-12-21T00:20:25.702089Z"
    },
    "papermill": {
     "duration": 0.285967,
     "end_time": "2022-12-21T00:20:25.707288",
     "exception": false,
     "start_time": "2022-12-21T00:20:25.421321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  71.03\n",
      "Average std:  2.19\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy: ', np.round( AUC.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std( AUC),4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a6894f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:26.259804Z",
     "iopub.status.busy": "2022-12-21T00:20:26.259403Z",
     "iopub.status.idle": "2022-12-21T00:20:26.263915Z",
     "shell.execute_reply": "2022-12-21T00:20:26.262975Z"
    },
    "id": "cxSh9vktxcVj",
    "papermill": {
     "duration": 0.278729,
     "end_time": "2022-12-21T00:20:26.265935",
     "exception": false,
     "start_time": "2022-12-21T00:20:25.987206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # accuracy\n",
    "# val_acc_GCCE  = np.zeros(NUM_RUNS)\n",
    "\n",
    "# for i in range(len(classification_report_r)):\n",
    "   \n",
    "#   val_acc_GCCE[i] = classification_report_r[i]['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46fb0964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:26.815828Z",
     "iopub.status.busy": "2022-12-21T00:20:26.815440Z",
     "iopub.status.idle": "2022-12-21T00:20:26.822879Z",
     "shell.execute_reply": "2022-12-21T00:20:26.821565Z"
    },
    "id": "Ak1z-BteyMF6",
    "outputId": "8b14abfb-4940-45fb-b50a-df0a4f7a731b",
    "papermill": {
     "duration": 0.284047,
     "end_time": "2022-12-21T00:20:26.825085",
     "exception": false,
     "start_time": "2022-12-21T00:20:26.541038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71431643, 0.67949271, 0.71560621, 0.7272141 , 0.72914875,\n",
       "       0.70958728, 0.65928632, 0.72699916, 0.72463459, 0.71711093])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5f65a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:27.441521Z",
     "iopub.status.busy": "2022-12-21T00:20:27.441169Z",
     "iopub.status.idle": "2022-12-21T00:20:27.446636Z",
     "shell.execute_reply": "2022-12-21T00:20:27.445711Z"
    },
    "id": "K-EeM9bqyI-w",
    "outputId": "b59f0070-7e4c-4480-cd00-da90044724ed",
    "papermill": {
     "duration": 0.344985,
     "end_time": "2022-12-21T00:20:27.449690",
     "exception": false,
     "start_time": "2022-12-21T00:20:27.104705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  71.03\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy: ', np.round(val_acc.mean(),4)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c7974e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:28.002881Z",
     "iopub.status.busy": "2022-12-21T00:20:28.002050Z",
     "iopub.status.idle": "2022-12-21T00:20:28.006518Z",
     "shell.execute_reply": "2022-12-21T00:20:28.005606Z"
    },
    "id": "I0E-qXsr1RFC",
    "papermill": {
     "duration": 0.281119,
     "end_time": "2022-12-21T00:20:28.008436",
     "exception": false,
     "start_time": "2022-12-21T00:20:27.727317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n",
    "# X_test = np.asarray([aux[0].numpy() for aux  in validation_data])\n",
    "# # N = len(y_true)\n",
    "# # #test_batches_MA\n",
    "# # aux1 = [test_batches_MA[i][0] for i in range(N)]\n",
    "# # aux2 = [test_batches_MA[i][1] for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3008abfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:28.569685Z",
     "iopub.status.busy": "2022-12-21T00:20:28.569301Z",
     "iopub.status.idle": "2022-12-21T00:20:28.573577Z",
     "shell.execute_reply": "2022-12-21T00:20:28.572672Z"
    },
    "id": "9P-KeFKp2TEr",
    "outputId": "1998d331-5546-4bc4-c007-8180b58dd574",
    "papermill": {
     "duration": 0.287428,
     "end_time": "2022-12-21T00:20:28.575556",
     "exception": false,
     "start_time": "2022-12-21T00:20:28.288128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63410241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:29.193320Z",
     "iopub.status.busy": "2022-12-21T00:20:29.192944Z",
     "iopub.status.idle": "2022-12-21T00:20:29.197309Z",
     "shell.execute_reply": "2022-12-21T00:20:29.196281Z"
    },
    "id": "6pWXVQnK1GXo",
    "outputId": "89294013-e100-4cc0-9a9e-3f7bad8f7729",
    "papermill": {
     "duration": 0.351052,
     "end_time": "2022-12-21T00:20:29.199643",
     "exception": false,
     "start_time": "2022-12-21T00:20:28.848591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(X_test)\n",
    "# pred[:, :2].argmax(axis=1)\n",
    "# print(classification_report(pred[:, :2].argmax(axis=1), y_test ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a7230",
   "metadata": {
    "id": "STPfoIdfxcVj",
    "papermill": {
     "duration": 0.271637,
     "end_time": "2022-12-21T00:20:29.748110",
     "exception": false,
     "start_time": "2022-12-21T00:20:29.476473",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d48da7fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:30.292290Z",
     "iopub.status.busy": "2022-12-21T00:20:30.291936Z",
     "iopub.status.idle": "2022-12-21T00:20:30.298324Z",
     "shell.execute_reply": "2022-12-21T00:20:30.297409Z"
    },
    "id": "z1b6tNcdxcVj",
    "outputId": "fcf6fada-a56b-45e9-ab8b-e3562b97621e",
    "papermill": {
     "duration": 0.28243,
     "end_time": "2022-12-21T00:20:30.300356",
     "exception": false,
     "start_time": "2022-12-21T00:20:30.017926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103396475315094"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "596d348e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:30.900742Z",
     "iopub.status.busy": "2022-12-21T00:20:30.900367Z",
     "iopub.status.idle": "2022-12-21T00:20:30.906038Z",
     "shell.execute_reply": "2022-12-21T00:20:30.905070Z"
    },
    "papermill": {
     "duration": 0.337621,
     "end_time": "2022-12-21T00:20:30.908843",
     "exception": false,
     "start_time": "2022-12-21T00:20:30.571222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD Accuracy:  2.18\n"
     ]
    }
   ],
   "source": [
    "print('STD Accuracy: ', np.round(np.std(val_acc),4)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed207d1f",
   "metadata": {
    "id": "xxyE_WnFxcVj",
    "papermill": {
     "duration": 0.27257,
     "end_time": "2022-12-21T00:20:31.452861",
     "exception": false,
     "start_time": "2022-12-21T00:20:31.180291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "MC droput run this in a loop with training layer set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee2af6ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:32.005062Z",
     "iopub.status.busy": "2022-12-21T00:20:32.003131Z",
     "iopub.status.idle": "2022-12-21T00:20:32.008364Z",
     "shell.execute_reply": "2022-12-21T00:20:32.007471Z"
    },
    "id": "I6R3im8_xcVk",
    "papermill": {
     "duration": 0.280711,
     "end_time": "2022-12-21T00:20:32.010911",
     "exception": false,
     "start_time": "2022-12-21T00:20:31.730200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_probas = np.stack([MA.eval_model((test_batches,training=True) # se activa training en True para que el Dropout se aplique\n",
    "#                    for sample in range(100)])\n",
    "\n",
    "# y_proba = y_probas.mean(axis=0)\n",
    "# y_std = y_probas.std(axis=0)\n",
    "# y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d3bd30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:32.613758Z",
     "iopub.status.busy": "2022-12-21T00:20:32.613383Z",
     "iopub.status.idle": "2022-12-21T00:20:32.617626Z",
     "shell.execute_reply": "2022-12-21T00:20:32.616625Z"
    },
    "id": "uLKmvJlpxcVk",
    "papermill": {
     "duration": 0.336962,
     "end_time": "2022-12-21T00:20:32.619744",
     "exception": false,
     "start_time": "2022-12-21T00:20:32.282782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_ped =np.argmax(y_proba,axis=1)\n",
    "# accuracy=np.sum(y_pred==test_label)/len(test_label)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fc2b4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:33.302690Z",
     "iopub.status.busy": "2022-12-21T00:20:33.302151Z",
     "iopub.status.idle": "2022-12-21T00:20:33.306920Z",
     "shell.execute_reply": "2022-12-21T00:20:33.305957Z"
    },
    "id": "Jl1sFNOf1KgC",
    "papermill": {
     "duration": 0.418537,
     "end_time": "2022-12-21T00:20:33.311297",
     "exception": false,
     "start_time": "2022-12-21T00:20:32.892760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "# r1 = np.mean(val_acc)\n",
    "# print(\"\\nMean: \", r1)\n",
    "  \n",
    "# r2 = np.std(val_acc)\n",
    "# print(\"\\nstd: \", r2)\n",
    "  \n",
    "# r3 = np.var(val_acc)\n",
    "# print(\"\\nvariance: \", r3)\n",
    "# #MA.eval_model(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a020d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T00:20:33.976251Z",
     "iopub.status.busy": "2022-12-21T00:20:33.975887Z",
     "iopub.status.idle": "2022-12-21T00:20:33.980353Z",
     "shell.execute_reply": "2022-12-21T00:20:33.979334Z"
    },
    "id": "KqeZpkxuxcVk",
    "papermill": {
     "duration": 0.28285,
     "end_time": "2022-12-21T00:20:33.982320",
     "exception": false,
     "start_time": "2022-12-21T00:20:33.699470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081ae8b",
   "metadata": {
    "id": "6cjM2VJJkuKK",
    "papermill": {
     "duration": 0.275067,
     "end_time": "2022-12-21T00:20:34.580416",
     "exception": false,
     "start_time": "2022-12-21T00:20:34.305349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "VGG19 --> acc:0.8613  --> 0.894454 --> 0.772356"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4549.015093,
   "end_time": "2022-12-21T00:20:38.032406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-20T23:04:49.017313",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
