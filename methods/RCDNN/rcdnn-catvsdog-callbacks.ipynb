{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf60cad",
   "metadata": {
    "id": "oAuRT75GdLFw",
    "papermill": {
     "duration": 0.008299,
     "end_time": "2023-02-14T20:07:19.950195",
     "exception": false,
     "start_time": "2023-02-14T20:07:19.941896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cats vs. Dogs Class dataset for multiple annotators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b9d57",
   "metadata": {
    "id": "9rK94t33nwDC",
    "papermill": {
     "duration": 0.006562,
     "end_time": "2023-02-14T20:07:19.965158",
     "exception": false,
     "start_time": "2023-02-14T20:07:19.958596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9991db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:19.981447Z",
     "iopub.status.busy": "2023-02-14T20:07:19.980490Z",
     "iopub.status.idle": "2023-02-14T20:07:26.552901Z",
     "shell.execute_reply": "2023-02-14T20:07:26.551896Z"
    },
    "id": "zSyMHuCVys-O",
    "papermill": {
     "duration": 6.583864,
     "end_time": "2023-02-14T20:07:26.555718",
     "exception": false,
     "start_time": "2023-02-14T20:07:19.971854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a2fb3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:26.571612Z",
     "iopub.status.busy": "2023-02-14T20:07:26.569912Z",
     "iopub.status.idle": "2023-02-14T20:07:27.195415Z",
     "shell.execute_reply": "2023-02-14T20:07:27.194420Z"
    },
    "id": "-E1MJt8cxlwg",
    "outputId": "ea43c1c9-075f-44de-d2d8-e135799b6630",
    "papermill": {
     "duration": 0.635406,
     "end_time": "2023-02-14T20:07:27.197800",
     "exception": false,
     "start_time": "2023-02-14T20:07:26.562394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.io import savemat\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import mode \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def ook(t):\n",
    "  lb = LabelBinarizer()\n",
    "  y_ook = lb.fit_transform(t)  \n",
    "\n",
    "  if len(np.unique(t))==2:\n",
    "    y_ook = np.concatenate((1-y_ook.astype(bool), y_ook), axis = 1) \n",
    "\n",
    "  return y_ook\n",
    "\n",
    "\n",
    "def scheduler1(step = 10, ratio = 1.2):\n",
    "  def scheduler(epoch, lr):\n",
    "    if epoch % step == 0 and epoch>1:\n",
    "      return lr/ratio\n",
    "    else:\n",
    "      return lr\n",
    "  return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a4bde5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:27.212197Z",
     "iopub.status.busy": "2023-02-14T20:07:27.211871Z",
     "iopub.status.idle": "2023-02-14T20:07:27.216209Z",
     "shell.execute_reply": "2023-02-14T20:07:27.215198Z"
    },
    "id": "QJPvjdZ-f8ca",
    "papermill": {
     "duration": 0.014132,
     "end_time": "2023-02-14T20:07:27.218581",
     "exception": false,
     "start_time": "2023-02-14T20:07:27.204449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/Shareddrives/Multiple Anotators/CrowdLayer/Notebooks')\n",
    "# cwd = os.getcwd()\n",
    "# sys.path.append(\"../Models\")\n",
    "\n",
    "\n",
    "# from Multiple_Annotators_C import MultipleAnnotators_Classification\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(1, '../input/multiple-annotators-c/')\n",
    "#os.chdir('/Multiple Anotators-c/')\n",
    "#cwd = os.getcwd()\n",
    "#sys.path.append('/input/multiple-annotators-c')\n",
    "#from Multiple_Annotators_C import MultipleAnnotators_Classification\n",
    "\n",
    "# seed_value= 12321 \n",
    "# from numpy.random import seed\n",
    "# seed(seed_value)\n",
    "# tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c390f6",
   "metadata": {
    "id": "6Un5nFWgnyem",
    "papermill": {
     "duration": 0.00744,
     "end_time": "2023-02-14T20:07:27.232299",
     "exception": false,
     "start_time": "2023-02-14T20:07:27.224859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download and Prepare the Dataset\n",
    "\n",
    "We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset and we can load it via Tensorflow Datasets. The images are labeled 0 for cats and 1 for dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47737adc",
   "metadata": {
    "id": "Gw6K2Uey06kh",
    "papermill": {
     "duration": 0.006102,
     "end_time": "2023-02-14T20:07:27.244584",
     "exception": false,
     "start_time": "2023-02-14T20:07:27.238482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiple annotators model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fe1b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:27.259099Z",
     "iopub.status.busy": "2023-02-14T20:07:27.258032Z",
     "iopub.status.idle": "2023-02-14T20:07:30.013814Z",
     "shell.execute_reply": "2023-02-14T20:07:30.012851Z"
    },
    "id": "xam4REp209Sd",
    "papermill": {
     "duration": 2.765392,
     "end_time": "2023-02-14T20:07:30.016160",
     "exception": false,
     "start_time": "2023-02-14T20:07:27.250768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 20:07:27.356302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:27.520552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:27.521463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:27.523579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 20:07:27.527109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:27.527873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:27.528611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:29.591093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:29.591950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:29.592661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 20:07:29.593304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_data = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_Te')\n",
    "train_data_MA = tf.data.experimental.load('/kaggle/input/cat-vs-dog-ma-sin/cats_dogs_MA_sin_Tr_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a95076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:30.032475Z",
     "iopub.status.busy": "2023-02-14T20:07:30.030733Z",
     "iopub.status.idle": "2023-02-14T20:07:30.041143Z",
     "shell.execute_reply": "2023-02-14T20:07:30.040057Z"
    },
    "id": "D_S0EJ3mFdfK",
    "outputId": "9ed3c2c7-50b4-4445-a01e-c9a3d780c403",
    "papermill": {
     "duration": 0.020587,
     "end_time": "2023-02-14T20:07:30.043693",
     "exception": false,
     "start_time": "2023-02-14T20:07:30.023106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_data_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3de654d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:30.058307Z",
     "iopub.status.busy": "2023-02-14T20:07:30.057955Z",
     "iopub.status.idle": "2023-02-14T20:07:30.065076Z",
     "shell.execute_reply": "2023-02-14T20:07:30.064214Z"
    },
    "id": "ctjLei0TxcVh",
    "outputId": "6f578b73-ebdf-4465-91c7-2adb7d127174",
    "papermill": {
     "duration": 0.016896,
     "end_time": "2023-02-14T20:07:30.067192",
     "exception": false,
     "start_time": "2023-02-14T20:07:30.050296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4652"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count1 = tf.data.experimental.cardinality(validation_data).numpy() # los datos de training son 18610\n",
    "image_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294ecd1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:30.082439Z",
     "iopub.status.busy": "2023-02-14T20:07:30.081746Z",
     "iopub.status.idle": "2023-02-14T20:07:48.699107Z",
     "shell.execute_reply": "2023-02-14T20:07:48.698095Z"
    },
    "id": "opk5MXl4IwjC",
    "papermill": {
     "duration": 18.627524,
     "end_time": "2023-02-14T20:07:48.701482",
     "exception": false,
     "start_time": "2023-02-14T20:07:30.073958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 20:07:30.108164: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "#X_test = [validation_data[i][0] for i in range(image_count1)]\n",
    "#Y_true_test = [validation_data[i][1] for i in range(image_count1)]\n",
    "Y_true_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n",
    "X_test = np.asarray([aux[0].numpy() for aux  in validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7498de0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:48.717572Z",
     "iopub.status.busy": "2023-02-14T20:07:48.717234Z",
     "iopub.status.idle": "2023-02-14T20:07:48.724265Z",
     "shell.execute_reply": "2023-02-14T20:07:48.723205Z"
    },
    "id": "-BydcVOQxcVh",
    "outputId": "8c1b4ed2-7c43-4675-f055-f9e4e3f5b3dd",
    "papermill": {
     "duration": 0.016991,
     "end_time": "2023-02-14T20:07:48.726440",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.709449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3dbc37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:48.741283Z",
     "iopub.status.busy": "2023-02-14T20:07:48.740949Z",
     "iopub.status.idle": "2023-02-14T20:07:48.748228Z",
     "shell.execute_reply": "2023-02-14T20:07:48.747326Z"
    },
    "id": "HdFme6fdxcVh",
    "papermill": {
     "duration": 0.016934,
     "end_time": "2023-02-14T20:07:48.750135",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.733201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds_MA = train_data_MA.skip(val_size)\n",
    "val_ds_MA = train_data_MA.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be2d8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:48.765583Z",
     "iopub.status.busy": "2023-02-14T20:07:48.765291Z",
     "iopub.status.idle": "2023-02-14T20:07:48.775155Z",
     "shell.execute_reply": "2023-02-14T20:07:48.774277Z"
    },
    "id": "aVHIlFpgxcVi",
    "papermill": {
     "duration": 0.020097,
     "end_time": "2023-02-14T20:07:48.777075",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.756978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_batches_MA = train_ds_MA.shuffle(1024).batch(batch_size)\n",
    "val_batches_MA = val_ds_MA.shuffle(1024).batch(batch_size)\n",
    "test_batches_MA = validation_data.shuffle(1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b89374e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:48.791824Z",
     "iopub.status.busy": "2023-02-14T20:07:48.791533Z",
     "iopub.status.idle": "2023-02-14T20:07:48.799019Z",
     "shell.execute_reply": "2023-02-14T20:07:48.797979Z"
    },
    "id": "GsB4EA2-xcVi",
    "outputId": "2d45809e-a9cc-408f-9a8b-745e8fe850e9",
    "papermill": {
     "duration": 0.017268,
     "end_time": "2023-02-14T20:07:48.801144",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.783876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1814dad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:48.816328Z",
     "iopub.status.busy": "2023-02-14T20:07:48.815989Z",
     "iopub.status.idle": "2023-02-14T20:07:48.823139Z",
     "shell.execute_reply": "2023-02-14T20:07:48.822213Z"
    },
    "id": "Hk33DzwkxcVi",
    "outputId": "aad91eec-842c-4995-de90-5bb715539b6a",
    "papermill": {
     "duration": 0.016992,
     "end_time": "2023-02-14T20:07:48.825076",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.808084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3722"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count_val = tf.data.experimental.cardinality(val_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n",
    "image_count_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5482296",
   "metadata": {
    "id": "UMeK3NG3xcVi",
    "papermill": {
     "duration": 0.006748,
     "end_time": "2023-02-14T20:07:48.838865",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.832117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e6b03d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:07:48.854889Z",
     "iopub.status.busy": "2023-02-14T20:07:48.853975Z",
     "iopub.status.idle": "2023-02-14T20:08:08.171159Z",
     "shell.execute_reply": "2023-02-14T20:08:08.170187Z"
    },
    "id": "uvwc7eixxcVi",
    "outputId": "d7766078-8c40-41ed-fb01-66b5f62a07f1",
    "papermill": {
     "duration": 19.327244,
     "end_time": "2023-02-14T20:08:08.173193",
     "exception": false,
     "start_time": "2023-02-14T20:07:48.845949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 20:08:02.319597: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n",
      "2023-02-14 20:08:05.816969: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.84      0.84        70\n",
      "         1.0       0.81      0.79      0.80        58\n",
      "\n",
      "    accuracy                           0.82       128\n",
      "   macro avg       0.82      0.82      0.82       128\n",
      "weighted avg       0.82      0.82      0.82       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.56      0.57        70\n",
      "         1.0       0.50      0.53      0.52        58\n",
      "\n",
      "    accuracy                           0.55       128\n",
      "   macro avg       0.55      0.55      0.55       128\n",
      "weighted avg       0.55      0.55      0.55       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.67      0.69        70\n",
      "         1.0       0.62      0.66      0.64        58\n",
      "\n",
      "    accuracy                           0.66       128\n",
      "   macro avg       0.66      0.66      0.66       128\n",
      "weighted avg       0.67      0.66      0.66       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.54      0.58        70\n",
      "         1.0       0.52      0.60      0.56        58\n",
      "\n",
      "    accuracy                           0.57       128\n",
      "   macro avg       0.57      0.57      0.57       128\n",
      "weighted avg       0.58      0.57      0.57       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.29      0.29        70\n",
      "         1.0       0.17      0.17      0.17        58\n",
      "\n",
      "    accuracy                           0.23       128\n",
      "   macro avg       0.23      0.23      0.23       128\n",
      "weighted avg       0.24      0.23      0.24       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.80      0.82        59\n",
      "         1.0       0.83      0.87      0.85        69\n",
      "\n",
      "    accuracy                           0.84       128\n",
      "   macro avg       0.84      0.83      0.83       128\n",
      "weighted avg       0.84      0.84      0.84       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.49      0.49        59\n",
      "         1.0       0.57      0.57      0.57        69\n",
      "\n",
      "    accuracy                           0.53       128\n",
      "   macro avg       0.53      0.53      0.53       128\n",
      "weighted avg       0.53      0.53      0.53       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.68      0.61        59\n",
      "         1.0       0.65      0.52      0.58        69\n",
      "\n",
      "    accuracy                           0.59       128\n",
      "   macro avg       0.60      0.60      0.59       128\n",
      "weighted avg       0.61      0.59      0.59       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.51      0.48        59\n",
      "         1.0       0.52      0.46      0.49        69\n",
      "\n",
      "    accuracy                           0.48       128\n",
      "   macro avg       0.49      0.49      0.48       128\n",
      "weighted avg       0.49      0.48      0.48       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.25      0.23        59\n",
      "         1.0       0.25      0.22      0.23        69\n",
      "\n",
      "    accuracy                           0.23       128\n",
      "   macro avg       0.24      0.24      0.23       128\n",
      "weighted avg       0.24      0.23      0.23       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.81        61\n",
      "         1.0       0.85      0.76      0.80        67\n",
      "\n",
      "    accuracy                           0.80       128\n",
      "   macro avg       0.81      0.81      0.80       128\n",
      "weighted avg       0.81      0.80      0.80       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.51      0.51        61\n",
      "         1.0       0.55      0.55      0.55        67\n",
      "\n",
      "    accuracy                           0.53       128\n",
      "   macro avg       0.53      0.53      0.53       128\n",
      "weighted avg       0.53      0.53      0.53       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.61      0.60        61\n",
      "         1.0       0.64      0.63      0.63        67\n",
      "\n",
      "    accuracy                           0.62       128\n",
      "   macro avg       0.62      0.62      0.62       128\n",
      "weighted avg       0.62      0.62      0.62       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.43      0.44        61\n",
      "         1.0       0.50      0.52      0.51        67\n",
      "\n",
      "    accuracy                           0.48       128\n",
      "   macro avg       0.47      0.47      0.47       128\n",
      "weighted avg       0.48      0.48      0.48       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.28      0.26        61\n",
      "         1.0       0.21      0.18      0.20        67\n",
      "\n",
      "    accuracy                           0.23       128\n",
      "   macro avg       0.23      0.23      0.23       128\n",
      "weighted avg       0.22      0.23      0.22       128\n",
      "\n",
      "annotator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80        61\n",
      "         1.0       0.82      0.82      0.82        67\n",
      "\n",
      "    accuracy                           0.81       128\n",
      "   macro avg       0.81      0.81      0.81       128\n",
      "weighted avg       0.81      0.81      0.81       128\n",
      "\n",
      "annotator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.57      0.57        61\n",
      "         1.0       0.61      0.61      0.61        67\n",
      "\n",
      "    accuracy                           0.59       128\n",
      "   macro avg       0.59      0.59      0.59       128\n",
      "weighted avg       0.59      0.59      0.59       128\n",
      "\n",
      "annotator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.69      0.63        61\n",
      "         1.0       0.66      0.55      0.60        67\n",
      "\n",
      "    accuracy                           0.62       128\n",
      "   macro avg       0.62      0.62      0.62       128\n",
      "weighted avg       0.62      0.62      0.62       128\n",
      "\n",
      "annotator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.59      0.56        61\n",
      "         1.0       0.58      0.52      0.55        67\n",
      "\n",
      "    accuracy                           0.55       128\n",
      "   macro avg       0.56      0.56      0.55       128\n",
      "weighted avg       0.56      0.55      0.55       128\n",
      "\n",
      "annotator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.21      0.25      0.22        61\n",
      "         1.0       0.16      0.13      0.15        67\n",
      "\n",
      "    accuracy                           0.19       128\n",
      "   macro avg       0.18      0.19      0.19       128\n",
      "weighted avg       0.18      0.19      0.18       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "i = 0\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for image, label, label2 in train_batches_MA.take(4):\n",
    "   # predictedLabel = int(predictions[i] >= 0.5)\n",
    "   # print(label2)\n",
    "    ax[i].axis('off')\n",
    "   # ax[i].set_title(classNames[label[i]])\n",
    "    ax[i].imshow(image[0])\n",
    "    i += 1\n",
    "    for j in range(label2.shape[1]):\n",
    "      print('annotator',j+1)\n",
    "      print(classification_report(label ,label2[:,j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d9182",
   "metadata": {
    "id": "9AgOHREc1bmd",
    "papermill": {
     "duration": 0.007917,
     "end_time": "2023-02-14T20:08:08.189744",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.181827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the classifier from multiple annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e760e6d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.208061Z",
     "iopub.status.busy": "2023-02-14T20:08:08.207357Z",
     "iopub.status.idle": "2023-02-14T20:08:08.233825Z",
     "shell.execute_reply": "2023-02-14T20:08:08.232904Z"
    },
    "id": "k-ePr0-fxcVi",
    "papermill": {
     "duration": 0.038186,
     "end_time": "2023-02-14T20:08:08.235871",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.197685",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "class MultipleAnnotators_Classification():\n",
    "    def __init__(self, output_dim, num_annotators, q= 0.0001):\n",
    "        self.K = output_dim\n",
    "        self.R = num_annotators\n",
    "        self.q = q\n",
    "        #self.callbacks #=callbacks\n",
    "        #self.l1_param=l1_param \n",
    "        #self.l2_param=l1_param\n",
    "\n",
    "    def CrowdLayer(self, input):\n",
    "       #x = keras.layers.Dense(self.R + self.K, kernel_regularizer=regularizers.L1L2(l1= 1e-2, l2=1e-3),  activation='tanh')(input)\n",
    "        output_cla = keras.layers.Dense(self.K,  activation='softmax')(input)\n",
    "        output_ann = keras.layers.Dense(self.R,  activation='sigmoid')(input)\n",
    "        output = keras.layers.Concatenate()([output_cla, output_ann])\n",
    "        \n",
    "        return output\n",
    "#RCDNN   \n",
    "    def loss(self):\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            # print(y_true,y_pred)\n",
    "            pred = y_pred[:, :self.K]\n",
    "            pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1-1e-9) #estabilidad numerica de la funcion de costo\n",
    "            ann_ = y_pred[:, self.K:]\n",
    "            Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n",
    "            Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n",
    "            p_logreg = tf.math.reduce_prod(tf.math.pow(Y_hat, Y_true), axis=1)\n",
    "            temp1 = ann_*tf.math.log(p_logreg)  \n",
    "            temp2 = (1 - ann_)*tf.math.log(1/self.K)*tf.reduce_sum(Y_true,axis=1)\n",
    "            # temp2 = (tf.ones(tf.shape(ann_)) - ann_)*tf.math.log(1/K)\n",
    "            # print(tf.reduce_mean(Y_true,axis=1).numpy())\n",
    "            return -tf.math.reduce_sum((temp1 + temp2))\n",
    "        return custom_loss\n",
    "    \n",
    "#     def loss(self):\n",
    "#         def custom_loss(y_true, y_pred):\n",
    "#                # print(y_true,y_pred)\n",
    "#            # q = 0.1\n",
    "#             pred = y_pred[:, :self.K]\n",
    "#             pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n",
    "#             ann_ = y_pred[:, self.K:]\n",
    "#             # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n",
    "#             Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n",
    "#             Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n",
    "\n",
    "#             p_gcce = Y_true*(1 - Y_hat**self.q)/self.q\n",
    "#             temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n",
    "#             temp2 = (1 - ann_)*(1-(1/self.K)**self.q)/self.q*tf.reduce_sum(Y_true,axis=1)\n",
    "#             return tf.math.reduce_sum((temp1 + temp2))\n",
    "#         return custom_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x, Y, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(x, training=True)\n",
    "            loss_value = self.loss_fn(Y, logits)\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        self.train_acc_metric.update_state(y, logits[:, :self.K])\n",
    "        return loss_value\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, x, y):\n",
    "        val_logits = self.model(x, training=False)\n",
    "        self.val_acc_metric.update_state(y, val_logits[:,:self.K])\n",
    "\n",
    "    def fit(self, model, Data_tr, Data_Val, epochs):\n",
    "        self.model = model\n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # Instantiate an optimizer.\n",
    "        #self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "        self.optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        #self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, clipnorm=1.0)\n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # Instantiate a loss function.\n",
    "        self.loss_fn = self.loss()\n",
    "        self.train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        train_loss = np.zeros(epochs)\n",
    "        train_accur = np.zeros(epochs)\n",
    "        val_accur = np.zeros(epochs)\n",
    "        val_loss = np.zeros(epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train, Y_batch_train) in enumerate(Data_tr):\n",
    "                # print(y_batch_train, Y_batch_train)\n",
    "                loss_value = self.train_step(x_batch_train, Y_batch_train, y_batch_train)\n",
    "\n",
    "                # Log every 200 batches.\n",
    "                if step % 10 == 0:\n",
    "                    train_acc = self.train_acc_metric.result()\n",
    "                    print(\n",
    "                      \"Training loss (for one batch) at step %d: %.4f, Accuracy: %.4f\"\n",
    "                      % (step, float(loss_value), float(train_acc))\n",
    "                            )\n",
    "                # print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "\n",
    "\n",
    "            # Run a validation loop at the end of each epoch.\n",
    "            for x_batch_val, y_batch_val,Y_batch_val in Data_Val:\n",
    "\n",
    "                val_logits = model(x_batch_val, training=False)\n",
    "\n",
    "                val_loss_value = self.loss_fn(Y_batch_val, val_logits)\n",
    "\n",
    "                self.val_acc_metric.update_state(y_batch_val, val_logits[:,:self.K])\n",
    "                \n",
    "               # np.round(np.mean([model(x_batch_val, training= True) for sample in range(100)]), 2)\n",
    "\n",
    "\n",
    "             # Display metrics at the end of each epoch.\n",
    "            train_acc = self.train_acc_metric.result()\n",
    "            val_acc = self.val_acc_metric.result()\n",
    "\n",
    "\n",
    "            print('---- Training ----')\n",
    "            print(\"Training loss: %.4f\" % (float(loss_value),))\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            self.train_acc_metric.reset_states()\n",
    "            self.val_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "            train_loss[epoch] = float(loss_value)\n",
    "            train_accur[epoch] = float(train_acc)\n",
    "\n",
    "            val_accur[epoch] = float(val_acc)\n",
    "            val_loss[epoch] = float(val_loss_value) \n",
    "\n",
    "\n",
    "            print('---- Validation ----')\n",
    "            print(\"Validation loss: %.4f\" % (float(val_loss_value),))\n",
    "            print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "\n",
    "            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Loss and accuracy')\n",
    "        ax1.plot(range(1,epochs+1),train_loss)\n",
    "        ax1.plot(range(1,epochs+1), val_loss)\n",
    "        ax2.plot(range(1,epochs+1),train_accur)\n",
    "        ax2.plot(range(1,epochs+1),val_accur)\n",
    "        #plt.figure(figsize=(16,9))\n",
    "        ax1.set(xlabel= 'Epoch', ylabel=\"Loss\")\n",
    "        ax2.set(xlabel= 'Epoch',ylabel=\"Accuracy\")\n",
    "        ax1.legend(['Training_loss', 'Validation_loss'])\n",
    "        ax2.legend(['Training', 'Validation'])\n",
    "        ax1.grid()\n",
    "        ax2.grid()\n",
    "        plt.show()\n",
    "        return self.model\n",
    "\n",
    "    def eval_model(self, Data):\n",
    "        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "        for x_batch_val, y_batch_val in Data:\n",
    "            self.test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        val_acc = self.val_acc_metric.result()\n",
    "        self.val_acc_metric.reset_states()\n",
    "        return val_acc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca045e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.253189Z",
     "iopub.status.busy": "2023-02-14T20:08:08.252894Z",
     "iopub.status.idle": "2023-02-14T20:08:08.263626Z",
     "shell.execute_reply": "2023-02-14T20:08:08.262800Z"
    },
    "id": "4l-_pkpaBkSv",
    "papermill": {
     "duration": 0.021901,
     "end_time": "2023-02-14T20:08:08.265812",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.243911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # print(y_true,y_pred)\n",
    "  K = 2 #len(np.unique(y_true))\n",
    "  R = 5\n",
    "  q = 0.1\n",
    "  pred = y_pred[:, K]\n",
    "  pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n",
    "  ann_ = y_pred[:,  K:]\n",
    "  # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n",
    "  Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=K, axis=1)\n",
    "  Y_hat = tf.repeat(tf.expand_dims(pred,-1), R, axis = -1)\n",
    "\n",
    "  p_gcce = Y_true*(1 - Y_hat**q)/q\n",
    "  temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n",
    "  temp2 = (1 - ann_)*(1-(1/K)**q)/q*tf.reduce_sum(Y_true,axis=1)\n",
    "  return tf.math.reduce_sum((temp1 + temp2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59717858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.283830Z",
     "iopub.status.busy": "2023-02-14T20:08:08.283117Z",
     "iopub.status.idle": "2023-02-14T20:08:08.291058Z",
     "shell.execute_reply": "2023-02-14T20:08:08.290102Z"
    },
    "papermill": {
     "duration": 0.018797,
     "end_time": "2023-02-14T20:08:08.292995",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.274198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.io import savemat\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import mode \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def ook(t):\n",
    "  lb = LabelBinarizer()\n",
    "  y_ook = lb.fit_transform(t)  \n",
    "\n",
    "  if len(np.unique(t))==2:\n",
    "    y_ook = np.concatenate((1-y_ook.astype(bool), y_ook), axis = 1) \n",
    "\n",
    "  return y_ook\n",
    "\n",
    "\n",
    "def scheduler1(step = 10, ratio = 1.2):\n",
    "  def scheduler(epoch, lr):\n",
    "    if epoch % step == 0 and epoch>1:\n",
    "      return lr/ratio\n",
    "    else:\n",
    "      return lr\n",
    "  return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91f4a6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.310788Z",
     "iopub.status.busy": "2023-02-14T20:08:08.310514Z",
     "iopub.status.idle": "2023-02-14T20:08:08.323419Z",
     "shell.execute_reply": "2023-02-14T20:08:08.322565Z"
    },
    "id": "0I4Rrc5TxcVj",
    "papermill": {
     "duration": 0.024201,
     "end_time": "2023-02-14T20:08:08.325342",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.301141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MA = MultipleAnnotators_Classification(2, 5, 0.001)\n",
    " \n",
    "def create_model():\n",
    "   \n",
    "    l1 = 1e-2\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=100)\n",
    "    # Block 1\n",
    "    inputs = keras.layers.Input(shape=(150, 150, 3), name='entrada')\n",
    "    x = keras.layers.BatchNormalization()(inputs)\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\" , name=\"block1_conv1\", bias_initializer='zeros', kernel_initializer=initializer)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n",
    "\n",
    "\n",
    "    # Block 2\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", bias_initializer='zeros', kernel_initializer=initializer, name=\"block2_conv1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\",bias_initializer='zeros', kernel_initializer=initializer, name=\"block3_conv1\" )(x)             \n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "   # x = keras.layers.Dropout(0.2)(x)\n",
    "   \n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n",
    "    \n",
    "    # Block 4\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\",bias_initializer='zeros', kernel_initializer=initializer, name=\"block4_conv1\")(x)            \n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    #x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "   \n",
    "    x = keras.layers.Flatten()(x)\n",
    "    #x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\",bias_initializer='zeros', kernel_initializer=initializer)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    output = MA.CrowdLayer(x)\n",
    "    model = keras.Model(inputs=inputs,outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ee2292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.343917Z",
     "iopub.status.busy": "2023-02-14T20:08:08.342421Z",
     "iopub.status.idle": "2023-02-14T20:08:08.347718Z",
     "shell.execute_reply": "2023-02-14T20:08:08.346896Z"
    },
    "id": "iZAxrNF3_hE_",
    "papermill": {
     "duration": 0.016125,
     "end_time": "2023-02-14T20:08:08.349499",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.333374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# callbacks = [\n",
    "#     EarlyStopping(patience=10, verbose=1),\n",
    "#     ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "#     ModelCheckpoint('model1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# ] ,  callbacks = [callback1, callback2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134b834",
   "metadata": {
    "id": "Z-fV95n3GEqa",
    "papermill": {
     "duration": 0.008359,
     "end_time": "2023-02-14T20:08:08.366496",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.358137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "512d26cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.385103Z",
     "iopub.status.busy": "2023-02-14T20:08:08.384213Z",
     "iopub.status.idle": "2023-02-14T20:08:08.389752Z",
     "shell.execute_reply": "2023-02-14T20:08:08.388829Z"
    },
    "id": "_H_sb1cl1FC_",
    "outputId": "59d957da-9223-4a01-e4d9-33933f7a2f4a",
    "papermill": {
     "duration": 0.017348,
     "end_time": "2023-02-14T20:08:08.391846",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.374498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classification_report_r= []\n",
    "# model = create_model()\n",
    "# K=2\n",
    "# R=5\n",
    "# NUM_RUNS = 5\n",
    "# N_EPOCHS = 30\n",
    "# val_acc = np.zeros(NUM_RUNS)\n",
    "# for i in range(NUM_RUNS):\n",
    "#   MA = MultipleAnnotators_Classification(K, R, 0.1)\n",
    "#   model = create_model()\n",
    "#   optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "#   model.compile(optimizer=optimizer, loss= MA.loss())\n",
    "#   history_model = model.fit(train_batches_MA, validation_data=val_batches_MA, epochs= N_EPOCHS, callbacks=callbacks, verbose=0)\n",
    "#   #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n",
    "#   pred_2 = model.predict(X_test)\n",
    "\n",
    "#   lambda_R_ = pred_2[:, K:] #annotators reliability prediction N x R   \n",
    "#   classification_report_r += [classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel(),output_dict=True)]\n",
    "#   print(classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel()))\n",
    "#   #val_acc[i] = MA.eval_model(test_batches_MA)\n",
    "#   #print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n",
    "#   # Create the history figure\n",
    "#   plt.figure(figsize=(16,9))\n",
    "#   for i in  history_model.history:\n",
    "#       plt.plot(history_model.history[i],label=i)\n",
    "#   plt.title('Model history')\n",
    "#   plt.legend()\n",
    "#   plt.grid()\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(val_acc)\n",
    "# #df.to_csimport pandas as pddf = pd.DataFrame(val_acc)#df.to_csv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output​v('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b67e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.409286Z",
     "iopub.status.busy": "2023-02-14T20:08:08.408956Z",
     "iopub.status.idle": "2023-02-14T20:08:08.414458Z",
     "shell.execute_reply": "2023-02-14T20:08:08.413484Z"
    },
    "papermill": {
     "duration": 0.016474,
     "end_time": "2023-02-14T20:08:08.416361",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.399887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback1 = tf.keras.callbacks.TerminateOnNaN()\n",
    "callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler1(ratio = 1))\n",
    "#callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler2)\n",
    "callback3 = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=1e-2,\n",
    "                                         patience=15, verbose=0, mode=\"auto\",\n",
    "                                         baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9cf3137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T20:08:08.434542Z",
     "iopub.status.busy": "2023-02-14T20:08:08.434253Z",
     "iopub.status.idle": "2023-02-14T21:38:39.971151Z",
     "shell.execute_reply": "2023-02-14T21:38:39.970082Z"
    },
    "id": "Mu0lyAUIGSTB",
    "outputId": "cb82872d-c3ba-4d76-a28c-237eb266e78b",
    "papermill": {
     "duration": 5431.550268,
     "end_time": "2023-02-14T21:38:39.975230",
     "exception": false,
     "start_time": "2023-02-14T20:08:08.424962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 20:08:11.870191: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 602.5605, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 573.9174, Accuracy: 0.5256\n",
      "Training loss (for one batch) at step 20: 530.3674, Accuracy: 0.5167\n",
      "Training loss (for one batch) at step 30: 526.7459, Accuracy: 0.5202\n",
      "Training loss (for one batch) at step 40: 500.4533, Accuracy: 0.5103\n",
      "Training loss (for one batch) at step 50: 476.6234, Accuracy: 0.5150\n",
      "Training loss (for one batch) at step 60: 482.1093, Accuracy: 0.5177\n",
      "Training loss (for one batch) at step 70: 482.3872, Accuracy: 0.5143\n",
      "Training loss (for one batch) at step 80: 468.0260, Accuracy: 0.5119\n",
      "Training loss (for one batch) at step 90: 461.2769, Accuracy: 0.5129\n",
      "Training loss (for one batch) at step 100: 461.7726, Accuracy: 0.5113\n",
      "Training loss (for one batch) at step 110: 464.1553, Accuracy: 0.5125\n",
      "---- Training ----\n",
      "Training loss: 144.7259\n",
      "Training acc over epoch: 0.5134\n",
      "---- Validation ----\n",
      "Validation loss: 34.8151\n",
      "Validation acc: 0.5134\n",
      "Time taken: 73.69s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 455.6971, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 453.7534, Accuracy: 0.5064\n",
      "Training loss (for one batch) at step 20: 453.7304, Accuracy: 0.5112\n",
      "Training loss (for one batch) at step 30: 449.7006, Accuracy: 0.5149\n",
      "Training loss (for one batch) at step 40: 450.3287, Accuracy: 0.5076\n",
      "Training loss (for one batch) at step 50: 452.3527, Accuracy: 0.5109\n",
      "Training loss (for one batch) at step 60: 455.4829, Accuracy: 0.5122\n",
      "Training loss (for one batch) at step 70: 447.1971, Accuracy: 0.5152\n",
      "Training loss (for one batch) at step 80: 449.4482, Accuracy: 0.5187\n",
      "Training loss (for one batch) at step 90: 449.1091, Accuracy: 0.5217\n",
      "Training loss (for one batch) at step 100: 447.2419, Accuracy: 0.5220\n",
      "Training loss (for one batch) at step 110: 448.0575, Accuracy: 0.5216\n",
      "---- Training ----\n",
      "Training loss: 140.4384\n",
      "Training acc over epoch: 0.5220\n",
      "---- Validation ----\n",
      "Validation loss: 34.2442\n",
      "Validation acc: 0.5124\n",
      "Time taken: 15.03s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.9486, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 10: 446.2013, Accuracy: 0.5199\n",
      "Training loss (for one batch) at step 20: 445.9075, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 30: 444.3066, Accuracy: 0.5348\n",
      "Training loss (for one batch) at step 40: 445.4554, Accuracy: 0.5381\n",
      "Training loss (for one batch) at step 50: 442.7244, Accuracy: 0.5392\n",
      "Training loss (for one batch) at step 60: 443.4618, Accuracy: 0.5428\n",
      "Training loss (for one batch) at step 70: 444.6294, Accuracy: 0.5470\n",
      "Training loss (for one batch) at step 80: 446.5974, Accuracy: 0.5476\n",
      "Training loss (for one batch) at step 90: 446.2294, Accuracy: 0.5449\n",
      "Training loss (for one batch) at step 100: 442.9945, Accuracy: 0.5440\n",
      "Training loss (for one batch) at step 110: 445.5647, Accuracy: 0.5418\n",
      "---- Training ----\n",
      "Training loss: 139.1073\n",
      "Training acc over epoch: 0.5422\n",
      "---- Validation ----\n",
      "Validation loss: 34.3679\n",
      "Validation acc: 0.5228\n",
      "Time taken: 10.74s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.1797, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 444.3423, Accuracy: 0.5540\n",
      "Training loss (for one batch) at step 20: 444.2467, Accuracy: 0.5696\n",
      "Training loss (for one batch) at step 30: 443.3181, Accuracy: 0.5713\n",
      "Training loss (for one batch) at step 40: 440.4026, Accuracy: 0.5692\n",
      "Training loss (for one batch) at step 50: 444.5744, Accuracy: 0.5699\n",
      "Training loss (for one batch) at step 60: 441.6972, Accuracy: 0.5722\n",
      "Training loss (for one batch) at step 70: 442.6252, Accuracy: 0.5753\n",
      "Training loss (for one batch) at step 80: 443.6958, Accuracy: 0.5795\n",
      "Training loss (for one batch) at step 90: 444.4673, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 100: 442.7642, Accuracy: 0.5764\n",
      "Training loss (for one batch) at step 110: 444.0304, Accuracy: 0.5753\n",
      "---- Training ----\n",
      "Training loss: 138.0974\n",
      "Training acc over epoch: 0.5756\n",
      "---- Validation ----\n",
      "Validation loss: 34.7399\n",
      "Validation acc: 0.6056\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 441.1714, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 443.9097, Accuracy: 0.6009\n",
      "Training loss (for one batch) at step 20: 439.9915, Accuracy: 0.6019\n",
      "Training loss (for one batch) at step 30: 440.8507, Accuracy: 0.6003\n",
      "Training loss (for one batch) at step 40: 440.7753, Accuracy: 0.6014\n",
      "Training loss (for one batch) at step 50: 440.3274, Accuracy: 0.6066\n",
      "Training loss (for one batch) at step 60: 441.8763, Accuracy: 0.6075\n",
      "Training loss (for one batch) at step 70: 442.7960, Accuracy: 0.6075\n",
      "Training loss (for one batch) at step 80: 442.6927, Accuracy: 0.6074\n",
      "Training loss (for one batch) at step 90: 441.3379, Accuracy: 0.6064\n",
      "Training loss (for one batch) at step 100: 445.2924, Accuracy: 0.6015\n",
      "Training loss (for one batch) at step 110: 441.7786, Accuracy: 0.6018\n",
      "---- Training ----\n",
      "Training loss: 137.0446\n",
      "Training acc over epoch: 0.6035\n",
      "---- Validation ----\n",
      "Validation loss: 34.2952\n",
      "Validation acc: 0.6239\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.7910, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 443.6920, Accuracy: 0.6108\n",
      "Training loss (for one batch) at step 20: 443.2376, Accuracy: 0.6179\n",
      "Training loss (for one batch) at step 30: 434.5606, Accuracy: 0.6275\n",
      "Training loss (for one batch) at step 40: 431.4146, Accuracy: 0.6303\n",
      "Training loss (for one batch) at step 50: 440.7319, Accuracy: 0.6268\n",
      "Training loss (for one batch) at step 60: 444.7281, Accuracy: 0.6303\n",
      "Training loss (for one batch) at step 70: 444.8405, Accuracy: 0.6315\n",
      "Training loss (for one batch) at step 80: 444.6549, Accuracy: 0.6307\n",
      "Training loss (for one batch) at step 90: 446.0739, Accuracy: 0.6264\n",
      "Training loss (for one batch) at step 100: 440.1132, Accuracy: 0.6231\n",
      "Training loss (for one batch) at step 110: 443.1360, Accuracy: 0.6239\n",
      "---- Training ----\n",
      "Training loss: 138.2580\n",
      "Training acc over epoch: 0.6246\n",
      "---- Validation ----\n",
      "Validation loss: 35.7198\n",
      "Validation acc: 0.6252\n",
      "Time taken: 10.79s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 444.8994, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 445.0916, Accuracy: 0.6413\n",
      "Training loss (for one batch) at step 20: 439.2439, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 30: 437.2577, Accuracy: 0.6283\n",
      "Training loss (for one batch) at step 40: 441.1274, Accuracy: 0.6317\n",
      "Training loss (for one batch) at step 50: 436.5796, Accuracy: 0.6354\n",
      "Training loss (for one batch) at step 60: 438.6437, Accuracy: 0.6391\n",
      "Training loss (for one batch) at step 70: 441.9965, Accuracy: 0.6430\n",
      "Training loss (for one batch) at step 80: 440.2295, Accuracy: 0.6399\n",
      "Training loss (for one batch) at step 90: 440.4388, Accuracy: 0.6368\n",
      "Training loss (for one batch) at step 100: 438.5900, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 110: 440.5381, Accuracy: 0.6384\n",
      "---- Training ----\n",
      "Training loss: 137.8311\n",
      "Training acc over epoch: 0.6387\n",
      "---- Validation ----\n",
      "Validation loss: 35.2983\n",
      "Validation acc: 0.6534\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 445.7458, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 442.8434, Accuracy: 0.6449\n",
      "Training loss (for one batch) at step 20: 440.4565, Accuracy: 0.6522\n",
      "Training loss (for one batch) at step 30: 442.2239, Accuracy: 0.6462\n",
      "Training loss (for one batch) at step 40: 436.0073, Accuracy: 0.6473\n",
      "Training loss (for one batch) at step 50: 431.6559, Accuracy: 0.6524\n",
      "Training loss (for one batch) at step 60: 440.5878, Accuracy: 0.6537\n",
      "Training loss (for one batch) at step 70: 441.0098, Accuracy: 0.6533\n",
      "Training loss (for one batch) at step 80: 441.6442, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 90: 441.9746, Accuracy: 0.6513\n",
      "Training loss (for one batch) at step 100: 436.3756, Accuracy: 0.6498\n",
      "Training loss (for one batch) at step 110: 438.1460, Accuracy: 0.6494\n",
      "---- Training ----\n",
      "Training loss: 142.0456\n",
      "Training acc over epoch: 0.6494\n",
      "---- Validation ----\n",
      "Validation loss: 33.3020\n",
      "Validation acc: 0.6722\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 442.5544, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 438.4077, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 20: 439.0009, Accuracy: 0.6499\n",
      "Training loss (for one batch) at step 30: 434.9772, Accuracy: 0.6537\n",
      "Training loss (for one batch) at step 40: 428.3329, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 50: 423.5443, Accuracy: 0.6656\n",
      "Training loss (for one batch) at step 60: 436.8120, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 70: 440.0259, Accuracy: 0.6713\n",
      "Training loss (for one batch) at step 80: 439.2502, Accuracy: 0.6705\n",
      "Training loss (for one batch) at step 90: 435.8616, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 100: 433.6741, Accuracy: 0.6699\n",
      "Training loss (for one batch) at step 110: 437.7340, Accuracy: 0.6716\n",
      "---- Training ----\n",
      "Training loss: 135.7064\n",
      "Training acc over epoch: 0.6717\n",
      "---- Validation ----\n",
      "Validation loss: 34.8872\n",
      "Validation acc: 0.6972\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 444.5267, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 444.7461, Accuracy: 0.6541\n",
      "Training loss (for one batch) at step 20: 439.8599, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 30: 436.5519, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 40: 432.5902, Accuracy: 0.6734\n",
      "Training loss (for one batch) at step 50: 422.9507, Accuracy: 0.6801\n",
      "Training loss (for one batch) at step 60: 438.7808, Accuracy: 0.6852\n",
      "Training loss (for one batch) at step 70: 443.0024, Accuracy: 0.6841\n",
      "Training loss (for one batch) at step 80: 441.0155, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 90: 437.7773, Accuracy: 0.6799\n",
      "Training loss (for one batch) at step 100: 434.8995, Accuracy: 0.6803\n",
      "Training loss (for one batch) at step 110: 446.1799, Accuracy: 0.6807\n",
      "---- Training ----\n",
      "Training loss: 134.3920\n",
      "Training acc over epoch: 0.6824\n",
      "---- Validation ----\n",
      "Validation loss: 35.5128\n",
      "Validation acc: 0.6443\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 442.6354, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 436.3070, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 440.5473, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 30: 431.2859, Accuracy: 0.6714\n",
      "Training loss (for one batch) at step 40: 419.2606, Accuracy: 0.6770\n",
      "Training loss (for one batch) at step 50: 428.9978, Accuracy: 0.6872\n",
      "Training loss (for one batch) at step 60: 430.2536, Accuracy: 0.6952\n",
      "Training loss (for one batch) at step 70: 441.0590, Accuracy: 0.6944\n",
      "Training loss (for one batch) at step 80: 433.2960, Accuracy: 0.6957\n",
      "Training loss (for one batch) at step 90: 437.9910, Accuracy: 0.6963\n",
      "Training loss (for one batch) at step 100: 441.3791, Accuracy: 0.6940\n",
      "Training loss (for one batch) at step 110: 442.3491, Accuracy: 0.6943\n",
      "---- Training ----\n",
      "Training loss: 136.0734\n",
      "Training acc over epoch: 0.6964\n",
      "---- Validation ----\n",
      "Validation loss: 34.9795\n",
      "Validation acc: 0.7262\n",
      "Time taken: 10.14s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 436.7264, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 442.0667, Accuracy: 0.7152\n",
      "Training loss (for one batch) at step 20: 438.2872, Accuracy: 0.7039\n",
      "Training loss (for one batch) at step 30: 423.4726, Accuracy: 0.7119\n",
      "Training loss (for one batch) at step 40: 432.1539, Accuracy: 0.7111\n",
      "Training loss (for one batch) at step 50: 421.8473, Accuracy: 0.7143\n",
      "Training loss (for one batch) at step 60: 432.3297, Accuracy: 0.7222\n",
      "Training loss (for one batch) at step 70: 437.4969, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 80: 435.9759, Accuracy: 0.7201\n",
      "Training loss (for one batch) at step 90: 432.3594, Accuracy: 0.7175\n",
      "Training loss (for one batch) at step 100: 434.3164, Accuracy: 0.7187\n",
      "Training loss (for one batch) at step 110: 430.4926, Accuracy: 0.7190\n",
      "---- Training ----\n",
      "Training loss: 141.5830\n",
      "Training acc over epoch: 0.7186\n",
      "---- Validation ----\n",
      "Validation loss: 32.4756\n",
      "Validation acc: 0.6916\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 437.5073, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 439.0718, Accuracy: 0.7237\n",
      "Training loss (for one batch) at step 20: 432.1623, Accuracy: 0.7150\n",
      "Training loss (for one batch) at step 30: 423.8784, Accuracy: 0.7200\n",
      "Training loss (for one batch) at step 40: 419.2132, Accuracy: 0.7283\n",
      "Training loss (for one batch) at step 50: 417.9699, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 60: 405.9700, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 70: 446.9718, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 80: 433.6235, Accuracy: 0.7373\n",
      "Training loss (for one batch) at step 90: 433.5423, Accuracy: 0.7319\n",
      "Training loss (for one batch) at step 100: 416.0399, Accuracy: 0.7303\n",
      "Training loss (for one batch) at step 110: 440.5426, Accuracy: 0.7319\n",
      "---- Training ----\n",
      "Training loss: 138.7988\n",
      "Training acc over epoch: 0.7327\n",
      "---- Validation ----\n",
      "Validation loss: 34.4695\n",
      "Validation acc: 0.7469\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 440.2269, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 435.1357, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 20: 432.4968, Accuracy: 0.7113\n",
      "Training loss (for one batch) at step 30: 428.4341, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 40: 416.4210, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 50: 415.9795, Accuracy: 0.7428\n",
      "Training loss (for one batch) at step 60: 442.1627, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 70: 435.4335, Accuracy: 0.7518\n",
      "Training loss (for one batch) at step 80: 437.4530, Accuracy: 0.7446\n",
      "Training loss (for one batch) at step 90: 435.7818, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 100: 428.7873, Accuracy: 0.7392\n",
      "Training loss (for one batch) at step 110: 423.3116, Accuracy: 0.7420\n",
      "---- Training ----\n",
      "Training loss: 135.6996\n",
      "Training acc over epoch: 0.7414\n",
      "---- Validation ----\n",
      "Validation loss: 34.4005\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.17s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 444.3531, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 432.4404, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 20: 432.0171, Accuracy: 0.7325\n",
      "Training loss (for one batch) at step 30: 428.1097, Accuracy: 0.7404\n",
      "Training loss (for one batch) at step 40: 419.7294, Accuracy: 0.7450\n",
      "Training loss (for one batch) at step 50: 415.9015, Accuracy: 0.7575\n",
      "Training loss (for one batch) at step 60: 409.0084, Accuracy: 0.7631\n",
      "Training loss (for one batch) at step 70: 424.9615, Accuracy: 0.7624\n",
      "Training loss (for one batch) at step 80: 435.8513, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 90: 433.4278, Accuracy: 0.7565\n",
      "Training loss (for one batch) at step 100: 418.4962, Accuracy: 0.7563\n",
      "Training loss (for one batch) at step 110: 430.9106, Accuracy: 0.7553\n",
      "---- Training ----\n",
      "Training loss: 134.9981\n",
      "Training acc over epoch: 0.7542\n",
      "---- Validation ----\n",
      "Validation loss: 38.0870\n",
      "Validation acc: 0.7211\n",
      "Time taken: 10.90s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 447.4433, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 431.2355, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 20: 430.8189, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 30: 425.6783, Accuracy: 0.7331\n",
      "Training loss (for one batch) at step 40: 406.3101, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 50: 391.4257, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 60: 422.3734, Accuracy: 0.7640\n",
      "Training loss (for one batch) at step 70: 435.6989, Accuracy: 0.7658\n",
      "Training loss (for one batch) at step 80: 438.9341, Accuracy: 0.7611\n",
      "Training loss (for one batch) at step 90: 420.5920, Accuracy: 0.7570\n",
      "Training loss (for one batch) at step 100: 412.7955, Accuracy: 0.7567\n",
      "Training loss (for one batch) at step 110: 425.1640, Accuracy: 0.7568\n",
      "---- Training ----\n",
      "Training loss: 132.3033\n",
      "Training acc over epoch: 0.7570\n",
      "---- Validation ----\n",
      "Validation loss: 37.3634\n",
      "Validation acc: 0.7563\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 436.8464, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 429.4765, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 20: 427.1349, Accuracy: 0.7641\n",
      "Training loss (for one batch) at step 30: 412.6382, Accuracy: 0.7729\n",
      "Training loss (for one batch) at step 40: 408.4457, Accuracy: 0.7792\n",
      "Training loss (for one batch) at step 50: 402.2187, Accuracy: 0.7852\n",
      "Training loss (for one batch) at step 60: 428.6535, Accuracy: 0.7942\n",
      "Training loss (for one batch) at step 70: 442.7158, Accuracy: 0.7904\n",
      "Training loss (for one batch) at step 80: 438.1671, Accuracy: 0.7799\n",
      "Training loss (for one batch) at step 90: 425.7289, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 100: 403.6406, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 110: 422.9333, Accuracy: 0.7710\n",
      "---- Training ----\n",
      "Training loss: 131.3962\n",
      "Training acc over epoch: 0.7712\n",
      "---- Validation ----\n",
      "Validation loss: 38.0624\n",
      "Validation acc: 0.7574\n",
      "Time taken: 10.18s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 433.2678, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 431.7527, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 430.0620, Accuracy: 0.7362\n",
      "Training loss (for one batch) at step 30: 413.2567, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 40: 393.8227, Accuracy: 0.7618\n",
      "Training loss (for one batch) at step 50: 384.2961, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 60: 413.6263, Accuracy: 0.7856\n",
      "Training loss (for one batch) at step 70: 427.7435, Accuracy: 0.7852\n",
      "Training loss (for one batch) at step 80: 435.6546, Accuracy: 0.7768\n",
      "Training loss (for one batch) at step 90: 417.8279, Accuracy: 0.7722\n",
      "Training loss (for one batch) at step 100: 421.3917, Accuracy: 0.7689\n",
      "Training loss (for one batch) at step 110: 423.4682, Accuracy: 0.7713\n",
      "---- Training ----\n",
      "Training loss: 131.7967\n",
      "Training acc over epoch: 0.7697\n",
      "---- Validation ----\n",
      "Validation loss: 36.3236\n",
      "Validation acc: 0.7526\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 446.4359, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 435.0901, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 413.3139, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 30: 416.6863, Accuracy: 0.7702\n",
      "Training loss (for one batch) at step 40: 394.0295, Accuracy: 0.7776\n",
      "Training loss (for one batch) at step 50: 384.6140, Accuracy: 0.7875\n",
      "Training loss (for one batch) at step 60: 400.0049, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 70: 432.2242, Accuracy: 0.7937\n",
      "Training loss (for one batch) at step 80: 428.8259, Accuracy: 0.7849\n",
      "Training loss (for one batch) at step 90: 424.3161, Accuracy: 0.7779\n",
      "Training loss (for one batch) at step 100: 415.8664, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 110: 419.9846, Accuracy: 0.7772\n",
      "---- Training ----\n",
      "Training loss: 130.0082\n",
      "Training acc over epoch: 0.7770\n",
      "---- Validation ----\n",
      "Validation loss: 32.2366\n",
      "Validation acc: 0.7601\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 431.3477, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 431.6581, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 20: 409.6848, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 30: 412.0044, Accuracy: 0.7775\n",
      "Training loss (for one batch) at step 40: 412.0078, Accuracy: 0.7885\n",
      "Training loss (for one batch) at step 50: 386.4080, Accuracy: 0.8021\n",
      "Training loss (for one batch) at step 60: 397.1062, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 70: 426.4586, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 80: 421.5849, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 90: 416.2437, Accuracy: 0.7934\n",
      "Training loss (for one batch) at step 100: 414.0921, Accuracy: 0.7919\n",
      "Training loss (for one batch) at step 110: 407.1124, Accuracy: 0.7922\n",
      "---- Training ----\n",
      "Training loss: 122.7263\n",
      "Training acc over epoch: 0.7910\n",
      "---- Validation ----\n",
      "Validation loss: 32.1812\n",
      "Validation acc: 0.7552\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 431.0035, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 419.2129, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 417.7222, Accuracy: 0.7693\n",
      "Training loss (for one batch) at step 30: 400.8904, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 40: 394.2882, Accuracy: 0.7908\n",
      "Training loss (for one batch) at step 50: 380.2609, Accuracy: 0.7995\n",
      "Training loss (for one batch) at step 60: 413.3939, Accuracy: 0.8067\n",
      "Training loss (for one batch) at step 70: 424.1009, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 80: 417.1381, Accuracy: 0.7982\n",
      "Training loss (for one batch) at step 90: 421.1615, Accuracy: 0.7907\n",
      "Training loss (for one batch) at step 100: 399.5964, Accuracy: 0.7889\n",
      "Training loss (for one batch) at step 110: 410.8577, Accuracy: 0.7877\n",
      "---- Training ----\n",
      "Training loss: 129.8664\n",
      "Training acc over epoch: 0.7878\n",
      "---- Validation ----\n",
      "Validation loss: 32.5698\n",
      "Validation acc: 0.7458\n",
      "Time taken: 12.15s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 432.4257, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 423.1692, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 20: 414.6860, Accuracy: 0.7850\n",
      "Training loss (for one batch) at step 30: 399.7823, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 40: 375.7296, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 50: 363.3503, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 60: 397.7697, Accuracy: 0.8204\n",
      "Training loss (for one batch) at step 70: 426.7071, Accuracy: 0.8156\n",
      "Training loss (for one batch) at step 80: 431.9124, Accuracy: 0.8097\n",
      "Training loss (for one batch) at step 90: 414.0995, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 100: 393.8562, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 110: 400.3429, Accuracy: 0.8014\n",
      "---- Training ----\n",
      "Training loss: 124.8633\n",
      "Training acc over epoch: 0.7999\n",
      "---- Validation ----\n",
      "Validation loss: 41.1850\n",
      "Validation acc: 0.7050\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 421.6672, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 424.4722, Accuracy: 0.7876\n",
      "Training loss (for one batch) at step 20: 419.1730, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 30: 397.1936, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 40: 397.4454, Accuracy: 0.7933\n",
      "Training loss (for one batch) at step 50: 369.4740, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 60: 384.4399, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 70: 403.5544, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 80: 407.5599, Accuracy: 0.8063\n",
      "Training loss (for one batch) at step 90: 396.7619, Accuracy: 0.8043\n",
      "Training loss (for one batch) at step 100: 391.7210, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 110: 388.0416, Accuracy: 0.8038\n",
      "---- Training ----\n",
      "Training loss: 132.0645\n",
      "Training acc over epoch: 0.8028\n",
      "---- Validation ----\n",
      "Validation loss: 30.7292\n",
      "Validation acc: 0.7080\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 432.6206, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 418.9453, Accuracy: 0.7855\n",
      "Training loss (for one batch) at step 20: 395.4051, Accuracy: 0.7850\n",
      "Training loss (for one batch) at step 30: 393.8027, Accuracy: 0.7931\n",
      "Training loss (for one batch) at step 40: 377.1448, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 50: 357.8006, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 60: 384.5199, Accuracy: 0.8211\n",
      "Training loss (for one batch) at step 70: 417.9178, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 80: 411.2398, Accuracy: 0.8092\n",
      "Training loss (for one batch) at step 90: 394.5361, Accuracy: 0.8076\n",
      "Training loss (for one batch) at step 100: 387.2570, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 110: 399.1216, Accuracy: 0.8040\n",
      "---- Training ----\n",
      "Training loss: 121.0263\n",
      "Training acc over epoch: 0.8033\n",
      "---- Validation ----\n",
      "Validation loss: 45.0392\n",
      "Validation acc: 0.7284\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 414.3554, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 421.2394, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 20: 387.2595, Accuracy: 0.7690\n",
      "Training loss (for one batch) at step 30: 377.4678, Accuracy: 0.7818\n",
      "Training loss (for one batch) at step 40: 382.4952, Accuracy: 0.7982\n",
      "Training loss (for one batch) at step 50: 358.4534, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 60: 370.4525, Accuracy: 0.8198\n",
      "Training loss (for one batch) at step 70: 393.3343, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 80: 413.8586, Accuracy: 0.8103\n",
      "Training loss (for one batch) at step 90: 380.6062, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 100: 390.8320, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 110: 374.4022, Accuracy: 0.8033\n",
      "---- Training ----\n",
      "Training loss: 131.3669\n",
      "Training acc over epoch: 0.8025\n",
      "---- Validation ----\n",
      "Validation loss: 38.7954\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 431.6486, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 408.1494, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 20: 387.6273, Accuracy: 0.7775\n",
      "Training loss (for one batch) at step 30: 379.4750, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 40: 359.3701, Accuracy: 0.8013\n",
      "Training loss (for one batch) at step 50: 361.3866, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 60: 370.5851, Accuracy: 0.8199\n",
      "Training loss (for one batch) at step 70: 412.5465, Accuracy: 0.8143\n",
      "Training loss (for one batch) at step 80: 409.5736, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 90: 378.1339, Accuracy: 0.8015\n",
      "Training loss (for one batch) at step 100: 384.7982, Accuracy: 0.8008\n",
      "Training loss (for one batch) at step 110: 395.6870, Accuracy: 0.8006\n",
      "---- Training ----\n",
      "Training loss: 119.9626\n",
      "Training acc over epoch: 0.7996\n",
      "---- Validation ----\n",
      "Validation loss: 42.0764\n",
      "Validation acc: 0.7380\n",
      "Time taken: 11.16s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 423.4359, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 407.8408, Accuracy: 0.7713\n",
      "Training loss (for one batch) at step 20: 386.8973, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 30: 380.8335, Accuracy: 0.7911\n",
      "Training loss (for one batch) at step 40: 377.0114, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 50: 342.4253, Accuracy: 0.8206\n",
      "Training loss (for one batch) at step 60: 376.9041, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 70: 398.1606, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 80: 413.4996, Accuracy: 0.8109\n",
      "Training loss (for one batch) at step 90: 385.3483, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 100: 354.2160, Accuracy: 0.8095\n",
      "Training loss (for one batch) at step 110: 380.1287, Accuracy: 0.8090\n",
      "---- Training ----\n",
      "Training loss: 114.2365\n",
      "Training acc over epoch: 0.8092\n",
      "---- Validation ----\n",
      "Validation loss: 41.6397\n",
      "Validation acc: 0.7448\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 418.1175, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 405.0642, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 20: 390.9263, Accuracy: 0.7712\n",
      "Training loss (for one batch) at step 30: 369.2945, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 40: 351.4113, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 50: 358.6129, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 60: 390.9449, Accuracy: 0.8299\n",
      "Training loss (for one batch) at step 70: 395.0846, Accuracy: 0.8249\n",
      "Training loss (for one batch) at step 80: 389.9908, Accuracy: 0.8156\n",
      "Training loss (for one batch) at step 90: 367.6411, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 100: 369.6899, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 110: 396.9735, Accuracy: 0.8131\n",
      "---- Training ----\n",
      "Training loss: 116.1350\n",
      "Training acc over epoch: 0.8119\n",
      "---- Validation ----\n",
      "Validation loss: 40.2677\n",
      "Validation acc: 0.7477\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 399.9671, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 402.2112, Accuracy: 0.7685\n",
      "Training loss (for one batch) at step 20: 374.4808, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 30: 365.9729, Accuracy: 0.8029\n",
      "Training loss (for one batch) at step 40: 362.2047, Accuracy: 0.8167\n",
      "Training loss (for one batch) at step 50: 356.0370, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 60: 369.0990, Accuracy: 0.8347\n",
      "Training loss (for one batch) at step 70: 402.0874, Accuracy: 0.8264\n",
      "Training loss (for one batch) at step 80: 413.2997, Accuracy: 0.8159\n",
      "Training loss (for one batch) at step 90: 373.4701, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 100: 379.4014, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 110: 360.8030, Accuracy: 0.8136\n",
      "---- Training ----\n",
      "Training loss: 109.8365\n",
      "Training acc over epoch: 0.8129\n",
      "---- Validation ----\n",
      "Validation loss: 40.4786\n",
      "Validation acc: 0.7378\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 398.0770, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 403.1609, Accuracy: 0.7756\n",
      "Training loss (for one batch) at step 20: 360.0464, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 30: 363.1022, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 40: 359.4528, Accuracy: 0.8155\n",
      "Training loss (for one batch) at step 50: 341.9678, Accuracy: 0.8307\n",
      "Training loss (for one batch) at step 60: 361.7031, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 70: 400.6051, Accuracy: 0.8268\n",
      "Training loss (for one batch) at step 80: 392.9745, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 90: 371.2802, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 100: 359.2035, Accuracy: 0.8124\n",
      "Training loss (for one batch) at step 110: 372.3091, Accuracy: 0.8140\n",
      "---- Training ----\n",
      "Training loss: 119.4084\n",
      "Training acc over epoch: 0.8129\n",
      "---- Validation ----\n",
      "Validation loss: 39.8340\n",
      "Validation acc: 0.7421\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 404.7970, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 397.9963, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 20: 370.7947, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 30: 346.0336, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 40: 339.0348, Accuracy: 0.8163\n",
      "Training loss (for one batch) at step 50: 323.7155, Accuracy: 0.8304\n",
      "Training loss (for one batch) at step 60: 353.3336, Accuracy: 0.8388\n",
      "Training loss (for one batch) at step 70: 386.5463, Accuracy: 0.8302\n",
      "Training loss (for one batch) at step 80: 389.8560, Accuracy: 0.8186\n",
      "Training loss (for one batch) at step 90: 365.4601, Accuracy: 0.8152\n",
      "Training loss (for one batch) at step 100: 353.1754, Accuracy: 0.8143\n",
      "Training loss (for one batch) at step 110: 376.9476, Accuracy: 0.8145\n",
      "---- Training ----\n",
      "Training loss: 108.9897\n",
      "Training acc over epoch: 0.8134\n",
      "---- Validation ----\n",
      "Validation loss: 57.0952\n",
      "Validation acc: 0.6969\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 421.9396, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 399.9809, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 365.9999, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 30: 367.9703, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 40: 341.7403, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 50: 337.1527, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 60: 360.7624, Accuracy: 0.8318\n",
      "Training loss (for one batch) at step 70: 380.9105, Accuracy: 0.8248\n",
      "Training loss (for one batch) at step 80: 387.7690, Accuracy: 0.8138\n",
      "Training loss (for one batch) at step 90: 365.4576, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 100: 359.0672, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 110: 364.0424, Accuracy: 0.8145\n",
      "---- Training ----\n",
      "Training loss: 113.2510\n",
      "Training acc over epoch: 0.8133\n",
      "---- Validation ----\n",
      "Validation loss: 44.4120\n",
      "Validation acc: 0.7265\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 405.0934, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 387.8784, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 373.9814, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 30: 348.5031, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 40: 336.2433, Accuracy: 0.8123\n",
      "Training loss (for one batch) at step 50: 326.9713, Accuracy: 0.8264\n",
      "Training loss (for one batch) at step 60: 366.8318, Accuracy: 0.8341\n",
      "Training loss (for one batch) at step 70: 368.8751, Accuracy: 0.8258\n",
      "Training loss (for one batch) at step 80: 385.8175, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 90: 376.7866, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 100: 341.7292, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 110: 357.7112, Accuracy: 0.8121\n",
      "---- Training ----\n",
      "Training loss: 128.9673\n",
      "Training acc over epoch: 0.8115\n",
      "---- Validation ----\n",
      "Validation loss: 44.2745\n",
      "Validation acc: 0.7294\n",
      "Time taken: 10.98s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 400.0998, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 377.8603, Accuracy: 0.7464\n",
      "Training loss (for one batch) at step 20: 354.8274, Accuracy: 0.7738\n",
      "Training loss (for one batch) at step 30: 336.7032, Accuracy: 0.7911\n",
      "Training loss (for one batch) at step 40: 330.2842, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 50: 322.1280, Accuracy: 0.8234\n",
      "Training loss (for one batch) at step 60: 338.5043, Accuracy: 0.8320\n",
      "Training loss (for one batch) at step 70: 375.3249, Accuracy: 0.8253\n",
      "Training loss (for one batch) at step 80: 392.5148, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 90: 331.0236, Accuracy: 0.8098\n",
      "Training loss (for one batch) at step 100: 358.6864, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 110: 365.3502, Accuracy: 0.8125\n",
      "---- Training ----\n",
      "Training loss: 122.0249\n",
      "Training acc over epoch: 0.8125\n",
      "---- Validation ----\n",
      "Validation loss: 48.3912\n",
      "Validation acc: 0.7227\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 388.6740, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 374.5245, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 349.7747, Accuracy: 0.7716\n",
      "Training loss (for one batch) at step 30: 341.3897, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 40: 332.0256, Accuracy: 0.8117\n",
      "Training loss (for one batch) at step 50: 322.8321, Accuracy: 0.8275\n",
      "Training loss (for one batch) at step 60: 346.7081, Accuracy: 0.8308\n",
      "Training loss (for one batch) at step 70: 365.9504, Accuracy: 0.8228\n",
      "Training loss (for one batch) at step 80: 396.2658, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 90: 357.1461, Accuracy: 0.8071\n",
      "Training loss (for one batch) at step 100: 351.8724, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 110: 345.5074, Accuracy: 0.8093\n",
      "---- Training ----\n",
      "Training loss: 113.3128\n",
      "Training acc over epoch: 0.8081\n",
      "---- Validation ----\n",
      "Validation loss: 48.2008\n",
      "Validation acc: 0.7327\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 402.6847, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 389.5172, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 343.9436, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 30: 360.7637, Accuracy: 0.8029\n",
      "Training loss (for one batch) at step 40: 371.5977, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 50: 315.0287, Accuracy: 0.8318\n",
      "Training loss (for one batch) at step 60: 354.0663, Accuracy: 0.8389\n",
      "Training loss (for one batch) at step 70: 374.1235, Accuracy: 0.8303\n",
      "Training loss (for one batch) at step 80: 389.9144, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 90: 351.3122, Accuracy: 0.8123\n",
      "Training loss (for one batch) at step 100: 353.3200, Accuracy: 0.8141\n",
      "Training loss (for one batch) at step 110: 366.8162, Accuracy: 0.8148\n",
      "---- Training ----\n",
      "Training loss: 115.5866\n",
      "Training acc over epoch: 0.8142\n",
      "---- Validation ----\n",
      "Validation loss: 46.1343\n",
      "Validation acc: 0.7335\n",
      "Time taken: 11.57s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 375.0192, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 372.2033, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 20: 351.7778, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 30: 344.0050, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 40: 330.9124, Accuracy: 0.8150\n",
      "Training loss (for one batch) at step 50: 326.6898, Accuracy: 0.8295\n",
      "Training loss (for one batch) at step 60: 351.3549, Accuracy: 0.8352\n",
      "Training loss (for one batch) at step 70: 386.6364, Accuracy: 0.8245\n",
      "Training loss (for one batch) at step 80: 377.3324, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 90: 347.4262, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 100: 331.9731, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 110: 356.5064, Accuracy: 0.8092\n",
      "---- Training ----\n",
      "Training loss: 130.0003\n",
      "Training acc over epoch: 0.8098\n",
      "---- Validation ----\n",
      "Validation loss: 36.2122\n",
      "Validation acc: 0.7340\n",
      "Time taken: 11.32s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 381.6008, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 383.8405, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 20: 323.8705, Accuracy: 0.7783\n",
      "Training loss (for one batch) at step 30: 326.0197, Accuracy: 0.8009\n",
      "Training loss (for one batch) at step 40: 328.6798, Accuracy: 0.8190\n",
      "Training loss (for one batch) at step 50: 312.2281, Accuracy: 0.8323\n",
      "Training loss (for one batch) at step 60: 320.2064, Accuracy: 0.8391\n",
      "Training loss (for one batch) at step 70: 363.6364, Accuracy: 0.8265\n",
      "Training loss (for one batch) at step 80: 375.0113, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 90: 349.2451, Accuracy: 0.8086\n",
      "Training loss (for one batch) at step 100: 322.2361, Accuracy: 0.8097\n",
      "Training loss (for one batch) at step 110: 349.4431, Accuracy: 0.8112\n",
      "---- Training ----\n",
      "Training loss: 117.4357\n",
      "Training acc over epoch: 0.8113\n",
      "---- Validation ----\n",
      "Validation loss: 42.4866\n",
      "Validation acc: 0.7370\n",
      "Time taken: 12.06s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 377.0153, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 361.3487, Accuracy: 0.7429\n",
      "Training loss (for one batch) at step 20: 341.4603, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 30: 316.3850, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 40: 318.3680, Accuracy: 0.8207\n",
      "Training loss (for one batch) at step 50: 325.2240, Accuracy: 0.8344\n",
      "Training loss (for one batch) at step 60: 343.0312, Accuracy: 0.8393\n",
      "Training loss (for one batch) at step 70: 337.3211, Accuracy: 0.8307\n",
      "Training loss (for one batch) at step 80: 357.0603, Accuracy: 0.8141\n",
      "Training loss (for one batch) at step 90: 352.3965, Accuracy: 0.8119\n",
      "Training loss (for one batch) at step 100: 333.0259, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 110: 339.1237, Accuracy: 0.8142\n",
      "---- Training ----\n",
      "Training loss: 116.6913\n",
      "Training acc over epoch: 0.8139\n",
      "---- Validation ----\n",
      "Validation loss: 30.9192\n",
      "Validation acc: 0.7176\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 382.8212, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 383.9166, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 20: 320.6210, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 30: 333.5728, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 40: 319.1996, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 50: 335.1447, Accuracy: 0.8347\n",
      "Training loss (for one batch) at step 60: 352.3471, Accuracy: 0.8402\n",
      "Training loss (for one batch) at step 70: 362.4205, Accuracy: 0.8313\n",
      "Training loss (for one batch) at step 80: 363.4453, Accuracy: 0.8171\n",
      "Training loss (for one batch) at step 90: 342.7716, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 100: 331.2252, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 110: 343.7407, Accuracy: 0.8162\n",
      "---- Training ----\n",
      "Training loss: 124.3153\n",
      "Training acc over epoch: 0.8154\n",
      "---- Validation ----\n",
      "Validation loss: 38.0356\n",
      "Validation acc: 0.7364\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 373.3754, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 376.7280, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 341.7968, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 335.3956, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 40: 330.6125, Accuracy: 0.8173\n",
      "Training loss (for one batch) at step 50: 300.5636, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 60: 348.8853, Accuracy: 0.8370\n",
      "Training loss (for one batch) at step 70: 356.0826, Accuracy: 0.8270\n",
      "Training loss (for one batch) at step 80: 347.1208, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 90: 309.6677, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 100: 333.9507, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 110: 337.2434, Accuracy: 0.8116\n",
      "---- Training ----\n",
      "Training loss: 108.6234\n",
      "Training acc over epoch: 0.8113\n",
      "---- Validation ----\n",
      "Validation loss: 38.5636\n",
      "Validation acc: 0.7370\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 384.5266, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 351.1156, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 337.2149, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 30: 320.5253, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 40: 328.7807, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 50: 310.0468, Accuracy: 0.8320\n",
      "Training loss (for one batch) at step 60: 320.5633, Accuracy: 0.8368\n",
      "Training loss (for one batch) at step 70: 354.0744, Accuracy: 0.8269\n",
      "Training loss (for one batch) at step 80: 362.5382, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 90: 333.1159, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 100: 315.8445, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 110: 355.2294, Accuracy: 0.8146\n",
      "---- Training ----\n",
      "Training loss: 108.9466\n",
      "Training acc over epoch: 0.8129\n",
      "---- Validation ----\n",
      "Validation loss: 65.5082\n",
      "Validation acc: 0.7337\n",
      "Time taken: 15.15s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 369.9716, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 369.6916, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 20: 318.4526, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 327.0975, Accuracy: 0.7981\n",
      "Training loss (for one batch) at step 40: 315.7213, Accuracy: 0.8215\n",
      "Training loss (for one batch) at step 50: 310.1476, Accuracy: 0.8366\n",
      "Training loss (for one batch) at step 60: 340.2835, Accuracy: 0.8423\n",
      "Training loss (for one batch) at step 70: 343.4081, Accuracy: 0.8275\n",
      "Training loss (for one batch) at step 80: 356.4190, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 90: 315.5521, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 100: 329.8589, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 110: 338.6930, Accuracy: 0.8152\n",
      "---- Training ----\n",
      "Training loss: 112.2254\n",
      "Training acc over epoch: 0.8150\n",
      "---- Validation ----\n",
      "Validation loss: 39.0890\n",
      "Validation acc: 0.7375\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 381.3257, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 355.1526, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 20: 315.9670, Accuracy: 0.7775\n",
      "Training loss (for one batch) at step 30: 314.8356, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 40: 299.3572, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 50: 301.8143, Accuracy: 0.8384\n",
      "Training loss (for one batch) at step 60: 341.6252, Accuracy: 0.8434\n",
      "Training loss (for one batch) at step 70: 358.6666, Accuracy: 0.8346\n",
      "Training loss (for one batch) at step 80: 370.4304, Accuracy: 0.8198\n",
      "Training loss (for one batch) at step 90: 317.1889, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 100: 317.5600, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 110: 339.3345, Accuracy: 0.8162\n",
      "---- Training ----\n",
      "Training loss: 99.0621\n",
      "Training acc over epoch: 0.8166\n",
      "---- Validation ----\n",
      "Validation loss: 39.8037\n",
      "Validation acc: 0.7405\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 374.5787, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 360.6949, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 309.1787, Accuracy: 0.7816\n",
      "Training loss (for one batch) at step 30: 319.5771, Accuracy: 0.8039\n",
      "Training loss (for one batch) at step 40: 318.1360, Accuracy: 0.8218\n",
      "Training loss (for one batch) at step 50: 294.7188, Accuracy: 0.8344\n",
      "Training loss (for one batch) at step 60: 332.0312, Accuracy: 0.8418\n",
      "Training loss (for one batch) at step 70: 350.7353, Accuracy: 0.8312\n",
      "Training loss (for one batch) at step 80: 347.4991, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 90: 324.1878, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 100: 303.9651, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 110: 328.6823, Accuracy: 0.8183\n",
      "---- Training ----\n",
      "Training loss: 110.6830\n",
      "Training acc over epoch: 0.8170\n",
      "---- Validation ----\n",
      "Validation loss: 45.8507\n",
      "Validation acc: 0.7458\n",
      "Time taken: 11.17s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 374.4427, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 374.2968, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 20: 332.4207, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 30: 314.8606, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 40: 306.1833, Accuracy: 0.8218\n",
      "Training loss (for one batch) at step 50: 309.0522, Accuracy: 0.8324\n",
      "Training loss (for one batch) at step 60: 305.7902, Accuracy: 0.8405\n",
      "Training loss (for one batch) at step 70: 354.7242, Accuracy: 0.8291\n",
      "Training loss (for one batch) at step 80: 354.8896, Accuracy: 0.8183\n",
      "Training loss (for one batch) at step 90: 331.0597, Accuracy: 0.8145\n",
      "Training loss (for one batch) at step 100: 325.1383, Accuracy: 0.8163\n",
      "Training loss (for one batch) at step 110: 328.3283, Accuracy: 0.8176\n",
      "---- Training ----\n",
      "Training loss: 108.7908\n",
      "Training acc over epoch: 0.8162\n",
      "---- Validation ----\n",
      "Validation loss: 55.1953\n",
      "Validation acc: 0.7491\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 366.6025, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 344.9116, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 20: 324.9994, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 330.4134, Accuracy: 0.7986\n",
      "Training loss (for one batch) at step 40: 313.8492, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 50: 312.2719, Accuracy: 0.8330\n",
      "Training loss (for one batch) at step 60: 325.1234, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 70: 355.5282, Accuracy: 0.8282\n",
      "Training loss (for one batch) at step 80: 370.9941, Accuracy: 0.8155\n",
      "Training loss (for one batch) at step 90: 310.7565, Accuracy: 0.8126\n",
      "Training loss (for one batch) at step 100: 305.9290, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 110: 354.6584, Accuracy: 0.8169\n",
      "---- Training ----\n",
      "Training loss: 111.9794\n",
      "Training acc over epoch: 0.8162\n",
      "---- Validation ----\n",
      "Validation loss: 33.1949\n",
      "Validation acc: 0.7362\n",
      "Time taken: 10.84s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 370.0065, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 364.4439, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 20: 320.4346, Accuracy: 0.7757\n",
      "Training loss (for one batch) at step 30: 308.9016, Accuracy: 0.8052\n",
      "Training loss (for one batch) at step 40: 316.4135, Accuracy: 0.8207\n",
      "Training loss (for one batch) at step 50: 297.2314, Accuracy: 0.8358\n",
      "Training loss (for one batch) at step 60: 310.6468, Accuracy: 0.8405\n",
      "Training loss (for one batch) at step 70: 354.2174, Accuracy: 0.8309\n",
      "Training loss (for one batch) at step 80: 359.4746, Accuracy: 0.8196\n",
      "Training loss (for one batch) at step 90: 323.9006, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 100: 302.9385, Accuracy: 0.8185\n",
      "Training loss (for one batch) at step 110: 347.6977, Accuracy: 0.8174\n",
      "---- Training ----\n",
      "Training loss: 94.9708\n",
      "Training acc over epoch: 0.8162\n",
      "---- Validation ----\n",
      "Validation loss: 45.6006\n",
      "Validation acc: 0.7311\n",
      "Time taken: 12.61s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 358.2950, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 367.4904, Accuracy: 0.7365\n",
      "Training loss (for one batch) at step 20: 331.4705, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 311.8570, Accuracy: 0.7966\n",
      "Training loss (for one batch) at step 40: 310.0619, Accuracy: 0.8197\n",
      "Training loss (for one batch) at step 50: 303.2054, Accuracy: 0.8335\n",
      "Training loss (for one batch) at step 60: 322.6523, Accuracy: 0.8405\n",
      "Training loss (for one batch) at step 70: 359.2196, Accuracy: 0.8293\n",
      "Training loss (for one batch) at step 80: 369.4108, Accuracy: 0.8152\n",
      "Training loss (for one batch) at step 90: 323.5508, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 100: 315.5982, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 110: 336.4255, Accuracy: 0.8152\n",
      "---- Training ----\n",
      "Training loss: 104.9063\n",
      "Training acc over epoch: 0.8149\n",
      "---- Validation ----\n",
      "Validation loss: 52.3055\n",
      "Validation acc: 0.7407\n",
      "Time taken: 11.28s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 364.4401, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 334.1479, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 20: 326.5085, Accuracy: 0.7697\n",
      "Training loss (for one batch) at step 30: 303.4355, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 40: 299.5107, Accuracy: 0.8211\n",
      "Training loss (for one batch) at step 50: 288.1929, Accuracy: 0.8373\n",
      "Training loss (for one batch) at step 60: 314.5602, Accuracy: 0.8414\n",
      "Training loss (for one batch) at step 70: 334.0199, Accuracy: 0.8297\n",
      "Training loss (for one batch) at step 80: 347.4319, Accuracy: 0.8173\n",
      "Training loss (for one batch) at step 90: 349.5535, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 100: 322.0001, Accuracy: 0.8174\n",
      "Training loss (for one batch) at step 110: 345.6832, Accuracy: 0.8184\n",
      "---- Training ----\n",
      "Training loss: 102.4324\n",
      "Training acc over epoch: 0.8172\n",
      "---- Validation ----\n",
      "Validation loss: 42.2532\n",
      "Validation acc: 0.7257\n",
      "Time taken: 10.73s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7350\n",
      "Validation AUC: 0.7349\n",
      "Validation Balanced_ACC: 0.4704\n",
      "Validation AUCSK: 0.8097\n",
      "Validation MI: 0.1180\n",
      "Validation Normalized MI: 0.1713\n",
      "Validation Adjusted MI: 0.1713\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 653.4407, Accuracy: 0.4609\n",
      "Training loss (for one batch) at step 10: 556.9301, Accuracy: 0.5043\n",
      "Training loss (for one batch) at step 20: 551.3837, Accuracy: 0.4914\n",
      "Training loss (for one batch) at step 30: 503.0959, Accuracy: 0.4927\n",
      "Training loss (for one batch) at step 40: 532.8497, Accuracy: 0.4970\n",
      "Training loss (for one batch) at step 50: 500.8148, Accuracy: 0.4972\n",
      "Training loss (for one batch) at step 60: 475.1050, Accuracy: 0.5024\n",
      "Training loss (for one batch) at step 70: 484.6721, Accuracy: 0.5054\n",
      "Training loss (for one batch) at step 80: 471.0672, Accuracy: 0.5080\n",
      "Training loss (for one batch) at step 90: 469.2424, Accuracy: 0.5111\n",
      "Training loss (for one batch) at step 100: 459.8274, Accuracy: 0.5104\n",
      "Training loss (for one batch) at step 110: 462.5811, Accuracy: 0.5113\n",
      "---- Training ----\n",
      "Training loss: 144.4550\n",
      "Training acc over epoch: 0.5105\n",
      "---- Validation ----\n",
      "Validation loss: 34.4707\n",
      "Validation acc: 0.4866\n",
      "Time taken: 20.06s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 460.4908, Accuracy: 0.4531\n",
      "Training loss (for one batch) at step 10: 453.8605, Accuracy: 0.5277\n",
      "Training loss (for one batch) at step 20: 462.1343, Accuracy: 0.5365\n",
      "Training loss (for one batch) at step 30: 455.6976, Accuracy: 0.5310\n",
      "Training loss (for one batch) at step 40: 448.0177, Accuracy: 0.5293\n",
      "Training loss (for one batch) at step 50: 441.6479, Accuracy: 0.5247\n",
      "Training loss (for one batch) at step 60: 449.7327, Accuracy: 0.5273\n",
      "Training loss (for one batch) at step 70: 445.8479, Accuracy: 0.5272\n",
      "Training loss (for one batch) at step 80: 446.7530, Accuracy: 0.5303\n",
      "Training loss (for one batch) at step 90: 446.3523, Accuracy: 0.5335\n",
      "Training loss (for one batch) at step 100: 450.6153, Accuracy: 0.5307\n",
      "Training loss (for one batch) at step 110: 448.1232, Accuracy: 0.5310\n",
      "---- Training ----\n",
      "Training loss: 138.4764\n",
      "Training acc over epoch: 0.5315\n",
      "---- Validation ----\n",
      "Validation loss: 34.6330\n",
      "Validation acc: 0.5126\n",
      "Time taken: 11.01s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 443.4902, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 443.3960, Accuracy: 0.5511\n",
      "Training loss (for one batch) at step 20: 445.2468, Accuracy: 0.5588\n",
      "Training loss (for one batch) at step 30: 445.1036, Accuracy: 0.5542\n",
      "Training loss (for one batch) at step 40: 447.7486, Accuracy: 0.5490\n",
      "Training loss (for one batch) at step 50: 448.2050, Accuracy: 0.5536\n",
      "Training loss (for one batch) at step 60: 445.8015, Accuracy: 0.5556\n",
      "Training loss (for one batch) at step 70: 443.1505, Accuracy: 0.5555\n",
      "Training loss (for one batch) at step 80: 443.4323, Accuracy: 0.5559\n",
      "Training loss (for one batch) at step 90: 443.2511, Accuracy: 0.5569\n",
      "Training loss (for one batch) at step 100: 444.0344, Accuracy: 0.5573\n",
      "Training loss (for one batch) at step 110: 445.4691, Accuracy: 0.5562\n",
      "---- Training ----\n",
      "Training loss: 138.6376\n",
      "Training acc over epoch: 0.5546\n",
      "---- Validation ----\n",
      "Validation loss: 34.7013\n",
      "Validation acc: 0.5188\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 445.5915, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 441.7234, Accuracy: 0.5923\n",
      "Training loss (for one batch) at step 20: 442.2917, Accuracy: 0.5852\n",
      "Training loss (for one batch) at step 30: 446.8828, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 40: 442.5693, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 50: 441.8781, Accuracy: 0.5789\n",
      "Training loss (for one batch) at step 60: 444.0934, Accuracy: 0.5806\n",
      "Training loss (for one batch) at step 70: 445.8877, Accuracy: 0.5787\n",
      "Training loss (for one batch) at step 80: 441.6913, Accuracy: 0.5782\n",
      "Training loss (for one batch) at step 90: 444.8995, Accuracy: 0.5791\n",
      "Training loss (for one batch) at step 100: 442.5641, Accuracy: 0.5795\n",
      "Training loss (for one batch) at step 110: 441.2797, Accuracy: 0.5814\n",
      "---- Training ----\n",
      "Training loss: 138.2363\n",
      "Training acc over epoch: 0.5797\n",
      "---- Validation ----\n",
      "Validation loss: 34.7049\n",
      "Validation acc: 0.5862\n",
      "Time taken: 10.12s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 442.6628, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 445.4346, Accuracy: 0.5973\n",
      "Training loss (for one batch) at step 20: 440.9587, Accuracy: 0.6079\n",
      "Training loss (for one batch) at step 30: 442.3163, Accuracy: 0.6056\n",
      "Training loss (for one batch) at step 40: 446.1125, Accuracy: 0.6042\n",
      "Training loss (for one batch) at step 50: 440.5222, Accuracy: 0.6086\n",
      "Training loss (for one batch) at step 60: 442.3417, Accuracy: 0.6073\n",
      "Training loss (for one batch) at step 70: 443.1985, Accuracy: 0.6074\n",
      "Training loss (for one batch) at step 80: 441.8867, Accuracy: 0.6053\n",
      "Training loss (for one batch) at step 90: 441.3530, Accuracy: 0.6053\n",
      "Training loss (for one batch) at step 100: 439.9900, Accuracy: 0.6069\n",
      "Training loss (for one batch) at step 110: 441.3580, Accuracy: 0.6086\n",
      "---- Training ----\n",
      "Training loss: 135.9982\n",
      "Training acc over epoch: 0.6086\n",
      "---- Validation ----\n",
      "Validation loss: 34.3507\n",
      "Validation acc: 0.6265\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.1059, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 444.3657, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 20: 439.4912, Accuracy: 0.6194\n",
      "Training loss (for one batch) at step 30: 440.7642, Accuracy: 0.6184\n",
      "Training loss (for one batch) at step 40: 441.2278, Accuracy: 0.6174\n",
      "Training loss (for one batch) at step 50: 440.7635, Accuracy: 0.6201\n",
      "Training loss (for one batch) at step 60: 438.8329, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 70: 440.1149, Accuracy: 0.6323\n",
      "Training loss (for one batch) at step 80: 441.6336, Accuracy: 0.6317\n",
      "Training loss (for one batch) at step 90: 440.7620, Accuracy: 0.6314\n",
      "Training loss (for one batch) at step 100: 443.1714, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 110: 442.6190, Accuracy: 0.6315\n",
      "---- Training ----\n",
      "Training loss: 136.5306\n",
      "Training acc over epoch: 0.6308\n",
      "---- Validation ----\n",
      "Validation loss: 34.4906\n",
      "Validation acc: 0.6051\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 442.0530, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 438.2094, Accuracy: 0.6399\n",
      "Training loss (for one batch) at step 20: 437.0696, Accuracy: 0.6272\n",
      "Training loss (for one batch) at step 30: 436.6738, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 40: 439.5483, Accuracy: 0.6260\n",
      "Training loss (for one batch) at step 50: 438.7569, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 60: 441.3570, Accuracy: 0.6341\n",
      "Training loss (for one batch) at step 70: 440.7305, Accuracy: 0.6373\n",
      "Training loss (for one batch) at step 80: 437.4902, Accuracy: 0.6376\n",
      "Training loss (for one batch) at step 90: 440.0113, Accuracy: 0.6408\n",
      "Training loss (for one batch) at step 100: 436.5880, Accuracy: 0.6412\n",
      "Training loss (for one batch) at step 110: 443.3099, Accuracy: 0.6422\n",
      "---- Training ----\n",
      "Training loss: 138.7723\n",
      "Training acc over epoch: 0.6426\n",
      "---- Validation ----\n",
      "Validation loss: 33.1393\n",
      "Validation acc: 0.6190\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.7801, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 440.9547, Accuracy: 0.6442\n",
      "Training loss (for one batch) at step 20: 437.4231, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 30: 435.7549, Accuracy: 0.6489\n",
      "Training loss (for one batch) at step 40: 435.4940, Accuracy: 0.6503\n",
      "Training loss (for one batch) at step 50: 438.1079, Accuracy: 0.6544\n",
      "Training loss (for one batch) at step 60: 434.7001, Accuracy: 0.6578\n",
      "Training loss (for one batch) at step 70: 447.0975, Accuracy: 0.6587\n",
      "Training loss (for one batch) at step 80: 438.1487, Accuracy: 0.6576\n",
      "Training loss (for one batch) at step 90: 436.7346, Accuracy: 0.6546\n",
      "Training loss (for one batch) at step 100: 440.7691, Accuracy: 0.6535\n",
      "Training loss (for one batch) at step 110: 431.7769, Accuracy: 0.6551\n",
      "---- Training ----\n",
      "Training loss: 137.7402\n",
      "Training acc over epoch: 0.6561\n",
      "---- Validation ----\n",
      "Validation loss: 33.6617\n",
      "Validation acc: 0.5758\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 437.6548, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 439.9036, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 20: 437.4730, Accuracy: 0.6629\n",
      "Training loss (for one batch) at step 30: 434.4510, Accuracy: 0.6638\n",
      "Training loss (for one batch) at step 40: 432.3378, Accuracy: 0.6711\n",
      "Training loss (for one batch) at step 50: 439.3911, Accuracy: 0.6720\n",
      "Training loss (for one batch) at step 60: 435.3417, Accuracy: 0.6771\n",
      "Training loss (for one batch) at step 70: 441.8771, Accuracy: 0.6835\n",
      "Training loss (for one batch) at step 80: 437.9470, Accuracy: 0.6798\n",
      "Training loss (for one batch) at step 90: 435.1834, Accuracy: 0.6769\n",
      "Training loss (for one batch) at step 100: 435.0112, Accuracy: 0.6765\n",
      "Training loss (for one batch) at step 110: 434.9536, Accuracy: 0.6788\n",
      "---- Training ----\n",
      "Training loss: 132.4498\n",
      "Training acc over epoch: 0.6789\n",
      "---- Validation ----\n",
      "Validation loss: 34.0843\n",
      "Validation acc: 0.6749\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 435.8784, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 435.4942, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 20: 436.1599, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 30: 429.5994, Accuracy: 0.6809\n",
      "Training loss (for one batch) at step 40: 432.5051, Accuracy: 0.6827\n",
      "Training loss (for one batch) at step 50: 428.3646, Accuracy: 0.6883\n",
      "Training loss (for one batch) at step 60: 441.0371, Accuracy: 0.6931\n",
      "Training loss (for one batch) at step 70: 442.4235, Accuracy: 0.6930\n",
      "Training loss (for one batch) at step 80: 436.8506, Accuracy: 0.6911\n",
      "Training loss (for one batch) at step 90: 433.3445, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 100: 434.6045, Accuracy: 0.6859\n",
      "Training loss (for one batch) at step 110: 432.0416, Accuracy: 0.6874\n",
      "---- Training ----\n",
      "Training loss: 133.4623\n",
      "Training acc over epoch: 0.6885\n",
      "---- Validation ----\n",
      "Validation loss: 34.4787\n",
      "Validation acc: 0.6198\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 438.4655, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 436.3891, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 20: 434.1224, Accuracy: 0.6912\n",
      "Training loss (for one batch) at step 30: 429.9857, Accuracy: 0.6905\n",
      "Training loss (for one batch) at step 40: 427.5669, Accuracy: 0.6980\n",
      "Training loss (for one batch) at step 50: 430.0610, Accuracy: 0.7045\n",
      "Training loss (for one batch) at step 60: 437.1844, Accuracy: 0.7090\n",
      "Training loss (for one batch) at step 70: 438.8839, Accuracy: 0.7103\n",
      "Training loss (for one batch) at step 80: 437.2300, Accuracy: 0.7070\n",
      "Training loss (for one batch) at step 90: 441.2524, Accuracy: 0.7043\n",
      "Training loss (for one batch) at step 100: 431.7303, Accuracy: 0.7058\n",
      "Training loss (for one batch) at step 110: 433.8137, Accuracy: 0.7088\n",
      "---- Training ----\n",
      "Training loss: 133.2340\n",
      "Training acc over epoch: 0.7086\n",
      "---- Validation ----\n",
      "Validation loss: 34.9378\n",
      "Validation acc: 0.7058\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 437.6443, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 432.3834, Accuracy: 0.7045\n",
      "Training loss (for one batch) at step 20: 431.9188, Accuracy: 0.7061\n",
      "Training loss (for one batch) at step 30: 429.3012, Accuracy: 0.7097\n",
      "Training loss (for one batch) at step 40: 429.8983, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 50: 433.5286, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 60: 432.3772, Accuracy: 0.7246\n",
      "Training loss (for one batch) at step 70: 441.3904, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 80: 435.7271, Accuracy: 0.7198\n",
      "Training loss (for one batch) at step 90: 431.3857, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 100: 426.8021, Accuracy: 0.7179\n",
      "Training loss (for one batch) at step 110: 432.0781, Accuracy: 0.7187\n",
      "---- Training ----\n",
      "Training loss: 132.1250\n",
      "Training acc over epoch: 0.7199\n",
      "---- Validation ----\n",
      "Validation loss: 33.5189\n",
      "Validation acc: 0.7157\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 436.1882, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 428.7617, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 20: 425.4599, Accuracy: 0.7247\n",
      "Training loss (for one batch) at step 30: 434.8837, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 40: 418.0031, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 50: 421.6420, Accuracy: 0.7408\n",
      "Training loss (for one batch) at step 60: 431.3792, Accuracy: 0.7426\n",
      "Training loss (for one batch) at step 70: 432.1966, Accuracy: 0.7437\n",
      "Training loss (for one batch) at step 80: 435.8387, Accuracy: 0.7401\n",
      "Training loss (for one batch) at step 90: 427.7070, Accuracy: 0.7370\n",
      "Training loss (for one batch) at step 100: 435.6767, Accuracy: 0.7338\n",
      "Training loss (for one batch) at step 110: 427.3067, Accuracy: 0.7340\n",
      "---- Training ----\n",
      "Training loss: 137.0659\n",
      "Training acc over epoch: 0.7340\n",
      "---- Validation ----\n",
      "Validation loss: 34.8374\n",
      "Validation acc: 0.7308\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 438.5333, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 433.7021, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 432.4207, Accuracy: 0.7336\n",
      "Training loss (for one batch) at step 30: 424.5097, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 40: 420.0706, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 50: 420.7704, Accuracy: 0.7529\n",
      "Training loss (for one batch) at step 60: 422.1877, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 70: 435.0071, Accuracy: 0.7514\n",
      "Training loss (for one batch) at step 80: 430.8454, Accuracy: 0.7474\n",
      "Training loss (for one batch) at step 90: 427.1375, Accuracy: 0.7454\n",
      "Training loss (for one batch) at step 100: 426.7101, Accuracy: 0.7418\n",
      "Training loss (for one batch) at step 110: 425.6611, Accuracy: 0.7405\n",
      "---- Training ----\n",
      "Training loss: 134.0248\n",
      "Training acc over epoch: 0.7421\n",
      "---- Validation ----\n",
      "Validation loss: 34.1513\n",
      "Validation acc: 0.7399\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 440.8873, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 435.2468, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 20: 420.5261, Accuracy: 0.7303\n",
      "Training loss (for one batch) at step 30: 420.3870, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 40: 413.8244, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 50: 414.6643, Accuracy: 0.7544\n",
      "Training loss (for one batch) at step 60: 425.5816, Accuracy: 0.7583\n",
      "Training loss (for one batch) at step 70: 441.4536, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 80: 427.7406, Accuracy: 0.7581\n",
      "Training loss (for one batch) at step 90: 421.4609, Accuracy: 0.7558\n",
      "Training loss (for one batch) at step 100: 418.5648, Accuracy: 0.7552\n",
      "Training loss (for one batch) at step 110: 427.6574, Accuracy: 0.7560\n",
      "---- Training ----\n",
      "Training loss: 130.8518\n",
      "Training acc over epoch: 0.7560\n",
      "---- Validation ----\n",
      "Validation loss: 37.9137\n",
      "Validation acc: 0.7703\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 425.7562, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 432.9608, Accuracy: 0.7756\n",
      "Training loss (for one batch) at step 20: 424.3031, Accuracy: 0.7567\n",
      "Training loss (for one batch) at step 30: 422.8979, Accuracy: 0.7623\n",
      "Training loss (for one batch) at step 40: 413.1541, Accuracy: 0.7666\n",
      "Training loss (for one batch) at step 50: 413.7883, Accuracy: 0.7721\n",
      "Training loss (for one batch) at step 60: 418.1925, Accuracy: 0.7770\n",
      "Training loss (for one batch) at step 70: 428.5164, Accuracy: 0.7741\n",
      "Training loss (for one batch) at step 80: 431.5605, Accuracy: 0.7677\n",
      "Training loss (for one batch) at step 90: 425.3812, Accuracy: 0.7651\n",
      "Training loss (for one batch) at step 100: 422.1410, Accuracy: 0.7639\n",
      "Training loss (for one batch) at step 110: 428.6710, Accuracy: 0.7652\n",
      "---- Training ----\n",
      "Training loss: 131.3038\n",
      "Training acc over epoch: 0.7652\n",
      "---- Validation ----\n",
      "Validation loss: 35.1497\n",
      "Validation acc: 0.7238\n",
      "Time taken: 11.25s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 430.5035, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 425.7309, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 20: 430.2661, Accuracy: 0.7664\n",
      "Training loss (for one batch) at step 30: 406.7043, Accuracy: 0.7737\n",
      "Training loss (for one batch) at step 40: 416.2298, Accuracy: 0.7797\n",
      "Training loss (for one batch) at step 50: 408.1762, Accuracy: 0.7877\n",
      "Training loss (for one batch) at step 60: 425.4728, Accuracy: 0.7905\n",
      "Training loss (for one batch) at step 70: 430.6818, Accuracy: 0.7890\n",
      "Training loss (for one batch) at step 80: 426.8672, Accuracy: 0.7846\n",
      "Training loss (for one batch) at step 90: 433.0978, Accuracy: 0.7823\n",
      "Training loss (for one batch) at step 100: 419.0894, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 110: 428.4215, Accuracy: 0.7797\n",
      "---- Training ----\n",
      "Training loss: 135.0954\n",
      "Training acc over epoch: 0.7802\n",
      "---- Validation ----\n",
      "Validation loss: 33.5743\n",
      "Validation acc: 0.7786\n",
      "Time taken: 11.50s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 435.8161, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 434.0654, Accuracy: 0.7827\n",
      "Training loss (for one batch) at step 20: 421.9327, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 30: 410.2409, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 40: 407.5270, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 50: 414.1584, Accuracy: 0.8025\n",
      "Training loss (for one batch) at step 60: 422.6426, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 70: 427.4587, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 80: 437.9081, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 90: 433.1164, Accuracy: 0.7899\n",
      "Training loss (for one batch) at step 100: 414.3754, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 110: 409.0025, Accuracy: 0.7887\n",
      "---- Training ----\n",
      "Training loss: 129.7670\n",
      "Training acc over epoch: 0.7895\n",
      "---- Validation ----\n",
      "Validation loss: 34.3215\n",
      "Validation acc: 0.7829\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 422.2969, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 419.6604, Accuracy: 0.7905\n",
      "Training loss (for one batch) at step 20: 416.3730, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 30: 405.5954, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 40: 409.5206, Accuracy: 0.8100\n",
      "Training loss (for one batch) at step 50: 392.4487, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 60: 413.9512, Accuracy: 0.8210\n",
      "Training loss (for one batch) at step 70: 439.2646, Accuracy: 0.8184\n",
      "Training loss (for one batch) at step 80: 433.5410, Accuracy: 0.8090\n",
      "Training loss (for one batch) at step 90: 416.7130, Accuracy: 0.8028\n",
      "Training loss (for one batch) at step 100: 408.0059, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 110: 415.0251, Accuracy: 0.7999\n",
      "---- Training ----\n",
      "Training loss: 129.6941\n",
      "Training acc over epoch: 0.7996\n",
      "---- Validation ----\n",
      "Validation loss: 35.8797\n",
      "Validation acc: 0.7775\n",
      "Time taken: 10.18s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 431.8764, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 426.8907, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 20: 419.8083, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 30: 416.1828, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 40: 407.1818, Accuracy: 0.8074\n",
      "Training loss (for one batch) at step 50: 393.4977, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 60: 403.5938, Accuracy: 0.8156\n",
      "Training loss (for one batch) at step 70: 431.4167, Accuracy: 0.8137\n",
      "Training loss (for one batch) at step 80: 428.8875, Accuracy: 0.8095\n",
      "Training loss (for one batch) at step 90: 415.8270, Accuracy: 0.8058\n",
      "Training loss (for one batch) at step 100: 421.3437, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 110: 411.0446, Accuracy: 0.8033\n",
      "---- Training ----\n",
      "Training loss: 130.6579\n",
      "Training acc over epoch: 0.8025\n",
      "---- Validation ----\n",
      "Validation loss: 33.9408\n",
      "Validation acc: 0.7730\n",
      "Time taken: 12.44s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 436.8090, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 425.1053, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 20: 409.8232, Accuracy: 0.8010\n",
      "Training loss (for one batch) at step 30: 416.9391, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 40: 398.7617, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 50: 392.8563, Accuracy: 0.8218\n",
      "Training loss (for one batch) at step 60: 416.1235, Accuracy: 0.8254\n",
      "Training loss (for one batch) at step 70: 409.8107, Accuracy: 0.8248\n",
      "Training loss (for one batch) at step 80: 408.1260, Accuracy: 0.8191\n",
      "Training loss (for one batch) at step 90: 409.3101, Accuracy: 0.8164\n",
      "Training loss (for one batch) at step 100: 411.8458, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 110: 409.7672, Accuracy: 0.8143\n",
      "---- Training ----\n",
      "Training loss: 129.8224\n",
      "Training acc over epoch: 0.8125\n",
      "---- Validation ----\n",
      "Validation loss: 34.1934\n",
      "Validation acc: 0.7687\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 419.8128, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 406.3700, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 20: 403.8003, Accuracy: 0.8028\n",
      "Training loss (for one batch) at step 30: 411.8231, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 40: 398.9064, Accuracy: 0.8171\n",
      "Training loss (for one batch) at step 50: 384.7111, Accuracy: 0.8269\n",
      "Training loss (for one batch) at step 60: 402.5841, Accuracy: 0.8307\n",
      "Training loss (for one batch) at step 70: 416.5535, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 80: 417.0016, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 90: 414.6304, Accuracy: 0.8155\n",
      "Training loss (for one batch) at step 100: 411.4570, Accuracy: 0.8136\n",
      "Training loss (for one batch) at step 110: 410.2381, Accuracy: 0.8133\n",
      "---- Training ----\n",
      "Training loss: 124.3304\n",
      "Training acc over epoch: 0.8123\n",
      "---- Validation ----\n",
      "Validation loss: 34.8788\n",
      "Validation acc: 0.7329\n",
      "Time taken: 11.10s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 429.2708, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 412.9831, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 20: 399.3144, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 30: 401.3103, Accuracy: 0.8117\n",
      "Training loss (for one batch) at step 40: 391.4172, Accuracy: 0.8192\n",
      "Training loss (for one batch) at step 50: 394.2135, Accuracy: 0.8283\n",
      "Training loss (for one batch) at step 60: 382.2676, Accuracy: 0.8332\n",
      "Training loss (for one batch) at step 70: 405.9974, Accuracy: 0.8319\n",
      "Training loss (for one batch) at step 80: 427.6143, Accuracy: 0.8254\n",
      "Training loss (for one batch) at step 90: 410.0766, Accuracy: 0.8245\n",
      "Training loss (for one batch) at step 100: 397.6902, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 110: 403.2440, Accuracy: 0.8226\n",
      "---- Training ----\n",
      "Training loss: 127.2588\n",
      "Training acc over epoch: 0.8221\n",
      "---- Validation ----\n",
      "Validation loss: 33.0081\n",
      "Validation acc: 0.7867\n",
      "Time taken: 10.15s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 417.5544, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 406.6168, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 20: 404.2650, Accuracy: 0.8114\n",
      "Training loss (for one batch) at step 30: 403.9474, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 40: 382.7736, Accuracy: 0.8228\n",
      "Training loss (for one batch) at step 50: 374.1808, Accuracy: 0.8315\n",
      "Training loss (for one batch) at step 60: 379.8135, Accuracy: 0.8373\n",
      "Training loss (for one batch) at step 70: 401.7059, Accuracy: 0.8343\n",
      "Training loss (for one batch) at step 80: 412.9540, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 90: 405.6709, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 100: 411.0044, Accuracy: 0.8219\n",
      "Training loss (for one batch) at step 110: 405.8868, Accuracy: 0.8195\n",
      "---- Training ----\n",
      "Training loss: 131.5481\n",
      "Training acc over epoch: 0.8201\n",
      "---- Validation ----\n",
      "Validation loss: 34.4300\n",
      "Validation acc: 0.7574\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 409.6174, Accuracy: 0.8594\n",
      "Training loss (for one batch) at step 10: 399.4196, Accuracy: 0.8196\n",
      "Training loss (for one batch) at step 20: 405.8558, Accuracy: 0.8192\n",
      "Training loss (for one batch) at step 30: 394.9727, Accuracy: 0.8248\n",
      "Training loss (for one batch) at step 40: 383.1567, Accuracy: 0.8304\n",
      "Training loss (for one batch) at step 50: 373.5457, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 60: 378.2562, Accuracy: 0.8412\n",
      "Training loss (for one batch) at step 70: 412.2131, Accuracy: 0.8378\n",
      "Training loss (for one batch) at step 80: 405.5193, Accuracy: 0.8310\n",
      "Training loss (for one batch) at step 90: 408.0341, Accuracy: 0.8293\n",
      "Training loss (for one batch) at step 100: 409.6609, Accuracy: 0.8260\n",
      "Training loss (for one batch) at step 110: 393.7925, Accuracy: 0.8269\n",
      "---- Training ----\n",
      "Training loss: 129.5498\n",
      "Training acc over epoch: 0.8252\n",
      "---- Validation ----\n",
      "Validation loss: 38.0458\n",
      "Validation acc: 0.7719\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 404.5950, Accuracy: 0.8594\n",
      "Training loss (for one batch) at step 10: 399.7997, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 20: 385.7620, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 30: 377.6134, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 40: 382.9290, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 50: 381.3469, Accuracy: 0.8390\n",
      "Training loss (for one batch) at step 60: 391.8363, Accuracy: 0.8435\n",
      "Training loss (for one batch) at step 70: 396.2083, Accuracy: 0.8435\n",
      "Training loss (for one batch) at step 80: 414.4244, Accuracy: 0.8373\n",
      "Training loss (for one batch) at step 90: 397.1108, Accuracy: 0.8328\n",
      "Training loss (for one batch) at step 100: 379.0723, Accuracy: 0.8327\n",
      "Training loss (for one batch) at step 110: 398.4095, Accuracy: 0.8336\n",
      "---- Training ----\n",
      "Training loss: 121.7991\n",
      "Training acc over epoch: 0.8336\n",
      "---- Validation ----\n",
      "Validation loss: 38.7217\n",
      "Validation acc: 0.7695\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 399.8452, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 10: 402.2378, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 20: 406.4944, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 30: 382.5360, Accuracy: 0.8173\n",
      "Training loss (for one batch) at step 40: 396.3559, Accuracy: 0.8287\n",
      "Training loss (for one batch) at step 50: 367.0646, Accuracy: 0.8358\n",
      "Training loss (for one batch) at step 60: 374.4243, Accuracy: 0.8394\n",
      "Training loss (for one batch) at step 70: 397.1725, Accuracy: 0.8336\n",
      "Training loss (for one batch) at step 80: 381.8072, Accuracy: 0.8280\n",
      "Training loss (for one batch) at step 90: 393.0997, Accuracy: 0.8266\n",
      "Training loss (for one batch) at step 100: 383.8758, Accuracy: 0.8291\n",
      "Training loss (for one batch) at step 110: 403.3742, Accuracy: 0.8286\n",
      "---- Training ----\n",
      "Training loss: 124.4883\n",
      "Training acc over epoch: 0.8276\n",
      "---- Validation ----\n",
      "Validation loss: 37.4525\n",
      "Validation acc: 0.7697\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 380.9418, Accuracy: 0.8750\n",
      "Training loss (for one batch) at step 10: 398.4366, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 20: 385.9356, Accuracy: 0.8158\n",
      "Training loss (for one batch) at step 30: 389.7673, Accuracy: 0.8173\n",
      "Training loss (for one batch) at step 40: 374.8901, Accuracy: 0.8338\n",
      "Training loss (for one batch) at step 50: 366.3161, Accuracy: 0.8425\n",
      "Training loss (for one batch) at step 60: 384.7950, Accuracy: 0.8445\n",
      "Training loss (for one batch) at step 70: 410.1757, Accuracy: 0.8408\n",
      "Training loss (for one batch) at step 80: 395.1171, Accuracy: 0.8322\n",
      "Training loss (for one batch) at step 90: 387.4407, Accuracy: 0.8317\n",
      "Training loss (for one batch) at step 100: 375.9362, Accuracy: 0.8321\n",
      "Training loss (for one batch) at step 110: 369.4395, Accuracy: 0.8321\n",
      "---- Training ----\n",
      "Training loss: 124.4706\n",
      "Training acc over epoch: 0.8309\n",
      "---- Validation ----\n",
      "Validation loss: 42.9102\n",
      "Validation acc: 0.7552\n",
      "Time taken: 10.16s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 409.2808, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 392.5227, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 20: 385.6772, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 30: 379.3047, Accuracy: 0.8329\n",
      "Training loss (for one batch) at step 40: 362.8928, Accuracy: 0.8384\n",
      "Training loss (for one batch) at step 50: 372.9041, Accuracy: 0.8473\n",
      "Training loss (for one batch) at step 60: 380.8168, Accuracy: 0.8511\n",
      "Training loss (for one batch) at step 70: 396.5111, Accuracy: 0.8464\n",
      "Training loss (for one batch) at step 80: 385.7523, Accuracy: 0.8410\n",
      "Training loss (for one batch) at step 90: 390.6480, Accuracy: 0.8375\n",
      "Training loss (for one batch) at step 100: 384.4974, Accuracy: 0.8366\n",
      "Training loss (for one batch) at step 110: 393.6610, Accuracy: 0.8361\n",
      "---- Training ----\n",
      "Training loss: 128.9716\n",
      "Training acc over epoch: 0.8352\n",
      "---- Validation ----\n",
      "Validation loss: 49.1037\n",
      "Validation acc: 0.7697\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 405.4009, Accuracy: 0.8672\n",
      "Training loss (for one batch) at step 10: 390.3052, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 20: 384.4676, Accuracy: 0.8225\n",
      "Training loss (for one batch) at step 30: 382.7626, Accuracy: 0.8269\n",
      "Training loss (for one batch) at step 40: 368.0850, Accuracy: 0.8344\n",
      "Training loss (for one batch) at step 50: 362.7834, Accuracy: 0.8427\n",
      "Training loss (for one batch) at step 60: 379.2953, Accuracy: 0.8470\n",
      "Training loss (for one batch) at step 70: 392.5780, Accuracy: 0.8415\n",
      "Training loss (for one batch) at step 80: 396.9719, Accuracy: 0.8358\n",
      "Training loss (for one batch) at step 90: 357.3862, Accuracy: 0.8343\n",
      "Training loss (for one batch) at step 100: 379.3701, Accuracy: 0.8358\n",
      "Training loss (for one batch) at step 110: 378.4932, Accuracy: 0.8352\n",
      "---- Training ----\n",
      "Training loss: 123.0882\n",
      "Training acc over epoch: 0.8346\n",
      "---- Validation ----\n",
      "Validation loss: 44.7021\n",
      "Validation acc: 0.7601\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 402.7133, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 388.8214, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 20: 372.7312, Accuracy: 0.8263\n",
      "Training loss (for one batch) at step 30: 378.1906, Accuracy: 0.8372\n",
      "Training loss (for one batch) at step 40: 375.3785, Accuracy: 0.8441\n",
      "Training loss (for one batch) at step 50: 365.9271, Accuracy: 0.8494\n",
      "Training loss (for one batch) at step 60: 387.9552, Accuracy: 0.8491\n",
      "Training loss (for one batch) at step 70: 408.3809, Accuracy: 0.8455\n",
      "Training loss (for one batch) at step 80: 395.2553, Accuracy: 0.8374\n",
      "Training loss (for one batch) at step 90: 372.4876, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 100: 370.9867, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 110: 372.4905, Accuracy: 0.8353\n",
      "---- Training ----\n",
      "Training loss: 120.7563\n",
      "Training acc over epoch: 0.8355\n",
      "---- Validation ----\n",
      "Validation loss: 45.6788\n",
      "Validation acc: 0.7579\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 402.9594, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 10: 384.4045, Accuracy: 0.8004\n",
      "Training loss (for one batch) at step 20: 376.0408, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 30: 356.7892, Accuracy: 0.8344\n",
      "Training loss (for one batch) at step 40: 372.9923, Accuracy: 0.8430\n",
      "Training loss (for one batch) at step 50: 349.2484, Accuracy: 0.8519\n",
      "Training loss (for one batch) at step 60: 370.1307, Accuracy: 0.8536\n",
      "Training loss (for one batch) at step 70: 389.3970, Accuracy: 0.8488\n",
      "Training loss (for one batch) at step 80: 377.3975, Accuracy: 0.8416\n",
      "Training loss (for one batch) at step 90: 371.7637, Accuracy: 0.8402\n",
      "Training loss (for one batch) at step 100: 366.0113, Accuracy: 0.8412\n",
      "Training loss (for one batch) at step 110: 355.7467, Accuracy: 0.8424\n",
      "---- Training ----\n",
      "Training loss: 120.9103\n",
      "Training acc over epoch: 0.8410\n",
      "---- Validation ----\n",
      "Validation loss: 33.9664\n",
      "Validation acc: 0.7711\n",
      "Time taken: 10.17s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 387.9793, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 372.4830, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 20: 357.6257, Accuracy: 0.8378\n",
      "Training loss (for one batch) at step 30: 361.7961, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 40: 359.6081, Accuracy: 0.8479\n",
      "Training loss (for one batch) at step 50: 334.4250, Accuracy: 0.8534\n",
      "Training loss (for one batch) at step 60: 362.1966, Accuracy: 0.8563\n",
      "Training loss (for one batch) at step 70: 374.6973, Accuracy: 0.8515\n",
      "Training loss (for one batch) at step 80: 390.9496, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 90: 364.9310, Accuracy: 0.8416\n",
      "Training loss (for one batch) at step 100: 349.4370, Accuracy: 0.8411\n",
      "Training loss (for one batch) at step 110: 373.5786, Accuracy: 0.8412\n",
      "---- Training ----\n",
      "Training loss: 116.3288\n",
      "Training acc over epoch: 0.8404\n",
      "---- Validation ----\n",
      "Validation loss: 41.9443\n",
      "Validation acc: 0.7727\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 389.5535, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 375.5826, Accuracy: 0.8097\n",
      "Training loss (for one batch) at step 20: 363.0510, Accuracy: 0.8251\n",
      "Training loss (for one batch) at step 30: 357.9859, Accuracy: 0.8390\n",
      "Training loss (for one batch) at step 40: 346.2454, Accuracy: 0.8439\n",
      "Training loss (for one batch) at step 50: 343.7426, Accuracy: 0.8520\n",
      "Training loss (for one batch) at step 60: 357.9008, Accuracy: 0.8566\n",
      "Training loss (for one batch) at step 70: 388.1388, Accuracy: 0.8515\n",
      "Training loss (for one batch) at step 80: 391.4852, Accuracy: 0.8442\n",
      "Training loss (for one batch) at step 90: 357.2273, Accuracy: 0.8428\n",
      "Training loss (for one batch) at step 100: 341.1560, Accuracy: 0.8422\n",
      "Training loss (for one batch) at step 110: 368.8656, Accuracy: 0.8416\n",
      "---- Training ----\n",
      "Training loss: 111.1781\n",
      "Training acc over epoch: 0.8415\n",
      "---- Validation ----\n",
      "Validation loss: 38.4172\n",
      "Validation acc: 0.7585\n",
      "Time taken: 10.19s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 380.4800, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 367.4596, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 20: 364.3348, Accuracy: 0.8311\n",
      "Training loss (for one batch) at step 30: 359.9687, Accuracy: 0.8422\n",
      "Training loss (for one batch) at step 40: 347.4378, Accuracy: 0.8508\n",
      "Training loss (for one batch) at step 50: 351.5642, Accuracy: 0.8574\n",
      "Training loss (for one batch) at step 60: 363.0528, Accuracy: 0.8598\n",
      "Training loss (for one batch) at step 70: 375.3520, Accuracy: 0.8530\n",
      "Training loss (for one batch) at step 80: 380.4359, Accuracy: 0.8460\n",
      "Training loss (for one batch) at step 90: 367.0573, Accuracy: 0.8411\n",
      "Training loss (for one batch) at step 100: 363.2031, Accuracy: 0.8409\n",
      "Training loss (for one batch) at step 110: 358.7037, Accuracy: 0.8409\n",
      "---- Training ----\n",
      "Training loss: 113.2923\n",
      "Training acc over epoch: 0.8408\n",
      "---- Validation ----\n",
      "Validation loss: 51.2671\n",
      "Validation acc: 0.7477\n",
      "Time taken: 10.17s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 400.2693, Accuracy: 0.8516\n",
      "Training loss (for one batch) at step 10: 367.9016, Accuracy: 0.8132\n",
      "Training loss (for one batch) at step 20: 380.9561, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 30: 359.1306, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 40: 338.4955, Accuracy: 0.8498\n",
      "Training loss (for one batch) at step 50: 344.4594, Accuracy: 0.8588\n",
      "Training loss (for one batch) at step 60: 350.2126, Accuracy: 0.8594\n",
      "Training loss (for one batch) at step 70: 372.3621, Accuracy: 0.8539\n",
      "Training loss (for one batch) at step 80: 354.4295, Accuracy: 0.8471\n",
      "Training loss (for one batch) at step 90: 353.2850, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 100: 357.0284, Accuracy: 0.8434\n",
      "Training loss (for one batch) at step 110: 348.9763, Accuracy: 0.8442\n",
      "---- Training ----\n",
      "Training loss: 108.1548\n",
      "Training acc over epoch: 0.8436\n",
      "---- Validation ----\n",
      "Validation loss: 49.1742\n",
      "Validation acc: 0.7706\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 381.6017, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 360.6715, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 20: 343.8275, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 30: 359.0778, Accuracy: 0.8390\n",
      "Training loss (for one batch) at step 40: 339.0116, Accuracy: 0.8478\n",
      "Training loss (for one batch) at step 50: 345.6368, Accuracy: 0.8539\n",
      "Training loss (for one batch) at step 60: 347.1768, Accuracy: 0.8591\n",
      "Training loss (for one batch) at step 70: 382.9850, Accuracy: 0.8528\n",
      "Training loss (for one batch) at step 80: 380.6125, Accuracy: 0.8450\n",
      "Training loss (for one batch) at step 90: 354.2098, Accuracy: 0.8436\n",
      "Training loss (for one batch) at step 100: 354.1423, Accuracy: 0.8435\n",
      "Training loss (for one batch) at step 110: 342.6422, Accuracy: 0.8426\n",
      "---- Training ----\n",
      "Training loss: 110.3943\n",
      "Training acc over epoch: 0.8418\n",
      "---- Validation ----\n",
      "Validation loss: 43.0067\n",
      "Validation acc: 0.7636\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 375.3877, Accuracy: 0.8594\n",
      "Training loss (for one batch) at step 10: 370.5115, Accuracy: 0.8168\n",
      "Training loss (for one batch) at step 20: 342.5310, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 30: 334.2600, Accuracy: 0.8460\n",
      "Training loss (for one batch) at step 40: 345.8143, Accuracy: 0.8525\n",
      "Training loss (for one batch) at step 50: 334.5493, Accuracy: 0.8608\n",
      "Training loss (for one batch) at step 60: 338.6928, Accuracy: 0.8619\n",
      "Training loss (for one batch) at step 70: 392.4996, Accuracy: 0.8562\n",
      "Training loss (for one batch) at step 80: 374.8146, Accuracy: 0.8495\n",
      "Training loss (for one batch) at step 90: 354.8586, Accuracy: 0.8475\n",
      "Training loss (for one batch) at step 100: 357.1370, Accuracy: 0.8475\n",
      "Training loss (for one batch) at step 110: 335.0157, Accuracy: 0.8469\n",
      "---- Training ----\n",
      "Training loss: 109.6552\n",
      "Training acc over epoch: 0.8464\n",
      "---- Validation ----\n",
      "Validation loss: 45.8432\n",
      "Validation acc: 0.7577\n",
      "Time taken: 10.19s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 371.4583, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 361.7013, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 20: 355.0939, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 30: 348.5993, Accuracy: 0.8349\n",
      "Training loss (for one batch) at step 40: 336.4259, Accuracy: 0.8510\n",
      "Training loss (for one batch) at step 50: 336.1702, Accuracy: 0.8572\n",
      "Training loss (for one batch) at step 60: 350.7783, Accuracy: 0.8623\n",
      "Training loss (for one batch) at step 70: 375.6190, Accuracy: 0.8537\n",
      "Training loss (for one batch) at step 80: 352.7657, Accuracy: 0.8477\n",
      "Training loss (for one batch) at step 90: 333.0016, Accuracy: 0.8454\n",
      "Training loss (for one batch) at step 100: 349.9857, Accuracy: 0.8461\n",
      "Training loss (for one batch) at step 110: 347.8181, Accuracy: 0.8453\n",
      "---- Training ----\n",
      "Training loss: 116.7654\n",
      "Training acc over epoch: 0.8448\n",
      "---- Validation ----\n",
      "Validation loss: 39.8915\n",
      "Validation acc: 0.7593\n",
      "Time taken: 11.15s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 369.2477, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 363.4565, Accuracy: 0.8168\n",
      "Training loss (for one batch) at step 20: 346.7933, Accuracy: 0.8326\n",
      "Training loss (for one batch) at step 30: 347.1665, Accuracy: 0.8483\n",
      "Training loss (for one batch) at step 40: 351.1372, Accuracy: 0.8540\n",
      "Training loss (for one batch) at step 50: 335.3770, Accuracy: 0.8615\n",
      "Training loss (for one batch) at step 60: 352.5532, Accuracy: 0.8654\n",
      "Training loss (for one batch) at step 70: 361.9255, Accuracy: 0.8609\n",
      "Training loss (for one batch) at step 80: 367.3645, Accuracy: 0.8519\n",
      "Training loss (for one batch) at step 90: 341.5908, Accuracy: 0.8480\n",
      "Training loss (for one batch) at step 100: 354.8248, Accuracy: 0.8485\n",
      "Training loss (for one batch) at step 110: 359.2790, Accuracy: 0.8486\n",
      "---- Training ----\n",
      "Training loss: 108.4711\n",
      "Training acc over epoch: 0.8479\n",
      "---- Validation ----\n",
      "Validation loss: 48.7712\n",
      "Validation acc: 0.7636\n",
      "Time taken: 11.78s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 362.7652, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 350.3971, Accuracy: 0.8146\n",
      "Training loss (for one batch) at step 20: 346.8939, Accuracy: 0.8374\n",
      "Training loss (for one batch) at step 30: 333.9165, Accuracy: 0.8448\n",
      "Training loss (for one batch) at step 40: 341.2097, Accuracy: 0.8518\n",
      "Training loss (for one batch) at step 50: 322.6062, Accuracy: 0.8591\n",
      "Training loss (for one batch) at step 60: 340.3625, Accuracy: 0.8637\n",
      "Training loss (for one batch) at step 70: 358.0001, Accuracy: 0.8583\n",
      "Training loss (for one batch) at step 80: 361.6202, Accuracy: 0.8491\n",
      "Training loss (for one batch) at step 90: 329.5889, Accuracy: 0.8450\n",
      "Training loss (for one batch) at step 100: 356.2818, Accuracy: 0.8471\n",
      "Training loss (for one batch) at step 110: 362.0742, Accuracy: 0.8470\n",
      "---- Training ----\n",
      "Training loss: 112.6507\n",
      "Training acc over epoch: 0.8458\n",
      "---- Validation ----\n",
      "Validation loss: 34.5976\n",
      "Validation acc: 0.7730\n",
      "Time taken: 12.13s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 371.5562, Accuracy: 0.8594\n",
      "Training loss (for one batch) at step 10: 354.6072, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 20: 328.3281, Accuracy: 0.8311\n",
      "Training loss (for one batch) at step 30: 345.2876, Accuracy: 0.8410\n",
      "Training loss (for one batch) at step 40: 325.3014, Accuracy: 0.8521\n",
      "Training loss (for one batch) at step 50: 340.7801, Accuracy: 0.8609\n",
      "Training loss (for one batch) at step 60: 367.1422, Accuracy: 0.8630\n",
      "Training loss (for one batch) at step 70: 349.6281, Accuracy: 0.8549\n",
      "Training loss (for one batch) at step 80: 358.4362, Accuracy: 0.8444\n",
      "Training loss (for one batch) at step 90: 350.5580, Accuracy: 0.8418\n",
      "Training loss (for one batch) at step 100: 350.7051, Accuracy: 0.8412\n",
      "Training loss (for one batch) at step 110: 364.6942, Accuracy: 0.8414\n",
      "---- Training ----\n",
      "Training loss: 108.1536\n",
      "Training acc over epoch: 0.8415\n",
      "---- Validation ----\n",
      "Validation loss: 29.6967\n",
      "Validation acc: 0.7727\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 369.6726, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 367.7222, Accuracy: 0.8246\n",
      "Training loss (for one batch) at step 20: 346.2566, Accuracy: 0.8426\n",
      "Training loss (for one batch) at step 30: 344.0568, Accuracy: 0.8470\n",
      "Training loss (for one batch) at step 40: 333.5928, Accuracy: 0.8580\n",
      "Training loss (for one batch) at step 50: 318.0502, Accuracy: 0.8635\n",
      "Training loss (for one batch) at step 60: 354.0560, Accuracy: 0.8660\n",
      "Training loss (for one batch) at step 70: 361.9729, Accuracy: 0.8581\n",
      "Training loss (for one batch) at step 80: 358.0693, Accuracy: 0.8514\n",
      "Training loss (for one batch) at step 90: 338.8206, Accuracy: 0.8486\n",
      "Training loss (for one batch) at step 100: 329.6201, Accuracy: 0.8496\n",
      "Training loss (for one batch) at step 110: 345.6869, Accuracy: 0.8487\n",
      "---- Training ----\n",
      "Training loss: 106.2058\n",
      "Training acc over epoch: 0.8481\n",
      "---- Validation ----\n",
      "Validation loss: 38.4881\n",
      "Validation acc: 0.7657\n",
      "Time taken: 10.82s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 362.5688, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 347.8472, Accuracy: 0.8082\n",
      "Training loss (for one batch) at step 20: 335.0418, Accuracy: 0.8322\n",
      "Training loss (for one batch) at step 30: 341.1741, Accuracy: 0.8470\n",
      "Training loss (for one batch) at step 40: 324.3450, Accuracy: 0.8567\n",
      "Training loss (for one batch) at step 50: 324.7678, Accuracy: 0.8644\n",
      "Training loss (for one batch) at step 60: 339.3706, Accuracy: 0.8689\n",
      "Training loss (for one batch) at step 70: 350.2513, Accuracy: 0.8618\n",
      "Training loss (for one batch) at step 80: 356.8459, Accuracy: 0.8536\n",
      "Training loss (for one batch) at step 90: 342.1461, Accuracy: 0.8493\n",
      "Training loss (for one batch) at step 100: 337.4310, Accuracy: 0.8506\n",
      "Training loss (for one batch) at step 110: 346.4634, Accuracy: 0.8512\n",
      "---- Training ----\n",
      "Training loss: 102.1634\n",
      "Training acc over epoch: 0.8512\n",
      "---- Validation ----\n",
      "Validation loss: 58.2400\n",
      "Validation acc: 0.7730\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 360.3650, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 349.8069, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 20: 338.1154, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 30: 338.7811, Accuracy: 0.8470\n",
      "Training loss (for one batch) at step 40: 322.4112, Accuracy: 0.8588\n",
      "Training loss (for one batch) at step 50: 323.4476, Accuracy: 0.8675\n",
      "Training loss (for one batch) at step 60: 341.4071, Accuracy: 0.8700\n",
      "Training loss (for one batch) at step 70: 344.3754, Accuracy: 0.8593\n",
      "Training loss (for one batch) at step 80: 343.6693, Accuracy: 0.8501\n",
      "Training loss (for one batch) at step 90: 337.6391, Accuracy: 0.8480\n",
      "Training loss (for one batch) at step 100: 331.8414, Accuracy: 0.8496\n",
      "Training loss (for one batch) at step 110: 333.6413, Accuracy: 0.8478\n",
      "---- Training ----\n",
      "Training loss: 103.5519\n",
      "Training acc over epoch: 0.8475\n",
      "---- Validation ----\n",
      "Validation loss: 49.4406\n",
      "Validation acc: 0.7657\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 355.2434, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 345.8766, Accuracy: 0.8026\n",
      "Training loss (for one batch) at step 20: 331.0911, Accuracy: 0.8289\n",
      "Training loss (for one batch) at step 30: 315.5402, Accuracy: 0.8395\n",
      "Training loss (for one batch) at step 40: 337.6172, Accuracy: 0.8535\n",
      "Training loss (for one batch) at step 50: 315.5464, Accuracy: 0.8621\n",
      "Training loss (for one batch) at step 60: 336.7098, Accuracy: 0.8655\n",
      "Training loss (for one batch) at step 70: 359.4901, Accuracy: 0.8581\n",
      "Training loss (for one batch) at step 80: 372.0294, Accuracy: 0.8482\n",
      "Training loss (for one batch) at step 90: 334.4125, Accuracy: 0.8459\n",
      "Training loss (for one batch) at step 100: 319.8891, Accuracy: 0.8471\n",
      "Training loss (for one batch) at step 110: 338.3358, Accuracy: 0.8468\n",
      "---- Training ----\n",
      "Training loss: 104.9837\n",
      "Training acc over epoch: 0.8467\n",
      "---- Validation ----\n",
      "Validation loss: 58.7251\n",
      "Validation acc: 0.7654\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 342.8499, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 347.8940, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 20: 332.6580, Accuracy: 0.8367\n",
      "Training loss (for one batch) at step 30: 330.2950, Accuracy: 0.8495\n",
      "Training loss (for one batch) at step 40: 346.0995, Accuracy: 0.8573\n",
      "Training loss (for one batch) at step 50: 320.8225, Accuracy: 0.8637\n",
      "Training loss (for one batch) at step 60: 327.7903, Accuracy: 0.8649\n",
      "Training loss (for one batch) at step 70: 360.7198, Accuracy: 0.8581\n",
      "Training loss (for one batch) at step 80: 349.4879, Accuracy: 0.8468\n",
      "Training loss (for one batch) at step 90: 343.2452, Accuracy: 0.8456\n",
      "Training loss (for one batch) at step 100: 363.9510, Accuracy: 0.8466\n",
      "Training loss (for one batch) at step 110: 346.7548, Accuracy: 0.8464\n",
      "---- Training ----\n",
      "Training loss: 112.1534\n",
      "Training acc over epoch: 0.8448\n",
      "---- Validation ----\n",
      "Validation loss: 34.8690\n",
      "Validation acc: 0.7641\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 349.5545, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 347.4158, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 20: 335.0250, Accuracy: 0.8318\n",
      "Training loss (for one batch) at step 30: 326.9735, Accuracy: 0.8448\n",
      "Training loss (for one batch) at step 40: 325.7363, Accuracy: 0.8535\n",
      "Training loss (for one batch) at step 50: 313.7989, Accuracy: 0.8652\n",
      "Training loss (for one batch) at step 60: 340.5249, Accuracy: 0.8674\n",
      "Training loss (for one batch) at step 70: 350.4472, Accuracy: 0.8576\n",
      "Training loss (for one batch) at step 80: 377.2142, Accuracy: 0.8501\n",
      "Training loss (for one batch) at step 90: 331.9616, Accuracy: 0.8484\n",
      "Training loss (for one batch) at step 100: 321.8015, Accuracy: 0.8490\n",
      "Training loss (for one batch) at step 110: 327.0549, Accuracy: 0.8506\n",
      "---- Training ----\n",
      "Training loss: 104.7704\n",
      "Training acc over epoch: 0.8503\n",
      "---- Validation ----\n",
      "Validation loss: 54.0158\n",
      "Validation acc: 0.7687\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 358.5238, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 341.2524, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 20: 350.1877, Accuracy: 0.8266\n",
      "Training loss (for one batch) at step 30: 334.2787, Accuracy: 0.8470\n",
      "Training loss (for one batch) at step 40: 311.8147, Accuracy: 0.8601\n",
      "Training loss (for one batch) at step 50: 313.5257, Accuracy: 0.8670\n",
      "Training loss (for one batch) at step 60: 326.0995, Accuracy: 0.8667\n",
      "Training loss (for one batch) at step 70: 343.1526, Accuracy: 0.8589\n",
      "Training loss (for one batch) at step 80: 345.5145, Accuracy: 0.8519\n",
      "Training loss (for one batch) at step 90: 333.3993, Accuracy: 0.8497\n",
      "Training loss (for one batch) at step 100: 321.0209, Accuracy: 0.8509\n",
      "Training loss (for one batch) at step 110: 331.3101, Accuracy: 0.8509\n",
      "---- Training ----\n",
      "Training loss: 115.9971\n",
      "Training acc over epoch: 0.8501\n",
      "---- Validation ----\n",
      "Validation loss: 57.7454\n",
      "Validation acc: 0.7638\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 374.4637, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 354.4665, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 20: 325.8706, Accuracy: 0.8326\n",
      "Training loss (for one batch) at step 30: 324.2609, Accuracy: 0.8450\n",
      "Training loss (for one batch) at step 40: 331.5408, Accuracy: 0.8556\n",
      "Training loss (for one batch) at step 50: 309.5842, Accuracy: 0.8669\n",
      "Training loss (for one batch) at step 60: 348.1362, Accuracy: 0.8672\n",
      "Training loss (for one batch) at step 70: 341.7449, Accuracy: 0.8593\n",
      "Training loss (for one batch) at step 80: 346.6754, Accuracy: 0.8532\n",
      "Training loss (for one batch) at step 90: 357.6453, Accuracy: 0.8512\n",
      "Training loss (for one batch) at step 100: 334.1848, Accuracy: 0.8496\n",
      "Training loss (for one batch) at step 110: 328.0044, Accuracy: 0.8495\n",
      "---- Training ----\n",
      "Training loss: 105.9819\n",
      "Training acc over epoch: 0.8489\n",
      "---- Validation ----\n",
      "Validation loss: 39.9352\n",
      "Validation acc: 0.7622\n",
      "Time taken: 10.11s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7549\n",
      "Validation AUC: 0.7563\n",
      "Validation Balanced_ACC: 0.4912\n",
      "Validation AUCSK: 0.8248\n",
      "Validation MI: 0.1303\n",
      "Validation Normalized MI: 0.1896\n",
      "Validation Adjusted MI: 0.1896\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 633.6382, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 645.6832, Accuracy: 0.4893\n",
      "Training loss (for one batch) at step 20: 577.5479, Accuracy: 0.5063\n",
      "Training loss (for one batch) at step 30: 549.8953, Accuracy: 0.5043\n",
      "Training loss (for one batch) at step 40: 505.4513, Accuracy: 0.5044\n",
      "Training loss (for one batch) at step 50: 505.1583, Accuracy: 0.5040\n",
      "Training loss (for one batch) at step 60: 515.3348, Accuracy: 0.5031\n",
      "Training loss (for one batch) at step 70: 469.0932, Accuracy: 0.5052\n",
      "Training loss (for one batch) at step 80: 482.1228, Accuracy: 0.5071\n",
      "Training loss (for one batch) at step 90: 481.1465, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 100: 470.6030, Accuracy: 0.5098\n",
      "Training loss (for one batch) at step 110: 479.3784, Accuracy: 0.5111\n",
      "---- Training ----\n",
      "Training loss: 154.4502\n",
      "Training acc over epoch: 0.5108\n",
      "---- Validation ----\n",
      "Validation loss: 34.7191\n",
      "Validation acc: 0.4938\n",
      "Time taken: 12.17s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 458.9650, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 453.9008, Accuracy: 0.5376\n",
      "Training loss (for one batch) at step 20: 457.7422, Accuracy: 0.5301\n",
      "Training loss (for one batch) at step 30: 463.2434, Accuracy: 0.5204\n",
      "Training loss (for one batch) at step 40: 453.0325, Accuracy: 0.5208\n",
      "Training loss (for one batch) at step 50: 455.7326, Accuracy: 0.5187\n",
      "Training loss (for one batch) at step 60: 452.5459, Accuracy: 0.5238\n",
      "Training loss (for one batch) at step 70: 452.6162, Accuracy: 0.5267\n",
      "Training loss (for one batch) at step 80: 448.7094, Accuracy: 0.5244\n",
      "Training loss (for one batch) at step 90: 446.9751, Accuracy: 0.5264\n",
      "Training loss (for one batch) at step 100: 451.0461, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 110: 448.7725, Accuracy: 0.5263\n",
      "---- Training ----\n",
      "Training loss: 140.0328\n",
      "Training acc over epoch: 0.5267\n",
      "---- Validation ----\n",
      "Validation loss: 34.7939\n",
      "Validation acc: 0.5116\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 449.0938, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 455.2111, Accuracy: 0.5433\n",
      "Training loss (for one batch) at step 20: 449.0193, Accuracy: 0.5305\n",
      "Training loss (for one batch) at step 30: 444.8570, Accuracy: 0.5305\n",
      "Training loss (for one batch) at step 40: 452.2039, Accuracy: 0.5320\n",
      "Training loss (for one batch) at step 50: 449.5188, Accuracy: 0.5354\n",
      "Training loss (for one batch) at step 60: 445.4026, Accuracy: 0.5352\n",
      "Training loss (for one batch) at step 70: 445.6435, Accuracy: 0.5361\n",
      "Training loss (for one batch) at step 80: 444.6648, Accuracy: 0.5361\n",
      "Training loss (for one batch) at step 90: 444.9772, Accuracy: 0.5369\n",
      "Training loss (for one batch) at step 100: 445.9797, Accuracy: 0.5363\n",
      "Training loss (for one batch) at step 110: 445.4570, Accuracy: 0.5371\n",
      "---- Training ----\n",
      "Training loss: 140.1770\n",
      "Training acc over epoch: 0.5375\n",
      "---- Validation ----\n",
      "Validation loss: 34.6042\n",
      "Validation acc: 0.5250\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 446.9637, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 446.7427, Accuracy: 0.5561\n",
      "Training loss (for one batch) at step 20: 445.6196, Accuracy: 0.5376\n",
      "Training loss (for one batch) at step 30: 445.6935, Accuracy: 0.5444\n",
      "Training loss (for one batch) at step 40: 445.5370, Accuracy: 0.5467\n",
      "Training loss (for one batch) at step 50: 446.5514, Accuracy: 0.5472\n",
      "Training loss (for one batch) at step 60: 443.1780, Accuracy: 0.5428\n",
      "Training loss (for one batch) at step 70: 444.2314, Accuracy: 0.5454\n",
      "Training loss (for one batch) at step 80: 444.6304, Accuracy: 0.5476\n",
      "Training loss (for one batch) at step 90: 442.5463, Accuracy: 0.5480\n",
      "Training loss (for one batch) at step 100: 445.3348, Accuracy: 0.5493\n",
      "Training loss (for one batch) at step 110: 444.6167, Accuracy: 0.5494\n",
      "---- Training ----\n",
      "Training loss: 139.4380\n",
      "Training acc over epoch: 0.5502\n",
      "---- Validation ----\n",
      "Validation loss: 34.8432\n",
      "Validation acc: 0.5806\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 441.8322, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 443.9858, Accuracy: 0.5661\n",
      "Training loss (for one batch) at step 20: 442.0341, Accuracy: 0.5681\n",
      "Training loss (for one batch) at step 30: 443.4840, Accuracy: 0.5706\n",
      "Training loss (for one batch) at step 40: 442.8472, Accuracy: 0.5699\n",
      "Training loss (for one batch) at step 50: 442.8596, Accuracy: 0.5749\n",
      "Training loss (for one batch) at step 60: 443.6351, Accuracy: 0.5754\n",
      "Training loss (for one batch) at step 70: 443.0876, Accuracy: 0.5764\n",
      "Training loss (for one batch) at step 80: 442.7206, Accuracy: 0.5772\n",
      "Training loss (for one batch) at step 90: 445.0051, Accuracy: 0.5746\n",
      "Training loss (for one batch) at step 100: 442.2674, Accuracy: 0.5769\n",
      "Training loss (for one batch) at step 110: 443.5256, Accuracy: 0.5783\n",
      "---- Training ----\n",
      "Training loss: 139.1476\n",
      "Training acc over epoch: 0.5788\n",
      "---- Validation ----\n",
      "Validation loss: 34.5768\n",
      "Validation acc: 0.6257\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 442.3123, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 443.7314, Accuracy: 0.5916\n",
      "Training loss (for one batch) at step 20: 441.9056, Accuracy: 0.5882\n",
      "Training loss (for one batch) at step 30: 445.3350, Accuracy: 0.5847\n",
      "Training loss (for one batch) at step 40: 441.5953, Accuracy: 0.5857\n",
      "Training loss (for one batch) at step 50: 445.4499, Accuracy: 0.5844\n",
      "Training loss (for one batch) at step 60: 443.6156, Accuracy: 0.5862\n",
      "Training loss (for one batch) at step 70: 442.9745, Accuracy: 0.5899\n",
      "Training loss (for one batch) at step 80: 446.2882, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 90: 439.2424, Accuracy: 0.5884\n",
      "Training loss (for one batch) at step 100: 443.2092, Accuracy: 0.5895\n",
      "Training loss (for one batch) at step 110: 441.8953, Accuracy: 0.5913\n",
      "---- Training ----\n",
      "Training loss: 137.8121\n",
      "Training acc over epoch: 0.5926\n",
      "---- Validation ----\n",
      "Validation loss: 34.5546\n",
      "Validation acc: 0.6397\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 441.2759, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 441.8027, Accuracy: 0.6207\n",
      "Training loss (for one batch) at step 20: 440.6535, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 30: 439.9090, Accuracy: 0.6056\n",
      "Training loss (for one batch) at step 40: 439.1626, Accuracy: 0.6061\n",
      "Training loss (for one batch) at step 50: 441.7034, Accuracy: 0.6029\n",
      "Training loss (for one batch) at step 60: 442.7346, Accuracy: 0.6054\n",
      "Training loss (for one batch) at step 70: 441.2320, Accuracy: 0.6074\n",
      "Training loss (for one batch) at step 80: 440.7327, Accuracy: 0.6087\n",
      "Training loss (for one batch) at step 90: 440.7497, Accuracy: 0.6114\n",
      "Training loss (for one batch) at step 100: 440.1418, Accuracy: 0.6116\n",
      "Training loss (for one batch) at step 110: 444.4174, Accuracy: 0.6138\n",
      "---- Training ----\n",
      "Training loss: 137.6835\n",
      "Training acc over epoch: 0.6139\n",
      "---- Validation ----\n",
      "Validation loss: 34.1654\n",
      "Validation acc: 0.6615\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.8806, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 444.3141, Accuracy: 0.6392\n",
      "Training loss (for one batch) at step 20: 437.4125, Accuracy: 0.6365\n",
      "Training loss (for one batch) at step 30: 438.0963, Accuracy: 0.6373\n",
      "Training loss (for one batch) at step 40: 441.7735, Accuracy: 0.6326\n",
      "Training loss (for one batch) at step 50: 438.4490, Accuracy: 0.6316\n",
      "Training loss (for one batch) at step 60: 444.4606, Accuracy: 0.6350\n",
      "Training loss (for one batch) at step 70: 439.1052, Accuracy: 0.6389\n",
      "Training loss (for one batch) at step 80: 436.8400, Accuracy: 0.6383\n",
      "Training loss (for one batch) at step 90: 439.3470, Accuracy: 0.6394\n",
      "Training loss (for one batch) at step 100: 439.1388, Accuracy: 0.6383\n",
      "Training loss (for one batch) at step 110: 441.1745, Accuracy: 0.6408\n",
      "---- Training ----\n",
      "Training loss: 138.2972\n",
      "Training acc over epoch: 0.6411\n",
      "---- Validation ----\n",
      "Validation loss: 34.6009\n",
      "Validation acc: 0.6728\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 439.7166, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 435.6782, Accuracy: 0.6513\n",
      "Training loss (for one batch) at step 20: 436.8680, Accuracy: 0.6455\n",
      "Training loss (for one batch) at step 30: 433.0107, Accuracy: 0.6457\n",
      "Training loss (for one batch) at step 40: 441.6049, Accuracy: 0.6446\n",
      "Training loss (for one batch) at step 50: 438.1997, Accuracy: 0.6532\n",
      "Training loss (for one batch) at step 60: 436.3760, Accuracy: 0.6559\n",
      "Training loss (for one batch) at step 70: 440.4669, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 80: 441.6814, Accuracy: 0.6561\n",
      "Training loss (for one batch) at step 90: 436.8449, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 100: 438.6816, Accuracy: 0.6581\n",
      "Training loss (for one batch) at step 110: 440.9690, Accuracy: 0.6570\n",
      "---- Training ----\n",
      "Training loss: 137.6613\n",
      "Training acc over epoch: 0.6578\n",
      "---- Validation ----\n",
      "Validation loss: 34.6917\n",
      "Validation acc: 0.6725\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 436.9854, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 440.7358, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 20: 437.7215, Accuracy: 0.6745\n",
      "Training loss (for one batch) at step 30: 434.5018, Accuracy: 0.6774\n",
      "Training loss (for one batch) at step 40: 438.7775, Accuracy: 0.6831\n",
      "Training loss (for one batch) at step 50: 432.8996, Accuracy: 0.6872\n",
      "Training loss (for one batch) at step 60: 437.7627, Accuracy: 0.6884\n",
      "Training loss (for one batch) at step 70: 440.5972, Accuracy: 0.6864\n",
      "Training loss (for one batch) at step 80: 438.6900, Accuracy: 0.6828\n",
      "Training loss (for one batch) at step 90: 437.6099, Accuracy: 0.6801\n",
      "Training loss (for one batch) at step 100: 435.3061, Accuracy: 0.6805\n",
      "Training loss (for one batch) at step 110: 435.4282, Accuracy: 0.6805\n",
      "---- Training ----\n",
      "Training loss: 139.7305\n",
      "Training acc over epoch: 0.6812\n",
      "---- Validation ----\n",
      "Validation loss: 33.5578\n",
      "Validation acc: 0.7174\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 443.2815, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 437.4844, Accuracy: 0.7081\n",
      "Training loss (for one batch) at step 20: 434.3711, Accuracy: 0.7028\n",
      "Training loss (for one batch) at step 30: 433.4245, Accuracy: 0.7014\n",
      "Training loss (for one batch) at step 40: 436.1443, Accuracy: 0.7018\n",
      "Training loss (for one batch) at step 50: 428.8642, Accuracy: 0.7082\n",
      "Training loss (for one batch) at step 60: 451.9810, Accuracy: 0.7112\n",
      "Training loss (for one batch) at step 70: 433.4803, Accuracy: 0.7123\n",
      "Training loss (for one batch) at step 80: 437.3905, Accuracy: 0.7080\n",
      "Training loss (for one batch) at step 90: 432.3236, Accuracy: 0.7044\n",
      "Training loss (for one batch) at step 100: 434.2662, Accuracy: 0.7038\n",
      "Training loss (for one batch) at step 110: 437.2988, Accuracy: 0.7044\n",
      "---- Training ----\n",
      "Training loss: 138.9392\n",
      "Training acc over epoch: 0.7049\n",
      "---- Validation ----\n",
      "Validation loss: 34.8866\n",
      "Validation acc: 0.7090\n",
      "Time taken: 10.19s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 441.7390, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 437.6072, Accuracy: 0.7060\n",
      "Training loss (for one batch) at step 20: 433.8213, Accuracy: 0.7039\n",
      "Training loss (for one batch) at step 30: 435.6602, Accuracy: 0.7044\n",
      "Training loss (for one batch) at step 40: 432.7845, Accuracy: 0.7098\n",
      "Training loss (for one batch) at step 50: 423.3956, Accuracy: 0.7178\n",
      "Training loss (for one batch) at step 60: 439.3013, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 70: 441.7411, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 80: 437.6853, Accuracy: 0.7129\n",
      "Training loss (for one batch) at step 90: 437.0233, Accuracy: 0.7086\n",
      "Training loss (for one batch) at step 100: 428.0882, Accuracy: 0.7083\n",
      "Training loss (for one batch) at step 110: 433.0666, Accuracy: 0.7093\n",
      "---- Training ----\n",
      "Training loss: 137.4471\n",
      "Training acc over epoch: 0.7099\n",
      "---- Validation ----\n",
      "Validation loss: 34.7628\n",
      "Validation acc: 0.6639\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 440.0456, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 433.6775, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 20: 436.2779, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 30: 428.5739, Accuracy: 0.7225\n",
      "Training loss (for one batch) at step 40: 426.3956, Accuracy: 0.7260\n",
      "Training loss (for one batch) at step 50: 418.3003, Accuracy: 0.7341\n",
      "Training loss (for one batch) at step 60: 427.7766, Accuracy: 0.7363\n",
      "Training loss (for one batch) at step 70: 437.2977, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 80: 434.3934, Accuracy: 0.7317\n",
      "Training loss (for one batch) at step 90: 431.7360, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 100: 431.3107, Accuracy: 0.7264\n",
      "Training loss (for one batch) at step 110: 420.8573, Accuracy: 0.7269\n",
      "---- Training ----\n",
      "Training loss: 137.0816\n",
      "Training acc over epoch: 0.7281\n",
      "---- Validation ----\n",
      "Validation loss: 36.1322\n",
      "Validation acc: 0.7423\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 441.1974, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 439.6648, Accuracy: 0.7280\n",
      "Training loss (for one batch) at step 20: 428.6888, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 30: 430.6563, Accuracy: 0.7371\n",
      "Training loss (for one batch) at step 40: 417.8840, Accuracy: 0.7470\n",
      "Training loss (for one batch) at step 50: 401.7112, Accuracy: 0.7520\n",
      "Training loss (for one batch) at step 60: 416.6474, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 70: 445.3053, Accuracy: 0.7520\n",
      "Training loss (for one batch) at step 80: 431.7088, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 90: 418.4118, Accuracy: 0.7465\n",
      "Training loss (for one batch) at step 100: 426.8790, Accuracy: 0.7433\n",
      "Training loss (for one batch) at step 110: 428.2265, Accuracy: 0.7426\n",
      "---- Training ----\n",
      "Training loss: 134.5551\n",
      "Training acc over epoch: 0.7432\n",
      "---- Validation ----\n",
      "Validation loss: 33.6987\n",
      "Validation acc: 0.7630\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 435.4467, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 430.1873, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 435.9358, Accuracy: 0.7507\n",
      "Training loss (for one batch) at step 30: 420.0963, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 40: 428.5253, Accuracy: 0.7628\n",
      "Training loss (for one batch) at step 50: 419.8862, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 60: 431.8748, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 70: 431.9053, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 80: 427.5852, Accuracy: 0.7682\n",
      "Training loss (for one batch) at step 90: 438.5889, Accuracy: 0.7675\n",
      "Training loss (for one batch) at step 100: 428.3403, Accuracy: 0.7658\n",
      "Training loss (for one batch) at step 110: 433.0344, Accuracy: 0.7650\n",
      "---- Training ----\n",
      "Training loss: 133.5357\n",
      "Training acc over epoch: 0.7647\n",
      "---- Validation ----\n",
      "Validation loss: 37.2410\n",
      "Validation acc: 0.7251\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 442.8885, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 432.0059, Accuracy: 0.7557\n",
      "Training loss (for one batch) at step 20: 429.9576, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 30: 424.6605, Accuracy: 0.7603\n",
      "Training loss (for one batch) at step 40: 422.5878, Accuracy: 0.7681\n",
      "Training loss (for one batch) at step 50: 400.9540, Accuracy: 0.7791\n",
      "Training loss (for one batch) at step 60: 406.2529, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 70: 438.9244, Accuracy: 0.7866\n",
      "Training loss (for one batch) at step 80: 424.9840, Accuracy: 0.7819\n",
      "Training loss (for one batch) at step 90: 424.9887, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 100: 418.7376, Accuracy: 0.7781\n",
      "Training loss (for one batch) at step 110: 421.9315, Accuracy: 0.7758\n",
      "---- Training ----\n",
      "Training loss: 132.6744\n",
      "Training acc over epoch: 0.7751\n",
      "---- Validation ----\n",
      "Validation loss: 34.8710\n",
      "Validation acc: 0.7413\n",
      "Time taken: 10.16s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 435.4200, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 437.2561, Accuracy: 0.7628\n",
      "Training loss (for one batch) at step 20: 427.5720, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 30: 415.4131, Accuracy: 0.7714\n",
      "Training loss (for one batch) at step 40: 415.6251, Accuracy: 0.7788\n",
      "Training loss (for one batch) at step 50: 401.9815, Accuracy: 0.7914\n",
      "Training loss (for one batch) at step 60: 413.1813, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 70: 427.3132, Accuracy: 0.7942\n",
      "Training loss (for one batch) at step 80: 434.3882, Accuracy: 0.7864\n",
      "Training loss (for one batch) at step 90: 419.9542, Accuracy: 0.7860\n",
      "Training loss (for one batch) at step 100: 424.7396, Accuracy: 0.7843\n",
      "Training loss (for one batch) at step 110: 421.9630, Accuracy: 0.7820\n",
      "---- Training ----\n",
      "Training loss: 132.8038\n",
      "Training acc over epoch: 0.7813\n",
      "---- Validation ----\n",
      "Validation loss: 33.8066\n",
      "Validation acc: 0.7585\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 442.1080, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 425.1679, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 20: 427.2386, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 30: 419.3103, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 401.0291, Accuracy: 0.7990\n",
      "Training loss (for one batch) at step 50: 401.1967, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 60: 416.5771, Accuracy: 0.8052\n",
      "Training loss (for one batch) at step 70: 431.5461, Accuracy: 0.8035\n",
      "Training loss (for one batch) at step 80: 430.7629, Accuracy: 0.7972\n",
      "Training loss (for one batch) at step 90: 433.5750, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 100: 421.1934, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 110: 420.6498, Accuracy: 0.7903\n",
      "---- Training ----\n",
      "Training loss: 136.2521\n",
      "Training acc over epoch: 0.7886\n",
      "---- Validation ----\n",
      "Validation loss: 33.9151\n",
      "Validation acc: 0.7453\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 445.6007, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 434.5505, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 20: 416.1791, Accuracy: 0.7868\n",
      "Training loss (for one batch) at step 30: 415.3777, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 40: 415.8407, Accuracy: 0.7948\n",
      "Training loss (for one batch) at step 50: 400.2796, Accuracy: 0.8028\n",
      "Training loss (for one batch) at step 60: 405.3651, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 70: 427.1664, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 80: 427.1494, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 90: 430.5197, Accuracy: 0.7940\n",
      "Training loss (for one batch) at step 100: 428.9952, Accuracy: 0.7913\n",
      "Training loss (for one batch) at step 110: 433.2081, Accuracy: 0.7891\n",
      "---- Training ----\n",
      "Training loss: 133.3504\n",
      "Training acc over epoch: 0.7897\n",
      "---- Validation ----\n",
      "Validation loss: 33.4010\n",
      "Validation acc: 0.7671\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 432.5450, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 416.5397, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 20: 415.2229, Accuracy: 0.8013\n",
      "Training loss (for one batch) at step 30: 400.2357, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 40: 416.1755, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 50: 399.8019, Accuracy: 0.8163\n",
      "Training loss (for one batch) at step 60: 413.2139, Accuracy: 0.8202\n",
      "Training loss (for one batch) at step 70: 426.6425, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 80: 421.8129, Accuracy: 0.8133\n",
      "Training loss (for one batch) at step 90: 425.2900, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 100: 414.4658, Accuracy: 0.8069\n",
      "Training loss (for one batch) at step 110: 418.2168, Accuracy: 0.8064\n",
      "---- Training ----\n",
      "Training loss: 131.7500\n",
      "Training acc over epoch: 0.8070\n",
      "---- Validation ----\n",
      "Validation loss: 36.6992\n",
      "Validation acc: 0.7644\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 417.8213, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 429.1399, Accuracy: 0.7884\n",
      "Training loss (for one batch) at step 20: 400.9892, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 30: 400.1658, Accuracy: 0.7959\n",
      "Training loss (for one batch) at step 40: 401.2920, Accuracy: 0.8030\n",
      "Training loss (for one batch) at step 50: 398.1836, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 60: 409.4059, Accuracy: 0.8186\n",
      "Training loss (for one batch) at step 70: 424.6918, Accuracy: 0.8184\n",
      "Training loss (for one batch) at step 80: 422.7468, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 90: 413.2729, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 100: 404.9761, Accuracy: 0.8086\n",
      "Training loss (for one batch) at step 110: 408.2427, Accuracy: 0.8062\n",
      "---- Training ----\n",
      "Training loss: 130.6784\n",
      "Training acc over epoch: 0.8045\n",
      "---- Validation ----\n",
      "Validation loss: 36.3801\n",
      "Validation acc: 0.7246\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 424.7510, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 410.2716, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 399.0077, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 30: 405.3253, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 40: 404.5805, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 50: 393.4438, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 60: 395.6612, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 70: 402.5426, Accuracy: 0.8191\n",
      "Training loss (for one batch) at step 80: 414.4609, Accuracy: 0.8167\n",
      "Training loss (for one batch) at step 90: 396.4666, Accuracy: 0.8149\n",
      "Training loss (for one batch) at step 100: 410.0093, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 110: 401.7502, Accuracy: 0.8098\n",
      "---- Training ----\n",
      "Training loss: 130.7227\n",
      "Training acc over epoch: 0.8105\n",
      "---- Validation ----\n",
      "Validation loss: 35.0990\n",
      "Validation acc: 0.7719\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 412.7524, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 410.3804, Accuracy: 0.7919\n",
      "Training loss (for one batch) at step 20: 426.9890, Accuracy: 0.8043\n",
      "Training loss (for one batch) at step 30: 400.5453, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 40: 382.3933, Accuracy: 0.8209\n",
      "Training loss (for one batch) at step 50: 385.9471, Accuracy: 0.8326\n",
      "Training loss (for one batch) at step 60: 385.4199, Accuracy: 0.8361\n",
      "Training loss (for one batch) at step 70: 413.0297, Accuracy: 0.8335\n",
      "Training loss (for one batch) at step 80: 413.2517, Accuracy: 0.8256\n",
      "Training loss (for one batch) at step 90: 415.5193, Accuracy: 0.8227\n",
      "Training loss (for one batch) at step 100: 402.2332, Accuracy: 0.8213\n",
      "Training loss (for one batch) at step 110: 396.7019, Accuracy: 0.8178\n",
      "---- Training ----\n",
      "Training loss: 129.5738\n",
      "Training acc over epoch: 0.8168\n",
      "---- Validation ----\n",
      "Validation loss: 32.6380\n",
      "Validation acc: 0.7649\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 405.2553, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 10: 406.8484, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 20: 397.6289, Accuracy: 0.8099\n",
      "Training loss (for one batch) at step 30: 384.8095, Accuracy: 0.8148\n",
      "Training loss (for one batch) at step 40: 400.4762, Accuracy: 0.8296\n",
      "Training loss (for one batch) at step 50: 393.2048, Accuracy: 0.8347\n",
      "Training loss (for one batch) at step 60: 387.3967, Accuracy: 0.8391\n",
      "Training loss (for one batch) at step 70: 413.9435, Accuracy: 0.8363\n",
      "Training loss (for one batch) at step 80: 414.7874, Accuracy: 0.8314\n",
      "Training loss (for one batch) at step 90: 428.7787, Accuracy: 0.8261\n",
      "Training loss (for one batch) at step 100: 403.3200, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 110: 386.7405, Accuracy: 0.8211\n",
      "---- Training ----\n",
      "Training loss: 122.3929\n",
      "Training acc over epoch: 0.8201\n",
      "---- Validation ----\n",
      "Validation loss: 31.2837\n",
      "Validation acc: 0.7501\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 415.0557, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 394.8669, Accuracy: 0.8082\n",
      "Training loss (for one batch) at step 20: 395.0103, Accuracy: 0.8136\n",
      "Training loss (for one batch) at step 30: 396.4727, Accuracy: 0.8168\n",
      "Training loss (for one batch) at step 40: 382.9949, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 50: 372.0168, Accuracy: 0.8333\n",
      "Training loss (for one batch) at step 60: 396.2020, Accuracy: 0.8388\n",
      "Training loss (for one batch) at step 70: 402.4316, Accuracy: 0.8343\n",
      "Training loss (for one batch) at step 80: 414.9746, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 90: 395.2808, Accuracy: 0.8245\n",
      "Training loss (for one batch) at step 100: 382.2597, Accuracy: 0.8219\n",
      "Training loss (for one batch) at step 110: 384.2177, Accuracy: 0.8193\n",
      "---- Training ----\n",
      "Training loss: 127.9648\n",
      "Training acc over epoch: 0.8186\n",
      "---- Validation ----\n",
      "Validation loss: 40.0977\n",
      "Validation acc: 0.7711\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 408.9376, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 401.1496, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 20: 394.0653, Accuracy: 0.8144\n",
      "Training loss (for one batch) at step 30: 373.9706, Accuracy: 0.8191\n",
      "Training loss (for one batch) at step 40: 399.0892, Accuracy: 0.8287\n",
      "Training loss (for one batch) at step 50: 370.3142, Accuracy: 0.8350\n",
      "Training loss (for one batch) at step 60: 378.9924, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 70: 399.6725, Accuracy: 0.8335\n",
      "Training loss (for one batch) at step 80: 398.0884, Accuracy: 0.8293\n",
      "Training loss (for one batch) at step 90: 385.7201, Accuracy: 0.8268\n",
      "Training loss (for one batch) at step 100: 395.0916, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 110: 392.1619, Accuracy: 0.8266\n",
      "---- Training ----\n",
      "Training loss: 118.5430\n",
      "Training acc over epoch: 0.8266\n",
      "---- Validation ----\n",
      "Validation loss: 32.9269\n",
      "Validation acc: 0.7711\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 402.7177, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 403.7936, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 20: 393.9763, Accuracy: 0.8077\n",
      "Training loss (for one batch) at step 30: 392.7884, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 40: 355.9048, Accuracy: 0.8327\n",
      "Training loss (for one batch) at step 50: 368.5607, Accuracy: 0.8405\n",
      "Training loss (for one batch) at step 60: 388.0942, Accuracy: 0.8431\n",
      "Training loss (for one batch) at step 70: 411.2501, Accuracy: 0.8389\n",
      "Training loss (for one batch) at step 80: 401.3789, Accuracy: 0.8344\n",
      "Training loss (for one batch) at step 90: 388.4499, Accuracy: 0.8291\n",
      "Training loss (for one batch) at step 100: 389.7647, Accuracy: 0.8263\n",
      "Training loss (for one batch) at step 110: 389.2646, Accuracy: 0.8259\n",
      "---- Training ----\n",
      "Training loss: 126.2680\n",
      "Training acc over epoch: 0.8253\n",
      "---- Validation ----\n",
      "Validation loss: 34.1033\n",
      "Validation acc: 0.7636\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 396.7987, Accuracy: 0.8516\n",
      "Training loss (for one batch) at step 10: 393.6672, Accuracy: 0.8026\n",
      "Training loss (for one batch) at step 20: 380.2737, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 30: 375.0907, Accuracy: 0.8208\n",
      "Training loss (for one batch) at step 40: 376.7846, Accuracy: 0.8298\n",
      "Training loss (for one batch) at step 50: 360.9627, Accuracy: 0.8375\n",
      "Training loss (for one batch) at step 60: 378.8727, Accuracy: 0.8405\n",
      "Training loss (for one batch) at step 70: 402.6821, Accuracy: 0.8376\n",
      "Training loss (for one batch) at step 80: 387.0378, Accuracy: 0.8314\n",
      "Training loss (for one batch) at step 90: 382.2458, Accuracy: 0.8278\n",
      "Training loss (for one batch) at step 100: 368.2703, Accuracy: 0.8277\n",
      "Training loss (for one batch) at step 110: 388.8472, Accuracy: 0.8279\n",
      "---- Training ----\n",
      "Training loss: 123.1459\n",
      "Training acc over epoch: 0.8278\n",
      "---- Validation ----\n",
      "Validation loss: 42.4661\n",
      "Validation acc: 0.7781\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 392.5768, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 390.3265, Accuracy: 0.8239\n",
      "Training loss (for one batch) at step 20: 389.9486, Accuracy: 0.8244\n",
      "Training loss (for one batch) at step 30: 383.7916, Accuracy: 0.8284\n",
      "Training loss (for one batch) at step 40: 368.7717, Accuracy: 0.8415\n",
      "Training loss (for one batch) at step 50: 377.6378, Accuracy: 0.8480\n",
      "Training loss (for one batch) at step 60: 391.3907, Accuracy: 0.8516\n",
      "Training loss (for one batch) at step 70: 385.5750, Accuracy: 0.8469\n",
      "Training loss (for one batch) at step 80: 386.6580, Accuracy: 0.8434\n",
      "Training loss (for one batch) at step 90: 396.9062, Accuracy: 0.8404\n",
      "Training loss (for one batch) at step 100: 372.1970, Accuracy: 0.8387\n",
      "Training loss (for one batch) at step 110: 388.6465, Accuracy: 0.8376\n",
      "---- Training ----\n",
      "Training loss: 127.0533\n",
      "Training acc over epoch: 0.8364\n",
      "---- Validation ----\n",
      "Validation loss: 41.4944\n",
      "Validation acc: 0.7649\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 392.3142, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 393.8980, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 20: 389.8522, Accuracy: 0.8181\n",
      "Training loss (for one batch) at step 30: 380.0368, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 40: 358.7833, Accuracy: 0.8378\n",
      "Training loss (for one batch) at step 50: 350.7847, Accuracy: 0.8468\n",
      "Training loss (for one batch) at step 60: 362.3802, Accuracy: 0.8496\n",
      "Training loss (for one batch) at step 70: 392.5903, Accuracy: 0.8426\n",
      "Training loss (for one batch) at step 80: 400.8792, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 90: 384.6849, Accuracy: 0.8341\n",
      "Training loss (for one batch) at step 100: 377.7254, Accuracy: 0.8312\n",
      "Training loss (for one batch) at step 110: 373.4923, Accuracy: 0.8304\n",
      "---- Training ----\n",
      "Training loss: 117.2167\n",
      "Training acc over epoch: 0.8311\n",
      "---- Validation ----\n",
      "Validation loss: 40.1001\n",
      "Validation acc: 0.7598\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 386.8459, Accuracy: 0.8672\n",
      "Training loss (for one batch) at step 10: 369.6188, Accuracy: 0.8303\n",
      "Training loss (for one batch) at step 20: 375.1506, Accuracy: 0.8337\n",
      "Training loss (for one batch) at step 30: 377.0925, Accuracy: 0.8412\n",
      "Training loss (for one batch) at step 40: 348.9965, Accuracy: 0.8514\n",
      "Training loss (for one batch) at step 50: 369.2478, Accuracy: 0.8592\n",
      "Training loss (for one batch) at step 60: 359.7881, Accuracy: 0.8603\n",
      "Training loss (for one batch) at step 70: 380.6511, Accuracy: 0.8529\n",
      "Training loss (for one batch) at step 80: 390.0812, Accuracy: 0.8478\n",
      "Training loss (for one batch) at step 90: 379.5653, Accuracy: 0.8428\n",
      "Training loss (for one batch) at step 100: 371.1362, Accuracy: 0.8401\n",
      "Training loss (for one batch) at step 110: 385.3497, Accuracy: 0.8388\n",
      "---- Training ----\n",
      "Training loss: 123.7490\n",
      "Training acc over epoch: 0.8381\n",
      "---- Validation ----\n",
      "Validation loss: 39.4474\n",
      "Validation acc: 0.7611\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 380.9476, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 382.4921, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 20: 386.0538, Accuracy: 0.8285\n",
      "Training loss (for one batch) at step 30: 362.0705, Accuracy: 0.8387\n",
      "Training loss (for one batch) at step 40: 366.8718, Accuracy: 0.8460\n",
      "Training loss (for one batch) at step 50: 361.2297, Accuracy: 0.8560\n",
      "Training loss (for one batch) at step 60: 362.2020, Accuracy: 0.8584\n",
      "Training loss (for one batch) at step 70: 372.8740, Accuracy: 0.8528\n",
      "Training loss (for one batch) at step 80: 381.9902, Accuracy: 0.8441\n",
      "Training loss (for one batch) at step 90: 375.5284, Accuracy: 0.8425\n",
      "Training loss (for one batch) at step 100: 366.7836, Accuracy: 0.8418\n",
      "Training loss (for one batch) at step 110: 383.2046, Accuracy: 0.8397\n",
      "---- Training ----\n",
      "Training loss: 123.3080\n",
      "Training acc over epoch: 0.8386\n",
      "---- Validation ----\n",
      "Validation loss: 35.9508\n",
      "Validation acc: 0.7630\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 382.9969, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 382.6957, Accuracy: 0.8068\n",
      "Training loss (for one batch) at step 20: 358.0329, Accuracy: 0.8285\n",
      "Training loss (for one batch) at step 30: 355.8803, Accuracy: 0.8453\n",
      "Training loss (for one batch) at step 40: 364.3448, Accuracy: 0.8537\n",
      "Training loss (for one batch) at step 50: 351.0244, Accuracy: 0.8586\n",
      "Training loss (for one batch) at step 60: 382.0103, Accuracy: 0.8630\n",
      "Training loss (for one batch) at step 70: 393.6530, Accuracy: 0.8549\n",
      "Training loss (for one batch) at step 80: 390.2086, Accuracy: 0.8459\n",
      "Training loss (for one batch) at step 90: 368.2956, Accuracy: 0.8427\n",
      "Training loss (for one batch) at step 100: 353.7420, Accuracy: 0.8409\n",
      "Training loss (for one batch) at step 110: 368.2830, Accuracy: 0.8393\n",
      "---- Training ----\n",
      "Training loss: 115.0822\n",
      "Training acc over epoch: 0.8384\n",
      "---- Validation ----\n",
      "Validation loss: 31.2930\n",
      "Validation acc: 0.7684\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 391.7481, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 10: 372.6668, Accuracy: 0.8239\n",
      "Training loss (for one batch) at step 20: 378.4485, Accuracy: 0.8307\n",
      "Training loss (for one batch) at step 30: 371.2223, Accuracy: 0.8387\n",
      "Training loss (for one batch) at step 40: 364.0553, Accuracy: 0.8485\n",
      "Training loss (for one batch) at step 50: 350.4016, Accuracy: 0.8551\n",
      "Training loss (for one batch) at step 60: 359.4536, Accuracy: 0.8600\n",
      "Training loss (for one batch) at step 70: 376.8423, Accuracy: 0.8513\n",
      "Training loss (for one batch) at step 80: 394.7859, Accuracy: 0.8439\n",
      "Training loss (for one batch) at step 90: 367.5368, Accuracy: 0.8413\n",
      "Training loss (for one batch) at step 100: 361.1026, Accuracy: 0.8408\n",
      "Training loss (for one batch) at step 110: 375.2013, Accuracy: 0.8397\n",
      "---- Training ----\n",
      "Training loss: 112.7874\n",
      "Training acc over epoch: 0.8377\n",
      "---- Validation ----\n",
      "Validation loss: 37.7004\n",
      "Validation acc: 0.7469\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 379.1282, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 373.3640, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 20: 360.6235, Accuracy: 0.8248\n",
      "Training loss (for one batch) at step 30: 350.0216, Accuracy: 0.8337\n",
      "Training loss (for one batch) at step 40: 349.2468, Accuracy: 0.8466\n",
      "Training loss (for one batch) at step 50: 339.6324, Accuracy: 0.8536\n",
      "Training loss (for one batch) at step 60: 355.3071, Accuracy: 0.8557\n",
      "Training loss (for one batch) at step 70: 367.6827, Accuracy: 0.8526\n",
      "Training loss (for one batch) at step 80: 386.1866, Accuracy: 0.8445\n",
      "Training loss (for one batch) at step 90: 373.5858, Accuracy: 0.8406\n",
      "Training loss (for one batch) at step 100: 376.0596, Accuracy: 0.8396\n",
      "Training loss (for one batch) at step 110: 376.9360, Accuracy: 0.8390\n",
      "---- Training ----\n",
      "Training loss: 108.2969\n",
      "Training acc over epoch: 0.8377\n",
      "---- Validation ----\n",
      "Validation loss: 31.5328\n",
      "Validation acc: 0.7504\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 375.6254, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 388.9916, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 20: 371.1815, Accuracy: 0.8411\n",
      "Training loss (for one batch) at step 30: 354.3414, Accuracy: 0.8440\n",
      "Training loss (for one batch) at step 40: 353.6313, Accuracy: 0.8521\n",
      "Training loss (for one batch) at step 50: 349.5375, Accuracy: 0.8609\n",
      "Training loss (for one batch) at step 60: 359.3121, Accuracy: 0.8631\n",
      "Training loss (for one batch) at step 70: 377.7501, Accuracy: 0.8571\n",
      "Training loss (for one batch) at step 80: 361.3000, Accuracy: 0.8498\n",
      "Training loss (for one batch) at step 90: 370.5185, Accuracy: 0.8454\n",
      "Training loss (for one batch) at step 100: 366.5697, Accuracy: 0.8455\n",
      "Training loss (for one batch) at step 110: 354.5879, Accuracy: 0.8446\n",
      "---- Training ----\n",
      "Training loss: 119.0653\n",
      "Training acc over epoch: 0.8428\n",
      "---- Validation ----\n",
      "Validation loss: 38.1267\n",
      "Validation acc: 0.7614\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 375.9584, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 10: 368.1996, Accuracy: 0.8246\n",
      "Training loss (for one batch) at step 20: 362.2322, Accuracy: 0.8382\n",
      "Training loss (for one batch) at step 30: 369.7391, Accuracy: 0.8425\n",
      "Training loss (for one batch) at step 40: 353.6869, Accuracy: 0.8476\n",
      "Training loss (for one batch) at step 50: 347.1947, Accuracy: 0.8580\n",
      "Training loss (for one batch) at step 60: 363.8746, Accuracy: 0.8617\n",
      "Training loss (for one batch) at step 70: 350.7074, Accuracy: 0.8563\n",
      "Training loss (for one batch) at step 80: 367.2792, Accuracy: 0.8493\n",
      "Training loss (for one batch) at step 90: 351.5147, Accuracy: 0.8473\n",
      "Training loss (for one batch) at step 100: 358.2139, Accuracy: 0.8456\n",
      "Training loss (for one batch) at step 110: 350.3343, Accuracy: 0.8459\n",
      "---- Training ----\n",
      "Training loss: 110.1141\n",
      "Training acc over epoch: 0.8444\n",
      "---- Validation ----\n",
      "Validation loss: 46.2217\n",
      "Validation acc: 0.7552\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 375.4164, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 367.8508, Accuracy: 0.8026\n",
      "Training loss (for one batch) at step 20: 342.0912, Accuracy: 0.8296\n",
      "Training loss (for one batch) at step 30: 339.1462, Accuracy: 0.8432\n",
      "Training loss (for one batch) at step 40: 354.0407, Accuracy: 0.8544\n",
      "Training loss (for one batch) at step 50: 351.3028, Accuracy: 0.8638\n",
      "Training loss (for one batch) at step 60: 357.4843, Accuracy: 0.8662\n",
      "Training loss (for one batch) at step 70: 371.5446, Accuracy: 0.8598\n",
      "Training loss (for one batch) at step 80: 378.2800, Accuracy: 0.8515\n",
      "Training loss (for one batch) at step 90: 349.9146, Accuracy: 0.8499\n",
      "Training loss (for one batch) at step 100: 352.7438, Accuracy: 0.8478\n",
      "Training loss (for one batch) at step 110: 349.6933, Accuracy: 0.8478\n",
      "---- Training ----\n",
      "Training loss: 109.9256\n",
      "Training acc over epoch: 0.8462\n",
      "---- Validation ----\n",
      "Validation loss: 38.8344\n",
      "Validation acc: 0.7332\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 374.3260, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 356.8749, Accuracy: 0.8153\n",
      "Training loss (for one batch) at step 20: 345.9991, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 30: 347.8580, Accuracy: 0.8417\n",
      "Training loss (for one batch) at step 40: 340.2466, Accuracy: 0.8529\n",
      "Training loss (for one batch) at step 50: 346.1340, Accuracy: 0.8600\n",
      "Training loss (for one batch) at step 60: 352.4117, Accuracy: 0.8623\n",
      "Training loss (for one batch) at step 70: 356.2738, Accuracy: 0.8587\n",
      "Training loss (for one batch) at step 80: 390.8767, Accuracy: 0.8512\n",
      "Training loss (for one batch) at step 90: 343.5359, Accuracy: 0.8501\n",
      "Training loss (for one batch) at step 100: 351.9276, Accuracy: 0.8494\n",
      "Training loss (for one batch) at step 110: 345.0393, Accuracy: 0.8485\n",
      "---- Training ----\n",
      "Training loss: 107.8993\n",
      "Training acc over epoch: 0.8490\n",
      "---- Validation ----\n",
      "Validation loss: 43.2974\n",
      "Validation acc: 0.7638\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 390.6665, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 352.9126, Accuracy: 0.8217\n",
      "Training loss (for one batch) at step 20: 354.9232, Accuracy: 0.8367\n",
      "Training loss (for one batch) at step 30: 344.7161, Accuracy: 0.8450\n",
      "Training loss (for one batch) at step 40: 345.2814, Accuracy: 0.8567\n",
      "Training loss (for one batch) at step 50: 335.0560, Accuracy: 0.8629\n",
      "Training loss (for one batch) at step 60: 366.8808, Accuracy: 0.8641\n",
      "Training loss (for one batch) at step 70: 382.0634, Accuracy: 0.8600\n",
      "Training loss (for one batch) at step 80: 379.9913, Accuracy: 0.8513\n",
      "Training loss (for one batch) at step 90: 352.3785, Accuracy: 0.8475\n",
      "Training loss (for one batch) at step 100: 349.7216, Accuracy: 0.8484\n",
      "Training loss (for one batch) at step 110: 353.5747, Accuracy: 0.8463\n",
      "---- Training ----\n",
      "Training loss: 115.6534\n",
      "Training acc over epoch: 0.8456\n",
      "---- Validation ----\n",
      "Validation loss: 49.8075\n",
      "Validation acc: 0.7577\n",
      "Time taken: 10.84s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 386.5121, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 368.5883, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 20: 350.2272, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 30: 345.5588, Accuracy: 0.8395\n",
      "Training loss (for one batch) at step 40: 364.9007, Accuracy: 0.8512\n",
      "Training loss (for one batch) at step 50: 342.1631, Accuracy: 0.8591\n",
      "Training loss (for one batch) at step 60: 347.3120, Accuracy: 0.8617\n",
      "Training loss (for one batch) at step 70: 343.0633, Accuracy: 0.8596\n",
      "Training loss (for one batch) at step 80: 376.8568, Accuracy: 0.8507\n",
      "Training loss (for one batch) at step 90: 358.6897, Accuracy: 0.8486\n",
      "Training loss (for one batch) at step 100: 344.6240, Accuracy: 0.8485\n",
      "Training loss (for one batch) at step 110: 353.1023, Accuracy: 0.8485\n",
      "---- Training ----\n",
      "Training loss: 128.8139\n",
      "Training acc over epoch: 0.8472\n",
      "---- Validation ----\n",
      "Validation loss: 41.5670\n",
      "Validation acc: 0.7582\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 365.4588, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 361.8736, Accuracy: 0.8189\n",
      "Training loss (for one batch) at step 20: 358.3099, Accuracy: 0.8311\n",
      "Training loss (for one batch) at step 30: 345.1512, Accuracy: 0.8475\n",
      "Training loss (for one batch) at step 40: 356.8012, Accuracy: 0.8563\n",
      "Training loss (for one batch) at step 50: 331.4374, Accuracy: 0.8660\n",
      "Training loss (for one batch) at step 60: 341.1949, Accuracy: 0.8673\n",
      "Training loss (for one batch) at step 70: 353.7622, Accuracy: 0.8612\n",
      "Training loss (for one batch) at step 80: 387.2369, Accuracy: 0.8546\n",
      "Training loss (for one batch) at step 90: 356.1570, Accuracy: 0.8501\n",
      "Training loss (for one batch) at step 100: 355.9800, Accuracy: 0.8501\n",
      "Training loss (for one batch) at step 110: 362.7710, Accuracy: 0.8502\n",
      "---- Training ----\n",
      "Training loss: 107.1425\n",
      "Training acc over epoch: 0.8484\n",
      "---- Validation ----\n",
      "Validation loss: 34.9336\n",
      "Validation acc: 0.7628\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 386.0348, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 10: 354.9663, Accuracy: 0.8239\n",
      "Training loss (for one batch) at step 20: 347.3344, Accuracy: 0.8367\n",
      "Training loss (for one batch) at step 30: 341.2388, Accuracy: 0.8478\n",
      "Training loss (for one batch) at step 40: 343.4980, Accuracy: 0.8537\n",
      "Training loss (for one batch) at step 50: 358.5620, Accuracy: 0.8612\n",
      "Training loss (for one batch) at step 60: 338.2967, Accuracy: 0.8659\n",
      "Training loss (for one batch) at step 70: 360.4535, Accuracy: 0.8632\n",
      "Training loss (for one batch) at step 80: 363.7658, Accuracy: 0.8543\n",
      "Training loss (for one batch) at step 90: 342.0231, Accuracy: 0.8510\n",
      "Training loss (for one batch) at step 100: 337.8848, Accuracy: 0.8510\n",
      "Training loss (for one batch) at step 110: 362.2370, Accuracy: 0.8496\n",
      "---- Training ----\n",
      "Training loss: 109.2022\n",
      "Training acc over epoch: 0.8484\n",
      "---- Validation ----\n",
      "Validation loss: 46.5572\n",
      "Validation acc: 0.7614\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 360.0818, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 362.2348, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 20: 363.6738, Accuracy: 0.8352\n",
      "Training loss (for one batch) at step 30: 350.5211, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 40: 358.3633, Accuracy: 0.8548\n",
      "Training loss (for one batch) at step 50: 343.9188, Accuracy: 0.8666\n",
      "Training loss (for one batch) at step 60: 332.0234, Accuracy: 0.8672\n",
      "Training loss (for one batch) at step 70: 356.7633, Accuracy: 0.8620\n",
      "Training loss (for one batch) at step 80: 354.3286, Accuracy: 0.8542\n",
      "Training loss (for one batch) at step 90: 345.0740, Accuracy: 0.8511\n",
      "Training loss (for one batch) at step 100: 344.3333, Accuracy: 0.8496\n",
      "Training loss (for one batch) at step 110: 340.9019, Accuracy: 0.8482\n",
      "---- Training ----\n",
      "Training loss: 114.8462\n",
      "Training acc over epoch: 0.8469\n",
      "---- Validation ----\n",
      "Validation loss: 56.7382\n",
      "Validation acc: 0.7665\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 353.3645, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 355.9552, Accuracy: 0.8139\n",
      "Training loss (for one batch) at step 20: 341.0597, Accuracy: 0.8300\n",
      "Training loss (for one batch) at step 30: 348.2498, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 40: 336.1133, Accuracy: 0.8579\n",
      "Training loss (for one batch) at step 50: 323.7624, Accuracy: 0.8663\n",
      "Training loss (for one batch) at step 60: 346.6311, Accuracy: 0.8686\n",
      "Training loss (for one batch) at step 70: 371.6722, Accuracy: 0.8618\n",
      "Training loss (for one batch) at step 80: 348.2543, Accuracy: 0.8533\n",
      "Training loss (for one batch) at step 90: 347.0063, Accuracy: 0.8502\n",
      "Training loss (for one batch) at step 100: 342.9485, Accuracy: 0.8481\n",
      "Training loss (for one batch) at step 110: 352.4227, Accuracy: 0.8476\n",
      "---- Training ----\n",
      "Training loss: 121.5441\n",
      "Training acc over epoch: 0.8463\n",
      "---- Validation ----\n",
      "Validation loss: 43.3207\n",
      "Validation acc: 0.7732\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 376.4125, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 357.1723, Accuracy: 0.8359\n",
      "Training loss (for one batch) at step 20: 355.2087, Accuracy: 0.8497\n",
      "Training loss (for one batch) at step 30: 330.6689, Accuracy: 0.8579\n",
      "Training loss (for one batch) at step 40: 322.0761, Accuracy: 0.8630\n",
      "Training loss (for one batch) at step 50: 336.6513, Accuracy: 0.8692\n",
      "Training loss (for one batch) at step 60: 348.2727, Accuracy: 0.8735\n",
      "Training loss (for one batch) at step 70: 346.9502, Accuracy: 0.8658\n",
      "Training loss (for one batch) at step 80: 365.2053, Accuracy: 0.8562\n",
      "Training loss (for one batch) at step 90: 361.6812, Accuracy: 0.8520\n",
      "Training loss (for one batch) at step 100: 349.8097, Accuracy: 0.8509\n",
      "Training loss (for one batch) at step 110: 337.7488, Accuracy: 0.8502\n",
      "---- Training ----\n",
      "Training loss: 104.8600\n",
      "Training acc over epoch: 0.8499\n",
      "---- Validation ----\n",
      "Validation loss: 31.8564\n",
      "Validation acc: 0.7622\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 351.0446, Accuracy: 0.8516\n",
      "Training loss (for one batch) at step 10: 361.6352, Accuracy: 0.8196\n",
      "Training loss (for one batch) at step 20: 344.3096, Accuracy: 0.8385\n",
      "Training loss (for one batch) at step 30: 328.7316, Accuracy: 0.8473\n",
      "Training loss (for one batch) at step 40: 338.5651, Accuracy: 0.8605\n",
      "Training loss (for one batch) at step 50: 340.5075, Accuracy: 0.8670\n",
      "Training loss (for one batch) at step 60: 340.0349, Accuracy: 0.8703\n",
      "Training loss (for one batch) at step 70: 344.2502, Accuracy: 0.8636\n",
      "Training loss (for one batch) at step 80: 368.4569, Accuracy: 0.8566\n",
      "Training loss (for one batch) at step 90: 347.6371, Accuracy: 0.8529\n",
      "Training loss (for one batch) at step 100: 341.2469, Accuracy: 0.8521\n",
      "Training loss (for one batch) at step 110: 345.3603, Accuracy: 0.8510\n",
      "---- Training ----\n",
      "Training loss: 110.0291\n",
      "Training acc over epoch: 0.8504\n",
      "---- Validation ----\n",
      "Validation loss: 35.5194\n",
      "Validation acc: 0.7644\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 376.0366, Accuracy: 0.8828\n",
      "Training loss (for one batch) at step 10: 358.2834, Accuracy: 0.8338\n",
      "Training loss (for one batch) at step 20: 332.9673, Accuracy: 0.8449\n",
      "Training loss (for one batch) at step 30: 332.5939, Accuracy: 0.8548\n",
      "Training loss (for one batch) at step 40: 326.6317, Accuracy: 0.8636\n",
      "Training loss (for one batch) at step 50: 323.7401, Accuracy: 0.8706\n",
      "Training loss (for one batch) at step 60: 335.8185, Accuracy: 0.8728\n",
      "Training loss (for one batch) at step 70: 346.9380, Accuracy: 0.8661\n",
      "Training loss (for one batch) at step 80: 339.9149, Accuracy: 0.8600\n",
      "Training loss (for one batch) at step 90: 342.0901, Accuracy: 0.8569\n",
      "Training loss (for one batch) at step 100: 349.1008, Accuracy: 0.8558\n",
      "Training loss (for one batch) at step 110: 345.4320, Accuracy: 0.8544\n",
      "---- Training ----\n",
      "Training loss: 110.3438\n",
      "Training acc over epoch: 0.8535\n",
      "---- Validation ----\n",
      "Validation loss: 57.6181\n",
      "Validation acc: 0.7614\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 350.7573, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 338.8723, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 20: 331.7487, Accuracy: 0.8326\n",
      "Training loss (for one batch) at step 30: 339.1910, Accuracy: 0.8463\n",
      "Training loss (for one batch) at step 40: 336.0369, Accuracy: 0.8542\n",
      "Training loss (for one batch) at step 50: 336.6347, Accuracy: 0.8631\n",
      "Training loss (for one batch) at step 60: 333.3742, Accuracy: 0.8676\n",
      "Training loss (for one batch) at step 70: 348.4042, Accuracy: 0.8616\n",
      "Training loss (for one batch) at step 80: 352.3759, Accuracy: 0.8519\n",
      "Training loss (for one batch) at step 90: 327.6336, Accuracy: 0.8505\n",
      "Training loss (for one batch) at step 100: 336.1948, Accuracy: 0.8506\n",
      "Training loss (for one batch) at step 110: 339.8530, Accuracy: 0.8498\n",
      "---- Training ----\n",
      "Training loss: 110.5882\n",
      "Training acc over epoch: 0.8487\n",
      "---- Validation ----\n",
      "Validation loss: 42.6761\n",
      "Validation acc: 0.7563\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 358.7021, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 353.0616, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 20: 335.5574, Accuracy: 0.8475\n",
      "Training loss (for one batch) at step 30: 326.8549, Accuracy: 0.8501\n",
      "Training loss (for one batch) at step 40: 334.6132, Accuracy: 0.8598\n",
      "Training loss (for one batch) at step 50: 327.5682, Accuracy: 0.8701\n",
      "Training loss (for one batch) at step 60: 346.0890, Accuracy: 0.8728\n",
      "Training loss (for one batch) at step 70: 346.5307, Accuracy: 0.8665\n",
      "Training loss (for one batch) at step 80: 351.8607, Accuracy: 0.8609\n",
      "Training loss (for one batch) at step 90: 331.9459, Accuracy: 0.8580\n",
      "Training loss (for one batch) at step 100: 357.9585, Accuracy: 0.8568\n",
      "Training loss (for one batch) at step 110: 347.6006, Accuracy: 0.8550\n",
      "---- Training ----\n",
      "Training loss: 122.2216\n",
      "Training acc over epoch: 0.8548\n",
      "---- Validation ----\n",
      "Validation loss: 43.7873\n",
      "Validation acc: 0.7617\n",
      "Time taken: 10.18s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7724\n",
      "Validation AUC: 0.7735\n",
      "Validation Balanced_ACC: 0.5099\n",
      "Validation AUCSK: 0.8362\n",
      "Validation MI: 0.1413\n",
      "Validation Normalized MI: 0.2057\n",
      "Validation Adjusted MI: 0.2057\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 627.0288, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 611.8431, Accuracy: 0.4709\n",
      "Training loss (for one batch) at step 20: 535.9321, Accuracy: 0.4918\n",
      "Training loss (for one batch) at step 30: 553.5740, Accuracy: 0.4957\n",
      "Training loss (for one batch) at step 40: 488.4061, Accuracy: 0.5008\n",
      "Training loss (for one batch) at step 50: 507.6210, Accuracy: 0.5074\n",
      "Training loss (for one batch) at step 60: 481.7278, Accuracy: 0.5028\n",
      "Training loss (for one batch) at step 70: 484.8870, Accuracy: 0.5040\n",
      "Training loss (for one batch) at step 80: 460.7573, Accuracy: 0.5062\n",
      "Training loss (for one batch) at step 90: 468.0842, Accuracy: 0.5050\n",
      "Training loss (for one batch) at step 100: 470.1277, Accuracy: 0.5052\n",
      "Training loss (for one batch) at step 110: 464.5655, Accuracy: 0.5056\n",
      "---- Training ----\n",
      "Training loss: 147.6303\n",
      "Training acc over epoch: 0.5061\n",
      "---- Validation ----\n",
      "Validation loss: 35.7356\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.52s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 466.8600, Accuracy: 0.4688\n",
      "Training loss (for one batch) at step 10: 457.6859, Accuracy: 0.5355\n",
      "Training loss (for one batch) at step 20: 456.7743, Accuracy: 0.5219\n",
      "Training loss (for one batch) at step 30: 463.4120, Accuracy: 0.5179\n",
      "Training loss (for one batch) at step 40: 451.9248, Accuracy: 0.5141\n",
      "Training loss (for one batch) at step 50: 451.2728, Accuracy: 0.5106\n",
      "Training loss (for one batch) at step 60: 452.8672, Accuracy: 0.5138\n",
      "Training loss (for one batch) at step 70: 452.1288, Accuracy: 0.5178\n",
      "Training loss (for one batch) at step 80: 449.4522, Accuracy: 0.5184\n",
      "Training loss (for one batch) at step 90: 448.5727, Accuracy: 0.5201\n",
      "Training loss (for one batch) at step 100: 449.4963, Accuracy: 0.5225\n",
      "Training loss (for one batch) at step 110: 444.8429, Accuracy: 0.5199\n",
      "---- Training ----\n",
      "Training loss: 141.0858\n",
      "Training acc over epoch: 0.5210\n",
      "---- Validation ----\n",
      "Validation loss: 34.4043\n",
      "Validation acc: 0.5137\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 448.9494, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 448.2864, Accuracy: 0.5518\n",
      "Training loss (for one batch) at step 20: 444.2178, Accuracy: 0.5461\n",
      "Training loss (for one batch) at step 30: 444.3619, Accuracy: 0.5474\n",
      "Training loss (for one batch) at step 40: 443.6674, Accuracy: 0.5446\n",
      "Training loss (for one batch) at step 50: 443.6953, Accuracy: 0.5437\n",
      "Training loss (for one batch) at step 60: 442.4837, Accuracy: 0.5452\n",
      "Training loss (for one batch) at step 70: 446.3774, Accuracy: 0.5456\n",
      "Training loss (for one batch) at step 80: 443.5836, Accuracy: 0.5474\n",
      "Training loss (for one batch) at step 90: 445.8774, Accuracy: 0.5452\n",
      "Training loss (for one batch) at step 100: 446.7261, Accuracy: 0.5449\n",
      "Training loss (for one batch) at step 110: 443.9117, Accuracy: 0.5440\n",
      "---- Training ----\n",
      "Training loss: 139.3592\n",
      "Training acc over epoch: 0.5437\n",
      "---- Validation ----\n",
      "Validation loss: 34.4125\n",
      "Validation acc: 0.5427\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 442.7534, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 443.2733, Accuracy: 0.5483\n",
      "Training loss (for one batch) at step 20: 440.1491, Accuracy: 0.5458\n",
      "Training loss (for one batch) at step 30: 443.8102, Accuracy: 0.5408\n",
      "Training loss (for one batch) at step 40: 444.2669, Accuracy: 0.5450\n",
      "Training loss (for one batch) at step 50: 444.5629, Accuracy: 0.5470\n",
      "Training loss (for one batch) at step 60: 443.2068, Accuracy: 0.5506\n",
      "Training loss (for one batch) at step 70: 444.6683, Accuracy: 0.5542\n",
      "Training loss (for one batch) at step 80: 443.7274, Accuracy: 0.5548\n",
      "Training loss (for one batch) at step 90: 444.9204, Accuracy: 0.5517\n",
      "Training loss (for one batch) at step 100: 445.0132, Accuracy: 0.5508\n",
      "Training loss (for one batch) at step 110: 442.9288, Accuracy: 0.5505\n",
      "---- Training ----\n",
      "Training loss: 138.9086\n",
      "Training acc over epoch: 0.5503\n",
      "---- Validation ----\n",
      "Validation loss: 34.7459\n",
      "Validation acc: 0.5672\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 445.0954, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 443.3996, Accuracy: 0.5739\n",
      "Training loss (for one batch) at step 20: 442.0522, Accuracy: 0.5722\n",
      "Training loss (for one batch) at step 30: 442.1922, Accuracy: 0.5706\n",
      "Training loss (for one batch) at step 40: 442.1218, Accuracy: 0.5776\n",
      "Training loss (for one batch) at step 50: 439.9312, Accuracy: 0.5833\n",
      "Training loss (for one batch) at step 60: 435.6932, Accuracy: 0.5836\n",
      "Training loss (for one batch) at step 70: 445.5844, Accuracy: 0.5878\n",
      "Training loss (for one batch) at step 80: 445.9976, Accuracy: 0.5880\n",
      "Training loss (for one batch) at step 90: 442.0354, Accuracy: 0.5835\n",
      "Training loss (for one batch) at step 100: 441.7951, Accuracy: 0.5791\n",
      "Training loss (for one batch) at step 110: 441.8057, Accuracy: 0.5793\n",
      "---- Training ----\n",
      "Training loss: 139.3075\n",
      "Training acc over epoch: 0.5787\n",
      "---- Validation ----\n",
      "Validation loss: 34.8654\n",
      "Validation acc: 0.5750\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 446.0326, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 442.3128, Accuracy: 0.5618\n",
      "Training loss (for one batch) at step 20: 439.2586, Accuracy: 0.5722\n",
      "Training loss (for one batch) at step 30: 438.5926, Accuracy: 0.5743\n",
      "Training loss (for one batch) at step 40: 436.4618, Accuracy: 0.5810\n",
      "Training loss (for one batch) at step 50: 442.0106, Accuracy: 0.5908\n",
      "Training loss (for one batch) at step 60: 440.5248, Accuracy: 0.5927\n",
      "Training loss (for one batch) at step 70: 444.1127, Accuracy: 0.5945\n",
      "Training loss (for one batch) at step 80: 440.5867, Accuracy: 0.5901\n",
      "Training loss (for one batch) at step 90: 434.9597, Accuracy: 0.5907\n",
      "Training loss (for one batch) at step 100: 442.0356, Accuracy: 0.5902\n",
      "Training loss (for one batch) at step 110: 446.3393, Accuracy: 0.5907\n",
      "---- Training ----\n",
      "Training loss: 136.8158\n",
      "Training acc over epoch: 0.5903\n",
      "---- Validation ----\n",
      "Validation loss: 34.2908\n",
      "Validation acc: 0.5881\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 440.7766, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 443.7752, Accuracy: 0.5803\n",
      "Training loss (for one batch) at step 20: 440.8430, Accuracy: 0.5480\n",
      "Training loss (for one batch) at step 30: 439.8218, Accuracy: 0.5549\n",
      "Training loss (for one batch) at step 40: 441.2098, Accuracy: 0.5736\n",
      "Training loss (for one batch) at step 50: 436.4968, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 60: 439.1250, Accuracy: 0.5941\n",
      "Training loss (for one batch) at step 70: 443.9104, Accuracy: 0.5939\n",
      "Training loss (for one batch) at step 80: 441.5544, Accuracy: 0.5934\n",
      "Training loss (for one batch) at step 90: 439.2307, Accuracy: 0.5909\n",
      "Training loss (for one batch) at step 100: 441.5032, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 110: 441.8798, Accuracy: 0.5909\n",
      "---- Training ----\n",
      "Training loss: 137.6078\n",
      "Training acc over epoch: 0.5907\n",
      "---- Validation ----\n",
      "Validation loss: 34.8074\n",
      "Validation acc: 0.6131\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 442.7619, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 443.3518, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 20: 442.1510, Accuracy: 0.5852\n",
      "Training loss (for one batch) at step 30: 436.0279, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 40: 439.2319, Accuracy: 0.5968\n",
      "Training loss (for one batch) at step 50: 429.0105, Accuracy: 0.6037\n",
      "Training loss (for one batch) at step 60: 443.1531, Accuracy: 0.6110\n",
      "Training loss (for one batch) at step 70: 445.0209, Accuracy: 0.6142\n",
      "Training loss (for one batch) at step 80: 443.0204, Accuracy: 0.6108\n",
      "Training loss (for one batch) at step 90: 442.5927, Accuracy: 0.6057\n",
      "Training loss (for one batch) at step 100: 437.9388, Accuracy: 0.6010\n",
      "Training loss (for one batch) at step 110: 440.6323, Accuracy: 0.6003\n",
      "---- Training ----\n",
      "Training loss: 137.2412\n",
      "Training acc over epoch: 0.6025\n",
      "---- Validation ----\n",
      "Validation loss: 34.5365\n",
      "Validation acc: 0.5798\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 440.7765, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 441.9011, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 20: 437.5680, Accuracy: 0.5707\n",
      "Training loss (for one batch) at step 30: 445.9454, Accuracy: 0.5885\n",
      "Training loss (for one batch) at step 40: 432.4304, Accuracy: 0.5939\n",
      "Training loss (for one batch) at step 50: 432.1983, Accuracy: 0.6029\n",
      "Training loss (for one batch) at step 60: 442.3739, Accuracy: 0.6095\n",
      "Training loss (for one batch) at step 70: 439.0746, Accuracy: 0.6139\n",
      "Training loss (for one batch) at step 80: 437.8587, Accuracy: 0.6121\n",
      "Training loss (for one batch) at step 90: 436.5970, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 100: 444.7784, Accuracy: 0.6056\n",
      "Training loss (for one batch) at step 110: 436.2013, Accuracy: 0.6065\n",
      "---- Training ----\n",
      "Training loss: 135.7619\n",
      "Training acc over epoch: 0.6039\n",
      "---- Validation ----\n",
      "Validation loss: 34.3633\n",
      "Validation acc: 0.5817\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 442.4809, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 444.0975, Accuracy: 0.5653\n",
      "Training loss (for one batch) at step 20: 440.1427, Accuracy: 0.5707\n",
      "Training loss (for one batch) at step 30: 433.3377, Accuracy: 0.5759\n",
      "Training loss (for one batch) at step 40: 435.1284, Accuracy: 0.5890\n",
      "Training loss (for one batch) at step 50: 423.8377, Accuracy: 0.6002\n",
      "Training loss (for one batch) at step 60: 433.6888, Accuracy: 0.6063\n",
      "Training loss (for one batch) at step 70: 436.0523, Accuracy: 0.6071\n",
      "Training loss (for one batch) at step 80: 434.9543, Accuracy: 0.6037\n",
      "Training loss (for one batch) at step 90: 442.9986, Accuracy: 0.5989\n",
      "Training loss (for one batch) at step 100: 434.4283, Accuracy: 0.5972\n",
      "Training loss (for one batch) at step 110: 436.0654, Accuracy: 0.6002\n",
      "---- Training ----\n",
      "Training loss: 139.3666\n",
      "Training acc over epoch: 0.5999\n",
      "---- Validation ----\n",
      "Validation loss: 34.3219\n",
      "Validation acc: 0.5720\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 438.6534, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 435.7595, Accuracy: 0.5838\n",
      "Training loss (for one batch) at step 20: 441.2502, Accuracy: 0.5755\n",
      "Training loss (for one batch) at step 30: 436.4180, Accuracy: 0.5880\n",
      "Training loss (for one batch) at step 40: 436.8427, Accuracy: 0.6002\n",
      "Training loss (for one batch) at step 50: 434.7435, Accuracy: 0.6060\n",
      "Training loss (for one batch) at step 60: 435.5589, Accuracy: 0.6126\n",
      "Training loss (for one batch) at step 70: 441.2727, Accuracy: 0.6155\n",
      "Training loss (for one batch) at step 80: 434.8742, Accuracy: 0.6138\n",
      "Training loss (for one batch) at step 90: 429.4821, Accuracy: 0.6088\n",
      "Training loss (for one batch) at step 100: 431.3131, Accuracy: 0.6055\n",
      "Training loss (for one batch) at step 110: 444.0789, Accuracy: 0.6063\n",
      "---- Training ----\n",
      "Training loss: 136.3408\n",
      "Training acc over epoch: 0.6075\n",
      "---- Validation ----\n",
      "Validation loss: 34.4904\n",
      "Validation acc: 0.5580\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 442.6389, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 433.4144, Accuracy: 0.5724\n",
      "Training loss (for one batch) at step 20: 437.4420, Accuracy: 0.5755\n",
      "Training loss (for one batch) at step 30: 439.6962, Accuracy: 0.5819\n",
      "Training loss (for one batch) at step 40: 428.8181, Accuracy: 0.5974\n",
      "Training loss (for one batch) at step 50: 436.1380, Accuracy: 0.6072\n",
      "Training loss (for one batch) at step 60: 434.2869, Accuracy: 0.6146\n",
      "Training loss (for one batch) at step 70: 439.3554, Accuracy: 0.6160\n",
      "Training loss (for one batch) at step 80: 443.8708, Accuracy: 0.6154\n",
      "Training loss (for one batch) at step 90: 431.5395, Accuracy: 0.6137\n",
      "Training loss (for one batch) at step 100: 432.2628, Accuracy: 0.6144\n",
      "Training loss (for one batch) at step 110: 433.4343, Accuracy: 0.6151\n",
      "---- Training ----\n",
      "Training loss: 131.8805\n",
      "Training acc over epoch: 0.6159\n",
      "---- Validation ----\n",
      "Validation loss: 35.5300\n",
      "Validation acc: 0.6053\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 441.2470, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 433.5499, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 20: 435.7743, Accuracy: 0.6120\n",
      "Training loss (for one batch) at step 30: 432.1036, Accuracy: 0.6167\n",
      "Training loss (for one batch) at step 40: 427.6494, Accuracy: 0.6277\n",
      "Training loss (for one batch) at step 50: 420.7946, Accuracy: 0.6299\n",
      "Training loss (for one batch) at step 60: 421.1548, Accuracy: 0.6416\n",
      "Training loss (for one batch) at step 70: 436.4356, Accuracy: 0.6425\n",
      "Training loss (for one batch) at step 80: 440.7087, Accuracy: 0.6358\n",
      "Training loss (for one batch) at step 90: 435.0588, Accuracy: 0.6315\n",
      "Training loss (for one batch) at step 100: 421.8042, Accuracy: 0.6310\n",
      "Training loss (for one batch) at step 110: 433.9458, Accuracy: 0.6327\n",
      "---- Training ----\n",
      "Training loss: 136.2077\n",
      "Training acc over epoch: 0.6326\n",
      "---- Validation ----\n",
      "Validation loss: 34.8242\n",
      "Validation acc: 0.6136\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 435.1813, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 440.2474, Accuracy: 0.6115\n",
      "Training loss (for one batch) at step 20: 437.2824, Accuracy: 0.6083\n",
      "Training loss (for one batch) at step 30: 423.9833, Accuracy: 0.6177\n",
      "Training loss (for one batch) at step 40: 426.8469, Accuracy: 0.6311\n",
      "Training loss (for one batch) at step 50: 409.7652, Accuracy: 0.6383\n",
      "Training loss (for one batch) at step 60: 431.0899, Accuracy: 0.6463\n",
      "Training loss (for one batch) at step 70: 432.1880, Accuracy: 0.6492\n",
      "Training loss (for one batch) at step 80: 432.2168, Accuracy: 0.6446\n",
      "Training loss (for one batch) at step 90: 433.5388, Accuracy: 0.6377\n",
      "Training loss (for one batch) at step 100: 428.1244, Accuracy: 0.6370\n",
      "Training loss (for one batch) at step 110: 434.7369, Accuracy: 0.6387\n",
      "---- Training ----\n",
      "Training loss: 131.7114\n",
      "Training acc over epoch: 0.6381\n",
      "---- Validation ----\n",
      "Validation loss: 31.7255\n",
      "Validation acc: 0.6333\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 435.9038, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 429.6978, Accuracy: 0.6257\n",
      "Training loss (for one batch) at step 20: 433.2264, Accuracy: 0.6138\n",
      "Training loss (for one batch) at step 30: 423.6299, Accuracy: 0.6247\n",
      "Training loss (for one batch) at step 40: 418.5620, Accuracy: 0.6341\n",
      "Training loss (for one batch) at step 50: 410.7232, Accuracy: 0.6474\n",
      "Training loss (for one batch) at step 60: 416.6439, Accuracy: 0.6538\n",
      "Training loss (for one batch) at step 70: 431.3499, Accuracy: 0.6550\n",
      "Training loss (for one batch) at step 80: 431.5051, Accuracy: 0.6504\n",
      "Training loss (for one batch) at step 90: 430.3726, Accuracy: 0.6457\n",
      "Training loss (for one batch) at step 100: 426.7619, Accuracy: 0.6447\n",
      "Training loss (for one batch) at step 110: 436.5605, Accuracy: 0.6456\n",
      "---- Training ----\n",
      "Training loss: 132.2777\n",
      "Training acc over epoch: 0.6464\n",
      "---- Validation ----\n",
      "Validation loss: 35.9193\n",
      "Validation acc: 0.6169\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 433.4873, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 430.8159, Accuracy: 0.6534\n",
      "Training loss (for one batch) at step 20: 432.2578, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 30: 437.1835, Accuracy: 0.6459\n",
      "Training loss (for one batch) at step 40: 417.0666, Accuracy: 0.6534\n",
      "Training loss (for one batch) at step 50: 417.2219, Accuracy: 0.6602\n",
      "Training loss (for one batch) at step 60: 420.3351, Accuracy: 0.6629\n",
      "Training loss (for one batch) at step 70: 436.6797, Accuracy: 0.6624\n",
      "Training loss (for one batch) at step 80: 434.9645, Accuracy: 0.6569\n",
      "Training loss (for one batch) at step 90: 421.6494, Accuracy: 0.6509\n",
      "Training loss (for one batch) at step 100: 420.2311, Accuracy: 0.6510\n",
      "Training loss (for one batch) at step 110: 437.5566, Accuracy: 0.6529\n",
      "---- Training ----\n",
      "Training loss: 138.4395\n",
      "Training acc over epoch: 0.6531\n",
      "---- Validation ----\n",
      "Validation loss: 35.2069\n",
      "Validation acc: 0.5862\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 445.1480, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 423.6563, Accuracy: 0.6264\n",
      "Training loss (for one batch) at step 20: 418.6828, Accuracy: 0.6254\n",
      "Training loss (for one batch) at step 30: 414.1833, Accuracy: 0.6431\n",
      "Training loss (for one batch) at step 40: 408.6983, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 50: 408.8993, Accuracy: 0.6622\n",
      "Training loss (for one batch) at step 60: 410.4218, Accuracy: 0.6714\n",
      "Training loss (for one batch) at step 70: 425.2071, Accuracy: 0.6698\n",
      "Training loss (for one batch) at step 80: 438.9955, Accuracy: 0.6623\n",
      "Training loss (for one batch) at step 90: 417.8052, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 100: 414.6450, Accuracy: 0.6592\n",
      "Training loss (for one batch) at step 110: 421.9142, Accuracy: 0.6591\n",
      "---- Training ----\n",
      "Training loss: 134.5757\n",
      "Training acc over epoch: 0.6593\n",
      "---- Validation ----\n",
      "Validation loss: 35.4340\n",
      "Validation acc: 0.6424\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 439.8507, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 432.5687, Accuracy: 0.6321\n",
      "Training loss (for one batch) at step 20: 424.5911, Accuracy: 0.6291\n",
      "Training loss (for one batch) at step 30: 418.8543, Accuracy: 0.6474\n",
      "Training loss (for one batch) at step 40: 403.9555, Accuracy: 0.6606\n",
      "Training loss (for one batch) at step 50: 419.7665, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 60: 420.3075, Accuracy: 0.6769\n",
      "Training loss (for one batch) at step 70: 433.6566, Accuracy: 0.6764\n",
      "Training loss (for one batch) at step 80: 426.1213, Accuracy: 0.6707\n",
      "Training loss (for one batch) at step 90: 426.1844, Accuracy: 0.6659\n",
      "Training loss (for one batch) at step 100: 417.9328, Accuracy: 0.6672\n",
      "Training loss (for one batch) at step 110: 418.4992, Accuracy: 0.6690\n",
      "---- Training ----\n",
      "Training loss: 127.9666\n",
      "Training acc over epoch: 0.6696\n",
      "---- Validation ----\n",
      "Validation loss: 37.0171\n",
      "Validation acc: 0.6663\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 431.1075, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 427.5180, Accuracy: 0.6591\n",
      "Training loss (for one batch) at step 20: 422.2101, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 30: 403.6414, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 40: 402.7343, Accuracy: 0.6843\n",
      "Training loss (for one batch) at step 50: 386.1422, Accuracy: 0.6935\n",
      "Training loss (for one batch) at step 60: 399.6685, Accuracy: 0.7025\n",
      "Training loss (for one batch) at step 70: 437.4722, Accuracy: 0.7005\n",
      "Training loss (for one batch) at step 80: 424.2536, Accuracy: 0.6892\n",
      "Training loss (for one batch) at step 90: 416.3339, Accuracy: 0.6850\n",
      "Training loss (for one batch) at step 100: 411.9606, Accuracy: 0.6841\n",
      "Training loss (for one batch) at step 110: 422.9708, Accuracy: 0.6837\n",
      "---- Training ----\n",
      "Training loss: 131.5224\n",
      "Training acc over epoch: 0.6826\n",
      "---- Validation ----\n",
      "Validation loss: 31.9848\n",
      "Validation acc: 0.6373\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 430.2664, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 425.3679, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 421.5502, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 30: 397.2744, Accuracy: 0.6759\n",
      "Training loss (for one batch) at step 40: 399.6071, Accuracy: 0.6845\n",
      "Training loss (for one batch) at step 50: 394.8005, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 60: 410.3433, Accuracy: 0.7004\n",
      "Training loss (for one batch) at step 70: 435.4228, Accuracy: 0.6971\n",
      "Training loss (for one batch) at step 80: 433.1745, Accuracy: 0.6885\n",
      "Training loss (for one batch) at step 90: 408.2353, Accuracy: 0.6833\n",
      "Training loss (for one batch) at step 100: 412.4256, Accuracy: 0.6844\n",
      "Training loss (for one batch) at step 110: 427.5926, Accuracy: 0.6870\n",
      "---- Training ----\n",
      "Training loss: 134.7555\n",
      "Training acc over epoch: 0.6871\n",
      "---- Validation ----\n",
      "Validation loss: 35.6348\n",
      "Validation acc: 0.6397\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 421.1973, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 423.9482, Accuracy: 0.6761\n",
      "Training loss (for one batch) at step 20: 412.9303, Accuracy: 0.6756\n",
      "Training loss (for one batch) at step 30: 387.0639, Accuracy: 0.6878\n",
      "Training loss (for one batch) at step 40: 393.5695, Accuracy: 0.6974\n",
      "Training loss (for one batch) at step 50: 403.9449, Accuracy: 0.7068\n",
      "Training loss (for one batch) at step 60: 397.9724, Accuracy: 0.7140\n",
      "Training loss (for one batch) at step 70: 421.4131, Accuracy: 0.7101\n",
      "Training loss (for one batch) at step 80: 426.2701, Accuracy: 0.7008\n",
      "Training loss (for one batch) at step 90: 409.0240, Accuracy: 0.6957\n",
      "Training loss (for one batch) at step 100: 405.2468, Accuracy: 0.6943\n",
      "Training loss (for one batch) at step 110: 423.6157, Accuracy: 0.6953\n",
      "---- Training ----\n",
      "Training loss: 126.2033\n",
      "Training acc over epoch: 0.6949\n",
      "---- Validation ----\n",
      "Validation loss: 35.0178\n",
      "Validation acc: 0.6677\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 420.7903, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 424.2346, Accuracy: 0.6300\n",
      "Training loss (for one batch) at step 20: 405.9388, Accuracy: 0.6585\n",
      "Training loss (for one batch) at step 30: 396.8347, Accuracy: 0.6739\n",
      "Training loss (for one batch) at step 40: 392.3678, Accuracy: 0.6886\n",
      "Training loss (for one batch) at step 50: 394.1487, Accuracy: 0.7013\n",
      "Training loss (for one batch) at step 60: 384.0595, Accuracy: 0.7091\n",
      "Training loss (for one batch) at step 70: 418.9822, Accuracy: 0.7063\n",
      "Training loss (for one batch) at step 80: 414.9807, Accuracy: 0.6977\n",
      "Training loss (for one batch) at step 90: 404.9615, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 100: 405.1090, Accuracy: 0.6904\n",
      "Training loss (for one batch) at step 110: 403.5561, Accuracy: 0.6927\n",
      "---- Training ----\n",
      "Training loss: 129.5149\n",
      "Training acc over epoch: 0.6910\n",
      "---- Validation ----\n",
      "Validation loss: 44.7252\n",
      "Validation acc: 0.6539\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 419.8201, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 422.2660, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 405.9817, Accuracy: 0.6622\n",
      "Training loss (for one batch) at step 30: 403.3272, Accuracy: 0.6799\n",
      "Training loss (for one batch) at step 40: 390.8736, Accuracy: 0.6881\n",
      "Training loss (for one batch) at step 50: 382.3607, Accuracy: 0.7027\n",
      "Training loss (for one batch) at step 60: 388.8673, Accuracy: 0.7134\n",
      "Training loss (for one batch) at step 70: 412.7651, Accuracy: 0.7107\n",
      "Training loss (for one batch) at step 80: 409.4676, Accuracy: 0.7008\n",
      "Training loss (for one batch) at step 90: 403.4081, Accuracy: 0.6944\n",
      "Training loss (for one batch) at step 100: 395.0768, Accuracy: 0.6941\n",
      "Training loss (for one batch) at step 110: 404.3461, Accuracy: 0.6947\n",
      "---- Training ----\n",
      "Training loss: 127.7602\n",
      "Training acc over epoch: 0.6951\n",
      "---- Validation ----\n",
      "Validation loss: 43.8553\n",
      "Validation acc: 0.6601\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 414.5549, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 417.8100, Accuracy: 0.6584\n",
      "Training loss (for one batch) at step 20: 398.7958, Accuracy: 0.6693\n",
      "Training loss (for one batch) at step 30: 385.2808, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 40: 393.0363, Accuracy: 0.7001\n",
      "Training loss (for one batch) at step 50: 374.9209, Accuracy: 0.7140\n",
      "Training loss (for one batch) at step 60: 398.9381, Accuracy: 0.7182\n",
      "Training loss (for one batch) at step 70: 415.5332, Accuracy: 0.7167\n",
      "Training loss (for one batch) at step 80: 413.7799, Accuracy: 0.7067\n",
      "Training loss (for one batch) at step 90: 396.8671, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 100: 387.6248, Accuracy: 0.7016\n",
      "Training loss (for one batch) at step 110: 400.7795, Accuracy: 0.7029\n",
      "---- Training ----\n",
      "Training loss: 124.5131\n",
      "Training acc over epoch: 0.7019\n",
      "---- Validation ----\n",
      "Validation loss: 39.0191\n",
      "Validation acc: 0.6545\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 408.7149, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 395.9294, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 20: 390.4394, Accuracy: 0.6827\n",
      "Training loss (for one batch) at step 30: 399.0627, Accuracy: 0.6938\n",
      "Training loss (for one batch) at step 40: 388.3102, Accuracy: 0.7033\n",
      "Training loss (for one batch) at step 50: 369.2468, Accuracy: 0.7192\n",
      "Training loss (for one batch) at step 60: 392.7318, Accuracy: 0.7208\n",
      "Training loss (for one batch) at step 70: 411.1513, Accuracy: 0.7169\n",
      "Training loss (for one batch) at step 80: 415.5004, Accuracy: 0.7057\n",
      "Training loss (for one batch) at step 90: 392.7290, Accuracy: 0.7008\n",
      "Training loss (for one batch) at step 100: 383.0419, Accuracy: 0.7015\n",
      "Training loss (for one batch) at step 110: 408.2121, Accuracy: 0.7038\n",
      "---- Training ----\n",
      "Training loss: 122.2203\n",
      "Training acc over epoch: 0.7030\n",
      "---- Validation ----\n",
      "Validation loss: 42.5965\n",
      "Validation acc: 0.6660\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 425.7293, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 419.3712, Accuracy: 0.6861\n",
      "Training loss (for one batch) at step 20: 392.4910, Accuracy: 0.6942\n",
      "Training loss (for one batch) at step 30: 373.3012, Accuracy: 0.7064\n",
      "Training loss (for one batch) at step 40: 381.4042, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 50: 369.3011, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 60: 377.9142, Accuracy: 0.7328\n",
      "Training loss (for one batch) at step 70: 418.0352, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 80: 383.8625, Accuracy: 0.7189\n",
      "Training loss (for one batch) at step 90: 394.4165, Accuracy: 0.7112\n",
      "Training loss (for one batch) at step 100: 385.0444, Accuracy: 0.7112\n",
      "Training loss (for one batch) at step 110: 392.7207, Accuracy: 0.7116\n",
      "---- Training ----\n",
      "Training loss: 128.3317\n",
      "Training acc over epoch: 0.7114\n",
      "---- Validation ----\n",
      "Validation loss: 39.7777\n",
      "Validation acc: 0.6531\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 417.0639, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 391.4211, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 20: 378.2867, Accuracy: 0.6793\n",
      "Training loss (for one batch) at step 30: 384.3750, Accuracy: 0.6996\n",
      "Training loss (for one batch) at step 40: 359.6496, Accuracy: 0.7125\n",
      "Training loss (for one batch) at step 50: 359.0082, Accuracy: 0.7224\n",
      "Training loss (for one batch) at step 60: 383.2048, Accuracy: 0.7254\n",
      "Training loss (for one batch) at step 70: 414.3928, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 80: 406.6896, Accuracy: 0.7070\n",
      "Training loss (for one batch) at step 90: 374.6177, Accuracy: 0.7017\n",
      "Training loss (for one batch) at step 100: 376.2833, Accuracy: 0.7023\n",
      "Training loss (for one batch) at step 110: 379.3155, Accuracy: 0.7033\n",
      "---- Training ----\n",
      "Training loss: 128.1374\n",
      "Training acc over epoch: 0.7027\n",
      "---- Validation ----\n",
      "Validation loss: 37.5502\n",
      "Validation acc: 0.6730\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 410.2117, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 400.2392, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 20: 375.6110, Accuracy: 0.6961\n",
      "Training loss (for one batch) at step 30: 350.9960, Accuracy: 0.7135\n",
      "Training loss (for one batch) at step 40: 362.6777, Accuracy: 0.7241\n",
      "Training loss (for one batch) at step 50: 355.9180, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 60: 403.1456, Accuracy: 0.7367\n",
      "Training loss (for one batch) at step 70: 384.4275, Accuracy: 0.7291\n",
      "Training loss (for one batch) at step 80: 398.3704, Accuracy: 0.7160\n",
      "Training loss (for one batch) at step 90: 372.3347, Accuracy: 0.7133\n",
      "Training loss (for one batch) at step 100: 387.9420, Accuracy: 0.7123\n",
      "Training loss (for one batch) at step 110: 392.5213, Accuracy: 0.7121\n",
      "---- Training ----\n",
      "Training loss: 122.3216\n",
      "Training acc over epoch: 0.7112\n",
      "---- Validation ----\n",
      "Validation loss: 34.1272\n",
      "Validation acc: 0.6456\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 398.0424, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 396.7172, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 20: 364.5175, Accuracy: 0.6908\n",
      "Training loss (for one batch) at step 30: 377.0861, Accuracy: 0.7069\n",
      "Training loss (for one batch) at step 40: 361.2460, Accuracy: 0.7199\n",
      "Training loss (for one batch) at step 50: 360.9617, Accuracy: 0.7335\n",
      "Training loss (for one batch) at step 60: 376.7124, Accuracy: 0.7398\n",
      "Training loss (for one batch) at step 70: 421.0889, Accuracy: 0.7338\n",
      "Training loss (for one batch) at step 80: 410.2099, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 90: 388.6507, Accuracy: 0.7174\n",
      "Training loss (for one batch) at step 100: 376.2246, Accuracy: 0.7176\n",
      "Training loss (for one batch) at step 110: 394.6853, Accuracy: 0.7180\n",
      "---- Training ----\n",
      "Training loss: 122.3909\n",
      "Training acc over epoch: 0.7176\n",
      "---- Validation ----\n",
      "Validation loss: 34.1663\n",
      "Validation acc: 0.6513\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 411.1500, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 403.4421, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 373.1987, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 30: 364.6063, Accuracy: 0.7087\n",
      "Training loss (for one batch) at step 40: 347.2550, Accuracy: 0.7197\n",
      "Training loss (for one batch) at step 50: 353.5058, Accuracy: 0.7289\n",
      "Training loss (for one batch) at step 60: 360.9152, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 70: 382.1808, Accuracy: 0.7300\n",
      "Training loss (for one batch) at step 80: 402.5220, Accuracy: 0.7194\n",
      "Training loss (for one batch) at step 90: 355.4223, Accuracy: 0.7157\n",
      "Training loss (for one batch) at step 100: 371.4849, Accuracy: 0.7162\n",
      "Training loss (for one batch) at step 110: 369.3181, Accuracy: 0.7166\n",
      "---- Training ----\n",
      "Training loss: 115.0021\n",
      "Training acc over epoch: 0.7157\n",
      "---- Validation ----\n",
      "Validation loss: 34.5501\n",
      "Validation acc: 0.6628\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 415.7303, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 392.1630, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 365.6882, Accuracy: 0.7013\n",
      "Training loss (for one batch) at step 30: 354.2072, Accuracy: 0.7200\n",
      "Training loss (for one batch) at step 40: 356.4667, Accuracy: 0.7277\n",
      "Training loss (for one batch) at step 50: 341.9670, Accuracy: 0.7376\n",
      "Training loss (for one batch) at step 60: 356.6091, Accuracy: 0.7432\n",
      "Training loss (for one batch) at step 70: 384.7137, Accuracy: 0.7347\n",
      "Training loss (for one batch) at step 80: 406.9131, Accuracy: 0.7210\n",
      "Training loss (for one batch) at step 90: 356.0286, Accuracy: 0.7157\n",
      "Training loss (for one batch) at step 100: 359.8174, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 110: 375.8401, Accuracy: 0.7173\n",
      "---- Training ----\n",
      "Training loss: 118.7319\n",
      "Training acc over epoch: 0.7169\n",
      "---- Validation ----\n",
      "Validation loss: 33.6297\n",
      "Validation acc: 0.6499\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 376.1049, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 400.7688, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 20: 360.2798, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 30: 350.3110, Accuracy: 0.7124\n",
      "Training loss (for one batch) at step 40: 341.4558, Accuracy: 0.7262\n",
      "Training loss (for one batch) at step 50: 351.6385, Accuracy: 0.7359\n",
      "Training loss (for one batch) at step 60: 373.3875, Accuracy: 0.7423\n",
      "Training loss (for one batch) at step 70: 379.5526, Accuracy: 0.7320\n",
      "Training loss (for one batch) at step 80: 381.4179, Accuracy: 0.7197\n",
      "Training loss (for one batch) at step 90: 356.2393, Accuracy: 0.7150\n",
      "Training loss (for one batch) at step 100: 354.1730, Accuracy: 0.7171\n",
      "Training loss (for one batch) at step 110: 378.3318, Accuracy: 0.7187\n",
      "---- Training ----\n",
      "Training loss: 120.7767\n",
      "Training acc over epoch: 0.7188\n",
      "---- Validation ----\n",
      "Validation loss: 39.3519\n",
      "Validation acc: 0.6639\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 400.0672, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 380.5655, Accuracy: 0.6655\n",
      "Training loss (for one batch) at step 20: 371.0853, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 30: 335.0737, Accuracy: 0.7253\n",
      "Training loss (for one batch) at step 40: 351.1650, Accuracy: 0.7334\n",
      "Training loss (for one batch) at step 50: 354.7430, Accuracy: 0.7423\n",
      "Training loss (for one batch) at step 60: 343.3598, Accuracy: 0.7477\n",
      "Training loss (for one batch) at step 70: 376.7410, Accuracy: 0.7373\n",
      "Training loss (for one batch) at step 80: 370.8746, Accuracy: 0.7250\n",
      "Training loss (for one batch) at step 90: 343.5167, Accuracy: 0.7186\n",
      "Training loss (for one batch) at step 100: 340.6269, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 110: 355.5586, Accuracy: 0.7199\n",
      "---- Training ----\n",
      "Training loss: 132.3760\n",
      "Training acc over epoch: 0.7198\n",
      "---- Validation ----\n",
      "Validation loss: 43.4273\n",
      "Validation acc: 0.6556\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 363.6400, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 366.7490, Accuracy: 0.6491\n",
      "Training loss (for one batch) at step 20: 364.1355, Accuracy: 0.6908\n",
      "Training loss (for one batch) at step 30: 355.8730, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 40: 343.0754, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 50: 342.0222, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 60: 347.9104, Accuracy: 0.7419\n",
      "Training loss (for one batch) at step 70: 368.7145, Accuracy: 0.7317\n",
      "Training loss (for one batch) at step 80: 372.5051, Accuracy: 0.7208\n",
      "Training loss (for one batch) at step 90: 353.5804, Accuracy: 0.7174\n",
      "Training loss (for one batch) at step 100: 355.5480, Accuracy: 0.7179\n",
      "Training loss (for one batch) at step 110: 364.8741, Accuracy: 0.7196\n",
      "---- Training ----\n",
      "Training loss: 110.2950\n",
      "Training acc over epoch: 0.7189\n",
      "---- Validation ----\n",
      "Validation loss: 38.4024\n",
      "Validation acc: 0.6556\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 396.5860, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 384.1901, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 353.8238, Accuracy: 0.6756\n",
      "Training loss (for one batch) at step 30: 366.8868, Accuracy: 0.7051\n",
      "Training loss (for one batch) at step 40: 334.4742, Accuracy: 0.7180\n",
      "Training loss (for one batch) at step 50: 336.8778, Accuracy: 0.7316\n",
      "Training loss (for one batch) at step 60: 358.5236, Accuracy: 0.7377\n",
      "Training loss (for one batch) at step 70: 385.8851, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 80: 377.4878, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 90: 353.3350, Accuracy: 0.7146\n",
      "Training loss (for one batch) at step 100: 351.0959, Accuracy: 0.7158\n",
      "Training loss (for one batch) at step 110: 362.9894, Accuracy: 0.7159\n",
      "---- Training ----\n",
      "Training loss: 112.4039\n",
      "Training acc over epoch: 0.7164\n",
      "---- Validation ----\n",
      "Validation loss: 43.1765\n",
      "Validation acc: 0.6634\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 388.2844, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 369.0833, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 20: 355.7394, Accuracy: 0.6830\n",
      "Training loss (for one batch) at step 30: 345.8327, Accuracy: 0.7072\n",
      "Training loss (for one batch) at step 40: 337.7369, Accuracy: 0.7235\n",
      "Training loss (for one batch) at step 50: 346.8645, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 60: 360.8555, Accuracy: 0.7398\n",
      "Training loss (for one batch) at step 70: 374.1290, Accuracy: 0.7310\n",
      "Training loss (for one batch) at step 80: 390.1429, Accuracy: 0.7157\n",
      "Training loss (for one batch) at step 90: 348.1563, Accuracy: 0.7122\n",
      "Training loss (for one batch) at step 100: 379.4058, Accuracy: 0.7144\n",
      "Training loss (for one batch) at step 110: 349.9141, Accuracy: 0.7158\n",
      "---- Training ----\n",
      "Training loss: 117.0384\n",
      "Training acc over epoch: 0.7149\n",
      "---- Validation ----\n",
      "Validation loss: 36.1527\n",
      "Validation acc: 0.6577\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 399.2088, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 381.0695, Accuracy: 0.6314\n",
      "Training loss (for one batch) at step 20: 342.2005, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 347.7593, Accuracy: 0.7162\n",
      "Training loss (for one batch) at step 40: 347.8725, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 50: 328.2280, Accuracy: 0.7446\n",
      "Training loss (for one batch) at step 60: 346.6436, Accuracy: 0.7488\n",
      "Training loss (for one batch) at step 70: 364.4076, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 80: 377.4420, Accuracy: 0.7275\n",
      "Training loss (for one batch) at step 90: 357.4131, Accuracy: 0.7194\n",
      "Training loss (for one batch) at step 100: 344.3872, Accuracy: 0.7213\n",
      "Training loss (for one batch) at step 110: 346.9803, Accuracy: 0.7212\n",
      "---- Training ----\n",
      "Training loss: 121.5418\n",
      "Training acc over epoch: 0.7217\n",
      "---- Validation ----\n",
      "Validation loss: 42.0279\n",
      "Validation acc: 0.6534\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 383.8633, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 379.7128, Accuracy: 0.6364\n",
      "Training loss (for one batch) at step 20: 350.4652, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 30: 341.5786, Accuracy: 0.7064\n",
      "Training loss (for one batch) at step 40: 350.4822, Accuracy: 0.7254\n",
      "Training loss (for one batch) at step 50: 322.9153, Accuracy: 0.7345\n",
      "Training loss (for one batch) at step 60: 359.0963, Accuracy: 0.7432\n",
      "Training loss (for one batch) at step 70: 359.4760, Accuracy: 0.7347\n",
      "Training loss (for one batch) at step 80: 390.6044, Accuracy: 0.7204\n",
      "Training loss (for one batch) at step 90: 333.1814, Accuracy: 0.7145\n",
      "Training loss (for one batch) at step 100: 341.3078, Accuracy: 0.7134\n",
      "Training loss (for one batch) at step 110: 362.8505, Accuracy: 0.7149\n",
      "---- Training ----\n",
      "Training loss: 113.9356\n",
      "Training acc over epoch: 0.7147\n",
      "---- Validation ----\n",
      "Validation loss: 40.6977\n",
      "Validation acc: 0.6596\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 370.6839, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 351.7584, Accuracy: 0.6392\n",
      "Training loss (for one batch) at step 20: 338.5394, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 30: 325.0379, Accuracy: 0.7104\n",
      "Training loss (for one batch) at step 40: 321.3272, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 50: 313.8441, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 60: 339.6626, Accuracy: 0.7430\n",
      "Training loss (for one batch) at step 70: 349.1263, Accuracy: 0.7333\n",
      "Training loss (for one batch) at step 80: 362.4106, Accuracy: 0.7212\n",
      "Training loss (for one batch) at step 90: 346.2404, Accuracy: 0.7178\n",
      "Training loss (for one batch) at step 100: 319.5403, Accuracy: 0.7193\n",
      "Training loss (for one batch) at step 110: 340.2255, Accuracy: 0.7190\n",
      "---- Training ----\n",
      "Training loss: 112.7359\n",
      "Training acc over epoch: 0.7172\n",
      "---- Validation ----\n",
      "Validation loss: 38.5434\n",
      "Validation acc: 0.6585\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 360.0592, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 371.3369, Accuracy: 0.6683\n",
      "Training loss (for one batch) at step 20: 342.1826, Accuracy: 0.6853\n",
      "Training loss (for one batch) at step 30: 336.7172, Accuracy: 0.7152\n",
      "Training loss (for one batch) at step 40: 342.6707, Accuracy: 0.7355\n",
      "Training loss (for one batch) at step 50: 318.0837, Accuracy: 0.7462\n",
      "Training loss (for one batch) at step 60: 346.2992, Accuracy: 0.7546\n",
      "Training loss (for one batch) at step 70: 354.4587, Accuracy: 0.7435\n",
      "Training loss (for one batch) at step 80: 363.7128, Accuracy: 0.7305\n",
      "Training loss (for one batch) at step 90: 340.1951, Accuracy: 0.7260\n",
      "Training loss (for one batch) at step 100: 332.6386, Accuracy: 0.7275\n",
      "Training loss (for one batch) at step 110: 331.9556, Accuracy: 0.7285\n",
      "---- Training ----\n",
      "Training loss: 113.4899\n",
      "Training acc over epoch: 0.7272\n",
      "---- Validation ----\n",
      "Validation loss: 38.3979\n",
      "Validation acc: 0.6505\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 362.4259, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 367.1844, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 20: 336.4499, Accuracy: 0.6830\n",
      "Training loss (for one batch) at step 30: 337.7793, Accuracy: 0.7067\n",
      "Training loss (for one batch) at step 40: 329.9939, Accuracy: 0.7243\n",
      "Training loss (for one batch) at step 50: 316.3544, Accuracy: 0.7394\n",
      "Training loss (for one batch) at step 60: 346.9506, Accuracy: 0.7455\n",
      "Training loss (for one batch) at step 70: 360.9354, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 80: 359.2249, Accuracy: 0.7205\n",
      "Training loss (for one batch) at step 90: 355.4150, Accuracy: 0.7157\n",
      "Training loss (for one batch) at step 100: 346.2261, Accuracy: 0.7164\n",
      "Training loss (for one batch) at step 110: 323.2264, Accuracy: 0.7192\n",
      "---- Training ----\n",
      "Training loss: 107.7276\n",
      "Training acc over epoch: 0.7178\n",
      "---- Validation ----\n",
      "Validation loss: 41.7433\n",
      "Validation acc: 0.6381\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 377.6194, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 373.9908, Accuracy: 0.6399\n",
      "Training loss (for one batch) at step 20: 350.6046, Accuracy: 0.6808\n",
      "Training loss (for one batch) at step 30: 332.0213, Accuracy: 0.7094\n",
      "Training loss (for one batch) at step 40: 329.6528, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 50: 322.8263, Accuracy: 0.7416\n",
      "Training loss (for one batch) at step 60: 349.0346, Accuracy: 0.7491\n",
      "Training loss (for one batch) at step 70: 355.5018, Accuracy: 0.7387\n",
      "Training loss (for one batch) at step 80: 369.6107, Accuracy: 0.7242\n",
      "Training loss (for one batch) at step 90: 336.5335, Accuracy: 0.7178\n",
      "Training loss (for one batch) at step 100: 337.9072, Accuracy: 0.7196\n",
      "Training loss (for one batch) at step 110: 338.3245, Accuracy: 0.7214\n",
      "---- Training ----\n",
      "Training loss: 117.8401\n",
      "Training acc over epoch: 0.7203\n",
      "---- Validation ----\n",
      "Validation loss: 40.2509\n",
      "Validation acc: 0.6663\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 356.4680, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 348.7940, Accuracy: 0.6420\n",
      "Training loss (for one batch) at step 20: 323.8209, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 30: 338.1933, Accuracy: 0.7072\n",
      "Training loss (for one batch) at step 40: 319.4510, Accuracy: 0.7256\n",
      "Training loss (for one batch) at step 50: 310.8316, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 60: 344.8049, Accuracy: 0.7451\n",
      "Training loss (for one batch) at step 70: 345.2021, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 80: 358.1738, Accuracy: 0.7233\n",
      "Training loss (for one batch) at step 90: 327.4710, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 100: 347.2998, Accuracy: 0.7227\n",
      "Training loss (for one batch) at step 110: 365.2839, Accuracy: 0.7221\n",
      "---- Training ----\n",
      "Training loss: 113.0716\n",
      "Training acc over epoch: 0.7219\n",
      "---- Validation ----\n",
      "Validation loss: 43.9857\n",
      "Validation acc: 0.6706\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 356.9908, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 359.6060, Accuracy: 0.6456\n",
      "Training loss (for one batch) at step 20: 330.9298, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 30: 311.9011, Accuracy: 0.7124\n",
      "Training loss (for one batch) at step 40: 321.5989, Accuracy: 0.7260\n",
      "Training loss (for one batch) at step 50: 329.7790, Accuracy: 0.7396\n",
      "Training loss (for one batch) at step 60: 333.4216, Accuracy: 0.7423\n",
      "Training loss (for one batch) at step 70: 381.4473, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 80: 357.3655, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 90: 335.3076, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 100: 332.2314, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 110: 330.9064, Accuracy: 0.7203\n",
      "---- Training ----\n",
      "Training loss: 101.7530\n",
      "Training acc over epoch: 0.7202\n",
      "---- Validation ----\n",
      "Validation loss: 42.0385\n",
      "Validation acc: 0.6701\n",
      "Time taken: 10.77s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 356.5646, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 356.2829, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 324.0247, Accuracy: 0.6845\n",
      "Training loss (for one batch) at step 30: 313.5724, Accuracy: 0.7097\n",
      "Training loss (for one batch) at step 40: 320.4792, Accuracy: 0.7243\n",
      "Training loss (for one batch) at step 50: 312.1140, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 60: 327.0859, Accuracy: 0.7428\n",
      "Training loss (for one batch) at step 70: 351.5000, Accuracy: 0.7335\n",
      "Training loss (for one batch) at step 80: 356.6083, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 90: 313.8093, Accuracy: 0.7170\n",
      "Training loss (for one batch) at step 100: 328.1270, Accuracy: 0.7201\n",
      "Training loss (for one batch) at step 110: 338.5869, Accuracy: 0.7204\n",
      "---- Training ----\n",
      "Training loss: 110.3416\n",
      "Training acc over epoch: 0.7194\n",
      "---- Validation ----\n",
      "Validation loss: 49.5060\n",
      "Validation acc: 0.6660\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 365.6214, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 344.7944, Accuracy: 0.6435\n",
      "Training loss (for one batch) at step 20: 332.4889, Accuracy: 0.6860\n",
      "Training loss (for one batch) at step 30: 337.1261, Accuracy: 0.7177\n",
      "Training loss (for one batch) at step 40: 317.9819, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 50: 317.5768, Accuracy: 0.7469\n",
      "Training loss (for one batch) at step 60: 347.2183, Accuracy: 0.7551\n",
      "Training loss (for one batch) at step 70: 341.7026, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 80: 339.4494, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 90: 323.3475, Accuracy: 0.7246\n",
      "Training loss (for one batch) at step 100: 341.8168, Accuracy: 0.7264\n",
      "Training loss (for one batch) at step 110: 354.9101, Accuracy: 0.7285\n",
      "---- Training ----\n",
      "Training loss: 123.4349\n",
      "Training acc over epoch: 0.7262\n",
      "---- Validation ----\n",
      "Validation loss: 37.9752\n",
      "Validation acc: 0.6588\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 362.4674, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 347.4403, Accuracy: 0.6527\n",
      "Training loss (for one batch) at step 20: 323.4999, Accuracy: 0.6908\n",
      "Training loss (for one batch) at step 30: 309.1589, Accuracy: 0.7177\n",
      "Training loss (for one batch) at step 40: 316.6436, Accuracy: 0.7342\n",
      "Training loss (for one batch) at step 50: 322.8832, Accuracy: 0.7480\n",
      "Training loss (for one batch) at step 60: 324.7106, Accuracy: 0.7527\n",
      "Training loss (for one batch) at step 70: 361.2599, Accuracy: 0.7441\n",
      "Training loss (for one batch) at step 80: 349.5583, Accuracy: 0.7274\n",
      "Training loss (for one batch) at step 90: 337.3725, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 100: 350.6806, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 110: 348.8396, Accuracy: 0.7254\n",
      "---- Training ----\n",
      "Training loss: 97.4669\n",
      "Training acc over epoch: 0.7247\n",
      "---- Validation ----\n",
      "Validation loss: 35.0992\n",
      "Validation acc: 0.6582\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 351.2713, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 349.8308, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 20: 330.8684, Accuracy: 0.6763\n",
      "Training loss (for one batch) at step 30: 321.6660, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 40: 314.0375, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 50: 307.9750, Accuracy: 0.7453\n",
      "Training loss (for one batch) at step 60: 330.0120, Accuracy: 0.7494\n",
      "Training loss (for one batch) at step 70: 349.7946, Accuracy: 0.7403\n",
      "Training loss (for one batch) at step 80: 351.7027, Accuracy: 0.7263\n",
      "Training loss (for one batch) at step 90: 323.7326, Accuracy: 0.7237\n",
      "Training loss (for one batch) at step 100: 317.6289, Accuracy: 0.7241\n",
      "Training loss (for one batch) at step 110: 329.2380, Accuracy: 0.7242\n",
      "---- Training ----\n",
      "Training loss: 117.2473\n",
      "Training acc over epoch: 0.7221\n",
      "---- Validation ----\n",
      "Validation loss: 38.1194\n",
      "Validation acc: 0.6623\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 348.8071, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 387.4812, Accuracy: 0.6378\n",
      "Training loss (for one batch) at step 20: 310.2572, Accuracy: 0.6793\n",
      "Training loss (for one batch) at step 30: 320.6680, Accuracy: 0.7074\n",
      "Training loss (for one batch) at step 40: 314.8457, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 50: 317.6863, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 60: 317.3728, Accuracy: 0.7495\n",
      "Training loss (for one batch) at step 70: 340.1924, Accuracy: 0.7371\n",
      "Training loss (for one batch) at step 80: 358.7703, Accuracy: 0.7235\n",
      "Training loss (for one batch) at step 90: 326.0851, Accuracy: 0.7181\n",
      "Training loss (for one batch) at step 100: 313.5137, Accuracy: 0.7214\n",
      "Training loss (for one batch) at step 110: 326.7284, Accuracy: 0.7223\n",
      "---- Training ----\n",
      "Training loss: 115.0407\n",
      "Training acc over epoch: 0.7219\n",
      "---- Validation ----\n",
      "Validation loss: 61.2118\n",
      "Validation acc: 0.6779\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 352.3544, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 336.5671, Accuracy: 0.6499\n",
      "Training loss (for one batch) at step 20: 318.0251, Accuracy: 0.6871\n",
      "Training loss (for one batch) at step 30: 304.0845, Accuracy: 0.7130\n",
      "Training loss (for one batch) at step 40: 308.6272, Accuracy: 0.7309\n",
      "Training loss (for one batch) at step 50: 310.2839, Accuracy: 0.7431\n",
      "Training loss (for one batch) at step 60: 329.7093, Accuracy: 0.7487\n",
      "Training loss (for one batch) at step 70: 342.2344, Accuracy: 0.7393\n",
      "Training loss (for one batch) at step 80: 351.5380, Accuracy: 0.7231\n",
      "Training loss (for one batch) at step 90: 301.4962, Accuracy: 0.7207\n",
      "Training loss (for one batch) at step 100: 339.7899, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 110: 334.6584, Accuracy: 0.7238\n",
      "---- Training ----\n",
      "Training loss: 114.6091\n",
      "Training acc over epoch: 0.7228\n",
      "---- Validation ----\n",
      "Validation loss: 62.0019\n",
      "Validation acc: 0.6609\n",
      "Time taken: 10.52s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6728\n",
      "Validation AUC: 0.6751\n",
      "Validation Balanced_ACC: 0.4696\n",
      "Validation AUCSK: 0.8056\n",
      "Validation MI: 0.1233\n",
      "Validation Normalized MI: 0.1799\n",
      "Validation Adjusted MI: 0.1799\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 664.3907, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 621.9774, Accuracy: 0.5249\n",
      "Training loss (for one batch) at step 20: 602.5035, Accuracy: 0.5283\n",
      "Training loss (for one batch) at step 30: 542.4471, Accuracy: 0.5189\n",
      "Training loss (for one batch) at step 40: 532.5485, Accuracy: 0.5112\n",
      "Training loss (for one batch) at step 50: 511.1518, Accuracy: 0.5124\n",
      "Training loss (for one batch) at step 60: 498.4182, Accuracy: 0.5119\n",
      "Training loss (for one batch) at step 70: 482.8534, Accuracy: 0.5062\n",
      "Training loss (for one batch) at step 80: 459.0420, Accuracy: 0.5080\n",
      "Training loss (for one batch) at step 90: 474.1564, Accuracy: 0.5065\n",
      "Training loss (for one batch) at step 100: 476.9121, Accuracy: 0.5060\n",
      "Training loss (for one batch) at step 110: 462.4377, Accuracy: 0.5049\n",
      "---- Training ----\n",
      "Training loss: 144.5126\n",
      "Training acc over epoch: 0.5052\n",
      "---- Validation ----\n",
      "Validation loss: 34.6076\n",
      "Validation acc: 0.5322\n",
      "Time taken: 12.08s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 461.3333, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 453.1189, Accuracy: 0.5135\n",
      "Training loss (for one batch) at step 20: 453.4415, Accuracy: 0.5089\n",
      "Training loss (for one batch) at step 30: 455.7811, Accuracy: 0.5159\n",
      "Training loss (for one batch) at step 40: 451.6796, Accuracy: 0.5202\n",
      "Training loss (for one batch) at step 50: 451.1520, Accuracy: 0.5169\n",
      "Training loss (for one batch) at step 60: 447.8344, Accuracy: 0.5186\n",
      "Training loss (for one batch) at step 70: 449.6113, Accuracy: 0.5177\n",
      "Training loss (for one batch) at step 80: 444.6291, Accuracy: 0.5192\n",
      "Training loss (for one batch) at step 90: 447.9073, Accuracy: 0.5215\n",
      "Training loss (for one batch) at step 100: 449.4902, Accuracy: 0.5189\n",
      "Training loss (for one batch) at step 110: 449.0903, Accuracy: 0.5165\n",
      "---- Training ----\n",
      "Training loss: 140.4934\n",
      "Training acc over epoch: 0.5168\n",
      "---- Validation ----\n",
      "Validation loss: 34.7469\n",
      "Validation acc: 0.5121\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 446.9464, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 448.0177, Accuracy: 0.5142\n",
      "Training loss (for one batch) at step 20: 445.2933, Accuracy: 0.5086\n",
      "Training loss (for one batch) at step 30: 448.5236, Accuracy: 0.5111\n",
      "Training loss (for one batch) at step 40: 451.5040, Accuracy: 0.5168\n",
      "Training loss (for one batch) at step 50: 447.2818, Accuracy: 0.5121\n",
      "Training loss (for one batch) at step 60: 446.0617, Accuracy: 0.5173\n",
      "Training loss (for one batch) at step 70: 442.2076, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 80: 445.2064, Accuracy: 0.5233\n",
      "Training loss (for one batch) at step 90: 447.3143, Accuracy: 0.5254\n",
      "Training loss (for one batch) at step 100: 447.1385, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 110: 449.6355, Accuracy: 0.5216\n",
      "---- Training ----\n",
      "Training loss: 140.2563\n",
      "Training acc over epoch: 0.5221\n",
      "---- Validation ----\n",
      "Validation loss: 34.7257\n",
      "Validation acc: 0.5287\n",
      "Time taken: 10.17s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.2097, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 446.0172, Accuracy: 0.5348\n",
      "Training loss (for one batch) at step 20: 442.9870, Accuracy: 0.5424\n",
      "Training loss (for one batch) at step 30: 444.2260, Accuracy: 0.5446\n",
      "Training loss (for one batch) at step 40: 441.5935, Accuracy: 0.5396\n",
      "Training loss (for one batch) at step 50: 445.1943, Accuracy: 0.5424\n",
      "Training loss (for one batch) at step 60: 441.4797, Accuracy: 0.5366\n",
      "Training loss (for one batch) at step 70: 445.4439, Accuracy: 0.5385\n",
      "Training loss (for one batch) at step 80: 446.4595, Accuracy: 0.5374\n",
      "Training loss (for one batch) at step 90: 442.2936, Accuracy: 0.5379\n",
      "Training loss (for one batch) at step 100: 443.3221, Accuracy: 0.5362\n",
      "Training loss (for one batch) at step 110: 443.9129, Accuracy: 0.5389\n",
      "---- Training ----\n",
      "Training loss: 139.8561\n",
      "Training acc over epoch: 0.5375\n",
      "---- Validation ----\n",
      "Validation loss: 34.5460\n",
      "Validation acc: 0.5360\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 442.8636, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 10: 444.2703, Accuracy: 0.5561\n",
      "Training loss (for one batch) at step 20: 441.8950, Accuracy: 0.5610\n",
      "Training loss (for one batch) at step 30: 443.8767, Accuracy: 0.5587\n",
      "Training loss (for one batch) at step 40: 444.1784, Accuracy: 0.5623\n",
      "Training loss (for one batch) at step 50: 442.9011, Accuracy: 0.5574\n",
      "Training loss (for one batch) at step 60: 441.4877, Accuracy: 0.5562\n",
      "Training loss (for one batch) at step 70: 444.7847, Accuracy: 0.5596\n",
      "Training loss (for one batch) at step 80: 443.8192, Accuracy: 0.5623\n",
      "Training loss (for one batch) at step 90: 442.3017, Accuracy: 0.5614\n",
      "Training loss (for one batch) at step 100: 439.5225, Accuracy: 0.5584\n",
      "Training loss (for one batch) at step 110: 445.8284, Accuracy: 0.5564\n",
      "---- Training ----\n",
      "Training loss: 140.2712\n",
      "Training acc over epoch: 0.5560\n",
      "---- Validation ----\n",
      "Validation loss: 34.9726\n",
      "Validation acc: 0.5693\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 444.1747, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 446.2745, Accuracy: 0.5639\n",
      "Training loss (for one batch) at step 20: 441.7624, Accuracy: 0.5737\n",
      "Training loss (for one batch) at step 30: 438.6831, Accuracy: 0.5698\n",
      "Training loss (for one batch) at step 40: 439.7636, Accuracy: 0.5688\n",
      "Training loss (for one batch) at step 50: 438.9139, Accuracy: 0.5737\n",
      "Training loss (for one batch) at step 60: 438.5507, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 70: 443.1778, Accuracy: 0.5700\n",
      "Training loss (for one batch) at step 80: 442.5000, Accuracy: 0.5675\n",
      "Training loss (for one batch) at step 90: 442.0652, Accuracy: 0.5665\n",
      "Training loss (for one batch) at step 100: 440.4494, Accuracy: 0.5651\n",
      "Training loss (for one batch) at step 110: 441.5822, Accuracy: 0.5654\n",
      "---- Training ----\n",
      "Training loss: 138.9861\n",
      "Training acc over epoch: 0.5645\n",
      "---- Validation ----\n",
      "Validation loss: 34.5488\n",
      "Validation acc: 0.5736\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.5006, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 444.4841, Accuracy: 0.5618\n",
      "Training loss (for one batch) at step 20: 439.4689, Accuracy: 0.5681\n",
      "Training loss (for one batch) at step 30: 436.4633, Accuracy: 0.5728\n",
      "Training loss (for one batch) at step 40: 440.5316, Accuracy: 0.5747\n",
      "Training loss (for one batch) at step 50: 440.0363, Accuracy: 0.5780\n",
      "Training loss (for one batch) at step 60: 436.9431, Accuracy: 0.5759\n",
      "Training loss (for one batch) at step 70: 436.2743, Accuracy: 0.5735\n",
      "Training loss (for one batch) at step 80: 443.6340, Accuracy: 0.5762\n",
      "Training loss (for one batch) at step 90: 442.2047, Accuracy: 0.5771\n",
      "Training loss (for one batch) at step 100: 434.9346, Accuracy: 0.5769\n",
      "Training loss (for one batch) at step 110: 437.4995, Accuracy: 0.5755\n",
      "---- Training ----\n",
      "Training loss: 137.3361\n",
      "Training acc over epoch: 0.5771\n",
      "---- Validation ----\n",
      "Validation loss: 36.5333\n",
      "Validation acc: 0.5766\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 439.3636, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 440.9293, Accuracy: 0.5817\n",
      "Training loss (for one batch) at step 20: 438.1196, Accuracy: 0.5863\n",
      "Training loss (for one batch) at step 30: 441.0632, Accuracy: 0.5925\n",
      "Training loss (for one batch) at step 40: 433.3002, Accuracy: 0.5936\n",
      "Training loss (for one batch) at step 50: 434.5895, Accuracy: 0.5924\n",
      "Training loss (for one batch) at step 60: 436.0709, Accuracy: 0.5875\n",
      "Training loss (for one batch) at step 70: 435.9244, Accuracy: 0.5843\n",
      "Training loss (for one batch) at step 80: 443.2150, Accuracy: 0.5867\n",
      "Training loss (for one batch) at step 90: 437.0948, Accuracy: 0.5847\n",
      "Training loss (for one batch) at step 100: 434.6083, Accuracy: 0.5855\n",
      "Training loss (for one batch) at step 110: 437.3254, Accuracy: 0.5864\n",
      "---- Training ----\n",
      "Training loss: 138.2974\n",
      "Training acc over epoch: 0.5874\n",
      "---- Validation ----\n",
      "Validation loss: 34.5835\n",
      "Validation acc: 0.5978\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 444.5791, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 440.9011, Accuracy: 0.5852\n",
      "Training loss (for one batch) at step 20: 438.5542, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 30: 440.1402, Accuracy: 0.5890\n",
      "Training loss (for one batch) at step 40: 433.6149, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 50: 434.1840, Accuracy: 0.5873\n",
      "Training loss (for one batch) at step 60: 436.5234, Accuracy: 0.5876\n",
      "Training loss (for one batch) at step 70: 437.7176, Accuracy: 0.5892\n",
      "Training loss (for one batch) at step 80: 439.7229, Accuracy: 0.5875\n",
      "Training loss (for one batch) at step 90: 439.1867, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 100: 432.7711, Accuracy: 0.5866\n",
      "Training loss (for one batch) at step 110: 436.7861, Accuracy: 0.5859\n",
      "---- Training ----\n",
      "Training loss: 139.1907\n",
      "Training acc over epoch: 0.5861\n",
      "---- Validation ----\n",
      "Validation loss: 34.1349\n",
      "Validation acc: 0.6072\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 445.1907, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 440.2800, Accuracy: 0.5980\n",
      "Training loss (for one batch) at step 20: 445.8230, Accuracy: 0.5975\n",
      "Training loss (for one batch) at step 30: 434.0616, Accuracy: 0.6104\n",
      "Training loss (for one batch) at step 40: 430.8422, Accuracy: 0.6159\n",
      "Training loss (for one batch) at step 50: 432.1318, Accuracy: 0.6112\n",
      "Training loss (for one batch) at step 60: 423.1134, Accuracy: 0.6180\n",
      "Training loss (for one batch) at step 70: 440.2504, Accuracy: 0.6164\n",
      "Training loss (for one batch) at step 80: 436.7713, Accuracy: 0.6141\n",
      "Training loss (for one batch) at step 90: 435.6552, Accuracy: 0.6096\n",
      "Training loss (for one batch) at step 100: 434.7122, Accuracy: 0.6084\n",
      "Training loss (for one batch) at step 110: 432.5169, Accuracy: 0.6089\n",
      "---- Training ----\n",
      "Training loss: 137.3355\n",
      "Training acc over epoch: 0.6075\n",
      "---- Validation ----\n",
      "Validation loss: 35.4712\n",
      "Validation acc: 0.5889\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 434.7089, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 442.7888, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 20: 433.6868, Accuracy: 0.6231\n",
      "Training loss (for one batch) at step 30: 426.7994, Accuracy: 0.6167\n",
      "Training loss (for one batch) at step 40: 430.9049, Accuracy: 0.6199\n",
      "Training loss (for one batch) at step 50: 428.4680, Accuracy: 0.6166\n",
      "Training loss (for one batch) at step 60: 433.0296, Accuracy: 0.6127\n",
      "Training loss (for one batch) at step 70: 442.3771, Accuracy: 0.6149\n",
      "Training loss (for one batch) at step 80: 436.8533, Accuracy: 0.6116\n",
      "Training loss (for one batch) at step 90: 432.7366, Accuracy: 0.6095\n",
      "Training loss (for one batch) at step 100: 435.4858, Accuracy: 0.6067\n",
      "Training loss (for one batch) at step 110: 440.7464, Accuracy: 0.6064\n",
      "---- Training ----\n",
      "Training loss: 134.9748\n",
      "Training acc over epoch: 0.6048\n",
      "---- Validation ----\n",
      "Validation loss: 36.9977\n",
      "Validation acc: 0.5916\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 434.1877, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 439.3742, Accuracy: 0.6072\n",
      "Training loss (for one batch) at step 20: 430.3831, Accuracy: 0.6198\n",
      "Training loss (for one batch) at step 30: 435.1506, Accuracy: 0.6247\n",
      "Training loss (for one batch) at step 40: 426.7656, Accuracy: 0.6279\n",
      "Training loss (for one batch) at step 50: 425.7907, Accuracy: 0.6278\n",
      "Training loss (for one batch) at step 60: 430.8948, Accuracy: 0.6279\n",
      "Training loss (for one batch) at step 70: 434.0760, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 80: 442.7555, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 90: 441.3744, Accuracy: 0.6148\n",
      "Training loss (for one batch) at step 100: 438.6943, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 110: 437.4232, Accuracy: 0.6133\n",
      "---- Training ----\n",
      "Training loss: 138.0083\n",
      "Training acc over epoch: 0.6128\n",
      "---- Validation ----\n",
      "Validation loss: 34.4059\n",
      "Validation acc: 0.6083\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 431.0803, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 434.9822, Accuracy: 0.6214\n",
      "Training loss (for one batch) at step 20: 436.8195, Accuracy: 0.6209\n",
      "Training loss (for one batch) at step 30: 426.4330, Accuracy: 0.6268\n",
      "Training loss (for one batch) at step 40: 437.0542, Accuracy: 0.6242\n",
      "Training loss (for one batch) at step 50: 428.0001, Accuracy: 0.6210\n",
      "Training loss (for one batch) at step 60: 441.4963, Accuracy: 0.6154\n",
      "Training loss (for one batch) at step 70: 435.0880, Accuracy: 0.6147\n",
      "Training loss (for one batch) at step 80: 440.0602, Accuracy: 0.6136\n",
      "Training loss (for one batch) at step 90: 422.9405, Accuracy: 0.6126\n",
      "Training loss (for one batch) at step 100: 425.1061, Accuracy: 0.6140\n",
      "Training loss (for one batch) at step 110: 427.1690, Accuracy: 0.6120\n",
      "---- Training ----\n",
      "Training loss: 132.3874\n",
      "Training acc over epoch: 0.6108\n",
      "---- Validation ----\n",
      "Validation loss: 32.8847\n",
      "Validation acc: 0.6061\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 439.7621, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 438.5103, Accuracy: 0.6165\n",
      "Training loss (for one batch) at step 20: 432.2177, Accuracy: 0.6287\n",
      "Training loss (for one batch) at step 30: 424.1001, Accuracy: 0.6278\n",
      "Training loss (for one batch) at step 40: 417.9252, Accuracy: 0.6214\n",
      "Training loss (for one batch) at step 50: 432.0038, Accuracy: 0.6180\n",
      "Training loss (for one batch) at step 60: 428.7497, Accuracy: 0.6145\n",
      "Training loss (for one batch) at step 70: 436.8295, Accuracy: 0.6125\n",
      "Training loss (for one batch) at step 80: 432.2136, Accuracy: 0.6128\n",
      "Training loss (for one batch) at step 90: 433.5203, Accuracy: 0.6142\n",
      "Training loss (for one batch) at step 100: 428.3211, Accuracy: 0.6141\n",
      "Training loss (for one batch) at step 110: 430.3913, Accuracy: 0.6129\n",
      "---- Training ----\n",
      "Training loss: 132.6033\n",
      "Training acc over epoch: 0.6119\n",
      "---- Validation ----\n",
      "Validation loss: 35.0867\n",
      "Validation acc: 0.5846\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 442.8963, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 440.6633, Accuracy: 0.6151\n",
      "Training loss (for one batch) at step 20: 438.7794, Accuracy: 0.6365\n",
      "Training loss (for one batch) at step 30: 418.9522, Accuracy: 0.6394\n",
      "Training loss (for one batch) at step 40: 418.1322, Accuracy: 0.6391\n",
      "Training loss (for one batch) at step 50: 409.0760, Accuracy: 0.6347\n",
      "Training loss (for one batch) at step 60: 422.9426, Accuracy: 0.6329\n",
      "Training loss (for one batch) at step 70: 446.1931, Accuracy: 0.6317\n",
      "Training loss (for one batch) at step 80: 427.5255, Accuracy: 0.6307\n",
      "Training loss (for one batch) at step 90: 427.2359, Accuracy: 0.6296\n",
      "Training loss (for one batch) at step 100: 428.2096, Accuracy: 0.6285\n",
      "Training loss (for one batch) at step 110: 429.1644, Accuracy: 0.6259\n",
      "---- Training ----\n",
      "Training loss: 134.1479\n",
      "Training acc over epoch: 0.6245\n",
      "---- Validation ----\n",
      "Validation loss: 34.4890\n",
      "Validation acc: 0.6029\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 441.3986, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 440.4522, Accuracy: 0.6179\n",
      "Training loss (for one batch) at step 20: 430.0307, Accuracy: 0.6473\n",
      "Training loss (for one batch) at step 30: 425.4662, Accuracy: 0.6482\n",
      "Training loss (for one batch) at step 40: 417.3680, Accuracy: 0.6416\n",
      "Training loss (for one batch) at step 50: 414.8093, Accuracy: 0.6394\n",
      "Training loss (for one batch) at step 60: 428.1497, Accuracy: 0.6363\n",
      "Training loss (for one batch) at step 70: 446.8354, Accuracy: 0.6355\n",
      "Training loss (for one batch) at step 80: 430.7756, Accuracy: 0.6295\n",
      "Training loss (for one batch) at step 90: 424.4415, Accuracy: 0.6266\n",
      "Training loss (for one batch) at step 100: 421.7605, Accuracy: 0.6259\n",
      "Training loss (for one batch) at step 110: 419.3812, Accuracy: 0.6228\n",
      "---- Training ----\n",
      "Training loss: 140.4587\n",
      "Training acc over epoch: 0.6226\n",
      "---- Validation ----\n",
      "Validation loss: 34.6013\n",
      "Validation acc: 0.5811\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 440.6028, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 430.1600, Accuracy: 0.6335\n",
      "Training loss (for one batch) at step 20: 422.6569, Accuracy: 0.6395\n",
      "Training loss (for one batch) at step 30: 417.6847, Accuracy: 0.6436\n",
      "Training loss (for one batch) at step 40: 413.4338, Accuracy: 0.6351\n",
      "Training loss (for one batch) at step 50: 426.9011, Accuracy: 0.6342\n",
      "Training loss (for one batch) at step 60: 420.8501, Accuracy: 0.6320\n",
      "Training loss (for one batch) at step 70: 431.0809, Accuracy: 0.6292\n",
      "Training loss (for one batch) at step 80: 432.8988, Accuracy: 0.6269\n",
      "Training loss (for one batch) at step 90: 416.3814, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 100: 426.8878, Accuracy: 0.6246\n",
      "Training loss (for one batch) at step 110: 428.7532, Accuracy: 0.6217\n",
      "---- Training ----\n",
      "Training loss: 130.7304\n",
      "Training acc over epoch: 0.6209\n",
      "---- Validation ----\n",
      "Validation loss: 37.3670\n",
      "Validation acc: 0.5739\n",
      "Time taken: 10.86s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 432.4126, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 426.9665, Accuracy: 0.6655\n",
      "Training loss (for one batch) at step 20: 430.8228, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 30: 421.4394, Accuracy: 0.6492\n",
      "Training loss (for one batch) at step 40: 406.7209, Accuracy: 0.6490\n",
      "Training loss (for one batch) at step 50: 404.8075, Accuracy: 0.6477\n",
      "Training loss (for one batch) at step 60: 418.7286, Accuracy: 0.6457\n",
      "Training loss (for one batch) at step 70: 421.2730, Accuracy: 0.6452\n",
      "Training loss (for one batch) at step 80: 436.7608, Accuracy: 0.6437\n",
      "Training loss (for one batch) at step 90: 417.3994, Accuracy: 0.6411\n",
      "Training loss (for one batch) at step 100: 414.4019, Accuracy: 0.6378\n",
      "Training loss (for one batch) at step 110: 417.9161, Accuracy: 0.6345\n",
      "---- Training ----\n",
      "Training loss: 131.3678\n",
      "Training acc over epoch: 0.6339\n",
      "---- Validation ----\n",
      "Validation loss: 38.0100\n",
      "Validation acc: 0.6225\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 426.8896, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 424.3188, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 20: 418.8437, Accuracy: 0.6362\n",
      "Training loss (for one batch) at step 30: 411.1696, Accuracy: 0.6416\n",
      "Training loss (for one batch) at step 40: 408.9947, Accuracy: 0.6429\n",
      "Training loss (for one batch) at step 50: 406.6962, Accuracy: 0.6414\n",
      "Training loss (for one batch) at step 60: 416.6844, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 70: 421.6098, Accuracy: 0.6381\n",
      "Training loss (for one batch) at step 80: 413.7734, Accuracy: 0.6380\n",
      "Training loss (for one batch) at step 90: 431.9533, Accuracy: 0.6340\n",
      "Training loss (for one batch) at step 100: 415.5188, Accuracy: 0.6327\n",
      "Training loss (for one batch) at step 110: 432.6198, Accuracy: 0.6307\n",
      "---- Training ----\n",
      "Training loss: 130.0345\n",
      "Training acc over epoch: 0.6294\n",
      "---- Validation ----\n",
      "Validation loss: 33.6428\n",
      "Validation acc: 0.6096\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 424.2462, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 420.1621, Accuracy: 0.6705\n",
      "Training loss (for one batch) at step 20: 422.5388, Accuracy: 0.6670\n",
      "Training loss (for one batch) at step 30: 410.3074, Accuracy: 0.6603\n",
      "Training loss (for one batch) at step 40: 403.9317, Accuracy: 0.6568\n",
      "Training loss (for one batch) at step 50: 408.3870, Accuracy: 0.6504\n",
      "Training loss (for one batch) at step 60: 411.6493, Accuracy: 0.6522\n",
      "Training loss (for one batch) at step 70: 432.6849, Accuracy: 0.6516\n",
      "Training loss (for one batch) at step 80: 431.7890, Accuracy: 0.6508\n",
      "Training loss (for one batch) at step 90: 421.9213, Accuracy: 0.6487\n",
      "Training loss (for one batch) at step 100: 416.0493, Accuracy: 0.6449\n",
      "Training loss (for one batch) at step 110: 430.5080, Accuracy: 0.6428\n",
      "---- Training ----\n",
      "Training loss: 132.6714\n",
      "Training acc over epoch: 0.6412\n",
      "---- Validation ----\n",
      "Validation loss: 32.2047\n",
      "Validation acc: 0.5790\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 429.4047, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 427.6483, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 20: 404.4566, Accuracy: 0.6488\n",
      "Training loss (for one batch) at step 30: 411.5610, Accuracy: 0.6530\n",
      "Training loss (for one batch) at step 40: 407.7426, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 50: 400.0973, Accuracy: 0.6509\n",
      "Training loss (for one batch) at step 60: 400.3929, Accuracy: 0.6496\n",
      "Training loss (for one batch) at step 70: 412.8819, Accuracy: 0.6496\n",
      "Training loss (for one batch) at step 80: 414.5846, Accuracy: 0.6519\n",
      "Training loss (for one batch) at step 90: 428.2470, Accuracy: 0.6505\n",
      "Training loss (for one batch) at step 100: 408.1625, Accuracy: 0.6481\n",
      "Training loss (for one batch) at step 110: 420.2564, Accuracy: 0.6420\n",
      "---- Training ----\n",
      "Training loss: 134.8624\n",
      "Training acc over epoch: 0.6409\n",
      "---- Validation ----\n",
      "Validation loss: 34.6799\n",
      "Validation acc: 0.6042\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 424.6599, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 422.2045, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 20: 406.0720, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 30: 406.4469, Accuracy: 0.6613\n",
      "Training loss (for one batch) at step 40: 399.7022, Accuracy: 0.6603\n",
      "Training loss (for one batch) at step 50: 392.4031, Accuracy: 0.6585\n",
      "Training loss (for one batch) at step 60: 417.8662, Accuracy: 0.6538\n",
      "Training loss (for one batch) at step 70: 411.1077, Accuracy: 0.6553\n",
      "Training loss (for one batch) at step 80: 408.6954, Accuracy: 0.6546\n",
      "Training loss (for one batch) at step 90: 411.7965, Accuracy: 0.6520\n",
      "Training loss (for one batch) at step 100: 414.3541, Accuracy: 0.6511\n",
      "Training loss (for one batch) at step 110: 413.5152, Accuracy: 0.6465\n",
      "---- Training ----\n",
      "Training loss: 134.8808\n",
      "Training acc over epoch: 0.6456\n",
      "---- Validation ----\n",
      "Validation loss: 36.3903\n",
      "Validation acc: 0.5774\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 428.1189, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 423.2065, Accuracy: 0.6591\n",
      "Training loss (for one batch) at step 20: 421.8775, Accuracy: 0.6507\n",
      "Training loss (for one batch) at step 30: 392.2225, Accuracy: 0.6530\n",
      "Training loss (for one batch) at step 40: 409.7081, Accuracy: 0.6551\n",
      "Training loss (for one batch) at step 50: 401.0772, Accuracy: 0.6543\n",
      "Training loss (for one batch) at step 60: 396.9714, Accuracy: 0.6510\n",
      "Training loss (for one batch) at step 70: 403.0447, Accuracy: 0.6538\n",
      "Training loss (for one batch) at step 80: 416.0340, Accuracy: 0.6547\n",
      "Training loss (for one batch) at step 90: 403.7478, Accuracy: 0.6544\n",
      "Training loss (for one batch) at step 100: 394.2446, Accuracy: 0.6533\n",
      "Training loss (for one batch) at step 110: 407.6378, Accuracy: 0.6493\n",
      "---- Training ----\n",
      "Training loss: 129.9874\n",
      "Training acc over epoch: 0.6478\n",
      "---- Validation ----\n",
      "Validation loss: 39.5614\n",
      "Validation acc: 0.5830\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 422.4618, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 430.3080, Accuracy: 0.6420\n",
      "Training loss (for one batch) at step 20: 404.0652, Accuracy: 0.6466\n",
      "Training loss (for one batch) at step 30: 408.5399, Accuracy: 0.6537\n",
      "Training loss (for one batch) at step 40: 393.0984, Accuracy: 0.6542\n",
      "Training loss (for one batch) at step 50: 399.2630, Accuracy: 0.6506\n",
      "Training loss (for one batch) at step 60: 398.2393, Accuracy: 0.6482\n",
      "Training loss (for one batch) at step 70: 420.9814, Accuracy: 0.6493\n",
      "Training loss (for one batch) at step 80: 406.9523, Accuracy: 0.6507\n",
      "Training loss (for one batch) at step 90: 396.9454, Accuracy: 0.6489\n",
      "Training loss (for one batch) at step 100: 404.7622, Accuracy: 0.6474\n",
      "Training loss (for one batch) at step 110: 416.9987, Accuracy: 0.6437\n",
      "---- Training ----\n",
      "Training loss: 128.5220\n",
      "Training acc over epoch: 0.6427\n",
      "---- Validation ----\n",
      "Validation loss: 38.0094\n",
      "Validation acc: 0.5833\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 422.8802, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 403.8396, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 20: 389.3484, Accuracy: 0.6581\n",
      "Training loss (for one batch) at step 30: 384.6408, Accuracy: 0.6575\n",
      "Training loss (for one batch) at step 40: 377.5344, Accuracy: 0.6538\n",
      "Training loss (for one batch) at step 50: 367.9994, Accuracy: 0.6523\n",
      "Training loss (for one batch) at step 60: 386.3713, Accuracy: 0.6464\n",
      "Training loss (for one batch) at step 70: 402.1819, Accuracy: 0.6485\n",
      "Training loss (for one batch) at step 80: 425.0185, Accuracy: 0.6508\n",
      "Training loss (for one batch) at step 90: 407.2885, Accuracy: 0.6459\n",
      "Training loss (for one batch) at step 100: 397.6174, Accuracy: 0.6433\n",
      "Training loss (for one batch) at step 110: 419.0265, Accuracy: 0.6424\n",
      "---- Training ----\n",
      "Training loss: 128.0786\n",
      "Training acc over epoch: 0.6423\n",
      "---- Validation ----\n",
      "Validation loss: 36.7869\n",
      "Validation acc: 0.5970\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 399.4319, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 405.7692, Accuracy: 0.6832\n",
      "Training loss (for one batch) at step 20: 392.1234, Accuracy: 0.6734\n",
      "Training loss (for one batch) at step 30: 383.2660, Accuracy: 0.6643\n",
      "Training loss (for one batch) at step 40: 381.8636, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 50: 388.5380, Accuracy: 0.6549\n",
      "Training loss (for one batch) at step 60: 394.2662, Accuracy: 0.6560\n",
      "Training loss (for one batch) at step 70: 415.1049, Accuracy: 0.6549\n",
      "Training loss (for one batch) at step 80: 404.8170, Accuracy: 0.6591\n",
      "Training loss (for one batch) at step 90: 383.1075, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 100: 375.2816, Accuracy: 0.6554\n",
      "Training loss (for one batch) at step 110: 381.5884, Accuracy: 0.6516\n",
      "---- Training ----\n",
      "Training loss: 130.6952\n",
      "Training acc over epoch: 0.6501\n",
      "---- Validation ----\n",
      "Validation loss: 33.9500\n",
      "Validation acc: 0.5650\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 406.6681, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 426.6683, Accuracy: 0.6818\n",
      "Training loss (for one batch) at step 20: 389.6186, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 30: 379.5564, Accuracy: 0.6673\n",
      "Training loss (for one batch) at step 40: 382.8966, Accuracy: 0.6606\n",
      "Training loss (for one batch) at step 50: 379.2004, Accuracy: 0.6558\n",
      "Training loss (for one batch) at step 60: 383.6588, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 70: 399.3962, Accuracy: 0.6527\n",
      "Training loss (for one batch) at step 80: 409.0607, Accuracy: 0.6531\n",
      "Training loss (for one batch) at step 90: 384.2066, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 100: 377.2205, Accuracy: 0.6508\n",
      "Training loss (for one batch) at step 110: 399.7237, Accuracy: 0.6510\n",
      "---- Training ----\n",
      "Training loss: 130.0645\n",
      "Training acc over epoch: 0.6499\n",
      "---- Validation ----\n",
      "Validation loss: 38.4496\n",
      "Validation acc: 0.5924\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 406.2803, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 425.7004, Accuracy: 0.7003\n",
      "Training loss (for one batch) at step 20: 368.7132, Accuracy: 0.6808\n",
      "Training loss (for one batch) at step 30: 373.3000, Accuracy: 0.6746\n",
      "Training loss (for one batch) at step 40: 383.7706, Accuracy: 0.6663\n",
      "Training loss (for one batch) at step 50: 370.1364, Accuracy: 0.6634\n",
      "Training loss (for one batch) at step 60: 380.4674, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 70: 405.8473, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 80: 402.8725, Accuracy: 0.6580\n",
      "Training loss (for one batch) at step 90: 375.6730, Accuracy: 0.6569\n",
      "Training loss (for one batch) at step 100: 364.3490, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 110: 393.8901, Accuracy: 0.6489\n",
      "---- Training ----\n",
      "Training loss: 124.0243\n",
      "Training acc over epoch: 0.6505\n",
      "---- Validation ----\n",
      "Validation loss: 31.7961\n",
      "Validation acc: 0.5946\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 394.9643, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 393.9823, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 373.0548, Accuracy: 0.6935\n",
      "Training loss (for one batch) at step 30: 365.0641, Accuracy: 0.6827\n",
      "Training loss (for one batch) at step 40: 371.2823, Accuracy: 0.6755\n",
      "Training loss (for one batch) at step 50: 366.4217, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 60: 383.5297, Accuracy: 0.6678\n",
      "Training loss (for one batch) at step 70: 417.5402, Accuracy: 0.6671\n",
      "Training loss (for one batch) at step 80: 391.1219, Accuracy: 0.6683\n",
      "Training loss (for one batch) at step 90: 371.1606, Accuracy: 0.6661\n",
      "Training loss (for one batch) at step 100: 394.2741, Accuracy: 0.6610\n",
      "Training loss (for one batch) at step 110: 395.6398, Accuracy: 0.6571\n",
      "---- Training ----\n",
      "Training loss: 113.2414\n",
      "Training acc over epoch: 0.6567\n",
      "---- Validation ----\n",
      "Validation loss: 36.1472\n",
      "Validation acc: 0.6010\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 387.4798, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 413.6863, Accuracy: 0.6889\n",
      "Training loss (for one batch) at step 20: 389.9888, Accuracy: 0.6819\n",
      "Training loss (for one batch) at step 30: 383.4828, Accuracy: 0.6777\n",
      "Training loss (for one batch) at step 40: 367.1052, Accuracy: 0.6764\n",
      "Training loss (for one batch) at step 50: 360.0479, Accuracy: 0.6708\n",
      "Training loss (for one batch) at step 60: 366.7521, Accuracy: 0.6701\n",
      "Training loss (for one batch) at step 70: 404.2455, Accuracy: 0.6715\n",
      "Training loss (for one batch) at step 80: 386.9625, Accuracy: 0.6703\n",
      "Training loss (for one batch) at step 90: 389.9213, Accuracy: 0.6671\n",
      "Training loss (for one batch) at step 100: 359.0198, Accuracy: 0.6621\n",
      "Training loss (for one batch) at step 110: 396.6973, Accuracy: 0.6608\n",
      "---- Training ----\n",
      "Training loss: 114.8151\n",
      "Training acc over epoch: 0.6601\n",
      "---- Validation ----\n",
      "Validation loss: 34.2898\n",
      "Validation acc: 0.6147\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 403.3413, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 413.0593, Accuracy: 0.6939\n",
      "Training loss (for one batch) at step 20: 365.8138, Accuracy: 0.6879\n",
      "Training loss (for one batch) at step 30: 350.4520, Accuracy: 0.6716\n",
      "Training loss (for one batch) at step 40: 365.7183, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 50: 360.1008, Accuracy: 0.6621\n",
      "Training loss (for one batch) at step 60: 372.8493, Accuracy: 0.6616\n",
      "Training loss (for one batch) at step 70: 381.0358, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 80: 384.7064, Accuracy: 0.6656\n",
      "Training loss (for one batch) at step 90: 355.6696, Accuracy: 0.6640\n",
      "Training loss (for one batch) at step 100: 367.5477, Accuracy: 0.6601\n",
      "Training loss (for one batch) at step 110: 379.4366, Accuracy: 0.6585\n",
      "---- Training ----\n",
      "Training loss: 113.2464\n",
      "Training acc over epoch: 0.6570\n",
      "---- Validation ----\n",
      "Validation loss: 32.0949\n",
      "Validation acc: 0.6102\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 405.1590, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 391.7632, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 20: 362.3261, Accuracy: 0.6927\n",
      "Training loss (for one batch) at step 30: 353.1356, Accuracy: 0.6779\n",
      "Training loss (for one batch) at step 40: 379.6438, Accuracy: 0.6705\n",
      "Training loss (for one batch) at step 50: 347.1942, Accuracy: 0.6691\n",
      "Training loss (for one batch) at step 60: 373.2494, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 70: 378.2488, Accuracy: 0.6654\n",
      "Training loss (for one batch) at step 80: 395.2551, Accuracy: 0.6659\n",
      "Training loss (for one batch) at step 90: 369.6786, Accuracy: 0.6630\n",
      "Training loss (for one batch) at step 100: 366.0690, Accuracy: 0.6593\n",
      "Training loss (for one batch) at step 110: 360.1613, Accuracy: 0.6546\n",
      "---- Training ----\n",
      "Training loss: 130.5656\n",
      "Training acc over epoch: 0.6533\n",
      "---- Validation ----\n",
      "Validation loss: 31.4064\n",
      "Validation acc: 0.5946\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 401.0779, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 371.7144, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 20: 370.0067, Accuracy: 0.6819\n",
      "Training loss (for one batch) at step 30: 342.1860, Accuracy: 0.6802\n",
      "Training loss (for one batch) at step 40: 358.1308, Accuracy: 0.6738\n",
      "Training loss (for one batch) at step 50: 349.7628, Accuracy: 0.6673\n",
      "Training loss (for one batch) at step 60: 370.2174, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 70: 411.3251, Accuracy: 0.6674\n",
      "Training loss (for one batch) at step 80: 376.4691, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 90: 356.2667, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 100: 354.2220, Accuracy: 0.6624\n",
      "Training loss (for one batch) at step 110: 371.8721, Accuracy: 0.6588\n",
      "---- Training ----\n",
      "Training loss: 117.5564\n",
      "Training acc over epoch: 0.6582\n",
      "---- Validation ----\n",
      "Validation loss: 42.7999\n",
      "Validation acc: 0.6107\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 377.8320, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 378.6151, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 20: 353.9085, Accuracy: 0.6964\n",
      "Training loss (for one batch) at step 30: 346.1332, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 40: 341.0465, Accuracy: 0.6755\n",
      "Training loss (for one batch) at step 50: 344.0281, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 60: 378.4766, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 70: 378.3839, Accuracy: 0.6666\n",
      "Training loss (for one batch) at step 80: 387.0858, Accuracy: 0.6668\n",
      "Training loss (for one batch) at step 90: 358.0141, Accuracy: 0.6643\n",
      "Training loss (for one batch) at step 100: 370.0970, Accuracy: 0.6603\n",
      "Training loss (for one batch) at step 110: 385.4878, Accuracy: 0.6569\n",
      "---- Training ----\n",
      "Training loss: 120.6877\n",
      "Training acc over epoch: 0.6573\n",
      "---- Validation ----\n",
      "Validation loss: 41.8288\n",
      "Validation acc: 0.5994\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 390.7589, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 370.0239, Accuracy: 0.6974\n",
      "Training loss (for one batch) at step 20: 356.5068, Accuracy: 0.6864\n",
      "Training loss (for one batch) at step 30: 343.9530, Accuracy: 0.6757\n",
      "Training loss (for one batch) at step 40: 340.3655, Accuracy: 0.6766\n",
      "Training loss (for one batch) at step 50: 339.6612, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 60: 348.2442, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 70: 381.4871, Accuracy: 0.6691\n",
      "Training loss (for one batch) at step 80: 383.9005, Accuracy: 0.6714\n",
      "Training loss (for one batch) at step 90: 359.8333, Accuracy: 0.6686\n",
      "Training loss (for one batch) at step 100: 355.6588, Accuracy: 0.6634\n",
      "Training loss (for one batch) at step 110: 357.2753, Accuracy: 0.6593\n",
      "---- Training ----\n",
      "Training loss: 119.0535\n",
      "Training acc over epoch: 0.6593\n",
      "---- Validation ----\n",
      "Validation loss: 34.4978\n",
      "Validation acc: 0.5895\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 385.0846, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 382.0712, Accuracy: 0.6832\n",
      "Training loss (for one batch) at step 20: 367.7744, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 30: 342.9146, Accuracy: 0.6777\n",
      "Training loss (for one batch) at step 40: 338.1586, Accuracy: 0.6711\n",
      "Training loss (for one batch) at step 50: 345.6173, Accuracy: 0.6661\n",
      "Training loss (for one batch) at step 60: 367.5895, Accuracy: 0.6614\n",
      "Training loss (for one batch) at step 70: 369.5118, Accuracy: 0.6603\n",
      "Training loss (for one batch) at step 80: 370.2834, Accuracy: 0.6622\n",
      "Training loss (for one batch) at step 90: 370.9297, Accuracy: 0.6597\n",
      "Training loss (for one batch) at step 100: 351.7098, Accuracy: 0.6552\n",
      "Training loss (for one batch) at step 110: 355.1481, Accuracy: 0.6526\n",
      "---- Training ----\n",
      "Training loss: 111.1074\n",
      "Training acc over epoch: 0.6527\n",
      "---- Validation ----\n",
      "Validation loss: 45.3048\n",
      "Validation acc: 0.6029\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 382.5540, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 377.1182, Accuracy: 0.6967\n",
      "Training loss (for one batch) at step 20: 350.2937, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 30: 351.2780, Accuracy: 0.6809\n",
      "Training loss (for one batch) at step 40: 343.7622, Accuracy: 0.6801\n",
      "Training loss (for one batch) at step 50: 341.6139, Accuracy: 0.6734\n",
      "Training loss (for one batch) at step 60: 358.7177, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 70: 379.8312, Accuracy: 0.6652\n",
      "Training loss (for one batch) at step 80: 385.0706, Accuracy: 0.6673\n",
      "Training loss (for one batch) at step 90: 371.7375, Accuracy: 0.6672\n",
      "Training loss (for one batch) at step 100: 333.1808, Accuracy: 0.6630\n",
      "Training loss (for one batch) at step 110: 378.0758, Accuracy: 0.6594\n",
      "---- Training ----\n",
      "Training loss: 119.9568\n",
      "Training acc over epoch: 0.6577\n",
      "---- Validation ----\n",
      "Validation loss: 37.5085\n",
      "Validation acc: 0.5935\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 375.1214, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 396.0823, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 20: 367.7458, Accuracy: 0.6897\n",
      "Training loss (for one batch) at step 30: 347.0334, Accuracy: 0.6820\n",
      "Training loss (for one batch) at step 40: 337.4196, Accuracy: 0.6738\n",
      "Training loss (for one batch) at step 50: 362.7782, Accuracy: 0.6720\n",
      "Training loss (for one batch) at step 60: 345.2769, Accuracy: 0.6694\n",
      "Training loss (for one batch) at step 70: 374.5158, Accuracy: 0.6686\n",
      "Training loss (for one batch) at step 80: 367.1060, Accuracy: 0.6686\n",
      "Training loss (for one batch) at step 90: 357.3266, Accuracy: 0.6670\n",
      "Training loss (for one batch) at step 100: 339.2631, Accuracy: 0.6635\n",
      "Training loss (for one batch) at step 110: 375.9718, Accuracy: 0.6602\n",
      "---- Training ----\n",
      "Training loss: 113.3433\n",
      "Training acc over epoch: 0.6601\n",
      "---- Validation ----\n",
      "Validation loss: 34.3933\n",
      "Validation acc: 0.6037\n",
      "Time taken: 10.20s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 390.3444, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 372.0757, Accuracy: 0.7067\n",
      "Training loss (for one batch) at step 20: 356.2044, Accuracy: 0.6912\n",
      "Training loss (for one batch) at step 30: 363.1599, Accuracy: 0.6822\n",
      "Training loss (for one batch) at step 40: 340.0999, Accuracy: 0.6780\n",
      "Training loss (for one batch) at step 50: 333.8551, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 60: 349.6449, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 70: 361.1255, Accuracy: 0.6685\n",
      "Training loss (for one batch) at step 80: 375.2906, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 90: 366.2951, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 100: 355.4845, Accuracy: 0.6650\n",
      "Training loss (for one batch) at step 110: 355.5695, Accuracy: 0.6603\n",
      "---- Training ----\n",
      "Training loss: 119.6534\n",
      "Training acc over epoch: 0.6613\n",
      "---- Validation ----\n",
      "Validation loss: 38.9840\n",
      "Validation acc: 0.5913\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 378.7744, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 378.5905, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 20: 332.4748, Accuracy: 0.6868\n",
      "Training loss (for one batch) at step 30: 329.7610, Accuracy: 0.6784\n",
      "Training loss (for one batch) at step 40: 354.6797, Accuracy: 0.6713\n",
      "Training loss (for one batch) at step 50: 330.3762, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 60: 337.5998, Accuracy: 0.6703\n",
      "Training loss (for one batch) at step 70: 349.6877, Accuracy: 0.6695\n",
      "Training loss (for one batch) at step 80: 383.7580, Accuracy: 0.6700\n",
      "Training loss (for one batch) at step 90: 346.4251, Accuracy: 0.6660\n",
      "Training loss (for one batch) at step 100: 339.5695, Accuracy: 0.6622\n",
      "Training loss (for one batch) at step 110: 353.4850, Accuracy: 0.6609\n",
      "---- Training ----\n",
      "Training loss: 107.4722\n",
      "Training acc over epoch: 0.6601\n",
      "---- Validation ----\n",
      "Validation loss: 41.5157\n",
      "Validation acc: 0.6080\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 380.9087, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 382.6647, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 20: 319.4588, Accuracy: 0.6905\n",
      "Training loss (for one batch) at step 30: 314.9413, Accuracy: 0.6757\n",
      "Training loss (for one batch) at step 40: 341.9004, Accuracy: 0.6724\n",
      "Training loss (for one batch) at step 50: 330.6731, Accuracy: 0.6679\n",
      "Training loss (for one batch) at step 60: 350.5983, Accuracy: 0.6660\n",
      "Training loss (for one batch) at step 70: 386.6498, Accuracy: 0.6671\n",
      "Training loss (for one batch) at step 80: 378.0471, Accuracy: 0.6674\n",
      "Training loss (for one batch) at step 90: 351.7501, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 100: 327.3410, Accuracy: 0.6590\n",
      "Training loss (for one batch) at step 110: 354.1787, Accuracy: 0.6576\n",
      "---- Training ----\n",
      "Training loss: 115.2787\n",
      "Training acc over epoch: 0.6566\n",
      "---- Validation ----\n",
      "Validation loss: 42.7374\n",
      "Validation acc: 0.6190\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 359.0451, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 393.8292, Accuracy: 0.7230\n",
      "Training loss (for one batch) at step 20: 330.7723, Accuracy: 0.7050\n",
      "Training loss (for one batch) at step 30: 333.8868, Accuracy: 0.6933\n",
      "Training loss (for one batch) at step 40: 332.7976, Accuracy: 0.6850\n",
      "Training loss (for one batch) at step 50: 323.2419, Accuracy: 0.6763\n",
      "Training loss (for one batch) at step 60: 329.5233, Accuracy: 0.6735\n",
      "Training loss (for one batch) at step 70: 364.1179, Accuracy: 0.6715\n",
      "Training loss (for one batch) at step 80: 362.0585, Accuracy: 0.6727\n",
      "Training loss (for one batch) at step 90: 333.0966, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 100: 340.8364, Accuracy: 0.6663\n",
      "Training loss (for one batch) at step 110: 336.4586, Accuracy: 0.6640\n",
      "---- Training ----\n",
      "Training loss: 112.6910\n",
      "Training acc over epoch: 0.6650\n",
      "---- Validation ----\n",
      "Validation loss: 42.7507\n",
      "Validation acc: 0.6188\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 378.9276, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 379.9185, Accuracy: 0.7024\n",
      "Training loss (for one batch) at step 20: 339.2355, Accuracy: 0.6972\n",
      "Training loss (for one batch) at step 30: 325.4431, Accuracy: 0.6862\n",
      "Training loss (for one batch) at step 40: 326.3277, Accuracy: 0.6772\n",
      "Training loss (for one batch) at step 50: 313.5965, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 60: 339.6072, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 70: 371.8324, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 80: 359.2655, Accuracy: 0.6675\n",
      "Training loss (for one batch) at step 90: 336.6208, Accuracy: 0.6635\n",
      "Training loss (for one batch) at step 100: 331.8651, Accuracy: 0.6608\n",
      "Training loss (for one batch) at step 110: 347.6640, Accuracy: 0.6570\n",
      "---- Training ----\n",
      "Training loss: 122.6111\n",
      "Training acc over epoch: 0.6575\n",
      "---- Validation ----\n",
      "Validation loss: 35.2675\n",
      "Validation acc: 0.6118\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 379.7888, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 366.0228, Accuracy: 0.7145\n",
      "Training loss (for one batch) at step 20: 319.8237, Accuracy: 0.6961\n",
      "Training loss (for one batch) at step 30: 322.9090, Accuracy: 0.6867\n",
      "Training loss (for one batch) at step 40: 335.6892, Accuracy: 0.6772\n",
      "Training loss (for one batch) at step 50: 317.4346, Accuracy: 0.6739\n",
      "Training loss (for one batch) at step 60: 327.1736, Accuracy: 0.6706\n",
      "Training loss (for one batch) at step 70: 344.3489, Accuracy: 0.6692\n",
      "Training loss (for one batch) at step 80: 376.2982, Accuracy: 0.6694\n",
      "Training loss (for one batch) at step 90: 325.7767, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 100: 326.2305, Accuracy: 0.6660\n",
      "Training loss (for one batch) at step 110: 356.0301, Accuracy: 0.6626\n",
      "---- Training ----\n",
      "Training loss: 125.5866\n",
      "Training acc over epoch: 0.6619\n",
      "---- Validation ----\n",
      "Validation loss: 44.5456\n",
      "Validation acc: 0.6067\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 367.3454, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 359.4801, Accuracy: 0.7216\n",
      "Training loss (for one batch) at step 20: 326.1092, Accuracy: 0.7001\n",
      "Training loss (for one batch) at step 30: 320.6622, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 40: 332.1608, Accuracy: 0.6862\n",
      "Training loss (for one batch) at step 50: 325.7229, Accuracy: 0.6820\n",
      "Training loss (for one batch) at step 60: 361.1664, Accuracy: 0.6746\n",
      "Training loss (for one batch) at step 70: 335.1013, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 80: 350.5726, Accuracy: 0.6707\n",
      "Training loss (for one batch) at step 90: 336.9710, Accuracy: 0.6689\n",
      "Training loss (for one batch) at step 100: 324.0411, Accuracy: 0.6642\n",
      "Training loss (for one batch) at step 110: 332.6931, Accuracy: 0.6620\n",
      "---- Training ----\n",
      "Training loss: 105.1001\n",
      "Training acc over epoch: 0.6609\n",
      "---- Validation ----\n",
      "Validation loss: 38.5686\n",
      "Validation acc: 0.6008\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 346.8725, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 371.3962, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 334.0930, Accuracy: 0.6990\n",
      "Training loss (for one batch) at step 30: 322.4356, Accuracy: 0.6893\n",
      "Training loss (for one batch) at step 40: 332.1813, Accuracy: 0.6804\n",
      "Training loss (for one batch) at step 50: 320.2260, Accuracy: 0.6769\n",
      "Training loss (for one batch) at step 60: 320.8238, Accuracy: 0.6725\n",
      "Training loss (for one batch) at step 70: 356.5721, Accuracy: 0.6707\n",
      "Training loss (for one batch) at step 80: 355.0818, Accuracy: 0.6718\n",
      "Training loss (for one batch) at step 90: 327.4026, Accuracy: 0.6700\n",
      "Training loss (for one batch) at step 100: 310.6745, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 110: 334.6324, Accuracy: 0.6633\n",
      "---- Training ----\n",
      "Training loss: 115.6621\n",
      "Training acc over epoch: 0.6636\n",
      "---- Validation ----\n",
      "Validation loss: 49.5728\n",
      "Validation acc: 0.6177\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 358.0545, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 375.9439, Accuracy: 0.7131\n",
      "Training loss (for one batch) at step 20: 333.8054, Accuracy: 0.7009\n",
      "Training loss (for one batch) at step 30: 307.2610, Accuracy: 0.6837\n",
      "Training loss (for one batch) at step 40: 314.5205, Accuracy: 0.6791\n",
      "Training loss (for one batch) at step 50: 308.5387, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 60: 334.1149, Accuracy: 0.6711\n",
      "Training loss (for one batch) at step 70: 342.2288, Accuracy: 0.6701\n",
      "Training loss (for one batch) at step 80: 354.6211, Accuracy: 0.6701\n",
      "Training loss (for one batch) at step 90: 327.4541, Accuracy: 0.6674\n",
      "Training loss (for one batch) at step 100: 328.3788, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 110: 358.9952, Accuracy: 0.6601\n",
      "---- Training ----\n",
      "Training loss: 118.4781\n",
      "Training acc over epoch: 0.6603\n",
      "---- Validation ----\n",
      "Validation loss: 37.0684\n",
      "Validation acc: 0.5913\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 366.2353, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 368.8934, Accuracy: 0.6925\n",
      "Training loss (for one batch) at step 20: 321.9110, Accuracy: 0.6864\n",
      "Training loss (for one batch) at step 30: 320.5035, Accuracy: 0.6825\n",
      "Training loss (for one batch) at step 40: 331.3160, Accuracy: 0.6744\n",
      "Training loss (for one batch) at step 50: 340.0679, Accuracy: 0.6716\n",
      "Training loss (for one batch) at step 60: 347.9738, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 70: 338.9346, Accuracy: 0.6659\n",
      "Training loss (for one batch) at step 80: 344.7879, Accuracy: 0.6671\n",
      "Training loss (for one batch) at step 90: 322.6275, Accuracy: 0.6643\n",
      "Training loss (for one batch) at step 100: 316.8340, Accuracy: 0.6616\n",
      "Training loss (for one batch) at step 110: 334.1960, Accuracy: 0.6585\n",
      "---- Training ----\n",
      "Training loss: 117.4502\n",
      "Training acc over epoch: 0.6594\n",
      "---- Validation ----\n",
      "Validation loss: 41.1193\n",
      "Validation acc: 0.6147\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 365.4482, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 378.7913, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 20: 331.8059, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 304.2970, Accuracy: 0.6862\n",
      "Training loss (for one batch) at step 40: 318.5869, Accuracy: 0.6784\n",
      "Training loss (for one batch) at step 50: 329.0023, Accuracy: 0.6766\n",
      "Training loss (for one batch) at step 60: 347.6949, Accuracy: 0.6734\n",
      "Training loss (for one batch) at step 70: 352.4757, Accuracy: 0.6740\n",
      "Training loss (for one batch) at step 80: 350.6788, Accuracy: 0.6722\n",
      "Training loss (for one batch) at step 90: 340.3908, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 100: 330.4782, Accuracy: 0.6657\n",
      "Training loss (for one batch) at step 110: 328.5493, Accuracy: 0.6630\n",
      "---- Training ----\n",
      "Training loss: 102.2927\n",
      "Training acc over epoch: 0.6621\n",
      "---- Validation ----\n",
      "Validation loss: 44.7374\n",
      "Validation acc: 0.6268\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 380.3676, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 352.1634, Accuracy: 0.7209\n",
      "Training loss (for one batch) at step 20: 325.2661, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 30: 316.1301, Accuracy: 0.6893\n",
      "Training loss (for one batch) at step 40: 320.2781, Accuracy: 0.6768\n",
      "Training loss (for one batch) at step 50: 347.4695, Accuracy: 0.6731\n",
      "Training loss (for one batch) at step 60: 323.4056, Accuracy: 0.6707\n",
      "Training loss (for one batch) at step 70: 345.7457, Accuracy: 0.6695\n",
      "Training loss (for one batch) at step 80: 341.3551, Accuracy: 0.6710\n",
      "Training loss (for one batch) at step 90: 330.6464, Accuracy: 0.6651\n",
      "Training loss (for one batch) at step 100: 324.6904, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 110: 333.4355, Accuracy: 0.6593\n",
      "---- Training ----\n",
      "Training loss: 115.7713\n",
      "Training acc over epoch: 0.6606\n",
      "---- Validation ----\n",
      "Validation loss: 42.2403\n",
      "Validation acc: 0.6107\n",
      "Time taken: 10.36s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6051\n",
      "Validation AUC: 0.6045\n",
      "Validation Balanced_ACC: 0.4171\n",
      "Validation AUCSK: 0.7745\n",
      "Validation MI: 0.1038\n",
      "Validation Normalized MI: 0.1514\n",
      "Validation Adjusted MI: 0.1514\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 672.8365, Accuracy: 0.4766\n",
      "Training loss (for one batch) at step 10: 601.5826, Accuracy: 0.5099\n",
      "Training loss (for one batch) at step 20: 563.2991, Accuracy: 0.4847\n",
      "Training loss (for one batch) at step 30: 540.3102, Accuracy: 0.4887\n",
      "Training loss (for one batch) at step 40: 548.2624, Accuracy: 0.4990\n",
      "Training loss (for one batch) at step 50: 506.2449, Accuracy: 0.5015\n",
      "Training loss (for one batch) at step 60: 518.9839, Accuracy: 0.4976\n",
      "Training loss (for one batch) at step 70: 529.9923, Accuracy: 0.4976\n",
      "Training loss (for one batch) at step 80: 498.8608, Accuracy: 0.4981\n",
      "Training loss (for one batch) at step 90: 506.7168, Accuracy: 0.4991\n",
      "Training loss (for one batch) at step 100: 496.8004, Accuracy: 0.4978\n",
      "Training loss (for one batch) at step 110: 476.4233, Accuracy: 0.5008\n",
      "---- Training ----\n",
      "Training loss: 146.8028\n",
      "Training acc over epoch: 0.4995\n",
      "---- Validation ----\n",
      "Validation loss: 35.0676\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.00s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 471.3243, Accuracy: 0.4531\n",
      "Training loss (for one batch) at step 10: 469.0092, Accuracy: 0.5185\n",
      "Training loss (for one batch) at step 20: 469.2349, Accuracy: 0.5175\n",
      "Training loss (for one batch) at step 30: 467.5761, Accuracy: 0.5174\n",
      "Training loss (for one batch) at step 40: 452.4658, Accuracy: 0.5175\n",
      "Training loss (for one batch) at step 50: 462.3298, Accuracy: 0.5213\n",
      "Training loss (for one batch) at step 60: 456.4035, Accuracy: 0.5280\n",
      "Training loss (for one batch) at step 70: 457.7769, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 80: 455.4058, Accuracy: 0.5271\n",
      "Training loss (for one batch) at step 90: 451.7848, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 100: 451.4896, Accuracy: 0.5224\n",
      "Training loss (for one batch) at step 110: 453.2516, Accuracy: 0.5207\n",
      "---- Training ----\n",
      "Training loss: 142.2992\n",
      "Training acc over epoch: 0.5205\n",
      "---- Validation ----\n",
      "Validation loss: 34.7365\n",
      "Validation acc: 0.5156\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 451.0947, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 450.0389, Accuracy: 0.5327\n",
      "Training loss (for one batch) at step 20: 446.2545, Accuracy: 0.5376\n",
      "Training loss (for one batch) at step 30: 446.2870, Accuracy: 0.5378\n",
      "Training loss (for one batch) at step 40: 446.4840, Accuracy: 0.5322\n",
      "Training loss (for one batch) at step 50: 448.5488, Accuracy: 0.5371\n",
      "Training loss (for one batch) at step 60: 449.7706, Accuracy: 0.5384\n",
      "Training loss (for one batch) at step 70: 447.2010, Accuracy: 0.5363\n",
      "Training loss (for one batch) at step 80: 444.3826, Accuracy: 0.5377\n",
      "Training loss (for one batch) at step 90: 447.5824, Accuracy: 0.5371\n",
      "Training loss (for one batch) at step 100: 448.5473, Accuracy: 0.5373\n",
      "Training loss (for one batch) at step 110: 446.3052, Accuracy: 0.5348\n",
      "---- Training ----\n",
      "Training loss: 139.8384\n",
      "Training acc over epoch: 0.5363\n",
      "---- Validation ----\n",
      "Validation loss: 34.7042\n",
      "Validation acc: 0.5242\n",
      "Time taken: 10.68s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 443.2271, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 446.9160, Accuracy: 0.5589\n",
      "Training loss (for one batch) at step 20: 441.5598, Accuracy: 0.5517\n",
      "Training loss (for one batch) at step 30: 445.2297, Accuracy: 0.5557\n",
      "Training loss (for one batch) at step 40: 444.0318, Accuracy: 0.5574\n",
      "Training loss (for one batch) at step 50: 445.2025, Accuracy: 0.5541\n",
      "Training loss (for one batch) at step 60: 444.0087, Accuracy: 0.5546\n",
      "Training loss (for one batch) at step 70: 444.5766, Accuracy: 0.5550\n",
      "Training loss (for one batch) at step 80: 446.5224, Accuracy: 0.5545\n",
      "Training loss (for one batch) at step 90: 446.0241, Accuracy: 0.5560\n",
      "Training loss (for one batch) at step 100: 445.4438, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 110: 444.5731, Accuracy: 0.5562\n",
      "---- Training ----\n",
      "Training loss: 138.7979\n",
      "Training acc over epoch: 0.5549\n",
      "---- Validation ----\n",
      "Validation loss: 34.8486\n",
      "Validation acc: 0.5771\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 444.9108, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 443.7497, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 20: 445.8199, Accuracy: 0.5554\n",
      "Training loss (for one batch) at step 30: 441.7227, Accuracy: 0.5554\n",
      "Training loss (for one batch) at step 40: 443.5701, Accuracy: 0.5614\n",
      "Training loss (for one batch) at step 50: 442.6705, Accuracy: 0.5628\n",
      "Training loss (for one batch) at step 60: 443.2131, Accuracy: 0.5630\n",
      "Training loss (for one batch) at step 70: 442.6349, Accuracy: 0.5665\n",
      "Training loss (for one batch) at step 80: 444.2549, Accuracy: 0.5693\n",
      "Training loss (for one batch) at step 90: 444.8272, Accuracy: 0.5691\n",
      "Training loss (for one batch) at step 100: 441.6999, Accuracy: 0.5684\n",
      "Training loss (for one batch) at step 110: 444.8782, Accuracy: 0.5691\n",
      "---- Training ----\n",
      "Training loss: 137.3420\n",
      "Training acc over epoch: 0.5701\n",
      "---- Validation ----\n",
      "Validation loss: 34.4785\n",
      "Validation acc: 0.6110\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 443.8503, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 443.7029, Accuracy: 0.5838\n",
      "Training loss (for one batch) at step 20: 444.2134, Accuracy: 0.5848\n",
      "Training loss (for one batch) at step 30: 441.5894, Accuracy: 0.5804\n",
      "Training loss (for one batch) at step 40: 443.5142, Accuracy: 0.5861\n",
      "Training loss (for one batch) at step 50: 441.8286, Accuracy: 0.5826\n",
      "Training loss (for one batch) at step 60: 443.5771, Accuracy: 0.5798\n",
      "Training loss (for one batch) at step 70: 441.8628, Accuracy: 0.5853\n",
      "Training loss (for one batch) at step 80: 442.8946, Accuracy: 0.5883\n",
      "Training loss (for one batch) at step 90: 440.7302, Accuracy: 0.5906\n",
      "Training loss (for one batch) at step 100: 440.3069, Accuracy: 0.5921\n",
      "Training loss (for one batch) at step 110: 441.1545, Accuracy: 0.5917\n",
      "---- Training ----\n",
      "Training loss: 138.9958\n",
      "Training acc over epoch: 0.5908\n",
      "---- Validation ----\n",
      "Validation loss: 34.8570\n",
      "Validation acc: 0.6284\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 441.0245, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 444.9054, Accuracy: 0.6115\n",
      "Training loss (for one batch) at step 20: 441.8073, Accuracy: 0.6031\n",
      "Training loss (for one batch) at step 30: 446.0325, Accuracy: 0.6028\n",
      "Training loss (for one batch) at step 40: 439.7075, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 50: 442.0478, Accuracy: 0.6042\n",
      "Training loss (for one batch) at step 60: 441.7747, Accuracy: 0.6043\n",
      "Training loss (for one batch) at step 70: 440.3047, Accuracy: 0.6085\n",
      "Training loss (for one batch) at step 80: 441.5891, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 90: 440.9081, Accuracy: 0.6099\n",
      "Training loss (for one batch) at step 100: 442.9988, Accuracy: 0.6119\n",
      "Training loss (for one batch) at step 110: 442.5576, Accuracy: 0.6124\n",
      "---- Training ----\n",
      "Training loss: 137.2334\n",
      "Training acc over epoch: 0.6132\n",
      "---- Validation ----\n",
      "Validation loss: 34.5453\n",
      "Validation acc: 0.6523\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 444.0679, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 445.5219, Accuracy: 0.6293\n",
      "Training loss (for one batch) at step 20: 441.7574, Accuracy: 0.6217\n",
      "Training loss (for one batch) at step 30: 443.3853, Accuracy: 0.6167\n",
      "Training loss (for one batch) at step 40: 442.7678, Accuracy: 0.6204\n",
      "Training loss (for one batch) at step 50: 438.1526, Accuracy: 0.6241\n",
      "Training loss (for one batch) at step 60: 437.6863, Accuracy: 0.6223\n",
      "Training loss (for one batch) at step 70: 445.3212, Accuracy: 0.6246\n",
      "Training loss (for one batch) at step 80: 445.0330, Accuracy: 0.6249\n",
      "Training loss (for one batch) at step 90: 441.0343, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 100: 442.6166, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 110: 443.6966, Accuracy: 0.6256\n",
      "---- Training ----\n",
      "Training loss: 136.4050\n",
      "Training acc over epoch: 0.6260\n",
      "---- Validation ----\n",
      "Validation loss: 34.1111\n",
      "Validation acc: 0.6497\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 445.2807, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 443.7726, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 20: 443.8581, Accuracy: 0.6168\n",
      "Training loss (for one batch) at step 30: 441.8953, Accuracy: 0.6177\n",
      "Training loss (for one batch) at step 40: 437.5453, Accuracy: 0.6221\n",
      "Training loss (for one batch) at step 50: 435.5268, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 60: 442.2269, Accuracy: 0.6259\n",
      "Training loss (for one batch) at step 70: 439.9832, Accuracy: 0.6295\n",
      "Training loss (for one batch) at step 80: 444.5155, Accuracy: 0.6301\n",
      "Training loss (for one batch) at step 90: 436.5613, Accuracy: 0.6305\n",
      "Training loss (for one batch) at step 100: 440.2787, Accuracy: 0.6319\n",
      "Training loss (for one batch) at step 110: 439.6779, Accuracy: 0.6348\n",
      "---- Training ----\n",
      "Training loss: 138.4890\n",
      "Training acc over epoch: 0.6349\n",
      "---- Validation ----\n",
      "Validation loss: 35.1624\n",
      "Validation acc: 0.6537\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 442.1350, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 442.5802, Accuracy: 0.6683\n",
      "Training loss (for one batch) at step 20: 438.5430, Accuracy: 0.6548\n",
      "Training loss (for one batch) at step 30: 436.4859, Accuracy: 0.6585\n",
      "Training loss (for one batch) at step 40: 435.9614, Accuracy: 0.6618\n",
      "Training loss (for one batch) at step 50: 436.9534, Accuracy: 0.6613\n",
      "Training loss (for one batch) at step 60: 442.9316, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 70: 441.3840, Accuracy: 0.6635\n",
      "Training loss (for one batch) at step 80: 441.8960, Accuracy: 0.6585\n",
      "Training loss (for one batch) at step 90: 441.7032, Accuracy: 0.6541\n",
      "Training loss (for one batch) at step 100: 437.3477, Accuracy: 0.6560\n",
      "Training loss (for one batch) at step 110: 438.8344, Accuracy: 0.6578\n",
      "---- Training ----\n",
      "Training loss: 136.1935\n",
      "Training acc over epoch: 0.6582\n",
      "---- Validation ----\n",
      "Validation loss: 34.4688\n",
      "Validation acc: 0.6862\n",
      "Time taken: 10.52s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 443.6147, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 439.1870, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 20: 439.7058, Accuracy: 0.6462\n",
      "Training loss (for one batch) at step 30: 429.3858, Accuracy: 0.6573\n",
      "Training loss (for one batch) at step 40: 431.0331, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 50: 437.2653, Accuracy: 0.6731\n",
      "Training loss (for one batch) at step 60: 433.2761, Accuracy: 0.6738\n",
      "Training loss (for one batch) at step 70: 446.1853, Accuracy: 0.6766\n",
      "Training loss (for one batch) at step 80: 438.4297, Accuracy: 0.6755\n",
      "Training loss (for one batch) at step 90: 437.8096, Accuracy: 0.6694\n",
      "Training loss (for one batch) at step 100: 436.9405, Accuracy: 0.6713\n",
      "Training loss (for one batch) at step 110: 426.5928, Accuracy: 0.6747\n",
      "---- Training ----\n",
      "Training loss: 136.2509\n",
      "Training acc over epoch: 0.6764\n",
      "---- Validation ----\n",
      "Validation loss: 33.7138\n",
      "Validation acc: 0.6857\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 447.1494, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 438.8091, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 435.0176, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 30: 430.8285, Accuracy: 0.6815\n",
      "Training loss (for one batch) at step 40: 428.5248, Accuracy: 0.6864\n",
      "Training loss (for one batch) at step 50: 428.4565, Accuracy: 0.6890\n",
      "Training loss (for one batch) at step 60: 447.6329, Accuracy: 0.6970\n",
      "Training loss (for one batch) at step 70: 444.9743, Accuracy: 0.6992\n",
      "Training loss (for one batch) at step 80: 437.3669, Accuracy: 0.6954\n",
      "Training loss (for one batch) at step 90: 437.3704, Accuracy: 0.6902\n",
      "Training loss (for one batch) at step 100: 440.5279, Accuracy: 0.6895\n",
      "Training loss (for one batch) at step 110: 432.5453, Accuracy: 0.6912\n",
      "---- Training ----\n",
      "Training loss: 136.5207\n",
      "Training acc over epoch: 0.6925\n",
      "---- Validation ----\n",
      "Validation loss: 35.2409\n",
      "Validation acc: 0.7093\n",
      "Time taken: 10.71s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 445.6476, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 439.2660, Accuracy: 0.7159\n",
      "Training loss (for one batch) at step 20: 436.4668, Accuracy: 0.6912\n",
      "Training loss (for one batch) at step 30: 439.5920, Accuracy: 0.6988\n",
      "Training loss (for one batch) at step 40: 425.2038, Accuracy: 0.7062\n",
      "Training loss (for one batch) at step 50: 429.7277, Accuracy: 0.7097\n",
      "Training loss (for one batch) at step 60: 432.3356, Accuracy: 0.7164\n",
      "Training loss (for one batch) at step 70: 443.8514, Accuracy: 0.7192\n",
      "Training loss (for one batch) at step 80: 435.9683, Accuracy: 0.7164\n",
      "Training loss (for one batch) at step 90: 436.3200, Accuracy: 0.7136\n",
      "Training loss (for one batch) at step 100: 426.3707, Accuracy: 0.7136\n",
      "Training loss (for one batch) at step 110: 440.9991, Accuracy: 0.7142\n",
      "---- Training ----\n",
      "Training loss: 134.8707\n",
      "Training acc over epoch: 0.7150\n",
      "---- Validation ----\n",
      "Validation loss: 35.0978\n",
      "Validation acc: 0.7509\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 441.2896, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 438.3429, Accuracy: 0.7095\n",
      "Training loss (for one batch) at step 20: 438.5903, Accuracy: 0.6983\n",
      "Training loss (for one batch) at step 30: 421.8294, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 40: 433.1165, Accuracy: 0.7151\n",
      "Training loss (for one batch) at step 50: 422.7901, Accuracy: 0.7200\n",
      "Training loss (for one batch) at step 60: 423.1450, Accuracy: 0.7285\n",
      "Training loss (for one batch) at step 70: 444.0645, Accuracy: 0.7282\n",
      "Training loss (for one batch) at step 80: 439.6531, Accuracy: 0.7239\n",
      "Training loss (for one batch) at step 90: 435.3732, Accuracy: 0.7224\n",
      "Training loss (for one batch) at step 100: 428.0488, Accuracy: 0.7223\n",
      "Training loss (for one batch) at step 110: 429.4169, Accuracy: 0.7223\n",
      "---- Training ----\n",
      "Training loss: 136.1155\n",
      "Training acc over epoch: 0.7231\n",
      "---- Validation ----\n",
      "Validation loss: 33.3278\n",
      "Validation acc: 0.7144\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 437.7410, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 441.5463, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 20: 433.7736, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 30: 420.2384, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 40: 415.1295, Accuracy: 0.7277\n",
      "Training loss (for one batch) at step 50: 417.8510, Accuracy: 0.7359\n",
      "Training loss (for one batch) at step 60: 420.7346, Accuracy: 0.7396\n",
      "Training loss (for one batch) at step 70: 444.6707, Accuracy: 0.7399\n",
      "Training loss (for one batch) at step 80: 427.3513, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 90: 426.3367, Accuracy: 0.7314\n",
      "Training loss (for one batch) at step 100: 425.1750, Accuracy: 0.7313\n",
      "Training loss (for one batch) at step 110: 428.6509, Accuracy: 0.7330\n",
      "---- Training ----\n",
      "Training loss: 133.1191\n",
      "Training acc over epoch: 0.7337\n",
      "---- Validation ----\n",
      "Validation loss: 33.1204\n",
      "Validation acc: 0.7466\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 448.1472, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 432.0400, Accuracy: 0.7322\n",
      "Training loss (for one batch) at step 20: 425.6977, Accuracy: 0.7098\n",
      "Training loss (for one batch) at step 30: 425.0507, Accuracy: 0.7245\n",
      "Training loss (for one batch) at step 40: 420.4723, Accuracy: 0.7325\n",
      "Training loss (for one batch) at step 50: 411.1409, Accuracy: 0.7405\n",
      "Training loss (for one batch) at step 60: 420.5558, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 70: 437.1292, Accuracy: 0.7519\n",
      "Training loss (for one batch) at step 80: 429.7715, Accuracy: 0.7502\n",
      "Training loss (for one batch) at step 90: 424.1875, Accuracy: 0.7489\n",
      "Training loss (for one batch) at step 100: 423.3964, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 110: 414.5020, Accuracy: 0.7506\n",
      "---- Training ----\n",
      "Training loss: 138.7495\n",
      "Training acc over epoch: 0.7506\n",
      "---- Validation ----\n",
      "Validation loss: 35.8527\n",
      "Validation acc: 0.7327\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 438.0594, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 436.6293, Accuracy: 0.7195\n",
      "Training loss (for one batch) at step 20: 420.8784, Accuracy: 0.7214\n",
      "Training loss (for one batch) at step 30: 420.0094, Accuracy: 0.7245\n",
      "Training loss (for one batch) at step 40: 415.8047, Accuracy: 0.7334\n",
      "Training loss (for one batch) at step 50: 406.9108, Accuracy: 0.7459\n",
      "Training loss (for one batch) at step 60: 423.4684, Accuracy: 0.7541\n",
      "Training loss (for one batch) at step 70: 432.2989, Accuracy: 0.7583\n",
      "Training loss (for one batch) at step 80: 441.6746, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 90: 435.0262, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 100: 425.1874, Accuracy: 0.7530\n",
      "Training loss (for one batch) at step 110: 421.8122, Accuracy: 0.7531\n",
      "---- Training ----\n",
      "Training loss: 132.8335\n",
      "Training acc over epoch: 0.7524\n",
      "---- Validation ----\n",
      "Validation loss: 34.0324\n",
      "Validation acc: 0.7550\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 437.6567, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 431.0932, Accuracy: 0.7607\n",
      "Training loss (for one batch) at step 20: 427.4944, Accuracy: 0.7426\n",
      "Training loss (for one batch) at step 30: 411.4062, Accuracy: 0.7475\n",
      "Training loss (for one batch) at step 40: 408.1262, Accuracy: 0.7483\n",
      "Training loss (for one batch) at step 50: 413.2890, Accuracy: 0.7580\n",
      "Training loss (for one batch) at step 60: 417.1749, Accuracy: 0.7638\n",
      "Training loss (for one batch) at step 70: 430.2460, Accuracy: 0.7651\n",
      "Training loss (for one batch) at step 80: 422.8441, Accuracy: 0.7622\n",
      "Training loss (for one batch) at step 90: 427.5933, Accuracy: 0.7596\n",
      "Training loss (for one batch) at step 100: 417.7419, Accuracy: 0.7594\n",
      "Training loss (for one batch) at step 110: 429.5136, Accuracy: 0.7617\n",
      "---- Training ----\n",
      "Training loss: 136.0442\n",
      "Training acc over epoch: 0.7612\n",
      "---- Validation ----\n",
      "Validation loss: 38.5476\n",
      "Validation acc: 0.7337\n",
      "Time taken: 10.75s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 449.1729, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 434.0074, Accuracy: 0.7521\n",
      "Training loss (for one batch) at step 20: 428.7162, Accuracy: 0.7396\n",
      "Training loss (for one batch) at step 30: 416.2692, Accuracy: 0.7485\n",
      "Training loss (for one batch) at step 40: 408.4355, Accuracy: 0.7553\n",
      "Training loss (for one batch) at step 50: 407.0180, Accuracy: 0.7632\n",
      "Training loss (for one batch) at step 60: 407.0593, Accuracy: 0.7705\n",
      "Training loss (for one batch) at step 70: 433.6667, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 80: 429.0698, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 90: 436.0973, Accuracy: 0.7673\n",
      "Training loss (for one batch) at step 100: 420.6935, Accuracy: 0.7672\n",
      "Training loss (for one batch) at step 110: 429.4506, Accuracy: 0.7674\n",
      "---- Training ----\n",
      "Training loss: 135.3318\n",
      "Training acc over epoch: 0.7681\n",
      "---- Validation ----\n",
      "Validation loss: 34.3537\n",
      "Validation acc: 0.7520\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 431.6444, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 430.0984, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 20: 416.7652, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 30: 416.0585, Accuracy: 0.7636\n",
      "Training loss (for one batch) at step 40: 409.1491, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 50: 397.9625, Accuracy: 0.7796\n",
      "Training loss (for one batch) at step 60: 412.0160, Accuracy: 0.7882\n",
      "Training loss (for one batch) at step 70: 426.3703, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 80: 428.9333, Accuracy: 0.7840\n",
      "Training loss (for one batch) at step 90: 433.4998, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 100: 410.1427, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 110: 420.5456, Accuracy: 0.7777\n",
      "---- Training ----\n",
      "Training loss: 131.3150\n",
      "Training acc over epoch: 0.7771\n",
      "---- Validation ----\n",
      "Validation loss: 33.3959\n",
      "Validation acc: 0.7590\n",
      "Time taken: 10.20s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 440.9620, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 425.2982, Accuracy: 0.7571\n",
      "Training loss (for one batch) at step 20: 421.9037, Accuracy: 0.7589\n",
      "Training loss (for one batch) at step 30: 404.8006, Accuracy: 0.7684\n",
      "Training loss (for one batch) at step 40: 398.1362, Accuracy: 0.7774\n",
      "Training loss (for one batch) at step 50: 400.5843, Accuracy: 0.7852\n",
      "Training loss (for one batch) at step 60: 404.6572, Accuracy: 0.7887\n",
      "Training loss (for one batch) at step 70: 426.7608, Accuracy: 0.7885\n",
      "Training loss (for one batch) at step 80: 427.9484, Accuracy: 0.7828\n",
      "Training loss (for one batch) at step 90: 421.2886, Accuracy: 0.7800\n",
      "Training loss (for one batch) at step 100: 401.0218, Accuracy: 0.7792\n",
      "Training loss (for one batch) at step 110: 411.2589, Accuracy: 0.7796\n",
      "---- Training ----\n",
      "Training loss: 125.7799\n",
      "Training acc over epoch: 0.7794\n",
      "---- Validation ----\n",
      "Validation loss: 35.2965\n",
      "Validation acc: 0.7517\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 418.3817, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 10: 428.5587, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 404.1502, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 30: 416.7620, Accuracy: 0.7629\n",
      "Training loss (for one batch) at step 40: 382.8458, Accuracy: 0.7738\n",
      "Training loss (for one batch) at step 50: 369.5357, Accuracy: 0.7860\n",
      "Training loss (for one batch) at step 60: 415.4210, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 70: 436.5446, Accuracy: 0.7881\n",
      "Training loss (for one batch) at step 80: 422.7722, Accuracy: 0.7840\n",
      "Training loss (for one batch) at step 90: 432.4420, Accuracy: 0.7796\n",
      "Training loss (for one batch) at step 100: 409.0941, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 110: 414.0324, Accuracy: 0.7812\n",
      "---- Training ----\n",
      "Training loss: 139.8401\n",
      "Training acc over epoch: 0.7818\n",
      "---- Validation ----\n",
      "Validation loss: 40.2625\n",
      "Validation acc: 0.7687\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 442.1507, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 410.6649, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 20: 413.7989, Accuracy: 0.7693\n",
      "Training loss (for one batch) at step 30: 394.3863, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 40: 383.1550, Accuracy: 0.7845\n",
      "Training loss (for one batch) at step 50: 391.2338, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 60: 390.8904, Accuracy: 0.8016\n",
      "Training loss (for one batch) at step 70: 413.6804, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 80: 409.1915, Accuracy: 0.7921\n",
      "Training loss (for one batch) at step 90: 404.5174, Accuracy: 0.7880\n",
      "Training loss (for one batch) at step 100: 405.2975, Accuracy: 0.7879\n",
      "Training loss (for one batch) at step 110: 409.8779, Accuracy: 0.7874\n",
      "---- Training ----\n",
      "Training loss: 125.0581\n",
      "Training acc over epoch: 0.7879\n",
      "---- Validation ----\n",
      "Validation loss: 38.4204\n",
      "Validation acc: 0.7657\n",
      "Time taken: 10.17s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 438.7769, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 417.4117, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 20: 401.4923, Accuracy: 0.7667\n",
      "Training loss (for one batch) at step 30: 396.4441, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 40: 384.2343, Accuracy: 0.7814\n",
      "Training loss (for one batch) at step 50: 382.9228, Accuracy: 0.7918\n",
      "Training loss (for one batch) at step 60: 381.9668, Accuracy: 0.8011\n",
      "Training loss (for one batch) at step 70: 407.0258, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 80: 419.8253, Accuracy: 0.7966\n",
      "Training loss (for one batch) at step 90: 409.1143, Accuracy: 0.7909\n",
      "Training loss (for one batch) at step 100: 414.7835, Accuracy: 0.7887\n",
      "Training loss (for one batch) at step 110: 407.3372, Accuracy: 0.7883\n",
      "---- Training ----\n",
      "Training loss: 124.2023\n",
      "Training acc over epoch: 0.7880\n",
      "---- Validation ----\n",
      "Validation loss: 37.6578\n",
      "Validation acc: 0.7509\n",
      "Time taken: 12.57s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 434.7946, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 422.0911, Accuracy: 0.7486\n",
      "Training loss (for one batch) at step 20: 394.2902, Accuracy: 0.7619\n",
      "Training loss (for one batch) at step 30: 397.3676, Accuracy: 0.7767\n",
      "Training loss (for one batch) at step 40: 370.4777, Accuracy: 0.7858\n",
      "Training loss (for one batch) at step 50: 371.7795, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 60: 391.8614, Accuracy: 0.8040\n",
      "Training loss (for one batch) at step 70: 419.6506, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 80: 410.5010, Accuracy: 0.7970\n",
      "Training loss (for one batch) at step 90: 392.7528, Accuracy: 0.7942\n",
      "Training loss (for one batch) at step 100: 396.7803, Accuracy: 0.7920\n",
      "Training loss (for one batch) at step 110: 402.6548, Accuracy: 0.7931\n",
      "---- Training ----\n",
      "Training loss: 130.9364\n",
      "Training acc over epoch: 0.7931\n",
      "---- Validation ----\n",
      "Validation loss: 40.2326\n",
      "Validation acc: 0.7445\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 439.3325, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 409.9749, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 401.8859, Accuracy: 0.7515\n",
      "Training loss (for one batch) at step 30: 377.3195, Accuracy: 0.7717\n",
      "Training loss (for one batch) at step 40: 377.7365, Accuracy: 0.7862\n",
      "Training loss (for one batch) at step 50: 377.1312, Accuracy: 0.7950\n",
      "Training loss (for one batch) at step 60: 380.8909, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 70: 412.5787, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 80: 421.4348, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 90: 400.8774, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 100: 394.1680, Accuracy: 0.7924\n",
      "Training loss (for one batch) at step 110: 385.4502, Accuracy: 0.7937\n",
      "---- Training ----\n",
      "Training loss: 123.9749\n",
      "Training acc over epoch: 0.7929\n",
      "---- Validation ----\n",
      "Validation loss: 37.5297\n",
      "Validation acc: 0.7297\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 421.0904, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 409.5104, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 392.4993, Accuracy: 0.7701\n",
      "Training loss (for one batch) at step 30: 392.6370, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 40: 369.3145, Accuracy: 0.7923\n",
      "Training loss (for one batch) at step 50: 376.9411, Accuracy: 0.8018\n",
      "Training loss (for one batch) at step 60: 386.8896, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 70: 410.7688, Accuracy: 0.8055\n",
      "Training loss (for one batch) at step 80: 411.2618, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 90: 382.7328, Accuracy: 0.7970\n",
      "Training loss (for one batch) at step 100: 390.7303, Accuracy: 0.7983\n",
      "Training loss (for one batch) at step 110: 404.0200, Accuracy: 0.7963\n",
      "---- Training ----\n",
      "Training loss: 125.2565\n",
      "Training acc over epoch: 0.7965\n",
      "---- Validation ----\n",
      "Validation loss: 38.1012\n",
      "Validation acc: 0.7544\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 426.8247, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 405.8201, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 20: 397.3095, Accuracy: 0.7653\n",
      "Training loss (for one batch) at step 30: 385.1559, Accuracy: 0.7782\n",
      "Training loss (for one batch) at step 40: 365.1353, Accuracy: 0.7931\n",
      "Training loss (for one batch) at step 50: 351.7686, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 60: 368.3412, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 70: 396.4898, Accuracy: 0.8053\n",
      "Training loss (for one batch) at step 80: 392.4657, Accuracy: 0.7972\n",
      "Training loss (for one batch) at step 90: 367.5801, Accuracy: 0.7942\n",
      "Training loss (for one batch) at step 100: 378.7070, Accuracy: 0.7956\n",
      "Training loss (for one batch) at step 110: 380.8526, Accuracy: 0.7961\n",
      "---- Training ----\n",
      "Training loss: 121.6895\n",
      "Training acc over epoch: 0.7953\n",
      "---- Validation ----\n",
      "Validation loss: 40.8505\n",
      "Validation acc: 0.7528\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 415.3447, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 414.7551, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 20: 384.4698, Accuracy: 0.7582\n",
      "Training loss (for one batch) at step 30: 376.8078, Accuracy: 0.7737\n",
      "Training loss (for one batch) at step 40: 367.8241, Accuracy: 0.7908\n",
      "Training loss (for one batch) at step 50: 357.8686, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 60: 372.7718, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 70: 399.6194, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 80: 403.3332, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 90: 381.3124, Accuracy: 0.8004\n",
      "Training loss (for one batch) at step 100: 375.6426, Accuracy: 0.8028\n",
      "Training loss (for one batch) at step 110: 370.2971, Accuracy: 0.8038\n",
      "---- Training ----\n",
      "Training loss: 129.4525\n",
      "Training acc over epoch: 0.8024\n",
      "---- Validation ----\n",
      "Validation loss: 40.0533\n",
      "Validation acc: 0.7603\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 424.1978, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 386.5424, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 390.8033, Accuracy: 0.7760\n",
      "Training loss (for one batch) at step 30: 380.0439, Accuracy: 0.7936\n",
      "Training loss (for one batch) at step 40: 362.8216, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 50: 344.0547, Accuracy: 0.8165\n",
      "Training loss (for one batch) at step 60: 367.6166, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 70: 387.1053, Accuracy: 0.8161\n",
      "Training loss (for one batch) at step 80: 409.0493, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 90: 381.2743, Accuracy: 0.8036\n",
      "Training loss (for one batch) at step 100: 379.9301, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 110: 375.0706, Accuracy: 0.8031\n",
      "---- Training ----\n",
      "Training loss: 124.7132\n",
      "Training acc over epoch: 0.8027\n",
      "---- Validation ----\n",
      "Validation loss: 33.5942\n",
      "Validation acc: 0.7536\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 417.5846, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 419.1126, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 20: 382.5413, Accuracy: 0.7775\n",
      "Training loss (for one batch) at step 30: 372.4571, Accuracy: 0.7878\n",
      "Training loss (for one batch) at step 40: 353.1728, Accuracy: 0.7984\n",
      "Training loss (for one batch) at step 50: 328.2805, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 60: 364.2926, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 70: 382.0364, Accuracy: 0.8145\n",
      "Training loss (for one batch) at step 80: 403.8398, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 90: 393.5965, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 100: 371.2521, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 110: 367.7019, Accuracy: 0.8018\n",
      "---- Training ----\n",
      "Training loss: 117.2148\n",
      "Training acc over epoch: 0.8008\n",
      "---- Validation ----\n",
      "Validation loss: 35.3343\n",
      "Validation acc: 0.7520\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 417.4866, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 403.2862, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 20: 388.8246, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 30: 352.2341, Accuracy: 0.7908\n",
      "Training loss (for one batch) at step 40: 336.1719, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 50: 351.7282, Accuracy: 0.8136\n",
      "Training loss (for one batch) at step 60: 351.3282, Accuracy: 0.8207\n",
      "Training loss (for one batch) at step 70: 387.6889, Accuracy: 0.8127\n",
      "Training loss (for one batch) at step 80: 395.4814, Accuracy: 0.8034\n",
      "Training loss (for one batch) at step 90: 365.2953, Accuracy: 0.8001\n",
      "Training loss (for one batch) at step 100: 361.8228, Accuracy: 0.8014\n",
      "Training loss (for one batch) at step 110: 376.4195, Accuracy: 0.8022\n",
      "---- Training ----\n",
      "Training loss: 118.7511\n",
      "Training acc over epoch: 0.8025\n",
      "---- Validation ----\n",
      "Validation loss: 39.7062\n",
      "Validation acc: 0.7641\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 398.5687, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 378.9849, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 365.3263, Accuracy: 0.7731\n",
      "Training loss (for one batch) at step 30: 354.4170, Accuracy: 0.7933\n",
      "Training loss (for one batch) at step 40: 344.7225, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 50: 335.8451, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 60: 359.2042, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 70: 408.5479, Accuracy: 0.8143\n",
      "Training loss (for one batch) at step 80: 395.7190, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 90: 358.6326, Accuracy: 0.8009\n",
      "Training loss (for one batch) at step 100: 353.1101, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 110: 363.0532, Accuracy: 0.8072\n",
      "---- Training ----\n",
      "Training loss: 110.5400\n",
      "Training acc over epoch: 0.8060\n",
      "---- Validation ----\n",
      "Validation loss: 36.3126\n",
      "Validation acc: 0.7633\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 401.7624, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 393.7496, Accuracy: 0.7713\n",
      "Training loss (for one batch) at step 20: 357.0103, Accuracy: 0.7857\n",
      "Training loss (for one batch) at step 30: 361.9445, Accuracy: 0.8062\n",
      "Training loss (for one batch) at step 40: 334.5288, Accuracy: 0.8144\n",
      "Training loss (for one batch) at step 50: 347.2060, Accuracy: 0.8231\n",
      "Training loss (for one batch) at step 60: 361.9967, Accuracy: 0.8267\n",
      "Training loss (for one batch) at step 70: 373.3015, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 80: 387.4427, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 90: 361.2301, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 100: 367.4032, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 110: 370.8792, Accuracy: 0.8085\n",
      "---- Training ----\n",
      "Training loss: 117.6425\n",
      "Training acc over epoch: 0.8078\n",
      "---- Validation ----\n",
      "Validation loss: 41.9195\n",
      "Validation acc: 0.7499\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 404.2683, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 407.1172, Accuracy: 0.7464\n",
      "Training loss (for one batch) at step 20: 352.0934, Accuracy: 0.7753\n",
      "Training loss (for one batch) at step 30: 351.9760, Accuracy: 0.7911\n",
      "Training loss (for one batch) at step 40: 338.5656, Accuracy: 0.8020\n",
      "Training loss (for one batch) at step 50: 321.2515, Accuracy: 0.8143\n",
      "Training loss (for one batch) at step 60: 344.7204, Accuracy: 0.8193\n",
      "Training loss (for one batch) at step 70: 360.2264, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 80: 402.0218, Accuracy: 0.8019\n",
      "Training loss (for one batch) at step 90: 345.3619, Accuracy: 0.7998\n",
      "Training loss (for one batch) at step 100: 341.2294, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 110: 368.6138, Accuracy: 0.8041\n",
      "---- Training ----\n",
      "Training loss: 114.4543\n",
      "Training acc over epoch: 0.8041\n",
      "---- Validation ----\n",
      "Validation loss: 41.1989\n",
      "Validation acc: 0.7512\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 403.3042, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 364.9690, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 20: 351.6622, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 30: 361.7602, Accuracy: 0.7913\n",
      "Training loss (for one batch) at step 40: 338.9762, Accuracy: 0.8081\n",
      "Training loss (for one batch) at step 50: 331.3301, Accuracy: 0.8209\n",
      "Training loss (for one batch) at step 60: 356.6136, Accuracy: 0.8261\n",
      "Training loss (for one batch) at step 70: 373.5869, Accuracy: 0.8184\n",
      "Training loss (for one batch) at step 80: 405.2251, Accuracy: 0.8099\n",
      "Training loss (for one batch) at step 90: 367.1955, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 100: 345.4001, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 110: 368.6801, Accuracy: 0.8084\n",
      "---- Training ----\n",
      "Training loss: 114.9356\n",
      "Training acc over epoch: 0.8086\n",
      "---- Validation ----\n",
      "Validation loss: 43.8991\n",
      "Validation acc: 0.7536\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 416.9055, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 365.7990, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 346.6077, Accuracy: 0.7809\n",
      "Training loss (for one batch) at step 30: 328.2592, Accuracy: 0.8002\n",
      "Training loss (for one batch) at step 40: 331.3993, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 50: 342.3992, Accuracy: 0.8218\n",
      "Training loss (for one batch) at step 60: 339.0386, Accuracy: 0.8277\n",
      "Training loss (for one batch) at step 70: 362.5565, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 80: 380.4253, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 90: 348.6333, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 100: 345.9551, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 110: 347.2389, Accuracy: 0.8102\n",
      "---- Training ----\n",
      "Training loss: 104.4362\n",
      "Training acc over epoch: 0.8102\n",
      "---- Validation ----\n",
      "Validation loss: 51.8389\n",
      "Validation acc: 0.7375\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 389.2152, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 383.0646, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 20: 333.7883, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 30: 327.7122, Accuracy: 0.7981\n",
      "Training loss (for one batch) at step 40: 346.2341, Accuracy: 0.8140\n",
      "Training loss (for one batch) at step 50: 320.0242, Accuracy: 0.8231\n",
      "Training loss (for one batch) at step 60: 343.4817, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 70: 371.7209, Accuracy: 0.8172\n",
      "Training loss (for one batch) at step 80: 379.2848, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 90: 376.9114, Accuracy: 0.8050\n",
      "Training loss (for one batch) at step 100: 315.3812, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 110: 363.5807, Accuracy: 0.8094\n",
      "---- Training ----\n",
      "Training loss: 115.9918\n",
      "Training acc over epoch: 0.8094\n",
      "---- Validation ----\n",
      "Validation loss: 39.8934\n",
      "Validation acc: 0.7426\n",
      "Time taken: 10.10s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 382.4909, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 373.2013, Accuracy: 0.7528\n",
      "Training loss (for one batch) at step 20: 348.1449, Accuracy: 0.7805\n",
      "Training loss (for one batch) at step 30: 340.4409, Accuracy: 0.7994\n",
      "Training loss (for one batch) at step 40: 324.9651, Accuracy: 0.8155\n",
      "Training loss (for one batch) at step 50: 323.6430, Accuracy: 0.8240\n",
      "Training loss (for one batch) at step 60: 354.8528, Accuracy: 0.8263\n",
      "Training loss (for one batch) at step 70: 361.2469, Accuracy: 0.8213\n",
      "Training loss (for one batch) at step 80: 374.2787, Accuracy: 0.8106\n",
      "Training loss (for one batch) at step 90: 332.0284, Accuracy: 0.8076\n",
      "Training loss (for one batch) at step 100: 341.5939, Accuracy: 0.8085\n",
      "Training loss (for one batch) at step 110: 354.6174, Accuracy: 0.8093\n",
      "---- Training ----\n",
      "Training loss: 116.2440\n",
      "Training acc over epoch: 0.8080\n",
      "---- Validation ----\n",
      "Validation loss: 55.1242\n",
      "Validation acc: 0.7474\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 386.6466, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 377.0732, Accuracy: 0.7436\n",
      "Training loss (for one batch) at step 20: 347.0545, Accuracy: 0.7653\n",
      "Training loss (for one batch) at step 30: 337.4829, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 40: 331.6154, Accuracy: 0.8091\n",
      "Training loss (for one batch) at step 50: 309.9962, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 60: 340.7019, Accuracy: 0.8274\n",
      "Training loss (for one batch) at step 70: 379.8391, Accuracy: 0.8192\n",
      "Training loss (for one batch) at step 80: 377.4007, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 90: 352.1007, Accuracy: 0.8064\n",
      "Training loss (for one batch) at step 100: 329.6327, Accuracy: 0.8087\n",
      "Training loss (for one batch) at step 110: 361.5393, Accuracy: 0.8091\n",
      "---- Training ----\n",
      "Training loss: 109.7564\n",
      "Training acc over epoch: 0.8081\n",
      "---- Validation ----\n",
      "Validation loss: 40.8962\n",
      "Validation acc: 0.7534\n",
      "Time taken: 10.21s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 400.7583, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 376.6474, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 20: 339.9683, Accuracy: 0.7820\n",
      "Training loss (for one batch) at step 30: 326.4484, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 40: 324.2500, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 50: 333.6090, Accuracy: 0.8260\n",
      "Training loss (for one batch) at step 60: 314.9308, Accuracy: 0.8311\n",
      "Training loss (for one batch) at step 70: 354.6323, Accuracy: 0.8214\n",
      "Training loss (for one batch) at step 80: 359.1885, Accuracy: 0.8073\n",
      "Training loss (for one batch) at step 90: 323.2195, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 100: 326.8870, Accuracy: 0.8079\n",
      "Training loss (for one batch) at step 110: 357.8248, Accuracy: 0.8089\n",
      "---- Training ----\n",
      "Training loss: 118.0409\n",
      "Training acc over epoch: 0.8085\n",
      "---- Validation ----\n",
      "Validation loss: 34.4847\n",
      "Validation acc: 0.7337\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 383.9706, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 356.1481, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 345.9658, Accuracy: 0.7746\n",
      "Training loss (for one batch) at step 30: 344.2809, Accuracy: 0.7999\n",
      "Training loss (for one batch) at step 40: 329.6102, Accuracy: 0.8163\n",
      "Training loss (for one batch) at step 50: 306.5114, Accuracy: 0.8266\n",
      "Training loss (for one batch) at step 60: 337.0331, Accuracy: 0.8336\n",
      "Training loss (for one batch) at step 70: 356.2139, Accuracy: 0.8225\n",
      "Training loss (for one batch) at step 80: 350.6885, Accuracy: 0.8096\n",
      "Training loss (for one batch) at step 90: 340.9043, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 100: 329.7590, Accuracy: 0.8124\n",
      "Training loss (for one batch) at step 110: 350.4422, Accuracy: 0.8148\n",
      "---- Training ----\n",
      "Training loss: 114.7070\n",
      "Training acc over epoch: 0.8133\n",
      "---- Validation ----\n",
      "Validation loss: 39.3516\n",
      "Validation acc: 0.7689\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 394.4030, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 365.5822, Accuracy: 0.7798\n",
      "Training loss (for one batch) at step 20: 317.8528, Accuracy: 0.7883\n",
      "Training loss (for one batch) at step 30: 353.1550, Accuracy: 0.8062\n",
      "Training loss (for one batch) at step 40: 320.2963, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 50: 295.0493, Accuracy: 0.8261\n",
      "Training loss (for one batch) at step 60: 334.1581, Accuracy: 0.8320\n",
      "Training loss (for one batch) at step 70: 363.5663, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 80: 376.1779, Accuracy: 0.8080\n",
      "Training loss (for one batch) at step 90: 310.6768, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 100: 325.1733, Accuracy: 0.8077\n",
      "Training loss (for one batch) at step 110: 324.5995, Accuracy: 0.8084\n",
      "---- Training ----\n",
      "Training loss: 112.9881\n",
      "Training acc over epoch: 0.8078\n",
      "---- Validation ----\n",
      "Validation loss: 50.5387\n",
      "Validation acc: 0.7569\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 373.3203, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 365.0341, Accuracy: 0.7457\n",
      "Training loss (for one batch) at step 20: 338.5103, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 334.4860, Accuracy: 0.7913\n",
      "Training loss (for one batch) at step 40: 317.7774, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 50: 316.3928, Accuracy: 0.8200\n",
      "Training loss (for one batch) at step 60: 317.4659, Accuracy: 0.8258\n",
      "Training loss (for one batch) at step 70: 363.0187, Accuracy: 0.8170\n",
      "Training loss (for one batch) at step 80: 371.8305, Accuracy: 0.8060\n",
      "Training loss (for one batch) at step 90: 312.0092, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 100: 311.5805, Accuracy: 0.8045\n",
      "Training loss (for one batch) at step 110: 337.9504, Accuracy: 0.8074\n",
      "---- Training ----\n",
      "Training loss: 106.9905\n",
      "Training acc over epoch: 0.8060\n",
      "---- Validation ----\n",
      "Validation loss: 65.9122\n",
      "Validation acc: 0.7477\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 372.5478, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 355.5847, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 20: 345.9565, Accuracy: 0.7612\n",
      "Training loss (for one batch) at step 30: 321.4066, Accuracy: 0.7883\n",
      "Training loss (for one batch) at step 40: 323.3259, Accuracy: 0.8053\n",
      "Training loss (for one batch) at step 50: 303.3930, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 60: 331.9989, Accuracy: 0.8247\n",
      "Training loss (for one batch) at step 70: 336.2631, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 80: 360.0345, Accuracy: 0.8017\n",
      "Training loss (for one batch) at step 90: 329.2743, Accuracy: 0.7997\n",
      "Training loss (for one batch) at step 100: 314.6989, Accuracy: 0.8048\n",
      "Training loss (for one batch) at step 110: 348.0789, Accuracy: 0.8063\n",
      "---- Training ----\n",
      "Training loss: 101.9531\n",
      "Training acc over epoch: 0.8057\n",
      "---- Validation ----\n",
      "Validation loss: 48.7002\n",
      "Validation acc: 0.7638\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 370.7579, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 361.8580, Accuracy: 0.7479\n",
      "Training loss (for one batch) at step 20: 329.4953, Accuracy: 0.7723\n",
      "Training loss (for one batch) at step 30: 326.6517, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 40: 315.7029, Accuracy: 0.8102\n",
      "Training loss (for one batch) at step 50: 301.8600, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 60: 313.2661, Accuracy: 0.8302\n",
      "Training loss (for one batch) at step 70: 343.9999, Accuracy: 0.8210\n",
      "Training loss (for one batch) at step 80: 360.8447, Accuracy: 0.8074\n",
      "Training loss (for one batch) at step 90: 320.9216, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 100: 329.5803, Accuracy: 0.8101\n",
      "Training loss (for one batch) at step 110: 328.1818, Accuracy: 0.8110\n",
      "---- Training ----\n",
      "Training loss: 103.0809\n",
      "Training acc over epoch: 0.8098\n",
      "---- Validation ----\n",
      "Validation loss: 44.3335\n",
      "Validation acc: 0.7523\n",
      "Time taken: 12.45s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 368.8898, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 354.0085, Accuracy: 0.7415\n",
      "Training loss (for one batch) at step 20: 323.0025, Accuracy: 0.7686\n",
      "Training loss (for one batch) at step 30: 306.8177, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 40: 329.6176, Accuracy: 0.8123\n",
      "Training loss (for one batch) at step 50: 301.4777, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 60: 311.7647, Accuracy: 0.8306\n",
      "Training loss (for one batch) at step 70: 361.3490, Accuracy: 0.8199\n",
      "Training loss (for one batch) at step 80: 344.0800, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 90: 330.3641, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 100: 315.9851, Accuracy: 0.8089\n",
      "Training loss (for one batch) at step 110: 338.2440, Accuracy: 0.8102\n",
      "---- Training ----\n",
      "Training loss: 100.6806\n",
      "Training acc over epoch: 0.8092\n",
      "---- Validation ----\n",
      "Validation loss: 56.7775\n",
      "Validation acc: 0.7536\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 364.8004, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 380.1398, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 20: 327.0562, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 321.5829, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 40: 310.3303, Accuracy: 0.8108\n",
      "Training loss (for one batch) at step 50: 308.5154, Accuracy: 0.8237\n",
      "Training loss (for one batch) at step 60: 318.8960, Accuracy: 0.8283\n",
      "Training loss (for one batch) at step 70: 335.5194, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 80: 372.4393, Accuracy: 0.8076\n",
      "Training loss (for one batch) at step 90: 326.6796, Accuracy: 0.8056\n",
      "Training loss (for one batch) at step 100: 303.9516, Accuracy: 0.8082\n",
      "Training loss (for one batch) at step 110: 327.8542, Accuracy: 0.8096\n",
      "---- Training ----\n",
      "Training loss: 104.9465\n",
      "Training acc over epoch: 0.8086\n",
      "---- Validation ----\n",
      "Validation loss: 41.0351\n",
      "Validation acc: 0.7515\n",
      "Time taken: 10.84s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 360.9210, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 333.4443, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 20: 318.3238, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 30: 316.3462, Accuracy: 0.7941\n",
      "Training loss (for one batch) at step 40: 308.7914, Accuracy: 0.8077\n",
      "Training loss (for one batch) at step 50: 302.4091, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 60: 327.1740, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 70: 346.1187, Accuracy: 0.8194\n",
      "Training loss (for one batch) at step 80: 341.6412, Accuracy: 0.8069\n",
      "Training loss (for one batch) at step 90: 330.5194, Accuracy: 0.8031\n",
      "Training loss (for one batch) at step 100: 303.7524, Accuracy: 0.8065\n",
      "Training loss (for one batch) at step 110: 341.9821, Accuracy: 0.8086\n",
      "---- Training ----\n",
      "Training loss: 92.8515\n",
      "Training acc over epoch: 0.8077\n",
      "---- Validation ----\n",
      "Validation loss: 48.3161\n",
      "Validation acc: 0.7450\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 356.2380, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 354.3872, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 20: 320.7248, Accuracy: 0.7708\n",
      "Training loss (for one batch) at step 30: 320.9902, Accuracy: 0.7949\n",
      "Training loss (for one batch) at step 40: 302.2834, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 50: 301.7066, Accuracy: 0.8263\n",
      "Training loss (for one batch) at step 60: 309.8890, Accuracy: 0.8324\n",
      "Training loss (for one batch) at step 70: 374.4340, Accuracy: 0.8244\n",
      "Training loss (for one batch) at step 80: 350.1263, Accuracy: 0.8109\n",
      "Training loss (for one batch) at step 90: 314.2046, Accuracy: 0.8061\n",
      "Training loss (for one batch) at step 100: 311.2735, Accuracy: 0.8093\n",
      "Training loss (for one batch) at step 110: 309.1478, Accuracy: 0.8090\n",
      "---- Training ----\n",
      "Training loss: 113.2430\n",
      "Training acc over epoch: 0.8088\n",
      "---- Validation ----\n",
      "Validation loss: 35.1457\n",
      "Validation acc: 0.7577\n",
      "Time taken: 10.42s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7575\n",
      "Validation AUC: 0.7584\n",
      "Validation Balanced_ACC: 0.4337\n",
      "Validation AUCSK: 0.7850\n",
      "Validation MI: 0.1109\n",
      "Validation Normalized MI: 0.1616\n",
      "Validation Adjusted MI: 0.1616\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 594.4665, Accuracy: 0.5000\n",
      "Training loss (for one batch) at step 10: 592.2834, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 20: 543.6012, Accuracy: 0.5219\n",
      "Training loss (for one batch) at step 30: 513.9310, Accuracy: 0.5161\n",
      "Training loss (for one batch) at step 40: 504.2957, Accuracy: 0.5179\n",
      "Training loss (for one batch) at step 50: 511.1634, Accuracy: 0.5153\n",
      "Training loss (for one batch) at step 60: 479.4170, Accuracy: 0.5170\n",
      "Training loss (for one batch) at step 70: 471.6881, Accuracy: 0.5150\n",
      "Training loss (for one batch) at step 80: 472.4713, Accuracy: 0.5135\n",
      "Training loss (for one batch) at step 90: 462.8412, Accuracy: 0.5154\n",
      "Training loss (for one batch) at step 100: 467.8433, Accuracy: 0.5132\n",
      "Training loss (for one batch) at step 110: 462.7366, Accuracy: 0.5147\n",
      "---- Training ----\n",
      "Training loss: 145.8459\n",
      "Training acc over epoch: 0.5156\n",
      "---- Validation ----\n",
      "Validation loss: 34.5688\n",
      "Validation acc: 0.5137\n",
      "Time taken: 12.37s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 464.8294, Accuracy: 0.4766\n",
      "Training loss (for one batch) at step 10: 449.2809, Accuracy: 0.5334\n",
      "Training loss (for one batch) at step 20: 460.3336, Accuracy: 0.5219\n",
      "Training loss (for one batch) at step 30: 451.0202, Accuracy: 0.5189\n",
      "Training loss (for one batch) at step 40: 456.0650, Accuracy: 0.5196\n",
      "Training loss (for one batch) at step 50: 453.1605, Accuracy: 0.5242\n",
      "Training loss (for one batch) at step 60: 450.5168, Accuracy: 0.5245\n",
      "Training loss (for one batch) at step 70: 452.3683, Accuracy: 0.5259\n",
      "Training loss (for one batch) at step 80: 449.9520, Accuracy: 0.5249\n",
      "Training loss (for one batch) at step 90: 448.8340, Accuracy: 0.5253\n",
      "Training loss (for one batch) at step 100: 454.9332, Accuracy: 0.5254\n",
      "Training loss (for one batch) at step 110: 451.4337, Accuracy: 0.5248\n",
      "---- Training ----\n",
      "Training loss: 141.5406\n",
      "Training acc over epoch: 0.5255\n",
      "---- Validation ----\n",
      "Validation loss: 34.5999\n",
      "Validation acc: 0.4882\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 447.7173, Accuracy: 0.4297\n",
      "Training loss (for one batch) at step 10: 451.3519, Accuracy: 0.4964\n",
      "Training loss (for one batch) at step 20: 448.0179, Accuracy: 0.5193\n",
      "Training loss (for one batch) at step 30: 442.7862, Accuracy: 0.5207\n",
      "Training loss (for one batch) at step 40: 447.0632, Accuracy: 0.5166\n",
      "Training loss (for one batch) at step 50: 446.4364, Accuracy: 0.5169\n",
      "Training loss (for one batch) at step 60: 445.8485, Accuracy: 0.5197\n",
      "Training loss (for one batch) at step 70: 444.4033, Accuracy: 0.5222\n",
      "Training loss (for one batch) at step 80: 446.4679, Accuracy: 0.5253\n",
      "Training loss (for one batch) at step 90: 444.7972, Accuracy: 0.5276\n",
      "Training loss (for one batch) at step 100: 443.0565, Accuracy: 0.5268\n",
      "Training loss (for one batch) at step 110: 444.6396, Accuracy: 0.5276\n",
      "---- Training ----\n",
      "Training loss: 138.7619\n",
      "Training acc over epoch: 0.5274\n",
      "---- Validation ----\n",
      "Validation loss: 35.1026\n",
      "Validation acc: 0.5333\n",
      "Time taken: 10.78s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.9844, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 449.1159, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 20: 443.7787, Accuracy: 0.5439\n",
      "Training loss (for one batch) at step 30: 442.9072, Accuracy: 0.5459\n",
      "Training loss (for one batch) at step 40: 444.9268, Accuracy: 0.5499\n",
      "Training loss (for one batch) at step 50: 443.3374, Accuracy: 0.5522\n",
      "Training loss (for one batch) at step 60: 444.5685, Accuracy: 0.5499\n",
      "Training loss (for one batch) at step 70: 444.4264, Accuracy: 0.5505\n",
      "Training loss (for one batch) at step 80: 443.3251, Accuracy: 0.5493\n",
      "Training loss (for one batch) at step 90: 445.4774, Accuracy: 0.5494\n",
      "Training loss (for one batch) at step 100: 444.1545, Accuracy: 0.5475\n",
      "Training loss (for one batch) at step 110: 444.9520, Accuracy: 0.5458\n",
      "---- Training ----\n",
      "Training loss: 139.7700\n",
      "Training acc over epoch: 0.5454\n",
      "---- Validation ----\n",
      "Validation loss: 34.9737\n",
      "Validation acc: 0.5476\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 445.7422, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 444.3052, Accuracy: 0.5597\n",
      "Training loss (for one batch) at step 20: 442.8058, Accuracy: 0.5636\n",
      "Training loss (for one batch) at step 30: 442.4453, Accuracy: 0.5741\n",
      "Training loss (for one batch) at step 40: 443.3442, Accuracy: 0.5726\n",
      "Training loss (for one batch) at step 50: 443.7192, Accuracy: 0.5689\n",
      "Training loss (for one batch) at step 60: 442.9535, Accuracy: 0.5616\n",
      "Training loss (for one batch) at step 70: 438.4772, Accuracy: 0.5649\n",
      "Training loss (for one batch) at step 80: 443.8799, Accuracy: 0.5652\n",
      "Training loss (for one batch) at step 90: 446.7173, Accuracy: 0.5665\n",
      "Training loss (for one batch) at step 100: 444.4373, Accuracy: 0.5667\n",
      "Training loss (for one batch) at step 110: 444.0682, Accuracy: 0.5638\n",
      "---- Training ----\n",
      "Training loss: 140.1012\n",
      "Training acc over epoch: 0.5623\n",
      "---- Validation ----\n",
      "Validation loss: 34.5824\n",
      "Validation acc: 0.5723\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 442.7890, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 443.5363, Accuracy: 0.5604\n",
      "Training loss (for one batch) at step 20: 442.1628, Accuracy: 0.5658\n",
      "Training loss (for one batch) at step 30: 443.1510, Accuracy: 0.5668\n",
      "Training loss (for one batch) at step 40: 441.4627, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 50: 442.6420, Accuracy: 0.5699\n",
      "Training loss (for one batch) at step 60: 440.0646, Accuracy: 0.5681\n",
      "Training loss (for one batch) at step 70: 441.5386, Accuracy: 0.5690\n",
      "Training loss (for one batch) at step 80: 441.3362, Accuracy: 0.5681\n",
      "Training loss (for one batch) at step 90: 440.8228, Accuracy: 0.5690\n",
      "Training loss (for one batch) at step 100: 443.5370, Accuracy: 0.5709\n",
      "Training loss (for one batch) at step 110: 442.6260, Accuracy: 0.5681\n",
      "---- Training ----\n",
      "Training loss: 139.5965\n",
      "Training acc over epoch: 0.5685\n",
      "---- Validation ----\n",
      "Validation loss: 35.0035\n",
      "Validation acc: 0.5419\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 442.8927, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 442.1856, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 20: 440.3397, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 30: 438.7393, Accuracy: 0.5801\n",
      "Training loss (for one batch) at step 40: 443.7782, Accuracy: 0.5852\n",
      "Training loss (for one batch) at step 50: 441.1997, Accuracy: 0.5821\n",
      "Training loss (for one batch) at step 60: 440.3383, Accuracy: 0.5809\n",
      "Training loss (for one batch) at step 70: 442.2334, Accuracy: 0.5837\n",
      "Training loss (for one batch) at step 80: 442.9154, Accuracy: 0.5813\n",
      "Training loss (for one batch) at step 90: 444.6222, Accuracy: 0.5792\n",
      "Training loss (for one batch) at step 100: 440.7971, Accuracy: 0.5762\n",
      "Training loss (for one batch) at step 110: 438.0519, Accuracy: 0.5763\n",
      "---- Training ----\n",
      "Training loss: 137.7832\n",
      "Training acc over epoch: 0.5757\n",
      "---- Validation ----\n",
      "Validation loss: 34.7511\n",
      "Validation acc: 0.5371\n",
      "Time taken: 10.61s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 441.3160, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 440.2923, Accuracy: 0.5455\n",
      "Training loss (for one batch) at step 20: 439.8500, Accuracy: 0.5595\n",
      "Training loss (for one batch) at step 30: 440.4884, Accuracy: 0.5736\n",
      "Training loss (for one batch) at step 40: 441.6985, Accuracy: 0.5861\n",
      "Training loss (for one batch) at step 50: 435.9868, Accuracy: 0.5843\n",
      "Training loss (for one batch) at step 60: 439.0821, Accuracy: 0.5786\n",
      "Training loss (for one batch) at step 70: 445.5397, Accuracy: 0.5812\n",
      "Training loss (for one batch) at step 80: 444.0949, Accuracy: 0.5832\n",
      "Training loss (for one batch) at step 90: 439.3054, Accuracy: 0.5834\n",
      "Training loss (for one batch) at step 100: 443.8781, Accuracy: 0.5839\n",
      "Training loss (for one batch) at step 110: 438.6967, Accuracy: 0.5854\n",
      "---- Training ----\n",
      "Training loss: 137.0208\n",
      "Training acc over epoch: 0.5861\n",
      "---- Validation ----\n",
      "Validation loss: 35.1431\n",
      "Validation acc: 0.5795\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 439.7898, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 444.8697, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 20: 439.2081, Accuracy: 0.5971\n",
      "Training loss (for one batch) at step 30: 437.3794, Accuracy: 0.5900\n",
      "Training loss (for one batch) at step 40: 435.5010, Accuracy: 0.5917\n",
      "Training loss (for one batch) at step 50: 433.5499, Accuracy: 0.5997\n",
      "Training loss (for one batch) at step 60: 438.3026, Accuracy: 0.5958\n",
      "Training loss (for one batch) at step 70: 438.8676, Accuracy: 0.5966\n",
      "Training loss (for one batch) at step 80: 438.6647, Accuracy: 0.5926\n",
      "Training loss (for one batch) at step 90: 445.5766, Accuracy: 0.5918\n",
      "Training loss (for one batch) at step 100: 439.4398, Accuracy: 0.5907\n",
      "Training loss (for one batch) at step 110: 439.5719, Accuracy: 0.5914\n",
      "---- Training ----\n",
      "Training loss: 136.3619\n",
      "Training acc over epoch: 0.5916\n",
      "---- Validation ----\n",
      "Validation loss: 34.5035\n",
      "Validation acc: 0.5905\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 442.7508, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 438.7286, Accuracy: 0.5952\n",
      "Training loss (for one batch) at step 20: 437.0934, Accuracy: 0.5941\n",
      "Training loss (for one batch) at step 30: 432.8238, Accuracy: 0.6061\n",
      "Training loss (for one batch) at step 40: 437.2222, Accuracy: 0.6147\n",
      "Training loss (for one batch) at step 50: 432.1613, Accuracy: 0.6150\n",
      "Training loss (for one batch) at step 60: 430.3159, Accuracy: 0.6085\n",
      "Training loss (for one batch) at step 70: 441.0202, Accuracy: 0.6070\n",
      "Training loss (for one batch) at step 80: 442.2502, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 90: 439.2934, Accuracy: 0.6056\n",
      "Training loss (for one batch) at step 100: 437.7764, Accuracy: 0.6066\n",
      "Training loss (for one batch) at step 110: 435.3049, Accuracy: 0.6073\n",
      "---- Training ----\n",
      "Training loss: 136.8719\n",
      "Training acc over epoch: 0.6075\n",
      "---- Validation ----\n",
      "Validation loss: 35.8010\n",
      "Validation acc: 0.5999\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 439.8527, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 442.1215, Accuracy: 0.5966\n",
      "Training loss (for one batch) at step 20: 435.0413, Accuracy: 0.5945\n",
      "Training loss (for one batch) at step 30: 436.0437, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 40: 432.2990, Accuracy: 0.6223\n",
      "Training loss (for one batch) at step 50: 431.2017, Accuracy: 0.6242\n",
      "Training loss (for one batch) at step 60: 436.7721, Accuracy: 0.6231\n",
      "Training loss (for one batch) at step 70: 440.9317, Accuracy: 0.6231\n",
      "Training loss (for one batch) at step 80: 435.3083, Accuracy: 0.6212\n",
      "Training loss (for one batch) at step 90: 433.5051, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 100: 434.7210, Accuracy: 0.6149\n",
      "Training loss (for one batch) at step 110: 430.9457, Accuracy: 0.6156\n",
      "---- Training ----\n",
      "Training loss: 135.4314\n",
      "Training acc over epoch: 0.6143\n",
      "---- Validation ----\n",
      "Validation loss: 34.8925\n",
      "Validation acc: 0.5556\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 444.3668, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 440.2718, Accuracy: 0.6122\n",
      "Training loss (for one batch) at step 20: 443.2975, Accuracy: 0.6205\n",
      "Training loss (for one batch) at step 30: 431.1770, Accuracy: 0.6290\n",
      "Training loss (for one batch) at step 40: 425.5803, Accuracy: 0.6338\n",
      "Training loss (for one batch) at step 50: 428.9212, Accuracy: 0.6336\n",
      "Training loss (for one batch) at step 60: 428.8065, Accuracy: 0.6332\n",
      "Training loss (for one batch) at step 70: 440.4773, Accuracy: 0.6369\n",
      "Training loss (for one batch) at step 80: 437.0276, Accuracy: 0.6325\n",
      "Training loss (for one batch) at step 90: 437.3224, Accuracy: 0.6270\n",
      "Training loss (for one batch) at step 100: 429.6845, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 110: 431.0049, Accuracy: 0.6259\n",
      "---- Training ----\n",
      "Training loss: 136.9686\n",
      "Training acc over epoch: 0.6277\n",
      "---- Validation ----\n",
      "Validation loss: 36.9040\n",
      "Validation acc: 0.6163\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 437.6099, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 434.6747, Accuracy: 0.6349\n",
      "Training loss (for one batch) at step 20: 434.6348, Accuracy: 0.6231\n",
      "Training loss (for one batch) at step 30: 433.3458, Accuracy: 0.6316\n",
      "Training loss (for one batch) at step 40: 426.7384, Accuracy: 0.6410\n",
      "Training loss (for one batch) at step 50: 425.6086, Accuracy: 0.6481\n",
      "Training loss (for one batch) at step 60: 439.5754, Accuracy: 0.6502\n",
      "Training loss (for one batch) at step 70: 440.1636, Accuracy: 0.6531\n",
      "Training loss (for one batch) at step 80: 444.2422, Accuracy: 0.6476\n",
      "Training loss (for one batch) at step 90: 432.4923, Accuracy: 0.6369\n",
      "Training loss (for one batch) at step 100: 430.5402, Accuracy: 0.6326\n",
      "Training loss (for one batch) at step 110: 436.2419, Accuracy: 0.6322\n",
      "---- Training ----\n",
      "Training loss: 132.0597\n",
      "Training acc over epoch: 0.6329\n",
      "---- Validation ----\n",
      "Validation loss: 35.2100\n",
      "Validation acc: 0.6115\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 440.9330, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 438.3563, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 20: 431.1411, Accuracy: 0.6239\n",
      "Training loss (for one batch) at step 30: 426.0154, Accuracy: 0.6336\n",
      "Training loss (for one batch) at step 40: 425.6888, Accuracy: 0.6458\n",
      "Training loss (for one batch) at step 50: 424.0285, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 60: 426.7396, Accuracy: 0.6530\n",
      "Training loss (for one batch) at step 70: 435.4908, Accuracy: 0.6555\n",
      "Training loss (for one batch) at step 80: 436.2415, Accuracy: 0.6538\n",
      "Training loss (for one batch) at step 90: 427.3592, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 100: 434.4119, Accuracy: 0.6481\n",
      "Training loss (for one batch) at step 110: 425.2219, Accuracy: 0.6486\n",
      "---- Training ----\n",
      "Training loss: 136.1356\n",
      "Training acc over epoch: 0.6487\n",
      "---- Validation ----\n",
      "Validation loss: 35.2714\n",
      "Validation acc: 0.6206\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 439.8717, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 431.4691, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 431.3083, Accuracy: 0.6391\n",
      "Training loss (for one batch) at step 30: 420.9198, Accuracy: 0.6505\n",
      "Training loss (for one batch) at step 40: 429.3045, Accuracy: 0.6545\n",
      "Training loss (for one batch) at step 50: 419.7137, Accuracy: 0.6639\n",
      "Training loss (for one batch) at step 60: 428.7400, Accuracy: 0.6659\n",
      "Training loss (for one batch) at step 70: 443.2437, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 80: 435.0646, Accuracy: 0.6640\n",
      "Training loss (for one batch) at step 90: 431.7607, Accuracy: 0.6601\n",
      "Training loss (for one batch) at step 100: 429.0384, Accuracy: 0.6560\n",
      "Training loss (for one batch) at step 110: 432.0920, Accuracy: 0.6536\n",
      "---- Training ----\n",
      "Training loss: 136.2623\n",
      "Training acc over epoch: 0.6523\n",
      "---- Validation ----\n",
      "Validation loss: 36.4495\n",
      "Validation acc: 0.5919\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 438.6586, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 430.5756, Accuracy: 0.6371\n",
      "Training loss (for one batch) at step 20: 430.6974, Accuracy: 0.6414\n",
      "Training loss (for one batch) at step 30: 421.0192, Accuracy: 0.6479\n",
      "Training loss (for one batch) at step 40: 422.1296, Accuracy: 0.6553\n",
      "Training loss (for one batch) at step 50: 410.0653, Accuracy: 0.6667\n",
      "Training loss (for one batch) at step 60: 415.9172, Accuracy: 0.6703\n",
      "Training loss (for one batch) at step 70: 427.6369, Accuracy: 0.6712\n",
      "Training loss (for one batch) at step 80: 437.3587, Accuracy: 0.6689\n",
      "Training loss (for one batch) at step 90: 422.2644, Accuracy: 0.6647\n",
      "Training loss (for one batch) at step 100: 420.3367, Accuracy: 0.6635\n",
      "Training loss (for one batch) at step 110: 432.8676, Accuracy: 0.6641\n",
      "---- Training ----\n",
      "Training loss: 132.3592\n",
      "Training acc over epoch: 0.6648\n",
      "---- Validation ----\n",
      "Validation loss: 34.1693\n",
      "Validation acc: 0.6531\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 427.7318, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 429.4471, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 20: 434.6521, Accuracy: 0.6380\n",
      "Training loss (for one batch) at step 30: 428.3928, Accuracy: 0.6487\n",
      "Training loss (for one batch) at step 40: 428.5185, Accuracy: 0.6526\n",
      "Training loss (for one batch) at step 50: 406.2205, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 60: 422.7073, Accuracy: 0.6692\n",
      "Training loss (for one batch) at step 70: 424.1186, Accuracy: 0.6718\n",
      "Training loss (for one batch) at step 80: 425.7017, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 90: 430.9966, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 100: 421.2657, Accuracy: 0.6573\n",
      "Training loss (for one batch) at step 110: 432.8134, Accuracy: 0.6575\n",
      "---- Training ----\n",
      "Training loss: 137.6421\n",
      "Training acc over epoch: 0.6578\n",
      "---- Validation ----\n",
      "Validation loss: 35.4355\n",
      "Validation acc: 0.6338\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 428.1535, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 424.7976, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 20: 421.2309, Accuracy: 0.6295\n",
      "Training loss (for one batch) at step 30: 420.3459, Accuracy: 0.6368\n",
      "Training loss (for one batch) at step 40: 412.3727, Accuracy: 0.6433\n",
      "Training loss (for one batch) at step 50: 407.2411, Accuracy: 0.6581\n",
      "Training loss (for one batch) at step 60: 410.0356, Accuracy: 0.6694\n",
      "Training loss (for one batch) at step 70: 433.2319, Accuracy: 0.6720\n",
      "Training loss (for one batch) at step 80: 436.0751, Accuracy: 0.6680\n",
      "Training loss (for one batch) at step 90: 414.2365, Accuracy: 0.6640\n",
      "Training loss (for one batch) at step 100: 424.6272, Accuracy: 0.6651\n",
      "Training loss (for one batch) at step 110: 422.6048, Accuracy: 0.6662\n",
      "---- Training ----\n",
      "Training loss: 129.6671\n",
      "Training acc over epoch: 0.6655\n",
      "---- Validation ----\n",
      "Validation loss: 36.1462\n",
      "Validation acc: 0.6370\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 421.8546, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 431.0889, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 20: 434.2852, Accuracy: 0.6481\n",
      "Training loss (for one batch) at step 30: 415.1888, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 40: 411.1130, Accuracy: 0.6686\n",
      "Training loss (for one batch) at step 50: 399.6651, Accuracy: 0.6749\n",
      "Training loss (for one batch) at step 60: 402.8464, Accuracy: 0.6821\n",
      "Training loss (for one batch) at step 70: 433.8433, Accuracy: 0.6840\n",
      "Training loss (for one batch) at step 80: 439.3385, Accuracy: 0.6828\n",
      "Training loss (for one batch) at step 90: 425.8320, Accuracy: 0.6773\n",
      "Training loss (for one batch) at step 100: 411.9341, Accuracy: 0.6751\n",
      "Training loss (for one batch) at step 110: 408.7736, Accuracy: 0.6715\n",
      "---- Training ----\n",
      "Training loss: 126.1911\n",
      "Training acc over epoch: 0.6711\n",
      "---- Validation ----\n",
      "Validation loss: 36.7412\n",
      "Validation acc: 0.6521\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 437.8088, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 428.7288, Accuracy: 0.6541\n",
      "Training loss (for one batch) at step 20: 413.7645, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 30: 412.5517, Accuracy: 0.6706\n",
      "Training loss (for one batch) at step 40: 396.6473, Accuracy: 0.6795\n",
      "Training loss (for one batch) at step 50: 389.9546, Accuracy: 0.6919\n",
      "Training loss (for one batch) at step 60: 410.7975, Accuracy: 0.6951\n",
      "Training loss (for one batch) at step 70: 428.5491, Accuracy: 0.6965\n",
      "Training loss (for one batch) at step 80: 416.2704, Accuracy: 0.6909\n",
      "Training loss (for one batch) at step 90: 415.5581, Accuracy: 0.6874\n",
      "Training loss (for one batch) at step 100: 410.6360, Accuracy: 0.6863\n",
      "Training loss (for one batch) at step 110: 414.9521, Accuracy: 0.6837\n",
      "---- Training ----\n",
      "Training loss: 128.1278\n",
      "Training acc over epoch: 0.6818\n",
      "---- Validation ----\n",
      "Validation loss: 35.1194\n",
      "Validation acc: 0.6572\n",
      "Time taken: 10.20s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 447.2966, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 415.1554, Accuracy: 0.6676\n",
      "Training loss (for one batch) at step 20: 405.4380, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 30: 407.9321, Accuracy: 0.6709\n",
      "Training loss (for one batch) at step 40: 394.6393, Accuracy: 0.6814\n",
      "Training loss (for one batch) at step 50: 370.5431, Accuracy: 0.6907\n",
      "Training loss (for one batch) at step 60: 429.0750, Accuracy: 0.7007\n",
      "Training loss (for one batch) at step 70: 425.9958, Accuracy: 0.6985\n",
      "Training loss (for one batch) at step 80: 426.7090, Accuracy: 0.6927\n",
      "Training loss (for one batch) at step 90: 422.6542, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 100: 405.5952, Accuracy: 0.6842\n",
      "Training loss (for one batch) at step 110: 408.5842, Accuracy: 0.6840\n",
      "---- Training ----\n",
      "Training loss: 137.5676\n",
      "Training acc over epoch: 0.6836\n",
      "---- Validation ----\n",
      "Validation loss: 38.3114\n",
      "Validation acc: 0.6368\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 416.0153, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 424.2843, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 20: 397.2127, Accuracy: 0.6514\n",
      "Training loss (for one batch) at step 30: 401.5845, Accuracy: 0.6615\n",
      "Training loss (for one batch) at step 40: 398.3141, Accuracy: 0.6732\n",
      "Training loss (for one batch) at step 50: 393.6196, Accuracy: 0.6867\n",
      "Training loss (for one batch) at step 60: 387.1836, Accuracy: 0.6917\n",
      "Training loss (for one batch) at step 70: 429.7993, Accuracy: 0.6928\n",
      "Training loss (for one batch) at step 80: 417.3646, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 90: 401.0437, Accuracy: 0.6833\n",
      "Training loss (for one batch) at step 100: 397.3191, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 110: 402.5262, Accuracy: 0.6826\n",
      "---- Training ----\n",
      "Training loss: 128.2796\n",
      "Training acc over epoch: 0.6810\n",
      "---- Validation ----\n",
      "Validation loss: 36.5105\n",
      "Validation acc: 0.6515\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 429.4974, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 411.6353, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 20: 409.1201, Accuracy: 0.6551\n",
      "Training loss (for one batch) at step 30: 388.3324, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 40: 388.4090, Accuracy: 0.6721\n",
      "Training loss (for one batch) at step 50: 381.6448, Accuracy: 0.6854\n",
      "Training loss (for one batch) at step 60: 387.7171, Accuracy: 0.6895\n",
      "Training loss (for one batch) at step 70: 409.3951, Accuracy: 0.6901\n",
      "Training loss (for one batch) at step 80: 431.7547, Accuracy: 0.6896\n",
      "Training loss (for one batch) at step 90: 411.7568, Accuracy: 0.6855\n",
      "Training loss (for one batch) at step 100: 391.7675, Accuracy: 0.6851\n",
      "Training loss (for one batch) at step 110: 396.5004, Accuracy: 0.6855\n",
      "---- Training ----\n",
      "Training loss: 136.3848\n",
      "Training acc over epoch: 0.6842\n",
      "---- Validation ----\n",
      "Validation loss: 36.0122\n",
      "Validation acc: 0.6625\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 429.4524, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 432.5466, Accuracy: 0.6506\n",
      "Training loss (for one batch) at step 20: 410.5057, Accuracy: 0.6518\n",
      "Training loss (for one batch) at step 30: 379.4918, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 40: 374.5422, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 50: 372.1702, Accuracy: 0.6893\n",
      "Training loss (for one batch) at step 60: 373.1539, Accuracy: 0.6957\n",
      "Training loss (for one batch) at step 70: 413.1080, Accuracy: 0.6933\n",
      "Training loss (for one batch) at step 80: 406.3874, Accuracy: 0.6904\n",
      "Training loss (for one batch) at step 90: 395.1579, Accuracy: 0.6821\n",
      "Training loss (for one batch) at step 100: 395.9871, Accuracy: 0.6806\n",
      "Training loss (for one batch) at step 110: 401.3427, Accuracy: 0.6809\n",
      "---- Training ----\n",
      "Training loss: 124.3253\n",
      "Training acc over epoch: 0.6779\n",
      "---- Validation ----\n",
      "Validation loss: 43.4352\n",
      "Validation acc: 0.6443\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 428.4767, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 406.6428, Accuracy: 0.6626\n",
      "Training loss (for one batch) at step 20: 391.8143, Accuracy: 0.6704\n",
      "Training loss (for one batch) at step 30: 395.8056, Accuracy: 0.6799\n",
      "Training loss (for one batch) at step 40: 363.4808, Accuracy: 0.6839\n",
      "Training loss (for one batch) at step 50: 376.6542, Accuracy: 0.6916\n",
      "Training loss (for one batch) at step 60: 392.9205, Accuracy: 0.6992\n",
      "Training loss (for one batch) at step 70: 396.9152, Accuracy: 0.6943\n",
      "Training loss (for one batch) at step 80: 411.8579, Accuracy: 0.6876\n",
      "Training loss (for one batch) at step 90: 382.7374, Accuracy: 0.6851\n",
      "Training loss (for one batch) at step 100: 400.5507, Accuracy: 0.6851\n",
      "Training loss (for one batch) at step 110: 379.2102, Accuracy: 0.6822\n",
      "---- Training ----\n",
      "Training loss: 117.5484\n",
      "Training acc over epoch: 0.6812\n",
      "---- Validation ----\n",
      "Validation loss: 33.2128\n",
      "Validation acc: 0.6472\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 409.2631, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 411.9529, Accuracy: 0.6683\n",
      "Training loss (for one batch) at step 20: 372.0362, Accuracy: 0.6596\n",
      "Training loss (for one batch) at step 30: 394.3368, Accuracy: 0.6648\n",
      "Training loss (for one batch) at step 40: 365.4274, Accuracy: 0.6761\n",
      "Training loss (for one batch) at step 50: 367.7515, Accuracy: 0.6880\n",
      "Training loss (for one batch) at step 60: 359.9407, Accuracy: 0.6938\n",
      "Training loss (for one batch) at step 70: 402.0695, Accuracy: 0.6914\n",
      "Training loss (for one batch) at step 80: 409.3981, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 90: 359.1176, Accuracy: 0.6829\n",
      "Training loss (for one batch) at step 100: 366.2885, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 110: 405.4185, Accuracy: 0.6798\n",
      "---- Training ----\n",
      "Training loss: 111.9315\n",
      "Training acc over epoch: 0.6789\n",
      "---- Validation ----\n",
      "Validation loss: 38.1720\n",
      "Validation acc: 0.6389\n",
      "Time taken: 10.23s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 414.9209, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 410.3374, Accuracy: 0.6357\n",
      "Training loss (for one batch) at step 20: 366.9417, Accuracy: 0.6507\n",
      "Training loss (for one batch) at step 30: 357.3376, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 40: 356.3931, Accuracy: 0.6688\n",
      "Training loss (for one batch) at step 50: 365.6756, Accuracy: 0.6809\n",
      "Training loss (for one batch) at step 60: 356.6430, Accuracy: 0.6878\n",
      "Training loss (for one batch) at step 70: 375.6749, Accuracy: 0.6814\n",
      "Training loss (for one batch) at step 80: 385.0370, Accuracy: 0.6761\n",
      "Training loss (for one batch) at step 90: 370.8433, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 100: 370.5331, Accuracy: 0.6730\n",
      "Training loss (for one batch) at step 110: 366.0823, Accuracy: 0.6723\n",
      "---- Training ----\n",
      "Training loss: 114.5611\n",
      "Training acc over epoch: 0.6709\n",
      "---- Validation ----\n",
      "Validation loss: 44.1348\n",
      "Validation acc: 0.6147\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 421.3426, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 413.6678, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 20: 372.6979, Accuracy: 0.6466\n",
      "Training loss (for one batch) at step 30: 367.9930, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 40: 359.1717, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 50: 359.5669, Accuracy: 0.6820\n",
      "Training loss (for one batch) at step 60: 345.3557, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 70: 391.3491, Accuracy: 0.6843\n",
      "Training loss (for one batch) at step 80: 379.0829, Accuracy: 0.6782\n",
      "Training loss (for one batch) at step 90: 360.1039, Accuracy: 0.6734\n",
      "Training loss (for one batch) at step 100: 351.7544, Accuracy: 0.6730\n",
      "Training loss (for one batch) at step 110: 373.0277, Accuracy: 0.6737\n",
      "---- Training ----\n",
      "Training loss: 108.6284\n",
      "Training acc over epoch: 0.6717\n",
      "---- Validation ----\n",
      "Validation loss: 35.0370\n",
      "Validation acc: 0.6150\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 391.1526, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 405.0139, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 20: 356.6247, Accuracy: 0.6391\n",
      "Training loss (for one batch) at step 30: 350.7171, Accuracy: 0.6520\n",
      "Training loss (for one batch) at step 40: 364.2483, Accuracy: 0.6627\n",
      "Training loss (for one batch) at step 50: 338.3913, Accuracy: 0.6751\n",
      "Training loss (for one batch) at step 60: 352.2010, Accuracy: 0.6831\n",
      "Training loss (for one batch) at step 70: 378.9402, Accuracy: 0.6787\n",
      "Training loss (for one batch) at step 80: 376.1880, Accuracy: 0.6695\n",
      "Training loss (for one batch) at step 90: 365.4102, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 100: 349.0807, Accuracy: 0.6675\n",
      "Training loss (for one batch) at step 110: 371.6235, Accuracy: 0.6679\n",
      "---- Training ----\n",
      "Training loss: 122.1129\n",
      "Training acc over epoch: 0.6673\n",
      "---- Validation ----\n",
      "Validation loss: 37.7875\n",
      "Validation acc: 0.6228\n",
      "Time taken: 10.25s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 401.0894, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 390.6440, Accuracy: 0.6080\n",
      "Training loss (for one batch) at step 20: 365.5125, Accuracy: 0.6168\n",
      "Training loss (for one batch) at step 30: 351.7881, Accuracy: 0.6416\n",
      "Training loss (for one batch) at step 40: 330.1671, Accuracy: 0.6509\n",
      "Training loss (for one batch) at step 50: 344.3107, Accuracy: 0.6656\n",
      "Training loss (for one batch) at step 60: 370.8503, Accuracy: 0.6703\n",
      "Training loss (for one batch) at step 70: 360.0339, Accuracy: 0.6664\n",
      "Training loss (for one batch) at step 80: 384.3540, Accuracy: 0.6622\n",
      "Training loss (for one batch) at step 90: 370.6294, Accuracy: 0.6581\n",
      "Training loss (for one batch) at step 100: 350.6844, Accuracy: 0.6585\n",
      "Training loss (for one batch) at step 110: 349.4948, Accuracy: 0.6591\n",
      "---- Training ----\n",
      "Training loss: 115.5234\n",
      "Training acc over epoch: 0.6580\n",
      "---- Validation ----\n",
      "Validation loss: 36.5270\n",
      "Validation acc: 0.6279\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 387.4867, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 385.0127, Accuracy: 0.6307\n",
      "Training loss (for one batch) at step 20: 353.4406, Accuracy: 0.6462\n",
      "Training loss (for one batch) at step 30: 323.3490, Accuracy: 0.6510\n",
      "Training loss (for one batch) at step 40: 331.1131, Accuracy: 0.6675\n",
      "Training loss (for one batch) at step 50: 350.9884, Accuracy: 0.6766\n",
      "Training loss (for one batch) at step 60: 345.2528, Accuracy: 0.6826\n",
      "Training loss (for one batch) at step 70: 375.2348, Accuracy: 0.6794\n",
      "Training loss (for one batch) at step 80: 365.2536, Accuracy: 0.6695\n",
      "Training loss (for one batch) at step 90: 344.2885, Accuracy: 0.6638\n",
      "Training loss (for one batch) at step 100: 353.0904, Accuracy: 0.6655\n",
      "Training loss (for one batch) at step 110: 353.6307, Accuracy: 0.6650\n",
      "---- Training ----\n",
      "Training loss: 138.5263\n",
      "Training acc over epoch: 0.6640\n",
      "---- Validation ----\n",
      "Validation loss: 37.8528\n",
      "Validation acc: 0.6249\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 404.2679, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 379.7718, Accuracy: 0.6257\n",
      "Training loss (for one batch) at step 20: 348.0676, Accuracy: 0.6269\n",
      "Training loss (for one batch) at step 30: 336.3049, Accuracy: 0.6444\n",
      "Training loss (for one batch) at step 40: 338.2764, Accuracy: 0.6599\n",
      "Training loss (for one batch) at step 50: 347.5149, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 60: 350.5912, Accuracy: 0.6761\n",
      "Training loss (for one batch) at step 70: 348.0707, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 80: 385.6508, Accuracy: 0.6649\n",
      "Training loss (for one batch) at step 90: 350.6904, Accuracy: 0.6618\n",
      "Training loss (for one batch) at step 100: 328.6954, Accuracy: 0.6620\n",
      "Training loss (for one batch) at step 110: 358.8515, Accuracy: 0.6629\n",
      "---- Training ----\n",
      "Training loss: 117.5658\n",
      "Training acc over epoch: 0.6611\n",
      "---- Validation ----\n",
      "Validation loss: 50.2334\n",
      "Validation acc: 0.6115\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 391.8605, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 379.5140, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 20: 341.5734, Accuracy: 0.6190\n",
      "Training loss (for one batch) at step 30: 317.7595, Accuracy: 0.6366\n",
      "Training loss (for one batch) at step 40: 328.0302, Accuracy: 0.6545\n",
      "Training loss (for one batch) at step 50: 302.7039, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 60: 346.9482, Accuracy: 0.6739\n",
      "Training loss (for one batch) at step 70: 371.3044, Accuracy: 0.6686\n",
      "Training loss (for one batch) at step 80: 369.9097, Accuracy: 0.6628\n",
      "Training loss (for one batch) at step 90: 334.8906, Accuracy: 0.6600\n",
      "Training loss (for one batch) at step 100: 327.2098, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 110: 344.9996, Accuracy: 0.6601\n",
      "---- Training ----\n",
      "Training loss: 125.0831\n",
      "Training acc over epoch: 0.6588\n",
      "---- Validation ----\n",
      "Validation loss: 35.8425\n",
      "Validation acc: 0.6147\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 407.5974, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 390.2153, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 20: 352.1782, Accuracy: 0.6343\n",
      "Training loss (for one batch) at step 30: 317.8766, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 40: 323.4886, Accuracy: 0.6681\n",
      "Training loss (for one batch) at step 50: 322.7260, Accuracy: 0.6771\n",
      "Training loss (for one batch) at step 60: 338.2728, Accuracy: 0.6822\n",
      "Training loss (for one batch) at step 70: 359.0724, Accuracy: 0.6723\n",
      "Training loss (for one batch) at step 80: 364.7494, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 90: 335.6923, Accuracy: 0.6601\n",
      "Training loss (for one batch) at step 100: 363.5433, Accuracy: 0.6594\n",
      "Training loss (for one batch) at step 110: 352.2630, Accuracy: 0.6569\n",
      "---- Training ----\n",
      "Training loss: 109.0418\n",
      "Training acc over epoch: 0.6567\n",
      "---- Validation ----\n",
      "Validation loss: 46.6889\n",
      "Validation acc: 0.6295\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 376.0264, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 368.7560, Accuracy: 0.5994\n",
      "Training loss (for one batch) at step 20: 328.2667, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 30: 330.6429, Accuracy: 0.6396\n",
      "Training loss (for one batch) at step 40: 329.9702, Accuracy: 0.6597\n",
      "Training loss (for one batch) at step 50: 305.8717, Accuracy: 0.6734\n",
      "Training loss (for one batch) at step 60: 351.1131, Accuracy: 0.6757\n",
      "Training loss (for one batch) at step 70: 344.9944, Accuracy: 0.6679\n",
      "Training loss (for one batch) at step 80: 366.1241, Accuracy: 0.6606\n",
      "Training loss (for one batch) at step 90: 342.2905, Accuracy: 0.6575\n",
      "Training loss (for one batch) at step 100: 322.2812, Accuracy: 0.6576\n",
      "Training loss (for one batch) at step 110: 356.8828, Accuracy: 0.6562\n",
      "---- Training ----\n",
      "Training loss: 114.2844\n",
      "Training acc over epoch: 0.6550\n",
      "---- Validation ----\n",
      "Validation loss: 31.2579\n",
      "Validation acc: 0.6188\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 387.4635, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 371.2214, Accuracy: 0.5916\n",
      "Training loss (for one batch) at step 20: 332.1449, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 30: 333.3534, Accuracy: 0.6436\n",
      "Training loss (for one batch) at step 40: 314.0024, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 50: 324.3451, Accuracy: 0.6677\n",
      "Training loss (for one batch) at step 60: 339.4205, Accuracy: 0.6770\n",
      "Training loss (for one batch) at step 70: 355.0861, Accuracy: 0.6674\n",
      "Training loss (for one batch) at step 80: 347.0664, Accuracy: 0.6583\n",
      "Training loss (for one batch) at step 90: 350.8286, Accuracy: 0.6553\n",
      "Training loss (for one batch) at step 100: 329.2040, Accuracy: 0.6573\n",
      "Training loss (for one batch) at step 110: 329.7393, Accuracy: 0.6579\n",
      "---- Training ----\n",
      "Training loss: 118.5114\n",
      "Training acc over epoch: 0.6551\n",
      "---- Validation ----\n",
      "Validation loss: 37.9220\n",
      "Validation acc: 0.6128\n",
      "Time taken: 10.81s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 370.3919, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 342.7322, Accuracy: 0.5902\n",
      "Training loss (for one batch) at step 20: 321.5139, Accuracy: 0.6194\n",
      "Training loss (for one batch) at step 30: 310.2512, Accuracy: 0.6439\n",
      "Training loss (for one batch) at step 40: 329.2771, Accuracy: 0.6610\n",
      "Training loss (for one batch) at step 50: 296.1905, Accuracy: 0.6742\n",
      "Training loss (for one batch) at step 60: 332.9404, Accuracy: 0.6790\n",
      "Training loss (for one batch) at step 70: 350.3354, Accuracy: 0.6723\n",
      "Training loss (for one batch) at step 80: 361.6834, Accuracy: 0.6617\n",
      "Training loss (for one batch) at step 90: 326.4386, Accuracy: 0.6579\n",
      "Training loss (for one batch) at step 100: 321.1986, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 110: 336.9337, Accuracy: 0.6586\n",
      "---- Training ----\n",
      "Training loss: 114.4761\n",
      "Training acc over epoch: 0.6567\n",
      "---- Validation ----\n",
      "Validation loss: 35.9075\n",
      "Validation acc: 0.5994\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 343.3310, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 345.5487, Accuracy: 0.5916\n",
      "Training loss (for one batch) at step 20: 301.2786, Accuracy: 0.6239\n",
      "Training loss (for one batch) at step 30: 319.2697, Accuracy: 0.6439\n",
      "Training loss (for one batch) at step 40: 343.7357, Accuracy: 0.6555\n",
      "Training loss (for one batch) at step 50: 304.4713, Accuracy: 0.6677\n",
      "Training loss (for one batch) at step 60: 336.0561, Accuracy: 0.6738\n",
      "Training loss (for one batch) at step 70: 370.8334, Accuracy: 0.6642\n",
      "Training loss (for one batch) at step 80: 356.7544, Accuracy: 0.6555\n",
      "Training loss (for one batch) at step 90: 313.3734, Accuracy: 0.6551\n",
      "Training loss (for one batch) at step 100: 322.7512, Accuracy: 0.6552\n",
      "Training loss (for one batch) at step 110: 320.7912, Accuracy: 0.6532\n",
      "---- Training ----\n",
      "Training loss: 103.8381\n",
      "Training acc over epoch: 0.6516\n",
      "---- Validation ----\n",
      "Validation loss: 60.1580\n",
      "Validation acc: 0.5940\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 358.6858, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 358.0642, Accuracy: 0.5881\n",
      "Training loss (for one batch) at step 20: 328.3710, Accuracy: 0.6127\n",
      "Training loss (for one batch) at step 30: 310.3304, Accuracy: 0.6373\n",
      "Training loss (for one batch) at step 40: 315.0583, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 50: 305.9265, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 60: 313.5445, Accuracy: 0.6744\n",
      "Training loss (for one batch) at step 70: 335.2630, Accuracy: 0.6668\n",
      "Training loss (for one batch) at step 80: 360.8305, Accuracy: 0.6541\n",
      "Training loss (for one batch) at step 90: 327.5275, Accuracy: 0.6512\n",
      "Training loss (for one batch) at step 100: 337.2352, Accuracy: 0.6542\n",
      "Training loss (for one batch) at step 110: 333.0264, Accuracy: 0.6539\n",
      "---- Training ----\n",
      "Training loss: 116.8417\n",
      "Training acc over epoch: 0.6521\n",
      "---- Validation ----\n",
      "Validation loss: 47.8844\n",
      "Validation acc: 0.6077\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 353.8914, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 370.3514, Accuracy: 0.5916\n",
      "Training loss (for one batch) at step 20: 311.4522, Accuracy: 0.6045\n",
      "Training loss (for one batch) at step 30: 319.0639, Accuracy: 0.6358\n",
      "Training loss (for one batch) at step 40: 309.6208, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 50: 315.2268, Accuracy: 0.6682\n",
      "Training loss (for one batch) at step 60: 321.0399, Accuracy: 0.6723\n",
      "Training loss (for one batch) at step 70: 355.7534, Accuracy: 0.6646\n",
      "Training loss (for one batch) at step 80: 370.9935, Accuracy: 0.6554\n",
      "Training loss (for one batch) at step 90: 321.3437, Accuracy: 0.6521\n",
      "Training loss (for one batch) at step 100: 313.8474, Accuracy: 0.6534\n",
      "Training loss (for one batch) at step 110: 327.8051, Accuracy: 0.6518\n",
      "---- Training ----\n",
      "Training loss: 102.2431\n",
      "Training acc over epoch: 0.6511\n",
      "---- Validation ----\n",
      "Validation loss: 43.4092\n",
      "Validation acc: 0.5959\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 358.0609, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 344.7958, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 20: 323.0303, Accuracy: 0.6083\n",
      "Training loss (for one batch) at step 30: 320.9038, Accuracy: 0.6268\n",
      "Training loss (for one batch) at step 40: 305.2556, Accuracy: 0.6446\n",
      "Training loss (for one batch) at step 50: 302.8680, Accuracy: 0.6612\n",
      "Training loss (for one batch) at step 60: 308.0463, Accuracy: 0.6685\n",
      "Training loss (for one batch) at step 70: 320.4299, Accuracy: 0.6637\n",
      "Training loss (for one batch) at step 80: 346.7715, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 90: 323.1349, Accuracy: 0.6521\n",
      "Training loss (for one batch) at step 100: 306.7157, Accuracy: 0.6533\n",
      "Training loss (for one batch) at step 110: 317.1383, Accuracy: 0.6536\n",
      "---- Training ----\n",
      "Training loss: 101.6398\n",
      "Training acc over epoch: 0.6503\n",
      "---- Validation ----\n",
      "Validation loss: 62.3927\n",
      "Validation acc: 0.5970\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 362.7463, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 349.9219, Accuracy: 0.5973\n",
      "Training loss (for one batch) at step 20: 316.1075, Accuracy: 0.6150\n",
      "Training loss (for one batch) at step 30: 295.7357, Accuracy: 0.6353\n",
      "Training loss (for one batch) at step 40: 294.7557, Accuracy: 0.6566\n",
      "Training loss (for one batch) at step 50: 298.8663, Accuracy: 0.6696\n",
      "Training loss (for one batch) at step 60: 313.8851, Accuracy: 0.6761\n",
      "Training loss (for one batch) at step 70: 322.1526, Accuracy: 0.6643\n",
      "Training loss (for one batch) at step 80: 345.9192, Accuracy: 0.6553\n",
      "Training loss (for one batch) at step 90: 313.9761, Accuracy: 0.6522\n",
      "Training loss (for one batch) at step 100: 322.3325, Accuracy: 0.6539\n",
      "Training loss (for one batch) at step 110: 327.2423, Accuracy: 0.6524\n",
      "---- Training ----\n",
      "Training loss: 101.6474\n",
      "Training acc over epoch: 0.6512\n",
      "---- Validation ----\n",
      "Validation loss: 55.3426\n",
      "Validation acc: 0.6032\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 371.9946, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 357.3165, Accuracy: 0.5646\n",
      "Training loss (for one batch) at step 20: 333.0382, Accuracy: 0.6116\n",
      "Training loss (for one batch) at step 30: 311.5126, Accuracy: 0.6318\n",
      "Training loss (for one batch) at step 40: 314.5683, Accuracy: 0.6500\n",
      "Training loss (for one batch) at step 50: 319.2741, Accuracy: 0.6570\n",
      "Training loss (for one batch) at step 60: 328.9909, Accuracy: 0.6651\n",
      "Training loss (for one batch) at step 70: 320.3891, Accuracy: 0.6602\n",
      "Training loss (for one batch) at step 80: 336.3773, Accuracy: 0.6507\n",
      "Training loss (for one batch) at step 90: 312.4639, Accuracy: 0.6491\n",
      "Training loss (for one batch) at step 100: 335.3387, Accuracy: 0.6521\n",
      "Training loss (for one batch) at step 110: 326.7207, Accuracy: 0.6491\n",
      "---- Training ----\n",
      "Training loss: 113.1206\n",
      "Training acc over epoch: 0.6496\n",
      "---- Validation ----\n",
      "Validation loss: 42.6436\n",
      "Validation acc: 0.6053\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 349.2989, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 377.6567, Accuracy: 0.5845\n",
      "Training loss (for one batch) at step 20: 299.7041, Accuracy: 0.6057\n",
      "Training loss (for one batch) at step 30: 299.5817, Accuracy: 0.6343\n",
      "Training loss (for one batch) at step 40: 304.4551, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 50: 287.1738, Accuracy: 0.6657\n",
      "Training loss (for one batch) at step 60: 329.4590, Accuracy: 0.6700\n",
      "Training loss (for one batch) at step 70: 321.3402, Accuracy: 0.6621\n",
      "Training loss (for one batch) at step 80: 344.4557, Accuracy: 0.6526\n",
      "Training loss (for one batch) at step 90: 331.1593, Accuracy: 0.6497\n",
      "Training loss (for one batch) at step 100: 303.1941, Accuracy: 0.6517\n",
      "Training loss (for one batch) at step 110: 322.0034, Accuracy: 0.6505\n",
      "---- Training ----\n",
      "Training loss: 97.7857\n",
      "Training acc over epoch: 0.6495\n",
      "---- Validation ----\n",
      "Validation loss: 43.7581\n",
      "Validation acc: 0.6067\n",
      "Time taken: 13.09s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 381.6393, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 349.6651, Accuracy: 0.5682\n",
      "Training loss (for one batch) at step 20: 302.4873, Accuracy: 0.6038\n",
      "Training loss (for one batch) at step 30: 302.9992, Accuracy: 0.6300\n",
      "Training loss (for one batch) at step 40: 293.1801, Accuracy: 0.6500\n",
      "Training loss (for one batch) at step 50: 299.4768, Accuracy: 0.6622\n",
      "Training loss (for one batch) at step 60: 323.8745, Accuracy: 0.6716\n",
      "Training loss (for one batch) at step 70: 319.9371, Accuracy: 0.6642\n",
      "Training loss (for one batch) at step 80: 337.6496, Accuracy: 0.6519\n",
      "Training loss (for one batch) at step 90: 322.3939, Accuracy: 0.6480\n",
      "Training loss (for one batch) at step 100: 324.1791, Accuracy: 0.6494\n",
      "Training loss (for one batch) at step 110: 300.8745, Accuracy: 0.6483\n",
      "---- Training ----\n",
      "Training loss: 108.7043\n",
      "Training acc over epoch: 0.6469\n",
      "---- Validation ----\n",
      "Validation loss: 41.9625\n",
      "Validation acc: 0.6128\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 363.7689, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 356.9856, Accuracy: 0.5753\n",
      "Training loss (for one batch) at step 20: 320.9817, Accuracy: 0.6202\n",
      "Training loss (for one batch) at step 30: 312.4068, Accuracy: 0.6421\n",
      "Training loss (for one batch) at step 40: 299.0054, Accuracy: 0.6568\n",
      "Training loss (for one batch) at step 50: 308.2807, Accuracy: 0.6688\n",
      "Training loss (for one batch) at step 60: 313.3814, Accuracy: 0.6729\n",
      "Training loss (for one batch) at step 70: 311.2350, Accuracy: 0.6665\n",
      "Training loss (for one batch) at step 80: 349.5833, Accuracy: 0.6536\n",
      "Training loss (for one batch) at step 90: 314.3047, Accuracy: 0.6503\n",
      "Training loss (for one batch) at step 100: 290.3454, Accuracy: 0.6526\n",
      "Training loss (for one batch) at step 110: 312.1721, Accuracy: 0.6524\n",
      "---- Training ----\n",
      "Training loss: 115.2212\n",
      "Training acc over epoch: 0.6511\n",
      "---- Validation ----\n",
      "Validation loss: 58.9416\n",
      "Validation acc: 0.5889\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 358.4570, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 345.5602, Accuracy: 0.5732\n",
      "Training loss (for one batch) at step 20: 307.2750, Accuracy: 0.6027\n",
      "Training loss (for one batch) at step 30: 296.1869, Accuracy: 0.6293\n",
      "Training loss (for one batch) at step 40: 299.2495, Accuracy: 0.6479\n",
      "Training loss (for one batch) at step 50: 306.3118, Accuracy: 0.6615\n",
      "Training loss (for one batch) at step 60: 313.4387, Accuracy: 0.6679\n",
      "Training loss (for one batch) at step 70: 324.6340, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 80: 315.4547, Accuracy: 0.6488\n",
      "Training loss (for one batch) at step 90: 310.2947, Accuracy: 0.6474\n",
      "Training loss (for one batch) at step 100: 310.2323, Accuracy: 0.6500\n",
      "Training loss (for one batch) at step 110: 309.3850, Accuracy: 0.6494\n",
      "---- Training ----\n",
      "Training loss: 108.0485\n",
      "Training acc over epoch: 0.6468\n",
      "---- Validation ----\n",
      "Validation loss: 37.2695\n",
      "Validation acc: 0.6088\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 364.2725, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 348.0876, Accuracy: 0.5824\n",
      "Training loss (for one batch) at step 20: 320.2769, Accuracy: 0.6205\n",
      "Training loss (for one batch) at step 30: 296.6022, Accuracy: 0.6467\n",
      "Training loss (for one batch) at step 40: 287.2712, Accuracy: 0.6559\n",
      "Training loss (for one batch) at step 50: 287.6271, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 60: 299.9991, Accuracy: 0.6760\n",
      "Training loss (for one batch) at step 70: 318.9612, Accuracy: 0.6669\n",
      "Training loss (for one batch) at step 80: 343.1738, Accuracy: 0.6563\n",
      "Training loss (for one batch) at step 90: 316.0055, Accuracy: 0.6515\n",
      "Training loss (for one batch) at step 100: 312.7828, Accuracy: 0.6521\n",
      "Training loss (for one batch) at step 110: 302.0035, Accuracy: 0.6508\n",
      "---- Training ----\n",
      "Training loss: 104.3877\n",
      "Training acc over epoch: 0.6507\n",
      "---- Validation ----\n",
      "Validation loss: 46.3298\n",
      "Validation acc: 0.5876\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 350.1509, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 356.7059, Accuracy: 0.5653\n",
      "Training loss (for one batch) at step 20: 304.1294, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 30: 290.9582, Accuracy: 0.6232\n",
      "Training loss (for one batch) at step 40: 285.0413, Accuracy: 0.6442\n",
      "Training loss (for one batch) at step 50: 293.8893, Accuracy: 0.6598\n",
      "Training loss (for one batch) at step 60: 301.3109, Accuracy: 0.6679\n",
      "Training loss (for one batch) at step 70: 309.9691, Accuracy: 0.6583\n",
      "Training loss (for one batch) at step 80: 316.1492, Accuracy: 0.6469\n",
      "Training loss (for one batch) at step 90: 304.7852, Accuracy: 0.6445\n",
      "Training loss (for one batch) at step 100: 313.9224, Accuracy: 0.6470\n",
      "Training loss (for one batch) at step 110: 313.0554, Accuracy: 0.6472\n",
      "---- Training ----\n",
      "Training loss: 110.7612\n",
      "Training acc over epoch: 0.6453\n",
      "---- Validation ----\n",
      "Validation loss: 40.2289\n",
      "Validation acc: 0.6158\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 332.5106, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 315.8003, Accuracy: 0.5817\n",
      "Training loss (for one batch) at step 20: 288.2901, Accuracy: 0.6112\n",
      "Training loss (for one batch) at step 30: 282.4130, Accuracy: 0.6351\n",
      "Training loss (for one batch) at step 40: 296.6296, Accuracy: 0.6519\n",
      "Training loss (for one batch) at step 50: 290.9231, Accuracy: 0.6638\n",
      "Training loss (for one batch) at step 60: 287.1370, Accuracy: 0.6739\n",
      "Training loss (for one batch) at step 70: 323.7363, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 80: 336.3425, Accuracy: 0.6528\n",
      "Training loss (for one batch) at step 90: 293.3615, Accuracy: 0.6497\n",
      "Training loss (for one batch) at step 100: 309.2014, Accuracy: 0.6517\n",
      "Training loss (for one batch) at step 110: 315.8015, Accuracy: 0.6520\n",
      "---- Training ----\n",
      "Training loss: 90.7229\n",
      "Training acc over epoch: 0.6503\n",
      "---- Validation ----\n",
      "Validation loss: 42.3409\n",
      "Validation acc: 0.6099\n",
      "Time taken: 10.34s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6337\n",
      "Validation AUC: 0.6333\n",
      "Validation Balanced_ACC: 0.4099\n",
      "Validation AUCSK: 0.7703\n",
      "Validation MI: 0.1007\n",
      "Validation Normalized MI: 0.1468\n",
      "Validation Adjusted MI: 0.1468\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 688.1454, Accuracy: 0.4375\n",
      "Training loss (for one batch) at step 10: 673.8788, Accuracy: 0.5121\n",
      "Training loss (for one batch) at step 20: 542.9769, Accuracy: 0.5041\n",
      "Training loss (for one batch) at step 30: 560.6143, Accuracy: 0.5111\n",
      "Training loss (for one batch) at step 40: 540.5743, Accuracy: 0.5099\n",
      "Training loss (for one batch) at step 50: 504.6660, Accuracy: 0.5046\n",
      "Training loss (for one batch) at step 60: 485.3459, Accuracy: 0.5055\n",
      "Training loss (for one batch) at step 70: 475.3705, Accuracy: 0.5111\n",
      "Training loss (for one batch) at step 80: 466.6476, Accuracy: 0.5097\n",
      "Training loss (for one batch) at step 90: 480.8861, Accuracy: 0.5110\n",
      "Training loss (for one batch) at step 100: 461.1818, Accuracy: 0.5104\n",
      "Training loss (for one batch) at step 110: 467.2394, Accuracy: 0.5088\n",
      "---- Training ----\n",
      "Training loss: 142.5889\n",
      "Training acc over epoch: 0.5093\n",
      "---- Validation ----\n",
      "Validation loss: 34.6800\n",
      "Validation acc: 0.5116\n",
      "Time taken: 13.98s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 470.2227, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 467.7594, Accuracy: 0.5334\n",
      "Training loss (for one batch) at step 20: 458.2816, Accuracy: 0.5272\n",
      "Training loss (for one batch) at step 30: 463.6097, Accuracy: 0.5214\n",
      "Training loss (for one batch) at step 40: 452.8585, Accuracy: 0.5177\n",
      "Training loss (for one batch) at step 50: 452.1103, Accuracy: 0.5191\n",
      "Training loss (for one batch) at step 60: 451.3398, Accuracy: 0.5210\n",
      "Training loss (for one batch) at step 70: 455.9909, Accuracy: 0.5224\n",
      "Training loss (for one batch) at step 80: 454.3606, Accuracy: 0.5205\n",
      "Training loss (for one batch) at step 90: 443.3242, Accuracy: 0.5218\n",
      "Training loss (for one batch) at step 100: 444.1181, Accuracy: 0.5224\n",
      "Training loss (for one batch) at step 110: 451.5718, Accuracy: 0.5225\n",
      "---- Training ----\n",
      "Training loss: 142.0300\n",
      "Training acc over epoch: 0.5220\n",
      "---- Validation ----\n",
      "Validation loss: 34.3933\n",
      "Validation acc: 0.5132\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 448.3449, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 451.9428, Accuracy: 0.5057\n",
      "Training loss (for one batch) at step 20: 446.3555, Accuracy: 0.5160\n",
      "Training loss (for one batch) at step 30: 451.8394, Accuracy: 0.5179\n",
      "Training loss (for one batch) at step 40: 448.5055, Accuracy: 0.5192\n",
      "Training loss (for one batch) at step 50: 442.3237, Accuracy: 0.5205\n",
      "Training loss (for one batch) at step 60: 444.5743, Accuracy: 0.5222\n",
      "Training loss (for one batch) at step 70: 444.5449, Accuracy: 0.5206\n",
      "Training loss (for one batch) at step 80: 452.8769, Accuracy: 0.5250\n",
      "Training loss (for one batch) at step 90: 441.6219, Accuracy: 0.5281\n",
      "Training loss (for one batch) at step 100: 441.1012, Accuracy: 0.5251\n",
      "Training loss (for one batch) at step 110: 446.9463, Accuracy: 0.5267\n",
      "---- Training ----\n",
      "Training loss: 139.8756\n",
      "Training acc over epoch: 0.5255\n",
      "---- Validation ----\n",
      "Validation loss: 34.8054\n",
      "Validation acc: 0.5494\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 445.6708, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 441.5357, Accuracy: 0.5384\n",
      "Training loss (for one batch) at step 20: 445.3602, Accuracy: 0.5424\n",
      "Training loss (for one batch) at step 30: 443.3031, Accuracy: 0.5466\n",
      "Training loss (for one batch) at step 40: 443.4833, Accuracy: 0.5471\n",
      "Training loss (for one batch) at step 50: 443.2555, Accuracy: 0.5403\n",
      "Training loss (for one batch) at step 60: 446.8707, Accuracy: 0.5406\n",
      "Training loss (for one batch) at step 70: 443.2543, Accuracy: 0.5416\n",
      "Training loss (for one batch) at step 80: 446.2528, Accuracy: 0.5421\n",
      "Training loss (for one batch) at step 90: 443.6368, Accuracy: 0.5437\n",
      "Training loss (for one batch) at step 100: 445.2294, Accuracy: 0.5432\n",
      "Training loss (for one batch) at step 110: 444.3474, Accuracy: 0.5420\n",
      "---- Training ----\n",
      "Training loss: 138.5260\n",
      "Training acc over epoch: 0.5416\n",
      "---- Validation ----\n",
      "Validation loss: 34.0662\n",
      "Validation acc: 0.5505\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 443.0158, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 443.6464, Accuracy: 0.5412\n",
      "Training loss (for one batch) at step 20: 446.6011, Accuracy: 0.5662\n",
      "Training loss (for one batch) at step 30: 448.2035, Accuracy: 0.5711\n",
      "Training loss (for one batch) at step 40: 440.4953, Accuracy: 0.5694\n",
      "Training loss (for one batch) at step 50: 445.4152, Accuracy: 0.5708\n",
      "Training loss (for one batch) at step 60: 443.7533, Accuracy: 0.5706\n",
      "Training loss (for one batch) at step 70: 443.3151, Accuracy: 0.5715\n",
      "Training loss (for one batch) at step 80: 444.1787, Accuracy: 0.5694\n",
      "Training loss (for one batch) at step 90: 445.4777, Accuracy: 0.5705\n",
      "Training loss (for one batch) at step 100: 443.1052, Accuracy: 0.5681\n",
      "Training loss (for one batch) at step 110: 442.0558, Accuracy: 0.5668\n",
      "---- Training ----\n",
      "Training loss: 138.0023\n",
      "Training acc over epoch: 0.5656\n",
      "---- Validation ----\n",
      "Validation loss: 34.5057\n",
      "Validation acc: 0.5607\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 442.2045, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 445.0610, Accuracy: 0.5533\n",
      "Training loss (for one batch) at step 20: 441.2916, Accuracy: 0.5662\n",
      "Training loss (for one batch) at step 30: 442.5268, Accuracy: 0.5665\n",
      "Training loss (for one batch) at step 40: 439.2174, Accuracy: 0.5612\n",
      "Training loss (for one batch) at step 50: 443.2107, Accuracy: 0.5646\n",
      "Training loss (for one batch) at step 60: 438.4163, Accuracy: 0.5689\n",
      "Training loss (for one batch) at step 70: 440.4870, Accuracy: 0.5702\n",
      "Training loss (for one batch) at step 80: 446.8897, Accuracy: 0.5700\n",
      "Training loss (for one batch) at step 90: 441.0529, Accuracy: 0.5700\n",
      "Training loss (for one batch) at step 100: 443.2831, Accuracy: 0.5678\n",
      "Training loss (for one batch) at step 110: 444.9790, Accuracy: 0.5683\n",
      "---- Training ----\n",
      "Training loss: 137.3071\n",
      "Training acc over epoch: 0.5687\n",
      "---- Validation ----\n",
      "Validation loss: 34.5278\n",
      "Validation acc: 0.5785\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 443.7301, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 444.6220, Accuracy: 0.5817\n",
      "Training loss (for one batch) at step 20: 441.2357, Accuracy: 0.5751\n",
      "Training loss (for one batch) at step 30: 436.7064, Accuracy: 0.5824\n",
      "Training loss (for one batch) at step 40: 440.9474, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 50: 436.8193, Accuracy: 0.5797\n",
      "Training loss (for one batch) at step 60: 442.6865, Accuracy: 0.5794\n",
      "Training loss (for one batch) at step 70: 440.7107, Accuracy: 0.5800\n",
      "Training loss (for one batch) at step 80: 441.6591, Accuracy: 0.5792\n",
      "Training loss (for one batch) at step 90: 440.3825, Accuracy: 0.5809\n",
      "Training loss (for one batch) at step 100: 444.1008, Accuracy: 0.5810\n",
      "Training loss (for one batch) at step 110: 440.3467, Accuracy: 0.5825\n",
      "---- Training ----\n",
      "Training loss: 137.8041\n",
      "Training acc over epoch: 0.5815\n",
      "---- Validation ----\n",
      "Validation loss: 34.3010\n",
      "Validation acc: 0.6016\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 440.1306, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 438.9932, Accuracy: 0.6001\n",
      "Training loss (for one batch) at step 20: 436.6930, Accuracy: 0.5982\n",
      "Training loss (for one batch) at step 30: 436.3112, Accuracy: 0.5910\n",
      "Training loss (for one batch) at step 40: 438.8208, Accuracy: 0.5886\n",
      "Training loss (for one batch) at step 50: 442.9925, Accuracy: 0.5879\n",
      "Training loss (for one batch) at step 60: 440.9814, Accuracy: 0.5879\n",
      "Training loss (for one batch) at step 70: 440.3633, Accuracy: 0.5888\n",
      "Training loss (for one batch) at step 80: 442.5631, Accuracy: 0.5863\n",
      "Training loss (for one batch) at step 90: 441.4218, Accuracy: 0.5865\n",
      "Training loss (for one batch) at step 100: 439.3968, Accuracy: 0.5882\n",
      "Training loss (for one batch) at step 110: 440.0610, Accuracy: 0.5903\n",
      "---- Training ----\n",
      "Training loss: 137.4149\n",
      "Training acc over epoch: 0.5926\n",
      "---- Validation ----\n",
      "Validation loss: 35.4425\n",
      "Validation acc: 0.6064\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 446.5274, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 438.7880, Accuracy: 0.6165\n",
      "Training loss (for one batch) at step 20: 439.0891, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 30: 431.4164, Accuracy: 0.6142\n",
      "Training loss (for one batch) at step 40: 434.9608, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 50: 433.7104, Accuracy: 0.6121\n",
      "Training loss (for one batch) at step 60: 431.5987, Accuracy: 0.6117\n",
      "Training loss (for one batch) at step 70: 441.9779, Accuracy: 0.6127\n",
      "Training loss (for one batch) at step 80: 440.7983, Accuracy: 0.6101\n",
      "Training loss (for one batch) at step 90: 440.7614, Accuracy: 0.6084\n",
      "Training loss (for one batch) at step 100: 437.6643, Accuracy: 0.6115\n",
      "Training loss (for one batch) at step 110: 436.6116, Accuracy: 0.6118\n",
      "---- Training ----\n",
      "Training loss: 135.7408\n",
      "Training acc over epoch: 0.6118\n",
      "---- Validation ----\n",
      "Validation loss: 34.8324\n",
      "Validation acc: 0.6316\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 439.0487, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 443.2263, Accuracy: 0.6080\n",
      "Training loss (for one batch) at step 20: 440.4565, Accuracy: 0.6146\n",
      "Training loss (for one batch) at step 30: 433.2106, Accuracy: 0.6142\n",
      "Training loss (for one batch) at step 40: 433.1408, Accuracy: 0.6130\n",
      "Training loss (for one batch) at step 50: 439.9532, Accuracy: 0.6131\n",
      "Training loss (for one batch) at step 60: 440.5276, Accuracy: 0.6196\n",
      "Training loss (for one batch) at step 70: 444.2659, Accuracy: 0.6188\n",
      "Training loss (for one batch) at step 80: 445.5845, Accuracy: 0.6189\n",
      "Training loss (for one batch) at step 90: 439.6486, Accuracy: 0.6177\n",
      "Training loss (for one batch) at step 100: 440.8579, Accuracy: 0.6182\n",
      "Training loss (for one batch) at step 110: 427.4803, Accuracy: 0.6189\n",
      "---- Training ----\n",
      "Training loss: 136.5180\n",
      "Training acc over epoch: 0.6191\n",
      "---- Validation ----\n",
      "Validation loss: 34.8168\n",
      "Validation acc: 0.6531\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 439.3366, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 436.3490, Accuracy: 0.6371\n",
      "Training loss (for one batch) at step 20: 435.5950, Accuracy: 0.6168\n",
      "Training loss (for one batch) at step 30: 430.0340, Accuracy: 0.6159\n",
      "Training loss (for one batch) at step 40: 429.5092, Accuracy: 0.6214\n",
      "Training loss (for one batch) at step 50: 433.8446, Accuracy: 0.6281\n",
      "Training loss (for one batch) at step 60: 444.1678, Accuracy: 0.6295\n",
      "Training loss (for one batch) at step 70: 433.7862, Accuracy: 0.6329\n",
      "Training loss (for one batch) at step 80: 432.7751, Accuracy: 0.6311\n",
      "Training loss (for one batch) at step 90: 437.1247, Accuracy: 0.6286\n",
      "Training loss (for one batch) at step 100: 435.1396, Accuracy: 0.6293\n",
      "Training loss (for one batch) at step 110: 434.2439, Accuracy: 0.6303\n",
      "---- Training ----\n",
      "Training loss: 136.0728\n",
      "Training acc over epoch: 0.6308\n",
      "---- Validation ----\n",
      "Validation loss: 35.5214\n",
      "Validation acc: 0.6666\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 443.0856, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 439.4245, Accuracy: 0.6413\n",
      "Training loss (for one batch) at step 20: 437.6946, Accuracy: 0.6261\n",
      "Training loss (for one batch) at step 30: 430.9002, Accuracy: 0.6353\n",
      "Training loss (for one batch) at step 40: 433.7965, Accuracy: 0.6408\n",
      "Training loss (for one batch) at step 50: 436.3149, Accuracy: 0.6399\n",
      "Training loss (for one batch) at step 60: 428.5609, Accuracy: 0.6443\n",
      "Training loss (for one batch) at step 70: 434.6648, Accuracy: 0.6433\n",
      "Training loss (for one batch) at step 80: 439.3493, Accuracy: 0.6423\n",
      "Training loss (for one batch) at step 90: 434.2170, Accuracy: 0.6429\n",
      "Training loss (for one batch) at step 100: 434.5348, Accuracy: 0.6434\n",
      "Training loss (for one batch) at step 110: 438.9180, Accuracy: 0.6444\n",
      "---- Training ----\n",
      "Training loss: 136.1200\n",
      "Training acc over epoch: 0.6460\n",
      "---- Validation ----\n",
      "Validation loss: 33.6750\n",
      "Validation acc: 0.6566\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 442.0044, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 434.5184, Accuracy: 0.6428\n",
      "Training loss (for one batch) at step 20: 437.3320, Accuracy: 0.6283\n",
      "Training loss (for one batch) at step 30: 430.7370, Accuracy: 0.6384\n",
      "Training loss (for one batch) at step 40: 423.1049, Accuracy: 0.6427\n",
      "Training loss (for one batch) at step 50: 429.0786, Accuracy: 0.6497\n",
      "Training loss (for one batch) at step 60: 430.9201, Accuracy: 0.6510\n",
      "Training loss (for one batch) at step 70: 441.7111, Accuracy: 0.6540\n",
      "Training loss (for one batch) at step 80: 435.4782, Accuracy: 0.6486\n",
      "Training loss (for one batch) at step 90: 436.2426, Accuracy: 0.6501\n",
      "Training loss (for one batch) at step 100: 427.2455, Accuracy: 0.6535\n",
      "Training loss (for one batch) at step 110: 435.0746, Accuracy: 0.6557\n",
      "---- Training ----\n",
      "Training loss: 141.8717\n",
      "Training acc over epoch: 0.6566\n",
      "---- Validation ----\n",
      "Validation loss: 35.2390\n",
      "Validation acc: 0.6808\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 447.0543, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 436.8400, Accuracy: 0.6619\n",
      "Training loss (for one batch) at step 20: 437.8681, Accuracy: 0.6514\n",
      "Training loss (for one batch) at step 30: 434.1193, Accuracy: 0.6522\n",
      "Training loss (for one batch) at step 40: 423.2111, Accuracy: 0.6606\n",
      "Training loss (for one batch) at step 50: 424.9653, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 60: 419.3524, Accuracy: 0.6670\n",
      "Training loss (for one batch) at step 70: 449.4597, Accuracy: 0.6651\n",
      "Training loss (for one batch) at step 80: 439.9325, Accuracy: 0.6605\n",
      "Training loss (for one batch) at step 90: 429.4294, Accuracy: 0.6609\n",
      "Training loss (for one batch) at step 100: 423.2276, Accuracy: 0.6627\n",
      "Training loss (for one batch) at step 110: 433.7070, Accuracy: 0.6632\n",
      "---- Training ----\n",
      "Training loss: 132.8964\n",
      "Training acc over epoch: 0.6625\n",
      "---- Validation ----\n",
      "Validation loss: 32.6367\n",
      "Validation acc: 0.6325\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 437.6270, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 437.7117, Accuracy: 0.6364\n",
      "Training loss (for one batch) at step 20: 433.3369, Accuracy: 0.6455\n",
      "Training loss (for one batch) at step 30: 422.6521, Accuracy: 0.6615\n",
      "Training loss (for one batch) at step 40: 420.2173, Accuracy: 0.6656\n",
      "Training loss (for one batch) at step 50: 423.6220, Accuracy: 0.6693\n",
      "Training loss (for one batch) at step 60: 428.4112, Accuracy: 0.6762\n",
      "Training loss (for one batch) at step 70: 424.6884, Accuracy: 0.6817\n",
      "Training loss (for one batch) at step 80: 443.2191, Accuracy: 0.6808\n",
      "Training loss (for one batch) at step 90: 435.7354, Accuracy: 0.6811\n",
      "Training loss (for one batch) at step 100: 421.4795, Accuracy: 0.6808\n",
      "Training loss (for one batch) at step 110: 434.7250, Accuracy: 0.6806\n",
      "---- Training ----\n",
      "Training loss: 135.8349\n",
      "Training acc over epoch: 0.6799\n",
      "---- Validation ----\n",
      "Validation loss: 36.1156\n",
      "Validation acc: 0.6693\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 441.1326, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 442.3770, Accuracy: 0.6790\n",
      "Training loss (for one batch) at step 20: 430.2393, Accuracy: 0.6667\n",
      "Training loss (for one batch) at step 30: 416.7044, Accuracy: 0.6731\n",
      "Training loss (for one batch) at step 40: 410.3894, Accuracy: 0.6843\n",
      "Training loss (for one batch) at step 50: 414.0672, Accuracy: 0.6932\n",
      "Training loss (for one batch) at step 60: 442.1862, Accuracy: 0.6938\n",
      "Training loss (for one batch) at step 70: 420.6671, Accuracy: 0.6941\n",
      "Training loss (for one batch) at step 80: 430.6169, Accuracy: 0.6935\n",
      "Training loss (for one batch) at step 90: 428.8151, Accuracy: 0.6907\n",
      "Training loss (for one batch) at step 100: 422.7546, Accuracy: 0.6912\n",
      "Training loss (for one batch) at step 110: 428.3918, Accuracy: 0.6924\n",
      "---- Training ----\n",
      "Training loss: 133.5124\n",
      "Training acc over epoch: 0.6930\n",
      "---- Validation ----\n",
      "Validation loss: 37.8452\n",
      "Validation acc: 0.6795\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 437.1793, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 429.7481, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 432.4940, Accuracy: 0.6741\n",
      "Training loss (for one batch) at step 30: 423.9353, Accuracy: 0.6860\n",
      "Training loss (for one batch) at step 40: 425.7156, Accuracy: 0.6913\n",
      "Training loss (for one batch) at step 50: 412.2305, Accuracy: 0.6961\n",
      "Training loss (for one batch) at step 60: 424.4094, Accuracy: 0.6990\n",
      "Training loss (for one batch) at step 70: 433.7583, Accuracy: 0.7005\n",
      "Training loss (for one batch) at step 80: 433.3685, Accuracy: 0.6980\n",
      "Training loss (for one batch) at step 90: 432.7491, Accuracy: 0.6969\n",
      "Training loss (for one batch) at step 100: 418.8774, Accuracy: 0.6969\n",
      "Training loss (for one batch) at step 110: 421.2950, Accuracy: 0.6959\n",
      "---- Training ----\n",
      "Training loss: 133.0613\n",
      "Training acc over epoch: 0.6959\n",
      "---- Validation ----\n",
      "Validation loss: 35.6833\n",
      "Validation acc: 0.6771\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 446.2124, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 10: 426.0681, Accuracy: 0.6939\n",
      "Training loss (for one batch) at step 20: 424.0977, Accuracy: 0.6838\n",
      "Training loss (for one batch) at step 30: 423.2084, Accuracy: 0.6865\n",
      "Training loss (for one batch) at step 40: 418.8453, Accuracy: 0.6925\n",
      "Training loss (for one batch) at step 50: 403.9606, Accuracy: 0.6961\n",
      "Training loss (for one batch) at step 60: 422.7369, Accuracy: 0.6992\n",
      "Training loss (for one batch) at step 70: 437.0938, Accuracy: 0.6948\n",
      "Training loss (for one batch) at step 80: 426.0717, Accuracy: 0.6904\n",
      "Training loss (for one batch) at step 90: 421.1690, Accuracy: 0.6892\n",
      "Training loss (for one batch) at step 100: 425.4568, Accuracy: 0.6887\n",
      "Training loss (for one batch) at step 110: 419.2735, Accuracy: 0.6914\n",
      "---- Training ----\n",
      "Training loss: 137.1857\n",
      "Training acc over epoch: 0.6933\n",
      "---- Validation ----\n",
      "Validation loss: 33.8095\n",
      "Validation acc: 0.6854\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 442.8587, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 432.3770, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 20: 425.8952, Accuracy: 0.6741\n",
      "Training loss (for one batch) at step 30: 423.0603, Accuracy: 0.6958\n",
      "Training loss (for one batch) at step 40: 402.4109, Accuracy: 0.7048\n",
      "Training loss (for one batch) at step 50: 407.0832, Accuracy: 0.7074\n",
      "Training loss (for one batch) at step 60: 418.5158, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 70: 422.3060, Accuracy: 0.7101\n",
      "Training loss (for one batch) at step 80: 422.3913, Accuracy: 0.7075\n",
      "Training loss (for one batch) at step 90: 430.0075, Accuracy: 0.7048\n",
      "Training loss (for one batch) at step 100: 413.9453, Accuracy: 0.7044\n",
      "Training loss (for one batch) at step 110: 416.3242, Accuracy: 0.7024\n",
      "---- Training ----\n",
      "Training loss: 132.9890\n",
      "Training acc over epoch: 0.7022\n",
      "---- Validation ----\n",
      "Validation loss: 35.4086\n",
      "Validation acc: 0.6956\n",
      "Time taken: 10.83s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 435.4853, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 421.8983, Accuracy: 0.7202\n",
      "Training loss (for one batch) at step 20: 424.8134, Accuracy: 0.7020\n",
      "Training loss (for one batch) at step 30: 407.6627, Accuracy: 0.7124\n",
      "Training loss (for one batch) at step 40: 400.7167, Accuracy: 0.7189\n",
      "Training loss (for one batch) at step 50: 407.1758, Accuracy: 0.7235\n",
      "Training loss (for one batch) at step 60: 414.8336, Accuracy: 0.7264\n",
      "Training loss (for one batch) at step 70: 419.1201, Accuracy: 0.7229\n",
      "Training loss (for one batch) at step 80: 433.9528, Accuracy: 0.7175\n",
      "Training loss (for one batch) at step 90: 415.3778, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 100: 402.7761, Accuracy: 0.7141\n",
      "Training loss (for one batch) at step 110: 420.4112, Accuracy: 0.7135\n",
      "---- Training ----\n",
      "Training loss: 138.2116\n",
      "Training acc over epoch: 0.7143\n",
      "---- Validation ----\n",
      "Validation loss: 36.4560\n",
      "Validation acc: 0.6854\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 424.3103, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 424.2206, Accuracy: 0.6925\n",
      "Training loss (for one batch) at step 20: 419.3980, Accuracy: 0.6935\n",
      "Training loss (for one batch) at step 30: 420.8559, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 40: 412.2183, Accuracy: 0.7020\n",
      "Training loss (for one batch) at step 50: 410.5548, Accuracy: 0.7119\n",
      "Training loss (for one batch) at step 60: 418.7754, Accuracy: 0.7161\n",
      "Training loss (for one batch) at step 70: 416.7359, Accuracy: 0.7151\n",
      "Training loss (for one batch) at step 80: 427.4084, Accuracy: 0.7132\n",
      "Training loss (for one batch) at step 90: 407.9208, Accuracy: 0.7118\n",
      "Training loss (for one batch) at step 100: 406.3466, Accuracy: 0.7129\n",
      "Training loss (for one batch) at step 110: 422.3444, Accuracy: 0.7149\n",
      "---- Training ----\n",
      "Training loss: 132.4889\n",
      "Training acc over epoch: 0.7147\n",
      "---- Validation ----\n",
      "Validation loss: 32.8395\n",
      "Validation acc: 0.7066\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 428.3576, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 425.0938, Accuracy: 0.6932\n",
      "Training loss (for one batch) at step 20: 420.7485, Accuracy: 0.6957\n",
      "Training loss (for one batch) at step 30: 405.0145, Accuracy: 0.7087\n",
      "Training loss (for one batch) at step 40: 405.4575, Accuracy: 0.7127\n",
      "Training loss (for one batch) at step 50: 407.8995, Accuracy: 0.7226\n",
      "Training loss (for one batch) at step 60: 426.9819, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 70: 423.7676, Accuracy: 0.7248\n",
      "Training loss (for one batch) at step 80: 426.4142, Accuracy: 0.7189\n",
      "Training loss (for one batch) at step 90: 420.8011, Accuracy: 0.7130\n",
      "Training loss (for one batch) at step 100: 422.2121, Accuracy: 0.7128\n",
      "Training loss (for one batch) at step 110: 420.4586, Accuracy: 0.7136\n",
      "---- Training ----\n",
      "Training loss: 125.2847\n",
      "Training acc over epoch: 0.7137\n",
      "---- Validation ----\n",
      "Validation loss: 47.0856\n",
      "Validation acc: 0.7246\n",
      "Time taken: 10.64s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 429.5732, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 431.3424, Accuracy: 0.6903\n",
      "Training loss (for one batch) at step 20: 411.9433, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 402.2415, Accuracy: 0.7130\n",
      "Training loss (for one batch) at step 40: 394.5376, Accuracy: 0.7180\n",
      "Training loss (for one batch) at step 50: 385.9709, Accuracy: 0.7302\n",
      "Training loss (for one batch) at step 60: 403.0892, Accuracy: 0.7325\n",
      "Training loss (for one batch) at step 70: 417.5828, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 80: 425.0913, Accuracy: 0.7228\n",
      "Training loss (for one batch) at step 90: 411.2596, Accuracy: 0.7189\n",
      "Training loss (for one batch) at step 100: 401.3198, Accuracy: 0.7171\n",
      "Training loss (for one batch) at step 110: 400.9983, Accuracy: 0.7181\n",
      "---- Training ----\n",
      "Training loss: 133.5935\n",
      "Training acc over epoch: 0.7185\n",
      "---- Validation ----\n",
      "Validation loss: 40.1433\n",
      "Validation acc: 0.6886\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 421.0210, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 431.3824, Accuracy: 0.6882\n",
      "Training loss (for one batch) at step 20: 413.6587, Accuracy: 0.6942\n",
      "Training loss (for one batch) at step 30: 406.9916, Accuracy: 0.7056\n",
      "Training loss (for one batch) at step 40: 383.9180, Accuracy: 0.7220\n",
      "Training loss (for one batch) at step 50: 385.6403, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 60: 391.2200, Accuracy: 0.7340\n",
      "Training loss (for one batch) at step 70: 415.4403, Accuracy: 0.7314\n",
      "Training loss (for one batch) at step 80: 410.8520, Accuracy: 0.7255\n",
      "Training loss (for one batch) at step 90: 412.0631, Accuracy: 0.7240\n",
      "Training loss (for one batch) at step 100: 404.5632, Accuracy: 0.7234\n",
      "Training loss (for one batch) at step 110: 408.7222, Accuracy: 0.7245\n",
      "---- Training ----\n",
      "Training loss: 134.4113\n",
      "Training acc over epoch: 0.7249\n",
      "---- Validation ----\n",
      "Validation loss: 33.9572\n",
      "Validation acc: 0.7090\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 427.1868, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 10: 424.5944, Accuracy: 0.7145\n",
      "Training loss (for one batch) at step 20: 401.8100, Accuracy: 0.7161\n",
      "Training loss (for one batch) at step 30: 407.1079, Accuracy: 0.7213\n",
      "Training loss (for one batch) at step 40: 384.4966, Accuracy: 0.7275\n",
      "Training loss (for one batch) at step 50: 375.6977, Accuracy: 0.7391\n",
      "Training loss (for one batch) at step 60: 403.4431, Accuracy: 0.7494\n",
      "Training loss (for one batch) at step 70: 411.8170, Accuracy: 0.7415\n",
      "Training loss (for one batch) at step 80: 423.0928, Accuracy: 0.7323\n",
      "Training loss (for one batch) at step 90: 395.9545, Accuracy: 0.7281\n",
      "Training loss (for one batch) at step 100: 396.1668, Accuracy: 0.7278\n",
      "Training loss (for one batch) at step 110: 418.0536, Accuracy: 0.7266\n",
      "---- Training ----\n",
      "Training loss: 122.0818\n",
      "Training acc over epoch: 0.7274\n",
      "---- Validation ----\n",
      "Validation loss: 34.9898\n",
      "Validation acc: 0.6996\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 419.3924, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 420.4846, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 20: 403.1634, Accuracy: 0.6975\n",
      "Training loss (for one batch) at step 30: 391.4932, Accuracy: 0.7097\n",
      "Training loss (for one batch) at step 40: 385.2703, Accuracy: 0.7144\n",
      "Training loss (for one batch) at step 50: 375.3695, Accuracy: 0.7226\n",
      "Training loss (for one batch) at step 60: 385.9893, Accuracy: 0.7291\n",
      "Training loss (for one batch) at step 70: 406.3183, Accuracy: 0.7252\n",
      "Training loss (for one batch) at step 80: 416.0116, Accuracy: 0.7214\n",
      "Training loss (for one batch) at step 90: 400.8394, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 100: 381.5860, Accuracy: 0.7221\n",
      "Training loss (for one batch) at step 110: 387.8213, Accuracy: 0.7226\n",
      "---- Training ----\n",
      "Training loss: 132.4114\n",
      "Training acc over epoch: 0.7222\n",
      "---- Validation ----\n",
      "Validation loss: 41.3884\n",
      "Validation acc: 0.7082\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 422.0257, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 419.8384, Accuracy: 0.6982\n",
      "Training loss (for one batch) at step 20: 409.0808, Accuracy: 0.7042\n",
      "Training loss (for one batch) at step 30: 390.9956, Accuracy: 0.7180\n",
      "Training loss (for one batch) at step 40: 376.1777, Accuracy: 0.7268\n",
      "Training loss (for one batch) at step 50: 390.1200, Accuracy: 0.7331\n",
      "Training loss (for one batch) at step 60: 386.0744, Accuracy: 0.7378\n",
      "Training loss (for one batch) at step 70: 430.9047, Accuracy: 0.7323\n",
      "Training loss (for one batch) at step 80: 409.4908, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 90: 393.3802, Accuracy: 0.7255\n",
      "Training loss (for one batch) at step 100: 385.1908, Accuracy: 0.7250\n",
      "Training loss (for one batch) at step 110: 416.9455, Accuracy: 0.7257\n",
      "---- Training ----\n",
      "Training loss: 125.3315\n",
      "Training acc over epoch: 0.7251\n",
      "---- Validation ----\n",
      "Validation loss: 41.8923\n",
      "Validation acc: 0.7214\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 420.9021, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 408.2828, Accuracy: 0.7088\n",
      "Training loss (for one batch) at step 20: 387.9750, Accuracy: 0.7135\n",
      "Training loss (for one batch) at step 30: 379.5648, Accuracy: 0.7185\n",
      "Training loss (for one batch) at step 40: 375.5070, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 50: 365.4666, Accuracy: 0.7402\n",
      "Training loss (for one batch) at step 60: 377.9424, Accuracy: 0.7451\n",
      "Training loss (for one batch) at step 70: 401.7011, Accuracy: 0.7391\n",
      "Training loss (for one batch) at step 80: 405.8672, Accuracy: 0.7301\n",
      "Training loss (for one batch) at step 90: 384.3768, Accuracy: 0.7276\n",
      "Training loss (for one batch) at step 100: 376.0575, Accuracy: 0.7257\n",
      "Training loss (for one batch) at step 110: 385.9079, Accuracy: 0.7250\n",
      "---- Training ----\n",
      "Training loss: 124.7702\n",
      "Training acc over epoch: 0.7248\n",
      "---- Validation ----\n",
      "Validation loss: 40.3741\n",
      "Validation acc: 0.6985\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 419.1625, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 394.6119, Accuracy: 0.7166\n",
      "Training loss (for one batch) at step 20: 381.3466, Accuracy: 0.7128\n",
      "Training loss (for one batch) at step 30: 380.7264, Accuracy: 0.7248\n",
      "Training loss (for one batch) at step 40: 353.9814, Accuracy: 0.7355\n",
      "Training loss (for one batch) at step 50: 367.2895, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 60: 387.6311, Accuracy: 0.7467\n",
      "Training loss (for one batch) at step 70: 393.4734, Accuracy: 0.7420\n",
      "Training loss (for one batch) at step 80: 421.7736, Accuracy: 0.7340\n",
      "Training loss (for one batch) at step 90: 376.6770, Accuracy: 0.7320\n",
      "Training loss (for one batch) at step 100: 355.1019, Accuracy: 0.7330\n",
      "Training loss (for one batch) at step 110: 379.4321, Accuracy: 0.7340\n",
      "---- Training ----\n",
      "Training loss: 116.5697\n",
      "Training acc over epoch: 0.7333\n",
      "---- Validation ----\n",
      "Validation loss: 33.2685\n",
      "Validation acc: 0.6878\n",
      "Time taken: 10.29s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 401.5458, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 407.6732, Accuracy: 0.6960\n",
      "Training loss (for one batch) at step 20: 395.4162, Accuracy: 0.6979\n",
      "Training loss (for one batch) at step 30: 372.9135, Accuracy: 0.7155\n",
      "Training loss (for one batch) at step 40: 378.8061, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 50: 379.4542, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 60: 354.0638, Accuracy: 0.7415\n",
      "Training loss (for one batch) at step 70: 416.4353, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 80: 388.2984, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 90: 361.0531, Accuracy: 0.7281\n",
      "Training loss (for one batch) at step 100: 380.1152, Accuracy: 0.7283\n",
      "Training loss (for one batch) at step 110: 383.3131, Accuracy: 0.7294\n",
      "---- Training ----\n",
      "Training loss: 127.7313\n",
      "Training acc over epoch: 0.7290\n",
      "---- Validation ----\n",
      "Validation loss: 34.4001\n",
      "Validation acc: 0.6932\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 400.7916, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 402.3224, Accuracy: 0.7017\n",
      "Training loss (for one batch) at step 20: 390.9956, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 30: 360.9295, Accuracy: 0.7228\n",
      "Training loss (for one batch) at step 40: 367.2871, Accuracy: 0.7338\n",
      "Training loss (for one batch) at step 50: 354.8819, Accuracy: 0.7413\n",
      "Training loss (for one batch) at step 60: 361.7924, Accuracy: 0.7447\n",
      "Training loss (for one batch) at step 70: 391.8003, Accuracy: 0.7358\n",
      "Training loss (for one batch) at step 80: 382.5017, Accuracy: 0.7318\n",
      "Training loss (for one batch) at step 90: 375.2873, Accuracy: 0.7312\n",
      "Training loss (for one batch) at step 100: 371.1303, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 110: 387.4041, Accuracy: 0.7312\n",
      "---- Training ----\n",
      "Training loss: 130.8015\n",
      "Training acc over epoch: 0.7307\n",
      "---- Validation ----\n",
      "Validation loss: 46.7035\n",
      "Validation acc: 0.6964\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 411.0499, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 398.1819, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 20: 371.4851, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 369.9351, Accuracy: 0.7054\n",
      "Training loss (for one batch) at step 40: 363.9909, Accuracy: 0.7235\n",
      "Training loss (for one batch) at step 50: 339.5287, Accuracy: 0.7364\n",
      "Training loss (for one batch) at step 60: 374.9334, Accuracy: 0.7419\n",
      "Training loss (for one batch) at step 70: 375.1111, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 80: 377.3621, Accuracy: 0.7272\n",
      "Training loss (for one batch) at step 90: 387.7978, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 100: 353.0985, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 110: 385.7313, Accuracy: 0.7271\n",
      "---- Training ----\n",
      "Training loss: 128.7814\n",
      "Training acc over epoch: 0.7263\n",
      "---- Validation ----\n",
      "Validation loss: 33.4343\n",
      "Validation acc: 0.6921\n",
      "Time taken: 10.30s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 386.3655, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 388.4032, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 20: 367.0260, Accuracy: 0.7042\n",
      "Training loss (for one batch) at step 30: 358.2522, Accuracy: 0.7130\n",
      "Training loss (for one batch) at step 40: 360.5967, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 50: 351.0482, Accuracy: 0.7373\n",
      "Training loss (for one batch) at step 60: 373.6285, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 70: 367.4026, Accuracy: 0.7351\n",
      "Training loss (for one batch) at step 80: 401.3683, Accuracy: 0.7270\n",
      "Training loss (for one batch) at step 90: 349.5574, Accuracy: 0.7237\n",
      "Training loss (for one batch) at step 100: 360.0167, Accuracy: 0.7254\n",
      "Training loss (for one batch) at step 110: 381.3568, Accuracy: 0.7259\n",
      "---- Training ----\n",
      "Training loss: 115.7621\n",
      "Training acc over epoch: 0.7260\n",
      "---- Validation ----\n",
      "Validation loss: 40.2578\n",
      "Validation acc: 0.6948\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 419.3618, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 381.4985, Accuracy: 0.7053\n",
      "Training loss (for one batch) at step 20: 358.8696, Accuracy: 0.7150\n",
      "Training loss (for one batch) at step 30: 373.7746, Accuracy: 0.7296\n",
      "Training loss (for one batch) at step 40: 358.5102, Accuracy: 0.7412\n",
      "Training loss (for one batch) at step 50: 350.6440, Accuracy: 0.7480\n",
      "Training loss (for one batch) at step 60: 347.2482, Accuracy: 0.7517\n",
      "Training loss (for one batch) at step 70: 374.9517, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 80: 375.7279, Accuracy: 0.7359\n",
      "Training loss (for one batch) at step 90: 381.3288, Accuracy: 0.7313\n",
      "Training loss (for one batch) at step 100: 366.5789, Accuracy: 0.7342\n",
      "Training loss (for one batch) at step 110: 370.7784, Accuracy: 0.7335\n",
      "---- Training ----\n",
      "Training loss: 106.7919\n",
      "Training acc over epoch: 0.7335\n",
      "---- Validation ----\n",
      "Validation loss: 40.5500\n",
      "Validation acc: 0.7096\n",
      "Time taken: 10.62s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 385.7979, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 386.3006, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 20: 357.6857, Accuracy: 0.7001\n",
      "Training loss (for one batch) at step 30: 356.3875, Accuracy: 0.7193\n",
      "Training loss (for one batch) at step 40: 346.0555, Accuracy: 0.7346\n",
      "Training loss (for one batch) at step 50: 342.2171, Accuracy: 0.7454\n",
      "Training loss (for one batch) at step 60: 353.7023, Accuracy: 0.7483\n",
      "Training loss (for one batch) at step 70: 376.0154, Accuracy: 0.7380\n",
      "Training loss (for one batch) at step 80: 386.3091, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 90: 355.7589, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 100: 351.9088, Accuracy: 0.7314\n",
      "Training loss (for one batch) at step 110: 375.4313, Accuracy: 0.7342\n",
      "---- Training ----\n",
      "Training loss: 121.3806\n",
      "Training acc over epoch: 0.7333\n",
      "---- Validation ----\n",
      "Validation loss: 36.8009\n",
      "Validation acc: 0.6951\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 379.0266, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 410.3781, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 20: 340.5419, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 30: 328.3616, Accuracy: 0.7175\n",
      "Training loss (for one batch) at step 40: 337.9142, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 50: 336.4741, Accuracy: 0.7454\n",
      "Training loss (for one batch) at step 60: 355.5696, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 70: 369.6463, Accuracy: 0.7389\n",
      "Training loss (for one batch) at step 80: 366.4468, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 90: 361.7394, Accuracy: 0.7280\n",
      "Training loss (for one batch) at step 100: 351.2902, Accuracy: 0.7308\n",
      "Training loss (for one batch) at step 110: 371.6459, Accuracy: 0.7298\n",
      "---- Training ----\n",
      "Training loss: 116.1690\n",
      "Training acc over epoch: 0.7285\n",
      "---- Validation ----\n",
      "Validation loss: 37.3714\n",
      "Validation acc: 0.7042\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 379.1043, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 391.7887, Accuracy: 0.6861\n",
      "Training loss (for one batch) at step 20: 363.5541, Accuracy: 0.7035\n",
      "Training loss (for one batch) at step 30: 327.8112, Accuracy: 0.7213\n",
      "Training loss (for one batch) at step 40: 346.1447, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 50: 336.5962, Accuracy: 0.7410\n",
      "Training loss (for one batch) at step 60: 348.3872, Accuracy: 0.7501\n",
      "Training loss (for one batch) at step 70: 358.2607, Accuracy: 0.7419\n",
      "Training loss (for one batch) at step 80: 370.3971, Accuracy: 0.7332\n",
      "Training loss (for one batch) at step 90: 348.4252, Accuracy: 0.7321\n",
      "Training loss (for one batch) at step 100: 341.3801, Accuracy: 0.7359\n",
      "Training loss (for one batch) at step 110: 377.8812, Accuracy: 0.7352\n",
      "---- Training ----\n",
      "Training loss: 125.6423\n",
      "Training acc over epoch: 0.7355\n",
      "---- Validation ----\n",
      "Validation loss: 36.9080\n",
      "Validation acc: 0.6945\n",
      "Time taken: 10.97s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 381.7385, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 399.5465, Accuracy: 0.7003\n",
      "Training loss (for one batch) at step 20: 343.8409, Accuracy: 0.7132\n",
      "Training loss (for one batch) at step 30: 332.6110, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 40: 351.1825, Accuracy: 0.7349\n",
      "Training loss (for one batch) at step 50: 342.7241, Accuracy: 0.7408\n",
      "Training loss (for one batch) at step 60: 338.5867, Accuracy: 0.7494\n",
      "Training loss (for one batch) at step 70: 363.1355, Accuracy: 0.7415\n",
      "Training loss (for one batch) at step 80: 368.6409, Accuracy: 0.7326\n",
      "Training loss (for one batch) at step 90: 336.3932, Accuracy: 0.7282\n",
      "Training loss (for one batch) at step 100: 344.9711, Accuracy: 0.7299\n",
      "Training loss (for one batch) at step 110: 357.4253, Accuracy: 0.7299\n",
      "---- Training ----\n",
      "Training loss: 104.3257\n",
      "Training acc over epoch: 0.7292\n",
      "---- Validation ----\n",
      "Validation loss: 39.3402\n",
      "Validation acc: 0.6814\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 364.9086, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 374.0705, Accuracy: 0.6577\n",
      "Training loss (for one batch) at step 20: 348.0116, Accuracy: 0.6793\n",
      "Training loss (for one batch) at step 30: 326.6353, Accuracy: 0.7039\n",
      "Training loss (for one batch) at step 40: 333.5533, Accuracy: 0.7144\n",
      "Training loss (for one batch) at step 50: 317.7155, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 60: 330.7494, Accuracy: 0.7335\n",
      "Training loss (for one batch) at step 70: 339.8277, Accuracy: 0.7271\n",
      "Training loss (for one batch) at step 80: 396.5274, Accuracy: 0.7203\n",
      "Training loss (for one batch) at step 90: 348.5242, Accuracy: 0.7189\n",
      "Training loss (for one batch) at step 100: 330.7863, Accuracy: 0.7218\n",
      "Training loss (for one batch) at step 110: 338.2184, Accuracy: 0.7243\n",
      "---- Training ----\n",
      "Training loss: 106.3939\n",
      "Training acc over epoch: 0.7243\n",
      "---- Validation ----\n",
      "Validation loss: 43.2520\n",
      "Validation acc: 0.6867\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 373.6649, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 10: 380.6546, Accuracy: 0.6683\n",
      "Training loss (for one batch) at step 20: 345.3019, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 319.6421, Accuracy: 0.7142\n",
      "Training loss (for one batch) at step 40: 323.9427, Accuracy: 0.7306\n",
      "Training loss (for one batch) at step 50: 331.4926, Accuracy: 0.7407\n",
      "Training loss (for one batch) at step 60: 331.0065, Accuracy: 0.7467\n",
      "Training loss (for one batch) at step 70: 363.5075, Accuracy: 0.7367\n",
      "Training loss (for one batch) at step 80: 365.3852, Accuracy: 0.7278\n",
      "Training loss (for one batch) at step 90: 343.7530, Accuracy: 0.7253\n",
      "Training loss (for one batch) at step 100: 349.6702, Accuracy: 0.7262\n",
      "Training loss (for one batch) at step 110: 350.3770, Accuracy: 0.7275\n",
      "---- Training ----\n",
      "Training loss: 127.5040\n",
      "Training acc over epoch: 0.7271\n",
      "---- Validation ----\n",
      "Validation loss: 33.3103\n",
      "Validation acc: 0.6889\n",
      "Time taken: 10.69s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 371.0974, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 369.3679, Accuracy: 0.6697\n",
      "Training loss (for one batch) at step 20: 345.4229, Accuracy: 0.6972\n",
      "Training loss (for one batch) at step 30: 343.1595, Accuracy: 0.7172\n",
      "Training loss (for one batch) at step 40: 333.6194, Accuracy: 0.7327\n",
      "Training loss (for one batch) at step 50: 320.4647, Accuracy: 0.7405\n",
      "Training loss (for one batch) at step 60: 353.0534, Accuracy: 0.7423\n",
      "Training loss (for one batch) at step 70: 346.5151, Accuracy: 0.7370\n",
      "Training loss (for one batch) at step 80: 379.6320, Accuracy: 0.7293\n",
      "Training loss (for one batch) at step 90: 334.0325, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 100: 325.6460, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 110: 356.3325, Accuracy: 0.7298\n",
      "---- Training ----\n",
      "Training loss: 111.8535\n",
      "Training acc over epoch: 0.7290\n",
      "---- Validation ----\n",
      "Validation loss: 43.1440\n",
      "Validation acc: 0.6883\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 395.0939, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 373.4824, Accuracy: 0.6662\n",
      "Training loss (for one batch) at step 20: 340.4014, Accuracy: 0.6942\n",
      "Training loss (for one batch) at step 30: 318.9005, Accuracy: 0.7175\n",
      "Training loss (for one batch) at step 40: 314.5474, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 50: 320.4860, Accuracy: 0.7420\n",
      "Training loss (for one batch) at step 60: 339.5728, Accuracy: 0.7435\n",
      "Training loss (for one batch) at step 70: 353.5726, Accuracy: 0.7355\n",
      "Training loss (for one batch) at step 80: 365.1406, Accuracy: 0.7269\n",
      "Training loss (for one batch) at step 90: 346.8432, Accuracy: 0.7250\n",
      "Training loss (for one batch) at step 100: 341.3592, Accuracy: 0.7302\n",
      "Training loss (for one batch) at step 110: 338.5761, Accuracy: 0.7307\n",
      "---- Training ----\n",
      "Training loss: 116.1367\n",
      "Training acc over epoch: 0.7301\n",
      "---- Validation ----\n",
      "Validation loss: 44.6544\n",
      "Validation acc: 0.6959\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 365.9894, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 355.2733, Accuracy: 0.6776\n",
      "Training loss (for one batch) at step 20: 346.8951, Accuracy: 0.7065\n",
      "Training loss (for one batch) at step 30: 303.9299, Accuracy: 0.7253\n",
      "Training loss (for one batch) at step 40: 345.4854, Accuracy: 0.7363\n",
      "Training loss (for one batch) at step 50: 312.9840, Accuracy: 0.7474\n",
      "Training loss (for one batch) at step 60: 325.6743, Accuracy: 0.7513\n",
      "Training loss (for one batch) at step 70: 354.6281, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 80: 376.3512, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 90: 324.4486, Accuracy: 0.7289\n",
      "Training loss (for one batch) at step 100: 333.4498, Accuracy: 0.7301\n",
      "Training loss (for one batch) at step 110: 345.6721, Accuracy: 0.7313\n",
      "---- Training ----\n",
      "Training loss: 107.1509\n",
      "Training acc over epoch: 0.7313\n",
      "---- Validation ----\n",
      "Validation loss: 54.4396\n",
      "Validation acc: 0.6964\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 378.2869, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 359.5961, Accuracy: 0.6740\n",
      "Training loss (for one batch) at step 20: 320.3508, Accuracy: 0.6853\n",
      "Training loss (for one batch) at step 30: 323.2206, Accuracy: 0.7026\n",
      "Training loss (for one batch) at step 40: 336.9687, Accuracy: 0.7208\n",
      "Training loss (for one batch) at step 50: 320.4116, Accuracy: 0.7364\n",
      "Training loss (for one batch) at step 60: 338.7583, Accuracy: 0.7430\n",
      "Training loss (for one batch) at step 70: 358.2278, Accuracy: 0.7353\n",
      "Training loss (for one batch) at step 80: 354.5446, Accuracy: 0.7242\n",
      "Training loss (for one batch) at step 90: 333.8654, Accuracy: 0.7224\n",
      "Training loss (for one batch) at step 100: 337.7517, Accuracy: 0.7249\n",
      "Training loss (for one batch) at step 110: 359.7131, Accuracy: 0.7266\n",
      "---- Training ----\n",
      "Training loss: 113.5224\n",
      "Training acc over epoch: 0.7257\n",
      "---- Validation ----\n",
      "Validation loss: 43.5847\n",
      "Validation acc: 0.6873\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 360.8002, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 364.2244, Accuracy: 0.6690\n",
      "Training loss (for one batch) at step 20: 333.1328, Accuracy: 0.6853\n",
      "Training loss (for one batch) at step 30: 307.9536, Accuracy: 0.7117\n",
      "Training loss (for one batch) at step 40: 325.9742, Accuracy: 0.7296\n",
      "Training loss (for one batch) at step 50: 325.3397, Accuracy: 0.7388\n",
      "Training loss (for one batch) at step 60: 325.0687, Accuracy: 0.7462\n",
      "Training loss (for one batch) at step 70: 355.4269, Accuracy: 0.7357\n",
      "Training loss (for one batch) at step 80: 353.7331, Accuracy: 0.7246\n",
      "Training loss (for one batch) at step 90: 319.7766, Accuracy: 0.7226\n",
      "Training loss (for one batch) at step 100: 332.3275, Accuracy: 0.7265\n",
      "Training loss (for one batch) at step 110: 344.0178, Accuracy: 0.7268\n",
      "---- Training ----\n",
      "Training loss: 110.8072\n",
      "Training acc over epoch: 0.7264\n",
      "---- Validation ----\n",
      "Validation loss: 46.8947\n",
      "Validation acc: 0.7007\n",
      "Time taken: 10.87s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 360.6869, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 375.7137, Accuracy: 0.6740\n",
      "Training loss (for one batch) at step 20: 337.8362, Accuracy: 0.6923\n",
      "Training loss (for one batch) at step 30: 329.7973, Accuracy: 0.7137\n",
      "Training loss (for one batch) at step 40: 324.4752, Accuracy: 0.7327\n",
      "Training loss (for one batch) at step 50: 317.3598, Accuracy: 0.7425\n",
      "Training loss (for one batch) at step 60: 345.0511, Accuracy: 0.7483\n",
      "Training loss (for one batch) at step 70: 353.8914, Accuracy: 0.7369\n",
      "Training loss (for one batch) at step 80: 327.2081, Accuracy: 0.7286\n",
      "Training loss (for one batch) at step 90: 345.6036, Accuracy: 0.7255\n",
      "Training loss (for one batch) at step 100: 331.1751, Accuracy: 0.7278\n",
      "Training loss (for one batch) at step 110: 328.0651, Accuracy: 0.7302\n",
      "---- Training ----\n",
      "Training loss: 108.7000\n",
      "Training acc over epoch: 0.7288\n",
      "---- Validation ----\n",
      "Validation loss: 39.7841\n",
      "Validation acc: 0.6905\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 354.2066, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 360.3615, Accuracy: 0.6719\n",
      "Training loss (for one batch) at step 20: 310.8778, Accuracy: 0.6931\n",
      "Training loss (for one batch) at step 30: 316.7739, Accuracy: 0.7170\n",
      "Training loss (for one batch) at step 40: 326.8205, Accuracy: 0.7298\n",
      "Training loss (for one batch) at step 50: 310.0900, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 60: 335.2329, Accuracy: 0.7462\n",
      "Training loss (for one batch) at step 70: 350.5107, Accuracy: 0.7379\n",
      "Training loss (for one batch) at step 80: 337.2871, Accuracy: 0.7267\n",
      "Training loss (for one batch) at step 90: 316.0663, Accuracy: 0.7242\n",
      "Training loss (for one batch) at step 100: 324.5393, Accuracy: 0.7284\n",
      "Training loss (for one batch) at step 110: 331.1284, Accuracy: 0.7271\n",
      "---- Training ----\n",
      "Training loss: 101.0451\n",
      "Training acc over epoch: 0.7266\n",
      "---- Validation ----\n",
      "Validation loss: 40.1710\n",
      "Validation acc: 0.6843\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 355.3042, Accuracy: 0.6797\n",
      "Training loss (for one batch) at step 10: 362.8206, Accuracy: 0.6527\n",
      "Training loss (for one batch) at step 20: 363.4908, Accuracy: 0.6849\n",
      "Training loss (for one batch) at step 30: 309.6272, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 40: 312.6269, Accuracy: 0.7281\n",
      "Training loss (for one batch) at step 50: 325.6482, Accuracy: 0.7384\n",
      "Training loss (for one batch) at step 60: 312.8266, Accuracy: 0.7417\n",
      "Training loss (for one batch) at step 70: 346.8528, Accuracy: 0.7312\n",
      "Training loss (for one batch) at step 80: 346.3315, Accuracy: 0.7217\n",
      "Training loss (for one batch) at step 90: 323.2431, Accuracy: 0.7206\n",
      "Training loss (for one batch) at step 100: 305.3455, Accuracy: 0.7259\n",
      "Training loss (for one batch) at step 110: 337.7052, Accuracy: 0.7275\n",
      "---- Training ----\n",
      "Training loss: 113.5239\n",
      "Training acc over epoch: 0.7269\n",
      "---- Validation ----\n",
      "Validation loss: 56.6965\n",
      "Validation acc: 0.7055\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 381.8192, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 360.5248, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 20: 319.0544, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 30: 305.8112, Accuracy: 0.7122\n",
      "Training loss (for one batch) at step 40: 322.4323, Accuracy: 0.7294\n",
      "Training loss (for one batch) at step 50: 319.2653, Accuracy: 0.7402\n",
      "Training loss (for one batch) at step 60: 313.0238, Accuracy: 0.7462\n",
      "Training loss (for one batch) at step 70: 329.3806, Accuracy: 0.7361\n",
      "Training loss (for one batch) at step 80: 333.2851, Accuracy: 0.7258\n",
      "Training loss (for one batch) at step 90: 319.8261, Accuracy: 0.7250\n",
      "Training loss (for one batch) at step 100: 334.1805, Accuracy: 0.7291\n",
      "Training loss (for one batch) at step 110: 331.2852, Accuracy: 0.7304\n",
      "---- Training ----\n",
      "Training loss: 112.1474\n",
      "Training acc over epoch: 0.7305\n",
      "---- Validation ----\n",
      "Validation loss: 58.1653\n",
      "Validation acc: 0.6897\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 366.5488, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 336.4813, Accuracy: 0.6733\n",
      "Training loss (for one batch) at step 20: 312.3747, Accuracy: 0.6946\n",
      "Training loss (for one batch) at step 30: 324.4951, Accuracy: 0.7157\n",
      "Training loss (for one batch) at step 40: 299.0435, Accuracy: 0.7329\n",
      "Training loss (for one batch) at step 50: 304.1048, Accuracy: 0.7428\n",
      "Training loss (for one batch) at step 60: 332.1697, Accuracy: 0.7472\n",
      "Training loss (for one batch) at step 70: 344.9936, Accuracy: 0.7366\n",
      "Training loss (for one batch) at step 80: 352.3366, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 90: 317.1205, Accuracy: 0.7254\n",
      "Training loss (for one batch) at step 100: 324.3034, Accuracy: 0.7288\n",
      "Training loss (for one batch) at step 110: 338.0177, Accuracy: 0.7314\n",
      "---- Training ----\n",
      "Training loss: 109.4613\n",
      "Training acc over epoch: 0.7304\n",
      "---- Validation ----\n",
      "Validation loss: 33.3745\n",
      "Validation acc: 0.6926\n",
      "Time taken: 10.31s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6801\n",
      "Validation AUC: 0.6820\n",
      "Validation Balanced_ACC: 0.4041\n",
      "Validation AUCSK: 0.7685\n",
      "Validation MI: 0.0974\n",
      "Validation Normalized MI: 0.1421\n",
      "Validation Adjusted MI: 0.1421\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 646.2151, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 598.6373, Accuracy: 0.4865\n",
      "Training loss (for one batch) at step 20: 566.9996, Accuracy: 0.4985\n",
      "Training loss (for one batch) at step 30: 546.5002, Accuracy: 0.5020\n",
      "Training loss (for one batch) at step 40: 521.3660, Accuracy: 0.5067\n",
      "Training loss (for one batch) at step 50: 515.0674, Accuracy: 0.5058\n",
      "Training loss (for one batch) at step 60: 491.5873, Accuracy: 0.5102\n",
      "Training loss (for one batch) at step 70: 466.9210, Accuracy: 0.5112\n",
      "Training loss (for one batch) at step 80: 483.9078, Accuracy: 0.5131\n",
      "Training loss (for one batch) at step 90: 468.3730, Accuracy: 0.5142\n",
      "Training loss (for one batch) at step 100: 462.4034, Accuracy: 0.5127\n",
      "Training loss (for one batch) at step 110: 473.6888, Accuracy: 0.5163\n",
      "---- Training ----\n",
      "Training loss: 148.0575\n",
      "Training acc over epoch: 0.5167\n",
      "---- Validation ----\n",
      "Validation loss: 34.7854\n",
      "Validation acc: 0.4871\n",
      "Time taken: 12.24s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 459.4458, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 462.2724, Accuracy: 0.5227\n",
      "Training loss (for one batch) at step 20: 458.9671, Accuracy: 0.5268\n",
      "Training loss (for one batch) at step 30: 455.9140, Accuracy: 0.5285\n",
      "Training loss (for one batch) at step 40: 448.7183, Accuracy: 0.5284\n",
      "Training loss (for one batch) at step 50: 450.9176, Accuracy: 0.5257\n",
      "Training loss (for one batch) at step 60: 449.8282, Accuracy: 0.5270\n",
      "Training loss (for one batch) at step 70: 454.0806, Accuracy: 0.5294\n",
      "Training loss (for one batch) at step 80: 449.0515, Accuracy: 0.5318\n",
      "Training loss (for one batch) at step 90: 444.6089, Accuracy: 0.5352\n",
      "Training loss (for one batch) at step 100: 448.2544, Accuracy: 0.5348\n",
      "Training loss (for one batch) at step 110: 453.5349, Accuracy: 0.5358\n",
      "---- Training ----\n",
      "Training loss: 142.6033\n",
      "Training acc over epoch: 0.5358\n",
      "---- Validation ----\n",
      "Validation loss: 34.7008\n",
      "Validation acc: 0.5132\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 450.3964, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 446.7384, Accuracy: 0.5320\n",
      "Training loss (for one batch) at step 20: 449.3375, Accuracy: 0.5339\n",
      "Training loss (for one batch) at step 30: 448.3886, Accuracy: 0.5348\n",
      "Training loss (for one batch) at step 40: 446.2091, Accuracy: 0.5396\n",
      "Training loss (for one batch) at step 50: 444.2731, Accuracy: 0.5411\n",
      "Training loss (for one batch) at step 60: 448.4913, Accuracy: 0.5435\n",
      "Training loss (for one batch) at step 70: 444.5588, Accuracy: 0.5465\n",
      "Training loss (for one batch) at step 80: 445.6497, Accuracy: 0.5489\n",
      "Training loss (for one batch) at step 90: 445.4366, Accuracy: 0.5498\n",
      "Training loss (for one batch) at step 100: 450.1962, Accuracy: 0.5485\n",
      "Training loss (for one batch) at step 110: 444.7241, Accuracy: 0.5501\n",
      "---- Training ----\n",
      "Training loss: 138.6695\n",
      "Training acc over epoch: 0.5524\n",
      "---- Validation ----\n",
      "Validation loss: 34.6097\n",
      "Validation acc: 0.5457\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 443.6287, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 443.1872, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 20: 443.4150, Accuracy: 0.5911\n",
      "Training loss (for one batch) at step 30: 443.9779, Accuracy: 0.5907\n",
      "Training loss (for one batch) at step 40: 439.7214, Accuracy: 0.5939\n",
      "Training loss (for one batch) at step 50: 443.3173, Accuracy: 0.5873\n",
      "Training loss (for one batch) at step 60: 444.5694, Accuracy: 0.5809\n",
      "Training loss (for one batch) at step 70: 445.9187, Accuracy: 0.5844\n",
      "Training loss (for one batch) at step 80: 445.3988, Accuracy: 0.5841\n",
      "Training loss (for one batch) at step 90: 445.4863, Accuracy: 0.5840\n",
      "Training loss (for one batch) at step 100: 447.6685, Accuracy: 0.5845\n",
      "Training loss (for one batch) at step 110: 443.2437, Accuracy: 0.5840\n",
      "---- Training ----\n",
      "Training loss: 139.0064\n",
      "Training acc over epoch: 0.5830\n",
      "---- Validation ----\n",
      "Validation loss: 33.9613\n",
      "Validation acc: 0.5932\n",
      "Time taken: 10.89s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 446.7310, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 443.6958, Accuracy: 0.5994\n",
      "Training loss (for one batch) at step 20: 442.4940, Accuracy: 0.5975\n",
      "Training loss (for one batch) at step 30: 441.4460, Accuracy: 0.5963\n",
      "Training loss (for one batch) at step 40: 443.4807, Accuracy: 0.5972\n",
      "Training loss (for one batch) at step 50: 439.0190, Accuracy: 0.5988\n",
      "Training loss (for one batch) at step 60: 444.8554, Accuracy: 0.6003\n",
      "Training loss (for one batch) at step 70: 442.6552, Accuracy: 0.6034\n",
      "Training loss (for one batch) at step 80: 443.8500, Accuracy: 0.6046\n",
      "Training loss (for one batch) at step 90: 441.3452, Accuracy: 0.6035\n",
      "Training loss (for one batch) at step 100: 441.7662, Accuracy: 0.6027\n",
      "Training loss (for one batch) at step 110: 443.9005, Accuracy: 0.6025\n",
      "---- Training ----\n",
      "Training loss: 139.2196\n",
      "Training acc over epoch: 0.6025\n",
      "---- Validation ----\n",
      "Validation loss: 33.7095\n",
      "Validation acc: 0.6214\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 440.9651, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 444.2812, Accuracy: 0.6264\n",
      "Training loss (for one batch) at step 20: 440.2206, Accuracy: 0.6228\n",
      "Training loss (for one batch) at step 30: 442.1526, Accuracy: 0.6255\n",
      "Training loss (for one batch) at step 40: 443.4333, Accuracy: 0.6225\n",
      "Training loss (for one batch) at step 50: 436.7483, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 60: 439.3117, Accuracy: 0.6218\n",
      "Training loss (for one batch) at step 70: 441.2331, Accuracy: 0.6239\n",
      "Training loss (for one batch) at step 80: 439.8581, Accuracy: 0.6277\n",
      "Training loss (for one batch) at step 90: 442.5792, Accuracy: 0.6246\n",
      "Training loss (for one batch) at step 100: 441.3915, Accuracy: 0.6239\n",
      "Training loss (for one batch) at step 110: 440.2246, Accuracy: 0.6245\n",
      "---- Training ----\n",
      "Training loss: 138.0580\n",
      "Training acc over epoch: 0.6252\n",
      "---- Validation ----\n",
      "Validation loss: 35.0216\n",
      "Validation acc: 0.6389\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 444.9794, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 444.5609, Accuracy: 0.5994\n",
      "Training loss (for one batch) at step 20: 441.2166, Accuracy: 0.6031\n",
      "Training loss (for one batch) at step 30: 438.8900, Accuracy: 0.6197\n",
      "Training loss (for one batch) at step 40: 438.7276, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 50: 441.2103, Accuracy: 0.6276\n",
      "Training loss (for one batch) at step 60: 436.2816, Accuracy: 0.6327\n",
      "Training loss (for one batch) at step 70: 440.9364, Accuracy: 0.6372\n",
      "Training loss (for one batch) at step 80: 444.7342, Accuracy: 0.6374\n",
      "Training loss (for one batch) at step 90: 437.8794, Accuracy: 0.6350\n",
      "Training loss (for one batch) at step 100: 438.6700, Accuracy: 0.6358\n",
      "Training loss (for one batch) at step 110: 437.6008, Accuracy: 0.6370\n",
      "---- Training ----\n",
      "Training loss: 137.9911\n",
      "Training acc over epoch: 0.6361\n",
      "---- Validation ----\n",
      "Validation loss: 34.7585\n",
      "Validation acc: 0.6196\n",
      "Time taken: 10.61s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 440.8046, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 439.8696, Accuracy: 0.6520\n",
      "Training loss (for one batch) at step 20: 437.6062, Accuracy: 0.6455\n",
      "Training loss (for one batch) at step 30: 437.3043, Accuracy: 0.6459\n",
      "Training loss (for one batch) at step 40: 434.0633, Accuracy: 0.6444\n",
      "Training loss (for one batch) at step 50: 431.8319, Accuracy: 0.6520\n",
      "Training loss (for one batch) at step 60: 439.1452, Accuracy: 0.6529\n",
      "Training loss (for one batch) at step 70: 447.4935, Accuracy: 0.6572\n",
      "Training loss (for one batch) at step 80: 439.1997, Accuracy: 0.6572\n",
      "Training loss (for one batch) at step 90: 440.1161, Accuracy: 0.6519\n",
      "Training loss (for one batch) at step 100: 438.4553, Accuracy: 0.6504\n",
      "Training loss (for one batch) at step 110: 436.8734, Accuracy: 0.6506\n",
      "---- Training ----\n",
      "Training loss: 134.0699\n",
      "Training acc over epoch: 0.6510\n",
      "---- Validation ----\n",
      "Validation loss: 35.0608\n",
      "Validation acc: 0.6470\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 447.7659, Accuracy: 0.6484\n",
      "Training loss (for one batch) at step 10: 439.0684, Accuracy: 0.6470\n",
      "Training loss (for one batch) at step 20: 438.7122, Accuracy: 0.6496\n",
      "Training loss (for one batch) at step 30: 431.6696, Accuracy: 0.6575\n",
      "Training loss (for one batch) at step 40: 438.1910, Accuracy: 0.6625\n",
      "Training loss (for one batch) at step 50: 426.8937, Accuracy: 0.6644\n",
      "Training loss (for one batch) at step 60: 437.2226, Accuracy: 0.6702\n",
      "Training loss (for one batch) at step 70: 441.1028, Accuracy: 0.6744\n",
      "Training loss (for one batch) at step 80: 435.6088, Accuracy: 0.6759\n",
      "Training loss (for one batch) at step 90: 440.8651, Accuracy: 0.6726\n",
      "Training loss (for one batch) at step 100: 440.9054, Accuracy: 0.6723\n",
      "Training loss (for one batch) at step 110: 435.9070, Accuracy: 0.6748\n",
      "---- Training ----\n",
      "Training loss: 137.6879\n",
      "Training acc over epoch: 0.6757\n",
      "---- Validation ----\n",
      "Validation loss: 34.3687\n",
      "Validation acc: 0.6972\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 439.2629, Accuracy: 0.6562\n",
      "Training loss (for one batch) at step 10: 440.6224, Accuracy: 0.6641\n",
      "Training loss (for one batch) at step 20: 440.9114, Accuracy: 0.6529\n",
      "Training loss (for one batch) at step 30: 430.3841, Accuracy: 0.6633\n",
      "Training loss (for one batch) at step 40: 428.8145, Accuracy: 0.6684\n",
      "Training loss (for one batch) at step 50: 431.4313, Accuracy: 0.6736\n",
      "Training loss (for one batch) at step 60: 444.6251, Accuracy: 0.6790\n",
      "Training loss (for one batch) at step 70: 437.9835, Accuracy: 0.6799\n",
      "Training loss (for one batch) at step 80: 443.7127, Accuracy: 0.6777\n",
      "Training loss (for one batch) at step 90: 436.3482, Accuracy: 0.6727\n",
      "Training loss (for one batch) at step 100: 437.2906, Accuracy: 0.6717\n",
      "Training loss (for one batch) at step 110: 433.5913, Accuracy: 0.6760\n",
      "---- Training ----\n",
      "Training loss: 135.6972\n",
      "Training acc over epoch: 0.6763\n",
      "---- Validation ----\n",
      "Validation loss: 34.9996\n",
      "Validation acc: 0.6886\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 441.7584, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 436.2147, Accuracy: 0.6818\n",
      "Training loss (for one batch) at step 20: 436.4144, Accuracy: 0.6682\n",
      "Training loss (for one batch) at step 30: 432.6571, Accuracy: 0.6812\n",
      "Training loss (for one batch) at step 40: 431.5053, Accuracy: 0.6818\n",
      "Training loss (for one batch) at step 50: 420.9161, Accuracy: 0.6910\n",
      "Training loss (for one batch) at step 60: 433.3304, Accuracy: 0.6974\n",
      "Training loss (for one batch) at step 70: 437.9826, Accuracy: 0.7009\n",
      "Training loss (for one batch) at step 80: 439.4474, Accuracy: 0.6968\n",
      "Training loss (for one batch) at step 90: 433.0549, Accuracy: 0.6914\n",
      "Training loss (for one batch) at step 100: 423.5142, Accuracy: 0.6921\n",
      "Training loss (for one batch) at step 110: 430.2980, Accuracy: 0.6938\n",
      "---- Training ----\n",
      "Training loss: 134.5691\n",
      "Training acc over epoch: 0.6955\n",
      "---- Validation ----\n",
      "Validation loss: 34.3409\n",
      "Validation acc: 0.7144\n",
      "Time taken: 10.24s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 440.9812, Accuracy: 0.7422\n",
      "Training loss (for one batch) at step 10: 436.2365, Accuracy: 0.6974\n",
      "Training loss (for one batch) at step 20: 436.1804, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 30: 429.8726, Accuracy: 0.6910\n",
      "Training loss (for one batch) at step 40: 427.6771, Accuracy: 0.6961\n",
      "Training loss (for one batch) at step 50: 421.8283, Accuracy: 0.7045\n",
      "Training loss (for one batch) at step 60: 433.9966, Accuracy: 0.7102\n",
      "Training loss (for one batch) at step 70: 435.2167, Accuracy: 0.7113\n",
      "Training loss (for one batch) at step 80: 441.4370, Accuracy: 0.7086\n",
      "Training loss (for one batch) at step 90: 437.2238, Accuracy: 0.7071\n",
      "Training loss (for one batch) at step 100: 423.0266, Accuracy: 0.7082\n",
      "Training loss (for one batch) at step 110: 434.7483, Accuracy: 0.7091\n",
      "---- Training ----\n",
      "Training loss: 141.5843\n",
      "Training acc over epoch: 0.7094\n",
      "---- Validation ----\n",
      "Validation loss: 34.4973\n",
      "Validation acc: 0.7286\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 446.9144, Accuracy: 0.6875\n",
      "Training loss (for one batch) at step 10: 435.0710, Accuracy: 0.7138\n",
      "Training loss (for one batch) at step 20: 437.2692, Accuracy: 0.7054\n",
      "Training loss (for one batch) at step 30: 427.2512, Accuracy: 0.7135\n",
      "Training loss (for one batch) at step 40: 415.1552, Accuracy: 0.7149\n",
      "Training loss (for one batch) at step 50: 414.0307, Accuracy: 0.7165\n",
      "Training loss (for one batch) at step 60: 426.6962, Accuracy: 0.7254\n",
      "Training loss (for one batch) at step 70: 437.9536, Accuracy: 0.7290\n",
      "Training loss (for one batch) at step 80: 444.0530, Accuracy: 0.7228\n",
      "Training loss (for one batch) at step 90: 427.6549, Accuracy: 0.7204\n",
      "Training loss (for one batch) at step 100: 421.0898, Accuracy: 0.7191\n",
      "Training loss (for one batch) at step 110: 429.7031, Accuracy: 0.7214\n",
      "---- Training ----\n",
      "Training loss: 135.1324\n",
      "Training acc over epoch: 0.7216\n",
      "---- Validation ----\n",
      "Validation loss: 35.3449\n",
      "Validation acc: 0.7324\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 437.8112, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 432.6187, Accuracy: 0.6953\n",
      "Training loss (for one batch) at step 20: 433.1928, Accuracy: 0.6853\n",
      "Training loss (for one batch) at step 30: 430.0403, Accuracy: 0.6976\n",
      "Training loss (for one batch) at step 40: 419.6490, Accuracy: 0.7094\n",
      "Training loss (for one batch) at step 50: 411.1996, Accuracy: 0.7221\n",
      "Training loss (for one batch) at step 60: 419.0403, Accuracy: 0.7305\n",
      "Training loss (for one batch) at step 70: 421.7220, Accuracy: 0.7322\n",
      "Training loss (for one batch) at step 80: 435.9798, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 90: 435.1724, Accuracy: 0.7262\n",
      "Training loss (for one batch) at step 100: 432.1586, Accuracy: 0.7287\n",
      "Training loss (for one batch) at step 110: 439.8438, Accuracy: 0.7319\n",
      "---- Training ----\n",
      "Training loss: 141.5653\n",
      "Training acc over epoch: 0.7327\n",
      "---- Validation ----\n",
      "Validation loss: 36.7507\n",
      "Validation acc: 0.7646\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 445.8234, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 434.3780, Accuracy: 0.7273\n",
      "Training loss (for one batch) at step 20: 438.4072, Accuracy: 0.7232\n",
      "Training loss (for one batch) at step 30: 428.3934, Accuracy: 0.7283\n",
      "Training loss (for one batch) at step 40: 411.4647, Accuracy: 0.7304\n",
      "Training loss (for one batch) at step 50: 396.8662, Accuracy: 0.7420\n",
      "Training loss (for one batch) at step 60: 420.9089, Accuracy: 0.7491\n",
      "Training loss (for one batch) at step 70: 440.4439, Accuracy: 0.7493\n",
      "Training loss (for one batch) at step 80: 437.0148, Accuracy: 0.7453\n",
      "Training loss (for one batch) at step 90: 430.8847, Accuracy: 0.7412\n",
      "Training loss (for one batch) at step 100: 430.9600, Accuracy: 0.7409\n",
      "Training loss (for one batch) at step 110: 419.3463, Accuracy: 0.7409\n",
      "---- Training ----\n",
      "Training loss: 132.7220\n",
      "Training acc over epoch: 0.7410\n",
      "---- Validation ----\n",
      "Validation loss: 35.3001\n",
      "Validation acc: 0.7456\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 435.7905, Accuracy: 0.7031\n",
      "Training loss (for one batch) at step 10: 436.3505, Accuracy: 0.7315\n",
      "Training loss (for one batch) at step 20: 428.6218, Accuracy: 0.7295\n",
      "Training loss (for one batch) at step 30: 425.7197, Accuracy: 0.7354\n",
      "Training loss (for one batch) at step 40: 414.9129, Accuracy: 0.7462\n",
      "Training loss (for one batch) at step 50: 403.7596, Accuracy: 0.7547\n",
      "Training loss (for one batch) at step 60: 413.4384, Accuracy: 0.7624\n",
      "Training loss (for one batch) at step 70: 431.5050, Accuracy: 0.7627\n",
      "Training loss (for one batch) at step 80: 430.4238, Accuracy: 0.7620\n",
      "Training loss (for one batch) at step 90: 433.4025, Accuracy: 0.7550\n",
      "Training loss (for one batch) at step 100: 424.0375, Accuracy: 0.7546\n",
      "Training loss (for one batch) at step 110: 423.1207, Accuracy: 0.7567\n",
      "---- Training ----\n",
      "Training loss: 130.7220\n",
      "Training acc over epoch: 0.7573\n",
      "---- Validation ----\n",
      "Validation loss: 32.9222\n",
      "Validation acc: 0.7351\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 436.4999, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 426.7191, Accuracy: 0.7507\n",
      "Training loss (for one batch) at step 20: 426.7240, Accuracy: 0.7459\n",
      "Training loss (for one batch) at step 30: 405.3025, Accuracy: 0.7460\n",
      "Training loss (for one batch) at step 40: 406.6971, Accuracy: 0.7490\n",
      "Training loss (for one batch) at step 50: 393.5992, Accuracy: 0.7621\n",
      "Training loss (for one batch) at step 60: 426.2438, Accuracy: 0.7691\n",
      "Training loss (for one batch) at step 70: 437.0014, Accuracy: 0.7662\n",
      "Training loss (for one batch) at step 80: 427.3524, Accuracy: 0.7597\n",
      "Training loss (for one batch) at step 90: 416.5779, Accuracy: 0.7582\n",
      "Training loss (for one batch) at step 100: 411.5673, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 110: 427.8612, Accuracy: 0.7618\n",
      "---- Training ----\n",
      "Training loss: 129.0376\n",
      "Training acc over epoch: 0.7644\n",
      "---- Validation ----\n",
      "Validation loss: 37.3863\n",
      "Validation acc: 0.7628\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 430.2886, Accuracy: 0.7344\n",
      "Training loss (for one batch) at step 10: 433.5753, Accuracy: 0.7443\n",
      "Training loss (for one batch) at step 20: 424.1908, Accuracy: 0.7321\n",
      "Training loss (for one batch) at step 30: 412.3436, Accuracy: 0.7492\n",
      "Training loss (for one batch) at step 40: 401.8822, Accuracy: 0.7532\n",
      "Training loss (for one batch) at step 50: 403.2669, Accuracy: 0.7642\n",
      "Training loss (for one batch) at step 60: 388.2643, Accuracy: 0.7715\n",
      "Training loss (for one batch) at step 70: 424.3321, Accuracy: 0.7720\n",
      "Training loss (for one batch) at step 80: 437.8073, Accuracy: 0.7644\n",
      "Training loss (for one batch) at step 90: 425.5840, Accuracy: 0.7598\n",
      "Training loss (for one batch) at step 100: 417.7414, Accuracy: 0.7586\n",
      "Training loss (for one batch) at step 110: 419.5644, Accuracy: 0.7600\n",
      "---- Training ----\n",
      "Training loss: 133.8114\n",
      "Training acc over epoch: 0.7607\n",
      "---- Validation ----\n",
      "Validation loss: 36.4521\n",
      "Validation acc: 0.7394\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 433.2924, Accuracy: 0.7266\n",
      "Training loss (for one batch) at step 10: 431.8684, Accuracy: 0.7536\n",
      "Training loss (for one batch) at step 20: 429.5142, Accuracy: 0.7481\n",
      "Training loss (for one batch) at step 30: 414.4550, Accuracy: 0.7596\n",
      "Training loss (for one batch) at step 40: 401.2112, Accuracy: 0.7647\n",
      "Training loss (for one batch) at step 50: 402.4933, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 60: 400.9446, Accuracy: 0.7837\n",
      "Training loss (for one batch) at step 70: 414.3674, Accuracy: 0.7808\n",
      "Training loss (for one batch) at step 80: 421.6536, Accuracy: 0.7763\n",
      "Training loss (for one batch) at step 90: 423.2443, Accuracy: 0.7719\n",
      "Training loss (for one batch) at step 100: 406.6671, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 110: 412.7879, Accuracy: 0.7755\n",
      "---- Training ----\n",
      "Training loss: 127.6505\n",
      "Training acc over epoch: 0.7768\n",
      "---- Validation ----\n",
      "Validation loss: 35.3751\n",
      "Validation acc: 0.7665\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 420.3925, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 427.4211, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 421.7033, Accuracy: 0.7560\n",
      "Training loss (for one batch) at step 30: 415.2361, Accuracy: 0.7606\n",
      "Training loss (for one batch) at step 40: 396.3469, Accuracy: 0.7681\n",
      "Training loss (for one batch) at step 50: 381.6270, Accuracy: 0.7826\n",
      "Training loss (for one batch) at step 60: 394.0292, Accuracy: 0.7909\n",
      "Training loss (for one batch) at step 70: 436.7594, Accuracy: 0.7895\n",
      "Training loss (for one batch) at step 80: 421.4969, Accuracy: 0.7836\n",
      "Training loss (for one batch) at step 90: 407.9571, Accuracy: 0.7817\n",
      "Training loss (for one batch) at step 100: 395.2454, Accuracy: 0.7811\n",
      "Training loss (for one batch) at step 110: 412.5871, Accuracy: 0.7825\n",
      "---- Training ----\n",
      "Training loss: 131.3964\n",
      "Training acc over epoch: 0.7824\n",
      "---- Validation ----\n",
      "Validation loss: 37.5295\n",
      "Validation acc: 0.7493\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 429.2982, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 425.5217, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 20: 422.3957, Accuracy: 0.7444\n",
      "Training loss (for one batch) at step 30: 408.5059, Accuracy: 0.7593\n",
      "Training loss (for one batch) at step 40: 386.5035, Accuracy: 0.7744\n",
      "Training loss (for one batch) at step 50: 366.6317, Accuracy: 0.7839\n",
      "Training loss (for one batch) at step 60: 400.8169, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 70: 405.6774, Accuracy: 0.7899\n",
      "Training loss (for one batch) at step 80: 420.8738, Accuracy: 0.7847\n",
      "Training loss (for one batch) at step 90: 397.8732, Accuracy: 0.7817\n",
      "Training loss (for one batch) at step 100: 398.3859, Accuracy: 0.7826\n",
      "Training loss (for one batch) at step 110: 404.5058, Accuracy: 0.7841\n",
      "---- Training ----\n",
      "Training loss: 120.4335\n",
      "Training acc over epoch: 0.7843\n",
      "---- Validation ----\n",
      "Validation loss: 36.0569\n",
      "Validation acc: 0.7663\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 430.9519, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 424.3900, Accuracy: 0.7614\n",
      "Training loss (for one batch) at step 20: 407.8162, Accuracy: 0.7641\n",
      "Training loss (for one batch) at step 30: 404.4970, Accuracy: 0.7699\n",
      "Training loss (for one batch) at step 40: 387.2949, Accuracy: 0.7801\n",
      "Training loss (for one batch) at step 50: 387.9534, Accuracy: 0.7906\n",
      "Training loss (for one batch) at step 60: 395.7677, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 70: 398.6700, Accuracy: 0.7934\n",
      "Training loss (for one batch) at step 80: 403.0862, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 90: 408.1233, Accuracy: 0.7848\n",
      "Training loss (for one batch) at step 100: 398.3047, Accuracy: 0.7866\n",
      "Training loss (for one batch) at step 110: 402.8342, Accuracy: 0.7878\n",
      "---- Training ----\n",
      "Training loss: 130.8976\n",
      "Training acc over epoch: 0.7884\n",
      "---- Validation ----\n",
      "Validation loss: 32.5041\n",
      "Validation acc: 0.7531\n",
      "Time taken: 10.46s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 431.8241, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 417.6058, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 20: 405.4118, Accuracy: 0.7623\n",
      "Training loss (for one batch) at step 30: 401.1608, Accuracy: 0.7790\n",
      "Training loss (for one batch) at step 40: 397.6497, Accuracy: 0.7866\n",
      "Training loss (for one batch) at step 50: 381.4923, Accuracy: 0.7949\n",
      "Training loss (for one batch) at step 60: 379.1270, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 70: 431.1891, Accuracy: 0.8003\n",
      "Training loss (for one batch) at step 80: 410.9279, Accuracy: 0.7943\n",
      "Training loss (for one batch) at step 90: 417.9247, Accuracy: 0.7910\n",
      "Training loss (for one batch) at step 100: 389.2625, Accuracy: 0.7925\n",
      "Training loss (for one batch) at step 110: 396.8599, Accuracy: 0.7933\n",
      "---- Training ----\n",
      "Training loss: 124.0890\n",
      "Training acc over epoch: 0.7933\n",
      "---- Validation ----\n",
      "Validation loss: 34.8635\n",
      "Validation acc: 0.7383\n",
      "Time taken: 10.27s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 434.5833, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 417.3366, Accuracy: 0.7635\n",
      "Training loss (for one batch) at step 20: 420.2197, Accuracy: 0.7671\n",
      "Training loss (for one batch) at step 30: 390.6173, Accuracy: 0.7729\n",
      "Training loss (for one batch) at step 40: 374.8291, Accuracy: 0.7847\n",
      "Training loss (for one batch) at step 50: 371.2108, Accuracy: 0.7961\n",
      "Training loss (for one batch) at step 60: 375.6812, Accuracy: 0.8044\n",
      "Training loss (for one batch) at step 70: 403.6509, Accuracy: 0.8042\n",
      "Training loss (for one batch) at step 80: 423.2181, Accuracy: 0.7960\n",
      "Training loss (for one batch) at step 90: 393.4944, Accuracy: 0.7939\n",
      "Training loss (for one batch) at step 100: 388.8963, Accuracy: 0.7952\n",
      "Training loss (for one batch) at step 110: 399.6180, Accuracy: 0.7952\n",
      "---- Training ----\n",
      "Training loss: 122.8669\n",
      "Training acc over epoch: 0.7949\n",
      "---- Validation ----\n",
      "Validation loss: 33.9561\n",
      "Validation acc: 0.7620\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 426.5950, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 406.6328, Accuracy: 0.7791\n",
      "Training loss (for one batch) at step 20: 403.0822, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 30: 384.6730, Accuracy: 0.7802\n",
      "Training loss (for one batch) at step 40: 383.6143, Accuracy: 0.7904\n",
      "Training loss (for one batch) at step 50: 351.2978, Accuracy: 0.8022\n",
      "Training loss (for one batch) at step 60: 401.8324, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 70: 403.8680, Accuracy: 0.8041\n",
      "Training loss (for one batch) at step 80: 426.6594, Accuracy: 0.7984\n",
      "Training loss (for one batch) at step 90: 381.3329, Accuracy: 0.7964\n",
      "Training loss (for one batch) at step 100: 389.3539, Accuracy: 0.7989\n",
      "Training loss (for one batch) at step 110: 395.3459, Accuracy: 0.8007\n",
      "---- Training ----\n",
      "Training loss: 121.0705\n",
      "Training acc over epoch: 0.8013\n",
      "---- Validation ----\n",
      "Validation loss: 35.3041\n",
      "Validation acc: 0.7536\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 407.4004, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 406.7542, Accuracy: 0.7543\n",
      "Training loss (for one batch) at step 20: 404.5807, Accuracy: 0.7649\n",
      "Training loss (for one batch) at step 30: 385.8467, Accuracy: 0.7810\n",
      "Training loss (for one batch) at step 40: 389.1818, Accuracy: 0.7954\n",
      "Training loss (for one batch) at step 50: 365.9640, Accuracy: 0.8078\n",
      "Training loss (for one batch) at step 60: 395.1280, Accuracy: 0.8121\n",
      "Training loss (for one batch) at step 70: 396.5188, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 80: 399.7906, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 90: 394.3210, Accuracy: 0.8048\n",
      "Training loss (for one batch) at step 100: 376.4299, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 110: 380.5073, Accuracy: 0.8048\n",
      "---- Training ----\n",
      "Training loss: 126.0003\n",
      "Training acc over epoch: 0.8053\n",
      "---- Validation ----\n",
      "Validation loss: 37.4409\n",
      "Validation acc: 0.7611\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 404.9796, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 10: 397.3351, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 20: 387.4749, Accuracy: 0.7876\n",
      "Training loss (for one batch) at step 30: 371.6539, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 40: 371.6133, Accuracy: 0.8049\n",
      "Training loss (for one batch) at step 50: 360.7993, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 60: 377.2064, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 70: 411.1794, Accuracy: 0.8118\n",
      "Training loss (for one batch) at step 80: 398.3806, Accuracy: 0.8066\n",
      "Training loss (for one batch) at step 90: 395.7372, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 100: 381.6560, Accuracy: 0.8024\n",
      "Training loss (for one batch) at step 110: 379.4379, Accuracy: 0.8034\n",
      "---- Training ----\n",
      "Training loss: 117.1723\n",
      "Training acc over epoch: 0.8035\n",
      "---- Validation ----\n",
      "Validation loss: 30.8366\n",
      "Validation acc: 0.7523\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 404.1664, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 398.8204, Accuracy: 0.7599\n",
      "Training loss (for one batch) at step 20: 391.9614, Accuracy: 0.7794\n",
      "Training loss (for one batch) at step 30: 367.5217, Accuracy: 0.7959\n",
      "Training loss (for one batch) at step 40: 357.9916, Accuracy: 0.8051\n",
      "Training loss (for one batch) at step 50: 354.1268, Accuracy: 0.8168\n",
      "Training loss (for one batch) at step 60: 391.4731, Accuracy: 0.8216\n",
      "Training loss (for one batch) at step 70: 409.9567, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 80: 395.0422, Accuracy: 0.8126\n",
      "Training loss (for one batch) at step 90: 394.8860, Accuracy: 0.8103\n",
      "Training loss (for one batch) at step 100: 376.8174, Accuracy: 0.8086\n",
      "Training loss (for one batch) at step 110: 391.8794, Accuracy: 0.8084\n",
      "---- Training ----\n",
      "Training loss: 125.6909\n",
      "Training acc over epoch: 0.8085\n",
      "---- Validation ----\n",
      "Validation loss: 39.5418\n",
      "Validation acc: 0.7515\n",
      "Time taken: 10.73s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 407.6062, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 398.7855, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 20: 380.5405, Accuracy: 0.7891\n",
      "Training loss (for one batch) at step 30: 390.9625, Accuracy: 0.8007\n",
      "Training loss (for one batch) at step 40: 367.3626, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 50: 332.5089, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 60: 372.6745, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 70: 410.0497, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 80: 375.5630, Accuracy: 0.8069\n",
      "Training loss (for one batch) at step 90: 372.1384, Accuracy: 0.8053\n",
      "Training loss (for one batch) at step 100: 358.8463, Accuracy: 0.8075\n",
      "Training loss (for one batch) at step 110: 374.9003, Accuracy: 0.8077\n",
      "---- Training ----\n",
      "Training loss: 113.0232\n",
      "Training acc over epoch: 0.8076\n",
      "---- Validation ----\n",
      "Validation loss: 42.2192\n",
      "Validation acc: 0.7407\n",
      "Time taken: 10.40s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 410.5726, Accuracy: 0.8438\n",
      "Training loss (for one batch) at step 10: 391.6242, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 385.2037, Accuracy: 0.7846\n",
      "Training loss (for one batch) at step 30: 364.1519, Accuracy: 0.7974\n",
      "Training loss (for one batch) at step 40: 347.5427, Accuracy: 0.8095\n",
      "Training loss (for one batch) at step 50: 348.4781, Accuracy: 0.8191\n",
      "Training loss (for one batch) at step 60: 372.2798, Accuracy: 0.8225\n",
      "Training loss (for one batch) at step 70: 396.9050, Accuracy: 0.8147\n",
      "Training loss (for one batch) at step 80: 385.1578, Accuracy: 0.8083\n",
      "Training loss (for one batch) at step 90: 377.3643, Accuracy: 0.8054\n",
      "Training loss (for one batch) at step 100: 350.4025, Accuracy: 0.8072\n",
      "Training loss (for one batch) at step 110: 359.0907, Accuracy: 0.8081\n",
      "---- Training ----\n",
      "Training loss: 116.8882\n",
      "Training acc over epoch: 0.8071\n",
      "---- Validation ----\n",
      "Validation loss: 40.5761\n",
      "Validation acc: 0.7544\n",
      "Time taken: 10.41s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 399.0031, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 380.4973, Accuracy: 0.7670\n",
      "Training loss (for one batch) at step 20: 351.7330, Accuracy: 0.7865\n",
      "Training loss (for one batch) at step 30: 357.1214, Accuracy: 0.7996\n",
      "Training loss (for one batch) at step 40: 358.4722, Accuracy: 0.8157\n",
      "Training loss (for one batch) at step 50: 345.1951, Accuracy: 0.8232\n",
      "Training loss (for one batch) at step 60: 373.8765, Accuracy: 0.8252\n",
      "Training loss (for one batch) at step 70: 384.3480, Accuracy: 0.8223\n",
      "Training loss (for one batch) at step 80: 386.4782, Accuracy: 0.8132\n",
      "Training loss (for one batch) at step 90: 359.7154, Accuracy: 0.8111\n",
      "Training loss (for one batch) at step 100: 343.9687, Accuracy: 0.8113\n",
      "Training loss (for one batch) at step 110: 379.2748, Accuracy: 0.8104\n",
      "---- Training ----\n",
      "Training loss: 130.7578\n",
      "Training acc over epoch: 0.8115\n",
      "---- Validation ----\n",
      "Validation loss: 55.7512\n",
      "Validation acc: 0.7507\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 386.9633, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 379.0285, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 20: 368.3536, Accuracy: 0.7842\n",
      "Training loss (for one batch) at step 30: 364.5147, Accuracy: 0.8009\n",
      "Training loss (for one batch) at step 40: 347.9702, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 50: 339.2991, Accuracy: 0.8197\n",
      "Training loss (for one batch) at step 60: 352.7074, Accuracy: 0.8257\n",
      "Training loss (for one batch) at step 70: 366.1147, Accuracy: 0.8199\n",
      "Training loss (for one batch) at step 80: 380.4380, Accuracy: 0.8127\n",
      "Training loss (for one batch) at step 90: 364.4210, Accuracy: 0.8088\n",
      "Training loss (for one batch) at step 100: 343.2324, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 110: 371.2229, Accuracy: 0.8133\n",
      "---- Training ----\n",
      "Training loss: 115.5216\n",
      "Training acc over epoch: 0.8131\n",
      "---- Validation ----\n",
      "Validation loss: 35.7124\n",
      "Validation acc: 0.7461\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 382.4370, Accuracy: 0.7109\n",
      "Training loss (for one batch) at step 10: 387.7354, Accuracy: 0.7692\n",
      "Training loss (for one batch) at step 20: 363.2789, Accuracy: 0.7839\n",
      "Training loss (for one batch) at step 30: 359.0385, Accuracy: 0.8037\n",
      "Training loss (for one batch) at step 40: 339.6930, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 50: 325.7875, Accuracy: 0.8238\n",
      "Training loss (for one batch) at step 60: 375.2273, Accuracy: 0.8284\n",
      "Training loss (for one batch) at step 70: 391.2867, Accuracy: 0.8254\n",
      "Training loss (for one batch) at step 80: 386.5092, Accuracy: 0.8168\n",
      "Training loss (for one batch) at step 90: 361.9842, Accuracy: 0.8141\n",
      "Training loss (for one batch) at step 100: 334.9380, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 110: 367.0670, Accuracy: 0.8160\n",
      "---- Training ----\n",
      "Training loss: 111.4315\n",
      "Training acc over epoch: 0.8150\n",
      "---- Validation ----\n",
      "Validation loss: 41.0645\n",
      "Validation acc: 0.7402\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 397.0563, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 10: 379.4219, Accuracy: 0.7678\n",
      "Training loss (for one batch) at step 20: 355.5142, Accuracy: 0.7835\n",
      "Training loss (for one batch) at step 30: 353.8902, Accuracy: 0.8012\n",
      "Training loss (for one batch) at step 40: 349.8363, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 50: 337.6418, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 60: 346.7827, Accuracy: 0.8249\n",
      "Training loss (for one batch) at step 70: 367.1783, Accuracy: 0.8192\n",
      "Training loss (for one batch) at step 80: 406.9803, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 90: 352.5969, Accuracy: 0.8097\n",
      "Training loss (for one batch) at step 100: 357.0299, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 110: 353.2340, Accuracy: 0.8135\n",
      "---- Training ----\n",
      "Training loss: 119.9699\n",
      "Training acc over epoch: 0.8115\n",
      "---- Validation ----\n",
      "Validation loss: 43.5264\n",
      "Validation acc: 0.7577\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 383.2349, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 368.9625, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 20: 357.3240, Accuracy: 0.7898\n",
      "Training loss (for one batch) at step 30: 347.5397, Accuracy: 0.7991\n",
      "Training loss (for one batch) at step 40: 332.5366, Accuracy: 0.8129\n",
      "Training loss (for one batch) at step 50: 334.7311, Accuracy: 0.8235\n",
      "Training loss (for one batch) at step 60: 344.7426, Accuracy: 0.8259\n",
      "Training loss (for one batch) at step 70: 369.7178, Accuracy: 0.8212\n",
      "Training loss (for one batch) at step 80: 394.8882, Accuracy: 0.8115\n",
      "Training loss (for one batch) at step 90: 354.8694, Accuracy: 0.8094\n",
      "Training loss (for one batch) at step 100: 346.4676, Accuracy: 0.8128\n",
      "Training loss (for one batch) at step 110: 349.2479, Accuracy: 0.8134\n",
      "---- Training ----\n",
      "Training loss: 118.4483\n",
      "Training acc over epoch: 0.8129\n",
      "---- Validation ----\n",
      "Validation loss: 46.0531\n",
      "Validation acc: 0.7509\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 370.7432, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 368.3979, Accuracy: 0.7905\n",
      "Training loss (for one batch) at step 20: 337.1190, Accuracy: 0.7872\n",
      "Training loss (for one batch) at step 30: 347.0961, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 40: 335.0119, Accuracy: 0.8142\n",
      "Training loss (for one batch) at step 50: 329.1021, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 60: 351.3488, Accuracy: 0.8295\n",
      "Training loss (for one batch) at step 70: 351.8224, Accuracy: 0.8228\n",
      "Training loss (for one batch) at step 80: 368.3876, Accuracy: 0.8125\n",
      "Training loss (for one batch) at step 90: 360.2030, Accuracy: 0.8092\n",
      "Training loss (for one batch) at step 100: 348.1204, Accuracy: 0.8116\n",
      "Training loss (for one batch) at step 110: 355.8806, Accuracy: 0.8128\n",
      "---- Training ----\n",
      "Training loss: 118.8060\n",
      "Training acc over epoch: 0.8137\n",
      "---- Validation ----\n",
      "Validation loss: 38.4855\n",
      "Validation acc: 0.7485\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 392.9922, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 364.0963, Accuracy: 0.7727\n",
      "Training loss (for one batch) at step 20: 350.6387, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 30: 360.3748, Accuracy: 0.8112\n",
      "Training loss (for one batch) at step 40: 337.8486, Accuracy: 0.8239\n",
      "Training loss (for one batch) at step 50: 322.1502, Accuracy: 0.8301\n",
      "Training loss (for one batch) at step 60: 343.7620, Accuracy: 0.8315\n",
      "Training loss (for one batch) at step 70: 374.8332, Accuracy: 0.8269\n",
      "Training loss (for one batch) at step 80: 378.7639, Accuracy: 0.8187\n",
      "Training loss (for one batch) at step 90: 362.5061, Accuracy: 0.8158\n",
      "Training loss (for one batch) at step 100: 349.5496, Accuracy: 0.8181\n",
      "Training loss (for one batch) at step 110: 350.3177, Accuracy: 0.8188\n",
      "---- Training ----\n",
      "Training loss: 110.4488\n",
      "Training acc over epoch: 0.8182\n",
      "---- Validation ----\n",
      "Validation loss: 44.7341\n",
      "Validation acc: 0.7405\n",
      "Time taken: 10.70s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 388.2861, Accuracy: 0.7500\n",
      "Training loss (for one batch) at step 10: 361.3475, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 20: 346.7188, Accuracy: 0.7943\n",
      "Training loss (for one batch) at step 30: 340.4005, Accuracy: 0.8122\n",
      "Training loss (for one batch) at step 40: 331.2166, Accuracy: 0.8251\n",
      "Training loss (for one batch) at step 50: 339.5592, Accuracy: 0.8364\n",
      "Training loss (for one batch) at step 60: 355.9776, Accuracy: 0.8380\n",
      "Training loss (for one batch) at step 70: 381.0753, Accuracy: 0.8283\n",
      "Training loss (for one batch) at step 80: 364.8500, Accuracy: 0.8205\n",
      "Training loss (for one batch) at step 90: 340.8657, Accuracy: 0.8171\n",
      "Training loss (for one batch) at step 100: 339.8668, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 110: 336.7016, Accuracy: 0.8186\n",
      "---- Training ----\n",
      "Training loss: 109.3181\n",
      "Training acc over epoch: 0.8177\n",
      "---- Validation ----\n",
      "Validation loss: 47.2862\n",
      "Validation acc: 0.7477\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 368.4761, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 378.6863, Accuracy: 0.7777\n",
      "Training loss (for one batch) at step 20: 347.6229, Accuracy: 0.7984\n",
      "Training loss (for one batch) at step 30: 322.7035, Accuracy: 0.8110\n",
      "Training loss (for one batch) at step 40: 339.3337, Accuracy: 0.8241\n",
      "Training loss (for one batch) at step 50: 320.8171, Accuracy: 0.8355\n",
      "Training loss (for one batch) at step 60: 334.8094, Accuracy: 0.8379\n",
      "Training loss (for one batch) at step 70: 359.4233, Accuracy: 0.8308\n",
      "Training loss (for one batch) at step 80: 366.4343, Accuracy: 0.8220\n",
      "Training loss (for one batch) at step 90: 342.8128, Accuracy: 0.8205\n",
      "Training loss (for one batch) at step 100: 331.8554, Accuracy: 0.8214\n",
      "Training loss (for one batch) at step 110: 352.9133, Accuracy: 0.8217\n",
      "---- Training ----\n",
      "Training loss: 107.5518\n",
      "Training acc over epoch: 0.8220\n",
      "---- Validation ----\n",
      "Validation loss: 42.5986\n",
      "Validation acc: 0.7603\n",
      "Time taken: 10.36s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 371.5376, Accuracy: 0.7812\n",
      "Training loss (for one batch) at step 10: 368.8527, Accuracy: 0.7791\n",
      "Training loss (for one batch) at step 20: 340.8697, Accuracy: 0.7894\n",
      "Training loss (for one batch) at step 30: 331.5790, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 40: 337.3459, Accuracy: 0.8228\n",
      "Training loss (for one batch) at step 50: 309.1928, Accuracy: 0.8332\n",
      "Training loss (for one batch) at step 60: 339.8433, Accuracy: 0.8366\n",
      "Training loss (for one batch) at step 70: 353.7115, Accuracy: 0.8293\n",
      "Training loss (for one batch) at step 80: 345.9409, Accuracy: 0.8223\n",
      "Training loss (for one batch) at step 90: 338.7423, Accuracy: 0.8184\n",
      "Training loss (for one batch) at step 100: 322.2323, Accuracy: 0.8208\n",
      "Training loss (for one batch) at step 110: 345.2863, Accuracy: 0.8217\n",
      "---- Training ----\n",
      "Training loss: 109.2937\n",
      "Training acc over epoch: 0.8207\n",
      "---- Validation ----\n",
      "Validation loss: 50.3408\n",
      "Validation acc: 0.7437\n",
      "Time taken: 10.31s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 374.7197, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 373.2053, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 348.6450, Accuracy: 0.7872\n",
      "Training loss (for one batch) at step 30: 328.3603, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 40: 319.6356, Accuracy: 0.8218\n",
      "Training loss (for one batch) at step 50: 321.9231, Accuracy: 0.8290\n",
      "Training loss (for one batch) at step 60: 337.0907, Accuracy: 0.8326\n",
      "Training loss (for one batch) at step 70: 361.3939, Accuracy: 0.8258\n",
      "Training loss (for one batch) at step 80: 368.5754, Accuracy: 0.8180\n",
      "Training loss (for one batch) at step 90: 335.0271, Accuracy: 0.8141\n",
      "Training loss (for one batch) at step 100: 312.8788, Accuracy: 0.8169\n",
      "Training loss (for one batch) at step 110: 356.4045, Accuracy: 0.8195\n",
      "---- Training ----\n",
      "Training loss: 108.4708\n",
      "Training acc over epoch: 0.8183\n",
      "---- Validation ----\n",
      "Validation loss: 38.0142\n",
      "Validation acc: 0.7496\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 377.9395, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 10: 379.6031, Accuracy: 0.7585\n",
      "Training loss (for one batch) at step 20: 332.5106, Accuracy: 0.7809\n",
      "Training loss (for one batch) at step 30: 330.7668, Accuracy: 0.8032\n",
      "Training loss (for one batch) at step 40: 324.6902, Accuracy: 0.8188\n",
      "Training loss (for one batch) at step 50: 311.3320, Accuracy: 0.8295\n",
      "Training loss (for one batch) at step 60: 333.5526, Accuracy: 0.8318\n",
      "Training loss (for one batch) at step 70: 372.5378, Accuracy: 0.8239\n",
      "Training loss (for one batch) at step 80: 366.7517, Accuracy: 0.8132\n",
      "Training loss (for one batch) at step 90: 347.7101, Accuracy: 0.8104\n",
      "Training loss (for one batch) at step 100: 334.7925, Accuracy: 0.8134\n",
      "Training loss (for one batch) at step 110: 315.7197, Accuracy: 0.8148\n",
      "---- Training ----\n",
      "Training loss: 110.7518\n",
      "Training acc over epoch: 0.8146\n",
      "---- Validation ----\n",
      "Validation loss: 39.1648\n",
      "Validation acc: 0.7389\n",
      "Time taken: 10.43s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 380.1339, Accuracy: 0.8047\n",
      "Training loss (for one batch) at step 10: 368.3026, Accuracy: 0.7749\n",
      "Training loss (for one batch) at step 20: 331.8589, Accuracy: 0.7965\n",
      "Training loss (for one batch) at step 30: 330.2857, Accuracy: 0.8135\n",
      "Training loss (for one batch) at step 40: 332.4773, Accuracy: 0.8239\n",
      "Training loss (for one batch) at step 50: 318.3771, Accuracy: 0.8362\n",
      "Training loss (for one batch) at step 60: 348.1066, Accuracy: 0.8397\n",
      "Training loss (for one batch) at step 70: 343.3707, Accuracy: 0.8289\n",
      "Training loss (for one batch) at step 80: 357.4906, Accuracy: 0.8221\n",
      "Training loss (for one batch) at step 90: 334.8070, Accuracy: 0.8175\n",
      "Training loss (for one batch) at step 100: 325.8188, Accuracy: 0.8200\n",
      "Training loss (for one batch) at step 110: 332.5310, Accuracy: 0.8180\n",
      "---- Training ----\n",
      "Training loss: 105.2418\n",
      "Training acc over epoch: 0.8185\n",
      "---- Validation ----\n",
      "Validation loss: 43.0799\n",
      "Validation acc: 0.7480\n",
      "Time taken: 10.28s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 358.3166, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 353.9829, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 327.2662, Accuracy: 0.7995\n",
      "Training loss (for one batch) at step 30: 315.3297, Accuracy: 0.8163\n",
      "Training loss (for one batch) at step 40: 321.1825, Accuracy: 0.8277\n",
      "Training loss (for one batch) at step 50: 323.3716, Accuracy: 0.8329\n",
      "Training loss (for one batch) at step 60: 315.2809, Accuracy: 0.8375\n",
      "Training loss (for one batch) at step 70: 370.8050, Accuracy: 0.8276\n",
      "Training loss (for one batch) at step 80: 341.2335, Accuracy: 0.8187\n",
      "Training loss (for one batch) at step 90: 339.4625, Accuracy: 0.8151\n",
      "Training loss (for one batch) at step 100: 315.9718, Accuracy: 0.8163\n",
      "Training loss (for one batch) at step 110: 325.3362, Accuracy: 0.8183\n",
      "---- Training ----\n",
      "Training loss: 104.1263\n",
      "Training acc over epoch: 0.8181\n",
      "---- Validation ----\n",
      "Validation loss: 35.2478\n",
      "Validation acc: 0.7359\n",
      "Time taken: 10.51s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 373.2951, Accuracy: 0.7578\n",
      "Training loss (for one batch) at step 10: 346.7864, Accuracy: 0.7663\n",
      "Training loss (for one batch) at step 20: 319.3569, Accuracy: 0.7824\n",
      "Training loss (for one batch) at step 30: 314.6310, Accuracy: 0.8002\n",
      "Training loss (for one batch) at step 40: 313.1274, Accuracy: 0.8148\n",
      "Training loss (for one batch) at step 50: 346.4553, Accuracy: 0.8264\n",
      "Training loss (for one batch) at step 60: 323.3928, Accuracy: 0.8334\n",
      "Training loss (for one batch) at step 70: 356.2296, Accuracy: 0.8275\n",
      "Training loss (for one batch) at step 80: 360.0949, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 90: 321.8124, Accuracy: 0.8152\n",
      "Training loss (for one batch) at step 100: 331.5569, Accuracy: 0.8178\n",
      "Training loss (for one batch) at step 110: 347.8593, Accuracy: 0.8188\n",
      "---- Training ----\n",
      "Training loss: 115.7826\n",
      "Training acc over epoch: 0.8184\n",
      "---- Validation ----\n",
      "Validation loss: 35.4044\n",
      "Validation acc: 0.7423\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 364.4417, Accuracy: 0.7969\n",
      "Training loss (for one batch) at step 10: 354.9221, Accuracy: 0.7841\n",
      "Training loss (for one batch) at step 20: 325.4256, Accuracy: 0.7984\n",
      "Training loss (for one batch) at step 30: 331.2036, Accuracy: 0.8183\n",
      "Training loss (for one batch) at step 40: 313.1955, Accuracy: 0.8255\n",
      "Training loss (for one batch) at step 50: 331.2977, Accuracy: 0.8343\n",
      "Training loss (for one batch) at step 60: 329.4083, Accuracy: 0.8376\n",
      "Training loss (for one batch) at step 70: 325.6510, Accuracy: 0.8293\n",
      "Training loss (for one batch) at step 80: 359.5624, Accuracy: 0.8193\n",
      "Training loss (for one batch) at step 90: 315.1213, Accuracy: 0.8179\n",
      "Training loss (for one batch) at step 100: 333.3120, Accuracy: 0.8226\n",
      "Training loss (for one batch) at step 110: 338.6003, Accuracy: 0.8226\n",
      "---- Training ----\n",
      "Training loss: 107.2952\n",
      "Training acc over epoch: 0.8224\n",
      "---- Validation ----\n",
      "Validation loss: 47.1371\n",
      "Validation acc: 0.7504\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 349.7064, Accuracy: 0.8281\n",
      "Training loss (for one batch) at step 10: 355.6971, Accuracy: 0.7713\n",
      "Training loss (for one batch) at step 20: 325.7935, Accuracy: 0.7928\n",
      "Training loss (for one batch) at step 30: 329.4095, Accuracy: 0.8112\n",
      "Training loss (for one batch) at step 40: 307.6678, Accuracy: 0.8256\n",
      "Training loss (for one batch) at step 50: 320.9547, Accuracy: 0.8346\n",
      "Training loss (for one batch) at step 60: 343.5544, Accuracy: 0.8385\n",
      "Training loss (for one batch) at step 70: 349.3001, Accuracy: 0.8311\n",
      "Training loss (for one batch) at step 80: 355.8536, Accuracy: 0.8193\n",
      "Training loss (for one batch) at step 90: 329.9477, Accuracy: 0.8159\n",
      "Training loss (for one batch) at step 100: 322.2779, Accuracy: 0.8187\n",
      "Training loss (for one batch) at step 110: 324.8570, Accuracy: 0.8204\n",
      "---- Training ----\n",
      "Training loss: 99.5945\n",
      "Training acc over epoch: 0.8201\n",
      "---- Validation ----\n",
      "Validation loss: 56.7560\n",
      "Validation acc: 0.7464\n",
      "Time taken: 10.57s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 350.7659, Accuracy: 0.8516\n",
      "Training loss (for one batch) at step 10: 340.2218, Accuracy: 0.7784\n",
      "Training loss (for one batch) at step 20: 320.0175, Accuracy: 0.7972\n",
      "Training loss (for one batch) at step 30: 327.2899, Accuracy: 0.8130\n",
      "Training loss (for one batch) at step 40: 297.8853, Accuracy: 0.8243\n",
      "Training loss (for one batch) at step 50: 294.7085, Accuracy: 0.8355\n",
      "Training loss (for one batch) at step 60: 320.1245, Accuracy: 0.8381\n",
      "Training loss (for one batch) at step 70: 356.3389, Accuracy: 0.8293\n",
      "Training loss (for one batch) at step 80: 347.7349, Accuracy: 0.8191\n",
      "Training loss (for one batch) at step 90: 336.8531, Accuracy: 0.8162\n",
      "Training loss (for one batch) at step 100: 303.9052, Accuracy: 0.8198\n",
      "Training loss (for one batch) at step 110: 317.5926, Accuracy: 0.8221\n",
      "---- Training ----\n",
      "Training loss: 114.4190\n",
      "Training acc over epoch: 0.8204\n",
      "---- Validation ----\n",
      "Validation loss: 38.7029\n",
      "Validation acc: 0.7515\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 354.6496, Accuracy: 0.7656\n",
      "Training loss (for one batch) at step 10: 338.7788, Accuracy: 0.7734\n",
      "Training loss (for one batch) at step 20: 349.0671, Accuracy: 0.7902\n",
      "Training loss (for one batch) at step 30: 308.4562, Accuracy: 0.8070\n",
      "Training loss (for one batch) at step 40: 317.6375, Accuracy: 0.8234\n",
      "Training loss (for one batch) at step 50: 310.3375, Accuracy: 0.8330\n",
      "Training loss (for one batch) at step 60: 320.9790, Accuracy: 0.8364\n",
      "Training loss (for one batch) at step 70: 329.1168, Accuracy: 0.8288\n",
      "Training loss (for one batch) at step 80: 351.5594, Accuracy: 0.8203\n",
      "Training loss (for one batch) at step 90: 310.1945, Accuracy: 0.8176\n",
      "Training loss (for one batch) at step 100: 301.4734, Accuracy: 0.8200\n",
      "Training loss (for one batch) at step 110: 320.1803, Accuracy: 0.8196\n",
      "---- Training ----\n",
      "Training loss: 123.3571\n",
      "Training acc over epoch: 0.8197\n",
      "---- Validation ----\n",
      "Validation loss: 53.9877\n",
      "Validation acc: 0.7504\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 361.0717, Accuracy: 0.7188\n",
      "Training loss (for one batch) at step 10: 336.9896, Accuracy: 0.7706\n",
      "Training loss (for one batch) at step 20: 308.6523, Accuracy: 0.7932\n",
      "Training loss (for one batch) at step 30: 308.0297, Accuracy: 0.8107\n",
      "Training loss (for one batch) at step 40: 297.5591, Accuracy: 0.8241\n",
      "Training loss (for one batch) at step 50: 310.1418, Accuracy: 0.8347\n",
      "Training loss (for one batch) at step 60: 324.8571, Accuracy: 0.8382\n",
      "Training loss (for one batch) at step 70: 345.3528, Accuracy: 0.8270\n",
      "Training loss (for one batch) at step 80: 336.7808, Accuracy: 0.8182\n",
      "Training loss (for one batch) at step 90: 320.0901, Accuracy: 0.8164\n",
      "Training loss (for one batch) at step 100: 312.4940, Accuracy: 0.8195\n",
      "Training loss (for one batch) at step 110: 351.6239, Accuracy: 0.8199\n",
      "---- Training ----\n",
      "Training loss: 110.1244\n",
      "Training acc over epoch: 0.8207\n",
      "---- Validation ----\n",
      "Validation loss: 63.8665\n",
      "Validation acc: 0.7501\n",
      "Time taken: 10.47s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7573\n",
      "Validation AUC: 0.7580\n",
      "Validation Balanced_ACC: 0.4166\n",
      "Validation AUCSK: 0.7761\n",
      "Validation MI: 0.1028\n",
      "Validation Normalized MI: 0.1499\n",
      "Validation Adjusted MI: 0.1499\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 630.5133, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 594.8061, Accuracy: 0.5114\n",
      "Training loss (for one batch) at step 20: 560.0387, Accuracy: 0.5056\n",
      "Training loss (for one batch) at step 30: 560.6892, Accuracy: 0.5048\n",
      "Training loss (for one batch) at step 40: 515.0499, Accuracy: 0.5042\n",
      "Training loss (for one batch) at step 50: 505.3909, Accuracy: 0.5080\n",
      "Training loss (for one batch) at step 60: 504.3572, Accuracy: 0.5100\n",
      "Training loss (for one batch) at step 70: 480.6252, Accuracy: 0.5125\n",
      "Training loss (for one batch) at step 80: 472.3816, Accuracy: 0.5123\n",
      "Training loss (for one batch) at step 90: 475.7220, Accuracy: 0.5114\n",
      "Training loss (for one batch) at step 100: 469.8789, Accuracy: 0.5082\n",
      "Training loss (for one batch) at step 110: 461.3717, Accuracy: 0.5075\n",
      "---- Training ----\n",
      "Training loss: 148.1136\n",
      "Training acc over epoch: 0.5056\n",
      "---- Validation ----\n",
      "Validation loss: 35.2885\n",
      "Validation acc: 0.5134\n",
      "Time taken: 12.09s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 459.0559, Accuracy: 0.4844\n",
      "Training loss (for one batch) at step 10: 467.5949, Accuracy: 0.5064\n",
      "Training loss (for one batch) at step 20: 468.8850, Accuracy: 0.5067\n",
      "Training loss (for one batch) at step 30: 450.9857, Accuracy: 0.5184\n",
      "Training loss (for one batch) at step 40: 452.0381, Accuracy: 0.5141\n",
      "Training loss (for one batch) at step 50: 454.9892, Accuracy: 0.5127\n",
      "Training loss (for one batch) at step 60: 450.3195, Accuracy: 0.5133\n",
      "Training loss (for one batch) at step 70: 455.0413, Accuracy: 0.5173\n",
      "Training loss (for one batch) at step 80: 449.2747, Accuracy: 0.5187\n",
      "Training loss (for one batch) at step 90: 450.4912, Accuracy: 0.5197\n",
      "Training loss (for one batch) at step 100: 445.9230, Accuracy: 0.5140\n",
      "Training loss (for one batch) at step 110: 452.4826, Accuracy: 0.5130\n",
      "---- Training ----\n",
      "Training loss: 139.4841\n",
      "Training acc over epoch: 0.5139\n",
      "---- Validation ----\n",
      "Validation loss: 34.6396\n",
      "Validation acc: 0.4713\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 448.8897, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 450.0039, Accuracy: 0.5014\n",
      "Training loss (for one batch) at step 20: 443.0980, Accuracy: 0.5115\n",
      "Training loss (for one batch) at step 30: 444.7549, Accuracy: 0.5166\n",
      "Training loss (for one batch) at step 40: 449.3133, Accuracy: 0.5187\n",
      "Training loss (for one batch) at step 50: 447.0376, Accuracy: 0.5138\n",
      "Training loss (for one batch) at step 60: 443.8340, Accuracy: 0.5142\n",
      "Training loss (for one batch) at step 70: 443.0833, Accuracy: 0.5118\n",
      "Training loss (for one batch) at step 80: 447.6978, Accuracy: 0.5092\n",
      "Training loss (for one batch) at step 90: 443.8486, Accuracy: 0.5091\n",
      "Training loss (for one batch) at step 100: 446.0347, Accuracy: 0.5114\n",
      "Training loss (for one batch) at step 110: 440.6024, Accuracy: 0.5087\n",
      "---- Training ----\n",
      "Training loss: 140.4367\n",
      "Training acc over epoch: 0.5083\n",
      "---- Validation ----\n",
      "Validation loss: 34.6806\n",
      "Validation acc: 0.4782\n",
      "Time taken: 10.59s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 444.5087, Accuracy: 0.4766\n",
      "Training loss (for one batch) at step 10: 442.2737, Accuracy: 0.5036\n",
      "Training loss (for one batch) at step 20: 445.2072, Accuracy: 0.5182\n",
      "Training loss (for one batch) at step 30: 444.9517, Accuracy: 0.5212\n",
      "Training loss (for one batch) at step 40: 444.6449, Accuracy: 0.5215\n",
      "Training loss (for one batch) at step 50: 444.3566, Accuracy: 0.5228\n",
      "Training loss (for one batch) at step 60: 443.5949, Accuracy: 0.5178\n",
      "Training loss (for one batch) at step 70: 443.5237, Accuracy: 0.5145\n",
      "Training loss (for one batch) at step 80: 443.9260, Accuracy: 0.5113\n",
      "Training loss (for one batch) at step 90: 443.2328, Accuracy: 0.5124\n",
      "Training loss (for one batch) at step 100: 443.3919, Accuracy: 0.5116\n",
      "Training loss (for one batch) at step 110: 444.8254, Accuracy: 0.5096\n",
      "---- Training ----\n",
      "Training loss: 138.7600\n",
      "Training acc over epoch: 0.5093\n",
      "---- Validation ----\n",
      "Validation loss: 34.5629\n",
      "Validation acc: 0.4979\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 442.5495, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 444.2532, Accuracy: 0.5064\n",
      "Training loss (for one batch) at step 20: 446.4362, Accuracy: 0.5275\n",
      "Training loss (for one batch) at step 30: 443.7516, Accuracy: 0.5323\n",
      "Training loss (for one batch) at step 40: 442.7142, Accuracy: 0.5314\n",
      "Training loss (for one batch) at step 50: 443.1921, Accuracy: 0.5322\n",
      "Training loss (for one batch) at step 60: 442.2786, Accuracy: 0.5300\n",
      "Training loss (for one batch) at step 70: 446.7015, Accuracy: 0.5265\n",
      "Training loss (for one batch) at step 80: 443.4797, Accuracy: 0.5231\n",
      "Training loss (for one batch) at step 90: 444.1346, Accuracy: 0.5258\n",
      "Training loss (for one batch) at step 100: 441.8853, Accuracy: 0.5250\n",
      "Training loss (for one batch) at step 110: 445.1721, Accuracy: 0.5225\n",
      "---- Training ----\n",
      "Training loss: 138.0709\n",
      "Training acc over epoch: 0.5212\n",
      "---- Validation ----\n",
      "Validation loss: 34.7193\n",
      "Validation acc: 0.4989\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 442.6570, Accuracy: 0.4375\n",
      "Training loss (for one batch) at step 10: 444.7131, Accuracy: 0.5135\n",
      "Training loss (for one batch) at step 20: 444.3193, Accuracy: 0.5301\n",
      "Training loss (for one batch) at step 30: 442.1875, Accuracy: 0.5381\n",
      "Training loss (for one batch) at step 40: 442.5338, Accuracy: 0.5459\n",
      "Training loss (for one batch) at step 50: 441.6380, Accuracy: 0.5406\n",
      "Training loss (for one batch) at step 60: 443.4918, Accuracy: 0.5393\n",
      "Training loss (for one batch) at step 70: 445.2506, Accuracy: 0.5397\n",
      "Training loss (for one batch) at step 80: 443.9008, Accuracy: 0.5378\n",
      "Training loss (for one batch) at step 90: 443.9124, Accuracy: 0.5353\n",
      "Training loss (for one batch) at step 100: 440.7404, Accuracy: 0.5333\n",
      "Training loss (for one batch) at step 110: 442.4203, Accuracy: 0.5327\n",
      "---- Training ----\n",
      "Training loss: 138.7082\n",
      "Training acc over epoch: 0.5316\n",
      "---- Validation ----\n",
      "Validation loss: 34.6318\n",
      "Validation acc: 0.5054\n",
      "Time taken: 10.47s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 440.9495, Accuracy: 0.5156\n",
      "Training loss (for one batch) at step 10: 443.0283, Accuracy: 0.5490\n",
      "Training loss (for one batch) at step 20: 443.6671, Accuracy: 0.5562\n",
      "Training loss (for one batch) at step 30: 441.0463, Accuracy: 0.5577\n",
      "Training loss (for one batch) at step 40: 440.3812, Accuracy: 0.5524\n",
      "Training loss (for one batch) at step 50: 443.1620, Accuracy: 0.5470\n",
      "Training loss (for one batch) at step 60: 437.7810, Accuracy: 0.5452\n",
      "Training loss (for one batch) at step 70: 438.7589, Accuracy: 0.5443\n",
      "Training loss (for one batch) at step 80: 439.3840, Accuracy: 0.5435\n",
      "Training loss (for one batch) at step 90: 443.0884, Accuracy: 0.5396\n",
      "Training loss (for one batch) at step 100: 437.8520, Accuracy: 0.5384\n",
      "Training loss (for one batch) at step 110: 441.9669, Accuracy: 0.5372\n",
      "---- Training ----\n",
      "Training loss: 138.4382\n",
      "Training acc over epoch: 0.5385\n",
      "---- Validation ----\n",
      "Validation loss: 34.7309\n",
      "Validation acc: 0.5099\n",
      "Time taken: 10.33s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 444.2034, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 443.3645, Accuracy: 0.5405\n",
      "Training loss (for one batch) at step 20: 439.1223, Accuracy: 0.5398\n",
      "Training loss (for one batch) at step 30: 444.6447, Accuracy: 0.5529\n",
      "Training loss (for one batch) at step 40: 439.3484, Accuracy: 0.5537\n",
      "Training loss (for one batch) at step 50: 450.2227, Accuracy: 0.5510\n",
      "Training loss (for one batch) at step 60: 440.1009, Accuracy: 0.5462\n",
      "Training loss (for one batch) at step 70: 442.4705, Accuracy: 0.5418\n",
      "Training loss (for one batch) at step 80: 440.7361, Accuracy: 0.5411\n",
      "Training loss (for one batch) at step 90: 441.4769, Accuracy: 0.5393\n",
      "Training loss (for one batch) at step 100: 435.4009, Accuracy: 0.5353\n",
      "Training loss (for one batch) at step 110: 443.4586, Accuracy: 0.5339\n",
      "---- Training ----\n",
      "Training loss: 135.9131\n",
      "Training acc over epoch: 0.5352\n",
      "---- Validation ----\n",
      "Validation loss: 34.7566\n",
      "Validation acc: 0.5099\n",
      "Time taken: 10.66s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 444.0616, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 440.0997, Accuracy: 0.5348\n",
      "Training loss (for one batch) at step 20: 439.8716, Accuracy: 0.5510\n",
      "Training loss (for one batch) at step 30: 440.7582, Accuracy: 0.5557\n",
      "Training loss (for one batch) at step 40: 435.4290, Accuracy: 0.5587\n",
      "Training loss (for one batch) at step 50: 440.6753, Accuracy: 0.5594\n",
      "Training loss (for one batch) at step 60: 442.5687, Accuracy: 0.5553\n",
      "Training loss (for one batch) at step 70: 447.7103, Accuracy: 0.5561\n",
      "Training loss (for one batch) at step 80: 441.2774, Accuracy: 0.5519\n",
      "Training loss (for one batch) at step 90: 438.8575, Accuracy: 0.5490\n",
      "Training loss (for one batch) at step 100: 436.7806, Accuracy: 0.5489\n",
      "Training loss (for one batch) at step 110: 436.5213, Accuracy: 0.5503\n",
      "---- Training ----\n",
      "Training loss: 139.9047\n",
      "Training acc over epoch: 0.5505\n",
      "---- Validation ----\n",
      "Validation loss: 34.7192\n",
      "Validation acc: 0.5398\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 443.8387, Accuracy: 0.5234\n",
      "Training loss (for one batch) at step 10: 443.8338, Accuracy: 0.5497\n",
      "Training loss (for one batch) at step 20: 439.6768, Accuracy: 0.5614\n",
      "Training loss (for one batch) at step 30: 437.2768, Accuracy: 0.5660\n",
      "Training loss (for one batch) at step 40: 434.3676, Accuracy: 0.5776\n",
      "Training loss (for one batch) at step 50: 434.1262, Accuracy: 0.5744\n",
      "Training loss (for one batch) at step 60: 441.7729, Accuracy: 0.5692\n",
      "Training loss (for one batch) at step 70: 441.6549, Accuracy: 0.5646\n",
      "Training loss (for one batch) at step 80: 443.1251, Accuracy: 0.5651\n",
      "Training loss (for one batch) at step 90: 437.2126, Accuracy: 0.5629\n",
      "Training loss (for one batch) at step 100: 436.0156, Accuracy: 0.5586\n",
      "Training loss (for one batch) at step 110: 439.9560, Accuracy: 0.5591\n",
      "---- Training ----\n",
      "Training loss: 135.9082\n",
      "Training acc over epoch: 0.5597\n",
      "---- Validation ----\n",
      "Validation loss: 33.5599\n",
      "Validation acc: 0.5599\n",
      "Time taken: 10.35s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 441.5988, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 445.4044, Accuracy: 0.5668\n",
      "Training loss (for one batch) at step 20: 435.3326, Accuracy: 0.5718\n",
      "Training loss (for one batch) at step 30: 437.6382, Accuracy: 0.5736\n",
      "Training loss (for one batch) at step 40: 432.4374, Accuracy: 0.5793\n",
      "Training loss (for one batch) at step 50: 429.7229, Accuracy: 0.5774\n",
      "Training loss (for one batch) at step 60: 434.0542, Accuracy: 0.5802\n",
      "Training loss (for one batch) at step 70: 440.7545, Accuracy: 0.5792\n",
      "Training loss (for one batch) at step 80: 442.5085, Accuracy: 0.5744\n",
      "Training loss (for one batch) at step 90: 434.3378, Accuracy: 0.5668\n",
      "Training loss (for one batch) at step 100: 431.3096, Accuracy: 0.5645\n",
      "Training loss (for one batch) at step 110: 435.6194, Accuracy: 0.5649\n",
      "---- Training ----\n",
      "Training loss: 136.0428\n",
      "Training acc over epoch: 0.5651\n",
      "---- Validation ----\n",
      "Validation loss: 34.9578\n",
      "Validation acc: 0.5454\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at step 0: 442.3161, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 442.8836, Accuracy: 0.5419\n",
      "Training loss (for one batch) at step 20: 435.3119, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 30: 432.6995, Accuracy: 0.5565\n",
      "Training loss (for one batch) at step 40: 435.7638, Accuracy: 0.5716\n",
      "Training loss (for one batch) at step 50: 435.9059, Accuracy: 0.5708\n",
      "Training loss (for one batch) at step 60: 439.7331, Accuracy: 0.5715\n",
      "Training loss (for one batch) at step 70: 441.4213, Accuracy: 0.5764\n",
      "Training loss (for one batch) at step 80: 436.6942, Accuracy: 0.5747\n",
      "Training loss (for one batch) at step 90: 438.9182, Accuracy: 0.5737\n",
      "Training loss (for one batch) at step 100: 428.9209, Accuracy: 0.5729\n",
      "Training loss (for one batch) at step 110: 436.1263, Accuracy: 0.5738\n",
      "---- Training ----\n",
      "Training loss: 133.8613\n",
      "Training acc over epoch: 0.5747\n",
      "---- Validation ----\n",
      "Validation loss: 35.2022\n",
      "Validation acc: 0.5425\n",
      "Time taken: 10.54s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at step 0: 439.4108, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 441.2307, Accuracy: 0.5618\n",
      "Training loss (for one batch) at step 20: 436.4807, Accuracy: 0.5737\n",
      "Training loss (for one batch) at step 30: 431.8224, Accuracy: 0.5806\n",
      "Training loss (for one batch) at step 40: 435.5187, Accuracy: 0.5798\n",
      "Training loss (for one batch) at step 50: 435.9383, Accuracy: 0.5795\n",
      "Training loss (for one batch) at step 60: 438.4498, Accuracy: 0.5812\n",
      "Training loss (for one batch) at step 70: 436.1753, Accuracy: 0.5825\n",
      "Training loss (for one batch) at step 80: 441.5800, Accuracy: 0.5783\n",
      "Training loss (for one batch) at step 90: 429.0495, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 100: 434.1826, Accuracy: 0.5736\n",
      "Training loss (for one batch) at step 110: 442.9258, Accuracy: 0.5741\n",
      "---- Training ----\n",
      "Training loss: 140.3169\n",
      "Training acc over epoch: 0.5743\n",
      "---- Validation ----\n",
      "Validation loss: 35.8632\n",
      "Validation acc: 0.5489\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at step 0: 440.9880, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 437.1416, Accuracy: 0.5753\n",
      "Training loss (for one batch) at step 20: 432.4580, Accuracy: 0.5818\n",
      "Training loss (for one batch) at step 30: 422.2870, Accuracy: 0.5862\n",
      "Training loss (for one batch) at step 40: 433.8652, Accuracy: 0.5901\n",
      "Training loss (for one batch) at step 50: 427.8055, Accuracy: 0.5876\n",
      "Training loss (for one batch) at step 60: 436.8894, Accuracy: 0.5902\n",
      "Training loss (for one batch) at step 70: 438.2725, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 80: 440.4863, Accuracy: 0.5883\n",
      "Training loss (for one batch) at step 90: 435.6791, Accuracy: 0.5854\n",
      "Training loss (for one batch) at step 100: 434.8471, Accuracy: 0.5833\n",
      "Training loss (for one batch) at step 110: 429.9968, Accuracy: 0.5821\n",
      "---- Training ----\n",
      "Training loss: 137.3794\n",
      "Training acc over epoch: 0.5822\n",
      "---- Validation ----\n",
      "Validation loss: 37.2405\n",
      "Validation acc: 0.5548\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at step 0: 451.1177, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 442.2832, Accuracy: 0.5732\n",
      "Training loss (for one batch) at step 20: 433.3294, Accuracy: 0.5640\n",
      "Training loss (for one batch) at step 30: 433.0716, Accuracy: 0.5688\n",
      "Training loss (for one batch) at step 40: 426.9304, Accuracy: 0.5789\n",
      "Training loss (for one batch) at step 50: 426.6727, Accuracy: 0.5843\n",
      "Training loss (for one batch) at step 60: 428.3935, Accuracy: 0.5894\n",
      "Training loss (for one batch) at step 70: 433.4569, Accuracy: 0.5901\n",
      "Training loss (for one batch) at step 80: 436.8329, Accuracy: 0.5866\n",
      "Training loss (for one batch) at step 90: 430.9678, Accuracy: 0.5805\n",
      "Training loss (for one batch) at step 100: 429.2646, Accuracy: 0.5814\n",
      "Training loss (for one batch) at step 110: 425.2997, Accuracy: 0.5788\n",
      "---- Training ----\n",
      "Training loss: 134.3141\n",
      "Training acc over epoch: 0.5776\n",
      "---- Validation ----\n",
      "Validation loss: 36.6941\n",
      "Validation acc: 0.5911\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at step 0: 443.5090, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 439.2186, Accuracy: 0.5611\n",
      "Training loss (for one batch) at step 20: 439.1285, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 30: 427.6215, Accuracy: 0.5791\n",
      "Training loss (for one batch) at step 40: 427.3303, Accuracy: 0.5892\n",
      "Training loss (for one batch) at step 50: 419.5306, Accuracy: 0.5934\n",
      "Training loss (for one batch) at step 60: 430.6994, Accuracy: 0.5972\n",
      "Training loss (for one batch) at step 70: 446.9072, Accuracy: 0.5973\n",
      "Training loss (for one batch) at step 80: 431.9406, Accuracy: 0.5946\n",
      "Training loss (for one batch) at step 90: 422.3804, Accuracy: 0.5908\n",
      "Training loss (for one batch) at step 100: 423.0016, Accuracy: 0.5906\n",
      "Training loss (for one batch) at step 110: 426.1958, Accuracy: 0.5916\n",
      "---- Training ----\n",
      "Training loss: 134.8314\n",
      "Training acc over epoch: 0.5916\n",
      "---- Validation ----\n",
      "Validation loss: 37.1737\n",
      "Validation acc: 0.5889\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at step 0: 444.6619, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 438.8212, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 20: 432.2841, Accuracy: 0.5755\n",
      "Training loss (for one batch) at step 30: 418.7106, Accuracy: 0.5915\n",
      "Training loss (for one batch) at step 40: 423.3101, Accuracy: 0.5955\n",
      "Training loss (for one batch) at step 50: 431.1342, Accuracy: 0.5954\n",
      "Training loss (for one batch) at step 60: 420.9705, Accuracy: 0.5975\n",
      "Training loss (for one batch) at step 70: 434.4415, Accuracy: 0.5971\n",
      "Training loss (for one batch) at step 80: 432.9889, Accuracy: 0.5962\n",
      "Training loss (for one batch) at step 90: 429.8665, Accuracy: 0.5919\n",
      "Training loss (for one batch) at step 100: 432.2007, Accuracy: 0.5903\n",
      "Training loss (for one batch) at step 110: 433.9254, Accuracy: 0.5877\n",
      "---- Training ----\n",
      "Training loss: 134.1966\n",
      "Training acc over epoch: 0.5873\n",
      "---- Validation ----\n",
      "Validation loss: 34.5408\n",
      "Validation acc: 0.5639\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at step 0: 439.3977, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 435.2458, Accuracy: 0.5916\n",
      "Training loss (for one batch) at step 20: 437.8411, Accuracy: 0.5897\n",
      "Training loss (for one batch) at step 30: 425.6997, Accuracy: 0.5993\n",
      "Training loss (for one batch) at step 40: 423.0735, Accuracy: 0.6006\n",
      "Training loss (for one batch) at step 50: 410.4321, Accuracy: 0.6036\n",
      "Training loss (for one batch) at step 60: 415.5725, Accuracy: 0.6048\n",
      "Training loss (for one batch) at step 70: 437.2225, Accuracy: 0.6063\n",
      "Training loss (for one batch) at step 80: 445.6990, Accuracy: 0.6025\n",
      "Training loss (for one batch) at step 90: 419.6705, Accuracy: 0.5983\n",
      "Training loss (for one batch) at step 100: 419.2530, Accuracy: 0.5972\n",
      "Training loss (for one batch) at step 110: 423.5583, Accuracy: 0.5964\n",
      "---- Training ----\n",
      "Training loss: 137.3694\n",
      "Training acc over epoch: 0.5965\n",
      "---- Validation ----\n",
      "Validation loss: 33.9028\n",
      "Validation acc: 0.5583\n",
      "Time taken: 10.48s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at step 0: 435.2525, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 434.6506, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 20: 427.6705, Accuracy: 0.5796\n",
      "Training loss (for one batch) at step 30: 417.2365, Accuracy: 0.5892\n",
      "Training loss (for one batch) at step 40: 418.2665, Accuracy: 0.5955\n",
      "Training loss (for one batch) at step 50: 408.1913, Accuracy: 0.6032\n",
      "Training loss (for one batch) at step 60: 422.4561, Accuracy: 0.6087\n",
      "Training loss (for one batch) at step 70: 430.3722, Accuracy: 0.6086\n",
      "Training loss (for one batch) at step 80: 435.7991, Accuracy: 0.6067\n",
      "Training loss (for one batch) at step 90: 421.6407, Accuracy: 0.6018\n",
      "Training loss (for one batch) at step 100: 412.7783, Accuracy: 0.6012\n",
      "Training loss (for one batch) at step 110: 427.1091, Accuracy: 0.5984\n",
      "---- Training ----\n",
      "Training loss: 130.9746\n",
      "Training acc over epoch: 0.5967\n",
      "---- Validation ----\n",
      "Validation loss: 37.3415\n",
      "Validation acc: 0.5701\n",
      "Time taken: 10.34s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at step 0: 449.5112, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 438.1103, Accuracy: 0.5959\n",
      "Training loss (for one batch) at step 20: 431.8188, Accuracy: 0.5967\n",
      "Training loss (for one batch) at step 30: 422.1691, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 40: 419.8521, Accuracy: 0.6084\n",
      "Training loss (for one batch) at step 50: 406.3370, Accuracy: 0.6106\n",
      "Training loss (for one batch) at step 60: 411.8881, Accuracy: 0.6131\n",
      "Training loss (for one batch) at step 70: 427.3613, Accuracy: 0.6158\n",
      "Training loss (for one batch) at step 80: 422.3996, Accuracy: 0.6142\n",
      "Training loss (for one batch) at step 90: 423.6850, Accuracy: 0.6104\n",
      "Training loss (for one batch) at step 100: 417.1910, Accuracy: 0.6084\n",
      "Training loss (for one batch) at step 110: 425.1776, Accuracy: 0.6049\n",
      "---- Training ----\n",
      "Training loss: 128.8761\n",
      "Training acc over epoch: 0.6039\n",
      "---- Validation ----\n",
      "Validation loss: 39.0834\n",
      "Validation acc: 0.5559\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at step 0: 428.3456, Accuracy: 0.6406\n",
      "Training loss (for one batch) at step 10: 432.6140, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 20: 425.7901, Accuracy: 0.5949\n",
      "Training loss (for one batch) at step 30: 418.2496, Accuracy: 0.5985\n",
      "Training loss (for one batch) at step 40: 408.4621, Accuracy: 0.6065\n",
      "Training loss (for one batch) at step 50: 411.0236, Accuracy: 0.6121\n",
      "Training loss (for one batch) at step 60: 426.1768, Accuracy: 0.6144\n",
      "Training loss (for one batch) at step 70: 423.4787, Accuracy: 0.6136\n",
      "Training loss (for one batch) at step 80: 424.9616, Accuracy: 0.6120\n",
      "Training loss (for one batch) at step 90: 411.4068, Accuracy: 0.6091\n",
      "Training loss (for one batch) at step 100: 411.2139, Accuracy: 0.6050\n",
      "Training loss (for one batch) at step 110: 419.5303, Accuracy: 0.6020\n",
      "---- Training ----\n",
      "Training loss: 133.6450\n",
      "Training acc over epoch: 0.6010\n",
      "---- Validation ----\n",
      "Validation loss: 39.3002\n",
      "Validation acc: 0.5715\n",
      "Time taken: 10.65s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at step 0: 425.7814, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 427.3431, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 20: 413.4678, Accuracy: 0.5990\n",
      "Training loss (for one batch) at step 30: 398.0955, Accuracy: 0.6104\n",
      "Training loss (for one batch) at step 40: 399.2484, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 50: 394.9483, Accuracy: 0.6157\n",
      "Training loss (for one batch) at step 60: 406.3453, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 70: 424.6837, Accuracy: 0.6200\n",
      "Training loss (for one batch) at step 80: 431.5052, Accuracy: 0.6171\n",
      "Training loss (for one batch) at step 90: 412.7250, Accuracy: 0.6141\n",
      "Training loss (for one batch) at step 100: 410.6650, Accuracy: 0.6112\n",
      "Training loss (for one batch) at step 110: 419.2993, Accuracy: 0.6097\n",
      "---- Training ----\n",
      "Training loss: 137.5645\n",
      "Training acc over epoch: 0.6096\n",
      "---- Validation ----\n",
      "Validation loss: 44.4496\n",
      "Validation acc: 0.5502\n",
      "Time taken: 10.50s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at step 0: 432.1536, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 427.3754, Accuracy: 0.5888\n",
      "Training loss (for one batch) at step 20: 408.1780, Accuracy: 0.6135\n",
      "Training loss (for one batch) at step 30: 410.4256, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 40: 414.6032, Accuracy: 0.6174\n",
      "Training loss (for one batch) at step 50: 393.8276, Accuracy: 0.6193\n",
      "Training loss (for one batch) at step 60: 400.3543, Accuracy: 0.6235\n",
      "Training loss (for one batch) at step 70: 426.9373, Accuracy: 0.6224\n",
      "Training loss (for one batch) at step 80: 424.1078, Accuracy: 0.6213\n",
      "Training loss (for one batch) at step 90: 414.9340, Accuracy: 0.6195\n",
      "Training loss (for one batch) at step 100: 402.9746, Accuracy: 0.6166\n",
      "Training loss (for one batch) at step 110: 412.6269, Accuracy: 0.6138\n",
      "---- Training ----\n",
      "Training loss: 132.1503\n",
      "Training acc over epoch: 0.6132\n",
      "---- Validation ----\n",
      "Validation loss: 37.2680\n",
      "Validation acc: 0.5521\n",
      "Time taken: 10.76s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at step 0: 427.3535, Accuracy: 0.5547\n",
      "Training loss (for one batch) at step 10: 417.6023, Accuracy: 0.5717\n",
      "Training loss (for one batch) at step 20: 420.0713, Accuracy: 0.5885\n",
      "Training loss (for one batch) at step 30: 411.5273, Accuracy: 0.5970\n",
      "Training loss (for one batch) at step 40: 385.2617, Accuracy: 0.6088\n",
      "Training loss (for one batch) at step 50: 396.7185, Accuracy: 0.6144\n",
      "Training loss (for one batch) at step 60: 393.6775, Accuracy: 0.6117\n",
      "Training loss (for one batch) at step 70: 415.8902, Accuracy: 0.6114\n",
      "Training loss (for one batch) at step 80: 431.0804, Accuracy: 0.6100\n",
      "Training loss (for one batch) at step 90: 412.1076, Accuracy: 0.6091\n",
      "Training loss (for one batch) at step 100: 403.1322, Accuracy: 0.6086\n",
      "Training loss (for one batch) at step 110: 398.6032, Accuracy: 0.6066\n",
      "---- Training ----\n",
      "Training loss: 133.3061\n",
      "Training acc over epoch: 0.6061\n",
      "---- Validation ----\n",
      "Validation loss: 33.8785\n",
      "Validation acc: 0.5489\n",
      "Time taken: 10.55s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at step 0: 426.1358, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 421.0994, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 20: 411.1592, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 30: 404.9339, Accuracy: 0.6237\n",
      "Training loss (for one batch) at step 40: 395.0052, Accuracy: 0.6265\n",
      "Training loss (for one batch) at step 50: 391.1828, Accuracy: 0.6296\n",
      "Training loss (for one batch) at step 60: 392.4173, Accuracy: 0.6304\n",
      "Training loss (for one batch) at step 70: 404.3454, Accuracy: 0.6271\n",
      "Training loss (for one batch) at step 80: 426.6810, Accuracy: 0.6237\n",
      "Training loss (for one batch) at step 90: 410.8917, Accuracy: 0.6213\n",
      "Training loss (for one batch) at step 100: 398.4659, Accuracy: 0.6190\n",
      "Training loss (for one batch) at step 110: 415.0662, Accuracy: 0.6142\n",
      "---- Training ----\n",
      "Training loss: 130.9654\n",
      "Training acc over epoch: 0.6135\n",
      "---- Validation ----\n",
      "Validation loss: 33.3059\n",
      "Validation acc: 0.5435\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at step 0: 427.0834, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 422.9683, Accuracy: 0.5874\n",
      "Training loss (for one batch) at step 20: 394.9212, Accuracy: 0.5986\n",
      "Training loss (for one batch) at step 30: 389.0996, Accuracy: 0.6106\n",
      "Training loss (for one batch) at step 40: 390.1772, Accuracy: 0.6139\n",
      "Training loss (for one batch) at step 50: 370.7171, Accuracy: 0.6160\n",
      "Training loss (for one batch) at step 60: 407.8969, Accuracy: 0.6196\n",
      "Training loss (for one batch) at step 70: 420.8649, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 80: 432.8366, Accuracy: 0.6161\n",
      "Training loss (for one batch) at step 90: 398.2730, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 100: 376.8579, Accuracy: 0.6111\n",
      "Training loss (for one batch) at step 110: 397.9422, Accuracy: 0.6122\n",
      "---- Training ----\n",
      "Training loss: 126.3388\n",
      "Training acc over epoch: 0.6119\n",
      "---- Validation ----\n",
      "Validation loss: 38.5109\n",
      "Validation acc: 0.5588\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at step 0: 432.0845, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 409.1620, Accuracy: 0.5945\n",
      "Training loss (for one batch) at step 20: 414.5139, Accuracy: 0.6083\n",
      "Training loss (for one batch) at step 30: 391.0588, Accuracy: 0.6144\n",
      "Training loss (for one batch) at step 40: 385.1128, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 50: 374.1509, Accuracy: 0.6190\n",
      "Training loss (for one batch) at step 60: 389.6664, Accuracy: 0.6192\n",
      "Training loss (for one batch) at step 70: 410.6562, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 80: 412.2862, Accuracy: 0.6153\n",
      "Training loss (for one batch) at step 90: 400.2310, Accuracy: 0.6120\n",
      "Training loss (for one batch) at step 100: 382.5660, Accuracy: 0.6110\n",
      "Training loss (for one batch) at step 110: 399.3019, Accuracy: 0.6082\n",
      "---- Training ----\n",
      "Training loss: 125.5738\n",
      "Training acc over epoch: 0.6067\n",
      "---- Validation ----\n",
      "Validation loss: 34.9438\n",
      "Validation acc: 0.5527\n",
      "Time taken: 10.53s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at step 0: 422.4159, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 10: 419.2094, Accuracy: 0.6030\n",
      "Training loss (for one batch) at step 20: 395.9073, Accuracy: 0.6068\n",
      "Training loss (for one batch) at step 30: 371.2780, Accuracy: 0.6142\n",
      "Training loss (for one batch) at step 40: 373.9962, Accuracy: 0.6176\n",
      "Training loss (for one batch) at step 50: 387.1234, Accuracy: 0.6236\n",
      "Training loss (for one batch) at step 60: 396.8154, Accuracy: 0.6233\n",
      "Training loss (for one batch) at step 70: 409.2338, Accuracy: 0.6194\n",
      "Training loss (for one batch) at step 80: 407.7972, Accuracy: 0.6182\n",
      "Training loss (for one batch) at step 90: 387.6591, Accuracy: 0.6132\n",
      "Training loss (for one batch) at step 100: 382.9070, Accuracy: 0.6125\n",
      "Training loss (for one batch) at step 110: 390.5962, Accuracy: 0.6109\n",
      "---- Training ----\n",
      "Training loss: 125.8169\n",
      "Training acc over epoch: 0.6098\n",
      "---- Validation ----\n",
      "Validation loss: 35.8181\n",
      "Validation acc: 0.5500\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at step 0: 416.2686, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 10: 423.6606, Accuracy: 0.6087\n",
      "Training loss (for one batch) at step 20: 387.4909, Accuracy: 0.6071\n",
      "Training loss (for one batch) at step 30: 393.3796, Accuracy: 0.6099\n",
      "Training loss (for one batch) at step 40: 367.4931, Accuracy: 0.6183\n",
      "Training loss (for one batch) at step 50: 369.7761, Accuracy: 0.6222\n",
      "Training loss (for one batch) at step 60: 390.1356, Accuracy: 0.6238\n",
      "Training loss (for one batch) at step 70: 393.9118, Accuracy: 0.6196\n",
      "Training loss (for one batch) at step 80: 383.6677, Accuracy: 0.6168\n",
      "Training loss (for one batch) at step 90: 377.4720, Accuracy: 0.6158\n",
      "Training loss (for one batch) at step 100: 370.3511, Accuracy: 0.6158\n",
      "Training loss (for one batch) at step 110: 391.3410, Accuracy: 0.6131\n",
      "---- Training ----\n",
      "Training loss: 110.5328\n",
      "Training acc over epoch: 0.6114\n",
      "---- Validation ----\n",
      "Validation loss: 34.0566\n",
      "Validation acc: 0.5545\n",
      "Time taken: 10.87s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at step 0: 405.9670, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 400.3818, Accuracy: 0.5952\n",
      "Training loss (for one batch) at step 20: 382.8206, Accuracy: 0.6023\n",
      "Training loss (for one batch) at step 30: 361.7761, Accuracy: 0.6081\n",
      "Training loss (for one batch) at step 40: 373.1836, Accuracy: 0.6138\n",
      "Training loss (for one batch) at step 50: 348.7567, Accuracy: 0.6198\n",
      "Training loss (for one batch) at step 60: 382.1634, Accuracy: 0.6223\n",
      "Training loss (for one batch) at step 70: 400.3233, Accuracy: 0.6196\n",
      "Training loss (for one batch) at step 80: 409.7398, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 90: 380.9524, Accuracy: 0.6129\n",
      "Training loss (for one batch) at step 100: 381.6461, Accuracy: 0.6110\n",
      "Training loss (for one batch) at step 110: 387.6443, Accuracy: 0.6082\n",
      "---- Training ----\n",
      "Training loss: 126.4088\n",
      "Training acc over epoch: 0.6068\n",
      "---- Validation ----\n",
      "Validation loss: 40.4188\n",
      "Validation acc: 0.5392\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at step 0: 403.8546, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 411.4352, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 20: 372.9214, Accuracy: 0.6045\n",
      "Training loss (for one batch) at step 30: 359.8270, Accuracy: 0.6101\n",
      "Training loss (for one batch) at step 40: 360.6180, Accuracy: 0.6155\n",
      "Training loss (for one batch) at step 50: 370.9557, Accuracy: 0.6193\n",
      "Training loss (for one batch) at step 60: 368.0534, Accuracy: 0.6197\n",
      "Training loss (for one batch) at step 70: 399.1773, Accuracy: 0.6173\n",
      "Training loss (for one batch) at step 80: 389.0360, Accuracy: 0.6152\n",
      "Training loss (for one batch) at step 90: 365.5070, Accuracy: 0.6145\n",
      "Training loss (for one batch) at step 100: 366.4580, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 110: 378.0787, Accuracy: 0.6101\n",
      "---- Training ----\n",
      "Training loss: 123.8195\n",
      "Training acc over epoch: 0.6087\n",
      "---- Validation ----\n",
      "Validation loss: 43.4099\n",
      "Validation acc: 0.5433\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at step 0: 397.9199, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 392.0389, Accuracy: 0.6108\n",
      "Training loss (for one batch) at step 20: 367.4834, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 30: 376.6339, Accuracy: 0.6119\n",
      "Training loss (for one batch) at step 40: 364.3434, Accuracy: 0.6174\n",
      "Training loss (for one batch) at step 50: 369.2392, Accuracy: 0.6161\n",
      "Training loss (for one batch) at step 60: 383.6017, Accuracy: 0.6182\n",
      "Training loss (for one batch) at step 70: 400.3701, Accuracy: 0.6171\n",
      "Training loss (for one batch) at step 80: 401.5985, Accuracy: 0.6144\n",
      "Training loss (for one batch) at step 90: 360.2581, Accuracy: 0.6143\n",
      "Training loss (for one batch) at step 100: 373.0702, Accuracy: 0.6127\n",
      "Training loss (for one batch) at step 110: 364.0456, Accuracy: 0.6097\n",
      "---- Training ----\n",
      "Training loss: 116.5383\n",
      "Training acc over epoch: 0.6084\n",
      "---- Validation ----\n",
      "Validation loss: 34.7256\n",
      "Validation acc: 0.5658\n",
      "Time taken: 10.67s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at step 0: 410.8242, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 423.0751, Accuracy: 0.5817\n",
      "Training loss (for one batch) at step 20: 378.1875, Accuracy: 0.5818\n",
      "Training loss (for one batch) at step 30: 365.7515, Accuracy: 0.5925\n",
      "Training loss (for one batch) at step 40: 349.9804, Accuracy: 0.6054\n",
      "Training loss (for one batch) at step 50: 330.6491, Accuracy: 0.6123\n",
      "Training loss (for one batch) at step 60: 373.5314, Accuracy: 0.6163\n",
      "Training loss (for one batch) at step 70: 378.8224, Accuracy: 0.6134\n",
      "Training loss (for one batch) at step 80: 395.8667, Accuracy: 0.6110\n",
      "Training loss (for one batch) at step 90: 378.9906, Accuracy: 0.6107\n",
      "Training loss (for one batch) at step 100: 360.9648, Accuracy: 0.6094\n",
      "Training loss (for one batch) at step 110: 375.1515, Accuracy: 0.6070\n",
      "---- Training ----\n",
      "Training loss: 125.8129\n",
      "Training acc over epoch: 0.6055\n",
      "---- Validation ----\n",
      "Validation loss: 44.4374\n",
      "Validation acc: 0.5548\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at step 0: 399.8656, Accuracy: 0.5078\n",
      "Training loss (for one batch) at step 10: 396.9177, Accuracy: 0.5788\n",
      "Training loss (for one batch) at step 20: 367.2338, Accuracy: 0.5941\n",
      "Training loss (for one batch) at step 30: 340.7193, Accuracy: 0.6033\n",
      "Training loss (for one batch) at step 40: 346.8993, Accuracy: 0.6117\n",
      "Training loss (for one batch) at step 50: 368.3565, Accuracy: 0.6141\n",
      "Training loss (for one batch) at step 60: 364.4559, Accuracy: 0.6219\n",
      "Training loss (for one batch) at step 70: 401.9128, Accuracy: 0.6184\n",
      "Training loss (for one batch) at step 80: 378.0564, Accuracy: 0.6111\n",
      "Training loss (for one batch) at step 90: 372.8145, Accuracy: 0.6109\n",
      "Training loss (for one batch) at step 100: 349.6225, Accuracy: 0.6089\n",
      "Training loss (for one batch) at step 110: 369.4083, Accuracy: 0.6068\n",
      "---- Training ----\n",
      "Training loss: 124.2523\n",
      "Training acc over epoch: 0.6060\n",
      "---- Validation ----\n",
      "Validation loss: 40.3889\n",
      "Validation acc: 0.5492\n",
      "Time taken: 10.42s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at step 0: 388.0644, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 391.2432, Accuracy: 0.5945\n",
      "Training loss (for one batch) at step 20: 372.1437, Accuracy: 0.5978\n",
      "Training loss (for one batch) at step 30: 358.8361, Accuracy: 0.6046\n",
      "Training loss (for one batch) at step 40: 346.9926, Accuracy: 0.6092\n",
      "Training loss (for one batch) at step 50: 361.8200, Accuracy: 0.6144\n",
      "Training loss (for one batch) at step 60: 375.8993, Accuracy: 0.6158\n",
      "Training loss (for one batch) at step 70: 379.8541, Accuracy: 0.6138\n",
      "Training loss (for one batch) at step 80: 400.1473, Accuracy: 0.6107\n",
      "Training loss (for one batch) at step 90: 371.7130, Accuracy: 0.6111\n",
      "Training loss (for one batch) at step 100: 355.8620, Accuracy: 0.6089\n",
      "Training loss (for one batch) at step 110: 369.1085, Accuracy: 0.6094\n",
      "---- Training ----\n",
      "Training loss: 128.7173\n",
      "Training acc over epoch: 0.6077\n",
      "---- Validation ----\n",
      "Validation loss: 35.3642\n",
      "Validation acc: 0.5626\n",
      "Time taken: 10.72s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at step 0: 387.4085, Accuracy: 0.6250\n",
      "Training loss (for one batch) at step 10: 382.6931, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 20: 356.8956, Accuracy: 0.5919\n",
      "Training loss (for one batch) at step 30: 355.8996, Accuracy: 0.6028\n",
      "Training loss (for one batch) at step 40: 349.9600, Accuracy: 0.6107\n",
      "Training loss (for one batch) at step 50: 358.0398, Accuracy: 0.6173\n",
      "Training loss (for one batch) at step 60: 366.5113, Accuracy: 0.6210\n",
      "Training loss (for one batch) at step 70: 387.7256, Accuracy: 0.6149\n",
      "Training loss (for one batch) at step 80: 402.9700, Accuracy: 0.6121\n",
      "Training loss (for one batch) at step 90: 358.9225, Accuracy: 0.6105\n",
      "Training loss (for one batch) at step 100: 377.1046, Accuracy: 0.6090\n",
      "Training loss (for one batch) at step 110: 395.2762, Accuracy: 0.6059\n",
      "---- Training ----\n",
      "Training loss: 115.8751\n",
      "Training acc over epoch: 0.6045\n",
      "---- Validation ----\n",
      "Validation loss: 39.9389\n",
      "Validation acc: 0.5486\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at step 0: 391.8979, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 10: 388.7119, Accuracy: 0.5881\n",
      "Training loss (for one batch) at step 20: 367.6693, Accuracy: 0.5960\n",
      "Training loss (for one batch) at step 30: 353.9894, Accuracy: 0.5970\n",
      "Training loss (for one batch) at step 40: 348.7647, Accuracy: 0.6029\n",
      "Training loss (for one batch) at step 50: 335.7123, Accuracy: 0.6083\n",
      "Training loss (for one batch) at step 60: 362.2945, Accuracy: 0.6123\n",
      "Training loss (for one batch) at step 70: 375.2720, Accuracy: 0.6098\n",
      "Training loss (for one batch) at step 80: 370.7674, Accuracy: 0.6066\n",
      "Training loss (for one batch) at step 90: 363.9932, Accuracy: 0.6065\n",
      "Training loss (for one batch) at step 100: 347.7846, Accuracy: 0.6064\n",
      "Training loss (for one batch) at step 110: 357.5609, Accuracy: 0.6032\n",
      "---- Training ----\n",
      "Training loss: 116.1182\n",
      "Training acc over epoch: 0.6015\n",
      "---- Validation ----\n",
      "Validation loss: 38.4500\n",
      "Validation acc: 0.5755\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at step 0: 395.9320, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 384.6807, Accuracy: 0.5994\n",
      "Training loss (for one batch) at step 20: 351.7439, Accuracy: 0.6161\n",
      "Training loss (for one batch) at step 30: 354.4413, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 40: 332.9704, Accuracy: 0.6155\n",
      "Training loss (for one batch) at step 50: 327.0232, Accuracy: 0.6187\n",
      "Training loss (for one batch) at step 60: 357.3716, Accuracy: 0.6204\n",
      "Training loss (for one batch) at step 70: 364.1285, Accuracy: 0.6154\n",
      "Training loss (for one batch) at step 80: 384.3989, Accuracy: 0.6093\n",
      "Training loss (for one batch) at step 90: 356.0722, Accuracy: 0.6083\n",
      "Training loss (for one batch) at step 100: 343.3906, Accuracy: 0.6079\n",
      "Training loss (for one batch) at step 110: 354.5721, Accuracy: 0.6058\n",
      "---- Training ----\n",
      "Training loss: 109.1956\n",
      "Training acc over epoch: 0.6044\n",
      "---- Validation ----\n",
      "Validation loss: 37.6300\n",
      "Validation acc: 0.5650\n",
      "Time taken: 10.58s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at step 0: 395.1835, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 383.7689, Accuracy: 0.5760\n",
      "Training loss (for one batch) at step 20: 346.7851, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 30: 339.4313, Accuracy: 0.6061\n",
      "Training loss (for one batch) at step 40: 346.3780, Accuracy: 0.6120\n",
      "Training loss (for one batch) at step 50: 331.8394, Accuracy: 0.6173\n",
      "Training loss (for one batch) at step 60: 355.0927, Accuracy: 0.6182\n",
      "Training loss (for one batch) at step 70: 350.7992, Accuracy: 0.6112\n",
      "Training loss (for one batch) at step 80: 385.2183, Accuracy: 0.6101\n",
      "Training loss (for one batch) at step 90: 351.0052, Accuracy: 0.6068\n",
      "Training loss (for one batch) at step 100: 339.8836, Accuracy: 0.6046\n",
      "Training loss (for one batch) at step 110: 345.4625, Accuracy: 0.6035\n",
      "---- Training ----\n",
      "Training loss: 108.9396\n",
      "Training acc over epoch: 0.6014\n",
      "---- Validation ----\n",
      "Validation loss: 44.3731\n",
      "Validation acc: 0.5446\n",
      "Time taken: 10.45s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at step 0: 365.0240, Accuracy: 0.6328\n",
      "Training loss (for one batch) at step 10: 401.5356, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 20: 338.5824, Accuracy: 0.5926\n",
      "Training loss (for one batch) at step 30: 337.2140, Accuracy: 0.5998\n",
      "Training loss (for one batch) at step 40: 325.8561, Accuracy: 0.6063\n",
      "Training loss (for one batch) at step 50: 334.1359, Accuracy: 0.6131\n",
      "Training loss (for one batch) at step 60: 332.1158, Accuracy: 0.6140\n",
      "Training loss (for one batch) at step 70: 380.1551, Accuracy: 0.6095\n",
      "Training loss (for one batch) at step 80: 368.4492, Accuracy: 0.6038\n",
      "Training loss (for one batch) at step 90: 345.8330, Accuracy: 0.6042\n",
      "Training loss (for one batch) at step 100: 328.5621, Accuracy: 0.6044\n",
      "Training loss (for one batch) at step 110: 341.6120, Accuracy: 0.6018\n",
      "---- Training ----\n",
      "Training loss: 119.9602\n",
      "Training acc over epoch: 0.6000\n",
      "---- Validation ----\n",
      "Validation loss: 55.1101\n",
      "Validation acc: 0.5513\n",
      "Time taken: 10.37s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at step 0: 385.1165, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 10: 374.7421, Accuracy: 0.5852\n",
      "Training loss (for one batch) at step 20: 361.8199, Accuracy: 0.5885\n",
      "Training loss (for one batch) at step 30: 322.7678, Accuracy: 0.6033\n",
      "Training loss (for one batch) at step 40: 335.5616, Accuracy: 0.6086\n",
      "Training loss (for one batch) at step 50: 317.7672, Accuracy: 0.6146\n",
      "Training loss (for one batch) at step 60: 352.4001, Accuracy: 0.6167\n",
      "Training loss (for one batch) at step 70: 375.8666, Accuracy: 0.6132\n",
      "Training loss (for one batch) at step 80: 367.0134, Accuracy: 0.6073\n",
      "Training loss (for one batch) at step 90: 341.5175, Accuracy: 0.6057\n",
      "Training loss (for one batch) at step 100: 326.2046, Accuracy: 0.6069\n",
      "Training loss (for one batch) at step 110: 359.4066, Accuracy: 0.6054\n",
      "---- Training ----\n",
      "Training loss: 119.8743\n",
      "Training acc over epoch: 0.6032\n",
      "---- Validation ----\n",
      "Validation loss: 40.1400\n",
      "Validation acc: 0.5610\n",
      "Time taken: 10.63s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at step 0: 377.4695, Accuracy: 0.5703\n",
      "Training loss (for one batch) at step 10: 377.4983, Accuracy: 0.5795\n",
      "Training loss (for one batch) at step 20: 350.7504, Accuracy: 0.6001\n",
      "Training loss (for one batch) at step 30: 337.3187, Accuracy: 0.6033\n",
      "Training loss (for one batch) at step 40: 324.0127, Accuracy: 0.6061\n",
      "Training loss (for one batch) at step 50: 336.1086, Accuracy: 0.6135\n",
      "Training loss (for one batch) at step 60: 342.5416, Accuracy: 0.6154\n",
      "Training loss (for one batch) at step 70: 361.5286, Accuracy: 0.6131\n",
      "Training loss (for one batch) at step 80: 375.7932, Accuracy: 0.6070\n",
      "Training loss (for one batch) at step 90: 343.6152, Accuracy: 0.6034\n",
      "Training loss (for one batch) at step 100: 322.8528, Accuracy: 0.6043\n",
      "Training loss (for one batch) at step 110: 337.8916, Accuracy: 0.6018\n",
      "---- Training ----\n",
      "Training loss: 117.2233\n",
      "Training acc over epoch: 0.6011\n",
      "---- Validation ----\n",
      "Validation loss: 46.4411\n",
      "Validation acc: 0.5553\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at step 0: 383.1654, Accuracy: 0.5938\n",
      "Training loss (for one batch) at step 10: 367.0695, Accuracy: 0.5817\n",
      "Training loss (for one batch) at step 20: 337.8887, Accuracy: 0.5919\n",
      "Training loss (for one batch) at step 30: 321.5462, Accuracy: 0.6096\n",
      "Training loss (for one batch) at step 40: 336.6283, Accuracy: 0.6155\n",
      "Training loss (for one batch) at step 50: 318.1543, Accuracy: 0.6169\n",
      "Training loss (for one batch) at step 60: 362.5357, Accuracy: 0.6171\n",
      "Training loss (for one batch) at step 70: 368.7585, Accuracy: 0.6120\n",
      "Training loss (for one batch) at step 80: 382.7405, Accuracy: 0.6061\n",
      "Training loss (for one batch) at step 90: 342.1404, Accuracy: 0.6051\n",
      "Training loss (for one batch) at step 100: 342.0417, Accuracy: 0.6034\n",
      "Training loss (for one batch) at step 110: 324.2564, Accuracy: 0.6016\n",
      "---- Training ----\n",
      "Training loss: 102.3013\n",
      "Training acc over epoch: 0.5998\n",
      "---- Validation ----\n",
      "Validation loss: 45.0204\n",
      "Validation acc: 0.5559\n",
      "Time taken: 10.32s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at step 0: 387.9214, Accuracy: 0.5312\n",
      "Training loss (for one batch) at step 10: 385.7802, Accuracy: 0.5788\n",
      "Training loss (for one batch) at step 20: 342.6803, Accuracy: 0.6038\n",
      "Training loss (for one batch) at step 30: 320.8111, Accuracy: 0.6127\n",
      "Training loss (for one batch) at step 40: 317.9981, Accuracy: 0.6124\n",
      "Training loss (for one batch) at step 50: 331.2621, Accuracy: 0.6213\n",
      "Training loss (for one batch) at step 60: 341.5084, Accuracy: 0.6171\n",
      "Training loss (for one batch) at step 70: 355.7680, Accuracy: 0.6126\n",
      "Training loss (for one batch) at step 80: 361.3864, Accuracy: 0.6089\n",
      "Training loss (for one batch) at step 90: 333.3022, Accuracy: 0.6063\n",
      "Training loss (for one batch) at step 100: 346.7267, Accuracy: 0.6064\n",
      "Training loss (for one batch) at step 110: 352.1213, Accuracy: 0.6028\n",
      "---- Training ----\n",
      "Training loss: 107.3163\n",
      "Training acc over epoch: 0.6030\n",
      "---- Validation ----\n",
      "Validation loss: 48.0587\n",
      "Validation acc: 0.5365\n",
      "Time taken: 10.56s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at step 0: 393.4393, Accuracy: 0.5859\n",
      "Training loss (for one batch) at step 10: 357.8743, Accuracy: 0.5831\n",
      "Training loss (for one batch) at step 20: 339.5090, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 30: 334.8444, Accuracy: 0.6031\n",
      "Training loss (for one batch) at step 40: 325.4398, Accuracy: 0.6117\n",
      "Training loss (for one batch) at step 50: 342.6455, Accuracy: 0.6198\n",
      "Training loss (for one batch) at step 60: 338.3465, Accuracy: 0.6189\n",
      "Training loss (for one batch) at step 70: 357.3987, Accuracy: 0.6153\n",
      "Training loss (for one batch) at step 80: 371.5468, Accuracy: 0.6112\n",
      "Training loss (for one batch) at step 90: 336.0158, Accuracy: 0.6071\n",
      "Training loss (for one batch) at step 100: 327.1926, Accuracy: 0.6058\n",
      "Training loss (for one batch) at step 110: 342.4089, Accuracy: 0.6048\n",
      "---- Training ----\n",
      "Training loss: 118.1112\n",
      "Training acc over epoch: 0.6030\n",
      "---- Validation ----\n",
      "Validation loss: 43.5180\n",
      "Validation acc: 0.5634\n",
      "Time taken: 10.79s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at step 0: 369.4305, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 360.0043, Accuracy: 0.5881\n",
      "Training loss (for one batch) at step 20: 316.1120, Accuracy: 0.6008\n",
      "Training loss (for one batch) at step 30: 325.7125, Accuracy: 0.6116\n",
      "Training loss (for one batch) at step 40: 323.1317, Accuracy: 0.6162\n",
      "Training loss (for one batch) at step 50: 313.8451, Accuracy: 0.6173\n",
      "Training loss (for one batch) at step 60: 344.8470, Accuracy: 0.6212\n",
      "Training loss (for one batch) at step 70: 358.7671, Accuracy: 0.6170\n",
      "Training loss (for one batch) at step 80: 357.6392, Accuracy: 0.6108\n",
      "Training loss (for one batch) at step 90: 328.1975, Accuracy: 0.6089\n",
      "Training loss (for one batch) at step 100: 312.9485, Accuracy: 0.6091\n",
      "Training loss (for one batch) at step 110: 339.1216, Accuracy: 0.6071\n",
      "---- Training ----\n",
      "Training loss: 111.7740\n",
      "Training acc over epoch: 0.6055\n",
      "---- Validation ----\n",
      "Validation loss: 44.3207\n",
      "Validation acc: 0.5578\n",
      "Time taken: 10.39s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at step 0: 357.2781, Accuracy: 0.5391\n",
      "Training loss (for one batch) at step 10: 400.0675, Accuracy: 0.5781\n",
      "Training loss (for one batch) at step 20: 326.4145, Accuracy: 0.5874\n",
      "Training loss (for one batch) at step 30: 313.2458, Accuracy: 0.6016\n",
      "Training loss (for one batch) at step 40: 331.5607, Accuracy: 0.6138\n",
      "Training loss (for one batch) at step 50: 316.2962, Accuracy: 0.6181\n",
      "Training loss (for one batch) at step 60: 353.1192, Accuracy: 0.6244\n",
      "Training loss (for one batch) at step 70: 354.6960, Accuracy: 0.6177\n",
      "Training loss (for one batch) at step 80: 356.5108, Accuracy: 0.6103\n",
      "Training loss (for one batch) at step 90: 321.8301, Accuracy: 0.6087\n",
      "Training loss (for one batch) at step 100: 312.1055, Accuracy: 0.6070\n",
      "Training loss (for one batch) at step 110: 317.9913, Accuracy: 0.6063\n",
      "---- Training ----\n",
      "Training loss: 114.5379\n",
      "Training acc over epoch: 0.6056\n",
      "---- Validation ----\n",
      "Validation loss: 36.7525\n",
      "Validation acc: 0.5720\n",
      "Time taken: 10.60s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at step 0: 373.9519, Accuracy: 0.4922\n",
      "Training loss (for one batch) at step 10: 360.6996, Accuracy: 0.5866\n",
      "Training loss (for one batch) at step 20: 319.4507, Accuracy: 0.5971\n",
      "Training loss (for one batch) at step 30: 316.6647, Accuracy: 0.6069\n",
      "Training loss (for one batch) at step 40: 318.0909, Accuracy: 0.6113\n",
      "Training loss (for one batch) at step 50: 325.5496, Accuracy: 0.6192\n",
      "Training loss (for one batch) at step 60: 342.0901, Accuracy: 0.6217\n",
      "Training loss (for one batch) at step 70: 348.7996, Accuracy: 0.6160\n",
      "Training loss (for one batch) at step 80: 361.0621, Accuracy: 0.6123\n",
      "Training loss (for one batch) at step 90: 325.3551, Accuracy: 0.6093\n",
      "Training loss (for one batch) at step 100: 316.5083, Accuracy: 0.6091\n",
      "Training loss (for one batch) at step 110: 352.5981, Accuracy: 0.6059\n",
      "---- Training ----\n",
      "Training loss: 124.1309\n",
      "Training acc over epoch: 0.6065\n",
      "---- Validation ----\n",
      "Validation loss: 58.7135\n",
      "Validation acc: 0.5527\n",
      "Time taken: 10.49s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at step 0: 384.8242, Accuracy: 0.5469\n",
      "Training loss (for one batch) at step 10: 371.1739, Accuracy: 0.5930\n",
      "Training loss (for one batch) at step 20: 334.0526, Accuracy: 0.6075\n",
      "Training loss (for one batch) at step 30: 355.5873, Accuracy: 0.6172\n",
      "Training loss (for one batch) at step 40: 317.7170, Accuracy: 0.6239\n",
      "Training loss (for one batch) at step 50: 300.3775, Accuracy: 0.6282\n",
      "Training loss (for one batch) at step 60: 332.1159, Accuracy: 0.6295\n",
      "Training loss (for one batch) at step 70: 350.4786, Accuracy: 0.6200\n",
      "Training loss (for one batch) at step 80: 360.8322, Accuracy: 0.6165\n",
      "Training loss (for one batch) at step 90: 340.7915, Accuracy: 0.6118\n",
      "Training loss (for one batch) at step 100: 335.0000, Accuracy: 0.6102\n",
      "Training loss (for one batch) at step 110: 343.4304, Accuracy: 0.6067\n",
      "---- Training ----\n",
      "Training loss: 108.2613\n",
      "Training acc over epoch: 0.6054\n",
      "---- Validation ----\n",
      "Validation loss: 35.4276\n",
      "Validation acc: 0.5521\n",
      "Time taken: 10.38s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at step 0: 369.1198, Accuracy: 0.5625\n",
      "Training loss (for one batch) at step 10: 375.7375, Accuracy: 0.5923\n",
      "Training loss (for one batch) at step 20: 327.2035, Accuracy: 0.6031\n",
      "Training loss (for one batch) at step 30: 332.8885, Accuracy: 0.6121\n",
      "Training loss (for one batch) at step 40: 312.0464, Accuracy: 0.6197\n",
      "Training loss (for one batch) at step 50: 308.8567, Accuracy: 0.6209\n",
      "Training loss (for one batch) at step 60: 326.3569, Accuracy: 0.6228\n",
      "Training loss (for one batch) at step 70: 359.4711, Accuracy: 0.6167\n",
      "Training loss (for one batch) at step 80: 349.1993, Accuracy: 0.6114\n",
      "Training loss (for one batch) at step 90: 338.1317, Accuracy: 0.6101\n",
      "Training loss (for one batch) at step 100: 313.6543, Accuracy: 0.6076\n",
      "Training loss (for one batch) at step 110: 331.2903, Accuracy: 0.6061\n",
      "---- Training ----\n",
      "Training loss: 112.4059\n",
      "Training acc over epoch: 0.6040\n",
      "---- Validation ----\n",
      "Validation loss: 45.6737\n",
      "Validation acc: 0.5637\n",
      "Time taken: 10.54s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.5795\n",
      "Validation AUC: 0.5784\n",
      "Validation Balanced_ACC: 0.3907\n",
      "Validation AUCSK: 0.7586\n",
      "Validation MI: 0.0942\n",
      "Validation Normalized MI: 0.1373\n",
      "Validation Adjusted MI: 0.1373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import normalized_mutual_info_score, mutual_info_score, adjusted_mutual_info_score\n",
    "#l1 =0.0001\n",
    "NUM_RUNS = 10\n",
    "N_EPOCHS = 50\n",
    "ACC = np.zeros(NUM_RUNS)\n",
    "AUC = np.zeros(NUM_RUNS)\n",
    "AUCSK = np.zeros(NUM_RUNS)\n",
    "MI = np.zeros(NUM_RUNS)\n",
    "NMI = np.zeros(NUM_RUNS)\n",
    "AMI = np.zeros(NUM_RUNS)\n",
    "BACC = np.zeros(NUM_RUNS)\n",
    "BACC1 = []\n",
    "MI1 = []\n",
    "NMI1 =[]\n",
    "AMI1 = []\n",
    "AUCSK1 = []\n",
    "#model = create_model()\n",
    "K=2\n",
    "R=5\n",
    "\n",
    "val_acc = np.zeros(NUM_RUNS)\n",
    "AUC= np.zeros(NUM_RUNS)\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "  MA = MultipleAnnotators_Classification(2, 5, 0.1)\n",
    "  model =  create_model()\n",
    "  model = MA.fit(model, train_batches_MA, val_batches_MA, N_EPOCHS)\n",
    "  #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n",
    "  ACC[i] = MA.eval_model(test_batches_MA)\n",
    "  print(\"Validation acc: %.4f\" % (float(ACC[i]),))\n",
    "    \n",
    " #AUC =======================\n",
    "  val_AUC_metric = tf.keras.metrics.AUC( from_logits = True)\n",
    "  for x_batch_val, y_batch_val in test_batches_MA:\n",
    "      val_logits = model(x_batch_val.numpy(), training=False)\n",
    "      # tf.print(y_batch_val)\n",
    "      val_AUC_metric.update_state(y_batch_val, val_logits[:,:K].numpy().argmax(axis=1).astype('float'))\n",
    "      BACC1.append(balanced_accuracy_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True))\n",
    "      MI1.append(mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n",
    "      NMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n",
    "      AMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n",
    "      AUCSK1.append(roc_auc_score(ook(y_batch_val.numpy()), val_logits[:,:K].numpy().astype('float')))\n",
    "    \n",
    "\n",
    "  val_AUC = val_AUC_metric.result()\n",
    "  val_AUC_metric.reset_states()\n",
    "  val_AUC = val_AUC.numpy()\n",
    "  print(\"Validation AUC: %.4f\" % (float(val_AUC),))\n",
    "  AUC[i] = val_AUC\n",
    "  #===================================================\n",
    "    \n",
    "    \n",
    "\n",
    "  # balanced. Accurcy\n",
    "  BACC[i] = np.array(BACC1).mean() # balanced_accuracy_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True)\n",
    "  print(\"Validation Balanced_ACC: %.4f\" % (float(BACC[i])))\n",
    "  AUCSK[i] = np.array(AUCSK1).mean() \n",
    "  print(\"Validation AUCSK: %.4f\" % (float( AUCSK[i] )))\n",
    "  #MI\n",
    "  \n",
    "  MI[i] =  np.array(MI1).mean()  #mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n",
    "  print(\"Validation MI: %.4f\" % (float(MI[i]),))\n",
    "  NMI[i] =  np.array(NMI1).mean()   #normalized_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n",
    "  print(\"Validation Normalized MI: %.4f\" % (float(NMI[i]),))\n",
    "  AMI[i]= np.array(AMI1).mean()  #adjusted_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n",
    "  print(\"Validation Adjusted MI: %.4f\" % (float(AMI[i]),))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(val_acc)\n",
    "#df.to_csv('/content/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd0acbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T21:38:40.659473Z",
     "iopub.status.busy": "2023-02-14T21:38:40.657688Z",
     "iopub.status.idle": "2023-02-14T21:38:40.666922Z",
     "shell.execute_reply": "2023-02-14T21:38:40.665985Z"
    },
    "papermill": {
     "duration": 0.351973,
     "end_time": "2023-02-14T21:38:40.669156",
     "exception": false,
     "start_time": "2023-02-14T21:38:40.317183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ook(y_batch_val.numpy()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d615e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T21:38:41.415510Z",
     "iopub.status.busy": "2023-02-14T21:38:41.415147Z",
     "iopub.status.idle": "2023-02-14T21:38:41.421979Z",
     "shell.execute_reply": "2023-02-14T21:38:41.421071Z"
    },
    "papermill": {
     "duration": 0.416998,
     "end_time": "2023-02-14T21:38:41.424372",
     "exception": false,
     "start_time": "2023-02-14T21:38:41.007374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_logits.numpy().astype('float').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4290114b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T21:38:42.097227Z",
     "iopub.status.busy": "2023-02-14T21:38:42.096858Z",
     "iopub.status.idle": "2023-02-14T21:38:42.110490Z",
     "shell.execute_reply": "2023-02-14T21:38:42.109477Z"
    },
    "papermill": {
     "duration": 0.352774,
     "end_time": "2023-02-14T21:38:42.113264",
     "exception": false,
     "start_time": "2023-02-14T21:38:41.760490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  69.48\n",
      "Average std:  6.7\n",
      "==============================================\n",
      "Average AUC:  69.54\n",
      "Average AUC std:  6.76\n",
      "Average std:  6.7\n",
      "==============================================\n",
      "Average AUCSK:  79.09\n",
      "Average AUCSK std:  2.5\n",
      "==============================================\n",
      "Average Balanced Accuracy:  44.13\n",
      "Average std:  3.88\n",
      "==============================================\n",
      "Average MI:  11.23\n",
      "Average std:  1.47\n",
      "==============================================\n",
      "Average Normalized MI:  16.36\n",
      "Average std:  2.13\n",
      "==============================================\n",
      "Average Ajdusted MI:  16.36\n",
      "Average std:  2.13\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy: ', np.round( ACC.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std( ACC),4)*100)\n",
    "print('==============================================')\n",
    "print('Average AUC: ', np.round( AUC.mean(),4)*100) \n",
    "print('Average AUC std: ',np.round(np.std( AUC),4)*100)\n",
    "print('Average std: ',np.round(np.std( ACC),4)*100)\n",
    "print('==============================================')\n",
    "print('Average AUCSK: ', np.round( AUCSK.mean(),4)*100) \n",
    "print('Average AUCSK std: ',np.round(np.std( AUCSK),4)*100)\n",
    "print('==============================================')\n",
    "print('Average Balanced Accuracy: ', np.round( BACC.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std( BACC),4)*100)\n",
    "print('==============================================')\n",
    "print('Average MI: ', np.round( MI.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std(MI),4)*100)\n",
    "print('==============================================')\n",
    "print('Average Normalized MI: ', np.round( NMI.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std(NMI),4)*100)\n",
    "print('==============================================')\n",
    "print('Average Ajdusted MI: ', np.round( AMI.mean(),4)*100) \n",
    "print('Average std: ',np.round(np.std(AMI),4)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5493.502268,
   "end_time": "2023-02-14T21:38:45.758134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-14T20:07:12.255866",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
