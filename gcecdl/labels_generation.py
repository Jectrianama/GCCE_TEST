# -*- coding: utf-8 -*-
"""labels_generation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Vn5eMujyFsoOiy3aXsDyLv8zLsHb5_H
"""

import random
import warnings
import numpy as np
#import climin
from functools import partial
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# Defining the Sigmoid function and Softmax function


def Sigmoid(f_r):
    lam_r = 1 / (1 + np.exp(-f_r))
    return lam_r


def MAjVot(Y, K):
    N, R = Y.shape
    Yhat = np.zeros((N, 1))
    for n in range(N):
        votes = np.zeros((K, 1))
        for r in range(R):
            for k in range(K):
                if Y[n, r] == k + 1:
                    votes[k] = votes[k] + 1
        Yhat[n] = np.argmax(votes) + 1
    return Yhat


def MA_Clas_Gen(Xtrain, ytrain, R, NrP):

    N = len(ytrain)
    K = len(np.unique(ytrain))
    Kn = np.unique(ytrain)
    aux = 0
    A = np.zeros((K, 1))
    for k in Kn:
        A[aux] = (ytrain == k).sum()
        aux = aux + 1
    per = np.min(A)
    if N < 25000:
        Xtrain = TSNE(n_components=1, perplexity=per / 2).fit_transform(Xtrain)
    else:
        Xtrain = np.sum(Xtrain, 1)

    Xtrain = Xtrain - Xtrain.min()
    #print(Xtrain.min(), Xtrain.max())
    Xtrain = Xtrain / Xtrain.max()
    Xtrain = Xtrain.reshape((N, 1))
    yprueba = np.ones((N, 1))

    u_q = np.empty((Xtrain.shape[0], 3))
    u_q[:, 0, None] = 4.5 * np.cos(2 * np.pi * Xtrain + 1.5 * np.pi) - \
        3 * np.sin(4.3 * np.pi * Xtrain + 0.3 * np.pi)

    u_q[:, 1, None] = 4.5 * np.cos(1.5 * np.pi * Xtrain + 0.5 * np.pi) + \
        5 * np.sin(3 * np.pi * Xtrain + 1.5 * np.pi)

    u_q[:, 2, None] = 1

    W = []
    # q=1
    Wq1 = np.array(([[0.4], [0.7], [-0.5], [0], [-0.7]]))
    W.append(Wq1)
    # q=2
    Wq2 = np.array(([[0.4], [-1.0], [-0.1], [-0.8], [1.0]]))
    W.append(Wq2)
    Wq3 = np.array(([[3.1], [-1.8], [-0.6], [-1.2], [1.0]]))
    W.append(Wq3)

    F_r = []
    Lam_r = []
    for r in range(R):
        f_r = np.zeros((Xtrain.shape[0], 1))
        # rho_r = np.zeros((Xtrain.shape[0], 1))
        for q in range(3):
            f_r += W[q][r].T * u_q[:, q, None]
        F_r.append(f_r)
        lam_r = Sigmoid(f_r)
        lam_r[lam_r > 0.5] = 1
        lam_r[lam_r <= 0.5] = 0
        Lam_r.append(lam_r)
    plt.plot(Xtrain, Lam_r[2], 'rx')
    plt.show()
    seed = 0
    np.random.seed(seed)
    Ytrain = np.ones((N, R))
    for r in range(R):
        aux = ytrain.copy()
        for n in range(N):
            if Lam_r[r][n] == 0:
                labels = np.arange(1, K + 1)
                a = np.where(labels == ytrain[n])
                labels = np.delete(labels, a)
                idxlabels = np.random.permutation(K - 1)
                aux[n] = labels[idxlabels[0]]
        Ytrain[:, r] = aux.flatten()

    # Ytrain = (Ytrain*maxy) + miny

    iAnn = np.zeros((N, R), dtype=int)  # this indicates if the annotator r labels the nth sample.
    Nr = np.ones((R), dtype=int) * int(np.floor(N * NrP))
    for r in range(R):
        if r < R - 1:
            indexR = np.random.permutation(range(N))[:Nr[r]]
            iAnn[indexR, r] = 1
        else:
            iSimm = np.sum(iAnn, axis=1)
            idxZero = np.asarray([i for (i, val) in enumerate(iSimm) if val == 0])
            Nzeros = idxZero.shape[0]
            idx2Choose = np.arange(N)
            if Nzeros == 0:
                indexR = np.random.permutation(range(N))[:Nr[r]]
                iAnn[indexR, r] = 1
            else:
                idx2Choose = np.delete(idx2Choose, idxZero)
                N2chose = idx2Choose.shape[0]
                idxNoZero = np.random.permutation(N2chose)[:(Nr[r] - Nzeros)]
                idxTot = np.concatenate((idxZero, idx2Choose[idxNoZero]))
                iAnn[idxTot, r] = 1

    # Now, we verify that all the samples were labeled at least once
    Nr = (np.sum(iAnn, 0))
    iSimm = np.sum(iAnn, axis=1)
    if np.asarray([i for (i, val) in enumerate(iSimm) if val == 0]).sum() == 0:
        ValueError("all the samples must be labeled at least once")

    # Finally, if iAnn=0 we assign a reference value to indicate a missing value
    Vref = -1e-20
    for r in range(R):
        Ytrain[iAnn[:, r] == 0, r] = Vref

    return Ytrain, iAnn, Lam_r


def CrossVal(X, pp, Nk):
    N = X.shape[0]
    Ntr = int(N * pp)
    Nte = N - Ntr
    idxtr = np.zeros((Ntr, Nk))
    idxte = np.zeros((Nte, Nk))

    for i in range(Nk):
        index = np.random.permutation(range(N))
        idxtr[:, i] = index[:Ntr]
        idxte[:, i] = index[Ntr:]

    return idxtr, idxte
