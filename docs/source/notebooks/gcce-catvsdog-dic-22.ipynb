{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jenntm/gcce-catvsdog-dic-22?scriptVersionId=119189014\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"25d2dcfd","metadata":{"id":"oAuRT75GdLFw","papermill":{"duration":0.006961,"end_time":"2023-02-14T21:49:52.178045","exception":false,"start_time":"2023-02-14T21:49:52.171084","status":"completed"},"tags":[]},"source":["# Cats vs. Dogs Class dataset for multiple annotators\n"]},{"cell_type":"markdown","id":"d4812ad6","metadata":{"id":"9rK94t33nwDC","papermill":{"duration":0.005611,"end_time":"2023-02-14T21:49:52.189442","exception":false,"start_time":"2023-02-14T21:49:52.183831","status":"completed"},"tags":[]},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"id":"096d9a4d","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:49:52.202932Z","iopub.status.busy":"2023-02-14T21:49:52.202089Z","iopub.status.idle":"2023-02-14T21:49:53.054241Z","shell.execute_reply":"2023-02-14T21:49:53.053255Z"},"papermill":{"duration":0.861777,"end_time":"2023-02-14T21:49:53.056727","exception":false,"start_time":"2023-02-14T21:49:52.19495","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import OneHotEncoder\n","from scipy.stats import mode \n","import numpy as np\n","\n","def ook(t):\n","  lb = LabelBinarizer()\n","  y_ook = lb.fit_transform(t)  \n","\n","  if len(np.unique(t))==2:\n","    y_ook = np.concatenate((1-y_ook.astype(bool), y_ook), axis = 1) \n","\n","  return y_ook"]},{"cell_type":"code","execution_count":2,"id":"58efbca9","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:49:53.069473Z","iopub.status.busy":"2023-02-14T21:49:53.069181Z","iopub.status.idle":"2023-02-14T21:49:59.12671Z","shell.execute_reply":"2023-02-14T21:49:59.125771Z"},"id":"zSyMHuCVys-O","papermill":{"duration":6.066491,"end_time":"2023-02-14T21:49:59.129088","exception":false,"start_time":"2023-02-14T21:49:53.062597","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n","from keras.utils.vis_utils import plot_model\n","from tensorflow.keras import regularizers\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy as sp\n","import cv2\n","import os\n","import time\n","import sys"]},{"cell_type":"code","execution_count":3,"id":"e64e1f98","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:49:59.143699Z","iopub.status.busy":"2023-02-14T21:49:59.141802Z","iopub.status.idle":"2023-02-14T21:49:59.146821Z","shell.execute_reply":"2023-02-14T21:49:59.145894Z"},"id":"-E1MJt8cxlwg","outputId":"ea43c1c9-075f-44de-d2d8-e135799b6630","papermill":{"duration":0.013892,"end_time":"2023-02-14T21:49:59.148906","exception":false,"start_time":"2023-02-14T21:49:59.135014","status":"completed"},"tags":[]},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"id":"fe4e3de5","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:49:59.161654Z","iopub.status.busy":"2023-02-14T21:49:59.160768Z","iopub.status.idle":"2023-02-14T21:49:59.16543Z","shell.execute_reply":"2023-02-14T21:49:59.164641Z"},"id":"QJPvjdZ-f8ca","papermill":{"duration":0.012939,"end_time":"2023-02-14T21:49:59.167348","exception":false,"start_time":"2023-02-14T21:49:59.154409","status":"completed"},"tags":[]},"outputs":[],"source":["# os.chdir('/content/drive/Shareddrives/Multiple Anotators/CrowdLayer/Notebooks')\n","# cwd = os.getcwd()\n","# sys.path.append(\"../Models\")\n","\n","\n","# from Multiple_Annotators_C import MultipleAnnotators_Classification\n","\n","#import sys\n","#sys.path.insert(1, '../input/multiple-annotators-c/')\n","#os.chdir('/Multiple Anotators-c/')\n","#cwd = os.getcwd()\n","#sys.path.append('/input/multiple-annotators-c')\n","#from Multiple_Annotators_C import MultipleAnnotators_Classification\n","\n","# seed_value= 12321 \n","# from numpy.random import seed\n","# seed(seed_value)\n","# tf.random.set_seed(seed_value)"]},{"cell_type":"markdown","id":"59b0d7e8","metadata":{"id":"6Un5nFWgnyem","papermill":{"duration":0.005405,"end_time":"2023-02-14T21:49:59.178293","exception":false,"start_time":"2023-02-14T21:49:59.172888","status":"completed"},"tags":[]},"source":["## Download and Prepare the Dataset\n","\n","We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset and we can load it via Tensorflow Datasets. The images are labeled 0 for cats and 1 for dogs."]},{"cell_type":"markdown","id":"2775c0fa","metadata":{"id":"Gw6K2Uey06kh","papermill":{"duration":0.006554,"end_time":"2023-02-14T21:49:59.190341","exception":false,"start_time":"2023-02-14T21:49:59.183787","status":"completed"},"tags":[]},"source":["# Multiple annotators model"]},{"cell_type":"code","execution_count":5,"id":"0e2b9496","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:49:59.203073Z","iopub.status.busy":"2023-02-14T21:49:59.202352Z","iopub.status.idle":"2023-02-14T21:50:01.934312Z","shell.execute_reply":"2023-02-14T21:50:01.933387Z"},"id":"xam4REp209Sd","papermill":{"duration":2.740733,"end_time":"2023-02-14T21:50:01.936509","exception":false,"start_time":"2023-02-14T21:49:59.195776","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-14 21:49:59.295511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:49:59.462904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:49:59.463771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:49:59.464974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-14 21:49:59.470654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:49:59.471346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:49:59.472030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:50:01.493675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:50:01.494509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:50:01.495200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-14 21:50:01.495814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["\n","validation_data = tf.data.experimental.load('/kaggle/input/catsvsdog-ma/cats_dogs_Te')\n","train_data_MA = tf.data.experimental.load('/kaggle/input/catsvsdog-ma/cats_dogs_MA_Tr_1')\n","\n"]},{"cell_type":"code","execution_count":6,"id":"7343aa96","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:01.950801Z","iopub.status.busy":"2023-02-14T21:50:01.9493Z","iopub.status.idle":"2023-02-14T21:50:01.96053Z","shell.execute_reply":"2023-02-14T21:50:01.959736Z"},"id":"D_S0EJ3mFdfK","outputId":"9ed3c2c7-50b4-4445-a01e-c9a3d780c403","papermill":{"duration":0.019933,"end_time":"2023-02-14T21:50:01.962647","exception":false,"start_time":"2023-02-14T21:50:01.942714","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["18610"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["image_count = tf.data.experimental.cardinality(train_data_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count"]},{"cell_type":"code","execution_count":7,"id":"a3f787da","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:01.975623Z","iopub.status.busy":"2023-02-14T21:50:01.975303Z","iopub.status.idle":"2023-02-14T21:50:01.982448Z","shell.execute_reply":"2023-02-14T21:50:01.981538Z"},"id":"ctjLei0TxcVh","outputId":"6f578b73-ebdf-4465-91c7-2adb7d127174","papermill":{"duration":0.015978,"end_time":"2023-02-14T21:50:01.984397","exception":false,"start_time":"2023-02-14T21:50:01.968419","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["4652"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["image_count1 = tf.data.experimental.cardinality(validation_data).numpy() # los datos de training son 18610\n","image_count1"]},{"cell_type":"code","execution_count":8,"id":"2911ba2b","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:01.998351Z","iopub.status.busy":"2023-02-14T21:50:01.996876Z","iopub.status.idle":"2023-02-14T21:50:02.001983Z","shell.execute_reply":"2023-02-14T21:50:02.001185Z"},"id":"opk5MXl4IwjC","papermill":{"duration":0.013583,"end_time":"2023-02-14T21:50:02.003851","exception":false,"start_time":"2023-02-14T21:50:01.990268","status":"completed"},"tags":[]},"outputs":[],"source":["#X_test = [validation_data[i][0] for i in range(image_count1)]\n","#Y_true_test = [validation_data[i][1] for i in range(image_count1)]\n","#Y_true_test = np.asarray([aux[1].numpy() for aux  in validation_data])\n","#X_test = np.asarray([aux[0].numpy() for aux  in validation_data])"]},{"cell_type":"code","execution_count":9,"id":"dc6d818a","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:02.017517Z","iopub.status.busy":"2023-02-14T21:50:02.016162Z","iopub.status.idle":"2023-02-14T21:50:02.023373Z","shell.execute_reply":"2023-02-14T21:50:02.022558Z"},"id":"-BydcVOQxcVh","outputId":"8c1b4ed2-7c43-4675-f055-f9e4e3f5b3dd","papermill":{"duration":0.015622,"end_time":"2023-02-14T21:50:02.025313","exception":false,"start_time":"2023-02-14T21:50:02.009691","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["18610"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["image_count"]},{"cell_type":"code","execution_count":10,"id":"7e1962ac","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:02.038193Z","iopub.status.busy":"2023-02-14T21:50:02.037936Z","iopub.status.idle":"2023-02-14T21:50:02.04559Z","shell.execute_reply":"2023-02-14T21:50:02.044802Z"},"id":"HdFme6fdxcVh","papermill":{"duration":0.01613,"end_time":"2023-02-14T21:50:02.047541","exception":false,"start_time":"2023-02-14T21:50:02.031411","status":"completed"},"tags":[]},"outputs":[],"source":["val_size = int(image_count * 0.2)\n","train_ds_MA = train_data_MA.skip(val_size)\n","val_ds_MA = train_data_MA.take(val_size)"]},{"cell_type":"code","execution_count":11,"id":"89d7b27e","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:02.060145Z","iopub.status.busy":"2023-02-14T21:50:02.059891Z","iopub.status.idle":"2023-02-14T21:50:02.071025Z","shell.execute_reply":"2023-02-14T21:50:02.070217Z"},"id":"aVHIlFpgxcVi","papermill":{"duration":0.019581,"end_time":"2023-02-14T21:50:02.072896","exception":false,"start_time":"2023-02-14T21:50:02.053315","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 100\n","train_batches_MA = train_ds_MA.shuffle(1024).batch(batch_size)\n","val_batches_MA = val_ds_MA.shuffle(1024).batch(batch_size)\n","test_batches_MA = validation_data.shuffle(1024).batch(batch_size)"]},{"cell_type":"code","execution_count":12,"id":"318b8f22","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:02.085801Z","iopub.status.busy":"2023-02-14T21:50:02.08552Z","iopub.status.idle":"2023-02-14T21:50:02.092393Z","shell.execute_reply":"2023-02-14T21:50:02.091579Z"},"id":"GsB4EA2-xcVi","outputId":"2d45809e-a9cc-408f-9a8b-745e8fe850e9","papermill":{"duration":0.015546,"end_time":"2023-02-14T21:50:02.094348","exception":false,"start_time":"2023-02-14T21:50:02.078802","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["14888"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["image_count = tf.data.experimental.cardinality(train_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count"]},{"cell_type":"code","execution_count":13,"id":"133b7ad5","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:02.107181Z","iopub.status.busy":"2023-02-14T21:50:02.106921Z","iopub.status.idle":"2023-02-14T21:50:02.11476Z","shell.execute_reply":"2023-02-14T21:50:02.113954Z"},"id":"Hk33DzwkxcVi","outputId":"aad91eec-842c-4995-de90-5bb715539b6a","papermill":{"duration":0.016488,"end_time":"2023-02-14T21:50:02.116656","exception":false,"start_time":"2023-02-14T21:50:02.100168","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["3722"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["image_count_val = tf.data.experimental.cardinality(val_ds_MA).numpy() # los datos de training son 18610 usar subconjunto de 5000\n","image_count_val"]},{"cell_type":"code","execution_count":null,"id":"e522ed6f","metadata":{"id":"UMeK3NG3xcVi","papermill":{"duration":0.00573,"end_time":"2023-02-14T21:50:02.128384","exception":false,"start_time":"2023-02-14T21:50:02.122654","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"id":"9e233165","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:02.141745Z","iopub.status.busy":"2023-02-14T21:50:02.140995Z","iopub.status.idle":"2023-02-14T21:50:23.079225Z","shell.execute_reply":"2023-02-14T21:50:23.077656Z"},"id":"uvwc7eixxcVi","outputId":"d7766078-8c40-41ed-fb01-66b5f62a07f1","papermill":{"duration":20.947302,"end_time":"2023-02-14T21:50:23.081597","exception":false,"start_time":"2023-02-14T21:50:02.134295","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-14 21:50:02.257325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2023-02-14 21:50:17.128965: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n","2023-02-14 21:50:21.116166: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.76      0.73        45\n","           1       0.79      0.75      0.77        55\n","\n","    accuracy                           0.75       100\n","   macro avg       0.75      0.75      0.75       100\n","weighted avg       0.75      0.75      0.75       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.87      0.89        45\n","           1       0.89      0.93      0.91        55\n","\n","    accuracy                           0.90       100\n","   macro avg       0.90      0.90      0.90       100\n","weighted avg       0.90      0.90      0.90       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.51      0.57        45\n","           1       0.66      0.76      0.71        55\n","\n","    accuracy                           0.65       100\n","   macro avg       0.65      0.64      0.64       100\n","weighted avg       0.65      0.65      0.64       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.22      0.35        45\n","           1       0.60      0.96      0.74        55\n","\n","    accuracy                           0.63       100\n","   macro avg       0.72      0.59      0.55       100\n","weighted avg       0.71      0.63      0.57       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.89      0.88        45\n","           1       0.91      0.89      0.90        55\n","\n","    accuracy                           0.89       100\n","   macro avg       0.89      0.89      0.89       100\n","weighted avg       0.89      0.89      0.89       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.70      0.76        50\n","           1       0.74      0.86      0.80        50\n","\n","    accuracy                           0.78       100\n","   macro avg       0.79      0.78      0.78       100\n","weighted avg       0.79      0.78      0.78       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.78      0.84        50\n","           1       0.81      0.92      0.86        50\n","\n","    accuracy                           0.85       100\n","   macro avg       0.86      0.85      0.85       100\n","weighted avg       0.86      0.85      0.85       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.54      0.63        50\n","           1       0.64      0.82      0.72        50\n","\n","    accuracy                           0.68       100\n","   macro avg       0.70      0.68      0.67       100\n","weighted avg       0.70      0.68      0.67       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.20      0.33        50\n","           1       0.55      0.98      0.71        50\n","\n","    accuracy                           0.59       100\n","   macro avg       0.73      0.59      0.52       100\n","weighted avg       0.73      0.59      0.52       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.88      0.87        50\n","           1       0.88      0.86      0.87        50\n","\n","    accuracy                           0.87       100\n","   macro avg       0.87      0.87      0.87       100\n","weighted avg       0.87      0.87      0.87       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.76      0.76        51\n","           1       0.75      0.73      0.74        49\n","\n","    accuracy                           0.75       100\n","   macro avg       0.75      0.75      0.75       100\n","weighted avg       0.75      0.75      0.75       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.86      0.92        51\n","           1       0.87      0.98      0.92        49\n","\n","    accuracy                           0.92       100\n","   macro avg       0.93      0.92      0.92       100\n","weighted avg       0.93      0.92      0.92       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.61      0.65        51\n","           1       0.64      0.71      0.67        49\n","\n","    accuracy                           0.66       100\n","   macro avg       0.66      0.66      0.66       100\n","weighted avg       0.66      0.66      0.66       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.22      0.35        51\n","           1       0.55      0.98      0.70        49\n","\n","    accuracy                           0.59       100\n","   macro avg       0.73      0.60      0.52       100\n","weighted avg       0.73      0.59      0.52       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.88      0.89        51\n","           1       0.88      0.90      0.89        49\n","\n","    accuracy                           0.89       100\n","   macro avg       0.89      0.89      0.89       100\n","weighted avg       0.89      0.89      0.89       100\n","\n","annotator 1\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.73      0.72        52\n","           1       0.70      0.67      0.68        48\n","\n","    accuracy                           0.70       100\n","   macro avg       0.70      0.70      0.70       100\n","weighted avg       0.70      0.70      0.70       100\n","\n","annotator 2\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.88      0.92        52\n","           1       0.88      0.96      0.92        48\n","\n","    accuracy                           0.92       100\n","   macro avg       0.92      0.92      0.92       100\n","weighted avg       0.92      0.92      0.92       100\n","\n","annotator 3\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.63      0.68        52\n","           1       0.65      0.75      0.70        48\n","\n","    accuracy                           0.69       100\n","   macro avg       0.69      0.69      0.69       100\n","weighted avg       0.70      0.69      0.69       100\n","\n","annotator 4\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.27      0.41        52\n","           1       0.55      0.96      0.70        48\n","\n","    accuracy                           0.60       100\n","   macro avg       0.71      0.61      0.55       100\n","weighted avg       0.72      0.60      0.55       100\n","\n","annotator 5\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.90      0.92        52\n","           1       0.90      0.94      0.92        48\n","\n","    accuracy                           0.92       100\n","   macro avg       0.92      0.92      0.92       100\n","weighted avg       0.92      0.92      0.92       100\n","\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from sklearn.metrics import classification_report\n","i = 0\n","fig, ax = plt.subplots(1, 4)\n","for image, label, label2 in train_batches_MA.take(4):\n","   # predictedLabel = int(predictions[i] >= 0.5)\n","   # print(label2)\n","    ax[i].axis('off')\n","   # ax[i].set_title(classNames[label[i]])\n","    ax[i].imshow(image[0])\n","    i += 1\n","    for j in range(label2.shape[1]):\n","      print('annotator',j+1)\n","      print(classification_report(label ,label2[:,j]))\n","plt.show()"]},{"cell_type":"markdown","id":"4305d094","metadata":{"id":"9AgOHREc1bmd","papermill":{"duration":0.007296,"end_time":"2023-02-14T21:50:23.096879","exception":false,"start_time":"2023-02-14T21:50:23.089583","status":"completed"},"tags":[]},"source":["## Build the classifier from multiple annotators"]},{"cell_type":"code","execution_count":15,"id":"fed169e1","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:23.11373Z","iopub.status.busy":"2023-02-14T21:50:23.113377Z","iopub.status.idle":"2023-02-14T21:50:23.139593Z","shell.execute_reply":"2023-02-14T21:50:23.138739Z"},"id":"k-ePr0-fxcVi","papermill":{"duration":0.037282,"end_time":"2023-02-14T21:50:23.141665","exception":false,"start_time":"2023-02-14T21:50:23.104383","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import time\n","from tensorflow.keras import regularizers\n","\n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n","from keras.utils.vis_utils import plot_model\n","\n","class MultipleAnnotators_Classification():\n","    def __init__(self, output_dim, num_annotators, q= 0.0001):\n","        self.K = output_dim\n","        self.R = num_annotators\n","        self.q = q\n","        #self.callbacks #=callbacks\n","        #self.l1_param=l1_param \n","        #self.l2_param=l1_param\n","\n","    def CrowdLayer(self, input):\n","       #x = keras.layers.Dense(self.R + self.K,  ,  activation='tanh')(input)\n","        output_cla = keras.layers.Dense(self.K,    activation='softmax')(input)\n","        output_ann = keras.layers.Dense(self.R, activation='sigmoid')(input)\n","        output = keras.layers.Concatenate()([output_cla, output_ann])\n","        \n","        return output\n","#RCDNN   \n","#     def loss(self):\n","#         def custom_loss(y_true, y_pred):\n","#             # print(y_true,y_pred)\n","#             pred = y_pred[:, :self.K]\n","#             pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1-1e-9) #estabilidad numerica de la funcion de costo\n","#             ann_ = y_pred[:, self.K:]\n","#             Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n","#             Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n","#             p_logreg = tf.math.reduce_prod(tf.math.pow(Y_hat, Y_true), axis=1)\n","#             temp1 = ann_*tf.math.log(p_logreg)  \n","#             temp2 = (1 - ann_)*tf.math.log(1/self.K)*tf.reduce_sum(Y_true,axis=1)\n","#             # temp2 = (tf.ones(tf.shape(ann_)) - ann_)*tf.math.log(1/K)\n","#             # print(tf.reduce_mean(Y_true,axis=1).numpy())\n","#             return -tf.math.reduce_sum((temp1 + temp2))\n","#         return custom_loss\n","    \n","    def loss(self):\n","        def custom_loss(y_true, y_pred):\n","               # print(y_true,y_pred)\n","           # q = 0.1\n","            pred = y_pred[:, :self.K]\n","            pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n","            ann_ = y_pred[:, self.K:]\n","            # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n","            Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.K, axis=1)\n","            Y_hat = tf.repeat(tf.expand_dims(pred,-1), self.R, axis = -1)\n","\n","            p_gcce = Y_true*(1 - Y_hat**self.q)/self.q\n","            temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n","            temp2 = (1 - ann_)*(1-(1/self.K)**self.q)/self.q*tf.reduce_sum(Y_true,axis=1)\n","            return tf.math.reduce_sum((temp1 + temp2))\n","        return custom_loss\n","\n","    @tf.function\n","    def train_step(self, x, Y, y):\n","        with tf.GradientTape() as tape:\n","            logits = self.model(x, training=True)\n","            loss_value = self.loss_fn(Y, logits)\n","        grads = tape.gradient(loss_value, self.model.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n","        self.train_acc_metric.update_state(y, logits[:, :self.K])\n","        return loss_value\n","\n","    @tf.function\n","    def test_step(self, x, y):\n","        val_logits = self.model(x, training=False)\n","        self.val_acc_metric.update_state(y, val_logits[:,:self.K])\n","\n","    def fit(self, model, Data_tr, Data_Val, epochs):\n","        self.model = model\n","        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        # Instantiate an optimizer.\n","        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n","        #self.optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n","        #self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, clipnorm=1.0)\n","        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        # Instantiate a loss function.\n","        self.loss_fn = self.loss()\n","        self.train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","        train_loss = np.zeros(epochs)\n","        train_accur = np.zeros(epochs)\n","        val_accur = np.zeros(epochs)\n","        val_loss = np.zeros(epochs)\n","\n","        for epoch in range(epochs):\n","            print(\"\\nStart of epoch %d\" % (epoch,))\n","            start_time = time.time()\n","\n","            # Iterate over the batches of the dataset.\n","            for step, (x_batch_train, y_batch_train, Y_batch_train) in enumerate(Data_tr):\n","                # print(y_batch_train, Y_batch_train)\n","                loss_value = self.train_step(x_batch_train, Y_batch_train, y_batch_train)\n","\n","                # Log every 200 batches.\n","                if step % 10 == 0:\n","                    train_acc = self.train_acc_metric.result()\n","                    print(\n","                      \"Training loss (for one batch) at step %d: %.4f, Accuracy: %.4f\"\n","                      % (step, float(loss_value), float(train_acc))\n","                            )\n","                # print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n","\n","\n","\n","            # Run a validation loop at the end of each epoch.\n","            for x_batch_val, y_batch_val,Y_batch_val in Data_Val:\n","\n","                val_logits = model(x_batch_val, training=False)\n","\n","                val_loss_value = self.loss_fn(Y_batch_val, val_logits)\n","\n","                self.val_acc_metric.update_state(y_batch_val, val_logits[:,:self.K])\n","                \n","               # np.round(np.mean([model(x_batch_val, training= True) for sample in range(100)]), 2)\n","\n","\n","             # Display metrics at the end of each epoch.\n","            train_acc = self.train_acc_metric.result()\n","            val_acc = self.val_acc_metric.result()\n","\n","\n","            print('---- Training ----')\n","            print(\"Training loss: %.4f\" % (float(loss_value),))\n","            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","            # Reset training metrics at the end of each epoch\n","            self.train_acc_metric.reset_states()\n","            self.val_acc_metric.reset_states()\n","\n","\n","            train_loss[epoch] = float(loss_value)\n","            train_accur[epoch] = float(train_acc)\n","\n","            val_accur[epoch] = float(val_acc)\n","            val_loss[epoch] = float(val_loss_value) \n","\n","\n","            print('---- Validation ----')\n","            print(\"Validation loss: %.4f\" % (float(val_loss_value),))\n","            print(\"Validation acc: %.4f\" % (float(val_acc),))\n","\n","            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n","\n","        fig, (ax1, ax2) = plt.subplots(1, 2)\n","        fig.suptitle('Loss and accuracy')\n","        ax1.plot(range(1,epochs+1),train_loss)\n","        ax1.plot(range(1,epochs+1), val_loss)\n","        ax2.plot(range(1,epochs+1),train_accur)\n","        ax2.plot(range(1,epochs+1),val_accur)\n","        #plt.figure(figsize=(16,9))\n","        ax1.set(xlabel= 'Epoch', ylabel=\"Loss\")\n","        ax2.set(xlabel= 'Epoch',ylabel=\"Accuracy\")\n","        ax1.legend(['Training_loss', 'Validation_loss'])\n","        ax2.legend(['Training', 'Validation'])\n","        ax1.grid()\n","        ax2.grid()\n","        plt.show()\n","        return self.model\n","\n","    def eval_model(self, Data):\n","        self.val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","        for x_batch_val, y_batch_val in Data:\n","            self.test_step(x_batch_val, y_batch_val)\n","\n","        val_acc = self.val_acc_metric.result()\n","        self.val_acc_metric.reset_states()\n","        return val_acc\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":16,"id":"a24ff9b3","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:23.157684Z","iopub.status.busy":"2023-02-14T21:50:23.157386Z","iopub.status.idle":"2023-02-14T21:50:23.16386Z","shell.execute_reply":"2023-02-14T21:50:23.162902Z"},"id":"4l-_pkpaBkSv","papermill":{"duration":0.016633,"end_time":"2023-02-14T21:50:23.165792","exception":false,"start_time":"2023-02-14T21:50:23.149159","status":"completed"},"tags":[]},"outputs":[],"source":["def custom_loss(y_true, y_pred):\n","  # print(y_true,y_pred)\n","  K = 2 #len(np.unique(y_true))\n","  R = 5\n","  q = 0.1\n","  pred = y_pred[:, K]\n","  pred = tf.clip_by_value(pred, clip_value_min=1e-9, clip_value_max=1)\n","  ann_ = y_pred[:,  K:]\n","  # ann_ = tf.clip_by_value(ann_, clip_value_min=1e-9, clip_value_max=1-1e-9)\n","  Y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=K, axis=1)\n","  Y_hat = tf.repeat(tf.expand_dims(pred,-1), R, axis = -1)\n","\n","  p_gcce = Y_true*(1 - Y_hat**q)/q\n","  temp1 = ann_*tf.math.reduce_sum(p_gcce, axis=1)\n","  temp2 = (1 - ann_)*(1-(1/K)**q)/q*tf.reduce_sum(Y_true,axis=1)\n","  return tf.math.reduce_sum((temp1 + temp2))\n","\n"]},{"cell_type":"code","execution_count":17,"id":"4c68eecb","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:23.182267Z","iopub.status.busy":"2023-02-14T21:50:23.181522Z","iopub.status.idle":"2023-02-14T21:50:23.192743Z","shell.execute_reply":"2023-02-14T21:50:23.191922Z"},"id":"Z-fV95n3GEqa","papermill":{"duration":0.021377,"end_time":"2023-02-14T21:50:23.194698","exception":false,"start_time":"2023-02-14T21:50:23.173321","status":"completed"},"tags":[]},"outputs":[],"source":["MA = MultipleAnnotators_Classification(2, 5, 0.001)\n"," \n","def create_model():\n","   \n","    l1 = 1e-2\n","    # Block 1\n","    inputs = keras.layers.Input(shape=(150, 150, 3), name='entrada')\n","    x = keras.layers.BatchNormalization()(inputs)\n","    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\" , name=\"block1_conv1\")(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n","\n","\n","    # Block 2\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", name=\"block2_conv1\")(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    #x = keras.layers.Dropout(0.2)(x)\n","    \n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n","\n","    # Block 3\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block3_conv1\" )(x)             \n","    x = keras.layers.BatchNormalization()(x)\n","   # x = keras.layers.Dropout(0.2)(x)\n","   \n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n","    \n","    # Block 4\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", name=\"block4_conv1\")(x)            \n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n","    #x = keras.layers.Dropout(0.2)(x)\n","    \n","    #x = keras.layers.GlobalAveragePooling2D()(x)\n","   \n","    x = keras.layers.Flatten()(x)\n","    #x = keras.layers.Dropout(0.5)(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Dense(128, activation='relu')(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.Dropout(0.5)(x)\n","    output = MA.CrowdLayer(x)\n","    model = keras.Model(inputs=inputs,outputs=output)\n","\n","    return model\n","  \n","  "]},{"cell_type":"code","execution_count":18,"id":"7e2086ff","metadata":{"execution":{"iopub.execute_input":"2023-02-14T21:50:23.211494Z","iopub.status.busy":"2023-02-14T21:50:23.211237Z","iopub.status.idle":"2023-02-15T03:55:52.002241Z","shell.execute_reply":"2023-02-15T03:55:52.001183Z"},"papermill":{"duration":21929.23303,"end_time":"2023-02-15T03:55:52.435739","exception":false,"start_time":"2023-02-14T21:50:23.202709","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-14 21:50:26.911913: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 527.5652, Accuracy: 0.4400\n","Training loss (for one batch) at step 10: 485.7293, Accuracy: 0.5664\n","Training loss (for one batch) at step 20: 470.1454, Accuracy: 0.5643\n","Training loss (for one batch) at step 30: 428.4604, Accuracy: 0.5665\n","Training loss (for one batch) at step 40: 460.2888, Accuracy: 0.5710\n","Training loss (for one batch) at step 50: 446.4178, Accuracy: 0.5696\n","Training loss (for one batch) at step 60: 445.7569, Accuracy: 0.5716\n","Training loss (for one batch) at step 70: 419.4080, Accuracy: 0.5735\n","Training loss (for one batch) at step 80: 450.2828, Accuracy: 0.5765\n","Training loss (for one batch) at step 90: 448.1821, Accuracy: 0.5760\n","Training loss (for one batch) at step 100: 469.8572, Accuracy: 0.5758\n","Training loss (for one batch) at step 110: 421.2848, Accuracy: 0.5786\n","Training loss (for one batch) at step 120: 415.3198, Accuracy: 0.5806\n","Training loss (for one batch) at step 130: 422.9765, Accuracy: 0.5824\n","Training loss (for one batch) at step 140: 421.0312, Accuracy: 0.5812\n","---- Training ----\n","Training loss: 350.7345\n","Training acc over epoch: 0.5824\n","---- Validation ----\n","Validation loss: 101.4941\n","Validation acc: 0.5134\n","Time taken: 69.16s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 414.7354, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 368.4087, Accuracy: 0.6127\n","Training loss (for one batch) at step 20: 399.2114, Accuracy: 0.6190\n","Training loss (for one batch) at step 30: 409.7503, Accuracy: 0.6155\n","Training loss (for one batch) at step 40: 374.2572, Accuracy: 0.6195\n","Training loss (for one batch) at step 50: 390.4643, Accuracy: 0.6225\n","Training loss (for one batch) at step 60: 383.4763, Accuracy: 0.6238\n","Training loss (for one batch) at step 70: 412.1743, Accuracy: 0.6234\n","Training loss (for one batch) at step 80: 414.9368, Accuracy: 0.6248\n","Training loss (for one batch) at step 90: 373.5606, Accuracy: 0.6266\n","Training loss (for one batch) at step 100: 397.1875, Accuracy: 0.6267\n","Training loss (for one batch) at step 110: 386.2385, Accuracy: 0.6250\n","Training loss (for one batch) at step 120: 381.1939, Accuracy: 0.6228\n","Training loss (for one batch) at step 130: 368.0622, Accuracy: 0.6244\n","Training loss (for one batch) at step 140: 382.5007, Accuracy: 0.6243\n","---- Training ----\n","Training loss: 352.9120\n","Training acc over epoch: 0.6250\n","---- Validation ----\n","Validation loss: 79.5263\n","Validation acc: 0.5306\n","Time taken: 10.53s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 375.4754, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 403.0332, Accuracy: 0.6327\n","Training loss (for one batch) at step 20: 378.3479, Accuracy: 0.6305\n","Training loss (for one batch) at step 30: 414.4794, Accuracy: 0.6365\n","Training loss (for one batch) at step 40: 398.7999, Accuracy: 0.6380\n","Training loss (for one batch) at step 50: 381.3060, Accuracy: 0.6376\n","Training loss (for one batch) at step 60: 384.7852, Accuracy: 0.6408\n","Training loss (for one batch) at step 70: 367.2447, Accuracy: 0.6406\n","Training loss (for one batch) at step 80: 396.3054, Accuracy: 0.6412\n","Training loss (for one batch) at step 90: 358.3841, Accuracy: 0.6390\n","Training loss (for one batch) at step 100: 363.4851, Accuracy: 0.6410\n","Training loss (for one batch) at step 110: 362.2993, Accuracy: 0.6422\n","Training loss (for one batch) at step 120: 349.9545, Accuracy: 0.6455\n","Training loss (for one batch) at step 130: 353.6843, Accuracy: 0.6447\n","Training loss (for one batch) at step 140: 369.4059, Accuracy: 0.6448\n","---- Training ----\n","Training loss: 306.4173\n","Training acc over epoch: 0.6452\n","---- Validation ----\n","Validation loss: 71.6043\n","Validation acc: 0.6905\n","Time taken: 10.33s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 361.0397, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 375.9297, Accuracy: 0.6682\n","Training loss (for one batch) at step 20: 348.9310, Accuracy: 0.6719\n","Training loss (for one batch) at step 30: 400.0352, Accuracy: 0.6655\n","Training loss (for one batch) at step 40: 342.6651, Accuracy: 0.6629\n","Training loss (for one batch) at step 50: 402.3806, Accuracy: 0.6661\n","Training loss (for one batch) at step 60: 357.3140, Accuracy: 0.6648\n","Training loss (for one batch) at step 70: 367.7959, Accuracy: 0.6641\n","Training loss (for one batch) at step 80: 379.3242, Accuracy: 0.6647\n","Training loss (for one batch) at step 90: 360.5052, Accuracy: 0.6644\n","Training loss (for one batch) at step 100: 380.4537, Accuracy: 0.6665\n","Training loss (for one batch) at step 110: 369.4744, Accuracy: 0.6677\n","Training loss (for one batch) at step 120: 338.3556, Accuracy: 0.6683\n","Training loss (for one batch) at step 130: 358.0639, Accuracy: 0.6685\n","Training loss (for one batch) at step 140: 386.4206, Accuracy: 0.6680\n","---- Training ----\n","Training loss: 318.3352\n","Training acc over epoch: 0.6669\n","---- Validation ----\n","Validation loss: 71.0933\n","Validation acc: 0.7106\n","Time taken: 10.45s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 365.2827, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 369.3956, Accuracy: 0.6782\n","Training loss (for one batch) at step 20: 334.1480, Accuracy: 0.6795\n","Training loss (for one batch) at step 30: 364.9940, Accuracy: 0.6755\n","Training loss (for one batch) at step 40: 377.7835, Accuracy: 0.6737\n","Training loss (for one batch) at step 50: 331.5173, Accuracy: 0.6776\n","Training loss (for one batch) at step 60: 338.0648, Accuracy: 0.6772\n","Training loss (for one batch) at step 70: 356.2871, Accuracy: 0.6776\n","Training loss (for one batch) at step 80: 346.5218, Accuracy: 0.6783\n","Training loss (for one batch) at step 90: 335.0776, Accuracy: 0.6758\n","Training loss (for one batch) at step 100: 326.9565, Accuracy: 0.6742\n","Training loss (for one batch) at step 110: 358.7886, Accuracy: 0.6729\n","Training loss (for one batch) at step 120: 334.4588, Accuracy: 0.6731\n","Training loss (for one batch) at step 130: 358.6262, Accuracy: 0.6732\n","Training loss (for one batch) at step 140: 329.9813, Accuracy: 0.6743\n","---- Training ----\n","Training loss: 288.3139\n","Training acc over epoch: 0.6753\n","---- Validation ----\n","Validation loss: 78.8003\n","Validation acc: 0.7034\n","Time taken: 9.91s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 327.2693, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 336.1891, Accuracy: 0.6936\n","Training loss (for one batch) at step 20: 342.4390, Accuracy: 0.6957\n","Training loss (for one batch) at step 30: 333.1637, Accuracy: 0.6868\n","Training loss (for one batch) at step 40: 323.9966, Accuracy: 0.6861\n","Training loss (for one batch) at step 50: 313.2051, Accuracy: 0.6867\n","Training loss (for one batch) at step 60: 347.4801, Accuracy: 0.6885\n","Training loss (for one batch) at step 70: 322.6429, Accuracy: 0.6923\n","Training loss (for one batch) at step 80: 350.3183, Accuracy: 0.6946\n","Training loss (for one batch) at step 90: 341.9393, Accuracy: 0.6938\n","Training loss (for one batch) at step 100: 328.0479, Accuracy: 0.6921\n","Training loss (for one batch) at step 110: 336.2398, Accuracy: 0.6923\n","Training loss (for one batch) at step 120: 344.7343, Accuracy: 0.6941\n","Training loss (for one batch) at step 130: 344.7416, Accuracy: 0.6939\n","Training loss (for one batch) at step 140: 337.3373, Accuracy: 0.6962\n","---- Training ----\n","Training loss: 295.1274\n","Training acc over epoch: 0.6953\n","---- Validation ----\n","Validation loss: 75.8963\n","Validation acc: 0.7007\n","Time taken: 9.73s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 328.4754, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 345.5945, Accuracy: 0.7036\n","Training loss (for one batch) at step 20: 336.1838, Accuracy: 0.6986\n","Training loss (for one batch) at step 30: 334.5241, Accuracy: 0.6977\n","Training loss (for one batch) at step 40: 343.0800, Accuracy: 0.7020\n","Training loss (for one batch) at step 50: 329.4874, Accuracy: 0.7051\n","Training loss (for one batch) at step 60: 319.4249, Accuracy: 0.7061\n","Training loss (for one batch) at step 70: 323.9439, Accuracy: 0.7068\n","Training loss (for one batch) at step 80: 328.1810, Accuracy: 0.7046\n","Training loss (for one batch) at step 90: 329.0745, Accuracy: 0.7065\n","Training loss (for one batch) at step 100: 336.4267, Accuracy: 0.7055\n","Training loss (for one batch) at step 110: 314.7868, Accuracy: 0.7051\n","Training loss (for one batch) at step 120: 332.8512, Accuracy: 0.7048\n","Training loss (for one batch) at step 130: 344.6004, Accuracy: 0.7060\n","Training loss (for one batch) at step 140: 324.1347, Accuracy: 0.7069\n","---- Training ----\n","Training loss: 295.2740\n","Training acc over epoch: 0.7078\n","---- Validation ----\n","Validation loss: 71.8922\n","Validation acc: 0.7383\n","Time taken: 9.66s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 321.7647, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 310.0202, Accuracy: 0.6936\n","Training loss (for one batch) at step 20: 309.3121, Accuracy: 0.7124\n","Training loss (for one batch) at step 30: 344.8871, Accuracy: 0.7052\n","Training loss (for one batch) at step 40: 317.7033, Accuracy: 0.7129\n","Training loss (for one batch) at step 50: 328.6810, Accuracy: 0.7169\n","Training loss (for one batch) at step 60: 314.9474, Accuracy: 0.7203\n","Training loss (for one batch) at step 70: 311.1190, Accuracy: 0.7235\n","Training loss (for one batch) at step 80: 336.7076, Accuracy: 0.7217\n","Training loss (for one batch) at step 90: 338.0130, Accuracy: 0.7199\n","Training loss (for one batch) at step 100: 335.6043, Accuracy: 0.7190\n","Training loss (for one batch) at step 110: 311.4397, Accuracy: 0.7214\n","Training loss (for one batch) at step 120: 327.8146, Accuracy: 0.7214\n","Training loss (for one batch) at step 130: 313.3764, Accuracy: 0.7210\n","Training loss (for one batch) at step 140: 324.4893, Accuracy: 0.7225\n","---- Training ----\n","Training loss: 295.1404\n","Training acc over epoch: 0.7215\n","---- Validation ----\n","Validation loss: 69.7238\n","Validation acc: 0.6964\n","Time taken: 9.50s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 313.9289, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 301.8256, Accuracy: 0.7227\n","Training loss (for one batch) at step 20: 302.5697, Accuracy: 0.7219\n","Training loss (for one batch) at step 30: 309.3948, Accuracy: 0.7239\n","Training loss (for one batch) at step 40: 351.4895, Accuracy: 0.7278\n","Training loss (for one batch) at step 50: 305.1110, Accuracy: 0.7296\n","Training loss (for one batch) at step 60: 315.3144, Accuracy: 0.7290\n","Training loss (for one batch) at step 70: 322.4496, Accuracy: 0.7287\n","Training loss (for one batch) at step 80: 307.2949, Accuracy: 0.7283\n","Training loss (for one batch) at step 90: 332.2927, Accuracy: 0.7246\n","Training loss (for one batch) at step 100: 317.0076, Accuracy: 0.7243\n","Training loss (for one batch) at step 110: 315.9072, Accuracy: 0.7261\n","Training loss (for one batch) at step 120: 304.7992, Accuracy: 0.7261\n","Training loss (for one batch) at step 130: 321.2657, Accuracy: 0.7256\n","Training loss (for one batch) at step 140: 311.0507, Accuracy: 0.7284\n","---- Training ----\n","Training loss: 289.8389\n","Training acc over epoch: 0.7280\n","---- Validation ----\n","Validation loss: 83.8228\n","Validation acc: 0.7227\n","Time taken: 9.77s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 297.6439, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 301.3385, Accuracy: 0.7464\n","Training loss (for one batch) at step 20: 335.2910, Accuracy: 0.7633\n","Training loss (for one batch) at step 30: 308.5423, Accuracy: 0.7587\n","Training loss (for one batch) at step 40: 330.3203, Accuracy: 0.7573\n","Training loss (for one batch) at step 50: 316.8153, Accuracy: 0.7557\n","Training loss (for one batch) at step 60: 318.7785, Accuracy: 0.7556\n","Training loss (for one batch) at step 70: 311.4369, Accuracy: 0.7548\n","Training loss (for one batch) at step 80: 314.5453, Accuracy: 0.7523\n","Training loss (for one batch) at step 90: 322.3553, Accuracy: 0.7531\n","Training loss (for one batch) at step 100: 290.3810, Accuracy: 0.7530\n","Training loss (for one batch) at step 110: 309.8307, Accuracy: 0.7516\n","Training loss (for one batch) at step 120: 298.1726, Accuracy: 0.7510\n","Training loss (for one batch) at step 130: 303.1388, Accuracy: 0.7511\n","Training loss (for one batch) at step 140: 312.4652, Accuracy: 0.7518\n","---- Training ----\n","Training loss: 298.6415\n","Training acc over epoch: 0.7521\n","---- Validation ----\n","Validation loss: 68.2228\n","Validation acc: 0.6773\n","Time taken: 9.58s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 303.8081, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 315.6491, Accuracy: 0.7582\n","Training loss (for one batch) at step 20: 299.7039, Accuracy: 0.7510\n","Training loss (for one batch) at step 30: 318.7493, Accuracy: 0.7523\n","Training loss (for one batch) at step 40: 296.9448, Accuracy: 0.7505\n","Training loss (for one batch) at step 50: 305.3838, Accuracy: 0.7506\n","Training loss (for one batch) at step 60: 317.8546, Accuracy: 0.7493\n","Training loss (for one batch) at step 70: 307.6823, Accuracy: 0.7541\n","Training loss (for one batch) at step 80: 313.1857, Accuracy: 0.7548\n","Training loss (for one batch) at step 90: 313.6532, Accuracy: 0.7521\n","Training loss (for one batch) at step 100: 322.8497, Accuracy: 0.7526\n","Training loss (for one batch) at step 110: 311.6450, Accuracy: 0.7502\n","Training loss (for one batch) at step 120: 318.1743, Accuracy: 0.7528\n","Training loss (for one batch) at step 130: 297.5695, Accuracy: 0.7536\n","Training loss (for one batch) at step 140: 312.5851, Accuracy: 0.7545\n","---- Training ----\n","Training loss: 270.7544\n","Training acc over epoch: 0.7548\n","---- Validation ----\n","Validation loss: 69.5605\n","Validation acc: 0.7184\n","Time taken: 9.60s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 295.1462, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 302.8084, Accuracy: 0.7591\n","Training loss (for one batch) at step 20: 303.0034, Accuracy: 0.7652\n","Training loss (for one batch) at step 30: 311.3145, Accuracy: 0.7545\n","Training loss (for one batch) at step 40: 286.4696, Accuracy: 0.7615\n","Training loss (for one batch) at step 50: 294.6967, Accuracy: 0.7659\n","Training loss (for one batch) at step 60: 275.4273, Accuracy: 0.7667\n","Training loss (for one batch) at step 70: 309.5190, Accuracy: 0.7666\n","Training loss (for one batch) at step 80: 301.8839, Accuracy: 0.7659\n","Training loss (for one batch) at step 90: 303.8592, Accuracy: 0.7624\n","Training loss (for one batch) at step 100: 305.8885, Accuracy: 0.7607\n","Training loss (for one batch) at step 110: 294.8497, Accuracy: 0.7617\n","Training loss (for one batch) at step 120: 300.2937, Accuracy: 0.7614\n","Training loss (for one batch) at step 130: 281.0685, Accuracy: 0.7625\n","Training loss (for one batch) at step 140: 296.7326, Accuracy: 0.7612\n","---- Training ----\n","Training loss: 266.6598\n","Training acc over epoch: 0.7616\n","---- Validation ----\n","Validation loss: 74.9823\n","Validation acc: 0.7375\n","Time taken: 9.69s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 296.6288, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 291.0009, Accuracy: 0.7855\n","Training loss (for one batch) at step 20: 288.2358, Accuracy: 0.7790\n","Training loss (for one batch) at step 30: 306.8449, Accuracy: 0.7710\n","Training loss (for one batch) at step 40: 273.7520, Accuracy: 0.7729\n","Training loss (for one batch) at step 50: 276.0591, Accuracy: 0.7747\n","Training loss (for one batch) at step 60: 296.8549, Accuracy: 0.7738\n","Training loss (for one batch) at step 70: 317.8672, Accuracy: 0.7724\n","Training loss (for one batch) at step 80: 298.5279, Accuracy: 0.7709\n","Training loss (for one batch) at step 90: 297.2271, Accuracy: 0.7697\n","Training loss (for one batch) at step 100: 304.9115, Accuracy: 0.7693\n","Training loss (for one batch) at step 110: 310.8136, Accuracy: 0.7685\n","Training loss (for one batch) at step 120: 298.3556, Accuracy: 0.7679\n","Training loss (for one batch) at step 130: 287.6582, Accuracy: 0.7679\n","Training loss (for one batch) at step 140: 296.9242, Accuracy: 0.7675\n","---- Training ----\n","Training loss: 271.1704\n","Training acc over epoch: 0.7677\n","---- Validation ----\n","Validation loss: 64.7361\n","Validation acc: 0.7270\n","Time taken: 9.56s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 287.1867, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 297.4686, Accuracy: 0.7927\n","Training loss (for one batch) at step 20: 281.0555, Accuracy: 0.7800\n","Training loss (for one batch) at step 30: 293.9285, Accuracy: 0.7826\n","Training loss (for one batch) at step 40: 283.0506, Accuracy: 0.7824\n","Training loss (for one batch) at step 50: 296.8868, Accuracy: 0.7839\n","Training loss (for one batch) at step 60: 287.4199, Accuracy: 0.7830\n","Training loss (for one batch) at step 70: 286.9984, Accuracy: 0.7837\n","Training loss (for one batch) at step 80: 296.7943, Accuracy: 0.7805\n","Training loss (for one batch) at step 90: 296.5591, Accuracy: 0.7799\n","Training loss (for one batch) at step 100: 283.2963, Accuracy: 0.7788\n","Training loss (for one batch) at step 110: 290.9077, Accuracy: 0.7788\n","Training loss (for one batch) at step 120: 291.3411, Accuracy: 0.7793\n","Training loss (for one batch) at step 130: 306.5003, Accuracy: 0.7773\n","Training loss (for one batch) at step 140: 291.8774, Accuracy: 0.7775\n","---- Training ----\n","Training loss: 258.3038\n","Training acc over epoch: 0.7783\n","---- Validation ----\n","Validation loss: 65.8365\n","Validation acc: 0.7187\n","Time taken: 9.49s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 283.7563, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 290.0991, Accuracy: 0.7809\n","Training loss (for one batch) at step 20: 278.3028, Accuracy: 0.7800\n","Training loss (for one batch) at step 30: 290.3202, Accuracy: 0.7887\n","Training loss (for one batch) at step 40: 276.7822, Accuracy: 0.7898\n","Training loss (for one batch) at step 50: 282.2297, Accuracy: 0.7927\n","Training loss (for one batch) at step 60: 290.2224, Accuracy: 0.7905\n","Training loss (for one batch) at step 70: 299.0808, Accuracy: 0.7899\n","Training loss (for one batch) at step 80: 293.3069, Accuracy: 0.7900\n","Training loss (for one batch) at step 90: 286.8884, Accuracy: 0.7878\n","Training loss (for one batch) at step 100: 297.0613, Accuracy: 0.7867\n","Training loss (for one batch) at step 110: 290.0004, Accuracy: 0.7879\n","Training loss (for one batch) at step 120: 289.4159, Accuracy: 0.7888\n","Training loss (for one batch) at step 130: 270.9205, Accuracy: 0.7908\n","Training loss (for one batch) at step 140: 289.3708, Accuracy: 0.7902\n","---- Training ----\n","Training loss: 249.7713\n","Training acc over epoch: 0.7900\n","---- Validation ----\n","Validation loss: 65.4737\n","Validation acc: 0.7257\n","Time taken: 9.51s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 281.0325, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 275.9476, Accuracy: 0.7973\n","Training loss (for one batch) at step 20: 289.4301, Accuracy: 0.7871\n","Training loss (for one batch) at step 30: 284.5569, Accuracy: 0.7884\n","Training loss (for one batch) at step 40: 284.0876, Accuracy: 0.7944\n","Training loss (for one batch) at step 50: 304.0462, Accuracy: 0.7988\n","Training loss (for one batch) at step 60: 277.5830, Accuracy: 0.7984\n","Training loss (for one batch) at step 70: 283.1639, Accuracy: 0.7987\n","Training loss (for one batch) at step 80: 273.1905, Accuracy: 0.7946\n","Training loss (for one batch) at step 90: 286.8107, Accuracy: 0.7933\n","Training loss (for one batch) at step 100: 280.2020, Accuracy: 0.7908\n","Training loss (for one batch) at step 110: 281.0310, Accuracy: 0.7903\n","Training loss (for one batch) at step 120: 297.7278, Accuracy: 0.7867\n","Training loss (for one batch) at step 130: 274.7339, Accuracy: 0.7871\n","Training loss (for one batch) at step 140: 260.2668, Accuracy: 0.7866\n","---- Training ----\n","Training loss: 265.2728\n","Training acc over epoch: 0.7869\n","---- Validation ----\n","Validation loss: 71.5178\n","Validation acc: 0.7192\n","Time taken: 9.63s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 274.4103, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 300.0254, Accuracy: 0.8018\n","Training loss (for one batch) at step 20: 276.3546, Accuracy: 0.7933\n","Training loss (for one batch) at step 30: 287.9843, Accuracy: 0.7955\n","Training loss (for one batch) at step 40: 285.2507, Accuracy: 0.7944\n","Training loss (for one batch) at step 50: 269.1497, Accuracy: 0.7955\n","Training loss (for one batch) at step 60: 270.6111, Accuracy: 0.7964\n","Training loss (for one batch) at step 70: 291.2901, Accuracy: 0.7969\n","Training loss (for one batch) at step 80: 294.9871, Accuracy: 0.7925\n","Training loss (for one batch) at step 90: 264.6625, Accuracy: 0.7922\n","Training loss (for one batch) at step 100: 298.0137, Accuracy: 0.7938\n","Training loss (for one batch) at step 110: 282.0747, Accuracy: 0.7940\n","Training loss (for one batch) at step 120: 287.8063, Accuracy: 0.7960\n","Training loss (for one batch) at step 130: 283.6217, Accuracy: 0.7955\n","Training loss (for one batch) at step 140: 289.8761, Accuracy: 0.7946\n","---- Training ----\n","Training loss: 256.7251\n","Training acc over epoch: 0.7947\n","---- Validation ----\n","Validation loss: 64.4297\n","Validation acc: 0.7018\n","Time taken: 9.80s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 292.0485, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 279.7513, Accuracy: 0.8082\n","Training loss (for one batch) at step 20: 275.5767, Accuracy: 0.8076\n","Training loss (for one batch) at step 30: 266.7609, Accuracy: 0.8035\n","Training loss (for one batch) at step 40: 273.1532, Accuracy: 0.8024\n","Training loss (for one batch) at step 50: 278.0567, Accuracy: 0.8063\n","Training loss (for one batch) at step 60: 276.4338, Accuracy: 0.8072\n","Training loss (for one batch) at step 70: 291.9246, Accuracy: 0.8056\n","Training loss (for one batch) at step 80: 297.4688, Accuracy: 0.8032\n","Training loss (for one batch) at step 90: 289.9101, Accuracy: 0.8013\n","Training loss (for one batch) at step 100: 279.5326, Accuracy: 0.8017\n","Training loss (for one batch) at step 110: 288.1198, Accuracy: 0.8021\n","Training loss (for one batch) at step 120: 274.8012, Accuracy: 0.8028\n","Training loss (for one batch) at step 130: 268.0208, Accuracy: 0.8035\n","Training loss (for one batch) at step 140: 273.4841, Accuracy: 0.8027\n","---- Training ----\n","Training loss: 250.7330\n","Training acc over epoch: 0.8023\n","---- Validation ----\n","Validation loss: 68.7349\n","Validation acc: 0.7370\n","Time taken: 9.47s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 280.5630, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 273.3553, Accuracy: 0.7873\n","Training loss (for one batch) at step 20: 278.0201, Accuracy: 0.8019\n","Training loss (for one batch) at step 30: 272.9178, Accuracy: 0.7997\n","Training loss (for one batch) at step 40: 254.3600, Accuracy: 0.8049\n","Training loss (for one batch) at step 50: 264.8229, Accuracy: 0.8092\n","Training loss (for one batch) at step 60: 291.8868, Accuracy: 0.8036\n","Training loss (for one batch) at step 70: 286.1880, Accuracy: 0.8035\n","Training loss (for one batch) at step 80: 286.6671, Accuracy: 0.8048\n","Training loss (for one batch) at step 90: 269.4072, Accuracy: 0.8032\n","Training loss (for one batch) at step 100: 269.3436, Accuracy: 0.8033\n","Training loss (for one batch) at step 110: 271.5280, Accuracy: 0.8031\n","Training loss (for one batch) at step 120: 265.4930, Accuracy: 0.8017\n","Training loss (for one batch) at step 130: 279.0914, Accuracy: 0.8018\n","Training loss (for one batch) at step 140: 269.4370, Accuracy: 0.8011\n","---- Training ----\n","Training loss: 247.9927\n","Training acc over epoch: 0.8012\n","---- Validation ----\n","Validation loss: 71.3467\n","Validation acc: 0.7284\n","Time taken: 9.66s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 267.3128, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 270.8720, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 273.5750, Accuracy: 0.8224\n","Training loss (for one batch) at step 30: 276.4769, Accuracy: 0.8171\n","Training loss (for one batch) at step 40: 295.6112, Accuracy: 0.8163\n","Training loss (for one batch) at step 50: 264.0731, Accuracy: 0.8165\n","Training loss (for one batch) at step 60: 276.1700, Accuracy: 0.8167\n","Training loss (for one batch) at step 70: 280.4786, Accuracy: 0.8166\n","Training loss (for one batch) at step 80: 284.1524, Accuracy: 0.8125\n","Training loss (for one batch) at step 90: 293.8797, Accuracy: 0.8105\n","Training loss (for one batch) at step 100: 257.7791, Accuracy: 0.8101\n","Training loss (for one batch) at step 110: 283.2241, Accuracy: 0.8095\n","Training loss (for one batch) at step 120: 273.7171, Accuracy: 0.8106\n","Training loss (for one batch) at step 130: 276.6753, Accuracy: 0.8087\n","Training loss (for one batch) at step 140: 269.7658, Accuracy: 0.8094\n","---- Training ----\n","Training loss: 248.0699\n","Training acc over epoch: 0.8096\n","---- Validation ----\n","Validation loss: 61.3913\n","Validation acc: 0.7289\n","Time taken: 9.60s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 267.8854, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 270.6834, Accuracy: 0.8218\n","Training loss (for one batch) at step 20: 276.9342, Accuracy: 0.8124\n","Training loss (for one batch) at step 30: 242.9749, Accuracy: 0.8158\n","Training loss (for one batch) at step 40: 284.6319, Accuracy: 0.8161\n","Training loss (for one batch) at step 50: 259.6818, Accuracy: 0.8210\n","Training loss (for one batch) at step 60: 270.6411, Accuracy: 0.8197\n","Training loss (for one batch) at step 70: 272.0410, Accuracy: 0.8186\n","Training loss (for one batch) at step 80: 267.1286, Accuracy: 0.8162\n","Training loss (for one batch) at step 90: 278.6115, Accuracy: 0.8149\n","Training loss (for one batch) at step 100: 256.2336, Accuracy: 0.8149\n","Training loss (for one batch) at step 110: 268.8988, Accuracy: 0.8148\n","Training loss (for one batch) at step 120: 258.3041, Accuracy: 0.8144\n","Training loss (for one batch) at step 130: 265.0509, Accuracy: 0.8134\n","Training loss (for one batch) at step 140: 275.9163, Accuracy: 0.8137\n","---- Training ----\n","Training loss: 232.4071\n","Training acc over epoch: 0.8132\n","---- Validation ----\n","Validation loss: 74.1707\n","Validation acc: 0.7133\n","Time taken: 9.69s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 276.4044, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 261.0562, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 263.4520, Accuracy: 0.8257\n","Training loss (for one batch) at step 30: 279.7070, Accuracy: 0.8216\n","Training loss (for one batch) at step 40: 256.7255, Accuracy: 0.8217\n","Training loss (for one batch) at step 50: 252.4158, Accuracy: 0.8241\n","Training loss (for one batch) at step 60: 270.0327, Accuracy: 0.8215\n","Training loss (for one batch) at step 70: 276.1600, Accuracy: 0.8238\n","Training loss (for one batch) at step 80: 269.4739, Accuracy: 0.8235\n","Training loss (for one batch) at step 90: 257.7021, Accuracy: 0.8190\n","Training loss (for one batch) at step 100: 255.9322, Accuracy: 0.8178\n","Training loss (for one batch) at step 110: 269.9975, Accuracy: 0.8181\n","Training loss (for one batch) at step 120: 278.6348, Accuracy: 0.8176\n","Training loss (for one batch) at step 130: 254.9585, Accuracy: 0.8167\n","Training loss (for one batch) at step 140: 266.3175, Accuracy: 0.8163\n","---- Training ----\n","Training loss: 250.0136\n","Training acc over epoch: 0.8165\n","---- Validation ----\n","Validation loss: 71.6924\n","Validation acc: 0.7391\n","Time taken: 9.62s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 248.2838, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 249.2325, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 281.3386, Accuracy: 0.8176\n","Training loss (for one batch) at step 30: 276.5588, Accuracy: 0.8190\n","Training loss (for one batch) at step 40: 262.4187, Accuracy: 0.8178\n","Training loss (for one batch) at step 50: 252.6470, Accuracy: 0.8214\n","Training loss (for one batch) at step 60: 264.4310, Accuracy: 0.8208\n","Training loss (for one batch) at step 70: 262.0877, Accuracy: 0.8245\n","Training loss (for one batch) at step 80: 285.3459, Accuracy: 0.8200\n","Training loss (for one batch) at step 90: 266.0043, Accuracy: 0.8188\n","Training loss (for one batch) at step 100: 251.2785, Accuracy: 0.8177\n","Training loss (for one batch) at step 110: 266.6462, Accuracy: 0.8184\n","Training loss (for one batch) at step 120: 253.9668, Accuracy: 0.8165\n","Training loss (for one batch) at step 130: 272.4949, Accuracy: 0.8166\n","Training loss (for one batch) at step 140: 258.9280, Accuracy: 0.8167\n","---- Training ----\n","Training loss: 220.2854\n","Training acc over epoch: 0.8166\n","---- Validation ----\n","Validation loss: 73.4674\n","Validation acc: 0.7308\n","Time taken: 9.73s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 256.3245, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 253.5680, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 252.2861, Accuracy: 0.8367\n","Training loss (for one batch) at step 30: 260.5576, Accuracy: 0.8300\n","Training loss (for one batch) at step 40: 256.0079, Accuracy: 0.8210\n","Training loss (for one batch) at step 50: 267.9693, Accuracy: 0.8257\n","Training loss (for one batch) at step 60: 250.6280, Accuracy: 0.8259\n","Training loss (for one batch) at step 70: 264.6138, Accuracy: 0.8270\n","Training loss (for one batch) at step 80: 274.8406, Accuracy: 0.8252\n","Training loss (for one batch) at step 90: 263.6708, Accuracy: 0.8240\n","Training loss (for one batch) at step 100: 248.9697, Accuracy: 0.8236\n","Training loss (for one batch) at step 110: 251.1908, Accuracy: 0.8236\n","Training loss (for one batch) at step 120: 259.8826, Accuracy: 0.8227\n","Training loss (for one batch) at step 130: 273.4259, Accuracy: 0.8221\n","Training loss (for one batch) at step 140: 284.1017, Accuracy: 0.8208\n","---- Training ----\n","Training loss: 215.5548\n","Training acc over epoch: 0.8221\n","---- Validation ----\n","Validation loss: 75.0286\n","Validation acc: 0.7362\n","Time taken: 9.51s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 240.5153, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 259.7513, Accuracy: 0.8127\n","Training loss (for one batch) at step 20: 276.9256, Accuracy: 0.8195\n","Training loss (for one batch) at step 30: 251.5533, Accuracy: 0.8184\n","Training loss (for one batch) at step 40: 249.6874, Accuracy: 0.8217\n","Training loss (for one batch) at step 50: 253.3733, Accuracy: 0.8259\n","Training loss (for one batch) at step 60: 255.6430, Accuracy: 0.8277\n","Training loss (for one batch) at step 70: 269.4500, Accuracy: 0.8283\n","Training loss (for one batch) at step 80: 249.9317, Accuracy: 0.8281\n","Training loss (for one batch) at step 90: 252.6238, Accuracy: 0.8259\n","Training loss (for one batch) at step 100: 255.3096, Accuracy: 0.8245\n","Training loss (for one batch) at step 110: 256.0580, Accuracy: 0.8244\n","Training loss (for one batch) at step 120: 253.1473, Accuracy: 0.8255\n","Training loss (for one batch) at step 130: 262.8895, Accuracy: 0.8235\n","Training loss (for one batch) at step 140: 256.2113, Accuracy: 0.8240\n","---- Training ----\n","Training loss: 244.2797\n","Training acc over epoch: 0.8240\n","---- Validation ----\n","Validation loss: 71.2011\n","Validation acc: 0.7254\n","Time taken: 10.35s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 250.4025, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 251.6705, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 255.6863, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 258.7211, Accuracy: 0.8239\n","Training loss (for one batch) at step 40: 251.2184, Accuracy: 0.8224\n","Training loss (for one batch) at step 50: 249.0692, Accuracy: 0.8282\n","Training loss (for one batch) at step 60: 245.7644, Accuracy: 0.8280\n","Training loss (for one batch) at step 70: 281.7910, Accuracy: 0.8263\n","Training loss (for one batch) at step 80: 248.8053, Accuracy: 0.8278\n","Training loss (for one batch) at step 90: 249.5143, Accuracy: 0.8241\n","Training loss (for one batch) at step 100: 266.8668, Accuracy: 0.8248\n","Training loss (for one batch) at step 110: 250.7866, Accuracy: 0.8259\n","Training loss (for one batch) at step 120: 246.7132, Accuracy: 0.8258\n","Training loss (for one batch) at step 130: 269.0662, Accuracy: 0.8257\n","Training loss (for one batch) at step 140: 267.2637, Accuracy: 0.8259\n","---- Training ----\n","Training loss: 227.9117\n","Training acc over epoch: 0.8254\n","---- Validation ----\n","Validation loss: 61.6761\n","Validation acc: 0.7294\n","Time taken: 9.58s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 251.1541, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 271.5143, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 255.7008, Accuracy: 0.8352\n","Training loss (for one batch) at step 30: 256.9074, Accuracy: 0.8268\n","Training loss (for one batch) at step 40: 232.6582, Accuracy: 0.8324\n","Training loss (for one batch) at step 50: 248.6599, Accuracy: 0.8367\n","Training loss (for one batch) at step 60: 240.2707, Accuracy: 0.8366\n","Training loss (for one batch) at step 70: 272.9339, Accuracy: 0.8368\n","Training loss (for one batch) at step 80: 237.2755, Accuracy: 0.8343\n","Training loss (for one batch) at step 90: 247.0536, Accuracy: 0.8332\n","Training loss (for one batch) at step 100: 264.4133, Accuracy: 0.8324\n","Training loss (for one batch) at step 110: 254.5302, Accuracy: 0.8329\n","Training loss (for one batch) at step 120: 241.8723, Accuracy: 0.8320\n","Training loss (for one batch) at step 130: 236.1336, Accuracy: 0.8322\n","Training loss (for one batch) at step 140: 248.4787, Accuracy: 0.8313\n","---- Training ----\n","Training loss: 221.9963\n","Training acc over epoch: 0.8311\n","---- Validation ----\n","Validation loss: 82.3368\n","Validation acc: 0.7243\n","Time taken: 9.47s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 246.6013, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 237.6495, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 252.1101, Accuracy: 0.8210\n","Training loss (for one batch) at step 30: 242.4967, Accuracy: 0.8216\n","Training loss (for one batch) at step 40: 218.8251, Accuracy: 0.8210\n","Training loss (for one batch) at step 50: 244.3240, Accuracy: 0.8318\n","Training loss (for one batch) at step 60: 234.6243, Accuracy: 0.8349\n","Training loss (for one batch) at step 70: 248.1142, Accuracy: 0.8324\n","Training loss (for one batch) at step 80: 266.1911, Accuracy: 0.8312\n","Training loss (for one batch) at step 90: 245.9972, Accuracy: 0.8318\n","Training loss (for one batch) at step 100: 239.7433, Accuracy: 0.8309\n","Training loss (for one batch) at step 110: 237.8589, Accuracy: 0.8320\n","Training loss (for one batch) at step 120: 237.3627, Accuracy: 0.8306\n","Training loss (for one batch) at step 130: 264.5100, Accuracy: 0.8304\n","Training loss (for one batch) at step 140: 238.8596, Accuracy: 0.8302\n","---- Training ----\n","Training loss: 213.5438\n","Training acc over epoch: 0.8297\n","---- Validation ----\n","Validation loss: 83.5850\n","Validation acc: 0.7391\n","Time taken: 9.52s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 240.8457, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 250.0671, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 259.5652, Accuracy: 0.8271\n","Training loss (for one batch) at step 30: 278.5872, Accuracy: 0.8294\n","Training loss (for one batch) at step 40: 265.2866, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 241.9479, Accuracy: 0.8320\n","Training loss (for one batch) at step 60: 249.6399, Accuracy: 0.8341\n","Training loss (for one batch) at step 70: 257.1518, Accuracy: 0.8337\n","Training loss (for one batch) at step 80: 254.5041, Accuracy: 0.8309\n","Training loss (for one batch) at step 90: 254.7278, Accuracy: 0.8301\n","Training loss (for one batch) at step 100: 242.3365, Accuracy: 0.8302\n","Training loss (for one batch) at step 110: 260.6128, Accuracy: 0.8307\n","Training loss (for one batch) at step 120: 236.3625, Accuracy: 0.8298\n","Training loss (for one batch) at step 130: 254.4282, Accuracy: 0.8304\n","Training loss (for one batch) at step 140: 264.2267, Accuracy: 0.8299\n","---- Training ----\n","Training loss: 208.5976\n","Training acc over epoch: 0.8297\n","---- Validation ----\n","Validation loss: 82.2375\n","Validation acc: 0.7265\n","Time taken: 9.68s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 234.9448, Accuracy: 0.9200\n","Training loss (for one batch) at step 10: 244.0874, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 257.8802, Accuracy: 0.8362\n","Training loss (for one batch) at step 30: 277.6575, Accuracy: 0.8355\n","Training loss (for one batch) at step 40: 233.8902, Accuracy: 0.8373\n","Training loss (for one batch) at step 50: 241.7343, Accuracy: 0.8388\n","Training loss (for one batch) at step 60: 239.6343, Accuracy: 0.8390\n","Training loss (for one batch) at step 70: 245.3801, Accuracy: 0.8407\n","Training loss (for one batch) at step 80: 261.7957, Accuracy: 0.8384\n","Training loss (for one batch) at step 90: 248.9822, Accuracy: 0.8375\n","Training loss (for one batch) at step 100: 236.4170, Accuracy: 0.8366\n","Training loss (for one batch) at step 110: 239.1794, Accuracy: 0.8375\n","Training loss (for one batch) at step 120: 234.6507, Accuracy: 0.8366\n","Training loss (for one batch) at step 130: 238.7095, Accuracy: 0.8351\n","Training loss (for one batch) at step 140: 225.8548, Accuracy: 0.8350\n","---- Training ----\n","Training loss: 218.6456\n","Training acc over epoch: 0.8355\n","---- Validation ----\n","Validation loss: 74.0508\n","Validation acc: 0.7300\n","Time taken: 9.57s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 253.9972, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 232.6485, Accuracy: 0.8282\n","Training loss (for one batch) at step 20: 242.5355, Accuracy: 0.8248\n","Training loss (for one batch) at step 30: 227.6811, Accuracy: 0.8303\n","Training loss (for one batch) at step 40: 214.0028, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 225.3032, Accuracy: 0.8412\n","Training loss (for one batch) at step 60: 232.4945, Accuracy: 0.8436\n","Training loss (for one batch) at step 70: 255.8896, Accuracy: 0.8401\n","Training loss (for one batch) at step 80: 256.5601, Accuracy: 0.8381\n","Training loss (for one batch) at step 90: 233.5290, Accuracy: 0.8380\n","Training loss (for one batch) at step 100: 245.9796, Accuracy: 0.8361\n","Training loss (for one batch) at step 110: 242.3031, Accuracy: 0.8377\n","Training loss (for one batch) at step 120: 239.8906, Accuracy: 0.8379\n","Training loss (for one batch) at step 130: 249.8137, Accuracy: 0.8368\n","Training loss (for one batch) at step 140: 234.6663, Accuracy: 0.8362\n","---- Training ----\n","Training loss: 215.4558\n","Training acc over epoch: 0.8360\n","---- Validation ----\n","Validation loss: 71.2096\n","Validation acc: 0.7176\n","Time taken: 9.59s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 244.8465, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 236.5500, Accuracy: 0.8627\n","Training loss (for one batch) at step 20: 247.4740, Accuracy: 0.8510\n","Training loss (for one batch) at step 30: 232.8262, Accuracy: 0.8458\n","Training loss (for one batch) at step 40: 222.6032, Accuracy: 0.8495\n","Training loss (for one batch) at step 50: 223.8422, Accuracy: 0.8512\n","Training loss (for one batch) at step 60: 228.9022, Accuracy: 0.8497\n","Training loss (for one batch) at step 70: 238.4008, Accuracy: 0.8501\n","Training loss (for one batch) at step 80: 238.5222, Accuracy: 0.8464\n","Training loss (for one batch) at step 90: 246.8759, Accuracy: 0.8435\n","Training loss (for one batch) at step 100: 225.1709, Accuracy: 0.8435\n","Training loss (for one batch) at step 110: 254.9440, Accuracy: 0.8447\n","Training loss (for one batch) at step 120: 223.5086, Accuracy: 0.8450\n","Training loss (for one batch) at step 130: 260.0201, Accuracy: 0.8444\n","Training loss (for one batch) at step 140: 226.6798, Accuracy: 0.8440\n","---- Training ----\n","Training loss: 196.1309\n","Training acc over epoch: 0.8438\n","---- Validation ----\n","Validation loss: 65.5344\n","Validation acc: 0.7303\n","Time taken: 9.76s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 245.6620, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 249.9153, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 239.4022, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 239.2310, Accuracy: 0.8361\n","Training loss (for one batch) at step 40: 232.2878, Accuracy: 0.8410\n","Training loss (for one batch) at step 50: 211.8647, Accuracy: 0.8445\n","Training loss (for one batch) at step 60: 235.3716, Accuracy: 0.8448\n","Training loss (for one batch) at step 70: 247.5717, Accuracy: 0.8454\n","Training loss (for one batch) at step 80: 236.4346, Accuracy: 0.8425\n","Training loss (for one batch) at step 90: 231.2220, Accuracy: 0.8398\n","Training loss (for one batch) at step 100: 229.5193, Accuracy: 0.8388\n","Training loss (for one batch) at step 110: 230.6603, Accuracy: 0.8398\n","Training loss (for one batch) at step 120: 247.0635, Accuracy: 0.8379\n","Training loss (for one batch) at step 130: 246.2391, Accuracy: 0.8386\n","Training loss (for one batch) at step 140: 219.3626, Accuracy: 0.8384\n","---- Training ----\n","Training loss: 226.0105\n","Training acc over epoch: 0.8399\n","---- Validation ----\n","Validation loss: 69.3452\n","Validation acc: 0.7329\n","Time taken: 11.97s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 244.7112, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 226.9756, Accuracy: 0.8664\n","Training loss (for one batch) at step 20: 231.2593, Accuracy: 0.8590\n","Training loss (for one batch) at step 30: 218.7529, Accuracy: 0.8500\n","Training loss (for one batch) at step 40: 231.0149, Accuracy: 0.8485\n","Training loss (for one batch) at step 50: 214.4648, Accuracy: 0.8486\n","Training loss (for one batch) at step 60: 229.7529, Accuracy: 0.8490\n","Training loss (for one batch) at step 70: 240.3711, Accuracy: 0.8486\n","Training loss (for one batch) at step 80: 241.3553, Accuracy: 0.8460\n","Training loss (for one batch) at step 90: 258.1209, Accuracy: 0.8456\n","Training loss (for one batch) at step 100: 236.4638, Accuracy: 0.8442\n","Training loss (for one batch) at step 110: 226.5936, Accuracy: 0.8457\n","Training loss (for one batch) at step 120: 239.6080, Accuracy: 0.8448\n","Training loss (for one batch) at step 130: 230.5999, Accuracy: 0.8455\n","Training loss (for one batch) at step 140: 229.2570, Accuracy: 0.8448\n","---- Training ----\n","Training loss: 207.7554\n","Training acc over epoch: 0.8440\n","---- Validation ----\n","Validation loss: 86.3289\n","Validation acc: 0.7289\n","Time taken: 9.61s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 229.9075, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 235.6371, Accuracy: 0.8691\n","Training loss (for one batch) at step 20: 221.1867, Accuracy: 0.8638\n","Training loss (for one batch) at step 30: 233.0702, Accuracy: 0.8597\n","Training loss (for one batch) at step 40: 223.8034, Accuracy: 0.8529\n","Training loss (for one batch) at step 50: 222.3977, Accuracy: 0.8539\n","Training loss (for one batch) at step 60: 228.8967, Accuracy: 0.8539\n","Training loss (for one batch) at step 70: 249.3415, Accuracy: 0.8534\n","Training loss (for one batch) at step 80: 225.5385, Accuracy: 0.8520\n","Training loss (for one batch) at step 90: 243.4591, Accuracy: 0.8482\n","Training loss (for one batch) at step 100: 243.5622, Accuracy: 0.8491\n","Training loss (for one batch) at step 110: 227.2881, Accuracy: 0.8493\n","Training loss (for one batch) at step 120: 267.4191, Accuracy: 0.8484\n","Training loss (for one batch) at step 130: 216.9229, Accuracy: 0.8473\n","Training loss (for one batch) at step 140: 225.6045, Accuracy: 0.8462\n","---- Training ----\n","Training loss: 204.3867\n","Training acc over epoch: 0.8459\n","---- Validation ----\n","Validation loss: 72.7294\n","Validation acc: 0.7268\n","Time taken: 9.77s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 208.4686, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 226.6248, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 229.0807, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 251.1629, Accuracy: 0.8471\n","Training loss (for one batch) at step 40: 218.7491, Accuracy: 0.8480\n","Training loss (for one batch) at step 50: 237.4094, Accuracy: 0.8504\n","Training loss (for one batch) at step 60: 220.0597, Accuracy: 0.8505\n","Training loss (for one batch) at step 70: 219.8678, Accuracy: 0.8524\n","Training loss (for one batch) at step 80: 225.7566, Accuracy: 0.8498\n","Training loss (for one batch) at step 90: 249.7518, Accuracy: 0.8487\n","Training loss (for one batch) at step 100: 236.8051, Accuracy: 0.8474\n","Training loss (for one batch) at step 110: 230.3651, Accuracy: 0.8469\n","Training loss (for one batch) at step 120: 251.5175, Accuracy: 0.8460\n","Training loss (for one batch) at step 130: 233.2234, Accuracy: 0.8469\n","Training loss (for one batch) at step 140: 217.2608, Accuracy: 0.8473\n","---- Training ----\n","Training loss: 193.6242\n","Training acc over epoch: 0.8471\n","---- Validation ----\n","Validation loss: 82.7324\n","Validation acc: 0.7407\n","Time taken: 9.62s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 236.0006, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 275.4685, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 224.0850, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 229.4396, Accuracy: 0.8484\n","Training loss (for one batch) at step 40: 214.2181, Accuracy: 0.8507\n","Training loss (for one batch) at step 50: 219.6051, Accuracy: 0.8543\n","Training loss (for one batch) at step 60: 210.5523, Accuracy: 0.8559\n","Training loss (for one batch) at step 70: 221.7872, Accuracy: 0.8545\n","Training loss (for one batch) at step 80: 252.8681, Accuracy: 0.8517\n","Training loss (for one batch) at step 90: 248.5285, Accuracy: 0.8485\n","Training loss (for one batch) at step 100: 220.0254, Accuracy: 0.8479\n","Training loss (for one batch) at step 110: 218.4499, Accuracy: 0.8478\n","Training loss (for one batch) at step 120: 236.8250, Accuracy: 0.8470\n","Training loss (for one batch) at step 130: 222.1794, Accuracy: 0.8462\n","Training loss (for one batch) at step 140: 225.6872, Accuracy: 0.8468\n","---- Training ----\n","Training loss: 213.6448\n","Training acc over epoch: 0.8459\n","---- Validation ----\n","Validation loss: 78.9477\n","Validation acc: 0.7233\n","Time taken: 9.55s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 249.1841, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 258.0826, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 233.1591, Accuracy: 0.8490\n","Training loss (for one batch) at step 30: 234.6354, Accuracy: 0.8506\n","Training loss (for one batch) at step 40: 216.6036, Accuracy: 0.8534\n","Training loss (for one batch) at step 50: 226.4022, Accuracy: 0.8569\n","Training loss (for one batch) at step 60: 227.7011, Accuracy: 0.8559\n","Training loss (for one batch) at step 70: 235.0992, Accuracy: 0.8558\n","Training loss (for one batch) at step 80: 239.4027, Accuracy: 0.8523\n","Training loss (for one batch) at step 90: 240.1903, Accuracy: 0.8533\n","Training loss (for one batch) at step 100: 224.4450, Accuracy: 0.8511\n","Training loss (for one batch) at step 110: 206.4951, Accuracy: 0.8518\n","Training loss (for one batch) at step 120: 238.6525, Accuracy: 0.8526\n","Training loss (for one batch) at step 130: 212.2846, Accuracy: 0.8520\n","Training loss (for one batch) at step 140: 224.5153, Accuracy: 0.8513\n","---- Training ----\n","Training loss: 195.0289\n","Training acc over epoch: 0.8501\n","---- Validation ----\n","Validation loss: 71.0064\n","Validation acc: 0.7268\n","Time taken: 9.74s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 217.5391, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 233.3684, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 221.3058, Accuracy: 0.8419\n","Training loss (for one batch) at step 30: 239.0179, Accuracy: 0.8371\n","Training loss (for one batch) at step 40: 217.2572, Accuracy: 0.8454\n","Training loss (for one batch) at step 50: 224.2989, Accuracy: 0.8502\n","Training loss (for one batch) at step 60: 222.0026, Accuracy: 0.8502\n","Training loss (for one batch) at step 70: 226.7914, Accuracy: 0.8520\n","Training loss (for one batch) at step 80: 225.1154, Accuracy: 0.8498\n","Training loss (for one batch) at step 90: 238.7160, Accuracy: 0.8502\n","Training loss (for one batch) at step 100: 223.8884, Accuracy: 0.8500\n","Training loss (for one batch) at step 110: 229.3535, Accuracy: 0.8499\n","Training loss (for one batch) at step 120: 239.7208, Accuracy: 0.8475\n","Training loss (for one batch) at step 130: 250.9081, Accuracy: 0.8473\n","Training loss (for one batch) at step 140: 213.8529, Accuracy: 0.8477\n","---- Training ----\n","Training loss: 198.9168\n","Training acc over epoch: 0.8476\n","---- Validation ----\n","Validation loss: 89.4679\n","Validation acc: 0.7292\n","Time taken: 9.56s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 239.5202, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 201.8464, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 215.8803, Accuracy: 0.8605\n","Training loss (for one batch) at step 30: 218.5889, Accuracy: 0.8600\n","Training loss (for one batch) at step 40: 224.1362, Accuracy: 0.8595\n","Training loss (for one batch) at step 50: 224.3408, Accuracy: 0.8584\n","Training loss (for one batch) at step 60: 207.1462, Accuracy: 0.8590\n","Training loss (for one batch) at step 70: 223.2149, Accuracy: 0.8562\n","Training loss (for one batch) at step 80: 210.5287, Accuracy: 0.8547\n","Training loss (for one batch) at step 90: 233.2205, Accuracy: 0.8538\n","Training loss (for one batch) at step 100: 215.8994, Accuracy: 0.8533\n","Training loss (for one batch) at step 110: 204.4661, Accuracy: 0.8545\n","Training loss (for one batch) at step 120: 240.0645, Accuracy: 0.8539\n","Training loss (for one batch) at step 130: 223.5328, Accuracy: 0.8534\n","Training loss (for one batch) at step 140: 214.7520, Accuracy: 0.8525\n","---- Training ----\n","Training loss: 192.4134\n","Training acc over epoch: 0.8522\n","---- Validation ----\n","Validation loss: 101.1248\n","Validation acc: 0.7464\n","Time taken: 9.55s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 225.3490, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 228.7551, Accuracy: 0.8673\n","Training loss (for one batch) at step 20: 215.2202, Accuracy: 0.8643\n","Training loss (for one batch) at step 30: 197.7697, Accuracy: 0.8565\n","Training loss (for one batch) at step 40: 216.7826, Accuracy: 0.8559\n","Training loss (for one batch) at step 50: 210.9516, Accuracy: 0.8563\n","Training loss (for one batch) at step 60: 185.4324, Accuracy: 0.8605\n","Training loss (for one batch) at step 70: 221.6328, Accuracy: 0.8597\n","Training loss (for one batch) at step 80: 237.9002, Accuracy: 0.8560\n","Training loss (for one batch) at step 90: 243.1780, Accuracy: 0.8542\n","Training loss (for one batch) at step 100: 220.1061, Accuracy: 0.8536\n","Training loss (for one batch) at step 110: 216.0082, Accuracy: 0.8541\n","Training loss (for one batch) at step 120: 216.7163, Accuracy: 0.8530\n","Training loss (for one batch) at step 130: 221.8288, Accuracy: 0.8538\n","Training loss (for one batch) at step 140: 243.2987, Accuracy: 0.8538\n","---- Training ----\n","Training loss: 187.5336\n","Training acc over epoch: 0.8530\n","---- Validation ----\n","Validation loss: 65.3169\n","Validation acc: 0.7399\n","Time taken: 12.26s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 223.1430, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 214.4745, Accuracy: 0.8609\n","Training loss (for one batch) at step 20: 224.4166, Accuracy: 0.8576\n","Training loss (for one batch) at step 30: 204.4060, Accuracy: 0.8558\n","Training loss (for one batch) at step 40: 229.6153, Accuracy: 0.8541\n","Training loss (for one batch) at step 50: 203.5903, Accuracy: 0.8608\n","Training loss (for one batch) at step 60: 200.2915, Accuracy: 0.8625\n","Training loss (for one batch) at step 70: 231.5151, Accuracy: 0.8601\n","Training loss (for one batch) at step 80: 213.8078, Accuracy: 0.8581\n","Training loss (for one batch) at step 90: 223.4111, Accuracy: 0.8568\n","Training loss (for one batch) at step 100: 249.9630, Accuracy: 0.8551\n","Training loss (for one batch) at step 110: 232.8295, Accuracy: 0.8560\n","Training loss (for one batch) at step 120: 204.2507, Accuracy: 0.8560\n","Training loss (for one batch) at step 130: 211.0639, Accuracy: 0.8555\n","Training loss (for one batch) at step 140: 205.2897, Accuracy: 0.8550\n","---- Training ----\n","Training loss: 205.8790\n","Training acc over epoch: 0.8546\n","---- Validation ----\n","Validation loss: 73.7562\n","Validation acc: 0.7340\n","Time taken: 11.61s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 210.7261, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 219.5418, Accuracy: 0.8618\n","Training loss (for one batch) at step 20: 223.3268, Accuracy: 0.8610\n","Training loss (for one batch) at step 30: 224.7014, Accuracy: 0.8555\n","Training loss (for one batch) at step 40: 207.7954, Accuracy: 0.8571\n","Training loss (for one batch) at step 50: 207.5413, Accuracy: 0.8590\n","Training loss (for one batch) at step 60: 212.0487, Accuracy: 0.8610\n","Training loss (for one batch) at step 70: 233.3741, Accuracy: 0.8596\n","Training loss (for one batch) at step 80: 220.9644, Accuracy: 0.8560\n","Training loss (for one batch) at step 90: 242.7449, Accuracy: 0.8536\n","Training loss (for one batch) at step 100: 204.8577, Accuracy: 0.8532\n","Training loss (for one batch) at step 110: 208.1953, Accuracy: 0.8541\n","Training loss (for one batch) at step 120: 236.1350, Accuracy: 0.8555\n","Training loss (for one batch) at step 130: 226.7918, Accuracy: 0.8550\n","Training loss (for one batch) at step 140: 190.4578, Accuracy: 0.8548\n","---- Training ----\n","Training loss: 212.8306\n","Training acc over epoch: 0.8559\n","---- Validation ----\n","Validation loss: 78.1958\n","Validation acc: 0.7380\n","Time taken: 12.03s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 211.8441, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 211.3328, Accuracy: 0.8682\n","Training loss (for one batch) at step 20: 216.5611, Accuracy: 0.8638\n","Training loss (for one batch) at step 30: 215.6792, Accuracy: 0.8619\n","Training loss (for one batch) at step 40: 214.7200, Accuracy: 0.8598\n","Training loss (for one batch) at step 50: 220.4537, Accuracy: 0.8616\n","Training loss (for one batch) at step 60: 217.9123, Accuracy: 0.8623\n","Training loss (for one batch) at step 70: 219.7946, Accuracy: 0.8631\n","Training loss (for one batch) at step 80: 205.6727, Accuracy: 0.8596\n","Training loss (for one batch) at step 90: 214.1844, Accuracy: 0.8595\n","Training loss (for one batch) at step 100: 240.4062, Accuracy: 0.8562\n","Training loss (for one batch) at step 110: 209.3367, Accuracy: 0.8571\n","Training loss (for one batch) at step 120: 217.5429, Accuracy: 0.8581\n","Training loss (for one batch) at step 130: 217.9002, Accuracy: 0.8579\n","Training loss (for one batch) at step 140: 182.7216, Accuracy: 0.8568\n","---- Training ----\n","Training loss: 191.6472\n","Training acc over epoch: 0.8566\n","---- Validation ----\n","Validation loss: 81.1752\n","Validation acc: 0.7294\n","Time taken: 11.67s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 213.2601, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 210.4605, Accuracy: 0.8609\n","Training loss (for one batch) at step 20: 219.0646, Accuracy: 0.8552\n","Training loss (for one batch) at step 30: 211.3838, Accuracy: 0.8539\n","Training loss (for one batch) at step 40: 210.8233, Accuracy: 0.8556\n","Training loss (for one batch) at step 50: 201.3317, Accuracy: 0.8618\n","Training loss (for one batch) at step 60: 219.7709, Accuracy: 0.8589\n","Training loss (for one batch) at step 70: 217.9709, Accuracy: 0.8586\n","Training loss (for one batch) at step 80: 218.9336, Accuracy: 0.8581\n","Training loss (for one batch) at step 90: 237.6157, Accuracy: 0.8555\n","Training loss (for one batch) at step 100: 195.1134, Accuracy: 0.8571\n","Training loss (for one batch) at step 110: 226.8462, Accuracy: 0.8574\n","Training loss (for one batch) at step 120: 203.3912, Accuracy: 0.8579\n","Training loss (for one batch) at step 130: 211.7243, Accuracy: 0.8567\n","Training loss (for one batch) at step 140: 199.8425, Accuracy: 0.8562\n","---- Training ----\n","Training loss: 187.9834\n","Training acc over epoch: 0.8557\n","---- Validation ----\n","Validation loss: 76.3640\n","Validation acc: 0.7351\n","Time taken: 12.68s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 222.3538, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 210.8752, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 199.0697, Accuracy: 0.8533\n","Training loss (for one batch) at step 30: 203.8229, Accuracy: 0.8606\n","Training loss (for one batch) at step 40: 189.1152, Accuracy: 0.8620\n","Training loss (for one batch) at step 50: 197.7253, Accuracy: 0.8625\n","Training loss (for one batch) at step 60: 211.7287, Accuracy: 0.8621\n","Training loss (for one batch) at step 70: 244.4792, Accuracy: 0.8586\n","Training loss (for one batch) at step 80: 223.9814, Accuracy: 0.8593\n","Training loss (for one batch) at step 90: 222.8166, Accuracy: 0.8582\n","Training loss (for one batch) at step 100: 202.9300, Accuracy: 0.8578\n","Training loss (for one batch) at step 110: 176.4690, Accuracy: 0.8581\n","Training loss (for one batch) at step 120: 204.1123, Accuracy: 0.8588\n","Training loss (for one batch) at step 130: 212.3854, Accuracy: 0.8586\n","Training loss (for one batch) at step 140: 220.5320, Accuracy: 0.8562\n","---- Training ----\n","Training loss: 194.5763\n","Training acc over epoch: 0.8561\n","---- Validation ----\n","Validation loss: 75.9550\n","Validation acc: 0.7157\n","Time taken: 9.59s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 230.0925, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 200.1562, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 223.3355, Accuracy: 0.8543\n","Training loss (for one batch) at step 30: 220.0371, Accuracy: 0.8519\n","Training loss (for one batch) at step 40: 194.4322, Accuracy: 0.8578\n","Training loss (for one batch) at step 50: 203.2601, Accuracy: 0.8600\n","Training loss (for one batch) at step 60: 201.8698, Accuracy: 0.8585\n","Training loss (for one batch) at step 70: 214.8760, Accuracy: 0.8576\n","Training loss (for one batch) at step 80: 220.6109, Accuracy: 0.8559\n","Training loss (for one batch) at step 90: 207.3334, Accuracy: 0.8562\n","Training loss (for one batch) at step 100: 190.1530, Accuracy: 0.8570\n","Training loss (for one batch) at step 110: 199.3675, Accuracy: 0.8579\n","Training loss (for one batch) at step 120: 221.2017, Accuracy: 0.8579\n","Training loss (for one batch) at step 130: 213.6779, Accuracy: 0.8588\n","Training loss (for one batch) at step 140: 217.9612, Accuracy: 0.8593\n","---- Training ----\n","Training loss: 176.6621\n","Training acc over epoch: 0.8587\n","---- Validation ----\n","Validation loss: 82.8633\n","Validation acc: 0.7356\n","Time taken: 9.56s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 213.9652, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 210.8337, Accuracy: 0.8582\n","Training loss (for one batch) at step 20: 227.5936, Accuracy: 0.8562\n","Training loss (for one batch) at step 30: 215.8772, Accuracy: 0.8561\n","Training loss (for one batch) at step 40: 205.1736, Accuracy: 0.8576\n","Training loss (for one batch) at step 50: 203.0273, Accuracy: 0.8625\n","Training loss (for one batch) at step 60: 211.5575, Accuracy: 0.8618\n","Training loss (for one batch) at step 70: 193.8993, Accuracy: 0.8617\n","Training loss (for one batch) at step 80: 197.0710, Accuracy: 0.8604\n","Training loss (for one batch) at step 90: 215.0128, Accuracy: 0.8592\n","Training loss (for one batch) at step 100: 213.6631, Accuracy: 0.8588\n","Training loss (for one batch) at step 110: 195.7118, Accuracy: 0.8601\n","Training loss (for one batch) at step 120: 203.1730, Accuracy: 0.8601\n","Training loss (for one batch) at step 130: 196.2987, Accuracy: 0.8598\n","Training loss (for one batch) at step 140: 194.9056, Accuracy: 0.8600\n","---- Training ----\n","Training loss: 181.0541\n","Training acc over epoch: 0.8599\n","---- Validation ----\n","Validation loss: 77.7909\n","Validation acc: 0.7491\n","Time taken: 9.53s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 197.4661, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 194.8199, Accuracy: 0.8709\n","Training loss (for one batch) at step 20: 219.4585, Accuracy: 0.8676\n","Training loss (for one batch) at step 30: 215.6848, Accuracy: 0.8616\n","Training loss (for one batch) at step 40: 222.6736, Accuracy: 0.8632\n","Training loss (for one batch) at step 50: 209.0684, Accuracy: 0.8645\n","Training loss (for one batch) at step 60: 192.6278, Accuracy: 0.8664\n","Training loss (for one batch) at step 70: 219.3259, Accuracy: 0.8611\n","Training loss (for one batch) at step 80: 226.5875, Accuracy: 0.8598\n","Training loss (for one batch) at step 90: 214.3805, Accuracy: 0.8589\n","Training loss (for one batch) at step 100: 207.9332, Accuracy: 0.8583\n","Training loss (for one batch) at step 110: 194.4805, Accuracy: 0.8584\n","Training loss (for one batch) at step 120: 207.2030, Accuracy: 0.8586\n","Training loss (for one batch) at step 130: 201.6017, Accuracy: 0.8595\n","Training loss (for one batch) at step 140: 209.0617, Accuracy: 0.8589\n","---- Training ----\n","Training loss: 181.4627\n","Training acc over epoch: 0.8591\n","---- Validation ----\n","Validation loss: 96.0079\n","Validation acc: 0.7303\n","Time taken: 9.56s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 204.8411, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 199.5325, Accuracy: 0.8709\n","Training loss (for one batch) at step 20: 204.9743, Accuracy: 0.8643\n","Training loss (for one batch) at step 30: 215.7510, Accuracy: 0.8648\n","Training loss (for one batch) at step 40: 185.2607, Accuracy: 0.8661\n","Training loss (for one batch) at step 50: 191.7678, Accuracy: 0.8694\n","Training loss (for one batch) at step 60: 191.7196, Accuracy: 0.8666\n","Training loss (for one batch) at step 70: 210.0619, Accuracy: 0.8627\n","Training loss (for one batch) at step 80: 198.7667, Accuracy: 0.8621\n","Training loss (for one batch) at step 90: 213.3179, Accuracy: 0.8600\n","Training loss (for one batch) at step 100: 203.1328, Accuracy: 0.8593\n","Training loss (for one batch) at step 110: 218.2767, Accuracy: 0.8590\n","Training loss (for one batch) at step 120: 214.2911, Accuracy: 0.8588\n","Training loss (for one batch) at step 130: 203.7892, Accuracy: 0.8591\n","Training loss (for one batch) at step 140: 208.8095, Accuracy: 0.8593\n","---- Training ----\n","Training loss: 182.7482\n","Training acc over epoch: 0.8588\n","---- Validation ----\n","Validation loss: 70.6561\n","Validation acc: 0.7364\n","Time taken: 9.60s\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABrjUlEQVR4nO2dd3hVxfaw35XeE5LQAyR06RCKiCWIBRtYQMEGdr12r/36Kbb706tey7Vi7xEbooKIQABFSugQeggQahJIIz2Z74/ZOTkJ6Tkn5WTe5zlPzp49M3tNsrPXnrXWrBGlFAaDwWAwALg1tQAGg8FgaD4YpWAwGAwGG0YpGAwGg8GGUQoGg8FgsGGUgsFgMBhsGKVgMBgMBhtGKRgMdUBEYkQkuanlMBichVEKhkZDRJJE5JymlsNgMFSNUQoGg4sgIh5NLYOh5WOUgqHJERFvEXlNRA5an9dExNs6Fy4iv4hIuogcE5FlIuJmnXtERA6ISJaIbBeRcVX0f5GIrBORTBHZLyIz7M5FiogSkWkisk9EUkXkX3bnfUXkExE5LiIJwIgaxvK6dY1MEVkjImfYnXMXkcdFZLcl8xoR6WKd6y8iC6wxHhGRx63yT0TkObs+ypmvrNnXIyKyETghIh4i8qjdNRJE5LIKMt4iIlvtzg8TkYdE5PsK9d4QkderG6/BBVFKmY/5NMoHSALOqaT8GWAF0A5oCywHnrXO/R/wLuBpfc4ABOgD7Ac6WfUigR5VXDcGGIh+CRoEHAEutWungPcBX2AwkA+cYp1/AVgGhAJdgM1AcjVjvBYIAzyAfwKHAR/r3EPAJkt2sa4VBgQCh6z6PtbxKKvNJ8BzFcaSXOF3ut6Szdcqmwx0ssZ7FXAC6Gh37gBauQnQE+gGdLTqhVj1PICjQHRT3zfm07ifJhfAfFrPpxqlsBu40O74fCDJ+v4M8BPQs0KbntZD6xzAs45yvAa8an0vVQoRdudXAVOs74nAeLtzt1anFCq51nFgsPV9OzCxkjpTgXVVtK+NUrixBhnWl14XmA/cW0W9ecAt1veLgYSmvmfMp/E/xnxkaA50AvbaHe+1ygBeAnYBv4tIoog8CqCU2gXcB8wAjopIrIh0ohJEZJSILBaRFBHJAG4HwitUO2z3PQcIsJNtfwXZqkREHrRMMxkikg4E212rC1oBVqSq8tpiLx8icr2IrLdMbunAgFrIAPApeqaD9fPzBshkaKEYpWBoDhxEmzBK6WqVoZTKUkr9UynVHZgAPFDqO1BKfaWUOt1qq4AXq+j/K2AO0EUpFYw2R0ktZTuEfpDay1Yplv/gYeBKoI1SKgTIsLvWfqBHJU33A92r6PYE4Gd33KGSOrZUxyLSDW0KuwsIs2TYXAsZAGYDg0RkAHqm8GUV9QwujFEKhsbGU0R87D4ewNfAEyLSVkTCgSeBLwBE5GIR6Skign7AFgMlItJHRM62HNJ5QC5QUsU1A4FjSqk8ERkJXF0HeWcBj4lIGxGJAO6upm4gUASkAB4i8iQQZHf+A+BZEeklmkEiEgb8AnQUkfssp3ugiIyy2qwHLhSRUBHpgJ4dVYc/WkmkAIjIDeiZgr0MD4pItCVDT0uRoJTKA75DK9FVSql9NVzL4IIYpWBobOaiH+ClnxnAc0A8sBHtiF1rlQH0Av4AsoG/gbeVUosBb7QTOBVt+mkHPFbFNf8BPCMiWWiFM6sO8j6NNhntAX6nepPKfOA3YIfVJo/ypp3/Wtf+HcgEPkQ7h7OAc4FLrLHsBMZabT4HNqB9B78D31QnrFIqAXgF/bs6gnaw/2V3/lvgefSDPws9Owi16+JTq40xHbVSRCmzyY7BYNCISFdgG9BBKZXZ1PIYGh8zUzAYDABY6z8eAGKNQmi9mBWQBoMBEfFHm5v2AuObWBxDE2LMRwaDwWCwYcxHBoPBYLBhlILBYDAYbBilYDAYDAYbRikYDAaDwYZRCgaDwWCwYZSCwWAwGGwYpWAwGAwGG0YpGAwGg8GGUQoGg8FgsGGUgsFgMBhsGKVgMBgMBhtGKRgMBoPBhlEKBoPBYLBhlILBYDAYbLTo/RTCw8NVZGSk7fjEiRP4+/s3nUCNgKuPsTmNb82aNalKqbZNce3Wdm+7+vigeY2xunu7RSuFyMhI4uPjbcdxcXHExMQ0nUCNgKuPsTmNT0T2NtW1W9u97erjg+Y1xurubWM+MhgMBoMNoxQMBoPBYMMoBYPBYDDYaNE+heZIYWEhycnJ5OXlOaX/4OBgtm7d6pS+mwNNMT4fHx8iIiLw9PRs1OsaDM0RoxQcTHJyMoGBgURGRiIiDu8/KyuLwMBAh/fbXGjs8SmlSEtLIzk5maioqEa7rsHQXDHmIweTl5dHWFiYUxSCwfGICGFhYU6b2RkMLQ2jFJyAUQgtC/P3MhjKcJr5SER8gKWAt3Wd75RST4nIJ8BZQIZVdbpSar3o/8zXgQuBHKt8bUNkKCouYf6WI0SF+9OvU1BDujIYDIZmRWp2PvFJx9mdkk2nEB+iwgPoGupHsK8n7m71f9Fxpk8hHzhbKZUtIp7AnyIyzzr3kFLquwr1LwB6WZ9RwDvWzzpTUqKYt/kw/12wnd0pJxjbpy0f3zCynsMwGAyG5kFJieKnDQd4e/Fudh7NrrJeoI8H/TsFEXvr6Dpfw2lKQSmlgFKpPa2PqqbJROAzq90KEQkRkY5KqUN1vfZ936xnzoaD9GwXQPe2/hzNyq+z/C2VtLQ0xo0bB8Dhw4dxd3enbVu9mn3VqlV4eXlV2TY+Pp7PPvuMN954o9prnHbaaSxfvtxhMn/yySfEx8fz5ptvOqxPg6ElcSK/iE0HMtiTeoI9qSfILyymd4dA+nYIJNDHk/ScQg5l5PLekkQSDmXSv1MQj13Ql+hubejTIZAjmXkkppwg+XguGbmFZOQWEuRTv8e7U6OPRMQdWAP0BN5SSq0UkTuA50XkSWAh8KhSKh/oDOy3a55slR2q0OetwK0A7du3Jy4uznYuOzubuLg4enkUcctAL0Z3KuHjzQVsSi0uV8+ZBAcHk5WV5bT+i4uLq+3fy8uLZcuWAfDvf/+bgIAA7rnnHgDy8/M5ceIEHh6V/9n79OnD888/X6P88+fPd+gY8/LyKCgoICsrq8bxOYu8vLxGu0cMBqUUWw5m8nvCEZbvSmX9/nSKSvQ7s5eHG55uwomC4pPaRbTx5fUpQ7hkUCfc7ExEgT6e9GznmKg9pyoFpVQxMEREQoAfRWQA8BhwGPACZgKPAM/Uoc+ZVjuGDx+u7HOJlOYWibGrvzp/G38fSuTMM88q90t0Flu3brWFVD798xYSDmY6tP9e4b48d8WQWtX19vbG29ubu+++Gx8fH9atW8eYMWOYMmUK9957L3l5efj6+vLxxx/Tp08f4uLiePnll/nll1+YMWMG+/btIzExkX379nHffffZlEtAQIBNAc+YMYPw8HA2b95MdHQ0X3zxBSLC3LlzeeCBB/D392fMmDEkJibyyy+/VCqnj48PXl5eBAYGsnnzZu655x5SU1Np27YtH3/8MV27duXbb7/l6aefxt3dneDgYJYuXcqWLVu44YYbKCgooKSkhO+//55evXrV6/fq4+PD0KFDqzwvIuPRPi934AOl1AsVzncFPgVCrDqPKqXmikgksBXYblVdoZS6vV5CGlosOQVF7Eov5mj8frYeymRBwhGSj+fiJjAwIoRbzuzOyKhQerULoGOwL24Cycdz2X44i7yiYkJ8vQjx86R3+0C8PJwbH9Qo6xSUUukishgYr5R62SrOF5GPgQet4wNAF7tmEVZZgwgP8KaoRJGRW0gb/6pNJ65OcnIyy5cvx93dnczMTJYtW4aHhwd//PEHjz/+ON9///1JbbZt28bixYvJysqiT58+3HHHHSct8Fq3bh1btmyhU6dOjBkzhr/++ovhw4dz2223sXTpUqKiopg6dWqt5XzooYeYNm0a06ZN46OPPuKee+5h9uzZPPPMM8yfP5/OnTuTnp4OwLvvvsu9997LNddcQ0FBAcXFJ79ZOQJrxvsWcC56BrtaROYopRLsqj0BzFJKvSMi/YC5QKR1brdSaohThDM0e7YczGD6x6tJycoHNuLt4cZpPcK45+xenNOvPaFVPJe6hPrRJdSvcYXFudFHbYFCSyH4ov+hXiz1E1jRRpcCm60mc4C7RCQW7WDOqI8/oSLhAfoXnpqd3+hK4alL+ju8z/qaViZPnoy7uzsAGRkZTJs2jZ07dyIiFBYWVtrmoosuss022rVrx5EjR4iIiChXZ+TIkbayIUOGkJSUREBAAN27d7ctBps6dSozZ86slZyrVq1izpw5AFx33XU8/PDDAIwZM4bp06dz5ZVXcvnllwMwevRonn/+eZKTk7n88svrPUuoBSOBXUqpRADrHp0I2CsFBZSGuAUDB50ljKF5UlRcwnO/bmXZzhRuO6sHlw/tzJq9x7n503gCfTy4a4g3k84ZTZdQvwZFBzkbZ84UOgKfWm9Zbui3qF9EZJGlMARYD5ROpeeiw1F3oUNSb3CEEG0DvAFIyc6nV3vXXQlcE/Z53P/f//t/jB07lh9//JGkpKQq0/l6e3vbvru7u1NUVFSvOo7g3XffZeXKlfz6669ER0ezZs0arr76akaNGsWvv/7KhRdeyHvvvcfZZ5/tjMtX5u+qGBk3A/hdRO4G/IFz7M5Ficg6IBN4Qim1rLKL1MZf5qq0tPEVlyhSchVhvoKnm5BbpHhrfT6bU4tp6ys8/N1GXpm7iWN5inBf4Z9DPPEuziVp82qSmlr4GnBm9NFG4CQjrVKq0v9aK+roTkfLER6oH1qp2QWO7rrFkpGRQefOnQEd+eNo+vTpQ2JiIklJSURGRvLNN9/Uuu2oUaOIjY3luuuu48svv+SMM84AYPfu3YwaNYpRo0Yxb9489u/fT0ZGBt27d+eee+5h3759bNy40VlKoTZMBT5RSr0iIqOBzy0f2iGgq1IqTUSigdki0l8pdZKzqTb+MlelJYxv/7EcZq87wIo9aazbl05OQTFeHm4Mjgjm2IkC9h4r4YXLB3LViC78nnCE1/7YSedwNz6YNoJQf68WMUZoBbmPwq2ZQmorCkutiYcffphp06bx3HPPcdFFFzm8f19fX95++23Gjx+Pv78/I0aMqHXbl156ibvvvpuXXnrJ5mgG7WvYuXMnSinGjRvH4MGDefHFF/n888/x9PSkQ4cOPP744w4fi0Vt/F03AeMBlFJ/W4s3w5VSR9FrdlBKrRGR3UBvIB5Ds+JEfhE7jmQxtGubcuV/JBzhwz/38HdiGiLQr2MQk6MjOKVjELuOZhO/9zhFJYpPbxzJmJ7hAJzfvwPn9+/QFMNoOEqpFvuJjo5W9ixevFhVpLi4RHV/7Ff14rytJ51zBgkJCU7tPzMz06n9O4qsrCyllFIlJSXqjjvuUP/9739r1a6pxlfZ3w2I1z/wABKBKHTU3Aagv7K7F4F56FX4AKegfQoCtAXcrfLuaGUSqhxwb7sSTT2+kpISddMnq1W3R35RT/20WRUUFavi4hL1yvxtqtsjv6jTX1yo3vhjh0o+nlPvazT1GO0pvbcr+7j8TMHNTQjz9yI128wUGpP333+fTz/9lIKCAoYOHcptt93W1CLVG6VUkYjcBcxHh5t+pJTaIiLPoP+55gD/BN4XkfvRTufpSiklImcCz4hIIVAC3K6UOtZEQzFUwfwth/lj6xGGdg3hk+VJbD2USViAF3M3Heaq4V149tIBTg8FbS64vFIAbUIyPoXG5f777+f+++8vV/bxxx/z+uuvlysbM2YMb731VmOKVi+UUnPRwRD2ZU/afU8AxlTS7nvg5HhfQ7MhM6+Qp+Zs4ZSOQcy6bTS/bDzIo99voqC4hH9deAo3nxHVqpImtg6lEOhtZgrNgBtuuIEbbnBIUJnB4DBenr+do1n5vHfdcDzd3bhsaAQDOweTkVtIdLfQphav0WkdSiHAi11HGj91gsFgaH7kFRbzxsKd7DqaTUp2Puv3pzNtdCRDuoTY6jgqZURLpFUohbaW+Ugp1aqmgQaDoTwlJYp/fruBuZsO0ad9IG0DvZk2OpIHz+/T1KI1G1qFUggP8KaguITMvCKCfc0+vAaDK6OUoqhE4el+smP4tT928OvGQzx2QV9uO6tHE0jX/GkVSiHMSnWRlp1vlILB4MIUlyju+moti7YdZWRUKKf3DKdX+wDcRNh5JJs3Fu3iquFduPXM7k0tarOlVcRY2RawtYIIpLFjxzJ//vxyZa+99hp33HFHpfVjYmKIj9frqC688EJbsjl7ZsyYwcsvv3xSuT2zZ88mIaEsFdCTTz7JH3/8UUfpq+aTTz7hrrvuclh/BtdDKcWzvyQwb/Nhzu7bjiOZefzfvG3c+Ek80z9ezfNztzK6exjPXjrAmJGroVXMFMqUgutHIE2dOpXY2FjOP/98W1lsbCz/+c9/amw7d+7cGutUxezZs7n44ovp168fAM88U+ts6AaDQ/hg2R4+WZ7ELWdE8a+L9H14JDOPwxl5FCuFUjCwc3CrWW9QX1qHUggsy5TaqMx7FA5vcmiX3mF9YMJ/qzw/adIknnjiCQoKCvDy8iIpKYmDBw/y9ddf88ADD5Cbm8ukSZN4+umnT2obGRlJfHw84eHhPP/883z66ae0a9eOLl26EB0dDehFaTNnzqSgoICePXvy+eefs379eubMmcOSJUt47rnn+P7773n22We5+OKLmTRpEgsXLuTBBx+kqKiIESNG8M477+Dt7U1kZCTTpk3j559/prCwkG+//daWk6k6kpKSuPHGGxt9zwVD8yMtO5+lO1NYvC2FORsOctHAjjx2wSm28+2DfGgf5NOEErY8WoXKDPXzQqR15D8KDQ1l5MiRzJunt8OOjY3lyiuv5Pnnnyc+Pp6NGzeyZMkSNm7cWGUfa9asITY2lvXr1zN37lxWr15tO3f55ZezevVqNmzYwCmnnMKHH37IaaedxoQJE3jppZdYv349PXqUOfDy8vKYPn0633zzDZs2baKoqIh33nnHdj48PJy1a9dyxx131GiiKuXuu+9m2rRpbNy4kWuuuca2+U/pngsbNmywpd8u3XNh/fr1xMfHn5T629DyKCwu4bfNh7nh41WMeP4P7v9mA3/tSuWaUV155crBjbKZlivTKmYKHu5uhPp5kdLYPoULXqi5Th3Jz8qipl0hSk1IEydOJDY2lg8//JBZs2Yxc+ZMioqKOHToEAkJCQwaNKjS9suWLeOyyy7Dz09v8DFhwgTbuc2bN/PEE0+Qnp5OdnZ2OTNVZWzfvp2oqCh69+4NwLRp03jrrbe47777AGx7I0RHR/PDDz/U4jcAf//9t61uM9pzwdAIJKWe4JoPVnIgPZf2Qd78I6Yn5/fvQP9OQUYZOIhWMVOA0lQXZTMFnRPKNZk4cSILFy5k7dq15OTkEBoayssvv8zChQvZuHEjF110EXl5efXqe/r06bz55pts2rSJp556qt79lFK6H4Mj9mJ49913ee6559i/fz/R0dGkpaVx9dVXM2fOHHx9fbnwwgtZtGhRg65haDqOZuZx3UcryS0s5v3rh/PXI2fz4Pl9GBgRbBSCA2k9SiGwLCnevrQcBj39O6uTXDMvWUBAAGPHjuXGG29k6tSpZGZm4u/vT3BwMEeOHLGZlqrizDPPZPbs2eTm5pKVlcXPP/9sO5eVlUXHjh0pLCzkyy+/tJUHBgZWuitcnz59SEpKYteuXQB8/vnnnHXWWQ0a32mnnUZsbCxApXsuPPPMM7Rt25b9+/eTmJho23Nh4sSJ1ZrNDM2XzLxCpn28mrTsAj6ePoJz+7XHo5J1CIaG0yrMR6BnCmv3HQfgx3UHyMorYu3e44yIdM3cJlOnTuWyyy4jNjaWvn37MnToUPr27UuXLl0YM+akvG3lGDZsGFdddRWDBw+mXbt25fZDePbZZxk1ahRt27Zl1KhRNkUwZcoUbrnlFt544w2+++47W30fHx8+/vhjJk+ebHM03357w/at/9///scNN9zQ3PZcMDiQ3IJi3li0k9V7jlFQXMLRzHzSTuTz4bQRDLZLR2FwPNKSzSjDhw9XpTH2UP3uTc/+ksBXK/eR8Mz5jPvvEhJTTjB1ZFf+7/KBDpVp69atnHLKKTVXrCdZWVkEBrpuXpamGl9lfzcRWaOUGt7owlC3e9sVsB/f6qRjPPzdRvaknmBEZBv8vT3w9nDjyuFdGHdK+6YVtAE0p79hdfd2q5op5BYWE7/3OIkpJwDYd+xEE0tlMBhKKSgq4ZXftzNzWSKdQ3z56uZRnGbtZGZoPFqRUtAxOx8u24OnuzC6Rzi7j2Y3sVSGinzxxRe899575cpayp4LhvpzNKeEye8uZ0NyBleP6sq/LjwFf+9W83hqVrSa33p4oI5y+T3hMGP7tKN/pyD+3JlCflEx3h7uDr2WycZaf6699toqU3I4i5ZsQnUF1u9P56nluXh6FPLONcO4YGDHphapVdN6lIK/VgolCiYM6URRsaJEQfLxXHq0DXDYdXx8fEhLSyMsLMwohhaAUoq0tDR8fMyq16aguETx+A+b8PUQfrrnDLqE+jW1SK2e1qMUrFQXPp5unHNKe7YeygR0eKojlUJERATJycmkpKQ4rE978vLyXPoB1hTj8/HxMSudm4ivV+0j4VAm/xjsbRRCM6HVKIUwf2/cBM7t1wF/bw+6hfkDkJTmWGezp6cnUVFRDu3Tnri4OIYOHeq0/pua5jo+ERkPvA64Ax8opV6ocL4r8CkQYtV51NrXGRF5DLgJKAbuUUqVT2PbSjl+ooCXf9/O6O5hjOiQ29TiGCxajVLw8nDjf1OHMbhLMKAdz35e7uxNy2liyQzNHRFxB94CzgWSgdUiMkcplWBX7QlgllLqHRHpB8wFIq3vU4D+QCfgDxHprZQqbtxRND0lJYo3Fu3Ew00Y2rUNP284SFZeEU9N6MfhbWubWjyDhdOUgoj4AEsBb+s63ymlnhKRKCAWCAPWANcppQpExBv4DIgG0oCrlFJJjpTpokFlDiwRoVuYP3sdPFMwuCQjgV1KqUQAEYkFJgL2SkEBQdb3YOCg9X0iEKuUygf2iMguq7+/G0Pw5sSXK/fy2h87y5VNPy2Svh2COLytiYQynIQzZwr5wNlKqWwR8QT+FJF5wAPAq0qpWBF5Fz2tfsf6eVwp1VNEpgAvAlc5UT66hfqx4+jJqRkMhgp0BvbbHScDoyrUmQH8LiJ3A/7AOXZtV1RoW2l+cBG5FbgVoH379sTFxdnOZWdnlztuaaTklPDcX7n0D3PjjsE+7Mko5vAJxal+R4mLS2nx46sNLWWMTlMKSsf5lS4E8LQ+CjgbuNoq/xT9z/QO+o1qhlX+HfCmiIhyYrxgt3A/Fm47QnGJwt0k1DI0jKnAJ0qpV0RkNPC5iAyoSwdKqZnATNArmu1Xvzan1bB1RSnF9R+twsO9gPduPpOINic7lFvy+GpLSxmjU30Kli12DdATbZPdDaQrpUrTYdq/NdnexpRSRSKSgTYxpVbo02FvU/mphRQWK36cv5hw37ol18ouUHy3o4ArensR6NV4CqWlvG3Ul2Y6vgNAF7vjCKvMnpuA8QBKqb8t82l4Ldu6NLPi97NsZyrPXjqgUoVgaF44VSlYzrQhIhIC/Aj0dUCfDnub8tqVyidbVtKx1yDG1HE5/UvztxGXvJvLTh9AzJCadwtzFC3lbaO+NNPxrQZ6Wf6wA2jH8dUV6uwDxgGfiMgpgA+QAswBvhKR/6Idzb2AVY0leFNzNDOP537dyqndQ7lmZNemFsdQCxol+kgplS4ii4HRQIiIeFizBfu3ptI3qmQR8UA769KcKVe3cB2WujcthzE9dWbGxduPciK/iLyiElAKbw93vD3dOL1nOGHWXs9ZeYV89vdeAFseJYPrYs1c7wLmo8NNP1JKbRGRZ4B4pdQc4J/A+yJyP9pMOt0yfW4RkVlop3QRcGdrijya8fMW8otK+L/LB5k9D1oIzow+agsUWgrBFx3O9yKwGJiEjkCaBvxkNZljHf9tnV/kTH8CQIcgH7zc3WwRSHd/vY4/th6ptG73cH9m3zWGIB9Pvlixj6y8Ivy83ElMNUqhNWCtOZhboexJu+8JQKU5yZVSzwPPO1XAZsCuo9n8uvEQ007rRoifFwsSjjB302EeOr8PUdYLmKH548yZQkfgU8uv4IaO4f5FRBKAWBF5DlgHfGjV/xDtnNsFHENP0Z2Ku5vQJdSXvWk5LEg4wh9bj3DvuF5cMSwCH083EJ25MeFgJnd8uZYHZ23g9SlD+fDPPZzRKxw3EfakmqR6BgPA878msHh7Cp/+ncQ/z+vN/xbuom+HQG49s3tTi2aoA86MPtoInLQ01Yr1HllJeR4w2VnyVEW3MH+2H8lixpwt9G4fwF1n98Szwo5OEW38eOyCvjz361amvr+C1Ox8/hEzlPlbDhOfdMwkwDO0epJSTxC3I4UrhkWQlHaCf/24GRF459phJ/0/GZo3rWZFc1V0C/Nj0bajAMy6bXSVN/BNp0exfn86v2w8xNCuIZzaPZSdR7M4UVBMSlY+7YJcNx+RwVATn6/Yi7sIj4zvQ3iAN7PXH6BEwdCubZpaNEMdMUrBSsI1KTqCkVFVb80pIrx4xSD8vTy4elRXRITu4TqR3u6UE0YpGFotOQVFzIrfzwUDO9r+Dy4fZhIMtlRa/bzurD7tOK9fex67oOZoWX9vD16cNMi2R2xUW+0822OczYZWTOme59NGd2tqUQwOoNXPFKLC/Zl5ff224e0Y5IO3h5txNhtaLUopPlu+l/6dgojuZkxFrkCrnyk0BDc3ISrc38wUDK2WvxPT2H4ki2mjI02whYtglEIDiQr3N2sVDK2Wd5ckEh7gxYQhnZpaFIODMEqhgXRv68++tBwKi0uaWhSDoVHZfCCDpTtSuGFMFD6ejt3n3NB0GKXQQKLCAygqUSQfNztHGVoX7y7ZTYC3B9eeahzMroRRCg2kdPm+cTYbWhNJqSeYu+kQ15zalWBfz6YWx+BAjFJoIN0tpWAS4xlaEzOXJeLh5sZNY5y3H7mhaTBKoYG08fcixM/TRCAZWg27U7L5bk0yV0RHmEWbLohRCg6ge7i/mSkYWgWZeYXc8lk8Ad4e3DOuZ1OLY3ACRik4gKjwgEpnCkopikucmv3bYGg0iksU98WuZ19aDm9fM4yOwb5NLZLBCRil4AC6t/XncGYeB9LLIpAycgu57O3l3Bu7rgklMxgcx38XbGfRtqM8dUk/Tu0e1tTiGJyEUQoO4Lx+7Qnw9mDqzBUcSM8lt6CYmz9dzfr96czbfJjjJwqaWkSDoUHEbT/KW4t3c9XwLiYE1cUxSsEB9GofyOc3jeR4TgFXvfc3t34eT/ze49x+Vg+KSxQLqtjNzWBoCaRk5fPgtxvo0z6Qpyf2N+ksXByjFBzE0K5t+PLmUWTmFrJsZyrPTBzAI+P70DnEl982H66yXZFZCW1oxpSUKB78dgNZeUW8MXWoWbncCjBKwYEMigjhh3+M4f3rh3Pdqd0QEcYP6MCfO1PJyis8qf66fcfp/9R81u9Pb3xhDYYaKCou4fWFO1myI4UnLjqFPh0Cm1okQyNglIKD6dkugHP7tbcdXzCgAwXFJbbd3eyZv+UI+UUlvP7HjsYU0VAPRGS8iGwXkV0i8mgl518VkfXWZ4eIpNudK7Y7N6dRBa8HSinmbTrE+a8t5fWFO7loYEfjR2hFtPr9FJzNsK5taBfozW+bDzNxSOdy5/7clYKbwOLtKWxKzmBgRHATSWmoDhFxB94CzgWSgdUiMkcplVBaRyl1v139uym/P3muUmpII4nbYN5YuItX/9hBz3YBvHttNOf3b2/8CK0IM1NwMm5uwvn9OxC3PYXcgmJb+bETBWw5mMktZ3QnyMeD/y3a2YRSGmpgJLBLKZWolCoAYoGJ1dSfCnzdKJI5gUXbjzK0awjz7zuT8QM6GIXQnFEKjm5zaJdmptAIXDCgA5+v2MuSHUcZP6AjAH/tSkUpGD+gA96e7ryxcCfbDmfSt0NQE0trqITOwH6742RgVGUVRaQbEAUssiv2EZF4oAh4QSk1u4q2twK3ArRv3564uDjbuezs7HLHzqKoRLElOYdzunmybOkSp1+vlMYaX1PijDG2PxzHKdteJT76FbIDHbPC3CiFRmBkVCjhAV7Ert5vUwp/7kwl0MeDQREhRIX78+GyRN5ctIs3rx7WxNIaGsgU4DulVLFdWTel1AER6Q4sEpFNSqndFRsqpWYCMwGGDx+uYmJibOfi4uKwP3YWmw9kUPT7n1w0egAxgxtv45zGGl+Tseg5tuRA/4ufcGy/n7wMwPDg43BmjEO6NOajRsDD3Y0bxkQRZ/kOlFL8uSuV03qE4e4mhPh5Me20SH7ddIiViWlNLa7hZA4AXeyOI6yyyphCBdORUuqA9TMRiKO8v6FZsSE5HYDBESFNKodLkZ0CS1/mlK2vwoG1jus3fR8kLdPfEx03qzNKoZG4fnQ3m+8gKS2HA+m5nN6rre38nWN70qWNH//8dkOl4auGJmU10EtEokTEC/3gPymKSET6Am2Av+3K2oiIt/U9HBgDJFRs21zYlJxBiJ8nXUJNXiOHsXshoCh294ZZ0yDnmGP63fiN/nnKJbB/JRTkOKRbpykFEekiIotFJEFEtojIvVb5DBE5YBeid6Fdm8eskL/tInK+s2RrCgJ9PLlhTBS/Jxzhg2WJAJzRM9x23t/bg1evGszB9Fye+bnZPjNaJUqpIuAuYD6wFZillNoiIs+IyAS7qlOAWKWUfRbEU4B4EdkALEb7FJrtH3hDcgYDOwcb53JNFBfBqvdr9yDeuQD827Jp4FOQdQh+vB1KGrhoVSnYEAvdxsCwaVBcAPtXNKxPC2fOFIqAfyql+gGnAneKSD/r3KtKqSHWZy6AdW4K0B8YD7xthQK6DDeOiSLA24MvV+6jc4gv3cL8yp2P7hbKP2J68u2a5GpXQRsaH6XUXKVUb6VUD6XU81bZk0qpOXZ1ZiilHq3QbrlSaqBSarD188PGlv0kCk7oh0oF8gqL2XEki0HNJTR61x+Q8FPD+tj6C+z8wzHylOv3J5j7IKz/svp6JcV6HD3PJTO4D5z/b9g5H5b+p2HXP7AG0nbB4KnQdTS4eTrMhOQ0paCUOqSUWmt9z0K/YXWupslE9FtWvlJqD7ALHQroMgT7eXL9aL0I6Ixe4ZW+jd0zrhcDOgdxT+w63l2yu8Y0GAfSc3nku43kFRZXW89gACAvE17pC5u/P+nUloOZFJcoBlXlT1jyEuz9u/JztWXfCi1DbfhjBnx/M6Sd5JOvHcWFMOcu/Skuql8fVbHxW/1z18Lq6yXHQ1469DpXH4+8RT/I4/4PNv+gy0qK4ff/B/+Lhqxa5knb8DV4+EC/ieAdABEjIDGu7HzOsXqbqRol+khEItHOtZVom+pdInI9EI+eTRxHKwz7+U8ylSiR5hC21xBOcVN0C3IjUlKqlPWW3opPC4UX5m3jm+U7GNvFgxKlX+76BOSXazdndwE/7Cykh3sKvdu0/IlVS/gbtmiO7Yb8TDi8EQZOKndqk+VkrnSmkHkIFj8H7frB7X+BWz3eJ/Oz4ZOLoM+FcNXn1dctKtDx9yWFMP9xuNqynx9LhB9uhZjHoOe46vvYswRyj+vvuxZAnwvqLnNl5BzT/bl7wZ6lUJQPHt6V1921AMQdeoyF1A0gApe8Dsf2wOw7wDcElr9p+R0EFj0LE98sa5++T18nsENZWVG+Vup9LwYfK4S9+1kQ94KWzTsIvrsRMpLhH3+De9320Ha6UhCRAOB74D6lVKaIvAM8Cyjr5yvAjbXtrzmE7TWUS86ruc6E8xS/bjrEkz9t4aPNZam3z+7qyUeXx9iOP05cBaQQ2rUPMdERjhe2kWkpf8MWy/Ek/TMj+aRTG5MzaBvoTYfKttgsjXI5mqDNH/V5wB7fAyVFsHUOJP0JkadXXTdlq1YIXUbBjt9g+2/QaQh8dimk79WziB5n64dsVWz5EbwCwdMX1n5WN5mV0m/w7pU8IhNm63GM/Rcsfh72/Q3dYyrvZ+fv0GUk+LYpK/Pwhqu+gA/Ohs8v06afi1/T5qC/39KziY6DIXUnfHAOdBwE034ua79/pVZ2Ay4vK+seo2cfSX9C8mpIXAyXvFFnhQBOjj4SEU+0QvhSKfUDgFLqiFKqWClVArxPmYmoLmF/Lo+IcPGgTvz1yNkse3gsKx4bxxm9wklILTMTFZco1u7Vb0J708x2oIZacHyv/pm+/6RTGw9kMKgqJ3PiEvAJgeCusOy/lfokauSYDrDA0w/mPaofulVxaKP+ecnrEN4HfnsEPr8cTqTCiFv0TMfeXFKR4kLtT+h7IQy9BnbM17OdmlAKEubAm8Phf0Ph8KaT62z8Vst06j/0W/zOBZX3lXUEDm0oMx3ZE9AWpn4DPc/VD/zhN8CZD4FfmP7dZB2BL67Qpqd9K6CwbAMvkv4EcdNO5lI6R4NXACz+Nyx/A4bfBNHTah5vJTgz+kiAD4GtSqn/2pV3tKt2GbDZ+j4HmCIi3iISBfQCVjlLvpaCr5c7XUL96BDsw1m923I4R9l2eNt2OJOsfG0rTUqrOgrimZ8TmBV/8kPA0AqpYqaQnV/E7pTsyv0JSmlTTNQZMOYeSF4Fe5fX/dqlSmH8C3BkE6yrxoR0aIN+yIX3gQte1HKn7oApX8L5z0NAe/3ws6fYLpQ7cYl+oPa/DIZeB6q4zClcUqydz0UVNr86lggfngezrtMmn+Iifbxldlmd9P2wbzkMnKxt+V1HV+1X2GU5uHtVYRpo3w+u/Q66jdbHviFw9hO6/5lnwYkUiHnciixaWdYu6S/oMEjXL8XdUyuJlK1apvEvVH7NWuDMmcIY4Drg7Arhp/8RkU0ishEYC9wPoJTaAsxCx3D/BtxZYVVoq+f0XjqE9a9dqQCs3qMdST3a+lc5UygpUXy5ci+fLk9qFBkNzZxSpZB1qNxDdPOBDJSqwp9wfA9k7Ieos2DoteAXDn/+9+R6NXEsEfzbwrDroetpsPBZ+PVBiL2G/pv/raOiSjm8EdoP0L6LHmNh/Ivar9BjrDa/nHoH7F6kZxSFuTrM88Uo/RYN2nTkHaRNTGE9IPIMrYSOJ2m/xpdXwPLXy8v3x9NwdCtM+B/csRxujdMyfDsN5twNKdth83e6bqk/pte5+kFsr2SV0orir9chsKPuo7YMux7aD4TsIzDpIxj9D62g9izV5wvztHmoMtPboCt128mfgodX7a9ZAWdGH/2plBKl1CD78FOl1HVWaN4gpdQEpdQhuzbPWyF/fZRS85wlW0ulT/tAgrzslMLe43QK9uG0HuHsST2BqmRKfzgzj/yiEhIOZZKeY7YFbfUcT9KmBxRkHgR0quyvVu7DTapQCqUPpKgztX3+1Dv0W/DBOu4/fmwPhHbXfoALXtBKYNO3cHQrbVNXavs76Df5w5u1Xb2UU28v71iOvkH7CxY9Cx9fqKNxvPzhyyu1Ytj2s3ZolzqAh03TY39zJBzZouVY81nZeoETqbDtVxh2nX4wu3tAYHuY/guMuh02fANvjYQl/4GIkRAapdv1PEf/LJ0V7Fuh/QBfXA75WXDhy9X7PSri5q6V3w2/aR+IdyB0HgZ7LJ9O8moozq9cKQycBHf8qeVuAGZFcwtCROgX5s5fu1IpKVGs3nOMEVGhdAvzIyuviPSck1dCJ6Xqty+lYOUeB62kNLRMSor1G3/pw9Z6u/1q1T7mbDjI/ef0JiygkiiaPUshoAOE99bHI24G31D47fHyvoW1n+kH4onUyq9/LFE/jEHL8PhBeHQv3LWaAs9g7QMorVd4QjtYq8I3RNvMd/5umZW+gtuW6AfipxMgL0Objko55RIIitAP2Nv/1E7ijH2QaOUt3BCrHdtDryt/HQ9vbb56IAHGPqHf/E+9vex827663+3zYOEz8PEF+i3/4lfh3vVwysVVj6EqgjtDV7t8i1Fn6nUJ+VnWTEi0ichJGKXQwugf5k5qdgELth7haFY+wyND6RbmD0BSJSakPVaZm8Dfu01epVZN5gEdNVP6lpmxn80HMnh6TgJn9QrlzqGVRKoopZVC1Jllb7y+IXDOU9r2vckypxzZok1Byav12oKKTuTCXH39UqUAZWGtbu6khY3QzuCifO1PAG03r44x9+m3+psWQN+LdNjmtJ/1Q9W3jTY1leLpA/esgxvmQZtuWkn4hUH8x3qMaz/Vsf7t+1V+Lf9wOOshuGctDLiirFxEz2B2/AbLXoEh1+gw0OE3Vh2mWlciz9A+kX0rYO9fWlna+xMcjFEKLYx+YXotwut/6P0XRkaGEmmtjN5bibM5KfUE3h5ujO4RxgqTbK91U+pP6KaVQn7aXv7x5VpC/b14u+9m3N4aWRbXX8rRrdrh2f2s8uVDr4NOQ+H3J/TM4PubwScYxj2lwyGXvFj5te2Vgh0pbUdDQZZWQIc36jDNtn2rH09AW23/t3+QB0fArUvglkUnP5Q9vMoUm4e3foBvn6dXTafu0Cam+jD0Wi3rlZ/rNQbeDt62tMuosiin/au0knAiRim0MMJ83ege7k/CoUyCfT3p1S6ALqF+iFSuFPakniAyzJ/TeoSz7XAWadn5TSB18+Hnn3+mpKF5Z1oqpeGobfuAXzh7E3ew71gOr141BP+ja7StumKo6h4rdULUmeXL3dy1vTz7MLx3ll6/cOnbcPr9MPhqbXu3Ty9RGnlUaouvKFqbwdpHsPVn7Txud0r9naV+oVUqn3JET9dv4D/dpSOd7M1NdaHLSLhzJfSbUHPd+uDlp2cx6z7XfyP7UFQnYJRCC2SMlUhveLc2uLkJPp7udAzyqTQCaU/qCSLD/RjdIwyAFYmt26/wzTff0KtXLx5++GG2bXPsjlXNnuNJOpIlOAKCI8g+mkSf9oGc2j20LB7fcj7b2LMM2kRBSNeT+4sYrt+SM5Nh5G06EkcELnpFvznPfbDM52BTCpU/rJWbp26/7Vc9U6jOn+AownpoZVeQpU1C3gHOv2Z9iToTCnMAKQthdRJGKbRAbEohMtRW1i3M/ySfQnGJYv+xXCLD/RnYORh/L3f+TqzCCdhK+OKLL1i3bh09evRg+vTpjB49mpkzZ5KVldXUojmf40laIbh7kuPXiYC8Q1w6tDNSXAAploLMqqAUUrbqlcRVcd7zesZw7tNlZV5+MOImHcqatkuXHUvUdn77lb0VOeViyEmFnDToMLjqeo5k1O1aUQ6vdVKFpqHUZNRhYPW/QwdglEIL5Kzebbn21K5cNrQsNVRkuN9J5qOD6bkUFJcQFeaPp7sbI6JCjbMZCAoKYtKkSUyZMoVDhw7x448/MmzYMP73v/81tWjOJX2vdrIC23OD6SypTBzcUfsNSqyEcfYzhZISyDgAwV0q6czCN0SnZfCssP9C6Sre0lBN+8ijquh1nradQ+PMFEA7qB/aVb3iaw5EDNcrymvK9+QAjFJogfh6ufPcpQPpEFyWo6ZrqD9pJwrItNugZ48VjhoZrqOTRncPY3fKCY5m5jWuwM2IOXPmcNlllxETE0NhYSGrVq1i3rx5bNiwgVdeeaWpxXMux5OgTSRKKf5O9cVf8unknVdmOnLzKK8UTqRoG3ZlpqOaaBMJYb3KUkDURil4B0L3sYDUbcFXQ/ELrblOU+PhDf9YAWc9WnPdhl7K6VcwNAqlEUj70nIY0FkvQCo1J0WVKgXLr7B0ZyqTXCB5Xn34/vvvuf/++znzzPKOUz8/Pz78sOm3OmgwOcd0Zs2Kb7752foh3yaSDckZbMwOAi/0WoXDm8DTXzugM+3SjWVYTufqZgrV0fMciP8IctP1dQZPrbnN2U9A7/Obt32/qQjqWHMdB2BmCi5CZWsV9qSewM/LnXaBOjSvf6dgercP4D+/beP4iYavbi4sLmHOhoOUlNQjOVoTMWPGDEaOLNumIzc3l6SkJADGjXP+1NzpLHoO3j/75NXG6VbkUUg3Zq87QIqbtRVsqVLoMED7G+xnCun7rDb1VAq9ztEzjfVfgSqpXURQx0HaH2FoMoxScBG6VbJWIckKRy3NeunuJrx61RCO5xTw2A+bKk2LURcWbTvKPV+vY+nOlAb105hMnjwZN7u9ANzd3Zk8eXITSuRg9izVYZY/3q7z5JRihaMWBXfj5w0H6dHLWgOQvs9SCgMhqLP2IZTeFw2dKXQbozeCWf2+Pq6NUjA0OUYpuAj+3h60DfQuF5aalJZjMx2V0r9TMA+e14ffthzm2zUn59SvC6U+izV7j9dQs/lQVFSEl1dZ/LuXlxcFBS6SEyr7KKTthB7jdDTRomfLzlmLx5akaN/TecMHgLs37P1Th2R2GAhBnXR6iXxrZ7T0/eAdXLaRS13x9NVRMzWEoxqaF0YpuBCRYX62FNqFxSXsP5ZDZLjfSfVuPqM7p3YP5ek5W0g+XouNx6ugVAG1JKXQtm1b5syxbavMTz/9RHh4eI3tRGS8iGwXkV0icpK3T0RetcsGvENE0u3OTRORndannstma8Hev/TPmMd0iOXfb+k0y6CVglcgn63PokOQDzF922lz0S4r90+pUoAyE1JGcv1NR6WUJozzDtJpJQzNHqMUXIhuYf62bKnJx3MpKlFEhvmfVM/dTXh58mAKixVvLa7n/rdAUqpWKOv3p9e4l3Rz4d133+Xf//43Xbt2pUuXLrz44ou899571bYREXfgLeACoB8wVUTKJclRSt1fmg0Y+B/wg9U2FHgKGIXeUOopEXFOoHnSX9ph3GkInPusDj/94gqdqO1oAgVBXVi6K5UrR3TBw91NK4XCEzpOv10/bT6CMmdzxv76m45KKQ1NDY2qW7ZQQ5NhlIILMSoqlJSsfF7+fbstO2pF81EpEW38uGpEF75bs9+2aU9FNh/IqHYWsO9YDgHeHuQUFLPtcMtY/NWjRw9WrFhBQkICW7duZfny5fTs2bOmZiOBXUqpRKVUARALTKym/lTga+v7+cACpdQxay/yBcD4Bg6jcvb+pVMuuHvq6J1pv+gFYctegaRl7CvRzuWrRlgP+tIHfnhvbeqxzRSsbPbp+xs+UwjroRVOTcntDM2GWoWkiog/kKuUKhGR3kBfYJ5S6uRczYYmY1J0BGv2HuetxbsZ1lUvUousQikA3B7Tg9jV+3gnbhfPXTqw3Lmi4hJu/jSeI1l53D22J/ee0xt3t7I3vbzCYg5m5DI5OoJZ8cnEJx2zhcI2d3799Ve2bNlCXl6ZI/bJJ5+srklnwD4pUDL6zf8kRKQbEAUsqqZt54rtrLa3ArcCtG/fnri4ONu57OzscscV8SzIZMzRBBL9h7LPvl7YtQREn0qXvd/zbspQBoa7s3P9SnYC3dKLiQKOSDu2xsUhJYWcBezZ+BfJx0I5Iz+D3akF7K/murXBo9e/KHHzpKSafmoanyvQUsZY23UKS4EzrGnv78Bq4CrgGmcJZqg7IsJzlw7gSGYei7enEOjtQZh/1UnFOof4Mim6C7NWJ3Pn2J50DC5blfrH1iMczsxjeLc2vLFoF2v2Hed/U4cRavWXfDwHpfTah6U7UlmzL53pzs3T5RBuv/12cnJyWLx4MTfffDPfffdduRBVBzAF+K4+uwYqpWYCMwGGDx+uYmJibOfi4uKwPz6JrXpj9+4x19H9pNw4MSxIuITvPotn5vghxPTvoIvXJUPS17QffA7tx1h9r2lHVKgXUQO6wZ/QIzqGHv2rua6DqHF8LkBLGWNtzUeilMoBLgfeVkpNBvo7TyxDffFwd+PNq4cxOCKYgRFVbMJuxz9ielCiFO8tSSxX/vmKvXQO8eWb20bznysGsXrPcV5dsMN2vjT0tVuYP9GRbVjbQpzNy5cv57PPPqNNmzY89dRT/P333+zYsaOmZgcAeztKhFVWGVMoMx3VtW39SfpLh392Hlbp6a9X7aNdoDdn921XVhjex5JoRFlZUCftaG5oOKqhxVJrpSAio9Ezg1+tMnfniGRoKP7eHnx3x2l8fMOIGut2CfXjimERfLVqH1sP6VDEXUez+WtXGleP6oq7m3DliC6M6h5KvN2DvzTKKTLMn+iubTiQnsuhjMp9E6DNUWNeWMTnfyfVe1xKKWbF7+dIA9J0+Pjo1CB+fn4cPHgQT09PDh06VEMrVgO9RCRKRLzQD/45FSuJSF+gDfC3XfF84DwRaWPNtM+zyhzL3j/1w72SjV1yC4pZtjOFS4d21g7mUrqMgDtXlc+6GdTZUgpWuLJRCq2O2iqF+4DHgB+VUltEpDuw2GlSGRqMp7sb3h6109sPnNebNn6e3PxpPClZ+Xy5ci+e7sKVw8seCEO7hLD9cCYn8nXitL1pJwj08aCNnyfR3XQwTXVO6Z1HszmQnsvCbUfrPaZfNx3i4e828vnfe+vdxyWXXEJ6ejoPPfQQw4YNIzIykquvvrraNkqpIuAu9MN8KzDL+j94RkTsk+hPAWKV3apApdQx4Fm0YlkNPGOVOY7c43pP48r27QXW7jtOYbGypTkpR9s+5Y+DOuroo/R9eh2Df1uHimpo/tTKp6CUWgIsARARNyBVKXWPMwUzNB7tg3z44PoRTH5vObd8Fs/ulGwuGNCRtoFlb51DuoZQomDTgQxO7R7G3rQcuoX56X2jOwXh4+lGfNJxLh7UqdJrbExOB2Dt3uOUlCjc3OoWnngiv4jnftkKaBnqQ0lJCePGjSMkJIQrrriCiy++mLy8PIKDa3aQK6XmAnMrlD1Z4XhGFW0/Aj6ql9C1Yf8qQFW5+crKxDTcRO+/USNBnSAvXe9EFhxRtmWmodVQq7+4iHwlIkFWFNJmIEFEHnKuaIbGZGBEMK9dNYT1+9PJyiviutHdyp0fHBEC6DUJoGcKpfmWPN3dGBwRwtp9Vc8UNiTrB3lmXhGJqdl1lu+NRTs5nJlHv45BbD6QUa8UHW5ubtx55522Y29v71ophGZP1mH9s4pdzVbs0ZFhgT6V7MFckdK1CvtXNjwc1dAiqe1rQD+lVCZwKTAPHXJ3nbOEMjQN4wd05NlLB3Dl8IiT3irDArzpGurH+n16oVry8VxbZlaAEZGhbDmYybxNldvnN+xPp3OIjm5auze9TnLtOprFh8v2cOXwCK4cHkHaiQKOZNZvW9Fx48bx/fffNzjvU7Oi2ErT4eFz0qm8wmLW709nVFQt00OXrlXIPa5nCoZWR22VgqeIeKKVwhxrfYIL/VcZSrnu1G78Z9LgSqOWhnQJYf3+dA6m51FUougWWrYG4oYxkQzsHMwdX67lv79vL5c5Na+wmO2Hs5gwpBPBvp51Tovx3K9b8fNy55HxfRkYod/s62tCeu+995g8eTLe3t4EBQURGBhIUFA9c/s0F4osx3slTuZ1+9IpKCrh1O61TDERZLeEIrge+ygYWjy1VQrvAUmAP7DUWqCT6SyhDM2TIV1COJyZx4o9emFcN7uZQliAN7G3nsrk6AjeWLSLB7/bYDuXcCiTohLFkC4hDO1avZmpIjkFRSzbmcrVo7oRFuDNKR2DENGrretDVlYWJSUlFBQUkJmZSVZWFpmZLfxWtimFk2cKK/ekIVJ+69ZqCbTL2W/MR62S2jqa3wDesCvaKyJjq2sjIl2Az4D26FnFTKXU61YumG+ASLSiuVIpdVz0q+nrwIVADjBdKbW2bsMxOJOhXUMAmLNeJ0zrViGvko+nO/+ZNIggX08+/HMP947rRbcwfzZYfojBESFsP5xF3PYUMnILCfat2ca9YX8GxSWKkVHanOXn5UGPtgFsOVg/pbB06dJKyytuutOiKMoHcdM7p1VgZeIx+nUMqtXvGtD7K/u2scxHRim0Rmqb5iIYndSr9D9nCfAMUN1/ZhHwT6XUWhEJBNaIyAJgOrBQKfWClW3yUeARdLKxXtZnFPAOVaQSMDQN/ToF4eXuxvLdqfh4utk277FHRLj5jCg+/msP38Yn8+D5fdiYnEG7QG86BPvYwlfX70/nrN41hzuWziqGdS3zcQzsHMzy3an1GsNLL71k+56Xl8eqVauIjo5m0aJF1bRq5hTl6VlCBZNfflExa/cd55pR3apoWAVBnbVSMDOFVkltzUcfAVnAldYnE/i4ugZKqUOlb/pKqSx0fHdndCKxT61qn6L9FFjlnynNCiBERBpn/zlDrfD2cOeUTkGUKOgW6l9lWGnHYF/O7N2W79YkU1yi2JCcziAremlwlxDcpPyahuoyrK7Ze5ye7QII8StL19G/UxBHMvM5mlX3RWw///yz7bNgwQI2b95MmzbOSVraaBTlV+pP2LA/g/yiEk7tXsc9iIM6AQKBlYcXG1yb2uY+6qGUusLu+GkRWV/bi4hIJDAUWAm0V0qVhqgcRpuXoOrEYeXCWRqSNMwVaOoxthUd9eOncqqVo79vEXGZ+bwUu5DElHyGhBTY6ncOcGPh+t0M9TjADzsLWbC3kIdH+tA92L3c+EqUYuXuHKLbe5S7VtExnVYo9rc/GdS2YduMK6VYs2ZNy75vSmcKFViZqP0JI2sbeVRK+wF6BzaPqvNmGVyX2v5H5YrI6UqpPwFEZAxQdU4DO0QkAPgeuE8plWkf1aKUUiJSpyimBiUNcwGaeozpwQf4Y996hvfpSkxMvyrrnVZUQuzOhcxO0n/vS88YypmWuejM45uYs/4gizLa8nOiXj09a48nP999On8tW2ob366j2ZyYv4SLR/UjZkSZKSM6r5AXVv2OhHYjJqZXneS/++67bZFVJSUlrF+/ntNPP71l3zeVzBSKSxRzNx+mb4egcrOsWjH2X3CmWYbUWqmtUrgd+MzyLQAcB2rcQcoKY/0e+FIp9YNVfEREOiqlDlnmodK8B42TOMzQIKK7tcFNoFf7wGrreXm4cfmwzry/bA8AgyLKFokN69qGL1fu4/MVe7ntrO4M69qG2z5fw8ylifS3s0iVJtkbVmHNRKCPJ1Hh/myuxNlcXKLIKyzG37vyW3v48OG27x4eHkydOpUxY1pAetfqqGSmELta57J6Y+rQuvfn7qE/hlZJbaOPNgCDRSTIOs4UkfuAjVW1saKJPgS2KqX+a3dqDlqhvGD9/Mmu/C4RiUU7mDPszEyGZkKXUD/m3Xsm3dtWvU9DKVeN6ML7y/bQLcyv3NvqmJ7htAv05oYxUdwR0wOACwZ04PWFO3lmdNkb75q9xwnx86R7JXtCDOgcXGlm1ge/3cDqpGMse3hspWstJk2ahI+PD+7uOi9UcXExOTk5+PmdvG1pi6HCTCE9p4CX529nVFQolwwybjlD3ahTYhOlVKa1shnggRqqj0Gvej7bbu/aC9HK4FwR2QmcYx2DziuTCOwC3gf+URfZDI1Hnw6BeLrXfOv0bBfIef3aM740f79Fh2AfVj4+zqYQAJ6e0B9vDzc+2pxvczyv2XecYV3bVOrQHtApiAPpuRw/UWArW7z9KD+uO0Dy8Vz2WDvPVWTcuHHk5pZZPnNzcznnnHNqHEuzpsJM4ZXfd5CRW8iMCf1rTJ1uMFSkIdmuqr3blFJ/KqVEKTWodO9apdRcpVSaUmqcUqqXUuqc0oyRVtTRnUqpHkqpgUqp+AbIZmgmzLx+OI9deMpJ5RUfVu2CfJhxSX92HC/h6Z8TSM8pYNfRbFsIa0VKo5leX7iTkhJFTkERT/y42ZbEL76KVdN5eXkEBATYjgMCAsjJyanP0JoPdjOFhIOZfLlyL9ed2o1TOrbwldqGJqEhhkOT5sLgUK6IjuCP+AQ+X7GXQxk63NR+fYI9p3YPZdrobnyyPImUrHzaBnpzID2Xb249ldu+WEN80rFyqb9L8ff3Z+3atQwbpjejWbNmDb6+vifVa1EU5YGXVnSfr0jCz8uDB87tU0Mjg6FyqlUKIpJF5Q9/AVr4f5KhOTK5tyfFvqH8nnAEdzdhSJeQSuuJCDMm9KdzG1/+PXcbAFNHdmVU9zCGd2tT5UzhtddeY/LkyXTq1AmlFIcPH+abb75x1nAah6IC20xhzd7jDI9sQ7BfLVcwGwwVqFYpKKWqDzExGByMmwivTRnC1PdX4uPhhq9X1RsFiQi3ntmDTiG+zF53gEfH9wUgulsof2w9Slp2PmEB5UM1R4wYwbZt29i+fTsAffr0wdOzhT9ALZ9CRk4hO45kc0kVe1oYDLXB7KBhaHb4eXnw7W2j+eymkbWqf/GgTnwwbYTt7XhEZNU7wb311lucOHGCAQMGMGDAALKzs3n77bcdJ3xTUJQPHj6s3a/HW5UfxmCoDUYpGJolXh613060IgM6B+Pl7lapCen9998nJCQE0KuZUwo8eP/99xsiatNTlAce3qzdexx3N2FwFSY3g6E2mBUqBpfDx9OdQRHBrE4qvxXyifwicgsKWbrjKEt2pLIg4Qh7U7PwOFH3HErNCmumsGbvcU7pGFjlwj2DoTaYu8fgkkRHtuGjP/eQV1hMZm4h13+0im2Hszge2JcLJlxBm+gL6d8piI7r5jH8gvFNLW7DKMqjxN2L9fvTmRxtdkszNAxjPjK4JCO6hVJYrIjbnsI1H6xk/7EcHjyvNx++9Sr/uHoiI/LWEJQUx0VnjUIVFdTYn4iMF5HtIrLLSvleWZ0rRSRBRLaIyFd25cV2CzjnOHCYUFIMJYWk5Ak5BcUnpQQxGOqKmSkYXJJSZ+s9X69DBD65YSSje+gtKXu4j+OrrCPMmjWL1NRUrrjiiuq6QkTcgbeAc9HZe1eLyBylVIJdnV7AY8AYa9OodnZd5CqlhjhweGUU6ay1+zP1KnDjZDY0FKMUDC5JG38verYLICn1BDOviyasOI2nn36Tr7/+mvDwcK666ioAFi9eXJvuRgK7lFKJAFZ+rolAgl2dW4C3lFLHAZRSR0/qxRlYW3EmZRTTPsibziFm+ZChYRilYHBZ/nvlYAqLlc7s6taRM844g19++YWePXsC8Oqrr9a2q8r2+qi4K2BvABH5C3AHZiilfrPO+YhIPHo3wheUUrMru0h99grxyk/jNGDb0Vy6hhSxZMmS2o6pWdHU+4Q0Bi1ljEYpGFyW0vxIAD/88AOxsbGMHTuW8ePHM2XKFJRyaKYWD/RWsjHotO9LRWSgUiod6KaUOiAi3YFFIrJJKbW7Ygf12ivk2B74G44VeDB+eB9iTo9y5JgajabeJ6QxaCljNI5mQ6vg0ksvJTY2lm3btjF27Fhee+01jh49yh133MHvv/9eU/Pa7PWRDMxRShUqpfYAO9BKAqXUAetnIhCH3oXQMVg+hXy8GNY1xGHdGlovRikYWhX+/v5cffXV/PzzzyQnJzN06FBefPHFmpqtBnqJSJSIeAFT0Pt/2DMbPUtARMLR5qREEWkjIt525WMo74toGJZPAXcvBnQOrr6uwVALjFIwtFratGnDrbfeysKFC6utp5QqAu4C5gNbgVlKqS0i8oyITLCqzQfSRCQBWAw8pJRKA04B4kVkg1X+gn3UUoMp1uG0XduH1mqPC4OhJoxPwWCoBUqpueiNoOzLnrT7rtAbTz1Qoc5yYKCz5MrKziYQ6NkxzFmXMLQyzKuFwdCC2XEgBYC+Xdo2sSQGV8EoBYOhBbP7UBoAvTqHN7EkBlfBKAWDoQWTdEQn/fPy9mtiSQyuglEKBkMLJTOvkNTjGfrAw7v6ygZDLTFKwWBoocQnHcOLQn3g4dO0whhcBqMUDIYWysrEY/i5FekDM1MwOAijFAyGFsqKPcfoFmztTmdmCgYHYZSCwdACOZFfxOYDGUSFWEuN3L2aViCDy+A0pSAiH4nIURHZbFc2Q0QO2G04cqHducesDUy2i8j5zpLLYHAFth3OpLhE0SlA9CxBpKlFMrgIzpwpfAJUts/hq0qpIdZnLoCI9EPnk+lvtXnb2tjEYDBUwoF0nfMo2LPY+BMMDsVpSkEptRQ4VmNFzUQgVimVb2WY3IXe2MRgMFTCwfRcAPzdi8DdKAWD42gKn8JdIrLRMi+V7h1Y2SYmnRtfNIOhZXAwPZcgHw+8VJFxMhscSmMnxHsHeBZQ1s9XgBvr0kF9dqdyJVx9jK4+PkdxMD2PTiG+OnW2MR8ZHEijKgWl1JHS7yLyPvCLdVibTUxK+6j77lQuhKuP0dXH5ygOpudaSiHfzBQMDqVRzUci0tHu8DKgNDJpDjBFRLxFJAq9Y9WqxpTNYGhJHMzIpVOIj5kpGByO02YKIvI1eieqcBFJBp4CYkRkCNp8lATcBmBtWDILvSNVEXCnUqrYWbIZDC2ZnIIi0nMK9UzhuJkpGByL05SCUmpqJcUfVlP/eeB5Z8ljMLgKB61w1E7Blk/Bx2zDaXAcZkWzwdDCKA1HNT4FgzMwSsFgaGGUKQXjUzA4HqMUDIZaICLjrRQsu0Tk0SrqXCkiCSKyRUS+siufJiI7rc+0hspyMD0XEWgf5GNmCgaH09jrFAyGFoeVcuUt4Fz0wsrVIjJHKZVgV6cX8BgwRil1XETaWeWh6CCL4egAizVW2+P1ledgRh7tA33wdHczMwWDwzEzBYOhZkYCu5RSiUqpAiAWnZrFnluAt0of9kqpo1b5+cACpdQx69wCKs8JVmv0GgVrdmBmCgYHY5SCwVAztUnD0hvoLSJ/icgKERlfh7Z1wrZwDcxMweBwjPnIYHAMHuhFlzHoFflLRWRgXTqoTQoXpRTJx3PoG1hI3OLFxBTnk5R8iKQWnhqkNaQ3aSljNErBYKiZ2qRhSQZWKqUKgT0isgOtJA6gFYV927jKLlKbFC6p2fkUzf+DUwf2ImZUJ1gCkT37EHlGTGVdthhaQ3qTljJGYz4yGGpmNdBLRKJExAu998ecCnVmYz38RSQcbU5KBOYD54lIGysr8HlWWb0ov0ZBL2IzPgWDIzEzBYOhBpRSRSJyF/ph7g58ZKVmeQaIV0rNoezhnwAUAw8ppdIARORZtGIBeEYpVdt9Rk7ipIVrYHwKBodilILBUAusXQLnVih70u67Ah6wPhXbfgR85Ag5Sndc6xTiC4UZutDMFAwOxJiPDIYWxKH0XHw83Wjj52k3UzBKweA4jFIwGFoQOmW2LyJi51Mw5iOD4zBKwWBoQRxIz9PZUcHMFAxOwSgFg6EFUX41s5kpGByPUQoGQwshv6iYlKz88quZwcwUDA7FRB8ZDC0ENxE+vmEEXdr46QITkmpwAkYpGAwtBE93N8b2aVdWYGYKBidgzEcGQ0uldKbg7tW0chhcCqMUDIaWipkpGJyAUQoGQ0ulqED/ND4FgwMxSsFgaKmYmYLBCRilYDC0VEz0kcEJGKVgMLRUivLAzRPc3JtaEoMLYZSCwdBSMfszG5yA05SCiHwkIkdFZLNdWaiILBCRndbPNla5iMgbIrJLRDaKyDBnyWUwuAxmf2aDE3DmTOETYHyFskeBhUqpXsBC6xjgAvTWhb3Qe9S+06ArKwW5xxvUhcHQ7DEzBYMTcNqKZqXUUhGJrFA8kbL9aj9F71X7iFX+mbVRyQoRCRGRjkqpQ/W6+Pc3w+FNcNeqejU3NBGJcfTcORNawD62zQIXmykUFhaSnJxMXl5eU4viFIKDg9m6dWujXtPHx4eIiAg8PT1r3aax01y0t3vQHwbaW987A/vt6iVbZfVTCmE9YcsPUJADXn71ldXQ2MS9SMSB5ZCfBd6BTS1N86coz6VmCsnJyQQGBhIZGan3i3AxsrKyCAxsvPtaKUVaWhrJyclERUXVul2T5T5SSikRUXVtJyK3ok1MtG/fnri4ONu57Oxs4uLiCE8VBqgS1vz2OVlBfRwmc3OgdIyuhnfeUUbvWw7Aqj9+JMe/axNL1AIoynepmUJeXp7LKoSmQEQICwsjJSWlTu0aWykcKTULiUhH4KhVfgDoYlcvwio7CaXUTGAmwPDhw1WMnakhLi6OmJgYSO8OW/6P6I4eMCKmsm5aLLYxuhrLXrF9HdmnE/SMcd61Dm+Gtn3AvfZT6maJi80UAKMQHEx9fp+NHZI6B5hmfZ8G/GRXfr0VhXQqkFFvfwJAcBfwCdF+BUPzRynYOAtCuunjjGTnXevYHnj3dNgQW6dmIjJeRLZbEXKPVnJ+uoikiMh663Oz3bliu/I5DhiFpigfPEwyPEeRlpbGkCFDGDJkCB06dKBz586244KCgmrbxsfHc88999R4jdNOO81R4joNp80URORrtFM5XESSgaeAF4BZInITsBe40qo+F7gQ2AXkADc08OLQYSAc3tigbgyNxOFNkLINLvgPat6jiDOVwr6/AVWne0NE3IG3gHPR/q7VIjJHKZVQoeo3Sqm7KukiVyk1pJ4SV01RHviFOrzb1kpYWBjr168HYMaMGQQEBPDggw/azhcVFeHhUfkjc/jw4QwfPrzGayxfvtwhsjoTp80UlFJTlVIdlVKeSqkIpdSHSqk0pdQ4pVQvpdQ5SqljVl2llLpTKdVDKTVQKRXfYAE6DIIjW6C4qMFdGZzMplng5gEDJ5Pv3ca5M4V9K/TPlG11aTUS2KWUSlRKFQCx6Ii5psXFfArNkenTp3P77bczatQoHn74YVatWsXo0aMZOnQop512Gtu3bwe0Wffiiy8GtEK58cYbiYmJoXv37rzxxhu2/gICAmz1Y2JimDRpEn379uWaa65BB1/C3Llz6du3L9HR0dxzzz22fhsL191kp+Mg/SaVtgva9W1qaQxVUVIMm76DnueCXyj53m3xcaZS2L9S/0zZXpdWlUXHjaqk3hUiciawA7hfKVXaxkdE4oEi4AWl1OzKLlKbIAp7RmVnkOGewTYXCDzIzs4mODiYrKwsAF78fTfbjmQ79Bp92wfwyHk9alU3Pz8fT09PCgsLOXz4MPPnz8fd3Z3MzEzmzp2Lh4cHixcv5uGHH+aLL74gJyeHoqIisrKyyM/PZ8uWLfz6669kZ2czbNgwrr32Wtzc9Dt4VlYWOTk5rFu3jpUrV9KxY0fOPfdcFixYwNChQ7n11luZN28ekZGR3HDDDbZ+60teXl6dglNcVyl0GKh/Ht5klEJzZu9yyDoE5/8bgDyftgQ7SynkHtczBL8wyD4COcccaX75GfhaKZUvIreh1+GcbZ3rppQ6ICLdgUUiskkptbtiB7UKorBnjeDbuSsdXCDwIC4uDh8fH1vIpqeXJ+7ujs3p5OnlWeuQUG9vb7y9vfH09GTq1KmEhIQAkJ6ezo033sjOnTsREQoLCwkMDMTPzw8PDw8CAwPx9vZmwoQJhIeHEx4eTvv27cnJySE4OBjAVn/kyJH07aufTdHR0Rw9epQDBw7Qo0cPBg7Uz6/rr7+emTNnNiiU1cfHh6FDh9a6vusqhfDe4O4NhzfAoMlNLY2hKpKWgbhBr3MByPduC2kroaQE3Bxs3dy/Wv8ccjUs/x+k7oCup9amZY3RcUqpNLvDD4D/2J07YP1MFJE4YChwklKoMy4YfVTKU5f0b2oRbPj7+9u+/7//9/8YO3YsP/74I0lJSVVGAnp7l5n13N3dKSo62YxdmzpNgesmxHP3hHanmAikxuLgOvjlAW0Oqgv7V0L7/rbFavne4VBcADmpjpdx/0oQdxhyjT6uvV9hNdBLRKJExAuYgo6Ys2GFWJcyAdhqlbcREW/rezgwBqjooK4fxqfQ6GRkZNC5c2cAPvnkE4f336dPHxITE0lKSgLgm2++cfg1asJ1lQJov8KhjTrk0eBc4j+C+A/hwJratykphuQ10KXMPJ/nE66/ZOyvolED2L9SmxXD+4CnX639CkqpIuAuYD76YT9LKbVFRJ4RkQlWtXtEZIuIbADuAaZb5acA8Vb5YrRPoeFKQSmXnik0Vx5++GEee+wxhg4d6pQ3e19fX95++23Gjx9PdHQ0gYGBNrNTY+G65iPQEUhrP4PMgxDcueH95WfDmyPg3GdcwySVcwx2/g7b50HqTugeA/0mQMTIuptukv7SP7f9Cl1GlpVnHNBvs/7hJ7c5uhUKsvT1LPK921rtkqFzdN1kqEjqLv0zvCcUF2qFNex6Pbbw3nWKQFJKzUWHTtuXPWn3/THgsUraLQcG1m8A1VBSBKrEzBScxIwZMyotHz16NDt27LAdP/fccwDExMTYTEkV227erBNFZ2VlkZ2dfVJ9gDfffNP2fezYsWzbtg2lFHfeeWetQl0diWvPFDoM0j8dtV4hcTFkHdR5lVo6xxLhtYHw4206dt8vFFa/Dx+dDx+Mq1sob9ZhOLYbEK1gSikugo/Gw1ujtHmpIqWRQHZKJM/HTilUh1KQsqPqWWBuOnw8Hj44WyuHw5ugMKfsWm371jUCqXlhtuJ0Wd5//32GDBlC//79ycjI4LbbbmvU67u2UmjfHxDH+RV2/KZ/7lmm3zxbMolxUJAN1/4AD2yD6b/AQ7vg3Gfh4FrYWIcVv3utWcKgqyB1O6RZPtQd8yBjn/YRfHIx7F5cvt3+VeDfDtpE2oqKPALA01/PMKriRBrEXg1vjYBFz1VeZ/HzkJMGCHw9BXYu0OVdLMdy2z6QeQDyMms/zuaEbStOoxRcjfvvv5/169eTkJDAl19+iZ9f4yb1dG2l4B2gM6buWVp1ncyDsODJmt9MS0r0g8W3jTZ5HFjrWFkbm4PrdSqQHmeXmYp8guG0u6HjEFjyYu0VX9Jf4BUIMY/o4+2WlWX1BzrlyD/+1iksvpwMu/4oa5e8Sr+52+dnEdGmvqp8CrsXwzun6X66ngbLXoa1n5evc2iDvvbwm2DKV3B8D8T9n5al1IzY1gpTTt1Bi8Q2UzDmI4NjcW2lABA9XYc97llW+fn5/4K/XtcPmk3fVd3PofU6tv3MhwHRb9otmYProNPQ8g9k0Mdj/wXp+2D9l7Xra+9f0HUUhHaH9gNg21zto0iM07//4Ai4Ya4+P/dhbVbKTtEmLHv/QynBEZUr6YSf4IvLtfK6ZRFMm6OV2i/3lc1CSkrg1wfBNxTO/hdEjoELXwZU+Wu1tbLn1m1lc/PBzBQMTsL1lcKImyCwEyx8+mT784G12j8w9DodkfL9TfD9LWX/cPbs/B0QGHQldBqi/QtV0RyinUqKq37TL8yDowl6HJXR61zoPByWvFT578KeE6n6wdptjD7ucyHsXwFL/qM3lR9m5T/0DYFzntK+hw1f6VkClIs8slGZUtj1B3x3E0SM0Aqhw0Addjz5U/23++IKeHWATnaXvArOe1bP6gCG3wCXvgNnPlTWX5tIvY6lxSoFa6bgbhLiGRyL6ysFT19t1kheXeYTAP3g/uMpvbr1/H/DDfMg5nGdh+frqXqDHnt2/KYfSP7hOkonebXeDMYepfRb6ntnODfnUkkJrPtCv81X5MgWPft5pY928B5POrnO0S06eqVTFascRfRbdmayDjWtjr1Wgi+bUrhAR8VsmgX9L4WAtmV1+1yoI4riXtQmPTdPbaqqSHAXOHG0TCHtWwGx1+qV6VfP0mbBUnyC4Lof4PT7tAwBbbWSHzSlfJ9DrtbrVkpxc7cikFqos7lU7qBOTSuHweVwfaUAerFSaA9Y+Kx+oALsXqQfTGc+rB8s7h5aeUx4U5/76sqyh37WYW1u6X2ePu4eox+qpQ/EUtZ+piN4Dm+CnfOdN55df8BPd8KbI/XbfH4WbPwWPjhHm8FWvqfDPHPS4MPz4UiFsPjSSKDKHsildB8LkWfAb49pJVNYxRaJe/8CD98yBdNxCARa67hG3FK+rgiMe1Irm9UfQMfB4FmJ+SPIsvtnHtDK+Zvr9MPv2h/0jKMigR10v5e/B9f/BBPfrF1Ibds+LXemUOrfamjYrsHG2LFjmT+//P/ta6+9xh133FFp/ZiYGOLjde7OCy+8kPT09JPqzJgxg5dffrna686ePZuEhLL/0SeffJI//vijmhbOpXUoBXdPGPu4fkP+8gr47XH9sAvppk0L9gy7Dq74QD/wPzhHh1ju/F2f6z1e/+xyqrbl2kfTHNoAcx/SCiOwU81v2KBNJPMe1esFKqO4CNZ8crI/ZOtP4B2kldTi5+CFbvDDzbqf8/8P/rkdpn6lZz+gQzOT7RaVHVyvbe4h1exuJgJTY2H4jfD3m/DemScrF9BO5i4jy/L6u7lB9A06wV1l/oLuMRB1plaqlZmOQJuPQP9+1nysZw0T34KAdlXLWx/a9tWzrYITju3X2ZSUwK4F0GOcnvEYHMLUqVOJjS0fdRcbG8vUqVNrbDt37lxbfqS6UlEpPPPMM5xzzjn16ssRtA6lAND/chhxsw51XPOxDp089+nKozcGToKrv9GhlF9P0Q/7oM7aiQr67bbr6DJnc9pumHW9Ni1d8aFeILVrod7QpSpKSuCH22DlO9rfUZEDa+D9GPj5Xph9hy19hJQU6QVivcfDlZ/BdbO1M/ea7+GueBj9D/AP03207wc3/a4VyK/3l/k6Dq6v3MlcEe8AuPi/+g09Lx2+vkrH/5eSexyObIbI08u3i3kErv2u6v7HPaVTZfc4u/LzpUohbZcOAog8A7qNrl7W+tCuhUYgHd4AJ1Js+aIMjmHSpEn8+uuvtg11kpKSOHjwIF9//TXDhw+nf//+PPXUU5W2jYyMJDVVp2Z5/vnn6d27N6effrottTbotBgjRoxg8ODBXHHFFeTk5LB8+XLmzJnDQw89xJAhQ9i9ezfTp0/nu+900MvChQsZOnQoAwcO5MYbbyQ/P992vaeeeophw4YxcOBAtm1z3IzXtVc02+PmBhdZWz4qpd8O7W3TFel1LnRfBeu/gj9fhYGTyz/keozVoaxvj9ZOW3cvmP6rVgzDroel/4G1n8I5Myrvf8XbsPdPvcBuzaf6wV5qglnyko6zD2gPo26Hle9qn0bfiwhJ36wfxv0mlMnRY2zV42jTDc54AH65X9vmOw2BlK1lprDa0HMcXPWFXoj2870w+ROtpOY/ASj95l8XIobDw4k6iqgySs1Hy17VEV+TajHrqg8RI2DC/yAowjn9O4udCwDRMwVXZd6jjs9b1mEgXPBCladDQ0MZOXIk8+bNY+LEicTGxnLllVfy+OOPExoaSnFxMePGjWPjxo0MGjSo0j7WrFlDbGws69evp6ioiGHDhhEdrU18l1xyCXfffTcATzzxBB9++CF33303EyZM4OKLL2bSpEnl+srLy2P69OksXLiQ3r17c/311/POO+9w3333ARAeHs7atWt5++23efnll/nggw8c8EtqTTMFe0SqVwiluHtC9DS4d712vNrT5yIdm+8TrE0296wrM5cEd4beF+j4+aJKtvE7uhUWPqMdr9N/0Ypk7sNaWS19SZuEBk6Cu1bBec/rh9aq9wEIT/1bL+7qWYfp5aApek3Cire1I7o6J3NVdBkJZz8BCbNh1Uz4dhqs/0L7ZKoyA1VHVQoB9EzMv51e+NZtzMkzEUcR2EErcHtneEtg5+/QeVjLk7sFYG9CKjUdzZo1i2HDhjF06FC2bNlSztRTkWXLlnHZZZfh5+dHUFAQEyZMsJ3bunUrZ5xxBgMHDuTLL79ky5Yt1cqyfft2oqKi6N27NwDTpk1j6dKyNVeXX345oNNulybQcwStZ6bgaMJ7wuPVLHgbcSNs/1U/5EsKIelP/TD2b6tj+L0D4ZI39MPxnBnacfz1FD0jGHSVDqEstRcPn65X7qZsp23KCj2L8fStvaxeftp38tfrZauHq3MyV8WY+2DPEphnrdW44CUYdWvd+6kNwZ21L+Gsh53Tf0vlRBokx8NZjzS1JM6lmjd6ZzJx4kTuv/9+1q5dS05ODqGhobz88susXr2aNm3aMH36dPLyqgi6qIE77riDn376icGDB/PJJ5/UaeObyihNve3otNutc6bQGHQ/Wz+Al/5H5+4Xd/AL1+YQd0+47L2yN73BV+sokh2/Qb9LYeLb5R2Iw6bp8M3Zd+BVmF5mOqoLI24BBP5+S8sRXA+TiZsbXDZTO4snfeg8hQDaj9B7PESd5bxrtER2LwIU9KqD+c9QawICAhg7diw33ngjU6dOJTMzE39/f4KDgzly5Ajz5s2rtv2ZZ57J7Nmzyc3NJSsri59//tl2Lisri44dO1JYWMiXX5YtDA0MDKx0Z7U+ffqQlJTErl06sePnn3/OWWc5///BzBSchZsbTP1Gp2voeqptv4Aq617+vl6xO/ouHR5rT0A76DcRNn9HsZsX7vV5IAR31usGNn9fOydzVQS212Gfzua8Z51/jZbIzt+1Uq+r+c9Qa6ZOncpll11GbGwsffv2ZejQofTt25cuXbowZsyYatsOGzaMq666isGDB9OuXTtGjBhhO/fEE08watQo2rZty6hRo2yKYMqUKdxyyy288cYbNgcz6B3TPv74YyZPnkxRUREjRozg9ttvd86g7VFKtdhPdHS0smfx4sXKZdn7t1JPBamUN86tfx/7Vyv1VJBSC59znFwOpjn9DYF41Zzu7eIipV6MUur7W5w15CZj8eLFKiEhoanFcCqZmZlNct3Kfq/V3dtmptBS6DIKYh5nb2YolexMUDsihusw1m7Vv+0Ymin5WdpsdEo9zIcGQy0xSqGlIAIxj5DVQOcU/SY6RBxDE+AbApe929RSGFwc42g2GAwGgw2jFAwGQ7NBNYcMwy5EfX6fTaIURCRJRDaJyHoRibfKQkVkgYjstH62aQrZDIbKEJHxIrJdRHaJyKOVnJ8uIinWPb1eRG62OzfNuq93isi0xpW85eDj40NaWppRDA5CKUVaWho+PnXbc6MpfQpjlVKpdsePAguVUi9Y/3SPAi6+QsfQEhARd+At4FwgGVgtInOUUhWXtn6jlLqrQttQ4ClgOKCANVbb440geosiIiKC5ORkUlJSmloUp5CXl1fnB3RD8fHxISKibmuSmpOjeSIQY33/FIjDKAVD82AksEsplQggIrHo+7XqfAdlnA8sUEods9ouAMYDXztJ1haLp6cnUVFRTS2G04iLi2Po0Oa/vqSpfAoK+F1E1ohI6bLY9kqpQ9b3w0D7phHNYDiJzoD9ptHJVllFrhCRjSLynYh0qWNbg6FZ0FQzhdOVUgdEpB2wQETK5X1VSikRqdSwaCmRWwHat29fLn9IdnZ2g/OJNHdcfYwteHw/A18rpfJF5Db0bLeK3OCV05rvbVcfH7SgMVa1qq2xPsAM4EFgO9DRKusIbK+pbata0Wzh6mNsTuPDWvUJjAbmq7J79jHgMVX1Pe0OZFjfpwLv2Z17D5haVVvVSu9tVx+fUs1rjFSzollUI3v6RcQfcFNKZVnfFwDPAOOANFXmaA5VSlWbIlNEUoC9dkXhQGoV1V0FVx9jcxpfN6VUWxHxAHag79EDwGrgaqWULfexiHRUlvlTRC4DHlFKnWo5mtcAw6yqa4FoZfkYqqIV3tuuPj5oXmPsppSqNPd6U5iP2gM/ik7I5gF8pZT6TURWA7NE5Cb0P8OVNXVUcVAiEq+UGu4EmZsNrj7G5jg+pVSRiNwFzEfPAj5SSm0RkWfQb1xzgHtEZAJQBBwDplttj4nIs2hFAvBMTQrBateq7m1XHx+0nDE2+kzBmbSUX3pDcPUxuvr46our/15cfXzQcsZoVjQbDAaDwYarKYWZTS1AI+DqY3T18dUXV/+9uPr4oIWM0aXMRwaDwWBoGK42UzAYDAZDA3AZpVBTwrKWhoh0EZHFIpIgIltE5F6r3KUSB4qIu4isE5FfrOMoEVlp/R2/ERGvppaxKXG1+xrMvd3c722XUAp2CcsuAPoBU0WkX9NK1WCKgH8qpfoBpwJ3WmMqTRzYC1hoHbdk7gW22h2/CLyqlOoJHAduahKpmgEuel+Dubeb9b3tEkoBu4RlSqkCoDRhWYtFKXVIKbXW+p6Fvrk6o8f1qVXtU+DSJhHQAYhIBHAR8IF1LOjUEKW7l7fo8TkAl7uvwdzbVpVmOz5XUQounXRMRCKBocBKXCtx4GvAw0CJdRwGpCuliqxjl/o71gOXvq/B3NtNIFeNuIpScFlEJAD4HrhPKZVpf87KYdIiw8dE5GLgqFJqTVPLYmgazL3dPGlO+yk0hANAF7vjCKusRSMinuh/mi+VUj9YxUdK8+yISEfgaNNJ2CDGABNE5ELABwgCXgdCRMTDeqNyib9jA3DJ+xrMvU0z/lu6ykxhNdDL8u57AVOAOU0sU4OwbJAfAluVUv+1OzUHKN3ScRrwU2PL5giUUo8ppSKUUpHov9cipdQ1wGJgklWtxY7PQbjcfQ3m3raqNdvxuYRSsDRvacKyrcAs+wyWLZQxwHXA2VK27++FwAvAuSKyEzjHOnYlHgEeEJFdaDvsh00sT5Phovc1mHu7Wd/bZkWzwWAwGGy4xEzBYDAYDI7BKAWDwWAw2DBKwWAwGAw2jFIwGAwGgw2jFAwGg8FgwyiFFoiIFNuF8q13ZPZMEYkUkc2O6s9gqAvm3m56XGVFc2sjVyk1pKmFMBicgLm3mxgzU3AhRCRJRP4jIptEZJWI9LTKI0VkkYhsFJGFItLVKm8vIj+KyAbrc5rVlbuIvG/luv9dRHybbFAGA+bebkyMUmiZ+FaYYl9ldy5DKTUQeBOdqRHgf8CnSqlBwJfAG1b5G8ASpdRgYBhQulq2F/CWUqo/kA5c4dTRGAxlmHu7iTErmlsgIpKtlAqopDwJOFsplWglHDuslAoTkVSgo1Kq0Co/pJQKF5EUIEIplW/XRySwwNroBBF5BPBUSj3XCEMztHLMvd30mJmC66Gq+F4X8u2+F2N8T4bmgbm3GwGjFFyPq+x+/m19X47O1ghwDbDM+r4QuANs+8kGN5aQBkM9MPd2I2C0ZMvEV0TW2x3/ppQqDd1rIyIb0W9EU62yu4GPReQhIAW4wSq/F5gpIjeh35ruAA5hMDQd5t5uYoxPwYWw7K7DlVKpTS2LweBIzL3deBjzkcFgMBhsmJmCwWAwGGyYmYLBYDAYbBilYDAYDAYbRikYDAaDwYZRCgaDwWCwYZSCwWAwGGwYpWAwGAwGG/8feIFY7ppg8MoAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7496\n","Validation AUC: 0.7471\n","Validation Balanced_ACC: 0.4953\n","Validation MI: 0.1444\n","Validation Normalized MI: 0.2161\n","Validation Adjusted MI: 0.2161\n","Validation aUc_Sklearn: 0.8370\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 532.5384, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 488.6142, Accuracy: 0.5136\n","Training loss (for one batch) at step 20: 499.7857, Accuracy: 0.5181\n","Training loss (for one batch) at step 30: 515.0516, Accuracy: 0.5252\n","Training loss (for one batch) at step 40: 469.2635, Accuracy: 0.5290\n","Training loss (for one batch) at step 50: 474.1211, Accuracy: 0.5355\n","Training loss (for one batch) at step 60: 507.0574, Accuracy: 0.5382\n","Training loss (for one batch) at step 70: 437.6133, Accuracy: 0.5414\n","Training loss (for one batch) at step 80: 412.1067, Accuracy: 0.5457\n","Training loss (for one batch) at step 90: 427.4181, Accuracy: 0.5479\n","Training loss (for one batch) at step 100: 413.1493, Accuracy: 0.5527\n","Training loss (for one batch) at step 110: 414.5948, Accuracy: 0.5549\n","Training loss (for one batch) at step 120: 467.1740, Accuracy: 0.5559\n","Training loss (for one batch) at step 130: 445.4490, Accuracy: 0.5578\n","Training loss (for one batch) at step 140: 465.0882, Accuracy: 0.5594\n","---- Training ----\n","Training loss: 381.7527\n","Training acc over epoch: 0.5582\n","---- Validation ----\n","Validation loss: 91.4688\n","Validation acc: 0.5134\n","Time taken: 12.93s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 423.3222, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 386.0050, Accuracy: 0.6082\n","Training loss (for one batch) at step 20: 406.3389, Accuracy: 0.6119\n","Training loss (for one batch) at step 30: 416.2047, Accuracy: 0.6013\n","Training loss (for one batch) at step 40: 389.9232, Accuracy: 0.5963\n","Training loss (for one batch) at step 50: 394.0270, Accuracy: 0.5912\n","Training loss (for one batch) at step 60: 439.0099, Accuracy: 0.5926\n","Training loss (for one batch) at step 70: 395.7939, Accuracy: 0.5918\n","Training loss (for one batch) at step 80: 395.9757, Accuracy: 0.5954\n","Training loss (for one batch) at step 90: 400.1547, Accuracy: 0.5965\n","Training loss (for one batch) at step 100: 395.6791, Accuracy: 0.5950\n","Training loss (for one batch) at step 110: 368.7736, Accuracy: 0.5976\n","Training loss (for one batch) at step 120: 407.2421, Accuracy: 0.5986\n","Training loss (for one batch) at step 130: 381.8151, Accuracy: 0.5998\n","Training loss (for one batch) at step 140: 386.4744, Accuracy: 0.6011\n","---- Training ----\n","Training loss: 342.1550\n","Training acc over epoch: 0.5997\n","---- Validation ----\n","Validation loss: 77.7988\n","Validation acc: 0.5742\n","Time taken: 9.74s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 395.3844, Accuracy: 0.6000\n","Training loss (for one batch) at step 10: 382.1066, Accuracy: 0.6309\n","Training loss (for one batch) at step 20: 350.0018, Accuracy: 0.6281\n","Training loss (for one batch) at step 30: 375.0786, Accuracy: 0.6194\n","Training loss (for one batch) at step 40: 386.4919, Accuracy: 0.6115\n","Training loss (for one batch) at step 50: 400.8813, Accuracy: 0.6086\n","Training loss (for one batch) at step 60: 363.8419, Accuracy: 0.6121\n","Training loss (for one batch) at step 70: 365.3380, Accuracy: 0.6114\n","Training loss (for one batch) at step 80: 373.2495, Accuracy: 0.6109\n","Training loss (for one batch) at step 90: 348.4840, Accuracy: 0.6107\n","Training loss (for one batch) at step 100: 378.3018, Accuracy: 0.6110\n","Training loss (for one batch) at step 110: 382.3780, Accuracy: 0.6105\n","Training loss (for one batch) at step 120: 389.9186, Accuracy: 0.6088\n","Training loss (for one batch) at step 130: 375.7372, Accuracy: 0.6089\n","Training loss (for one batch) at step 140: 376.8884, Accuracy: 0.6105\n","---- Training ----\n","Training loss: 315.8708\n","Training acc over epoch: 0.6106\n","---- Validation ----\n","Validation loss: 76.7956\n","Validation acc: 0.6421\n","Time taken: 10.87s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 386.4293, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 345.0205, Accuracy: 0.6109\n","Training loss (for one batch) at step 20: 357.3569, Accuracy: 0.6114\n","Training loss (for one batch) at step 30: 350.7261, Accuracy: 0.6255\n","Training loss (for one batch) at step 40: 339.4309, Accuracy: 0.6249\n","Training loss (for one batch) at step 50: 377.9559, Accuracy: 0.6263\n","Training loss (for one batch) at step 60: 375.5185, Accuracy: 0.6246\n","Training loss (for one batch) at step 70: 340.7684, Accuracy: 0.6272\n","Training loss (for one batch) at step 80: 383.8318, Accuracy: 0.6277\n","Training loss (for one batch) at step 90: 354.1663, Accuracy: 0.6278\n","Training loss (for one batch) at step 100: 347.8271, Accuracy: 0.6262\n","Training loss (for one batch) at step 110: 349.0966, Accuracy: 0.6265\n","Training loss (for one batch) at step 120: 352.9415, Accuracy: 0.6286\n","Training loss (for one batch) at step 130: 353.2911, Accuracy: 0.6271\n","Training loss (for one batch) at step 140: 348.8654, Accuracy: 0.6276\n","---- Training ----\n","Training loss: 313.5492\n","Training acc over epoch: 0.6276\n","---- Validation ----\n","Validation loss: 70.5024\n","Validation acc: 0.6574\n","Time taken: 10.99s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 352.2755, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 336.2549, Accuracy: 0.6355\n","Training loss (for one batch) at step 20: 352.6798, Accuracy: 0.6357\n","Training loss (for one batch) at step 30: 344.6459, Accuracy: 0.6371\n","Training loss (for one batch) at step 40: 333.4243, Accuracy: 0.6373\n","Training loss (for one batch) at step 50: 342.2039, Accuracy: 0.6394\n","Training loss (for one batch) at step 60: 337.2793, Accuracy: 0.6415\n","Training loss (for one batch) at step 70: 350.7221, Accuracy: 0.6401\n","Training loss (for one batch) at step 80: 348.6115, Accuracy: 0.6377\n","Training loss (for one batch) at step 90: 375.6487, Accuracy: 0.6385\n","Training loss (for one batch) at step 100: 330.1545, Accuracy: 0.6387\n","Training loss (for one batch) at step 110: 352.1969, Accuracy: 0.6391\n","Training loss (for one batch) at step 120: 344.3016, Accuracy: 0.6421\n","Training loss (for one batch) at step 130: 329.2963, Accuracy: 0.6422\n","Training loss (for one batch) at step 140: 322.1857, Accuracy: 0.6430\n","---- Training ----\n","Training loss: 293.7799\n","Training acc over epoch: 0.6422\n","---- Validation ----\n","Validation loss: 70.3065\n","Validation acc: 0.6795\n","Time taken: 10.71s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 338.7166, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 336.9220, Accuracy: 0.6700\n","Training loss (for one batch) at step 20: 324.5417, Accuracy: 0.6690\n","Training loss (for one batch) at step 30: 336.1305, Accuracy: 0.6594\n","Training loss (for one batch) at step 40: 330.5879, Accuracy: 0.6554\n","Training loss (for one batch) at step 50: 318.3790, Accuracy: 0.6606\n","Training loss (for one batch) at step 60: 343.9391, Accuracy: 0.6644\n","Training loss (for one batch) at step 70: 332.9477, Accuracy: 0.6652\n","Training loss (for one batch) at step 80: 322.4262, Accuracy: 0.6664\n","Training loss (for one batch) at step 90: 331.2088, Accuracy: 0.6673\n","Training loss (for one batch) at step 100: 337.5417, Accuracy: 0.6639\n","Training loss (for one batch) at step 110: 327.0276, Accuracy: 0.6647\n","Training loss (for one batch) at step 120: 330.8496, Accuracy: 0.6645\n","Training loss (for one batch) at step 130: 335.1422, Accuracy: 0.6638\n","Training loss (for one batch) at step 140: 329.7738, Accuracy: 0.6656\n","---- Training ----\n","Training loss: 297.7567\n","Training acc over epoch: 0.6656\n","---- Validation ----\n","Validation loss: 66.9397\n","Validation acc: 0.6838\n","Time taken: 10.80s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 317.3223, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 330.2586, Accuracy: 0.6636\n","Training loss (for one batch) at step 20: 333.4373, Accuracy: 0.6700\n","Training loss (for one batch) at step 30: 341.3629, Accuracy: 0.6668\n","Training loss (for one batch) at step 40: 318.1258, Accuracy: 0.6717\n","Training loss (for one batch) at step 50: 338.6136, Accuracy: 0.6761\n","Training loss (for one batch) at step 60: 327.3754, Accuracy: 0.6774\n","Training loss (for one batch) at step 70: 333.1983, Accuracy: 0.6780\n","Training loss (for one batch) at step 80: 310.3654, Accuracy: 0.6815\n","Training loss (for one batch) at step 90: 332.8737, Accuracy: 0.6798\n","Training loss (for one batch) at step 100: 308.6673, Accuracy: 0.6821\n","Training loss (for one batch) at step 110: 328.4141, Accuracy: 0.6826\n","Training loss (for one batch) at step 120: 328.3063, Accuracy: 0.6838\n","Training loss (for one batch) at step 130: 325.1132, Accuracy: 0.6850\n","Training loss (for one batch) at step 140: 321.8087, Accuracy: 0.6859\n","---- Training ----\n","Training loss: 278.9861\n","Training acc over epoch: 0.6857\n","---- Validation ----\n","Validation loss: 72.5834\n","Validation acc: 0.6797\n","Time taken: 10.98s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 324.7319, Accuracy: 0.6700\n","Training loss (for one batch) at step 10: 320.4777, Accuracy: 0.6873\n","Training loss (for one batch) at step 20: 317.8574, Accuracy: 0.6948\n","Training loss (for one batch) at step 30: 319.7660, Accuracy: 0.6913\n","Training loss (for one batch) at step 40: 319.2584, Accuracy: 0.6888\n","Training loss (for one batch) at step 50: 321.5404, Accuracy: 0.6914\n","Training loss (for one batch) at step 60: 316.7865, Accuracy: 0.6923\n","Training loss (for one batch) at step 70: 323.0349, Accuracy: 0.6982\n","Training loss (for one batch) at step 80: 328.0501, Accuracy: 0.6990\n","Training loss (for one batch) at step 90: 317.0677, Accuracy: 0.6973\n","Training loss (for one batch) at step 100: 316.0226, Accuracy: 0.6998\n","Training loss (for one batch) at step 110: 329.0569, Accuracy: 0.7011\n","Training loss (for one batch) at step 120: 328.1413, Accuracy: 0.7009\n","Training loss (for one batch) at step 130: 311.4375, Accuracy: 0.6993\n","Training loss (for one batch) at step 140: 315.8752, Accuracy: 0.7000\n","---- Training ----\n","Training loss: 278.0114\n","Training acc over epoch: 0.6987\n","---- Validation ----\n","Validation loss: 68.0495\n","Validation acc: 0.6929\n","Time taken: 11.93s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 303.3510, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 305.7903, Accuracy: 0.6945\n","Training loss (for one batch) at step 20: 315.8214, Accuracy: 0.7195\n","Training loss (for one batch) at step 30: 314.0969, Accuracy: 0.7255\n","Training loss (for one batch) at step 40: 303.2455, Accuracy: 0.7271\n","Training loss (for one batch) at step 50: 329.9886, Accuracy: 0.7243\n","Training loss (for one batch) at step 60: 303.2504, Accuracy: 0.7280\n","Training loss (for one batch) at step 70: 306.6991, Accuracy: 0.7280\n","Training loss (for one batch) at step 80: 309.1677, Accuracy: 0.7263\n","Training loss (for one batch) at step 90: 331.5750, Accuracy: 0.7245\n","Training loss (for one batch) at step 100: 329.2792, Accuracy: 0.7215\n","Training loss (for one batch) at step 110: 312.7532, Accuracy: 0.7228\n","Training loss (for one batch) at step 120: 315.2220, Accuracy: 0.7238\n","Training loss (for one batch) at step 130: 321.9098, Accuracy: 0.7237\n","Training loss (for one batch) at step 140: 308.0268, Accuracy: 0.7236\n","---- Training ----\n","Training loss: 291.8036\n","Training acc over epoch: 0.7225\n","---- Validation ----\n","Validation loss: 67.5904\n","Validation acc: 0.6943\n","Time taken: 11.33s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 317.4150, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 307.0728, Accuracy: 0.7236\n","Training loss (for one batch) at step 20: 292.4958, Accuracy: 0.7205\n","Training loss (for one batch) at step 30: 301.7903, Accuracy: 0.7174\n","Training loss (for one batch) at step 40: 298.4632, Accuracy: 0.7259\n","Training loss (for one batch) at step 50: 297.8342, Accuracy: 0.7276\n","Training loss (for one batch) at step 60: 293.4085, Accuracy: 0.7289\n","Training loss (for one batch) at step 70: 327.3109, Accuracy: 0.7301\n","Training loss (for one batch) at step 80: 326.4135, Accuracy: 0.7296\n","Training loss (for one batch) at step 90: 321.7564, Accuracy: 0.7297\n","Training loss (for one batch) at step 100: 301.1256, Accuracy: 0.7306\n","Training loss (for one batch) at step 110: 302.3408, Accuracy: 0.7302\n","Training loss (for one batch) at step 120: 309.2495, Accuracy: 0.7305\n","Training loss (for one batch) at step 130: 287.2078, Accuracy: 0.7285\n","Training loss (for one batch) at step 140: 298.7309, Accuracy: 0.7276\n","---- Training ----\n","Training loss: 286.6552\n","Training acc over epoch: 0.7276\n","---- Validation ----\n","Validation loss: 78.5559\n","Validation acc: 0.6937\n","Time taken: 11.27s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 303.0883, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 294.1454, Accuracy: 0.7436\n","Training loss (for one batch) at step 20: 312.7238, Accuracy: 0.7424\n","Training loss (for one batch) at step 30: 312.7216, Accuracy: 0.7355\n","Training loss (for one batch) at step 40: 313.3586, Accuracy: 0.7295\n","Training loss (for one batch) at step 50: 298.4822, Accuracy: 0.7382\n","Training loss (for one batch) at step 60: 302.1435, Accuracy: 0.7387\n","Training loss (for one batch) at step 70: 321.3716, Accuracy: 0.7379\n","Training loss (for one batch) at step 80: 317.8369, Accuracy: 0.7377\n","Training loss (for one batch) at step 90: 305.5776, Accuracy: 0.7359\n","Training loss (for one batch) at step 100: 307.7971, Accuracy: 0.7362\n","Training loss (for one batch) at step 110: 302.8350, Accuracy: 0.7361\n","Training loss (for one batch) at step 120: 291.5175, Accuracy: 0.7352\n","Training loss (for one batch) at step 130: 303.6716, Accuracy: 0.7350\n","Training loss (for one batch) at step 140: 295.2291, Accuracy: 0.7326\n","---- Training ----\n","Training loss: 272.1477\n","Training acc over epoch: 0.7341\n","---- Validation ----\n","Validation loss: 71.7400\n","Validation acc: 0.6886\n","Time taken: 13.93s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 305.0111, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 303.1106, Accuracy: 0.7518\n","Training loss (for one batch) at step 20: 303.5155, Accuracy: 0.7610\n","Training loss (for one batch) at step 30: 292.7544, Accuracy: 0.7600\n","Training loss (for one batch) at step 40: 299.2800, Accuracy: 0.7512\n","Training loss (for one batch) at step 50: 282.3928, Accuracy: 0.7527\n","Training loss (for one batch) at step 60: 296.7701, Accuracy: 0.7513\n","Training loss (for one batch) at step 70: 309.7339, Accuracy: 0.7506\n","Training loss (for one batch) at step 80: 305.1432, Accuracy: 0.7481\n","Training loss (for one batch) at step 90: 301.9145, Accuracy: 0.7491\n","Training loss (for one batch) at step 100: 309.7827, Accuracy: 0.7469\n","Training loss (for one batch) at step 110: 291.7575, Accuracy: 0.7473\n","Training loss (for one batch) at step 120: 302.0829, Accuracy: 0.7470\n","Training loss (for one batch) at step 130: 301.5794, Accuracy: 0.7460\n","Training loss (for one batch) at step 140: 313.4924, Accuracy: 0.7457\n","---- Training ----\n","Training loss: 264.4988\n","Training acc over epoch: 0.7454\n","---- Validation ----\n","Validation loss: 69.1021\n","Validation acc: 0.6913\n","Time taken: 12.10s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 289.6073, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 287.1545, Accuracy: 0.7545\n","Training loss (for one batch) at step 20: 302.9305, Accuracy: 0.7586\n","Training loss (for one batch) at step 30: 318.5050, Accuracy: 0.7513\n","Training loss (for one batch) at step 40: 293.1088, Accuracy: 0.7520\n","Training loss (for one batch) at step 50: 297.7626, Accuracy: 0.7553\n","Training loss (for one batch) at step 60: 308.1187, Accuracy: 0.7564\n","Training loss (for one batch) at step 70: 278.6101, Accuracy: 0.7561\n","Training loss (for one batch) at step 80: 309.9602, Accuracy: 0.7562\n","Training loss (for one batch) at step 90: 287.4146, Accuracy: 0.7566\n","Training loss (for one batch) at step 100: 297.7722, Accuracy: 0.7548\n","Training loss (for one batch) at step 110: 302.0871, Accuracy: 0.7551\n","Training loss (for one batch) at step 120: 294.8892, Accuracy: 0.7559\n","Training loss (for one batch) at step 130: 304.1132, Accuracy: 0.7539\n","Training loss (for one batch) at step 140: 301.6970, Accuracy: 0.7538\n","---- Training ----\n","Training loss: 262.4887\n","Training acc over epoch: 0.7540\n","---- Validation ----\n","Validation loss: 69.9440\n","Validation acc: 0.7074\n","Time taken: 11.85s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 293.5333, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 295.0630, Accuracy: 0.7745\n","Training loss (for one batch) at step 20: 287.0632, Accuracy: 0.7705\n","Training loss (for one batch) at step 30: 306.0687, Accuracy: 0.7684\n","Training loss (for one batch) at step 40: 285.9910, Accuracy: 0.7690\n","Training loss (for one batch) at step 50: 326.7936, Accuracy: 0.7720\n","Training loss (for one batch) at step 60: 289.9844, Accuracy: 0.7710\n","Training loss (for one batch) at step 70: 300.4421, Accuracy: 0.7721\n","Training loss (for one batch) at step 80: 302.0107, Accuracy: 0.7711\n","Training loss (for one batch) at step 90: 289.7980, Accuracy: 0.7699\n","Training loss (for one batch) at step 100: 300.9894, Accuracy: 0.7655\n","Training loss (for one batch) at step 110: 296.8793, Accuracy: 0.7659\n","Training loss (for one batch) at step 120: 274.0785, Accuracy: 0.7669\n","Training loss (for one batch) at step 130: 287.1812, Accuracy: 0.7663\n","Training loss (for one batch) at step 140: 317.5496, Accuracy: 0.7651\n","---- Training ----\n","Training loss: 268.2782\n","Training acc over epoch: 0.7662\n","---- Validation ----\n","Validation loss: 69.5460\n","Validation acc: 0.7166\n","Time taken: 18.23s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 277.2243, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 300.0375, Accuracy: 0.7691\n","Training loss (for one batch) at step 20: 295.4369, Accuracy: 0.7643\n","Training loss (for one batch) at step 30: 289.8055, Accuracy: 0.7626\n","Training loss (for one batch) at step 40: 293.4218, Accuracy: 0.7639\n","Training loss (for one batch) at step 50: 292.4017, Accuracy: 0.7673\n","Training loss (for one batch) at step 60: 297.9947, Accuracy: 0.7718\n","Training loss (for one batch) at step 70: 289.0736, Accuracy: 0.7697\n","Training loss (for one batch) at step 80: 305.4175, Accuracy: 0.7699\n","Training loss (for one batch) at step 90: 300.5384, Accuracy: 0.7674\n","Training loss (for one batch) at step 100: 287.5411, Accuracy: 0.7663\n","Training loss (for one batch) at step 110: 288.9365, Accuracy: 0.7672\n","Training loss (for one batch) at step 120: 279.3419, Accuracy: 0.7669\n","Training loss (for one batch) at step 130: 282.7158, Accuracy: 0.7664\n","Training loss (for one batch) at step 140: 280.2452, Accuracy: 0.7655\n","---- Training ----\n","Training loss: 253.5590\n","Training acc over epoch: 0.7662\n","---- Validation ----\n","Validation loss: 72.9656\n","Validation acc: 0.7042\n","Time taken: 10.51s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 300.2415, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 279.8725, Accuracy: 0.7827\n","Training loss (for one batch) at step 20: 286.4525, Accuracy: 0.7852\n","Training loss (for one batch) at step 30: 288.8819, Accuracy: 0.7890\n","Training loss (for one batch) at step 40: 292.2672, Accuracy: 0.7898\n","Training loss (for one batch) at step 50: 282.0624, Accuracy: 0.7894\n","Training loss (for one batch) at step 60: 284.5005, Accuracy: 0.7857\n","Training loss (for one batch) at step 70: 285.2954, Accuracy: 0.7849\n","Training loss (for one batch) at step 80: 290.9615, Accuracy: 0.7842\n","Training loss (for one batch) at step 90: 308.6555, Accuracy: 0.7807\n","Training loss (for one batch) at step 100: 290.6957, Accuracy: 0.7803\n","Training loss (for one batch) at step 110: 279.9492, Accuracy: 0.7785\n","Training loss (for one batch) at step 120: 280.5481, Accuracy: 0.7774\n","Training loss (for one batch) at step 130: 288.9973, Accuracy: 0.7763\n","Training loss (for one batch) at step 140: 279.2231, Accuracy: 0.7767\n","---- Training ----\n","Training loss: 254.4610\n","Training acc over epoch: 0.7765\n","---- Validation ----\n","Validation loss: 67.7294\n","Validation acc: 0.7211\n","Time taken: 11.29s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 285.6526, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 279.4961, Accuracy: 0.7891\n","Training loss (for one batch) at step 20: 293.5388, Accuracy: 0.7881\n","Training loss (for one batch) at step 30: 301.9880, Accuracy: 0.7855\n","Training loss (for one batch) at step 40: 268.9919, Accuracy: 0.7800\n","Training loss (for one batch) at step 50: 275.0904, Accuracy: 0.7825\n","Training loss (for one batch) at step 60: 280.5791, Accuracy: 0.7844\n","Training loss (for one batch) at step 70: 283.7652, Accuracy: 0.7825\n","Training loss (for one batch) at step 80: 267.1924, Accuracy: 0.7816\n","Training loss (for one batch) at step 90: 289.0630, Accuracy: 0.7798\n","Training loss (for one batch) at step 100: 291.7070, Accuracy: 0.7782\n","Training loss (for one batch) at step 110: 283.8939, Accuracy: 0.7793\n","Training loss (for one batch) at step 120: 275.0883, Accuracy: 0.7796\n","Training loss (for one batch) at step 130: 279.4808, Accuracy: 0.7808\n","Training loss (for one batch) at step 140: 291.6949, Accuracy: 0.7787\n","---- Training ----\n","Training loss: 248.3508\n","Training acc over epoch: 0.7789\n","---- Validation ----\n","Validation loss: 79.3065\n","Validation acc: 0.7308\n","Time taken: 9.67s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 278.9569, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 273.6313, Accuracy: 0.7927\n","Training loss (for one batch) at step 20: 281.0540, Accuracy: 0.7852\n","Training loss (for one batch) at step 30: 292.5652, Accuracy: 0.7890\n","Training loss (for one batch) at step 40: 272.3949, Accuracy: 0.7868\n","Training loss (for one batch) at step 50: 276.1077, Accuracy: 0.7914\n","Training loss (for one batch) at step 60: 266.1566, Accuracy: 0.7928\n","Training loss (for one batch) at step 70: 289.3810, Accuracy: 0.7918\n","Training loss (for one batch) at step 80: 283.2122, Accuracy: 0.7906\n","Training loss (for one batch) at step 90: 271.7021, Accuracy: 0.7904\n","Training loss (for one batch) at step 100: 271.2239, Accuracy: 0.7900\n","Training loss (for one batch) at step 110: 284.2550, Accuracy: 0.7905\n","Training loss (for one batch) at step 120: 309.3036, Accuracy: 0.7894\n","Training loss (for one batch) at step 130: 274.8307, Accuracy: 0.7884\n","Training loss (for one batch) at step 140: 279.1962, Accuracy: 0.7884\n","---- Training ----\n","Training loss: 243.1614\n","Training acc over epoch: 0.7880\n","---- Validation ----\n","Validation loss: 61.6628\n","Validation acc: 0.7219\n","Time taken: 9.88s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 276.8687, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 278.1779, Accuracy: 0.7755\n","Training loss (for one batch) at step 20: 281.2620, Accuracy: 0.7848\n","Training loss (for one batch) at step 30: 284.5782, Accuracy: 0.7852\n","Training loss (for one batch) at step 40: 284.5167, Accuracy: 0.7866\n","Training loss (for one batch) at step 50: 292.7481, Accuracy: 0.7933\n","Training loss (for one batch) at step 60: 271.7957, Accuracy: 0.7961\n","Training loss (for one batch) at step 70: 292.5124, Accuracy: 0.7961\n","Training loss (for one batch) at step 80: 262.5511, Accuracy: 0.7923\n","Training loss (for one batch) at step 90: 293.8504, Accuracy: 0.7916\n","Training loss (for one batch) at step 100: 285.4265, Accuracy: 0.7880\n","Training loss (for one batch) at step 110: 284.6936, Accuracy: 0.7893\n","Training loss (for one batch) at step 120: 281.6410, Accuracy: 0.7901\n","Training loss (for one batch) at step 130: 283.2319, Accuracy: 0.7902\n","Training loss (for one batch) at step 140: 271.5083, Accuracy: 0.7893\n","---- Training ----\n","Training loss: 261.6610\n","Training acc over epoch: 0.7887\n","---- Validation ----\n","Validation loss: 68.7282\n","Validation acc: 0.7423\n","Time taken: 9.61s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 274.9865, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 290.3083, Accuracy: 0.7982\n","Training loss (for one batch) at step 20: 258.6560, Accuracy: 0.8000\n","Training loss (for one batch) at step 30: 295.1824, Accuracy: 0.8035\n","Training loss (for one batch) at step 40: 276.7542, Accuracy: 0.7968\n","Training loss (for one batch) at step 50: 261.4685, Accuracy: 0.8031\n","Training loss (for one batch) at step 60: 252.8735, Accuracy: 0.8028\n","Training loss (for one batch) at step 70: 305.6752, Accuracy: 0.7999\n","Training loss (for one batch) at step 80: 265.6022, Accuracy: 0.7990\n","Training loss (for one batch) at step 90: 285.9725, Accuracy: 0.7982\n","Training loss (for one batch) at step 100: 268.9459, Accuracy: 0.7963\n","Training loss (for one batch) at step 110: 275.7827, Accuracy: 0.7968\n","Training loss (for one batch) at step 120: 277.7347, Accuracy: 0.7960\n","Training loss (for one batch) at step 130: 284.6166, Accuracy: 0.7936\n","Training loss (for one batch) at step 140: 272.6837, Accuracy: 0.7938\n","---- Training ----\n","Training loss: 236.6186\n","Training acc over epoch: 0.7933\n","---- Validation ----\n","Validation loss: 56.6453\n","Validation acc: 0.7354\n","Time taken: 9.66s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 274.3875, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 280.5367, Accuracy: 0.8082\n","Training loss (for one batch) at step 20: 280.1284, Accuracy: 0.8014\n","Training loss (for one batch) at step 30: 262.6679, Accuracy: 0.8003\n","Training loss (for one batch) at step 40: 271.7087, Accuracy: 0.8039\n","Training loss (for one batch) at step 50: 281.2905, Accuracy: 0.8047\n","Training loss (for one batch) at step 60: 267.8870, Accuracy: 0.8074\n","Training loss (for one batch) at step 70: 282.7853, Accuracy: 0.8076\n","Training loss (for one batch) at step 80: 264.1942, Accuracy: 0.8051\n","Training loss (for one batch) at step 90: 275.5016, Accuracy: 0.8059\n","Training loss (for one batch) at step 100: 261.6238, Accuracy: 0.8031\n","Training loss (for one batch) at step 110: 250.2139, Accuracy: 0.8032\n","Training loss (for one batch) at step 120: 280.6247, Accuracy: 0.8019\n","Training loss (for one batch) at step 130: 263.3033, Accuracy: 0.8000\n","Training loss (for one batch) at step 140: 263.2477, Accuracy: 0.8006\n","---- Training ----\n","Training loss: 243.5570\n","Training acc over epoch: 0.8004\n","---- Validation ----\n","Validation loss: 77.5258\n","Validation acc: 0.7195\n","Time taken: 9.62s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 271.3231, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 262.4483, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 280.7091, Accuracy: 0.8157\n","Training loss (for one batch) at step 30: 270.2301, Accuracy: 0.8103\n","Training loss (for one batch) at step 40: 260.5597, Accuracy: 0.8117\n","Training loss (for one batch) at step 50: 259.7688, Accuracy: 0.8125\n","Training loss (for one batch) at step 60: 246.7004, Accuracy: 0.8095\n","Training loss (for one batch) at step 70: 278.2313, Accuracy: 0.8106\n","Training loss (for one batch) at step 80: 261.3978, Accuracy: 0.8077\n","Training loss (for one batch) at step 90: 281.8924, Accuracy: 0.8056\n","Training loss (for one batch) at step 100: 252.1762, Accuracy: 0.8065\n","Training loss (for one batch) at step 110: 248.3022, Accuracy: 0.8064\n","Training loss (for one batch) at step 120: 274.3501, Accuracy: 0.8075\n","Training loss (for one batch) at step 130: 282.2742, Accuracy: 0.8058\n","Training loss (for one batch) at step 140: 265.7295, Accuracy: 0.8040\n","---- Training ----\n","Training loss: 237.2026\n","Training acc over epoch: 0.8034\n","---- Validation ----\n","Validation loss: 78.2420\n","Validation acc: 0.7166\n","Time taken: 9.78s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 283.3798, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 267.3272, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 276.6802, Accuracy: 0.8105\n","Training loss (for one batch) at step 30: 274.0831, Accuracy: 0.8094\n","Training loss (for one batch) at step 40: 267.1344, Accuracy: 0.8166\n","Training loss (for one batch) at step 50: 278.5636, Accuracy: 0.8149\n","Training loss (for one batch) at step 60: 247.9444, Accuracy: 0.8141\n","Training loss (for one batch) at step 70: 255.2581, Accuracy: 0.8135\n","Training loss (for one batch) at step 80: 281.2744, Accuracy: 0.8111\n","Training loss (for one batch) at step 90: 278.5781, Accuracy: 0.8107\n","Training loss (for one batch) at step 100: 254.9485, Accuracy: 0.8088\n","Training loss (for one batch) at step 110: 264.4947, Accuracy: 0.8089\n","Training loss (for one batch) at step 120: 256.2567, Accuracy: 0.8083\n","Training loss (for one batch) at step 130: 262.6553, Accuracy: 0.8061\n","Training loss (for one batch) at step 140: 281.6485, Accuracy: 0.8070\n","---- Training ----\n","Training loss: 243.0540\n","Training acc over epoch: 0.8062\n","---- Validation ----\n","Validation loss: 81.6703\n","Validation acc: 0.7300\n","Time taken: 39.42s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 260.8897, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 270.6202, Accuracy: 0.8118\n","Training loss (for one batch) at step 20: 265.0498, Accuracy: 0.8105\n","Training loss (for one batch) at step 30: 259.1041, Accuracy: 0.8119\n","Training loss (for one batch) at step 40: 248.1390, Accuracy: 0.8144\n","Training loss (for one batch) at step 50: 253.2325, Accuracy: 0.8139\n","Training loss (for one batch) at step 60: 269.5449, Accuracy: 0.8111\n","Training loss (for one batch) at step 70: 258.1758, Accuracy: 0.8113\n","Training loss (for one batch) at step 80: 259.9524, Accuracy: 0.8102\n","Training loss (for one batch) at step 90: 271.6006, Accuracy: 0.8070\n","Training loss (for one batch) at step 100: 275.3140, Accuracy: 0.8069\n","Training loss (for one batch) at step 110: 252.1321, Accuracy: 0.8061\n","Training loss (for one batch) at step 120: 255.7211, Accuracy: 0.8051\n","Training loss (for one batch) at step 130: 269.1982, Accuracy: 0.8034\n","Training loss (for one batch) at step 140: 251.7784, Accuracy: 0.8043\n","---- Training ----\n","Training loss: 231.2586\n","Training acc over epoch: 0.8043\n","---- Validation ----\n","Validation loss: 69.5229\n","Validation acc: 0.7311\n","Time taken: 36.57s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 255.5729, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 264.6110, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 237.6397, Accuracy: 0.8310\n","Training loss (for one batch) at step 30: 273.6924, Accuracy: 0.8129\n","Training loss (for one batch) at step 40: 264.2789, Accuracy: 0.8139\n","Training loss (for one batch) at step 50: 271.2490, Accuracy: 0.8165\n","Training loss (for one batch) at step 60: 255.2498, Accuracy: 0.8180\n","Training loss (for one batch) at step 70: 249.7104, Accuracy: 0.8161\n","Training loss (for one batch) at step 80: 251.5654, Accuracy: 0.8152\n","Training loss (for one batch) at step 90: 274.5956, Accuracy: 0.8115\n","Training loss (for one batch) at step 100: 279.0344, Accuracy: 0.8112\n","Training loss (for one batch) at step 110: 255.0255, Accuracy: 0.8108\n","Training loss (for one batch) at step 120: 259.4402, Accuracy: 0.8102\n","Training loss (for one batch) at step 130: 271.2220, Accuracy: 0.8092\n","Training loss (for one batch) at step 140: 293.1538, Accuracy: 0.8082\n","---- Training ----\n","Training loss: 229.6865\n","Training acc over epoch: 0.8082\n","---- Validation ----\n","Validation loss: 69.8550\n","Validation acc: 0.7311\n","Time taken: 9.68s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 257.6564, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 244.9152, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 260.8322, Accuracy: 0.8229\n","Training loss (for one batch) at step 30: 265.3689, Accuracy: 0.8187\n","Training loss (for one batch) at step 40: 248.7107, Accuracy: 0.8195\n","Training loss (for one batch) at step 50: 248.1336, Accuracy: 0.8255\n","Training loss (for one batch) at step 60: 273.3561, Accuracy: 0.8230\n","Training loss (for one batch) at step 70: 239.0714, Accuracy: 0.8217\n","Training loss (for one batch) at step 80: 267.3216, Accuracy: 0.8215\n","Training loss (for one batch) at step 90: 260.4554, Accuracy: 0.8204\n","Training loss (for one batch) at step 100: 252.7559, Accuracy: 0.8175\n","Training loss (for one batch) at step 110: 266.0077, Accuracy: 0.8159\n","Training loss (for one batch) at step 120: 259.8048, Accuracy: 0.8164\n","Training loss (for one batch) at step 130: 274.8131, Accuracy: 0.8163\n","Training loss (for one batch) at step 140: 238.6626, Accuracy: 0.8145\n","---- Training ----\n","Training loss: 239.0369\n","Training acc over epoch: 0.8136\n","---- Validation ----\n","Validation loss: 80.2194\n","Validation acc: 0.7351\n","Time taken: 9.56s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 258.6690, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 261.2102, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 255.9427, Accuracy: 0.8229\n","Training loss (for one batch) at step 30: 268.3126, Accuracy: 0.8223\n","Training loss (for one batch) at step 40: 245.6063, Accuracy: 0.8215\n","Training loss (for one batch) at step 50: 247.6566, Accuracy: 0.8231\n","Training loss (for one batch) at step 60: 264.9247, Accuracy: 0.8254\n","Training loss (for one batch) at step 70: 245.0810, Accuracy: 0.8255\n","Training loss (for one batch) at step 80: 265.7842, Accuracy: 0.8221\n","Training loss (for one batch) at step 90: 277.6035, Accuracy: 0.8211\n","Training loss (for one batch) at step 100: 265.4823, Accuracy: 0.8185\n","Training loss (for one batch) at step 110: 255.6524, Accuracy: 0.8169\n","Training loss (for one batch) at step 120: 258.8064, Accuracy: 0.8168\n","Training loss (for one batch) at step 130: 253.4174, Accuracy: 0.8182\n","Training loss (for one batch) at step 140: 256.7956, Accuracy: 0.8172\n","---- Training ----\n","Training loss: 232.6860\n","Training acc over epoch: 0.8169\n","---- Validation ----\n","Validation loss: 68.4831\n","Validation acc: 0.7305\n","Time taken: 9.66s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 256.4757, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 258.6226, Accuracy: 0.8209\n","Training loss (for one batch) at step 20: 264.3828, Accuracy: 0.8176\n","Training loss (for one batch) at step 30: 257.5995, Accuracy: 0.8223\n","Training loss (for one batch) at step 40: 245.5201, Accuracy: 0.8212\n","Training loss (for one batch) at step 50: 247.7158, Accuracy: 0.8212\n","Training loss (for one batch) at step 60: 271.1698, Accuracy: 0.8174\n","Training loss (for one batch) at step 70: 254.2565, Accuracy: 0.8182\n","Training loss (for one batch) at step 80: 247.1605, Accuracy: 0.8177\n","Training loss (for one batch) at step 90: 252.7296, Accuracy: 0.8165\n","Training loss (for one batch) at step 100: 253.8263, Accuracy: 0.8171\n","Training loss (for one batch) at step 110: 250.9061, Accuracy: 0.8164\n","Training loss (for one batch) at step 120: 244.7705, Accuracy: 0.8157\n","Training loss (for one batch) at step 130: 271.2404, Accuracy: 0.8155\n","Training loss (for one batch) at step 140: 248.6124, Accuracy: 0.8155\n","---- Training ----\n","Training loss: 221.4033\n","Training acc over epoch: 0.8148\n","---- Validation ----\n","Validation loss: 71.9015\n","Validation acc: 0.7364\n","Time taken: 9.63s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 235.5808, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 256.4344, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 260.0185, Accuracy: 0.8224\n","Training loss (for one batch) at step 30: 242.0847, Accuracy: 0.8261\n","Training loss (for one batch) at step 40: 264.1365, Accuracy: 0.8198\n","Training loss (for one batch) at step 50: 255.4674, Accuracy: 0.8214\n","Training loss (for one batch) at step 60: 236.4243, Accuracy: 0.8244\n","Training loss (for one batch) at step 70: 254.1051, Accuracy: 0.8228\n","Training loss (for one batch) at step 80: 253.2704, Accuracy: 0.8225\n","Training loss (for one batch) at step 90: 248.9781, Accuracy: 0.8224\n","Training loss (for one batch) at step 100: 242.2585, Accuracy: 0.8201\n","Training loss (for one batch) at step 110: 242.6348, Accuracy: 0.8198\n","Training loss (for one batch) at step 120: 254.0946, Accuracy: 0.8201\n","Training loss (for one batch) at step 130: 227.2512, Accuracy: 0.8185\n","Training loss (for one batch) at step 140: 272.3870, Accuracy: 0.8191\n","---- Training ----\n","Training loss: 231.8638\n","Training acc over epoch: 0.8178\n","---- Validation ----\n","Validation loss: 61.4181\n","Validation acc: 0.7163\n","Time taken: 9.59s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 250.4533, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 235.7308, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 262.1500, Accuracy: 0.8286\n","Training loss (for one batch) at step 30: 229.8177, Accuracy: 0.8248\n","Training loss (for one batch) at step 40: 234.1809, Accuracy: 0.8178\n","Training loss (for one batch) at step 50: 234.8945, Accuracy: 0.8239\n","Training loss (for one batch) at step 60: 245.6645, Accuracy: 0.8257\n","Training loss (for one batch) at step 70: 270.1336, Accuracy: 0.8234\n","Training loss (for one batch) at step 80: 254.9946, Accuracy: 0.8246\n","Training loss (for one batch) at step 90: 255.4315, Accuracy: 0.8225\n","Training loss (for one batch) at step 100: 258.2914, Accuracy: 0.8213\n","Training loss (for one batch) at step 110: 248.0752, Accuracy: 0.8202\n","Training loss (for one batch) at step 120: 251.2256, Accuracy: 0.8206\n","Training loss (for one batch) at step 130: 259.2333, Accuracy: 0.8209\n","Training loss (for one batch) at step 140: 236.4722, Accuracy: 0.8201\n","---- Training ----\n","Training loss: 218.4847\n","Training acc over epoch: 0.8207\n","---- Validation ----\n","Validation loss: 76.3847\n","Validation acc: 0.7235\n","Time taken: 9.55s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 265.6779, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 255.6735, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 257.1455, Accuracy: 0.8157\n","Training loss (for one batch) at step 30: 250.5950, Accuracy: 0.8161\n","Training loss (for one batch) at step 40: 236.6871, Accuracy: 0.8254\n","Training loss (for one batch) at step 50: 251.0590, Accuracy: 0.8280\n","Training loss (for one batch) at step 60: 223.4849, Accuracy: 0.8318\n","Training loss (for one batch) at step 70: 245.4058, Accuracy: 0.8313\n","Training loss (for one batch) at step 80: 247.3261, Accuracy: 0.8310\n","Training loss (for one batch) at step 90: 247.9943, Accuracy: 0.8309\n","Training loss (for one batch) at step 100: 244.3882, Accuracy: 0.8294\n","Training loss (for one batch) at step 110: 248.4085, Accuracy: 0.8303\n","Training loss (for one batch) at step 120: 255.9235, Accuracy: 0.8282\n","Training loss (for one batch) at step 130: 251.2894, Accuracy: 0.8259\n","Training loss (for one batch) at step 140: 249.1193, Accuracy: 0.8257\n","---- Training ----\n","Training loss: 215.8392\n","Training acc over epoch: 0.8264\n","---- Validation ----\n","Validation loss: 78.0000\n","Validation acc: 0.7208\n","Time taken: 9.63s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 235.1634, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 246.7077, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 246.4282, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 248.3089, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 242.9275, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 255.3733, Accuracy: 0.8322\n","Training loss (for one batch) at step 60: 229.8822, Accuracy: 0.8325\n","Training loss (for one batch) at step 70: 245.4441, Accuracy: 0.8334\n","Training loss (for one batch) at step 80: 244.0942, Accuracy: 0.8304\n","Training loss (for one batch) at step 90: 237.0383, Accuracy: 0.8289\n","Training loss (for one batch) at step 100: 264.4553, Accuracy: 0.8267\n","Training loss (for one batch) at step 110: 254.1648, Accuracy: 0.8262\n","Training loss (for one batch) at step 120: 253.3862, Accuracy: 0.8254\n","Training loss (for one batch) at step 130: 242.9842, Accuracy: 0.8259\n","Training loss (for one batch) at step 140: 257.7800, Accuracy: 0.8257\n","---- Training ----\n","Training loss: 225.2136\n","Training acc over epoch: 0.8252\n","---- Validation ----\n","Validation loss: 74.8686\n","Validation acc: 0.7303\n","Time taken: 9.53s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 234.7693, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 256.4996, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 239.4987, Accuracy: 0.8367\n","Training loss (for one batch) at step 30: 249.8239, Accuracy: 0.8365\n","Training loss (for one batch) at step 40: 246.1911, Accuracy: 0.8356\n","Training loss (for one batch) at step 50: 228.7412, Accuracy: 0.8408\n","Training loss (for one batch) at step 60: 235.0481, Accuracy: 0.8384\n","Training loss (for one batch) at step 70: 226.4197, Accuracy: 0.8365\n","Training loss (for one batch) at step 80: 251.5651, Accuracy: 0.8336\n","Training loss (for one batch) at step 90: 227.3966, Accuracy: 0.8340\n","Training loss (for one batch) at step 100: 252.8682, Accuracy: 0.8296\n","Training loss (for one batch) at step 110: 250.3952, Accuracy: 0.8289\n","Training loss (for one batch) at step 120: 247.3540, Accuracy: 0.8294\n","Training loss (for one batch) at step 130: 247.0959, Accuracy: 0.8299\n","Training loss (for one batch) at step 140: 230.8268, Accuracy: 0.8297\n","---- Training ----\n","Training loss: 198.4410\n","Training acc over epoch: 0.8286\n","---- Validation ----\n","Validation loss: 73.4166\n","Validation acc: 0.7227\n","Time taken: 9.53s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 238.2776, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 216.8593, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 247.9523, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 247.5690, Accuracy: 0.8284\n","Training loss (for one batch) at step 40: 235.1917, Accuracy: 0.8268\n","Training loss (for one batch) at step 50: 239.1824, Accuracy: 0.8318\n","Training loss (for one batch) at step 60: 246.0228, Accuracy: 0.8302\n","Training loss (for one batch) at step 70: 225.9839, Accuracy: 0.8304\n","Training loss (for one batch) at step 80: 243.1880, Accuracy: 0.8283\n","Training loss (for one batch) at step 90: 228.3529, Accuracy: 0.8277\n","Training loss (for one batch) at step 100: 221.7016, Accuracy: 0.8262\n","Training loss (for one batch) at step 110: 227.8886, Accuracy: 0.8268\n","Training loss (for one batch) at step 120: 246.4049, Accuracy: 0.8265\n","Training loss (for one batch) at step 130: 237.8077, Accuracy: 0.8263\n","Training loss (for one batch) at step 140: 229.7881, Accuracy: 0.8260\n","---- Training ----\n","Training loss: 213.0684\n","Training acc over epoch: 0.8260\n","---- Validation ----\n","Validation loss: 78.0020\n","Validation acc: 0.7251\n","Time taken: 17.69s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 239.0599, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 244.0765, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 255.7596, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 257.1249, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 222.9073, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 220.3813, Accuracy: 0.8345\n","Training loss (for one batch) at step 60: 238.6107, Accuracy: 0.8316\n","Training loss (for one batch) at step 70: 230.7518, Accuracy: 0.8293\n","Training loss (for one batch) at step 80: 238.3144, Accuracy: 0.8289\n","Training loss (for one batch) at step 90: 243.2593, Accuracy: 0.8286\n","Training loss (for one batch) at step 100: 231.2838, Accuracy: 0.8276\n","Training loss (for one batch) at step 110: 240.6799, Accuracy: 0.8295\n","Training loss (for one batch) at step 120: 216.7725, Accuracy: 0.8287\n","Training loss (for one batch) at step 130: 234.7756, Accuracy: 0.8297\n","Training loss (for one batch) at step 140: 248.8953, Accuracy: 0.8284\n","---- Training ----\n","Training loss: 224.9543\n","Training acc over epoch: 0.8287\n","---- Validation ----\n","Validation loss: 70.5153\n","Validation acc: 0.7300\n","Time taken: 13.57s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 232.9356, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 227.8999, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 246.5025, Accuracy: 0.8362\n","Training loss (for one batch) at step 30: 225.8062, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 235.5363, Accuracy: 0.8344\n","Training loss (for one batch) at step 50: 228.9272, Accuracy: 0.8376\n","Training loss (for one batch) at step 60: 205.0694, Accuracy: 0.8361\n","Training loss (for one batch) at step 70: 238.6744, Accuracy: 0.8369\n","Training loss (for one batch) at step 80: 219.4124, Accuracy: 0.8333\n","Training loss (for one batch) at step 90: 245.6010, Accuracy: 0.8345\n","Training loss (for one batch) at step 100: 235.6540, Accuracy: 0.8341\n","Training loss (for one batch) at step 110: 232.8627, Accuracy: 0.8337\n","Training loss (for one batch) at step 120: 255.7673, Accuracy: 0.8336\n","Training loss (for one batch) at step 130: 239.2982, Accuracy: 0.8336\n","Training loss (for one batch) at step 140: 247.3188, Accuracy: 0.8332\n","---- Training ----\n","Training loss: 211.4240\n","Training acc over epoch: 0.8340\n","---- Validation ----\n","Validation loss: 95.1816\n","Validation acc: 0.7203\n","Time taken: 9.63s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 237.7467, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 226.8647, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 229.1485, Accuracy: 0.8462\n","Training loss (for one batch) at step 30: 239.4305, Accuracy: 0.8294\n","Training loss (for one batch) at step 40: 232.0672, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 236.5449, Accuracy: 0.8349\n","Training loss (for one batch) at step 60: 225.5422, Accuracy: 0.8354\n","Training loss (for one batch) at step 70: 231.6777, Accuracy: 0.8356\n","Training loss (for one batch) at step 80: 241.3332, Accuracy: 0.8332\n","Training loss (for one batch) at step 90: 220.7050, Accuracy: 0.8307\n","Training loss (for one batch) at step 100: 251.4076, Accuracy: 0.8298\n","Training loss (for one batch) at step 110: 239.8605, Accuracy: 0.8275\n","Training loss (for one batch) at step 120: 242.3238, Accuracy: 0.8286\n","Training loss (for one batch) at step 130: 258.0800, Accuracy: 0.8297\n","Training loss (for one batch) at step 140: 242.2086, Accuracy: 0.8291\n","---- Training ----\n","Training loss: 190.8828\n","Training acc over epoch: 0.8290\n","---- Validation ----\n","Validation loss: 86.1767\n","Validation acc: 0.7106\n","Time taken: 9.59s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 230.5379, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 214.9417, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 225.0596, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 236.1614, Accuracy: 0.8397\n","Training loss (for one batch) at step 40: 215.0872, Accuracy: 0.8363\n","Training loss (for one batch) at step 50: 226.5049, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 230.5347, Accuracy: 0.8397\n","Training loss (for one batch) at step 70: 248.4264, Accuracy: 0.8369\n","Training loss (for one batch) at step 80: 240.4931, Accuracy: 0.8347\n","Training loss (for one batch) at step 90: 227.0157, Accuracy: 0.8333\n","Training loss (for one batch) at step 100: 236.1184, Accuracy: 0.8321\n","Training loss (for one batch) at step 110: 233.4433, Accuracy: 0.8311\n","Training loss (for one batch) at step 120: 234.4109, Accuracy: 0.8314\n","Training loss (for one batch) at step 130: 242.4969, Accuracy: 0.8298\n","Training loss (for one batch) at step 140: 219.1986, Accuracy: 0.8299\n","---- Training ----\n","Training loss: 208.8055\n","Training acc over epoch: 0.8298\n","---- Validation ----\n","Validation loss: 75.9376\n","Validation acc: 0.7039\n","Time taken: 9.55s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 230.3796, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 217.6215, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 243.9621, Accuracy: 0.8348\n","Training loss (for one batch) at step 30: 227.5560, Accuracy: 0.8316\n","Training loss (for one batch) at step 40: 228.8665, Accuracy: 0.8322\n","Training loss (for one batch) at step 50: 235.3100, Accuracy: 0.8335\n","Training loss (for one batch) at step 60: 213.8705, Accuracy: 0.8364\n","Training loss (for one batch) at step 70: 224.1072, Accuracy: 0.8354\n","Training loss (for one batch) at step 80: 222.1025, Accuracy: 0.8348\n","Training loss (for one batch) at step 90: 248.2388, Accuracy: 0.8333\n","Training loss (for one batch) at step 100: 221.8412, Accuracy: 0.8332\n","Training loss (for one batch) at step 110: 217.2371, Accuracy: 0.8345\n","Training loss (for one batch) at step 120: 243.3704, Accuracy: 0.8336\n","Training loss (for one batch) at step 130: 230.4152, Accuracy: 0.8338\n","Training loss (for one batch) at step 140: 255.5522, Accuracy: 0.8326\n","---- Training ----\n","Training loss: 198.6040\n","Training acc over epoch: 0.8327\n","---- Validation ----\n","Validation loss: 81.3925\n","Validation acc: 0.7120\n","Time taken: 9.55s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 242.8118, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 240.4739, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 217.6738, Accuracy: 0.8495\n","Training loss (for one batch) at step 30: 252.6936, Accuracy: 0.8397\n","Training loss (for one batch) at step 40: 233.0319, Accuracy: 0.8366\n","Training loss (for one batch) at step 50: 217.0856, Accuracy: 0.8378\n","Training loss (for one batch) at step 60: 215.1580, Accuracy: 0.8372\n","Training loss (for one batch) at step 70: 219.6463, Accuracy: 0.8377\n","Training loss (for one batch) at step 80: 238.3092, Accuracy: 0.8378\n","Training loss (for one batch) at step 90: 258.0686, Accuracy: 0.8348\n","Training loss (for one batch) at step 100: 222.4865, Accuracy: 0.8339\n","Training loss (for one batch) at step 110: 222.9928, Accuracy: 0.8351\n","Training loss (for one batch) at step 120: 228.0995, Accuracy: 0.8340\n","Training loss (for one batch) at step 130: 217.0885, Accuracy: 0.8344\n","Training loss (for one batch) at step 140: 228.3335, Accuracy: 0.8351\n","---- Training ----\n","Training loss: 221.7710\n","Training acc over epoch: 0.8351\n","---- Validation ----\n","Validation loss: 86.8606\n","Validation acc: 0.7071\n","Time taken: 9.70s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 224.1778, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 222.8591, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 200.8625, Accuracy: 0.8490\n","Training loss (for one batch) at step 30: 201.2006, Accuracy: 0.8435\n","Training loss (for one batch) at step 40: 226.8645, Accuracy: 0.8415\n","Training loss (for one batch) at step 50: 229.5835, Accuracy: 0.8465\n","Training loss (for one batch) at step 60: 220.5945, Accuracy: 0.8470\n","Training loss (for one batch) at step 70: 236.1765, Accuracy: 0.8463\n","Training loss (for one batch) at step 80: 212.4132, Accuracy: 0.8462\n","Training loss (for one batch) at step 90: 246.5308, Accuracy: 0.8416\n","Training loss (for one batch) at step 100: 243.9339, Accuracy: 0.8417\n","Training loss (for one batch) at step 110: 249.2395, Accuracy: 0.8404\n","Training loss (for one batch) at step 120: 236.9610, Accuracy: 0.8388\n","Training loss (for one batch) at step 130: 228.3718, Accuracy: 0.8390\n","Training loss (for one batch) at step 140: 221.1117, Accuracy: 0.8385\n","---- Training ----\n","Training loss: 194.9970\n","Training acc over epoch: 0.8381\n","---- Validation ----\n","Validation loss: 70.7449\n","Validation acc: 0.7112\n","Time taken: 9.62s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 229.2253, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 216.8373, Accuracy: 0.8545\n","Training loss (for one batch) at step 20: 222.6333, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 219.3059, Accuracy: 0.8390\n","Training loss (for one batch) at step 40: 227.7141, Accuracy: 0.8390\n","Training loss (for one batch) at step 50: 205.0518, Accuracy: 0.8433\n","Training loss (for one batch) at step 60: 217.1050, Accuracy: 0.8446\n","Training loss (for one batch) at step 70: 205.7720, Accuracy: 0.8441\n","Training loss (for one batch) at step 80: 229.0675, Accuracy: 0.8406\n","Training loss (for one batch) at step 90: 220.0661, Accuracy: 0.8399\n","Training loss (for one batch) at step 100: 225.0611, Accuracy: 0.8400\n","Training loss (for one batch) at step 110: 213.3906, Accuracy: 0.8397\n","Training loss (for one batch) at step 120: 234.8103, Accuracy: 0.8398\n","Training loss (for one batch) at step 130: 229.9227, Accuracy: 0.8388\n","Training loss (for one batch) at step 140: 224.1520, Accuracy: 0.8366\n","---- Training ----\n","Training loss: 192.9002\n","Training acc over epoch: 0.8374\n","---- Validation ----\n","Validation loss: 91.8686\n","Validation acc: 0.7114\n","Time taken: 9.62s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 228.6310, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 206.9173, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 204.8218, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 226.7624, Accuracy: 0.8400\n","Training loss (for one batch) at step 40: 227.9356, Accuracy: 0.8383\n","Training loss (for one batch) at step 50: 222.6228, Accuracy: 0.8406\n","Training loss (for one batch) at step 60: 222.6140, Accuracy: 0.8395\n","Training loss (for one batch) at step 70: 210.3168, Accuracy: 0.8394\n","Training loss (for one batch) at step 80: 206.2185, Accuracy: 0.8380\n","Training loss (for one batch) at step 90: 233.1849, Accuracy: 0.8368\n","Training loss (for one batch) at step 100: 206.1390, Accuracy: 0.8345\n","Training loss (for one batch) at step 110: 222.8156, Accuracy: 0.8355\n","Training loss (for one batch) at step 120: 236.2708, Accuracy: 0.8364\n","Training loss (for one batch) at step 130: 241.0279, Accuracy: 0.8365\n","Training loss (for one batch) at step 140: 225.0012, Accuracy: 0.8374\n","---- Training ----\n","Training loss: 208.9243\n","Training acc over epoch: 0.8376\n","---- Validation ----\n","Validation loss: 78.3577\n","Validation acc: 0.7286\n","Time taken: 9.80s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 207.9833, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 219.3080, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 220.0188, Accuracy: 0.8429\n","Training loss (for one batch) at step 30: 225.8286, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 210.2229, Accuracy: 0.8385\n","Training loss (for one batch) at step 50: 217.5680, Accuracy: 0.8431\n","Training loss (for one batch) at step 60: 242.1019, Accuracy: 0.8382\n","Training loss (for one batch) at step 70: 260.2966, Accuracy: 0.8394\n","Training loss (for one batch) at step 80: 215.0033, Accuracy: 0.8407\n","Training loss (for one batch) at step 90: 211.0357, Accuracy: 0.8411\n","Training loss (for one batch) at step 100: 224.6381, Accuracy: 0.8414\n","Training loss (for one batch) at step 110: 240.2129, Accuracy: 0.8421\n","Training loss (for one batch) at step 120: 217.2250, Accuracy: 0.8418\n","Training loss (for one batch) at step 130: 219.7348, Accuracy: 0.8416\n","Training loss (for one batch) at step 140: 205.0614, Accuracy: 0.8404\n","---- Training ----\n","Training loss: 211.0566\n","Training acc over epoch: 0.8406\n","---- Validation ----\n","Validation loss: 74.5098\n","Validation acc: 0.7284\n","Time taken: 9.69s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 217.2118, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 229.5181, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 228.7163, Accuracy: 0.8543\n","Training loss (for one batch) at step 30: 234.9878, Accuracy: 0.8487\n","Training loss (for one batch) at step 40: 228.6249, Accuracy: 0.8446\n","Training loss (for one batch) at step 50: 204.3716, Accuracy: 0.8459\n","Training loss (for one batch) at step 60: 213.8173, Accuracy: 0.8461\n","Training loss (for one batch) at step 70: 229.2013, Accuracy: 0.8466\n","Training loss (for one batch) at step 80: 227.1932, Accuracy: 0.8446\n","Training loss (for one batch) at step 90: 227.3181, Accuracy: 0.8429\n","Training loss (for one batch) at step 100: 210.6842, Accuracy: 0.8440\n","Training loss (for one batch) at step 110: 206.9723, Accuracy: 0.8428\n","Training loss (for one batch) at step 120: 234.9632, Accuracy: 0.8420\n","Training loss (for one batch) at step 130: 222.9170, Accuracy: 0.8425\n","Training loss (for one batch) at step 140: 230.7695, Accuracy: 0.8422\n","---- Training ----\n","Training loss: 174.9993\n","Training acc over epoch: 0.8424\n","---- Validation ----\n","Validation loss: 82.3881\n","Validation acc: 0.7251\n","Time taken: 9.58s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 216.1512, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 224.4157, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 206.0892, Accuracy: 0.8424\n","Training loss (for one batch) at step 30: 211.1161, Accuracy: 0.8439\n","Training loss (for one batch) at step 40: 236.1564, Accuracy: 0.8395\n","Training loss (for one batch) at step 50: 224.7358, Accuracy: 0.8457\n","Training loss (for one batch) at step 60: 196.2570, Accuracy: 0.8448\n","Training loss (for one batch) at step 70: 235.5951, Accuracy: 0.8427\n","Training loss (for one batch) at step 80: 227.4509, Accuracy: 0.8431\n","Training loss (for one batch) at step 90: 210.9881, Accuracy: 0.8430\n","Training loss (for one batch) at step 100: 217.2804, Accuracy: 0.8414\n","Training loss (for one batch) at step 110: 231.4447, Accuracy: 0.8423\n","Training loss (for one batch) at step 120: 212.3268, Accuracy: 0.8432\n","Training loss (for one batch) at step 130: 217.6592, Accuracy: 0.8429\n","Training loss (for one batch) at step 140: 221.5043, Accuracy: 0.8429\n","---- Training ----\n","Training loss: 205.6389\n","Training acc over epoch: 0.8418\n","---- Validation ----\n","Validation loss: 76.0679\n","Validation acc: 0.7144\n","Time taken: 10.45s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 222.8471, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 211.2410, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 223.2019, Accuracy: 0.8529\n","Training loss (for one batch) at step 30: 221.7294, Accuracy: 0.8513\n","Training loss (for one batch) at step 40: 193.5117, Accuracy: 0.8493\n","Training loss (for one batch) at step 50: 229.3386, Accuracy: 0.8476\n","Training loss (for one batch) at step 60: 205.3208, Accuracy: 0.8489\n","Training loss (for one batch) at step 70: 219.5587, Accuracy: 0.8462\n","Training loss (for one batch) at step 80: 197.7336, Accuracy: 0.8457\n","Training loss (for one batch) at step 90: 216.8507, Accuracy: 0.8444\n","Training loss (for one batch) at step 100: 208.5492, Accuracy: 0.8428\n","Training loss (for one batch) at step 110: 209.7371, Accuracy: 0.8416\n","Training loss (for one batch) at step 120: 204.9613, Accuracy: 0.8424\n","Training loss (for one batch) at step 130: 199.6359, Accuracy: 0.8431\n","Training loss (for one batch) at step 140: 229.7995, Accuracy: 0.8414\n","---- Training ----\n","Training loss: 183.8128\n","Training acc over epoch: 0.8424\n","---- Validation ----\n","Validation loss: 79.5987\n","Validation acc: 0.7265\n","Time taken: 9.59s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 201.0368, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 215.0016, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 198.9877, Accuracy: 0.8448\n","Training loss (for one batch) at step 30: 220.2661, Accuracy: 0.8448\n","Training loss (for one batch) at step 40: 219.1730, Accuracy: 0.8420\n","Training loss (for one batch) at step 50: 213.4567, Accuracy: 0.8459\n","Training loss (for one batch) at step 60: 216.2872, Accuracy: 0.8480\n","Training loss (for one batch) at step 70: 209.5771, Accuracy: 0.8468\n","Training loss (for one batch) at step 80: 241.7383, Accuracy: 0.8446\n","Training loss (for one batch) at step 90: 256.3990, Accuracy: 0.8441\n","Training loss (for one batch) at step 100: 220.1964, Accuracy: 0.8431\n","Training loss (for one batch) at step 110: 220.0380, Accuracy: 0.8428\n","Training loss (for one batch) at step 120: 207.1185, Accuracy: 0.8429\n","Training loss (for one batch) at step 130: 238.6928, Accuracy: 0.8425\n","Training loss (for one batch) at step 140: 203.9113, Accuracy: 0.8423\n","---- Training ----\n","Training loss: 197.6594\n","Training acc over epoch: 0.8431\n","---- Validation ----\n","Validation loss: 60.0447\n","Validation acc: 0.7117\n","Time taken: 9.60s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 243.9871, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 209.3907, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 227.6386, Accuracy: 0.8600\n","Training loss (for one batch) at step 30: 204.8152, Accuracy: 0.8571\n","Training loss (for one batch) at step 40: 226.9688, Accuracy: 0.8524\n","Training loss (for one batch) at step 50: 202.1578, Accuracy: 0.8559\n","Training loss (for one batch) at step 60: 193.7741, Accuracy: 0.8536\n","Training loss (for one batch) at step 70: 228.1769, Accuracy: 0.8523\n","Training loss (for one batch) at step 80: 225.6700, Accuracy: 0.8478\n","Training loss (for one batch) at step 90: 211.7131, Accuracy: 0.8477\n","Training loss (for one batch) at step 100: 205.3952, Accuracy: 0.8475\n","Training loss (for one batch) at step 110: 191.2701, Accuracy: 0.8467\n","Training loss (for one batch) at step 120: 213.7761, Accuracy: 0.8483\n","Training loss (for one batch) at step 130: 221.8164, Accuracy: 0.8482\n","Training loss (for one batch) at step 140: 199.3681, Accuracy: 0.8479\n","---- Training ----\n","Training loss: 199.3873\n","Training acc over epoch: 0.8477\n","---- Validation ----\n","Validation loss: 69.5440\n","Validation acc: 0.7208\n","Time taken: 9.59s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 212.3693, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 223.0607, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 205.1521, Accuracy: 0.8610\n","Training loss (for one batch) at step 30: 202.5189, Accuracy: 0.8587\n","Training loss (for one batch) at step 40: 189.2282, Accuracy: 0.8600\n","Training loss (for one batch) at step 50: 197.0823, Accuracy: 0.8602\n","Training loss (for one batch) at step 60: 217.6607, Accuracy: 0.8579\n","Training loss (for one batch) at step 70: 202.2034, Accuracy: 0.8558\n","Training loss (for one batch) at step 80: 210.1555, Accuracy: 0.8541\n","Training loss (for one batch) at step 90: 218.9495, Accuracy: 0.8519\n","Training loss (for one batch) at step 100: 201.6199, Accuracy: 0.8492\n","Training loss (for one batch) at step 110: 214.3871, Accuracy: 0.8504\n","Training loss (for one batch) at step 120: 217.6900, Accuracy: 0.8500\n","Training loss (for one batch) at step 130: 209.3839, Accuracy: 0.8489\n","Training loss (for one batch) at step 140: 220.0328, Accuracy: 0.8487\n","---- Training ----\n","Training loss: 185.0838\n","Training acc over epoch: 0.8489\n","---- Validation ----\n","Validation loss: 62.7616\n","Validation acc: 0.7149\n","Time taken: 9.65s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7418\n","Validation AUC: 0.7391\n","Validation Balanced_ACC: 0.4875\n","Validation MI: 0.1415\n","Validation Normalized MI: 0.2121\n","Validation Adjusted MI: 0.2121\n","Validation aUc_Sklearn: 0.8273\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 568.8857, Accuracy: 0.4200\n","Training loss (for one batch) at step 10: 451.6623, Accuracy: 0.5155\n","Training loss (for one batch) at step 20: 446.0349, Accuracy: 0.5333\n","Training loss (for one batch) at step 30: 532.7630, Accuracy: 0.5335\n","Training loss (for one batch) at step 40: 497.5677, Accuracy: 0.5305\n","Training loss (for one batch) at step 50: 432.1443, Accuracy: 0.5367\n","Training loss (for one batch) at step 60: 450.0684, Accuracy: 0.5392\n","Training loss (for one batch) at step 70: 471.9392, Accuracy: 0.5425\n","Training loss (for one batch) at step 80: 431.8223, Accuracy: 0.5479\n","Training loss (for one batch) at step 90: 456.9954, Accuracy: 0.5488\n","Training loss (for one batch) at step 100: 417.6610, Accuracy: 0.5505\n","Training loss (for one batch) at step 110: 415.3194, Accuracy: 0.5516\n","Training loss (for one batch) at step 120: 414.7607, Accuracy: 0.5542\n","Training loss (for one batch) at step 130: 442.2986, Accuracy: 0.5556\n","Training loss (for one batch) at step 140: 416.3670, Accuracy: 0.5577\n","---- Training ----\n","Training loss: 377.5881\n","Training acc over epoch: 0.5596\n","---- Validation ----\n","Validation loss: 80.6350\n","Validation acc: 0.5134\n","Time taken: 13.23s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 440.1349, Accuracy: 0.5200\n","Training loss (for one batch) at step 10: 413.3390, Accuracy: 0.6218\n","Training loss (for one batch) at step 20: 413.7313, Accuracy: 0.6157\n","Training loss (for one batch) at step 30: 396.4484, Accuracy: 0.6116\n","Training loss (for one batch) at step 40: 395.4899, Accuracy: 0.6080\n","Training loss (for one batch) at step 50: 384.6578, Accuracy: 0.6059\n","Training loss (for one batch) at step 60: 397.2538, Accuracy: 0.6049\n","Training loss (for one batch) at step 70: 405.0442, Accuracy: 0.6051\n","Training loss (for one batch) at step 80: 402.7356, Accuracy: 0.6075\n","Training loss (for one batch) at step 90: 386.2458, Accuracy: 0.6080\n","Training loss (for one batch) at step 100: 399.7001, Accuracy: 0.6070\n","Training loss (for one batch) at step 110: 379.1230, Accuracy: 0.6080\n","Training loss (for one batch) at step 120: 411.8099, Accuracy: 0.6081\n","Training loss (for one batch) at step 130: 397.9330, Accuracy: 0.6091\n","Training loss (for one batch) at step 140: 388.2307, Accuracy: 0.6087\n","---- Training ----\n","Training loss: 331.2840\n","Training acc over epoch: 0.6107\n","---- Validation ----\n","Validation loss: 86.0560\n","Validation acc: 0.5261\n","Time taken: 9.50s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 387.5569, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 379.3525, Accuracy: 0.6264\n","Training loss (for one batch) at step 20: 352.2607, Accuracy: 0.6310\n","Training loss (for one batch) at step 30: 380.0068, Accuracy: 0.6294\n","Training loss (for one batch) at step 40: 388.8598, Accuracy: 0.6312\n","Training loss (for one batch) at step 50: 351.8120, Accuracy: 0.6339\n","Training loss (for one batch) at step 60: 368.2588, Accuracy: 0.6320\n","Training loss (for one batch) at step 70: 376.6803, Accuracy: 0.6358\n","Training loss (for one batch) at step 80: 387.9629, Accuracy: 0.6328\n","Training loss (for one batch) at step 90: 391.5165, Accuracy: 0.6300\n","Training loss (for one batch) at step 100: 380.8597, Accuracy: 0.6331\n","Training loss (for one batch) at step 110: 362.5974, Accuracy: 0.6328\n","Training loss (for one batch) at step 120: 371.5395, Accuracy: 0.6305\n","Training loss (for one batch) at step 130: 365.3699, Accuracy: 0.6326\n","Training loss (for one batch) at step 140: 378.5998, Accuracy: 0.6342\n","---- Training ----\n","Training loss: 340.2219\n","Training acc over epoch: 0.6334\n","---- Validation ----\n","Validation loss: 76.6787\n","Validation acc: 0.6784\n","Time taken: 9.64s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 362.3145, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 357.5943, Accuracy: 0.6455\n","Training loss (for one batch) at step 20: 370.5651, Accuracy: 0.6348\n","Training loss (for one batch) at step 30: 353.3396, Accuracy: 0.6413\n","Training loss (for one batch) at step 40: 360.1042, Accuracy: 0.6463\n","Training loss (for one batch) at step 50: 341.5472, Accuracy: 0.6453\n","Training loss (for one batch) at step 60: 361.8873, Accuracy: 0.6461\n","Training loss (for one batch) at step 70: 344.2211, Accuracy: 0.6454\n","Training loss (for one batch) at step 80: 338.4622, Accuracy: 0.6478\n","Training loss (for one batch) at step 90: 348.9875, Accuracy: 0.6481\n","Training loss (for one batch) at step 100: 345.3639, Accuracy: 0.6465\n","Training loss (for one batch) at step 110: 343.4567, Accuracy: 0.6483\n","Training loss (for one batch) at step 120: 383.7917, Accuracy: 0.6491\n","Training loss (for one batch) at step 130: 362.2031, Accuracy: 0.6511\n","Training loss (for one batch) at step 140: 358.5007, Accuracy: 0.6520\n","---- Training ----\n","Training loss: 315.4431\n","Training acc over epoch: 0.6524\n","---- Validation ----\n","Validation loss: 74.4960\n","Validation acc: 0.6803\n","Time taken: 9.69s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 353.1662, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 315.5179, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 356.0611, Accuracy: 0.6595\n","Training loss (for one batch) at step 30: 342.7633, Accuracy: 0.6587\n","Training loss (for one batch) at step 40: 342.4004, Accuracy: 0.6620\n","Training loss (for one batch) at step 50: 332.2070, Accuracy: 0.6659\n","Training loss (for one batch) at step 60: 346.2701, Accuracy: 0.6702\n","Training loss (for one batch) at step 70: 339.8632, Accuracy: 0.6689\n","Training loss (for one batch) at step 80: 332.8863, Accuracy: 0.6721\n","Training loss (for one batch) at step 90: 338.4653, Accuracy: 0.6703\n","Training loss (for one batch) at step 100: 336.6691, Accuracy: 0.6704\n","Training loss (for one batch) at step 110: 355.5804, Accuracy: 0.6685\n","Training loss (for one batch) at step 120: 353.3295, Accuracy: 0.6668\n","Training loss (for one batch) at step 130: 329.4775, Accuracy: 0.6656\n","Training loss (for one batch) at step 140: 321.3842, Accuracy: 0.6650\n","---- Training ----\n","Training loss: 288.3111\n","Training acc over epoch: 0.6652\n","---- Validation ----\n","Validation loss: 78.0440\n","Validation acc: 0.6910\n","Time taken: 9.60s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 345.0480, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 331.3069, Accuracy: 0.7091\n","Training loss (for one batch) at step 20: 350.7400, Accuracy: 0.6990\n","Training loss (for one batch) at step 30: 337.7690, Accuracy: 0.6816\n","Training loss (for one batch) at step 40: 350.2240, Accuracy: 0.6805\n","Training loss (for one batch) at step 50: 331.9173, Accuracy: 0.6806\n","Training loss (for one batch) at step 60: 337.8227, Accuracy: 0.6849\n","Training loss (for one batch) at step 70: 333.6231, Accuracy: 0.6873\n","Training loss (for one batch) at step 80: 331.2105, Accuracy: 0.6864\n","Training loss (for one batch) at step 90: 326.0552, Accuracy: 0.6866\n","Training loss (for one batch) at step 100: 316.4421, Accuracy: 0.6867\n","Training loss (for one batch) at step 110: 336.8534, Accuracy: 0.6844\n","Training loss (for one batch) at step 120: 337.2903, Accuracy: 0.6836\n","Training loss (for one batch) at step 130: 333.8102, Accuracy: 0.6831\n","Training loss (for one batch) at step 140: 330.0198, Accuracy: 0.6808\n","---- Training ----\n","Training loss: 275.4659\n","Training acc over epoch: 0.6805\n","---- Validation ----\n","Validation loss: 64.0486\n","Validation acc: 0.6929\n","Time taken: 9.58s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 341.7885, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 317.0500, Accuracy: 0.6791\n","Training loss (for one batch) at step 20: 315.4883, Accuracy: 0.6957\n","Training loss (for one batch) at step 30: 322.5573, Accuracy: 0.6916\n","Training loss (for one batch) at step 40: 323.7074, Accuracy: 0.6871\n","Training loss (for one batch) at step 50: 332.8784, Accuracy: 0.6890\n","Training loss (for one batch) at step 60: 320.9678, Accuracy: 0.6877\n","Training loss (for one batch) at step 70: 325.7137, Accuracy: 0.6889\n","Training loss (for one batch) at step 80: 328.9455, Accuracy: 0.6858\n","Training loss (for one batch) at step 90: 332.9308, Accuracy: 0.6853\n","Training loss (for one batch) at step 100: 324.8896, Accuracy: 0.6871\n","Training loss (for one batch) at step 110: 312.8874, Accuracy: 0.6868\n","Training loss (for one batch) at step 120: 320.6367, Accuracy: 0.6877\n","Training loss (for one batch) at step 130: 339.0819, Accuracy: 0.6868\n","Training loss (for one batch) at step 140: 338.1364, Accuracy: 0.6882\n","---- Training ----\n","Training loss: 267.4569\n","Training acc over epoch: 0.6898\n","---- Validation ----\n","Validation loss: 64.6937\n","Validation acc: 0.7023\n","Time taken: 10.42s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 321.4506, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 324.3830, Accuracy: 0.7082\n","Training loss (for one batch) at step 20: 335.8668, Accuracy: 0.7086\n","Training loss (for one batch) at step 30: 341.3915, Accuracy: 0.7039\n","Training loss (for one batch) at step 40: 321.2319, Accuracy: 0.7017\n","Training loss (for one batch) at step 50: 304.8556, Accuracy: 0.7024\n","Training loss (for one batch) at step 60: 309.0815, Accuracy: 0.7026\n","Training loss (for one batch) at step 70: 328.6027, Accuracy: 0.7006\n","Training loss (for one batch) at step 80: 317.6494, Accuracy: 0.7025\n","Training loss (for one batch) at step 90: 314.4439, Accuracy: 0.7033\n","Training loss (for one batch) at step 100: 308.5929, Accuracy: 0.7028\n","Training loss (for one batch) at step 110: 305.4953, Accuracy: 0.7014\n","Training loss (for one batch) at step 120: 321.3786, Accuracy: 0.7017\n","Training loss (for one batch) at step 130: 308.8441, Accuracy: 0.7008\n","Training loss (for one batch) at step 140: 320.2889, Accuracy: 0.7015\n","---- Training ----\n","Training loss: 285.2229\n","Training acc over epoch: 0.7012\n","---- Validation ----\n","Validation loss: 69.4343\n","Validation acc: 0.6991\n","Time taken: 9.59s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 332.4197, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 307.3240, Accuracy: 0.7055\n","Training loss (for one batch) at step 20: 316.6884, Accuracy: 0.7076\n","Training loss (for one batch) at step 30: 311.5858, Accuracy: 0.7058\n","Training loss (for one batch) at step 40: 308.5185, Accuracy: 0.7049\n","Training loss (for one batch) at step 50: 313.3641, Accuracy: 0.7118\n","Training loss (for one batch) at step 60: 299.7479, Accuracy: 0.7118\n","Training loss (for one batch) at step 70: 307.5673, Accuracy: 0.7123\n","Training loss (for one batch) at step 80: 317.8106, Accuracy: 0.7125\n","Training loss (for one batch) at step 90: 335.4947, Accuracy: 0.7134\n","Training loss (for one batch) at step 100: 328.5099, Accuracy: 0.7129\n","Training loss (for one batch) at step 110: 317.0024, Accuracy: 0.7134\n","Training loss (for one batch) at step 120: 305.5397, Accuracy: 0.7147\n","Training loss (for one batch) at step 130: 314.6164, Accuracy: 0.7142\n","Training loss (for one batch) at step 140: 338.7523, Accuracy: 0.7138\n","---- Training ----\n","Training loss: 282.7435\n","Training acc over epoch: 0.7130\n","---- Validation ----\n","Validation loss: 66.9310\n","Validation acc: 0.7136\n","Time taken: 9.74s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 318.3720, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 313.7696, Accuracy: 0.7500\n","Training loss (for one batch) at step 20: 309.9187, Accuracy: 0.7324\n","Training loss (for one batch) at step 30: 314.7567, Accuracy: 0.7261\n","Training loss (for one batch) at step 40: 297.2915, Accuracy: 0.7263\n","Training loss (for one batch) at step 50: 299.2422, Accuracy: 0.7267\n","Training loss (for one batch) at step 60: 310.5887, Accuracy: 0.7280\n","Training loss (for one batch) at step 70: 315.0131, Accuracy: 0.7294\n","Training loss (for one batch) at step 80: 315.9003, Accuracy: 0.7259\n","Training loss (for one batch) at step 90: 288.9050, Accuracy: 0.7282\n","Training loss (for one batch) at step 100: 308.9812, Accuracy: 0.7253\n","Training loss (for one batch) at step 110: 304.1180, Accuracy: 0.7233\n","Training loss (for one batch) at step 120: 327.4302, Accuracy: 0.7221\n","Training loss (for one batch) at step 130: 313.0915, Accuracy: 0.7228\n","Training loss (for one batch) at step 140: 300.7927, Accuracy: 0.7240\n","---- Training ----\n","Training loss: 260.9564\n","Training acc over epoch: 0.7253\n","---- Validation ----\n","Validation loss: 73.4276\n","Validation acc: 0.7200\n","Time taken: 10.35s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 312.5225, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 297.5049, Accuracy: 0.7373\n","Training loss (for one batch) at step 20: 298.7780, Accuracy: 0.7329\n","Training loss (for one batch) at step 30: 318.7906, Accuracy: 0.7310\n","Training loss (for one batch) at step 40: 304.3469, Accuracy: 0.7310\n","Training loss (for one batch) at step 50: 305.5131, Accuracy: 0.7335\n","Training loss (for one batch) at step 60: 301.3974, Accuracy: 0.7334\n","Training loss (for one batch) at step 70: 308.1199, Accuracy: 0.7365\n","Training loss (for one batch) at step 80: 306.3313, Accuracy: 0.7320\n","Training loss (for one batch) at step 90: 298.6764, Accuracy: 0.7318\n","Training loss (for one batch) at step 100: 321.1740, Accuracy: 0.7319\n","Training loss (for one batch) at step 110: 312.0657, Accuracy: 0.7334\n","Training loss (for one batch) at step 120: 334.5854, Accuracy: 0.7325\n","Training loss (for one batch) at step 130: 302.5723, Accuracy: 0.7323\n","Training loss (for one batch) at step 140: 298.4282, Accuracy: 0.7326\n","---- Training ----\n","Training loss: 266.0488\n","Training acc over epoch: 0.7334\n","---- Validation ----\n","Validation loss: 65.9251\n","Validation acc: 0.7141\n","Time taken: 9.73s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 293.2030, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 291.8892, Accuracy: 0.7573\n","Training loss (for one batch) at step 20: 306.3955, Accuracy: 0.7519\n","Training loss (for one batch) at step 30: 309.8345, Accuracy: 0.7535\n","Training loss (for one batch) at step 40: 301.2954, Accuracy: 0.7512\n","Training loss (for one batch) at step 50: 318.3407, Accuracy: 0.7490\n","Training loss (for one batch) at step 60: 304.4682, Accuracy: 0.7525\n","Training loss (for one batch) at step 70: 301.5425, Accuracy: 0.7523\n","Training loss (for one batch) at step 80: 304.9781, Accuracy: 0.7531\n","Training loss (for one batch) at step 90: 309.9811, Accuracy: 0.7529\n","Training loss (for one batch) at step 100: 296.2306, Accuracy: 0.7524\n","Training loss (for one batch) at step 110: 288.0007, Accuracy: 0.7525\n","Training loss (for one batch) at step 120: 287.5788, Accuracy: 0.7507\n","Training loss (for one batch) at step 130: 301.3459, Accuracy: 0.7500\n","Training loss (for one batch) at step 140: 308.7523, Accuracy: 0.7499\n","---- Training ----\n","Training loss: 253.2676\n","Training acc over epoch: 0.7505\n","---- Validation ----\n","Validation loss: 70.4911\n","Validation acc: 0.7214\n","Time taken: 9.68s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 285.7964, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 286.6335, Accuracy: 0.7718\n","Training loss (for one batch) at step 20: 317.1285, Accuracy: 0.7571\n","Training loss (for one batch) at step 30: 299.2650, Accuracy: 0.7574\n","Training loss (for one batch) at step 40: 294.5296, Accuracy: 0.7585\n","Training loss (for one batch) at step 50: 286.6991, Accuracy: 0.7620\n","Training loss (for one batch) at step 60: 293.9570, Accuracy: 0.7634\n","Training loss (for one batch) at step 70: 290.3295, Accuracy: 0.7624\n","Training loss (for one batch) at step 80: 291.7386, Accuracy: 0.7593\n","Training loss (for one batch) at step 90: 298.1132, Accuracy: 0.7599\n","Training loss (for one batch) at step 100: 298.0750, Accuracy: 0.7610\n","Training loss (for one batch) at step 110: 290.3265, Accuracy: 0.7594\n","Training loss (for one batch) at step 120: 285.7820, Accuracy: 0.7585\n","Training loss (for one batch) at step 130: 309.8615, Accuracy: 0.7586\n","Training loss (for one batch) at step 140: 287.1933, Accuracy: 0.7578\n","---- Training ----\n","Training loss: 253.7690\n","Training acc over epoch: 0.7577\n","---- Validation ----\n","Validation loss: 77.1732\n","Validation acc: 0.7141\n","Time taken: 9.64s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 305.8049, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 285.2593, Accuracy: 0.7745\n","Training loss (for one batch) at step 20: 283.4224, Accuracy: 0.7714\n","Training loss (for one batch) at step 30: 294.5608, Accuracy: 0.7658\n","Training loss (for one batch) at step 40: 271.0587, Accuracy: 0.7663\n","Training loss (for one batch) at step 50: 296.1379, Accuracy: 0.7665\n","Training loss (for one batch) at step 60: 289.7236, Accuracy: 0.7651\n","Training loss (for one batch) at step 70: 298.9829, Accuracy: 0.7665\n","Training loss (for one batch) at step 80: 289.8520, Accuracy: 0.7658\n","Training loss (for one batch) at step 90: 316.5719, Accuracy: 0.7646\n","Training loss (for one batch) at step 100: 305.2875, Accuracy: 0.7647\n","Training loss (for one batch) at step 110: 301.4951, Accuracy: 0.7646\n","Training loss (for one batch) at step 120: 288.8124, Accuracy: 0.7640\n","Training loss (for one batch) at step 130: 297.0461, Accuracy: 0.7627\n","Training loss (for one batch) at step 140: 290.1013, Accuracy: 0.7627\n","---- Training ----\n","Training loss: 255.0035\n","Training acc over epoch: 0.7625\n","---- Validation ----\n","Validation loss: 66.1202\n","Validation acc: 0.7198\n","Time taken: 9.96s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 288.1241, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 293.3087, Accuracy: 0.7800\n","Training loss (for one batch) at step 20: 278.7477, Accuracy: 0.7824\n","Training loss (for one batch) at step 30: 293.9792, Accuracy: 0.7797\n","Training loss (for one batch) at step 40: 299.6009, Accuracy: 0.7785\n","Training loss (for one batch) at step 50: 284.5036, Accuracy: 0.7827\n","Training loss (for one batch) at step 60: 280.4675, Accuracy: 0.7808\n","Training loss (for one batch) at step 70: 291.1841, Accuracy: 0.7821\n","Training loss (for one batch) at step 80: 295.5735, Accuracy: 0.7825\n","Training loss (for one batch) at step 90: 286.6116, Accuracy: 0.7788\n","Training loss (for one batch) at step 100: 284.8466, Accuracy: 0.7765\n","Training loss (for one batch) at step 110: 284.9034, Accuracy: 0.7776\n","Training loss (for one batch) at step 120: 282.2497, Accuracy: 0.7785\n","Training loss (for one batch) at step 130: 287.7419, Accuracy: 0.7768\n","Training loss (for one batch) at step 140: 292.4550, Accuracy: 0.7757\n","---- Training ----\n","Training loss: 262.5373\n","Training acc over epoch: 0.7753\n","---- Validation ----\n","Validation loss: 70.8101\n","Validation acc: 0.7332\n","Time taken: 9.68s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 271.4908, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 288.4997, Accuracy: 0.7591\n","Training loss (for one batch) at step 20: 289.0241, Accuracy: 0.7833\n","Training loss (for one batch) at step 30: 286.8523, Accuracy: 0.7800\n","Training loss (for one batch) at step 40: 291.0082, Accuracy: 0.7815\n","Training loss (for one batch) at step 50: 272.8422, Accuracy: 0.7816\n","Training loss (for one batch) at step 60: 300.6828, Accuracy: 0.7802\n","Training loss (for one batch) at step 70: 297.7192, Accuracy: 0.7813\n","Training loss (for one batch) at step 80: 286.3366, Accuracy: 0.7833\n","Training loss (for one batch) at step 90: 291.8858, Accuracy: 0.7813\n","Training loss (for one batch) at step 100: 288.6480, Accuracy: 0.7820\n","Training loss (for one batch) at step 110: 273.4122, Accuracy: 0.7828\n","Training loss (for one batch) at step 120: 286.9872, Accuracy: 0.7821\n","Training loss (for one batch) at step 130: 266.3191, Accuracy: 0.7811\n","Training loss (for one batch) at step 140: 280.7135, Accuracy: 0.7809\n","---- Training ----\n","Training loss: 256.4079\n","Training acc over epoch: 0.7817\n","---- Validation ----\n","Validation loss: 73.2241\n","Validation acc: 0.7343\n","Time taken: 9.66s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 273.8684, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 275.1499, Accuracy: 0.7918\n","Training loss (for one batch) at step 20: 280.5081, Accuracy: 0.7957\n","Training loss (for one batch) at step 30: 294.6706, Accuracy: 0.7829\n","Training loss (for one batch) at step 40: 275.4331, Accuracy: 0.7832\n","Training loss (for one batch) at step 50: 293.3192, Accuracy: 0.7778\n","Training loss (for one batch) at step 60: 276.2329, Accuracy: 0.7789\n","Training loss (for one batch) at step 70: 291.7392, Accuracy: 0.7806\n","Training loss (for one batch) at step 80: 277.3940, Accuracy: 0.7804\n","Training loss (for one batch) at step 90: 291.4399, Accuracy: 0.7791\n","Training loss (for one batch) at step 100: 283.0084, Accuracy: 0.7789\n","Training loss (for one batch) at step 110: 282.6981, Accuracy: 0.7803\n","Training loss (for one batch) at step 120: 278.4494, Accuracy: 0.7810\n","Training loss (for one batch) at step 130: 272.0303, Accuracy: 0.7811\n","Training loss (for one batch) at step 140: 280.7204, Accuracy: 0.7805\n","---- Training ----\n","Training loss: 262.6554\n","Training acc over epoch: 0.7800\n","---- Validation ----\n","Validation loss: 67.2954\n","Validation acc: 0.7198\n","Time taken: 9.80s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 276.3493, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 273.3190, Accuracy: 0.7991\n","Training loss (for one batch) at step 20: 291.9644, Accuracy: 0.8029\n","Training loss (for one batch) at step 30: 284.1984, Accuracy: 0.7939\n","Training loss (for one batch) at step 40: 279.7314, Accuracy: 0.7898\n","Training loss (for one batch) at step 50: 276.8441, Accuracy: 0.7947\n","Training loss (for one batch) at step 60: 299.7368, Accuracy: 0.7925\n","Training loss (for one batch) at step 70: 287.6313, Accuracy: 0.7930\n","Training loss (for one batch) at step 80: 281.3807, Accuracy: 0.7911\n","Training loss (for one batch) at step 90: 276.4063, Accuracy: 0.7910\n","Training loss (for one batch) at step 100: 296.4628, Accuracy: 0.7919\n","Training loss (for one batch) at step 110: 289.6125, Accuracy: 0.7932\n","Training loss (for one batch) at step 120: 282.2740, Accuracy: 0.7934\n","Training loss (for one batch) at step 130: 283.9520, Accuracy: 0.7944\n","Training loss (for one batch) at step 140: 272.2465, Accuracy: 0.7933\n","---- Training ----\n","Training loss: 250.5517\n","Training acc over epoch: 0.7921\n","---- Validation ----\n","Validation loss: 80.6092\n","Validation acc: 0.7281\n","Time taken: 9.75s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 299.2094, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 284.2640, Accuracy: 0.7882\n","Training loss (for one batch) at step 20: 291.3737, Accuracy: 0.7910\n","Training loss (for one batch) at step 30: 265.8117, Accuracy: 0.7897\n","Training loss (for one batch) at step 40: 269.2454, Accuracy: 0.7966\n","Training loss (for one batch) at step 50: 265.5245, Accuracy: 0.7955\n","Training loss (for one batch) at step 60: 284.3410, Accuracy: 0.7975\n","Training loss (for one batch) at step 70: 288.6520, Accuracy: 0.7965\n","Training loss (for one batch) at step 80: 294.8955, Accuracy: 0.7946\n","Training loss (for one batch) at step 90: 285.7061, Accuracy: 0.7960\n","Training loss (for one batch) at step 100: 283.0970, Accuracy: 0.7951\n","Training loss (for one batch) at step 110: 270.5354, Accuracy: 0.7965\n","Training loss (for one batch) at step 120: 282.6263, Accuracy: 0.7956\n","Training loss (for one batch) at step 130: 286.4620, Accuracy: 0.7956\n","Training loss (for one batch) at step 140: 287.9868, Accuracy: 0.7955\n","---- Training ----\n","Training loss: 246.0517\n","Training acc over epoch: 0.7948\n","---- Validation ----\n","Validation loss: 66.9030\n","Validation acc: 0.7257\n","Time taken: 9.73s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 260.3656, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 266.1412, Accuracy: 0.8200\n","Training loss (for one batch) at step 20: 261.8364, Accuracy: 0.8005\n","Training loss (for one batch) at step 30: 284.2681, Accuracy: 0.7871\n","Training loss (for one batch) at step 40: 261.4339, Accuracy: 0.7937\n","Training loss (for one batch) at step 50: 280.3197, Accuracy: 0.7975\n","Training loss (for one batch) at step 60: 275.0101, Accuracy: 0.8000\n","Training loss (for one batch) at step 70: 273.3321, Accuracy: 0.7976\n","Training loss (for one batch) at step 80: 267.8221, Accuracy: 0.7973\n","Training loss (for one batch) at step 90: 272.1797, Accuracy: 0.7971\n","Training loss (for one batch) at step 100: 260.0889, Accuracy: 0.7985\n","Training loss (for one batch) at step 110: 256.8557, Accuracy: 0.7984\n","Training loss (for one batch) at step 120: 275.8348, Accuracy: 0.7988\n","Training loss (for one batch) at step 130: 273.0999, Accuracy: 0.7976\n","Training loss (for one batch) at step 140: 284.1077, Accuracy: 0.7962\n","---- Training ----\n","Training loss: 239.8792\n","Training acc over epoch: 0.7965\n","---- Validation ----\n","Validation loss: 59.4943\n","Validation acc: 0.7260\n","Time taken: 9.81s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 267.5208, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 296.7277, Accuracy: 0.8145\n","Training loss (for one batch) at step 20: 281.9499, Accuracy: 0.8062\n","Training loss (for one batch) at step 30: 280.5839, Accuracy: 0.8045\n","Training loss (for one batch) at step 40: 268.7167, Accuracy: 0.8022\n","Training loss (for one batch) at step 50: 251.4016, Accuracy: 0.8039\n","Training loss (for one batch) at step 60: 244.0307, Accuracy: 0.8066\n","Training loss (for one batch) at step 70: 262.3195, Accuracy: 0.8025\n","Training loss (for one batch) at step 80: 270.9123, Accuracy: 0.8005\n","Training loss (for one batch) at step 90: 259.1586, Accuracy: 0.7993\n","Training loss (for one batch) at step 100: 267.4345, Accuracy: 0.7975\n","Training loss (for one batch) at step 110: 257.5613, Accuracy: 0.7976\n","Training loss (for one batch) at step 120: 265.1866, Accuracy: 0.7979\n","Training loss (for one batch) at step 130: 261.2609, Accuracy: 0.7981\n","Training loss (for one batch) at step 140: 284.3525, Accuracy: 0.7986\n","---- Training ----\n","Training loss: 244.1778\n","Training acc over epoch: 0.7988\n","---- Validation ----\n","Validation loss: 73.2954\n","Validation acc: 0.7238\n","Time taken: 9.72s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 265.3951, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 280.5075, Accuracy: 0.8009\n","Training loss (for one batch) at step 20: 278.6241, Accuracy: 0.8000\n","Training loss (for one batch) at step 30: 251.6960, Accuracy: 0.8029\n","Training loss (for one batch) at step 40: 264.1543, Accuracy: 0.8007\n","Training loss (for one batch) at step 50: 255.2797, Accuracy: 0.8065\n","Training loss (for one batch) at step 60: 263.0266, Accuracy: 0.8052\n","Training loss (for one batch) at step 70: 296.2678, Accuracy: 0.8038\n","Training loss (for one batch) at step 80: 274.7296, Accuracy: 0.8042\n","Training loss (for one batch) at step 90: 294.4360, Accuracy: 0.8027\n","Training loss (for one batch) at step 100: 251.4995, Accuracy: 0.8038\n","Training loss (for one batch) at step 110: 266.3806, Accuracy: 0.8019\n","Training loss (for one batch) at step 120: 282.3898, Accuracy: 0.8014\n","Training loss (for one batch) at step 130: 258.4463, Accuracy: 0.8008\n","Training loss (for one batch) at step 140: 275.0091, Accuracy: 0.7994\n","---- Training ----\n","Training loss: 232.7555\n","Training acc over epoch: 0.7995\n","---- Validation ----\n","Validation loss: 70.3553\n","Validation acc: 0.7241\n","Time taken: 9.59s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 256.6317, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 267.0557, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 247.0319, Accuracy: 0.8219\n","Training loss (for one batch) at step 30: 250.3326, Accuracy: 0.8090\n","Training loss (for one batch) at step 40: 256.8799, Accuracy: 0.8093\n","Training loss (for one batch) at step 50: 265.6338, Accuracy: 0.8118\n","Training loss (for one batch) at step 60: 266.9166, Accuracy: 0.8110\n","Training loss (for one batch) at step 70: 285.6589, Accuracy: 0.8075\n","Training loss (for one batch) at step 80: 264.8353, Accuracy: 0.8043\n","Training loss (for one batch) at step 90: 276.4013, Accuracy: 0.8040\n","Training loss (for one batch) at step 100: 272.3308, Accuracy: 0.8050\n","Training loss (for one batch) at step 110: 279.8630, Accuracy: 0.8043\n","Training loss (for one batch) at step 120: 254.5966, Accuracy: 0.8061\n","Training loss (for one batch) at step 130: 258.0412, Accuracy: 0.8053\n","Training loss (for one batch) at step 140: 256.1932, Accuracy: 0.8045\n","---- Training ----\n","Training loss: 222.2882\n","Training acc over epoch: 0.8039\n","---- Validation ----\n","Validation loss: 73.0445\n","Validation acc: 0.7222\n","Time taken: 9.56s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 234.7218, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 264.3424, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 277.0273, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 249.5613, Accuracy: 0.8281\n","Training loss (for one batch) at step 40: 254.1422, Accuracy: 0.8212\n","Training loss (for one batch) at step 50: 251.4501, Accuracy: 0.8237\n","Training loss (for one batch) at step 60: 260.8612, Accuracy: 0.8231\n","Training loss (for one batch) at step 70: 242.9721, Accuracy: 0.8187\n","Training loss (for one batch) at step 80: 302.3999, Accuracy: 0.8157\n","Training loss (for one batch) at step 90: 254.4896, Accuracy: 0.8135\n","Training loss (for one batch) at step 100: 249.0810, Accuracy: 0.8157\n","Training loss (for one batch) at step 110: 248.4544, Accuracy: 0.8156\n","Training loss (for one batch) at step 120: 267.6320, Accuracy: 0.8136\n","Training loss (for one batch) at step 130: 253.3341, Accuracy: 0.8123\n","Training loss (for one batch) at step 140: 268.4758, Accuracy: 0.8113\n","---- Training ----\n","Training loss: 231.1224\n","Training acc over epoch: 0.8118\n","---- Validation ----\n","Validation loss: 67.9434\n","Validation acc: 0.7335\n","Time taken: 9.64s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 239.0714, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 255.4821, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 276.9843, Accuracy: 0.8167\n","Training loss (for one batch) at step 30: 270.6553, Accuracy: 0.8100\n","Training loss (for one batch) at step 40: 254.6047, Accuracy: 0.8083\n","Training loss (for one batch) at step 50: 261.0518, Accuracy: 0.8098\n","Training loss (for one batch) at step 60: 263.5450, Accuracy: 0.8146\n","Training loss (for one batch) at step 70: 279.2819, Accuracy: 0.8125\n","Training loss (for one batch) at step 80: 254.0916, Accuracy: 0.8114\n","Training loss (for one batch) at step 90: 246.0985, Accuracy: 0.8120\n","Training loss (for one batch) at step 100: 247.5107, Accuracy: 0.8119\n","Training loss (for one batch) at step 110: 265.1039, Accuracy: 0.8101\n","Training loss (for one batch) at step 120: 259.2791, Accuracy: 0.8105\n","Training loss (for one batch) at step 130: 244.1434, Accuracy: 0.8106\n","Training loss (for one batch) at step 140: 264.1385, Accuracy: 0.8097\n","---- Training ----\n","Training loss: 236.7735\n","Training acc over epoch: 0.8092\n","---- Validation ----\n","Validation loss: 60.7450\n","Validation acc: 0.7356\n","Time taken: 9.57s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 266.1420, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 242.3362, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 256.8047, Accuracy: 0.8152\n","Training loss (for one batch) at step 30: 250.4251, Accuracy: 0.8161\n","Training loss (for one batch) at step 40: 258.0813, Accuracy: 0.8195\n","Training loss (for one batch) at step 50: 244.1172, Accuracy: 0.8218\n","Training loss (for one batch) at step 60: 238.4470, Accuracy: 0.8198\n","Training loss (for one batch) at step 70: 278.9713, Accuracy: 0.8182\n","Training loss (for one batch) at step 80: 268.7217, Accuracy: 0.8169\n","Training loss (for one batch) at step 90: 265.1924, Accuracy: 0.8142\n","Training loss (for one batch) at step 100: 259.3540, Accuracy: 0.8119\n","Training loss (for one batch) at step 110: 289.2863, Accuracy: 0.8123\n","Training loss (for one batch) at step 120: 270.8283, Accuracy: 0.8118\n","Training loss (for one batch) at step 130: 280.7487, Accuracy: 0.8115\n","Training loss (for one batch) at step 140: 280.1719, Accuracy: 0.8107\n","---- Training ----\n","Training loss: 230.5517\n","Training acc over epoch: 0.8108\n","---- Validation ----\n","Validation loss: 67.4935\n","Validation acc: 0.7206\n","Time taken: 9.68s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 240.5555, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 235.8230, Accuracy: 0.8164\n","Training loss (for one batch) at step 20: 250.6454, Accuracy: 0.8162\n","Training loss (for one batch) at step 30: 258.3047, Accuracy: 0.8174\n","Training loss (for one batch) at step 40: 245.9718, Accuracy: 0.8183\n","Training loss (for one batch) at step 50: 242.2543, Accuracy: 0.8190\n","Training loss (for one batch) at step 60: 248.4176, Accuracy: 0.8198\n","Training loss (for one batch) at step 70: 258.6502, Accuracy: 0.8207\n","Training loss (for one batch) at step 80: 257.2397, Accuracy: 0.8189\n","Training loss (for one batch) at step 90: 259.1409, Accuracy: 0.8169\n","Training loss (for one batch) at step 100: 265.5749, Accuracy: 0.8163\n","Training loss (for one batch) at step 110: 249.0969, Accuracy: 0.8178\n","Training loss (for one batch) at step 120: 257.0253, Accuracy: 0.8156\n","Training loss (for one batch) at step 130: 260.8539, Accuracy: 0.8166\n","Training loss (for one batch) at step 140: 254.0574, Accuracy: 0.8154\n","---- Training ----\n","Training loss: 213.4419\n","Training acc over epoch: 0.8149\n","---- Validation ----\n","Validation loss: 76.8305\n","Validation acc: 0.7230\n","Time taken: 9.74s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 240.1873, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 259.5272, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 229.3839, Accuracy: 0.8443\n","Training loss (for one batch) at step 30: 256.2858, Accuracy: 0.8342\n","Training loss (for one batch) at step 40: 231.8938, Accuracy: 0.8332\n","Training loss (for one batch) at step 50: 236.6128, Accuracy: 0.8296\n","Training loss (for one batch) at step 60: 236.4161, Accuracy: 0.8261\n","Training loss (for one batch) at step 70: 265.6651, Accuracy: 0.8246\n","Training loss (for one batch) at step 80: 234.3083, Accuracy: 0.8217\n","Training loss (for one batch) at step 90: 276.8144, Accuracy: 0.8209\n","Training loss (for one batch) at step 100: 242.2392, Accuracy: 0.8210\n","Training loss (for one batch) at step 110: 249.0187, Accuracy: 0.8234\n","Training loss (for one batch) at step 120: 268.6803, Accuracy: 0.8229\n","Training loss (for one batch) at step 130: 259.5720, Accuracy: 0.8215\n","Training loss (for one batch) at step 140: 265.2687, Accuracy: 0.8201\n","---- Training ----\n","Training loss: 237.1714\n","Training acc over epoch: 0.8178\n","---- Validation ----\n","Validation loss: 70.0988\n","Validation acc: 0.7265\n","Time taken: 9.49s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 234.2666, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 246.9106, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 256.2159, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 242.4002, Accuracy: 0.8371\n","Training loss (for one batch) at step 40: 230.1869, Accuracy: 0.8344\n","Training loss (for one batch) at step 50: 246.8077, Accuracy: 0.8327\n","Training loss (for one batch) at step 60: 248.5719, Accuracy: 0.8333\n","Training loss (for one batch) at step 70: 256.4771, Accuracy: 0.8296\n","Training loss (for one batch) at step 80: 257.8198, Accuracy: 0.8264\n","Training loss (for one batch) at step 90: 236.5115, Accuracy: 0.8247\n","Training loss (for one batch) at step 100: 238.5842, Accuracy: 0.8226\n","Training loss (for one batch) at step 110: 237.7143, Accuracy: 0.8222\n","Training loss (for one batch) at step 120: 239.3602, Accuracy: 0.8239\n","Training loss (for one batch) at step 130: 253.2077, Accuracy: 0.8227\n","Training loss (for one batch) at step 140: 262.8368, Accuracy: 0.8205\n","---- Training ----\n","Training loss: 217.1011\n","Training acc over epoch: 0.8203\n","---- Validation ----\n","Validation loss: 83.4478\n","Validation acc: 0.7308\n","Time taken: 11.21s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 244.9474, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 245.4117, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 232.6878, Accuracy: 0.8276\n","Training loss (for one batch) at step 30: 245.6552, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 251.4379, Accuracy: 0.8276\n","Training loss (for one batch) at step 50: 254.8624, Accuracy: 0.8298\n","Training loss (for one batch) at step 60: 230.3929, Accuracy: 0.8282\n","Training loss (for one batch) at step 70: 230.9916, Accuracy: 0.8294\n","Training loss (for one batch) at step 80: 261.0179, Accuracy: 0.8267\n","Training loss (for one batch) at step 90: 244.9283, Accuracy: 0.8243\n","Training loss (for one batch) at step 100: 235.9061, Accuracy: 0.8240\n","Training loss (for one batch) at step 110: 242.1841, Accuracy: 0.8246\n","Training loss (for one batch) at step 120: 253.8230, Accuracy: 0.8244\n","Training loss (for one batch) at step 130: 230.8425, Accuracy: 0.8231\n","Training loss (for one batch) at step 140: 255.6741, Accuracy: 0.8223\n","---- Training ----\n","Training loss: 222.7404\n","Training acc over epoch: 0.8229\n","---- Validation ----\n","Validation loss: 77.6406\n","Validation acc: 0.7160\n","Time taken: 40.90s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 235.3695, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 246.9484, Accuracy: 0.8164\n","Training loss (for one batch) at step 20: 234.0510, Accuracy: 0.8229\n","Training loss (for one batch) at step 30: 271.7093, Accuracy: 0.8274\n","Training loss (for one batch) at step 40: 224.9515, Accuracy: 0.8305\n","Training loss (for one batch) at step 50: 237.2552, Accuracy: 0.8339\n","Training loss (for one batch) at step 60: 253.7531, Accuracy: 0.8310\n","Training loss (for one batch) at step 70: 257.6694, Accuracy: 0.8301\n","Training loss (for one batch) at step 80: 225.9790, Accuracy: 0.8284\n","Training loss (for one batch) at step 90: 221.7338, Accuracy: 0.8292\n","Training loss (for one batch) at step 100: 236.6535, Accuracy: 0.8281\n","Training loss (for one batch) at step 110: 237.2383, Accuracy: 0.8274\n","Training loss (for one batch) at step 120: 247.4409, Accuracy: 0.8266\n","Training loss (for one batch) at step 130: 239.9785, Accuracy: 0.8250\n","Training loss (for one batch) at step 140: 248.9273, Accuracy: 0.8243\n","---- Training ----\n","Training loss: 220.5516\n","Training acc over epoch: 0.8246\n","---- Validation ----\n","Validation loss: 76.0133\n","Validation acc: 0.7063\n","Time taken: 44.87s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 247.7379, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 245.2246, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 229.4580, Accuracy: 0.8243\n","Training loss (for one batch) at step 30: 234.1063, Accuracy: 0.8200\n","Training loss (for one batch) at step 40: 252.9295, Accuracy: 0.8168\n","Training loss (for one batch) at step 50: 252.5554, Accuracy: 0.8212\n","Training loss (for one batch) at step 60: 236.8541, Accuracy: 0.8233\n","Training loss (for one batch) at step 70: 230.5878, Accuracy: 0.8228\n","Training loss (for one batch) at step 80: 248.3631, Accuracy: 0.8227\n","Training loss (for one batch) at step 90: 224.5014, Accuracy: 0.8221\n","Training loss (for one batch) at step 100: 236.2500, Accuracy: 0.8216\n","Training loss (for one batch) at step 110: 234.8505, Accuracy: 0.8244\n","Training loss (for one batch) at step 120: 224.0596, Accuracy: 0.8244\n","Training loss (for one batch) at step 130: 257.0427, Accuracy: 0.8234\n","Training loss (for one batch) at step 140: 252.2448, Accuracy: 0.8226\n","---- Training ----\n","Training loss: 208.8132\n","Training acc over epoch: 0.8226\n","---- Validation ----\n","Validation loss: 68.3137\n","Validation acc: 0.7332\n","Time taken: 13.16s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 235.9049, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 250.2157, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 234.9003, Accuracy: 0.8252\n","Training loss (for one batch) at step 30: 224.0032, Accuracy: 0.8219\n","Training loss (for one batch) at step 40: 261.6929, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 249.5603, Accuracy: 0.8312\n","Training loss (for one batch) at step 60: 243.6052, Accuracy: 0.8279\n","Training loss (for one batch) at step 70: 252.3250, Accuracy: 0.8262\n","Training loss (for one batch) at step 80: 223.3544, Accuracy: 0.8233\n","Training loss (for one batch) at step 90: 236.4557, Accuracy: 0.8213\n","Training loss (for one batch) at step 100: 245.2966, Accuracy: 0.8216\n","Training loss (for one batch) at step 110: 267.2341, Accuracy: 0.8210\n","Training loss (for one batch) at step 120: 256.1924, Accuracy: 0.8210\n","Training loss (for one batch) at step 130: 243.9004, Accuracy: 0.8190\n","Training loss (for one batch) at step 140: 226.0442, Accuracy: 0.8207\n","---- Training ----\n","Training loss: 213.9327\n","Training acc over epoch: 0.8202\n","---- Validation ----\n","Validation loss: 56.3077\n","Validation acc: 0.7106\n","Time taken: 10.18s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 219.3780, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 239.4357, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 244.6727, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 234.3810, Accuracy: 0.8303\n","Training loss (for one batch) at step 40: 223.2774, Accuracy: 0.8356\n","Training loss (for one batch) at step 50: 246.5952, Accuracy: 0.8388\n","Training loss (for one batch) at step 60: 235.0320, Accuracy: 0.8352\n","Training loss (for one batch) at step 70: 261.8803, Accuracy: 0.8341\n","Training loss (for one batch) at step 80: 225.6315, Accuracy: 0.8342\n","Training loss (for one batch) at step 90: 240.7434, Accuracy: 0.8322\n","Training loss (for one batch) at step 100: 258.1422, Accuracy: 0.8308\n","Training loss (for one batch) at step 110: 221.1968, Accuracy: 0.8310\n","Training loss (for one batch) at step 120: 237.9480, Accuracy: 0.8293\n","Training loss (for one batch) at step 130: 255.7223, Accuracy: 0.8293\n","Training loss (for one batch) at step 140: 234.2554, Accuracy: 0.8274\n","---- Training ----\n","Training loss: 208.3088\n","Training acc over epoch: 0.8283\n","---- Validation ----\n","Validation loss: 82.6219\n","Validation acc: 0.7139\n","Time taken: 9.55s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 244.2167, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 227.8242, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 221.4904, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 233.6985, Accuracy: 0.8326\n","Training loss (for one batch) at step 40: 237.6233, Accuracy: 0.8329\n","Training loss (for one batch) at step 50: 213.4700, Accuracy: 0.8337\n","Training loss (for one batch) at step 60: 246.1398, Accuracy: 0.8354\n","Training loss (for one batch) at step 70: 224.5761, Accuracy: 0.8346\n","Training loss (for one batch) at step 80: 257.4429, Accuracy: 0.8343\n","Training loss (for one batch) at step 90: 232.5710, Accuracy: 0.8301\n","Training loss (for one batch) at step 100: 233.8082, Accuracy: 0.8293\n","Training loss (for one batch) at step 110: 256.8495, Accuracy: 0.8284\n","Training loss (for one batch) at step 120: 258.6192, Accuracy: 0.8279\n","Training loss (for one batch) at step 130: 241.3607, Accuracy: 0.8292\n","Training loss (for one batch) at step 140: 233.5746, Accuracy: 0.8289\n","---- Training ----\n","Training loss: 231.1290\n","Training acc over epoch: 0.8288\n","---- Validation ----\n","Validation loss: 81.9866\n","Validation acc: 0.7093\n","Time taken: 9.54s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 230.6310, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 242.6400, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 233.3724, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 249.6623, Accuracy: 0.8290\n","Training loss (for one batch) at step 40: 235.9851, Accuracy: 0.8317\n","Training loss (for one batch) at step 50: 232.9670, Accuracy: 0.8335\n","Training loss (for one batch) at step 60: 227.9044, Accuracy: 0.8333\n","Training loss (for one batch) at step 70: 225.8050, Accuracy: 0.8303\n","Training loss (for one batch) at step 80: 233.7613, Accuracy: 0.8278\n","Training loss (for one batch) at step 90: 241.3584, Accuracy: 0.8275\n","Training loss (for one batch) at step 100: 260.7972, Accuracy: 0.8266\n","Training loss (for one batch) at step 110: 229.2756, Accuracy: 0.8283\n","Training loss (for one batch) at step 120: 235.9443, Accuracy: 0.8298\n","Training loss (for one batch) at step 130: 208.9955, Accuracy: 0.8306\n","Training loss (for one batch) at step 140: 219.9080, Accuracy: 0.8296\n","---- Training ----\n","Training loss: 215.8701\n","Training acc over epoch: 0.8293\n","---- Validation ----\n","Validation loss: 71.5641\n","Validation acc: 0.7176\n","Time taken: 9.69s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 218.7443, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 239.7801, Accuracy: 0.8409\n","Training loss (for one batch) at step 20: 229.6436, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 226.6543, Accuracy: 0.8390\n","Training loss (for one batch) at step 40: 214.9633, Accuracy: 0.8410\n","Training loss (for one batch) at step 50: 219.3358, Accuracy: 0.8424\n","Training loss (for one batch) at step 60: 216.2000, Accuracy: 0.8443\n","Training loss (for one batch) at step 70: 230.2177, Accuracy: 0.8385\n","Training loss (for one batch) at step 80: 248.7017, Accuracy: 0.8357\n","Training loss (for one batch) at step 90: 248.3117, Accuracy: 0.8335\n","Training loss (for one batch) at step 100: 217.7673, Accuracy: 0.8335\n","Training loss (for one batch) at step 110: 228.0830, Accuracy: 0.8339\n","Training loss (for one batch) at step 120: 243.9439, Accuracy: 0.8330\n","Training loss (for one batch) at step 130: 226.9312, Accuracy: 0.8324\n","Training loss (for one batch) at step 140: 253.1754, Accuracy: 0.8318\n","---- Training ----\n","Training loss: 227.4523\n","Training acc over epoch: 0.8316\n","---- Validation ----\n","Validation loss: 78.3847\n","Validation acc: 0.7225\n","Time taken: 9.59s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 220.8493, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 223.6789, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 226.2724, Accuracy: 0.8424\n","Training loss (for one batch) at step 30: 226.7975, Accuracy: 0.8355\n","Training loss (for one batch) at step 40: 233.7830, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 232.5348, Accuracy: 0.8369\n","Training loss (for one batch) at step 60: 230.6130, Accuracy: 0.8369\n","Training loss (for one batch) at step 70: 237.2115, Accuracy: 0.8346\n","Training loss (for one batch) at step 80: 228.8734, Accuracy: 0.8327\n","Training loss (for one batch) at step 90: 241.5975, Accuracy: 0.8310\n","Training loss (for one batch) at step 100: 218.0959, Accuracy: 0.8313\n","Training loss (for one batch) at step 110: 219.0130, Accuracy: 0.8331\n","Training loss (for one batch) at step 120: 238.1155, Accuracy: 0.8318\n","Training loss (for one batch) at step 130: 226.5946, Accuracy: 0.8315\n","Training loss (for one batch) at step 140: 258.4516, Accuracy: 0.8300\n","---- Training ----\n","Training loss: 202.0920\n","Training acc over epoch: 0.8288\n","---- Validation ----\n","Validation loss: 79.1211\n","Validation acc: 0.7249\n","Time taken: 9.63s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 232.9817, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 253.2494, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 228.4005, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 229.8097, Accuracy: 0.8352\n","Training loss (for one batch) at step 40: 208.9173, Accuracy: 0.8351\n","Training loss (for one batch) at step 50: 222.1250, Accuracy: 0.8359\n","Training loss (for one batch) at step 60: 238.3908, Accuracy: 0.8348\n","Training loss (for one batch) at step 70: 211.8581, Accuracy: 0.8356\n","Training loss (for one batch) at step 80: 245.3698, Accuracy: 0.8325\n","Training loss (for one batch) at step 90: 245.6047, Accuracy: 0.8320\n","Training loss (for one batch) at step 100: 232.1185, Accuracy: 0.8304\n","Training loss (for one batch) at step 110: 232.0072, Accuracy: 0.8296\n","Training loss (for one batch) at step 120: 225.2266, Accuracy: 0.8310\n","Training loss (for one batch) at step 130: 242.8485, Accuracy: 0.8300\n","Training loss (for one batch) at step 140: 238.0581, Accuracy: 0.8294\n","---- Training ----\n","Training loss: 218.3212\n","Training acc over epoch: 0.8288\n","---- Validation ----\n","Validation loss: 92.4215\n","Validation acc: 0.7117\n","Time taken: 9.83s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 219.8919, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 228.6551, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 217.4753, Accuracy: 0.8386\n","Training loss (for one batch) at step 30: 241.8304, Accuracy: 0.8316\n","Training loss (for one batch) at step 40: 223.0713, Accuracy: 0.8346\n","Training loss (for one batch) at step 50: 234.5320, Accuracy: 0.8375\n","Training loss (for one batch) at step 60: 214.8170, Accuracy: 0.8398\n","Training loss (for one batch) at step 70: 222.2683, Accuracy: 0.8387\n","Training loss (for one batch) at step 80: 216.3513, Accuracy: 0.8380\n","Training loss (for one batch) at step 90: 230.6865, Accuracy: 0.8342\n","Training loss (for one batch) at step 100: 227.7464, Accuracy: 0.8307\n","Training loss (for one batch) at step 110: 223.0265, Accuracy: 0.8311\n","Training loss (for one batch) at step 120: 226.1981, Accuracy: 0.8317\n","Training loss (for one batch) at step 130: 224.6382, Accuracy: 0.8315\n","Training loss (for one batch) at step 140: 220.7974, Accuracy: 0.8314\n","---- Training ----\n","Training loss: 211.2923\n","Training acc over epoch: 0.8308\n","---- Validation ----\n","Validation loss: 83.3380\n","Validation acc: 0.7241\n","Time taken: 9.77s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 218.7774, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 223.0770, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 214.9090, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 255.1538, Accuracy: 0.8342\n","Training loss (for one batch) at step 40: 225.4198, Accuracy: 0.8334\n","Training loss (for one batch) at step 50: 232.3734, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 210.4738, Accuracy: 0.8367\n","Training loss (for one batch) at step 70: 216.6053, Accuracy: 0.8356\n","Training loss (for one batch) at step 80: 236.8077, Accuracy: 0.8341\n","Training loss (for one batch) at step 90: 259.1871, Accuracy: 0.8325\n","Training loss (for one batch) at step 100: 215.5978, Accuracy: 0.8325\n","Training loss (for one batch) at step 110: 221.0990, Accuracy: 0.8328\n","Training loss (for one batch) at step 120: 223.6682, Accuracy: 0.8331\n","Training loss (for one batch) at step 130: 251.3186, Accuracy: 0.8320\n","Training loss (for one batch) at step 140: 216.3574, Accuracy: 0.8304\n","---- Training ----\n","Training loss: 193.0591\n","Training acc over epoch: 0.8307\n","---- Validation ----\n","Validation loss: 77.2192\n","Validation acc: 0.7206\n","Time taken: 9.57s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 225.8048, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 210.4793, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 217.9125, Accuracy: 0.8395\n","Training loss (for one batch) at step 30: 216.2503, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 224.9591, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 236.3305, Accuracy: 0.8410\n","Training loss (for one batch) at step 60: 233.0443, Accuracy: 0.8423\n","Training loss (for one batch) at step 70: 226.3054, Accuracy: 0.8401\n","Training loss (for one batch) at step 80: 200.0298, Accuracy: 0.8399\n","Training loss (for one batch) at step 90: 228.8600, Accuracy: 0.8375\n","Training loss (for one batch) at step 100: 236.6974, Accuracy: 0.8377\n","Training loss (for one batch) at step 110: 219.9674, Accuracy: 0.8376\n","Training loss (for one batch) at step 120: 233.4905, Accuracy: 0.8376\n","Training loss (for one batch) at step 130: 229.5224, Accuracy: 0.8365\n","Training loss (for one batch) at step 140: 231.0572, Accuracy: 0.8358\n","---- Training ----\n","Training loss: 231.0610\n","Training acc over epoch: 0.8358\n","---- Validation ----\n","Validation loss: 76.8167\n","Validation acc: 0.7050\n","Time taken: 9.81s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 222.6756, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 206.8035, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 217.5736, Accuracy: 0.8433\n","Training loss (for one batch) at step 30: 242.1945, Accuracy: 0.8377\n","Training loss (for one batch) at step 40: 213.5858, Accuracy: 0.8390\n","Training loss (for one batch) at step 50: 201.6639, Accuracy: 0.8416\n","Training loss (for one batch) at step 60: 215.8832, Accuracy: 0.8433\n","Training loss (for one batch) at step 70: 221.5072, Accuracy: 0.8427\n","Training loss (for one batch) at step 80: 221.5431, Accuracy: 0.8391\n","Training loss (for one batch) at step 90: 226.3882, Accuracy: 0.8374\n","Training loss (for one batch) at step 100: 234.4612, Accuracy: 0.8371\n","Training loss (for one batch) at step 110: 205.6039, Accuracy: 0.8383\n","Training loss (for one batch) at step 120: 213.1352, Accuracy: 0.8355\n","Training loss (for one batch) at step 130: 221.9426, Accuracy: 0.8345\n","Training loss (for one batch) at step 140: 237.4054, Accuracy: 0.8335\n","---- Training ----\n","Training loss: 200.0415\n","Training acc over epoch: 0.8332\n","---- Validation ----\n","Validation loss: 73.9523\n","Validation acc: 0.7168\n","Time taken: 9.60s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 227.2273, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 199.8592, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 238.0352, Accuracy: 0.8267\n","Training loss (for one batch) at step 30: 208.7123, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 222.4830, Accuracy: 0.8376\n","Training loss (for one batch) at step 50: 229.0582, Accuracy: 0.8367\n","Training loss (for one batch) at step 60: 206.6049, Accuracy: 0.8374\n","Training loss (for one batch) at step 70: 213.3353, Accuracy: 0.8339\n","Training loss (for one batch) at step 80: 242.9052, Accuracy: 0.8332\n","Training loss (for one batch) at step 90: 199.1495, Accuracy: 0.8349\n","Training loss (for one batch) at step 100: 226.2308, Accuracy: 0.8326\n","Training loss (for one batch) at step 110: 230.3159, Accuracy: 0.8343\n","Training loss (for one batch) at step 120: 234.3087, Accuracy: 0.8354\n","Training loss (for one batch) at step 130: 238.2438, Accuracy: 0.8337\n","Training loss (for one batch) at step 140: 218.3726, Accuracy: 0.8332\n","---- Training ----\n","Training loss: 206.7480\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 82.4739\n","Validation acc: 0.7123\n","Time taken: 9.64s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 227.2998, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 207.2437, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 234.3904, Accuracy: 0.8438\n","Training loss (for one batch) at step 30: 208.8576, Accuracy: 0.8429\n","Training loss (for one batch) at step 40: 214.4279, Accuracy: 0.8429\n","Training loss (for one batch) at step 50: 217.6417, Accuracy: 0.8429\n","Training loss (for one batch) at step 60: 209.7145, Accuracy: 0.8443\n","Training loss (for one batch) at step 70: 216.6323, Accuracy: 0.8428\n","Training loss (for one batch) at step 80: 214.6248, Accuracy: 0.8430\n","Training loss (for one batch) at step 90: 237.5531, Accuracy: 0.8435\n","Training loss (for one batch) at step 100: 208.2892, Accuracy: 0.8410\n","Training loss (for one batch) at step 110: 212.3934, Accuracy: 0.8405\n","Training loss (for one batch) at step 120: 213.7562, Accuracy: 0.8399\n","Training loss (for one batch) at step 130: 231.2911, Accuracy: 0.8402\n","Training loss (for one batch) at step 140: 213.3674, Accuracy: 0.8387\n","---- Training ----\n","Training loss: 204.2462\n","Training acc over epoch: 0.8383\n","---- Validation ----\n","Validation loss: 83.9572\n","Validation acc: 0.7179\n","Time taken: 9.62s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 215.8687, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 206.1679, Accuracy: 0.8545\n","Training loss (for one batch) at step 20: 223.4741, Accuracy: 0.8410\n","Training loss (for one batch) at step 30: 218.1333, Accuracy: 0.8361\n","Training loss (for one batch) at step 40: 218.2756, Accuracy: 0.8446\n","Training loss (for one batch) at step 50: 207.5849, Accuracy: 0.8459\n","Training loss (for one batch) at step 60: 215.5799, Accuracy: 0.8479\n","Training loss (for one batch) at step 70: 216.3109, Accuracy: 0.8448\n","Training loss (for one batch) at step 80: 201.5624, Accuracy: 0.8422\n","Training loss (for one batch) at step 90: 223.1222, Accuracy: 0.8412\n","Training loss (for one batch) at step 100: 216.0837, Accuracy: 0.8407\n","Training loss (for one batch) at step 110: 217.2916, Accuracy: 0.8406\n","Training loss (for one batch) at step 120: 215.3176, Accuracy: 0.8403\n","Training loss (for one batch) at step 130: 206.8334, Accuracy: 0.8396\n","Training loss (for one batch) at step 140: 222.4428, Accuracy: 0.8387\n","---- Training ----\n","Training loss: 180.2562\n","Training acc over epoch: 0.8386\n","---- Validation ----\n","Validation loss: 80.9475\n","Validation acc: 0.7123\n","Time taken: 9.66s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 209.5163, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 208.1714, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 211.0677, Accuracy: 0.8529\n","Training loss (for one batch) at step 30: 224.6927, Accuracy: 0.8471\n","Training loss (for one batch) at step 40: 220.4998, Accuracy: 0.8490\n","Training loss (for one batch) at step 50: 204.5905, Accuracy: 0.8494\n","Training loss (for one batch) at step 60: 229.6257, Accuracy: 0.8467\n","Training loss (for one batch) at step 70: 221.1817, Accuracy: 0.8468\n","Training loss (for one batch) at step 80: 234.8339, Accuracy: 0.8437\n","Training loss (for one batch) at step 90: 244.1282, Accuracy: 0.8420\n","Training loss (for one batch) at step 100: 205.1720, Accuracy: 0.8429\n","Training loss (for one batch) at step 110: 194.1258, Accuracy: 0.8410\n","Training loss (for one batch) at step 120: 226.3641, Accuracy: 0.8400\n","Training loss (for one batch) at step 130: 236.3472, Accuracy: 0.8390\n","Training loss (for one batch) at step 140: 229.2845, Accuracy: 0.8402\n","---- Training ----\n","Training loss: 199.9718\n","Training acc over epoch: 0.8400\n","---- Validation ----\n","Validation loss: 97.3775\n","Validation acc: 0.7063\n","Time taken: 9.62s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 200.9306, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 226.3208, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 228.0918, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 214.4343, Accuracy: 0.8381\n","Training loss (for one batch) at step 40: 204.1142, Accuracy: 0.8390\n","Training loss (for one batch) at step 50: 216.8195, Accuracy: 0.8384\n","Training loss (for one batch) at step 60: 188.5444, Accuracy: 0.8390\n","Training loss (for one batch) at step 70: 199.5902, Accuracy: 0.8377\n","Training loss (for one batch) at step 80: 229.2637, Accuracy: 0.8385\n","Training loss (for one batch) at step 90: 206.7613, Accuracy: 0.8402\n","Training loss (for one batch) at step 100: 205.0843, Accuracy: 0.8405\n","Training loss (for one batch) at step 110: 205.5422, Accuracy: 0.8388\n","Training loss (for one batch) at step 120: 228.2941, Accuracy: 0.8383\n","Training loss (for one batch) at step 130: 240.8025, Accuracy: 0.8378\n","Training loss (for one batch) at step 140: 213.6078, Accuracy: 0.8387\n","---- Training ----\n","Training loss: 177.6363\n","Training acc over epoch: 0.8383\n","---- Validation ----\n","Validation loss: 89.8141\n","Validation acc: 0.7058\n","Time taken: 11.62s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 222.6773, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 227.4706, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 210.6111, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 195.9910, Accuracy: 0.8497\n","Training loss (for one batch) at step 40: 219.4763, Accuracy: 0.8495\n","Training loss (for one batch) at step 50: 201.2770, Accuracy: 0.8512\n","Training loss (for one batch) at step 60: 205.5363, Accuracy: 0.8497\n","Training loss (for one batch) at step 70: 205.8807, Accuracy: 0.8504\n","Training loss (for one batch) at step 80: 212.2473, Accuracy: 0.8459\n","Training loss (for one batch) at step 90: 223.6670, Accuracy: 0.8441\n","Training loss (for one batch) at step 100: 200.8794, Accuracy: 0.8433\n","Training loss (for one batch) at step 110: 220.6843, Accuracy: 0.8423\n","Training loss (for one batch) at step 120: 199.8413, Accuracy: 0.8430\n","Training loss (for one batch) at step 130: 206.0350, Accuracy: 0.8423\n","Training loss (for one batch) at step 140: 219.5604, Accuracy: 0.8409\n","---- Training ----\n","Training loss: 192.0632\n","Training acc over epoch: 0.8411\n","---- Validation ----\n","Validation loss: 72.6851\n","Validation acc: 0.7063\n","Time taken: 45.04s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 214.0029, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 201.8076, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 207.5621, Accuracy: 0.8490\n","Training loss (for one batch) at step 30: 200.5233, Accuracy: 0.8474\n","Training loss (for one batch) at step 40: 208.3105, Accuracy: 0.8420\n","Training loss (for one batch) at step 50: 196.7835, Accuracy: 0.8422\n","Training loss (for one batch) at step 60: 207.2898, Accuracy: 0.8434\n","Training loss (for one batch) at step 70: 240.8251, Accuracy: 0.8432\n","Training loss (for one batch) at step 80: 199.7949, Accuracy: 0.8423\n","Training loss (for one batch) at step 90: 232.1943, Accuracy: 0.8415\n","Training loss (for one batch) at step 100: 205.3019, Accuracy: 0.8401\n","Training loss (for one batch) at step 110: 224.3130, Accuracy: 0.8401\n","Training loss (for one batch) at step 120: 206.5830, Accuracy: 0.8412\n","Training loss (for one batch) at step 130: 207.0338, Accuracy: 0.8393\n","Training loss (for one batch) at step 140: 209.5956, Accuracy: 0.8385\n","---- Training ----\n","Training loss: 191.1318\n","Training acc over epoch: 0.8389\n","---- Validation ----\n","Validation loss: 75.7542\n","Validation acc: 0.7214\n","Time taken: 45.40s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7416\n","Validation AUC: 0.7391\n","Validation Balanced_ACC: 0.4842\n","Validation MI: 0.1399\n","Validation Normalized MI: 0.2092\n","Validation Adjusted MI: 0.2092\n","Validation aUc_Sklearn: 0.8249\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 462.4945, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 481.6254, Accuracy: 0.5355\n","Training loss (for one batch) at step 20: 436.0072, Accuracy: 0.5414\n","Training loss (for one batch) at step 30: 472.8438, Accuracy: 0.5368\n","Training loss (for one batch) at step 40: 433.4752, Accuracy: 0.5434\n","Training loss (for one batch) at step 50: 411.9770, Accuracy: 0.5512\n","Training loss (for one batch) at step 60: 441.7998, Accuracy: 0.5564\n","Training loss (for one batch) at step 70: 438.5501, Accuracy: 0.5573\n","Training loss (for one batch) at step 80: 422.8438, Accuracy: 0.5531\n","Training loss (for one batch) at step 90: 447.9939, Accuracy: 0.5555\n","Training loss (for one batch) at step 100: 461.6626, Accuracy: 0.5605\n","Training loss (for one batch) at step 110: 440.8398, Accuracy: 0.5608\n","Training loss (for one batch) at step 120: 406.2740, Accuracy: 0.5661\n","Training loss (for one batch) at step 130: 404.3879, Accuracy: 0.5695\n","Training loss (for one batch) at step 140: 414.4918, Accuracy: 0.5716\n","---- Training ----\n","Training loss: 364.7257\n","Training acc over epoch: 0.5723\n","---- Validation ----\n","Validation loss: 115.5089\n","Validation acc: 0.5134\n","Time taken: 81.38s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 405.4017, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 415.0469, Accuracy: 0.5955\n","Training loss (for one batch) at step 20: 403.0074, Accuracy: 0.5976\n","Training loss (for one batch) at step 30: 406.2607, Accuracy: 0.6074\n","Training loss (for one batch) at step 40: 394.2004, Accuracy: 0.6098\n","Training loss (for one batch) at step 50: 394.2165, Accuracy: 0.6104\n","Training loss (for one batch) at step 60: 359.2870, Accuracy: 0.6092\n","Training loss (for one batch) at step 70: 401.5722, Accuracy: 0.6101\n","Training loss (for one batch) at step 80: 410.9602, Accuracy: 0.6121\n","Training loss (for one batch) at step 90: 371.4424, Accuracy: 0.6113\n","Training loss (for one batch) at step 100: 392.1620, Accuracy: 0.6106\n","Training loss (for one batch) at step 110: 405.6764, Accuracy: 0.6141\n","Training loss (for one batch) at step 120: 409.7331, Accuracy: 0.6160\n","Training loss (for one batch) at step 130: 391.8154, Accuracy: 0.6163\n","Training loss (for one batch) at step 140: 354.0526, Accuracy: 0.6171\n","---- Training ----\n","Training loss: 326.1150\n","Training acc over epoch: 0.6184\n","---- Validation ----\n","Validation loss: 99.2873\n","Validation acc: 0.5156\n","Time taken: 42.21s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 351.1504, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 359.7747, Accuracy: 0.6618\n","Training loss (for one batch) at step 20: 372.9870, Accuracy: 0.6452\n","Training loss (for one batch) at step 30: 382.2603, Accuracy: 0.6445\n","Training loss (for one batch) at step 40: 370.2717, Accuracy: 0.6393\n","Training loss (for one batch) at step 50: 408.9975, Accuracy: 0.6373\n","Training loss (for one batch) at step 60: 364.3759, Accuracy: 0.6387\n","Training loss (for one batch) at step 70: 343.9471, Accuracy: 0.6358\n","Training loss (for one batch) at step 80: 346.7945, Accuracy: 0.6333\n","Training loss (for one batch) at step 90: 377.0862, Accuracy: 0.6366\n","Training loss (for one batch) at step 100: 379.5439, Accuracy: 0.6368\n","Training loss (for one batch) at step 110: 333.3613, Accuracy: 0.6363\n","Training loss (for one batch) at step 120: 351.4202, Accuracy: 0.6379\n","Training loss (for one batch) at step 130: 372.4748, Accuracy: 0.6392\n","Training loss (for one batch) at step 140: 363.9186, Accuracy: 0.6392\n","---- Training ----\n","Training loss: 306.4356\n","Training acc over epoch: 0.6404\n","---- Validation ----\n","Validation loss: 86.4792\n","Validation acc: 0.6478\n","Time taken: 75.23s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 316.3073, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 329.0652, Accuracy: 0.6682\n","Training loss (for one batch) at step 20: 397.9362, Accuracy: 0.6771\n","Training loss (for one batch) at step 30: 354.6608, Accuracy: 0.6639\n","Training loss (for one batch) at step 40: 368.3846, Accuracy: 0.6583\n","Training loss (for one batch) at step 50: 329.7556, Accuracy: 0.6643\n","Training loss (for one batch) at step 60: 363.1759, Accuracy: 0.6659\n","Training loss (for one batch) at step 70: 348.4765, Accuracy: 0.6635\n","Training loss (for one batch) at step 80: 367.6892, Accuracy: 0.6605\n","Training loss (for one batch) at step 90: 369.4305, Accuracy: 0.6607\n","Training loss (for one batch) at step 100: 333.4050, Accuracy: 0.6645\n","Training loss (for one batch) at step 110: 342.3410, Accuracy: 0.6672\n","Training loss (for one batch) at step 120: 354.5013, Accuracy: 0.6679\n","Training loss (for one batch) at step 130: 344.5506, Accuracy: 0.6689\n","Training loss (for one batch) at step 140: 339.1610, Accuracy: 0.6691\n","---- Training ----\n","Training loss: 349.2352\n","Training acc over epoch: 0.6687\n","---- Validation ----\n","Validation loss: 68.8476\n","Validation acc: 0.7225\n","Time taken: 41.31s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 340.0846, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 350.6988, Accuracy: 0.6555\n","Training loss (for one batch) at step 20: 325.1117, Accuracy: 0.6657\n","Training loss (for one batch) at step 30: 341.2325, Accuracy: 0.6684\n","Training loss (for one batch) at step 40: 327.5476, Accuracy: 0.6751\n","Training loss (for one batch) at step 50: 328.1347, Accuracy: 0.6800\n","Training loss (for one batch) at step 60: 375.2064, Accuracy: 0.6816\n","Training loss (for one batch) at step 70: 367.6034, Accuracy: 0.6811\n","Training loss (for one batch) at step 80: 330.0310, Accuracy: 0.6848\n","Training loss (for one batch) at step 90: 333.6727, Accuracy: 0.6863\n","Training loss (for one batch) at step 100: 329.6299, Accuracy: 0.6853\n","Training loss (for one batch) at step 110: 334.2189, Accuracy: 0.6860\n","Training loss (for one batch) at step 120: 345.4995, Accuracy: 0.6861\n","Training loss (for one batch) at step 130: 364.2303, Accuracy: 0.6851\n","Training loss (for one batch) at step 140: 347.7419, Accuracy: 0.6855\n","---- Training ----\n","Training loss: 290.5633\n","Training acc over epoch: 0.6855\n","---- Validation ----\n","Validation loss: 76.0565\n","Validation acc: 0.7123\n","Time taken: 72.74s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 334.4956, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 330.0557, Accuracy: 0.7155\n","Training loss (for one batch) at step 20: 330.7626, Accuracy: 0.6957\n","Training loss (for one batch) at step 30: 342.0861, Accuracy: 0.7006\n","Training loss (for one batch) at step 40: 318.6769, Accuracy: 0.6978\n","Training loss (for one batch) at step 50: 339.4202, Accuracy: 0.6961\n","Training loss (for one batch) at step 60: 317.2092, Accuracy: 0.6997\n","Training loss (for one batch) at step 70: 340.0663, Accuracy: 0.7014\n","Training loss (for one batch) at step 80: 323.6572, Accuracy: 0.6990\n","Training loss (for one batch) at step 90: 336.8378, Accuracy: 0.7002\n","Training loss (for one batch) at step 100: 317.6731, Accuracy: 0.6995\n","Training loss (for one batch) at step 110: 319.2567, Accuracy: 0.6999\n","Training loss (for one batch) at step 120: 343.1408, Accuracy: 0.7014\n","Training loss (for one batch) at step 130: 299.9915, Accuracy: 0.7024\n","Training loss (for one batch) at step 140: 328.7273, Accuracy: 0.7038\n","---- Training ----\n","Training loss: 271.5647\n","Training acc over epoch: 0.7044\n","---- Validation ----\n","Validation loss: 66.6843\n","Validation acc: 0.7098\n","Time taken: 46.24s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 320.1594, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 330.8873, Accuracy: 0.7145\n","Training loss (for one batch) at step 20: 315.7589, Accuracy: 0.7033\n","Training loss (for one batch) at step 30: 335.0496, Accuracy: 0.7181\n","Training loss (for one batch) at step 40: 317.1343, Accuracy: 0.7134\n","Training loss (for one batch) at step 50: 322.8420, Accuracy: 0.7124\n","Training loss (for one batch) at step 60: 309.3087, Accuracy: 0.7116\n","Training loss (for one batch) at step 70: 339.3080, Accuracy: 0.7093\n","Training loss (for one batch) at step 80: 332.5640, Accuracy: 0.7114\n","Training loss (for one batch) at step 90: 333.9123, Accuracy: 0.7121\n","Training loss (for one batch) at step 100: 312.0687, Accuracy: 0.7135\n","Training loss (for one batch) at step 110: 326.7243, Accuracy: 0.7135\n","Training loss (for one batch) at step 120: 324.5206, Accuracy: 0.7136\n","Training loss (for one batch) at step 130: 299.7973, Accuracy: 0.7136\n","Training loss (for one batch) at step 140: 340.1161, Accuracy: 0.7155\n","---- Training ----\n","Training loss: 314.8104\n","Training acc over epoch: 0.7153\n","---- Validation ----\n","Validation loss: 68.3427\n","Validation acc: 0.7174\n","Time taken: 73.61s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 314.0048, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 306.2929, Accuracy: 0.7255\n","Training loss (for one batch) at step 20: 318.2923, Accuracy: 0.7129\n","Training loss (for one batch) at step 30: 330.7050, Accuracy: 0.7184\n","Training loss (for one batch) at step 40: 301.1106, Accuracy: 0.7285\n","Training loss (for one batch) at step 50: 328.3098, Accuracy: 0.7280\n","Training loss (for one batch) at step 60: 304.2132, Accuracy: 0.7311\n","Training loss (for one batch) at step 70: 333.9699, Accuracy: 0.7299\n","Training loss (for one batch) at step 80: 316.6306, Accuracy: 0.7286\n","Training loss (for one batch) at step 90: 310.9717, Accuracy: 0.7276\n","Training loss (for one batch) at step 100: 339.8084, Accuracy: 0.7277\n","Training loss (for one batch) at step 110: 302.9724, Accuracy: 0.7289\n","Training loss (for one batch) at step 120: 327.3542, Accuracy: 0.7297\n","Training loss (for one batch) at step 130: 315.7186, Accuracy: 0.7301\n","Training loss (for one batch) at step 140: 315.9429, Accuracy: 0.7287\n","---- Training ----\n","Training loss: 294.3959\n","Training acc over epoch: 0.7274\n","---- Validation ----\n","Validation loss: 72.1802\n","Validation acc: 0.7434\n","Time taken: 47.77s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 310.8565, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 293.7169, Accuracy: 0.7445\n","Training loss (for one batch) at step 20: 304.9658, Accuracy: 0.7348\n","Training loss (for one batch) at step 30: 310.4268, Accuracy: 0.7381\n","Training loss (for one batch) at step 40: 304.4953, Accuracy: 0.7429\n","Training loss (for one batch) at step 50: 309.0963, Accuracy: 0.7418\n","Training loss (for one batch) at step 60: 330.1755, Accuracy: 0.7451\n","Training loss (for one batch) at step 70: 307.6349, Accuracy: 0.7444\n","Training loss (for one batch) at step 80: 299.4986, Accuracy: 0.7435\n","Training loss (for one batch) at step 90: 307.6444, Accuracy: 0.7422\n","Training loss (for one batch) at step 100: 297.8293, Accuracy: 0.7414\n","Training loss (for one batch) at step 110: 294.5128, Accuracy: 0.7423\n","Training loss (for one batch) at step 120: 312.2430, Accuracy: 0.7438\n","Training loss (for one batch) at step 130: 304.7820, Accuracy: 0.7437\n","Training loss (for one batch) at step 140: 334.6964, Accuracy: 0.7438\n","---- Training ----\n","Training loss: 264.5877\n","Training acc over epoch: 0.7433\n","---- Validation ----\n","Validation loss: 61.4669\n","Validation acc: 0.7211\n","Time taken: 76.05s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 287.3747, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 298.2817, Accuracy: 0.7545\n","Training loss (for one batch) at step 20: 311.1218, Accuracy: 0.7495\n","Training loss (for one batch) at step 30: 317.3705, Accuracy: 0.7506\n","Training loss (for one batch) at step 40: 314.1895, Accuracy: 0.7490\n","Training loss (for one batch) at step 50: 298.9588, Accuracy: 0.7539\n","Training loss (for one batch) at step 60: 312.2599, Accuracy: 0.7510\n","Training loss (for one batch) at step 70: 302.9776, Accuracy: 0.7494\n","Training loss (for one batch) at step 80: 324.8993, Accuracy: 0.7510\n","Training loss (for one batch) at step 90: 306.8815, Accuracy: 0.7519\n","Training loss (for one batch) at step 100: 325.1688, Accuracy: 0.7510\n","Training loss (for one batch) at step 110: 303.2360, Accuracy: 0.7520\n","Training loss (for one batch) at step 120: 299.2087, Accuracy: 0.7532\n","Training loss (for one batch) at step 130: 301.7130, Accuracy: 0.7541\n","Training loss (for one batch) at step 140: 312.9973, Accuracy: 0.7540\n","---- Training ----\n","Training loss: 279.1200\n","Training acc over epoch: 0.7531\n","---- Validation ----\n","Validation loss: 68.8446\n","Validation acc: 0.7281\n","Time taken: 50.59s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 286.3283, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 299.8705, Accuracy: 0.7564\n","Training loss (for one batch) at step 20: 313.8468, Accuracy: 0.7624\n","Training loss (for one batch) at step 30: 284.4884, Accuracy: 0.7665\n","Training loss (for one batch) at step 40: 296.6488, Accuracy: 0.7683\n","Training loss (for one batch) at step 50: 303.2616, Accuracy: 0.7676\n","Training loss (for one batch) at step 60: 316.0962, Accuracy: 0.7692\n","Training loss (for one batch) at step 70: 305.5449, Accuracy: 0.7672\n","Training loss (for one batch) at step 80: 302.6543, Accuracy: 0.7649\n","Training loss (for one batch) at step 90: 308.8016, Accuracy: 0.7613\n","Training loss (for one batch) at step 100: 283.7222, Accuracy: 0.7621\n","Training loss (for one batch) at step 110: 300.6004, Accuracy: 0.7631\n","Training loss (for one batch) at step 120: 290.9043, Accuracy: 0.7628\n","Training loss (for one batch) at step 130: 283.5622, Accuracy: 0.7631\n","Training loss (for one batch) at step 140: 297.4100, Accuracy: 0.7632\n","---- Training ----\n","Training loss: 265.7136\n","Training acc over epoch: 0.7618\n","---- Validation ----\n","Validation loss: 74.1557\n","Validation acc: 0.7423\n","Time taken: 75.16s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 294.4209, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 289.8373, Accuracy: 0.7936\n","Training loss (for one batch) at step 20: 311.1196, Accuracy: 0.7767\n","Training loss (for one batch) at step 30: 328.1051, Accuracy: 0.7774\n","Training loss (for one batch) at step 40: 297.8694, Accuracy: 0.7749\n","Training loss (for one batch) at step 50: 278.7606, Accuracy: 0.7747\n","Training loss (for one batch) at step 60: 288.7660, Accuracy: 0.7777\n","Training loss (for one batch) at step 70: 297.8023, Accuracy: 0.7756\n","Training loss (for one batch) at step 80: 310.7255, Accuracy: 0.7741\n","Training loss (for one batch) at step 90: 312.9312, Accuracy: 0.7745\n","Training loss (for one batch) at step 100: 296.7748, Accuracy: 0.7733\n","Training loss (for one batch) at step 110: 299.2525, Accuracy: 0.7727\n","Training loss (for one batch) at step 120: 279.5258, Accuracy: 0.7736\n","Training loss (for one batch) at step 130: 287.1721, Accuracy: 0.7735\n","Training loss (for one batch) at step 140: 290.9178, Accuracy: 0.7726\n","---- Training ----\n","Training loss: 263.4150\n","Training acc over epoch: 0.7727\n","---- Validation ----\n","Validation loss: 73.2550\n","Validation acc: 0.7391\n","Time taken: 48.23s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 303.9907, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 293.8959, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 295.5364, Accuracy: 0.7952\n","Training loss (for one batch) at step 30: 292.0740, Accuracy: 0.7861\n","Training loss (for one batch) at step 40: 305.4835, Accuracy: 0.7810\n","Training loss (for one batch) at step 50: 282.4120, Accuracy: 0.7861\n","Training loss (for one batch) at step 60: 287.4642, Accuracy: 0.7893\n","Training loss (for one batch) at step 70: 288.0137, Accuracy: 0.7873\n","Training loss (for one batch) at step 80: 290.3631, Accuracy: 0.7832\n","Training loss (for one batch) at step 90: 310.0232, Accuracy: 0.7822\n","Training loss (for one batch) at step 100: 285.4058, Accuracy: 0.7813\n","Training loss (for one batch) at step 110: 295.1399, Accuracy: 0.7795\n","Training loss (for one batch) at step 120: 297.2738, Accuracy: 0.7804\n","Training loss (for one batch) at step 130: 302.7381, Accuracy: 0.7793\n","Training loss (for one batch) at step 140: 293.5962, Accuracy: 0.7794\n","---- Training ----\n","Training loss: 265.7573\n","Training acc over epoch: 0.7800\n","---- Validation ----\n","Validation loss: 72.0216\n","Validation acc: 0.7466\n","Time taken: 72.96s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 284.3481, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 288.7666, Accuracy: 0.7891\n","Training loss (for one batch) at step 20: 291.1651, Accuracy: 0.7871\n","Training loss (for one batch) at step 30: 277.1967, Accuracy: 0.7942\n","Training loss (for one batch) at step 40: 283.4806, Accuracy: 0.7912\n","Training loss (for one batch) at step 50: 298.0894, Accuracy: 0.7914\n","Training loss (for one batch) at step 60: 296.5533, Accuracy: 0.7936\n","Training loss (for one batch) at step 70: 275.7156, Accuracy: 0.7941\n","Training loss (for one batch) at step 80: 292.8945, Accuracy: 0.7894\n","Training loss (for one batch) at step 90: 284.6855, Accuracy: 0.7880\n","Training loss (for one batch) at step 100: 302.8197, Accuracy: 0.7846\n","Training loss (for one batch) at step 110: 293.3873, Accuracy: 0.7854\n","Training loss (for one batch) at step 120: 297.0097, Accuracy: 0.7845\n","Training loss (for one batch) at step 130: 294.6768, Accuracy: 0.7844\n","Training loss (for one batch) at step 140: 278.7377, Accuracy: 0.7830\n","---- Training ----\n","Training loss: 261.7491\n","Training acc over epoch: 0.7841\n","---- Validation ----\n","Validation loss: 68.2820\n","Validation acc: 0.7474\n","Time taken: 48.72s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 292.1087, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 304.4556, Accuracy: 0.7773\n","Training loss (for one batch) at step 20: 274.2166, Accuracy: 0.7771\n","Training loss (for one batch) at step 30: 283.0068, Accuracy: 0.7871\n","Training loss (for one batch) at step 40: 279.3158, Accuracy: 0.7883\n","Training loss (for one batch) at step 50: 280.7079, Accuracy: 0.7904\n","Training loss (for one batch) at step 60: 274.6526, Accuracy: 0.7923\n","Training loss (for one batch) at step 70: 297.0395, Accuracy: 0.7923\n","Training loss (for one batch) at step 80: 281.8358, Accuracy: 0.7870\n","Training loss (for one batch) at step 90: 292.2492, Accuracy: 0.7860\n","Training loss (for one batch) at step 100: 285.1976, Accuracy: 0.7859\n","Training loss (for one batch) at step 110: 287.4148, Accuracy: 0.7865\n","Training loss (for one batch) at step 120: 298.8933, Accuracy: 0.7858\n","Training loss (for one batch) at step 130: 278.1132, Accuracy: 0.7860\n","Training loss (for one batch) at step 140: 286.4241, Accuracy: 0.7856\n","---- Training ----\n","Training loss: 247.5695\n","Training acc over epoch: 0.7857\n","---- Validation ----\n","Validation loss: 63.6154\n","Validation acc: 0.7407\n","Time taken: 71.20s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 284.2998, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 261.7900, Accuracy: 0.7927\n","Training loss (for one batch) at step 20: 280.9203, Accuracy: 0.8043\n","Training loss (for one batch) at step 30: 273.1909, Accuracy: 0.8023\n","Training loss (for one batch) at step 40: 293.9917, Accuracy: 0.8005\n","Training loss (for one batch) at step 50: 277.6827, Accuracy: 0.8020\n","Training loss (for one batch) at step 60: 278.8696, Accuracy: 0.8003\n","Training loss (for one batch) at step 70: 269.2966, Accuracy: 0.7982\n","Training loss (for one batch) at step 80: 265.9207, Accuracy: 0.7998\n","Training loss (for one batch) at step 90: 286.8654, Accuracy: 0.7974\n","Training loss (for one batch) at step 100: 266.5216, Accuracy: 0.7948\n","Training loss (for one batch) at step 110: 268.6319, Accuracy: 0.7941\n","Training loss (for one batch) at step 120: 264.7807, Accuracy: 0.7942\n","Training loss (for one batch) at step 130: 261.4902, Accuracy: 0.7940\n","Training loss (for one batch) at step 140: 279.0629, Accuracy: 0.7915\n","---- Training ----\n","Training loss: 246.4611\n","Training acc over epoch: 0.7927\n","---- Validation ----\n","Validation loss: 59.2873\n","Validation acc: 0.7512\n","Time taken: 47.58s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 270.9504, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 278.6192, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 260.3029, Accuracy: 0.8095\n","Training loss (for one batch) at step 30: 264.5818, Accuracy: 0.8016\n","Training loss (for one batch) at step 40: 269.8613, Accuracy: 0.8061\n","Training loss (for one batch) at step 50: 293.1936, Accuracy: 0.8076\n","Training loss (for one batch) at step 60: 286.4384, Accuracy: 0.8084\n","Training loss (for one batch) at step 70: 256.3606, Accuracy: 0.8082\n","Training loss (for one batch) at step 80: 305.2526, Accuracy: 0.8033\n","Training loss (for one batch) at step 90: 290.1290, Accuracy: 0.8031\n","Training loss (for one batch) at step 100: 283.7592, Accuracy: 0.8021\n","Training loss (for one batch) at step 110: 274.7346, Accuracy: 0.8016\n","Training loss (for one batch) at step 120: 269.0453, Accuracy: 0.8016\n","Training loss (for one batch) at step 130: 283.1921, Accuracy: 0.8020\n","Training loss (for one batch) at step 140: 278.8521, Accuracy: 0.8013\n","---- Training ----\n","Training loss: 255.6921\n","Training acc over epoch: 0.8019\n","---- Validation ----\n","Validation loss: 66.1974\n","Validation acc: 0.7423\n","Time taken: 70.29s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 269.1211, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 273.1809, Accuracy: 0.8145\n","Training loss (for one batch) at step 20: 276.4555, Accuracy: 0.8071\n","Training loss (for one batch) at step 30: 279.8569, Accuracy: 0.8068\n","Training loss (for one batch) at step 40: 263.2839, Accuracy: 0.8080\n","Training loss (for one batch) at step 50: 263.5492, Accuracy: 0.8033\n","Training loss (for one batch) at step 60: 277.9813, Accuracy: 0.8067\n","Training loss (for one batch) at step 70: 272.4186, Accuracy: 0.8072\n","Training loss (for one batch) at step 80: 287.8450, Accuracy: 0.8079\n","Training loss (for one batch) at step 90: 277.7690, Accuracy: 0.8067\n","Training loss (for one batch) at step 100: 275.8005, Accuracy: 0.8050\n","Training loss (for one batch) at step 110: 265.0179, Accuracy: 0.8051\n","Training loss (for one batch) at step 120: 279.6172, Accuracy: 0.8073\n","Training loss (for one batch) at step 130: 263.2620, Accuracy: 0.8050\n","Training loss (for one batch) at step 140: 284.9210, Accuracy: 0.8040\n","---- Training ----\n","Training loss: 217.6964\n","Training acc over epoch: 0.8046\n","---- Validation ----\n","Validation loss: 83.0035\n","Validation acc: 0.7606\n","Time taken: 48.26s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 278.6023, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 258.4124, Accuracy: 0.8082\n","Training loss (for one batch) at step 20: 280.3420, Accuracy: 0.8195\n","Training loss (for one batch) at step 30: 259.1935, Accuracy: 0.8126\n","Training loss (for one batch) at step 40: 270.9853, Accuracy: 0.8115\n","Training loss (for one batch) at step 50: 261.8784, Accuracy: 0.8118\n","Training loss (for one batch) at step 60: 278.9285, Accuracy: 0.8167\n","Training loss (for one batch) at step 70: 284.1260, Accuracy: 0.8169\n","Training loss (for one batch) at step 80: 273.2464, Accuracy: 0.8119\n","Training loss (for one batch) at step 90: 275.1462, Accuracy: 0.8122\n","Training loss (for one batch) at step 100: 304.0707, Accuracy: 0.8111\n","Training loss (for one batch) at step 110: 274.3969, Accuracy: 0.8093\n","Training loss (for one batch) at step 120: 257.3253, Accuracy: 0.8097\n","Training loss (for one batch) at step 130: 257.0511, Accuracy: 0.8102\n","Training loss (for one batch) at step 140: 290.6767, Accuracy: 0.8091\n","---- Training ----\n","Training loss: 231.9300\n","Training acc over epoch: 0.8091\n","---- Validation ----\n","Validation loss: 65.0506\n","Validation acc: 0.7246\n","Time taken: 69.21s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 274.7234, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 272.6221, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 258.1388, Accuracy: 0.8014\n","Training loss (for one batch) at step 30: 264.5694, Accuracy: 0.8048\n","Training loss (for one batch) at step 40: 256.8817, Accuracy: 0.8090\n","Training loss (for one batch) at step 50: 283.4989, Accuracy: 0.8145\n","Training loss (for one batch) at step 60: 248.0944, Accuracy: 0.8149\n","Training loss (for one batch) at step 70: 292.2782, Accuracy: 0.8121\n","Training loss (for one batch) at step 80: 260.2818, Accuracy: 0.8100\n","Training loss (for one batch) at step 90: 276.4194, Accuracy: 0.8101\n","Training loss (for one batch) at step 100: 264.2451, Accuracy: 0.8096\n","Training loss (for one batch) at step 110: 259.6966, Accuracy: 0.8110\n","Training loss (for one batch) at step 120: 261.0137, Accuracy: 0.8119\n","Training loss (for one batch) at step 130: 271.9887, Accuracy: 0.8094\n","Training loss (for one batch) at step 140: 262.2770, Accuracy: 0.8097\n","---- Training ----\n","Training loss: 243.1116\n","Training acc over epoch: 0.8100\n","---- Validation ----\n","Validation loss: 72.0539\n","Validation acc: 0.7499\n","Time taken: 49.18s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 276.8091, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 233.3608, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 275.2937, Accuracy: 0.8200\n","Training loss (for one batch) at step 30: 275.8474, Accuracy: 0.8210\n","Training loss (for one batch) at step 40: 262.0216, Accuracy: 0.8246\n","Training loss (for one batch) at step 50: 249.8707, Accuracy: 0.8239\n","Training loss (for one batch) at step 60: 251.1090, Accuracy: 0.8216\n","Training loss (for one batch) at step 70: 272.6890, Accuracy: 0.8193\n","Training loss (for one batch) at step 80: 258.3679, Accuracy: 0.8151\n","Training loss (for one batch) at step 90: 272.8467, Accuracy: 0.8131\n","Training loss (for one batch) at step 100: 266.4882, Accuracy: 0.8115\n","Training loss (for one batch) at step 110: 255.7374, Accuracy: 0.8134\n","Training loss (for one batch) at step 120: 259.4840, Accuracy: 0.8129\n","Training loss (for one batch) at step 130: 249.7050, Accuracy: 0.8135\n","Training loss (for one batch) at step 140: 253.0890, Accuracy: 0.8135\n","---- Training ----\n","Training loss: 247.9153\n","Training acc over epoch: 0.8131\n","---- Validation ----\n","Validation loss: 80.1312\n","Validation acc: 0.7469\n","Time taken: 68.72s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 282.2611, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 273.5271, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 260.9685, Accuracy: 0.8133\n","Training loss (for one batch) at step 30: 255.9858, Accuracy: 0.8165\n","Training loss (for one batch) at step 40: 263.7656, Accuracy: 0.8205\n","Training loss (for one batch) at step 50: 248.1970, Accuracy: 0.8247\n","Training loss (for one batch) at step 60: 258.5424, Accuracy: 0.8259\n","Training loss (for one batch) at step 70: 258.5097, Accuracy: 0.8224\n","Training loss (for one batch) at step 80: 259.1600, Accuracy: 0.8193\n","Training loss (for one batch) at step 90: 273.1676, Accuracy: 0.8189\n","Training loss (for one batch) at step 100: 270.5992, Accuracy: 0.8173\n","Training loss (for one batch) at step 110: 286.5652, Accuracy: 0.8179\n","Training loss (for one batch) at step 120: 266.8365, Accuracy: 0.8177\n","Training loss (for one batch) at step 130: 267.1877, Accuracy: 0.8167\n","Training loss (for one batch) at step 140: 264.7686, Accuracy: 0.8170\n","---- Training ----\n","Training loss: 228.2524\n","Training acc over epoch: 0.8162\n","---- Validation ----\n","Validation loss: 86.3974\n","Validation acc: 0.7362\n","Time taken: 47.59s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 266.6479, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 251.6947, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 262.5891, Accuracy: 0.8267\n","Training loss (for one batch) at step 30: 266.7438, Accuracy: 0.8265\n","Training loss (for one batch) at step 40: 241.9616, Accuracy: 0.8298\n","Training loss (for one batch) at step 50: 245.8165, Accuracy: 0.8314\n","Training loss (for one batch) at step 60: 254.3049, Accuracy: 0.8295\n","Training loss (for one batch) at step 70: 265.8818, Accuracy: 0.8300\n","Training loss (for one batch) at step 80: 264.3921, Accuracy: 0.8286\n","Training loss (for one batch) at step 90: 270.7385, Accuracy: 0.8267\n","Training loss (for one batch) at step 100: 274.8617, Accuracy: 0.8261\n","Training loss (for one batch) at step 110: 263.4152, Accuracy: 0.8275\n","Training loss (for one batch) at step 120: 254.7430, Accuracy: 0.8255\n","Training loss (for one batch) at step 130: 256.1833, Accuracy: 0.8240\n","Training loss (for one batch) at step 140: 270.9845, Accuracy: 0.8235\n","---- Training ----\n","Training loss: 226.4933\n","Training acc over epoch: 0.8234\n","---- Validation ----\n","Validation loss: 74.0025\n","Validation acc: 0.7313\n","Time taken: 65.90s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 256.8888, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 232.4763, Accuracy: 0.8400\n","Training loss (for one batch) at step 20: 256.7532, Accuracy: 0.8286\n","Training loss (for one batch) at step 30: 247.1436, Accuracy: 0.8281\n","Training loss (for one batch) at step 40: 254.0002, Accuracy: 0.8271\n","Training loss (for one batch) at step 50: 268.9605, Accuracy: 0.8263\n","Training loss (for one batch) at step 60: 240.5142, Accuracy: 0.8280\n","Training loss (for one batch) at step 70: 247.0794, Accuracy: 0.8287\n","Training loss (for one batch) at step 80: 243.1646, Accuracy: 0.8262\n","Training loss (for one batch) at step 90: 269.1459, Accuracy: 0.8243\n","Training loss (for one batch) at step 100: 264.4463, Accuracy: 0.8238\n","Training loss (for one batch) at step 110: 267.0716, Accuracy: 0.8242\n","Training loss (for one batch) at step 120: 258.2694, Accuracy: 0.8253\n","Training loss (for one batch) at step 130: 261.3351, Accuracy: 0.8240\n","Training loss (for one batch) at step 140: 242.9196, Accuracy: 0.8241\n","---- Training ----\n","Training loss: 233.8724\n","Training acc over epoch: 0.8242\n","---- Validation ----\n","Validation loss: 65.2387\n","Validation acc: 0.7294\n","Time taken: 48.65s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 258.0302, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 244.7492, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 244.7027, Accuracy: 0.8290\n","Training loss (for one batch) at step 30: 243.3652, Accuracy: 0.8287\n","Training loss (for one batch) at step 40: 237.2431, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 250.9232, Accuracy: 0.8325\n","Training loss (for one batch) at step 60: 273.0603, Accuracy: 0.8305\n","Training loss (for one batch) at step 70: 259.3407, Accuracy: 0.8287\n","Training loss (for one batch) at step 80: 235.0057, Accuracy: 0.8294\n","Training loss (for one batch) at step 90: 283.1172, Accuracy: 0.8280\n","Training loss (for one batch) at step 100: 234.1767, Accuracy: 0.8285\n","Training loss (for one batch) at step 110: 256.9485, Accuracy: 0.8284\n","Training loss (for one batch) at step 120: 249.4432, Accuracy: 0.8283\n","Training loss (for one batch) at step 130: 252.4680, Accuracy: 0.8279\n","Training loss (for one batch) at step 140: 260.3544, Accuracy: 0.8276\n","---- Training ----\n","Training loss: 237.2687\n","Training acc over epoch: 0.8270\n","---- Validation ----\n","Validation loss: 55.4981\n","Validation acc: 0.7397\n","Time taken: 66.48s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 250.1915, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 252.2198, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 259.6033, Accuracy: 0.8252\n","Training loss (for one batch) at step 30: 264.4632, Accuracy: 0.8300\n","Training loss (for one batch) at step 40: 247.0715, Accuracy: 0.8280\n","Training loss (for one batch) at step 50: 238.4732, Accuracy: 0.8271\n","Training loss (for one batch) at step 60: 253.9532, Accuracy: 0.8236\n","Training loss (for one batch) at step 70: 238.6592, Accuracy: 0.8261\n","Training loss (for one batch) at step 80: 248.9244, Accuracy: 0.8256\n","Training loss (for one batch) at step 90: 275.2949, Accuracy: 0.8238\n","Training loss (for one batch) at step 100: 231.5262, Accuracy: 0.8225\n","Training loss (for one batch) at step 110: 250.6348, Accuracy: 0.8236\n","Training loss (for one batch) at step 120: 230.9099, Accuracy: 0.8237\n","Training loss (for one batch) at step 130: 234.4983, Accuracy: 0.8240\n","Training loss (for one batch) at step 140: 248.7874, Accuracy: 0.8228\n","---- Training ----\n","Training loss: 224.8908\n","Training acc over epoch: 0.8221\n","---- Validation ----\n","Validation loss: 64.3145\n","Validation acc: 0.7308\n","Time taken: 48.33s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 250.0240, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 237.6883, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 253.4129, Accuracy: 0.8367\n","Training loss (for one batch) at step 30: 229.0220, Accuracy: 0.8345\n","Training loss (for one batch) at step 40: 238.1877, Accuracy: 0.8371\n","Training loss (for one batch) at step 50: 248.6768, Accuracy: 0.8369\n","Training loss (for one batch) at step 60: 240.6119, Accuracy: 0.8387\n","Training loss (for one batch) at step 70: 250.4222, Accuracy: 0.8368\n","Training loss (for one batch) at step 80: 265.2087, Accuracy: 0.8330\n","Training loss (for one batch) at step 90: 244.8881, Accuracy: 0.8321\n","Training loss (for one batch) at step 100: 253.6809, Accuracy: 0.8331\n","Training loss (for one batch) at step 110: 246.7009, Accuracy: 0.8336\n","Training loss (for one batch) at step 120: 253.5293, Accuracy: 0.8338\n","Training loss (for one batch) at step 130: 255.3558, Accuracy: 0.8334\n","Training loss (for one batch) at step 140: 253.3228, Accuracy: 0.8334\n","---- Training ----\n","Training loss: 219.5867\n","Training acc over epoch: 0.8338\n","---- Validation ----\n","Validation loss: 70.0449\n","Validation acc: 0.7340\n","Time taken: 65.02s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 235.8341, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 244.8620, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 264.7985, Accuracy: 0.8319\n","Training loss (for one batch) at step 30: 233.3059, Accuracy: 0.8313\n","Training loss (for one batch) at step 40: 234.9283, Accuracy: 0.8295\n","Training loss (for one batch) at step 50: 222.8051, Accuracy: 0.8353\n","Training loss (for one batch) at step 60: 239.9344, Accuracy: 0.8343\n","Training loss (for one batch) at step 70: 258.9313, Accuracy: 0.8351\n","Training loss (for one batch) at step 80: 244.2281, Accuracy: 0.8338\n","Training loss (for one batch) at step 90: 250.7219, Accuracy: 0.8342\n","Training loss (for one batch) at step 100: 226.4685, Accuracy: 0.8349\n","Training loss (for one batch) at step 110: 244.0710, Accuracy: 0.8350\n","Training loss (for one batch) at step 120: 236.4039, Accuracy: 0.8360\n","Training loss (for one batch) at step 130: 256.5294, Accuracy: 0.8342\n","Training loss (for one batch) at step 140: 269.9176, Accuracy: 0.8336\n","---- Training ----\n","Training loss: 216.4017\n","Training acc over epoch: 0.8338\n","---- Validation ----\n","Validation loss: 70.8455\n","Validation acc: 0.7437\n","Time taken: 48.04s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 242.4442, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 253.9982, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 244.0049, Accuracy: 0.8381\n","Training loss (for one batch) at step 30: 244.6115, Accuracy: 0.8368\n","Training loss (for one batch) at step 40: 241.3944, Accuracy: 0.8398\n","Training loss (for one batch) at step 50: 234.6852, Accuracy: 0.8369\n","Training loss (for one batch) at step 60: 251.5306, Accuracy: 0.8370\n","Training loss (for one batch) at step 70: 238.6640, Accuracy: 0.8369\n","Training loss (for one batch) at step 80: 256.7857, Accuracy: 0.8352\n","Training loss (for one batch) at step 90: 249.2139, Accuracy: 0.8346\n","Training loss (for one batch) at step 100: 234.3451, Accuracy: 0.8312\n","Training loss (for one batch) at step 110: 228.6245, Accuracy: 0.8308\n","Training loss (for one batch) at step 120: 247.9938, Accuracy: 0.8297\n","Training loss (for one batch) at step 130: 244.8251, Accuracy: 0.8298\n","Training loss (for one batch) at step 140: 263.2701, Accuracy: 0.8289\n","---- Training ----\n","Training loss: 222.3003\n","Training acc over epoch: 0.8294\n","---- Validation ----\n","Validation loss: 70.5740\n","Validation acc: 0.7423\n","Time taken: 64.31s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 218.1247, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 252.7379, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 237.2572, Accuracy: 0.8433\n","Training loss (for one batch) at step 30: 238.6425, Accuracy: 0.8406\n","Training loss (for one batch) at step 40: 229.8781, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 238.0301, Accuracy: 0.8398\n","Training loss (for one batch) at step 60: 253.3215, Accuracy: 0.8385\n","Training loss (for one batch) at step 70: 251.5755, Accuracy: 0.8373\n","Training loss (for one batch) at step 80: 238.9077, Accuracy: 0.8362\n","Training loss (for one batch) at step 90: 241.8138, Accuracy: 0.8355\n","Training loss (for one batch) at step 100: 244.8103, Accuracy: 0.8352\n","Training loss (for one batch) at step 110: 232.0469, Accuracy: 0.8363\n","Training loss (for one batch) at step 120: 245.1599, Accuracy: 0.8356\n","Training loss (for one batch) at step 130: 232.6996, Accuracy: 0.8362\n","Training loss (for one batch) at step 140: 255.0106, Accuracy: 0.8335\n","---- Training ----\n","Training loss: 217.7722\n","Training acc over epoch: 0.8334\n","---- Validation ----\n","Validation loss: 57.9025\n","Validation acc: 0.7319\n","Time taken: 48.64s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 235.5676, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 227.9011, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 240.9100, Accuracy: 0.8424\n","Training loss (for one batch) at step 30: 230.4607, Accuracy: 0.8368\n","Training loss (for one batch) at step 40: 213.9492, Accuracy: 0.8395\n","Training loss (for one batch) at step 50: 223.1538, Accuracy: 0.8427\n","Training loss (for one batch) at step 60: 240.4632, Accuracy: 0.8448\n","Training loss (for one batch) at step 70: 247.7459, Accuracy: 0.8415\n","Training loss (for one batch) at step 80: 239.9848, Accuracy: 0.8396\n","Training loss (for one batch) at step 90: 237.7835, Accuracy: 0.8376\n","Training loss (for one batch) at step 100: 239.4716, Accuracy: 0.8370\n","Training loss (for one batch) at step 110: 229.3162, Accuracy: 0.8372\n","Training loss (for one batch) at step 120: 232.6068, Accuracy: 0.8359\n","Training loss (for one batch) at step 130: 239.0383, Accuracy: 0.8355\n","Training loss (for one batch) at step 140: 245.0959, Accuracy: 0.8335\n","---- Training ----\n","Training loss: 210.9928\n","Training acc over epoch: 0.8336\n","---- Validation ----\n","Validation loss: 80.2742\n","Validation acc: 0.7440\n","Time taken: 62.50s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 235.1917, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 235.4564, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 235.1737, Accuracy: 0.8386\n","Training loss (for one batch) at step 30: 230.6480, Accuracy: 0.8365\n","Training loss (for one batch) at step 40: 224.7778, Accuracy: 0.8376\n","Training loss (for one batch) at step 50: 211.9872, Accuracy: 0.8392\n","Training loss (for one batch) at step 60: 244.7687, Accuracy: 0.8377\n","Training loss (for one batch) at step 70: 242.8194, Accuracy: 0.8370\n","Training loss (for one batch) at step 80: 247.0181, Accuracy: 0.8364\n","Training loss (for one batch) at step 90: 234.0558, Accuracy: 0.8370\n","Training loss (for one batch) at step 100: 237.1889, Accuracy: 0.8363\n","Training loss (for one batch) at step 110: 245.5160, Accuracy: 0.8359\n","Training loss (for one batch) at step 120: 235.1613, Accuracy: 0.8340\n","Training loss (for one batch) at step 130: 236.0915, Accuracy: 0.8345\n","Training loss (for one batch) at step 140: 273.2734, Accuracy: 0.8349\n","---- Training ----\n","Training loss: 198.8916\n","Training acc over epoch: 0.8339\n","---- Validation ----\n","Validation loss: 69.5140\n","Validation acc: 0.7311\n","Time taken: 50.07s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 222.5908, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 221.8011, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 234.1125, Accuracy: 0.8395\n","Training loss (for one batch) at step 30: 220.9308, Accuracy: 0.8413\n","Training loss (for one batch) at step 40: 243.8415, Accuracy: 0.8402\n","Training loss (for one batch) at step 50: 236.5141, Accuracy: 0.8439\n","Training loss (for one batch) at step 60: 244.0346, Accuracy: 0.8444\n","Training loss (for one batch) at step 70: 241.0282, Accuracy: 0.8445\n","Training loss (for one batch) at step 80: 248.0688, Accuracy: 0.8441\n","Training loss (for one batch) at step 90: 251.8934, Accuracy: 0.8430\n","Training loss (for one batch) at step 100: 247.4602, Accuracy: 0.8426\n","Training loss (for one batch) at step 110: 225.8649, Accuracy: 0.8444\n","Training loss (for one batch) at step 120: 225.9892, Accuracy: 0.8440\n","Training loss (for one batch) at step 130: 255.0406, Accuracy: 0.8425\n","Training loss (for one batch) at step 140: 229.9544, Accuracy: 0.8427\n","---- Training ----\n","Training loss: 215.9789\n","Training acc over epoch: 0.8416\n","---- Validation ----\n","Validation loss: 80.6376\n","Validation acc: 0.7225\n","Time taken: 62.26s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 234.1671, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 226.8352, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 228.6739, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 234.8060, Accuracy: 0.8387\n","Training loss (for one batch) at step 40: 228.8894, Accuracy: 0.8439\n","Training loss (for one batch) at step 50: 214.6906, Accuracy: 0.8439\n","Training loss (for one batch) at step 60: 218.4252, Accuracy: 0.8457\n","Training loss (for one batch) at step 70: 232.5582, Accuracy: 0.8434\n","Training loss (for one batch) at step 80: 227.5370, Accuracy: 0.8425\n","Training loss (for one batch) at step 90: 256.1789, Accuracy: 0.8404\n","Training loss (for one batch) at step 100: 230.7294, Accuracy: 0.8390\n","Training loss (for one batch) at step 110: 207.5177, Accuracy: 0.8392\n","Training loss (for one batch) at step 120: 227.6081, Accuracy: 0.8392\n","Training loss (for one batch) at step 130: 237.9324, Accuracy: 0.8392\n","Training loss (for one batch) at step 140: 238.7729, Accuracy: 0.8398\n","---- Training ----\n","Training loss: 210.8249\n","Training acc over epoch: 0.8390\n","---- Validation ----\n","Validation loss: 68.1152\n","Validation acc: 0.7219\n","Time taken: 50.16s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 248.0710, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 228.9749, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 234.5841, Accuracy: 0.8533\n","Training loss (for one batch) at step 30: 220.7189, Accuracy: 0.8468\n","Training loss (for one batch) at step 40: 214.9964, Accuracy: 0.8434\n","Training loss (for one batch) at step 50: 232.7071, Accuracy: 0.8443\n","Training loss (for one batch) at step 60: 243.5460, Accuracy: 0.8426\n","Training loss (for one batch) at step 70: 225.7935, Accuracy: 0.8438\n","Training loss (for one batch) at step 80: 239.7450, Accuracy: 0.8438\n","Training loss (for one batch) at step 90: 235.9796, Accuracy: 0.8430\n","Training loss (for one batch) at step 100: 234.4512, Accuracy: 0.8425\n","Training loss (for one batch) at step 110: 240.6454, Accuracy: 0.8421\n","Training loss (for one batch) at step 120: 231.1975, Accuracy: 0.8403\n","Training loss (for one batch) at step 130: 230.1047, Accuracy: 0.8402\n","Training loss (for one batch) at step 140: 236.8565, Accuracy: 0.8397\n","---- Training ----\n","Training loss: 207.1141\n","Training acc over epoch: 0.8394\n","---- Validation ----\n","Validation loss: 71.6887\n","Validation acc: 0.7356\n","Time taken: 61.75s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 238.8915, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 221.9431, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 238.1560, Accuracy: 0.8452\n","Training loss (for one batch) at step 30: 230.5274, Accuracy: 0.8500\n","Training loss (for one batch) at step 40: 215.5167, Accuracy: 0.8478\n","Training loss (for one batch) at step 50: 202.4013, Accuracy: 0.8488\n","Training loss (for one batch) at step 60: 252.6227, Accuracy: 0.8479\n","Training loss (for one batch) at step 70: 221.8537, Accuracy: 0.8496\n","Training loss (for one batch) at step 80: 211.0092, Accuracy: 0.8465\n","Training loss (for one batch) at step 90: 213.9940, Accuracy: 0.8451\n","Training loss (for one batch) at step 100: 231.1083, Accuracy: 0.8426\n","Training loss (for one batch) at step 110: 207.6015, Accuracy: 0.8431\n","Training loss (for one batch) at step 120: 214.2682, Accuracy: 0.8440\n","Training loss (for one batch) at step 130: 240.0047, Accuracy: 0.8420\n","Training loss (for one batch) at step 140: 207.8425, Accuracy: 0.8423\n","---- Training ----\n","Training loss: 217.1189\n","Training acc over epoch: 0.8419\n","---- Validation ----\n","Validation loss: 76.8453\n","Validation acc: 0.7397\n","Time taken: 49.20s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 229.4817, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 225.8322, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 193.1220, Accuracy: 0.8471\n","Training loss (for one batch) at step 30: 229.3266, Accuracy: 0.8448\n","Training loss (for one batch) at step 40: 229.7551, Accuracy: 0.8493\n","Training loss (for one batch) at step 50: 211.7243, Accuracy: 0.8504\n","Training loss (for one batch) at step 60: 215.5340, Accuracy: 0.8479\n","Training loss (for one batch) at step 70: 230.1568, Accuracy: 0.8476\n","Training loss (for one batch) at step 80: 231.3604, Accuracy: 0.8456\n","Training loss (for one batch) at step 90: 228.7775, Accuracy: 0.8449\n","Training loss (for one batch) at step 100: 203.7249, Accuracy: 0.8431\n","Training loss (for one batch) at step 110: 247.6174, Accuracy: 0.8425\n","Training loss (for one batch) at step 120: 209.9360, Accuracy: 0.8428\n","Training loss (for one batch) at step 130: 235.9964, Accuracy: 0.8410\n","Training loss (for one batch) at step 140: 202.7510, Accuracy: 0.8409\n","---- Training ----\n","Training loss: 193.7022\n","Training acc over epoch: 0.8411\n","---- Validation ----\n","Validation loss: 65.9168\n","Validation acc: 0.7329\n","Time taken: 60.29s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 228.4591, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 216.3184, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 244.3288, Accuracy: 0.8481\n","Training loss (for one batch) at step 30: 226.4332, Accuracy: 0.8484\n","Training loss (for one batch) at step 40: 230.0277, Accuracy: 0.8529\n","Training loss (for one batch) at step 50: 216.0572, Accuracy: 0.8563\n","Training loss (for one batch) at step 60: 211.5734, Accuracy: 0.8570\n","Training loss (for one batch) at step 70: 227.8326, Accuracy: 0.8551\n","Training loss (for one batch) at step 80: 235.5448, Accuracy: 0.8535\n","Training loss (for one batch) at step 90: 208.9021, Accuracy: 0.8516\n","Training loss (for one batch) at step 100: 224.6111, Accuracy: 0.8485\n","Training loss (for one batch) at step 110: 234.5329, Accuracy: 0.8482\n","Training loss (for one batch) at step 120: 242.4199, Accuracy: 0.8472\n","Training loss (for one batch) at step 130: 238.3328, Accuracy: 0.8475\n","Training loss (for one batch) at step 140: 208.4721, Accuracy: 0.8475\n","---- Training ----\n","Training loss: 209.9401\n","Training acc over epoch: 0.8467\n","---- Validation ----\n","Validation loss: 59.2811\n","Validation acc: 0.7389\n","Time taken: 50.07s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 200.2514, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 218.9404, Accuracy: 0.8500\n","Training loss (for one batch) at step 20: 205.0095, Accuracy: 0.8486\n","Training loss (for one batch) at step 30: 213.7009, Accuracy: 0.8448\n","Training loss (for one batch) at step 40: 210.0462, Accuracy: 0.8451\n","Training loss (for one batch) at step 50: 212.5746, Accuracy: 0.8476\n","Training loss (for one batch) at step 60: 202.3568, Accuracy: 0.8472\n","Training loss (for one batch) at step 70: 234.1981, Accuracy: 0.8462\n","Training loss (for one batch) at step 80: 224.5644, Accuracy: 0.8463\n","Training loss (for one batch) at step 90: 209.1035, Accuracy: 0.8441\n","Training loss (for one batch) at step 100: 230.6502, Accuracy: 0.8421\n","Training loss (for one batch) at step 110: 227.3220, Accuracy: 0.8431\n","Training loss (for one batch) at step 120: 251.9786, Accuracy: 0.8437\n","Training loss (for one batch) at step 130: 236.6940, Accuracy: 0.8432\n","Training loss (for one batch) at step 140: 233.2983, Accuracy: 0.8440\n","---- Training ----\n","Training loss: 201.5356\n","Training acc over epoch: 0.8439\n","---- Validation ----\n","Validation loss: 88.3494\n","Validation acc: 0.7273\n","Time taken: 60.99s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 225.2239, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 206.5844, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 264.9331, Accuracy: 0.8448\n","Training loss (for one batch) at step 30: 216.8722, Accuracy: 0.8468\n","Training loss (for one batch) at step 40: 226.6909, Accuracy: 0.8432\n","Training loss (for one batch) at step 50: 206.7373, Accuracy: 0.8459\n","Training loss (for one batch) at step 60: 203.7588, Accuracy: 0.8485\n","Training loss (for one batch) at step 70: 229.0410, Accuracy: 0.8485\n","Training loss (for one batch) at step 80: 218.1293, Accuracy: 0.8465\n","Training loss (for one batch) at step 90: 256.6113, Accuracy: 0.8465\n","Training loss (for one batch) at step 100: 219.9882, Accuracy: 0.8473\n","Training loss (for one batch) at step 110: 211.8772, Accuracy: 0.8481\n","Training loss (for one batch) at step 120: 220.2987, Accuracy: 0.8474\n","Training loss (for one batch) at step 130: 247.4305, Accuracy: 0.8464\n","Training loss (for one batch) at step 140: 221.8912, Accuracy: 0.8468\n","---- Training ----\n","Training loss: 207.9988\n","Training acc over epoch: 0.8456\n","---- Validation ----\n","Validation loss: 83.2030\n","Validation acc: 0.7233\n","Time taken: 52.66s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 250.2291, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 197.3427, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 210.8969, Accuracy: 0.8305\n","Training loss (for one batch) at step 30: 233.7159, Accuracy: 0.8329\n","Training loss (for one batch) at step 40: 194.5068, Accuracy: 0.8383\n","Training loss (for one batch) at step 50: 208.8749, Accuracy: 0.8422\n","Training loss (for one batch) at step 60: 221.0687, Accuracy: 0.8428\n","Training loss (for one batch) at step 70: 215.2544, Accuracy: 0.8445\n","Training loss (for one batch) at step 80: 220.7688, Accuracy: 0.8442\n","Training loss (for one batch) at step 90: 235.6701, Accuracy: 0.8425\n","Training loss (for one batch) at step 100: 213.8069, Accuracy: 0.8420\n","Training loss (for one batch) at step 110: 210.0951, Accuracy: 0.8427\n","Training loss (for one batch) at step 120: 236.1404, Accuracy: 0.8439\n","Training loss (for one batch) at step 130: 217.4057, Accuracy: 0.8448\n","Training loss (for one batch) at step 140: 235.6296, Accuracy: 0.8440\n","---- Training ----\n","Training loss: 183.8158\n","Training acc over epoch: 0.8449\n","---- Validation ----\n","Validation loss: 67.1604\n","Validation acc: 0.7319\n","Time taken: 62.92s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 201.6018, Accuracy: 0.9100\n","Training loss (for one batch) at step 10: 218.7362, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 226.8827, Accuracy: 0.8505\n","Training loss (for one batch) at step 30: 199.4951, Accuracy: 0.8435\n","Training loss (for one batch) at step 40: 203.8652, Accuracy: 0.8454\n","Training loss (for one batch) at step 50: 215.1268, Accuracy: 0.8441\n","Training loss (for one batch) at step 60: 207.8360, Accuracy: 0.8470\n","Training loss (for one batch) at step 70: 223.5363, Accuracy: 0.8492\n","Training loss (for one batch) at step 80: 214.4162, Accuracy: 0.8483\n","Training loss (for one batch) at step 90: 244.9549, Accuracy: 0.8468\n","Training loss (for one batch) at step 100: 207.7923, Accuracy: 0.8460\n","Training loss (for one batch) at step 110: 209.3508, Accuracy: 0.8486\n","Training loss (for one batch) at step 120: 237.1217, Accuracy: 0.8474\n","Training loss (for one batch) at step 130: 223.8634, Accuracy: 0.8477\n","Training loss (for one batch) at step 140: 210.6277, Accuracy: 0.8474\n","---- Training ----\n","Training loss: 216.9761\n","Training acc over epoch: 0.8476\n","---- Validation ----\n","Validation loss: 85.7685\n","Validation acc: 0.7265\n","Time taken: 53.59s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 213.3884, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 209.0462, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 217.0547, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 214.4684, Accuracy: 0.8410\n","Training loss (for one batch) at step 40: 196.3888, Accuracy: 0.8415\n","Training loss (for one batch) at step 50: 215.5532, Accuracy: 0.8461\n","Training loss (for one batch) at step 60: 236.9741, Accuracy: 0.8475\n","Training loss (for one batch) at step 70: 199.7617, Accuracy: 0.8489\n","Training loss (for one batch) at step 80: 210.1101, Accuracy: 0.8480\n","Training loss (for one batch) at step 90: 210.8024, Accuracy: 0.8496\n","Training loss (for one batch) at step 100: 227.2229, Accuracy: 0.8472\n","Training loss (for one batch) at step 110: 207.6299, Accuracy: 0.8473\n","Training loss (for one batch) at step 120: 226.2038, Accuracy: 0.8469\n","Training loss (for one batch) at step 130: 219.2592, Accuracy: 0.8476\n","Training loss (for one batch) at step 140: 216.2121, Accuracy: 0.8470\n","---- Training ----\n","Training loss: 190.0255\n","Training acc over epoch: 0.8468\n","---- Validation ----\n","Validation loss: 69.8368\n","Validation acc: 0.7249\n","Time taken: 61.01s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 217.6565, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 216.9246, Accuracy: 0.8409\n","Training loss (for one batch) at step 20: 212.3205, Accuracy: 0.8443\n","Training loss (for one batch) at step 30: 200.5739, Accuracy: 0.8516\n","Training loss (for one batch) at step 40: 216.7517, Accuracy: 0.8507\n","Training loss (for one batch) at step 50: 222.8231, Accuracy: 0.8553\n","Training loss (for one batch) at step 60: 211.8153, Accuracy: 0.8544\n","Training loss (for one batch) at step 70: 223.2672, Accuracy: 0.8515\n","Training loss (for one batch) at step 80: 198.6165, Accuracy: 0.8489\n","Training loss (for one batch) at step 90: 223.4437, Accuracy: 0.8477\n","Training loss (for one batch) at step 100: 208.6168, Accuracy: 0.8466\n","Training loss (for one batch) at step 110: 223.4621, Accuracy: 0.8481\n","Training loss (for one batch) at step 120: 210.4071, Accuracy: 0.8472\n","Training loss (for one batch) at step 130: 216.0071, Accuracy: 0.8488\n","Training loss (for one batch) at step 140: 210.7066, Accuracy: 0.8469\n","---- Training ----\n","Training loss: 175.4065\n","Training acc over epoch: 0.8467\n","---- Validation ----\n","Validation loss: 106.1096\n","Validation acc: 0.7305\n","Time taken: 53.30s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 225.2161, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 233.6169, Accuracy: 0.8591\n","Training loss (for one batch) at step 20: 215.2918, Accuracy: 0.8619\n","Training loss (for one batch) at step 30: 216.5158, Accuracy: 0.8519\n","Training loss (for one batch) at step 40: 213.1790, Accuracy: 0.8549\n","Training loss (for one batch) at step 50: 207.2064, Accuracy: 0.8539\n","Training loss (for one batch) at step 60: 226.5098, Accuracy: 0.8521\n","Training loss (for one batch) at step 70: 231.9284, Accuracy: 0.8514\n","Training loss (for one batch) at step 80: 206.0839, Accuracy: 0.8517\n","Training loss (for one batch) at step 90: 205.9093, Accuracy: 0.8505\n","Training loss (for one batch) at step 100: 196.6962, Accuracy: 0.8496\n","Training loss (for one batch) at step 110: 216.0640, Accuracy: 0.8486\n","Training loss (for one batch) at step 120: 206.7236, Accuracy: 0.8489\n","Training loss (for one batch) at step 130: 204.4394, Accuracy: 0.8488\n","Training loss (for one batch) at step 140: 208.1075, Accuracy: 0.8490\n","---- Training ----\n","Training loss: 177.7242\n","Training acc over epoch: 0.8483\n","---- Validation ----\n","Validation loss: 73.8137\n","Validation acc: 0.7270\n","Time taken: 61.61s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 192.2081, Accuracy: 0.9200\n","Training loss (for one batch) at step 10: 207.4653, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 196.1846, Accuracy: 0.8510\n","Training loss (for one batch) at step 30: 182.6079, Accuracy: 0.8474\n","Training loss (for one batch) at step 40: 203.0189, Accuracy: 0.8454\n","Training loss (for one batch) at step 50: 193.7542, Accuracy: 0.8492\n","Training loss (for one batch) at step 60: 222.8609, Accuracy: 0.8479\n","Training loss (for one batch) at step 70: 213.1559, Accuracy: 0.8485\n","Training loss (for one batch) at step 80: 195.5713, Accuracy: 0.8479\n","Training loss (for one batch) at step 90: 199.6198, Accuracy: 0.8473\n","Training loss (for one batch) at step 100: 217.9117, Accuracy: 0.8456\n","Training loss (for one batch) at step 110: 205.0130, Accuracy: 0.8467\n","Training loss (for one batch) at step 120: 200.6017, Accuracy: 0.8451\n","Training loss (for one batch) at step 130: 202.5632, Accuracy: 0.8444\n","Training loss (for one batch) at step 140: 197.5107, Accuracy: 0.8432\n","---- Training ----\n","Training loss: 164.1999\n","Training acc over epoch: 0.8435\n","---- Validation ----\n","Validation loss: 68.9356\n","Validation acc: 0.7268\n","Time taken: 54.68s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 197.0468, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 213.0845, Accuracy: 0.8591\n","Training loss (for one batch) at step 20: 203.0128, Accuracy: 0.8586\n","Training loss (for one batch) at step 30: 226.7425, Accuracy: 0.8561\n","Training loss (for one batch) at step 40: 182.7890, Accuracy: 0.8571\n","Training loss (for one batch) at step 50: 211.7321, Accuracy: 0.8559\n","Training loss (for one batch) at step 60: 200.3920, Accuracy: 0.8577\n","Training loss (for one batch) at step 70: 202.4686, Accuracy: 0.8561\n","Training loss (for one batch) at step 80: 243.6484, Accuracy: 0.8540\n","Training loss (for one batch) at step 90: 204.9140, Accuracy: 0.8511\n","Training loss (for one batch) at step 100: 204.2000, Accuracy: 0.8500\n","Training loss (for one batch) at step 110: 228.0543, Accuracy: 0.8499\n","Training loss (for one batch) at step 120: 206.3541, Accuracy: 0.8498\n","Training loss (for one batch) at step 130: 215.6771, Accuracy: 0.8501\n","Training loss (for one batch) at step 140: 200.8600, Accuracy: 0.8494\n","---- Training ----\n","Training loss: 180.5217\n","Training acc over epoch: 0.8492\n","---- Validation ----\n","Validation loss: 76.8593\n","Validation acc: 0.7289\n","Time taken: 60.85s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 205.2282, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 225.3042, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 194.5104, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 207.6927, Accuracy: 0.8484\n","Training loss (for one batch) at step 40: 195.5227, Accuracy: 0.8478\n","Training loss (for one batch) at step 50: 205.1373, Accuracy: 0.8510\n","Training loss (for one batch) at step 60: 182.7279, Accuracy: 0.8539\n","Training loss (for one batch) at step 70: 210.3254, Accuracy: 0.8510\n","Training loss (for one batch) at step 80: 199.3923, Accuracy: 0.8510\n","Training loss (for one batch) at step 90: 192.8136, Accuracy: 0.8529\n","Training loss (for one batch) at step 100: 193.6104, Accuracy: 0.8520\n","Training loss (for one batch) at step 110: 215.2464, Accuracy: 0.8512\n","Training loss (for one batch) at step 120: 204.0931, Accuracy: 0.8521\n","Training loss (for one batch) at step 130: 198.4651, Accuracy: 0.8525\n","Training loss (for one batch) at step 140: 195.2698, Accuracy: 0.8513\n","---- Training ----\n","Training loss: 201.9470\n","Training acc over epoch: 0.8510\n","---- Validation ----\n","Validation loss: 94.6841\n","Validation acc: 0.7265\n","Time taken: 54.15s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 210.6264, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 203.2037, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 200.8780, Accuracy: 0.8576\n","Training loss (for one batch) at step 30: 219.5609, Accuracy: 0.8506\n","Training loss (for one batch) at step 40: 196.9256, Accuracy: 0.8507\n","Training loss (for one batch) at step 50: 201.9439, Accuracy: 0.8510\n","Training loss (for one batch) at step 60: 216.0611, Accuracy: 0.8492\n","Training loss (for one batch) at step 70: 214.3053, Accuracy: 0.8499\n","Training loss (for one batch) at step 80: 186.2735, Accuracy: 0.8488\n","Training loss (for one batch) at step 90: 259.5701, Accuracy: 0.8467\n","Training loss (for one batch) at step 100: 190.9406, Accuracy: 0.8457\n","Training loss (for one batch) at step 110: 191.0650, Accuracy: 0.8461\n","Training loss (for one batch) at step 120: 235.3501, Accuracy: 0.8470\n","Training loss (for one batch) at step 130: 202.3817, Accuracy: 0.8480\n","Training loss (for one batch) at step 140: 235.8335, Accuracy: 0.8479\n","---- Training ----\n","Training loss: 164.7656\n","Training acc over epoch: 0.8482\n","---- Validation ----\n","Validation loss: 87.9655\n","Validation acc: 0.7311\n","Time taken: 58.62s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 204.5627, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 221.2933, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 188.6167, Accuracy: 0.8571\n","Training loss (for one batch) at step 30: 200.0119, Accuracy: 0.8519\n","Training loss (for one batch) at step 40: 191.6080, Accuracy: 0.8507\n","Training loss (for one batch) at step 50: 193.1429, Accuracy: 0.8533\n","Training loss (for one batch) at step 60: 215.9621, Accuracy: 0.8551\n","Training loss (for one batch) at step 70: 210.9236, Accuracy: 0.8548\n","Training loss (for one batch) at step 80: 216.9274, Accuracy: 0.8519\n","Training loss (for one batch) at step 90: 226.3201, Accuracy: 0.8513\n","Training loss (for one batch) at step 100: 202.2559, Accuracy: 0.8508\n","Training loss (for one batch) at step 110: 207.3746, Accuracy: 0.8507\n","Training loss (for one batch) at step 120: 194.7182, Accuracy: 0.8505\n","Training loss (for one batch) at step 130: 200.0363, Accuracy: 0.8513\n","Training loss (for one batch) at step 140: 201.0230, Accuracy: 0.8497\n","---- Training ----\n","Training loss: 189.4398\n","Training acc over epoch: 0.8508\n","---- Validation ----\n","Validation loss: 65.8887\n","Validation acc: 0.7311\n","Time taken: 57.65s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7425\n","Validation AUC: 0.7401\n","Validation Balanced_ACC: 0.4830\n","Validation MI: 0.1387\n","Validation Normalized MI: 0.2073\n","Validation Adjusted MI: 0.2073\n","Validation aUc_Sklearn: 0.8270\n","\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-14 23:10:29.300861: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n","2023-02-14 23:10:32.539571: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 436.6236, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 435.5614, Accuracy: 0.5491\n","Training loss (for one batch) at step 20: 410.9731, Accuracy: 0.5462\n","Training loss (for one batch) at step 30: 471.3681, Accuracy: 0.5542\n","Training loss (for one batch) at step 40: 433.4162, Accuracy: 0.5566\n","Training loss (for one batch) at step 50: 428.1716, Accuracy: 0.5569\n","Training loss (for one batch) at step 60: 433.5032, Accuracy: 0.5631\n","Training loss (for one batch) at step 70: 429.7946, Accuracy: 0.5599\n","Training loss (for one batch) at step 80: 430.2086, Accuracy: 0.5647\n","Training loss (for one batch) at step 90: 456.7353, Accuracy: 0.5653\n","Training loss (for one batch) at step 100: 419.2536, Accuracy: 0.5691\n","Training loss (for one batch) at step 110: 395.0050, Accuracy: 0.5692\n","Training loss (for one batch) at step 120: 414.5247, Accuracy: 0.5704\n","Training loss (for one batch) at step 130: 382.7275, Accuracy: 0.5730\n","Training loss (for one batch) at step 140: 388.0818, Accuracy: 0.5755\n","---- Training ----\n","Training loss: 394.8313\n","Training acc over epoch: 0.5761\n","---- Validation ----\n","Validation loss: 87.6995\n","Validation acc: 0.5134\n","Time taken: 68.22s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 396.7151, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 374.0270, Accuracy: 0.6045\n","Training loss (for one batch) at step 20: 392.8275, Accuracy: 0.6124\n","Training loss (for one batch) at step 30: 391.8384, Accuracy: 0.6077\n","Training loss (for one batch) at step 40: 415.2708, Accuracy: 0.6054\n","Training loss (for one batch) at step 50: 399.8800, Accuracy: 0.6075\n","Training loss (for one batch) at step 60: 363.1733, Accuracy: 0.6087\n","Training loss (for one batch) at step 70: 391.1283, Accuracy: 0.6106\n","Training loss (for one batch) at step 80: 401.3207, Accuracy: 0.6131\n","Training loss (for one batch) at step 90: 393.3836, Accuracy: 0.6168\n","Training loss (for one batch) at step 100: 388.7330, Accuracy: 0.6165\n","Training loss (for one batch) at step 110: 378.7025, Accuracy: 0.6186\n","Training loss (for one batch) at step 120: 394.8909, Accuracy: 0.6190\n","Training loss (for one batch) at step 130: 392.1635, Accuracy: 0.6191\n","Training loss (for one batch) at step 140: 382.8720, Accuracy: 0.6195\n","---- Training ----\n","Training loss: 355.5984\n","Training acc over epoch: 0.6204\n","---- Validation ----\n","Validation loss: 73.7167\n","Validation acc: 0.5228\n","Time taken: 55.17s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 373.6795, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 349.8850, Accuracy: 0.6491\n","Training loss (for one batch) at step 20: 401.0105, Accuracy: 0.6429\n","Training loss (for one batch) at step 30: 401.1235, Accuracy: 0.6432\n","Training loss (for one batch) at step 40: 349.6929, Accuracy: 0.6488\n","Training loss (for one batch) at step 50: 365.1029, Accuracy: 0.6455\n","Training loss (for one batch) at step 60: 361.0728, Accuracy: 0.6472\n","Training loss (for one batch) at step 70: 377.0344, Accuracy: 0.6513\n","Training loss (for one batch) at step 80: 362.3386, Accuracy: 0.6511\n","Training loss (for one batch) at step 90: 372.0692, Accuracy: 0.6488\n","Training loss (for one batch) at step 100: 357.8613, Accuracy: 0.6489\n","Training loss (for one batch) at step 110: 364.9118, Accuracy: 0.6495\n","Training loss (for one batch) at step 120: 392.6961, Accuracy: 0.6491\n","Training loss (for one batch) at step 130: 370.6182, Accuracy: 0.6492\n","Training loss (for one batch) at step 140: 366.3666, Accuracy: 0.6502\n","---- Training ----\n","Training loss: 333.8393\n","Training acc over epoch: 0.6494\n","---- Validation ----\n","Validation loss: 76.3876\n","Validation acc: 0.6531\n","Time taken: 69.05s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 336.2198, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 365.8463, Accuracy: 0.6836\n","Training loss (for one batch) at step 20: 341.6383, Accuracy: 0.6771\n","Training loss (for one batch) at step 30: 350.0477, Accuracy: 0.6616\n","Training loss (for one batch) at step 40: 380.0253, Accuracy: 0.6600\n","Training loss (for one batch) at step 50: 359.6744, Accuracy: 0.6627\n","Training loss (for one batch) at step 60: 342.7433, Accuracy: 0.6656\n","Training loss (for one batch) at step 70: 334.3157, Accuracy: 0.6672\n","Training loss (for one batch) at step 80: 344.7623, Accuracy: 0.6712\n","Training loss (for one batch) at step 90: 360.6187, Accuracy: 0.6725\n","Training loss (for one batch) at step 100: 347.4454, Accuracy: 0.6698\n","Training loss (for one batch) at step 110: 358.5741, Accuracy: 0.6716\n","Training loss (for one batch) at step 120: 357.0551, Accuracy: 0.6699\n","Training loss (for one batch) at step 130: 350.0647, Accuracy: 0.6708\n","Training loss (for one batch) at step 140: 338.0910, Accuracy: 0.6701\n","---- Training ----\n","Training loss: 308.0896\n","Training acc over epoch: 0.6698\n","---- Validation ----\n","Validation loss: 69.7564\n","Validation acc: 0.7120\n","Time taken: 46.18s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 328.9666, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 339.1441, Accuracy: 0.6745\n","Training loss (for one batch) at step 20: 337.8909, Accuracy: 0.6714\n","Training loss (for one batch) at step 30: 352.2290, Accuracy: 0.6774\n","Training loss (for one batch) at step 40: 364.9357, Accuracy: 0.6863\n","Training loss (for one batch) at step 50: 339.1195, Accuracy: 0.6908\n","Training loss (for one batch) at step 60: 340.5474, Accuracy: 0.6887\n","Training loss (for one batch) at step 70: 347.6205, Accuracy: 0.6859\n","Training loss (for one batch) at step 80: 354.3122, Accuracy: 0.6844\n","Training loss (for one batch) at step 90: 345.6548, Accuracy: 0.6857\n","Training loss (for one batch) at step 100: 349.2248, Accuracy: 0.6868\n","Training loss (for one batch) at step 110: 332.4956, Accuracy: 0.6885\n","Training loss (for one batch) at step 120: 339.8990, Accuracy: 0.6877\n","Training loss (for one batch) at step 130: 334.7568, Accuracy: 0.6888\n","Training loss (for one batch) at step 140: 312.8282, Accuracy: 0.6893\n","---- Training ----\n","Training loss: 308.9268\n","Training acc over epoch: 0.6896\n","---- Validation ----\n","Validation loss: 65.5789\n","Validation acc: 0.7243\n","Time taken: 69.48s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 351.3552, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 332.9081, Accuracy: 0.7027\n","Training loss (for one batch) at step 20: 335.3109, Accuracy: 0.6990\n","Training loss (for one batch) at step 30: 334.2821, Accuracy: 0.7052\n","Training loss (for one batch) at step 40: 316.3886, Accuracy: 0.7066\n","Training loss (for one batch) at step 50: 349.9482, Accuracy: 0.7043\n","Training loss (for one batch) at step 60: 348.0242, Accuracy: 0.6980\n","Training loss (for one batch) at step 70: 337.8733, Accuracy: 0.6987\n","Training loss (for one batch) at step 80: 347.6678, Accuracy: 0.7000\n","Training loss (for one batch) at step 90: 338.2899, Accuracy: 0.6981\n","Training loss (for one batch) at step 100: 352.0109, Accuracy: 0.6972\n","Training loss (for one batch) at step 110: 336.4189, Accuracy: 0.6977\n","Training loss (for one batch) at step 120: 329.9515, Accuracy: 0.7005\n","Training loss (for one batch) at step 130: 310.9571, Accuracy: 0.7009\n","Training loss (for one batch) at step 140: 320.9157, Accuracy: 0.7012\n","---- Training ----\n","Training loss: 293.2957\n","Training acc over epoch: 0.7012\n","---- Validation ----\n","Validation loss: 73.1645\n","Validation acc: 0.7297\n","Time taken: 55.36s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 315.5915, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 350.5636, Accuracy: 0.7182\n","Training loss (for one batch) at step 20: 317.6315, Accuracy: 0.7171\n","Training loss (for one batch) at step 30: 319.8180, Accuracy: 0.7194\n","Training loss (for one batch) at step 40: 350.3785, Accuracy: 0.7173\n","Training loss (for one batch) at step 50: 318.8316, Accuracy: 0.7182\n","Training loss (for one batch) at step 60: 331.2031, Accuracy: 0.7144\n","Training loss (for one batch) at step 70: 311.3257, Accuracy: 0.7158\n","Training loss (for one batch) at step 80: 350.2624, Accuracy: 0.7147\n","Training loss (for one batch) at step 90: 308.1411, Accuracy: 0.7133\n","Training loss (for one batch) at step 100: 338.3254, Accuracy: 0.7120\n","Training loss (for one batch) at step 110: 315.9450, Accuracy: 0.7123\n","Training loss (for one batch) at step 120: 332.0000, Accuracy: 0.7112\n","Training loss (for one batch) at step 130: 302.6914, Accuracy: 0.7145\n","Training loss (for one batch) at step 140: 302.8059, Accuracy: 0.7140\n","---- Training ----\n","Training loss: 296.1591\n","Training acc over epoch: 0.7139\n","---- Validation ----\n","Validation loss: 70.5558\n","Validation acc: 0.7343\n","Time taken: 67.16s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 303.1763, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 339.5162, Accuracy: 0.7300\n","Training loss (for one batch) at step 20: 306.1322, Accuracy: 0.7329\n","Training loss (for one batch) at step 30: 325.7250, Accuracy: 0.7274\n","Training loss (for one batch) at step 40: 319.2345, Accuracy: 0.7361\n","Training loss (for one batch) at step 50: 322.6181, Accuracy: 0.7335\n","Training loss (for one batch) at step 60: 324.2099, Accuracy: 0.7346\n","Training loss (for one batch) at step 70: 300.6813, Accuracy: 0.7330\n","Training loss (for one batch) at step 80: 307.7044, Accuracy: 0.7340\n","Training loss (for one batch) at step 90: 312.5745, Accuracy: 0.7344\n","Training loss (for one batch) at step 100: 321.3698, Accuracy: 0.7321\n","Training loss (for one batch) at step 110: 299.6636, Accuracy: 0.7342\n","Training loss (for one batch) at step 120: 309.2267, Accuracy: 0.7342\n","Training loss (for one batch) at step 130: 298.1317, Accuracy: 0.7344\n","Training loss (for one batch) at step 140: 312.5305, Accuracy: 0.7351\n","---- Training ----\n","Training loss: 281.9247\n","Training acc over epoch: 0.7354\n","---- Validation ----\n","Validation loss: 73.4071\n","Validation acc: 0.7198\n","Time taken: 49.16s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 332.0253, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 312.9711, Accuracy: 0.7564\n","Training loss (for one batch) at step 20: 306.9419, Accuracy: 0.7533\n","Training loss (for one batch) at step 30: 308.1533, Accuracy: 0.7484\n","Training loss (for one batch) at step 40: 292.7788, Accuracy: 0.7495\n","Training loss (for one batch) at step 50: 301.1482, Accuracy: 0.7531\n","Training loss (for one batch) at step 60: 334.4452, Accuracy: 0.7503\n","Training loss (for one batch) at step 70: 297.8073, Accuracy: 0.7493\n","Training loss (for one batch) at step 80: 335.2913, Accuracy: 0.7490\n","Training loss (for one batch) at step 90: 295.9787, Accuracy: 0.7468\n","Training loss (for one batch) at step 100: 311.6848, Accuracy: 0.7457\n","Training loss (for one batch) at step 110: 308.6985, Accuracy: 0.7447\n","Training loss (for one batch) at step 120: 331.5086, Accuracy: 0.7436\n","Training loss (for one batch) at step 130: 306.9093, Accuracy: 0.7431\n","Training loss (for one batch) at step 140: 307.9696, Accuracy: 0.7425\n","---- Training ----\n","Training loss: 267.6394\n","Training acc over epoch: 0.7438\n","---- Validation ----\n","Validation loss: 69.5071\n","Validation acc: 0.7397\n","Time taken: 67.83s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 307.4138, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 305.3198, Accuracy: 0.7618\n","Training loss (for one batch) at step 20: 324.4145, Accuracy: 0.7610\n","Training loss (for one batch) at step 30: 290.7440, Accuracy: 0.7671\n","Training loss (for one batch) at step 40: 315.3165, Accuracy: 0.7676\n","Training loss (for one batch) at step 50: 308.7544, Accuracy: 0.7714\n","Training loss (for one batch) at step 60: 307.5600, Accuracy: 0.7680\n","Training loss (for one batch) at step 70: 312.9109, Accuracy: 0.7680\n","Training loss (for one batch) at step 80: 304.0013, Accuracy: 0.7643\n","Training loss (for one batch) at step 90: 307.1109, Accuracy: 0.7627\n","Training loss (for one batch) at step 100: 300.6502, Accuracy: 0.7610\n","Training loss (for one batch) at step 110: 301.0058, Accuracy: 0.7615\n","Training loss (for one batch) at step 120: 323.5319, Accuracy: 0.7617\n","Training loss (for one batch) at step 130: 303.5409, Accuracy: 0.7615\n","Training loss (for one batch) at step 140: 313.2774, Accuracy: 0.7598\n","---- Training ----\n","Training loss: 270.2176\n","Training acc over epoch: 0.7595\n","---- Validation ----\n","Validation loss: 64.7523\n","Validation acc: 0.7394\n","Time taken: 53.70s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 293.1106, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 292.2770, Accuracy: 0.7818\n","Training loss (for one batch) at step 20: 332.5087, Accuracy: 0.7790\n","Training loss (for one batch) at step 30: 306.5567, Accuracy: 0.7755\n","Training loss (for one batch) at step 40: 305.6478, Accuracy: 0.7766\n","Training loss (for one batch) at step 50: 295.3223, Accuracy: 0.7798\n","Training loss (for one batch) at step 60: 301.2914, Accuracy: 0.7779\n","Training loss (for one batch) at step 70: 313.5097, Accuracy: 0.7759\n","Training loss (for one batch) at step 80: 295.1678, Accuracy: 0.7769\n","Training loss (for one batch) at step 90: 309.8512, Accuracy: 0.7756\n","Training loss (for one batch) at step 100: 313.2135, Accuracy: 0.7732\n","Training loss (for one batch) at step 110: 299.1552, Accuracy: 0.7750\n","Training loss (for one batch) at step 120: 297.9593, Accuracy: 0.7746\n","Training loss (for one batch) at step 130: 306.1283, Accuracy: 0.7730\n","Training loss (for one batch) at step 140: 291.9704, Accuracy: 0.7730\n","---- Training ----\n","Training loss: 264.5132\n","Training acc over epoch: 0.7720\n","---- Validation ----\n","Validation loss: 72.0313\n","Validation acc: 0.7579\n","Time taken: 62.59s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 295.4385, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 301.2710, Accuracy: 0.7873\n","Training loss (for one batch) at step 20: 289.2612, Accuracy: 0.7852\n","Training loss (for one batch) at step 30: 305.8139, Accuracy: 0.7826\n","Training loss (for one batch) at step 40: 304.6992, Accuracy: 0.7788\n","Training loss (for one batch) at step 50: 297.2608, Accuracy: 0.7780\n","Training loss (for one batch) at step 60: 316.0440, Accuracy: 0.7836\n","Training loss (for one batch) at step 70: 306.9107, Accuracy: 0.7818\n","Training loss (for one batch) at step 80: 308.2156, Accuracy: 0.7816\n","Training loss (for one batch) at step 90: 290.6125, Accuracy: 0.7785\n","Training loss (for one batch) at step 100: 298.0476, Accuracy: 0.7773\n","Training loss (for one batch) at step 110: 292.1115, Accuracy: 0.7800\n","Training loss (for one batch) at step 120: 290.1648, Accuracy: 0.7778\n","Training loss (for one batch) at step 130: 302.0177, Accuracy: 0.7757\n","Training loss (for one batch) at step 140: 304.9943, Accuracy: 0.7749\n","---- Training ----\n","Training loss: 247.7040\n","Training acc over epoch: 0.7753\n","---- Validation ----\n","Validation loss: 71.1890\n","Validation acc: 0.7654\n","Time taken: 58.10s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 296.2700, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 284.1924, Accuracy: 0.7982\n","Training loss (for one batch) at step 20: 301.7405, Accuracy: 0.7852\n","Training loss (for one batch) at step 30: 305.6154, Accuracy: 0.7865\n","Training loss (for one batch) at step 40: 305.4304, Accuracy: 0.7876\n","Training loss (for one batch) at step 50: 306.1944, Accuracy: 0.7890\n","Training loss (for one batch) at step 60: 285.4800, Accuracy: 0.7836\n","Training loss (for one batch) at step 70: 280.3773, Accuracy: 0.7848\n","Training loss (for one batch) at step 80: 304.5646, Accuracy: 0.7833\n","Training loss (for one batch) at step 90: 291.0331, Accuracy: 0.7832\n","Training loss (for one batch) at step 100: 315.4756, Accuracy: 0.7825\n","Training loss (for one batch) at step 110: 315.1168, Accuracy: 0.7829\n","Training loss (for one batch) at step 120: 312.0225, Accuracy: 0.7809\n","Training loss (for one batch) at step 130: 279.3751, Accuracy: 0.7797\n","Training loss (for one batch) at step 140: 295.1747, Accuracy: 0.7804\n","---- Training ----\n","Training loss: 260.6504\n","Training acc over epoch: 0.7798\n","---- Validation ----\n","Validation loss: 62.6049\n","Validation acc: 0.7512\n","Time taken: 60.11s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 292.3410, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 280.6440, Accuracy: 0.7991\n","Training loss (for one batch) at step 20: 285.8524, Accuracy: 0.7919\n","Training loss (for one batch) at step 30: 302.8146, Accuracy: 0.7935\n","Training loss (for one batch) at step 40: 278.5385, Accuracy: 0.7941\n","Training loss (for one batch) at step 50: 286.1875, Accuracy: 0.7976\n","Training loss (for one batch) at step 60: 281.8354, Accuracy: 0.7989\n","Training loss (for one batch) at step 70: 293.0889, Accuracy: 0.7970\n","Training loss (for one batch) at step 80: 294.8672, Accuracy: 0.7933\n","Training loss (for one batch) at step 90: 299.2309, Accuracy: 0.7921\n","Training loss (for one batch) at step 100: 269.1779, Accuracy: 0.7926\n","Training loss (for one batch) at step 110: 306.9193, Accuracy: 0.7920\n","Training loss (for one batch) at step 120: 302.1734, Accuracy: 0.7921\n","Training loss (for one batch) at step 130: 314.5122, Accuracy: 0.7918\n","Training loss (for one batch) at step 140: 300.9662, Accuracy: 0.7909\n","---- Training ----\n","Training loss: 265.0974\n","Training acc over epoch: 0.7906\n","---- Validation ----\n","Validation loss: 65.3173\n","Validation acc: 0.7477\n","Time taken: 63.96s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 297.4746, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 274.2362, Accuracy: 0.7827\n","Training loss (for one batch) at step 20: 278.2871, Accuracy: 0.7914\n","Training loss (for one batch) at step 30: 287.4460, Accuracy: 0.7900\n","Training loss (for one batch) at step 40: 276.1657, Accuracy: 0.7934\n","Training loss (for one batch) at step 50: 280.8741, Accuracy: 0.7996\n","Training loss (for one batch) at step 60: 280.3805, Accuracy: 0.8020\n","Training loss (for one batch) at step 70: 299.2661, Accuracy: 0.7993\n","Training loss (for one batch) at step 80: 284.0093, Accuracy: 0.7988\n","Training loss (for one batch) at step 90: 307.7014, Accuracy: 0.7982\n","Training loss (for one batch) at step 100: 293.5166, Accuracy: 0.7986\n","Training loss (for one batch) at step 110: 285.0305, Accuracy: 0.8003\n","Training loss (for one batch) at step 120: 290.3971, Accuracy: 0.8013\n","Training loss (for one batch) at step 130: 298.2986, Accuracy: 0.8021\n","Training loss (for one batch) at step 140: 290.5678, Accuracy: 0.8010\n","---- Training ----\n","Training loss: 266.7722\n","Training acc over epoch: 0.8010\n","---- Validation ----\n","Validation loss: 78.6809\n","Validation acc: 0.7238\n","Time taken: 58.54s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 289.3987, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 263.7898, Accuracy: 0.8045\n","Training loss (for one batch) at step 20: 264.7597, Accuracy: 0.7981\n","Training loss (for one batch) at step 30: 285.3677, Accuracy: 0.7913\n","Training loss (for one batch) at step 40: 289.4695, Accuracy: 0.7934\n","Training loss (for one batch) at step 50: 275.6686, Accuracy: 0.8000\n","Training loss (for one batch) at step 60: 265.1435, Accuracy: 0.8020\n","Training loss (for one batch) at step 70: 299.9144, Accuracy: 0.8027\n","Training loss (for one batch) at step 80: 270.1911, Accuracy: 0.8019\n","Training loss (for one batch) at step 90: 306.9959, Accuracy: 0.7984\n","Training loss (for one batch) at step 100: 282.6654, Accuracy: 0.7971\n","Training loss (for one batch) at step 110: 270.1904, Accuracy: 0.7992\n","Training loss (for one batch) at step 120: 290.6110, Accuracy: 0.7990\n","Training loss (for one batch) at step 130: 280.2569, Accuracy: 0.7988\n","Training loss (for one batch) at step 140: 276.3566, Accuracy: 0.7978\n","---- Training ----\n","Training loss: 246.3596\n","Training acc over epoch: 0.7988\n","---- Validation ----\n","Validation loss: 69.0349\n","Validation acc: 0.7324\n","Time taken: 68.72s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 282.3566, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 283.1825, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 301.1286, Accuracy: 0.8148\n","Training loss (for one batch) at step 30: 306.3073, Accuracy: 0.8119\n","Training loss (for one batch) at step 40: 290.4330, Accuracy: 0.8095\n","Training loss (for one batch) at step 50: 268.0714, Accuracy: 0.8112\n","Training loss (for one batch) at step 60: 268.8825, Accuracy: 0.8100\n","Training loss (for one batch) at step 70: 284.6416, Accuracy: 0.8090\n","Training loss (for one batch) at step 80: 295.9355, Accuracy: 0.8093\n","Training loss (for one batch) at step 90: 291.3719, Accuracy: 0.8085\n","Training loss (for one batch) at step 100: 277.4905, Accuracy: 0.8086\n","Training loss (for one batch) at step 110: 282.2858, Accuracy: 0.8076\n","Training loss (for one batch) at step 120: 284.9858, Accuracy: 0.8076\n","Training loss (for one batch) at step 130: 263.2606, Accuracy: 0.8073\n","Training loss (for one batch) at step 140: 275.5289, Accuracy: 0.8055\n","---- Training ----\n","Training loss: 245.3577\n","Training acc over epoch: 0.8051\n","---- Validation ----\n","Validation loss: 66.0141\n","Validation acc: 0.7281\n","Time taken: 51.68s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 274.8900, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 269.1225, Accuracy: 0.8100\n","Training loss (for one batch) at step 20: 269.4502, Accuracy: 0.8119\n","Training loss (for one batch) at step 30: 283.3691, Accuracy: 0.8023\n","Training loss (for one batch) at step 40: 247.5764, Accuracy: 0.8080\n","Training loss (for one batch) at step 50: 269.8650, Accuracy: 0.8102\n","Training loss (for one batch) at step 60: 267.3361, Accuracy: 0.8080\n","Training loss (for one batch) at step 70: 274.3218, Accuracy: 0.8094\n","Training loss (for one batch) at step 80: 287.8150, Accuracy: 0.8112\n","Training loss (for one batch) at step 90: 274.4793, Accuracy: 0.8093\n","Training loss (for one batch) at step 100: 290.6978, Accuracy: 0.8061\n","Training loss (for one batch) at step 110: 279.4243, Accuracy: 0.8057\n","Training loss (for one batch) at step 120: 264.9689, Accuracy: 0.8066\n","Training loss (for one batch) at step 130: 281.6041, Accuracy: 0.8083\n","Training loss (for one batch) at step 140: 284.7175, Accuracy: 0.8078\n","---- Training ----\n","Training loss: 248.8784\n","Training acc over epoch: 0.8076\n","---- Validation ----\n","Validation loss: 63.9478\n","Validation acc: 0.7491\n","Time taken: 70.26s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 272.9466, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 247.9762, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 252.5648, Accuracy: 0.8267\n","Training loss (for one batch) at step 30: 263.1140, Accuracy: 0.8213\n","Training loss (for one batch) at step 40: 292.3441, Accuracy: 0.8198\n","Training loss (for one batch) at step 50: 291.2531, Accuracy: 0.8198\n","Training loss (for one batch) at step 60: 278.8389, Accuracy: 0.8208\n","Training loss (for one batch) at step 70: 285.0758, Accuracy: 0.8203\n","Training loss (for one batch) at step 80: 271.2791, Accuracy: 0.8178\n","Training loss (for one batch) at step 90: 291.3209, Accuracy: 0.8165\n","Training loss (for one batch) at step 100: 266.3471, Accuracy: 0.8134\n","Training loss (for one batch) at step 110: 269.3744, Accuracy: 0.8148\n","Training loss (for one batch) at step 120: 274.5425, Accuracy: 0.8140\n","Training loss (for one batch) at step 130: 279.9560, Accuracy: 0.8140\n","Training loss (for one batch) at step 140: 277.9289, Accuracy: 0.8141\n","---- Training ----\n","Training loss: 233.6852\n","Training acc over epoch: 0.8138\n","---- Validation ----\n","Validation loss: 68.4359\n","Validation acc: 0.7389\n","Time taken: 52.34s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 279.3813, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 278.1928, Accuracy: 0.8009\n","Training loss (for one batch) at step 20: 302.7805, Accuracy: 0.8224\n","Training loss (for one batch) at step 30: 271.0864, Accuracy: 0.8155\n","Training loss (for one batch) at step 40: 264.1951, Accuracy: 0.8151\n","Training loss (for one batch) at step 50: 263.7999, Accuracy: 0.8196\n","Training loss (for one batch) at step 60: 275.9771, Accuracy: 0.8241\n","Training loss (for one batch) at step 70: 275.3202, Accuracy: 0.8207\n","Training loss (for one batch) at step 80: 250.8969, Accuracy: 0.8185\n","Training loss (for one batch) at step 90: 280.7341, Accuracy: 0.8185\n","Training loss (for one batch) at step 100: 272.0509, Accuracy: 0.8172\n","Training loss (for one batch) at step 110: 245.7936, Accuracy: 0.8185\n","Training loss (for one batch) at step 120: 274.5477, Accuracy: 0.8171\n","Training loss (for one batch) at step 130: 257.8491, Accuracy: 0.8163\n","Training loss (for one batch) at step 140: 251.0247, Accuracy: 0.8165\n","---- Training ----\n","Training loss: 232.0712\n","Training acc over epoch: 0.8174\n","---- Validation ----\n","Validation loss: 70.7217\n","Validation acc: 0.7544\n","Time taken: 71.62s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 276.1212, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 259.0184, Accuracy: 0.8055\n","Training loss (for one batch) at step 20: 275.1533, Accuracy: 0.8243\n","Training loss (for one batch) at step 30: 280.4181, Accuracy: 0.8206\n","Training loss (for one batch) at step 40: 274.4850, Accuracy: 0.8244\n","Training loss (for one batch) at step 50: 261.8997, Accuracy: 0.8276\n","Training loss (for one batch) at step 60: 279.0751, Accuracy: 0.8262\n","Training loss (for one batch) at step 70: 266.4477, Accuracy: 0.8258\n","Training loss (for one batch) at step 80: 246.7224, Accuracy: 0.8272\n","Training loss (for one batch) at step 90: 263.9696, Accuracy: 0.8237\n","Training loss (for one batch) at step 100: 267.0291, Accuracy: 0.8229\n","Training loss (for one batch) at step 110: 250.1994, Accuracy: 0.8232\n","Training loss (for one batch) at step 120: 272.1264, Accuracy: 0.8221\n","Training loss (for one batch) at step 130: 269.3633, Accuracy: 0.8219\n","Training loss (for one batch) at step 140: 274.8252, Accuracy: 0.8206\n","---- Training ----\n","Training loss: 237.5782\n","Training acc over epoch: 0.8205\n","---- Validation ----\n","Validation loss: 74.7589\n","Validation acc: 0.7453\n","Time taken: 45.99s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 257.6081, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 266.4244, Accuracy: 0.8164\n","Training loss (for one batch) at step 20: 248.3438, Accuracy: 0.8238\n","Training loss (for one batch) at step 30: 249.7629, Accuracy: 0.8219\n","Training loss (for one batch) at step 40: 254.5240, Accuracy: 0.8222\n","Training loss (for one batch) at step 50: 275.6307, Accuracy: 0.8267\n","Training loss (for one batch) at step 60: 268.2240, Accuracy: 0.8293\n","Training loss (for one batch) at step 70: 283.9367, Accuracy: 0.8265\n","Training loss (for one batch) at step 80: 260.9476, Accuracy: 0.8253\n","Training loss (for one batch) at step 90: 269.2513, Accuracy: 0.8242\n","Training loss (for one batch) at step 100: 260.6063, Accuracy: 0.8224\n","Training loss (for one batch) at step 110: 256.6330, Accuracy: 0.8234\n","Training loss (for one batch) at step 120: 262.2977, Accuracy: 0.8239\n","Training loss (for one batch) at step 130: 258.6865, Accuracy: 0.8222\n","Training loss (for one batch) at step 140: 260.8006, Accuracy: 0.8216\n","---- Training ----\n","Training loss: 217.3291\n","Training acc over epoch: 0.8223\n","---- Validation ----\n","Validation loss: 72.3949\n","Validation acc: 0.7421\n","Time taken: 71.40s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 276.4825, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 259.5473, Accuracy: 0.8209\n","Training loss (for one batch) at step 20: 267.1228, Accuracy: 0.8214\n","Training loss (for one batch) at step 30: 240.8865, Accuracy: 0.8232\n","Training loss (for one batch) at step 40: 254.7351, Accuracy: 0.8259\n","Training loss (for one batch) at step 50: 267.2617, Accuracy: 0.8292\n","Training loss (for one batch) at step 60: 258.9462, Accuracy: 0.8302\n","Training loss (for one batch) at step 70: 272.0041, Accuracy: 0.8315\n","Training loss (for one batch) at step 80: 246.8758, Accuracy: 0.8285\n","Training loss (for one batch) at step 90: 258.6791, Accuracy: 0.8259\n","Training loss (for one batch) at step 100: 265.4581, Accuracy: 0.8258\n","Training loss (for one batch) at step 110: 270.8426, Accuracy: 0.8250\n","Training loss (for one batch) at step 120: 280.7317, Accuracy: 0.8236\n","Training loss (for one batch) at step 130: 257.4622, Accuracy: 0.8237\n","Training loss (for one batch) at step 140: 270.6691, Accuracy: 0.8224\n","---- Training ----\n","Training loss: 232.1438\n","Training acc over epoch: 0.8224\n","---- Validation ----\n","Validation loss: 61.9496\n","Validation acc: 0.7539\n","Time taken: 46.75s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 265.7611, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 242.0949, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 265.8304, Accuracy: 0.8333\n","Training loss (for one batch) at step 30: 270.2719, Accuracy: 0.8297\n","Training loss (for one batch) at step 40: 265.8326, Accuracy: 0.8305\n","Training loss (for one batch) at step 50: 251.3139, Accuracy: 0.8367\n","Training loss (for one batch) at step 60: 248.8955, Accuracy: 0.8321\n","Training loss (for one batch) at step 70: 243.8008, Accuracy: 0.8301\n","Training loss (for one batch) at step 80: 270.3539, Accuracy: 0.8284\n","Training loss (for one batch) at step 90: 239.1412, Accuracy: 0.8280\n","Training loss (for one batch) at step 100: 270.8295, Accuracy: 0.8265\n","Training loss (for one batch) at step 110: 251.3218, Accuracy: 0.8264\n","Training loss (for one batch) at step 120: 236.0970, Accuracy: 0.8281\n","Training loss (for one batch) at step 130: 244.9296, Accuracy: 0.8287\n","Training loss (for one batch) at step 140: 267.5606, Accuracy: 0.8278\n","---- Training ----\n","Training loss: 227.3950\n","Training acc over epoch: 0.8268\n","---- Validation ----\n","Validation loss: 69.4867\n","Validation acc: 0.7480\n","Time taken: 69.38s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 272.0812, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 245.1203, Accuracy: 0.8282\n","Training loss (for one batch) at step 20: 243.8790, Accuracy: 0.8271\n","Training loss (for one batch) at step 30: 263.6561, Accuracy: 0.8210\n","Training loss (for one batch) at step 40: 246.8000, Accuracy: 0.8251\n","Training loss (for one batch) at step 50: 242.7812, Accuracy: 0.8343\n","Training loss (for one batch) at step 60: 255.8884, Accuracy: 0.8334\n","Training loss (for one batch) at step 70: 248.4144, Accuracy: 0.8314\n","Training loss (for one batch) at step 80: 246.6351, Accuracy: 0.8275\n","Training loss (for one batch) at step 90: 271.6547, Accuracy: 0.8265\n","Training loss (for one batch) at step 100: 259.4817, Accuracy: 0.8273\n","Training loss (for one batch) at step 110: 240.5323, Accuracy: 0.8279\n","Training loss (for one batch) at step 120: 254.9436, Accuracy: 0.8278\n","Training loss (for one batch) at step 130: 238.9370, Accuracy: 0.8271\n","Training loss (for one batch) at step 140: 258.3929, Accuracy: 0.8269\n","---- Training ----\n","Training loss: 228.5497\n","Training acc over epoch: 0.8266\n","---- Validation ----\n","Validation loss: 74.4236\n","Validation acc: 0.7168\n","Time taken: 49.24s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 256.0342, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 254.4592, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 251.3453, Accuracy: 0.8190\n","Training loss (for one batch) at step 30: 257.1556, Accuracy: 0.8277\n","Training loss (for one batch) at step 40: 247.4315, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 241.7233, Accuracy: 0.8341\n","Training loss (for one batch) at step 60: 243.6523, Accuracy: 0.8359\n","Training loss (for one batch) at step 70: 264.5139, Accuracy: 0.8358\n","Training loss (for one batch) at step 80: 249.9616, Accuracy: 0.8356\n","Training loss (for one batch) at step 90: 252.9820, Accuracy: 0.8345\n","Training loss (for one batch) at step 100: 261.4125, Accuracy: 0.8334\n","Training loss (for one batch) at step 110: 247.1939, Accuracy: 0.8338\n","Training loss (for one batch) at step 120: 252.2254, Accuracy: 0.8340\n","Training loss (for one batch) at step 130: 245.3759, Accuracy: 0.8344\n","Training loss (for one batch) at step 140: 256.6851, Accuracy: 0.8345\n","---- Training ----\n","Training loss: 212.4499\n","Training acc over epoch: 0.8330\n","---- Validation ----\n","Validation loss: 69.2358\n","Validation acc: 0.7421\n","Time taken: 69.31s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 246.8632, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 247.7753, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 258.1092, Accuracy: 0.8419\n","Training loss (for one batch) at step 30: 233.8673, Accuracy: 0.8416\n","Training loss (for one batch) at step 40: 235.2881, Accuracy: 0.8449\n","Training loss (for one batch) at step 50: 250.0424, Accuracy: 0.8420\n","Training loss (for one batch) at step 60: 242.9477, Accuracy: 0.8398\n","Training loss (for one batch) at step 70: 253.6862, Accuracy: 0.8415\n","Training loss (for one batch) at step 80: 256.7579, Accuracy: 0.8391\n","Training loss (for one batch) at step 90: 230.7756, Accuracy: 0.8390\n","Training loss (for one batch) at step 100: 236.8679, Accuracy: 0.8377\n","Training loss (for one batch) at step 110: 264.4499, Accuracy: 0.8385\n","Training loss (for one batch) at step 120: 246.7062, Accuracy: 0.8389\n","Training loss (for one batch) at step 130: 256.0327, Accuracy: 0.8376\n","Training loss (for one batch) at step 140: 256.4574, Accuracy: 0.8365\n","---- Training ----\n","Training loss: 215.5723\n","Training acc over epoch: 0.8360\n","---- Validation ----\n","Validation loss: 76.6262\n","Validation acc: 0.7426\n","Time taken: 50.23s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 277.0906, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 262.1761, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 246.4196, Accuracy: 0.8471\n","Training loss (for one batch) at step 30: 238.4443, Accuracy: 0.8442\n","Training loss (for one batch) at step 40: 238.5031, Accuracy: 0.8478\n","Training loss (for one batch) at step 50: 252.5024, Accuracy: 0.8463\n","Training loss (for one batch) at step 60: 224.9248, Accuracy: 0.8487\n","Training loss (for one batch) at step 70: 246.4198, Accuracy: 0.8485\n","Training loss (for one batch) at step 80: 241.9708, Accuracy: 0.8452\n","Training loss (for one batch) at step 90: 254.1552, Accuracy: 0.8438\n","Training loss (for one batch) at step 100: 256.2594, Accuracy: 0.8432\n","Training loss (for one batch) at step 110: 246.4868, Accuracy: 0.8436\n","Training loss (for one batch) at step 120: 244.1653, Accuracy: 0.8432\n","Training loss (for one batch) at step 130: 290.4219, Accuracy: 0.8408\n","Training loss (for one batch) at step 140: 251.2270, Accuracy: 0.8408\n","---- Training ----\n","Training loss: 231.0719\n","Training acc over epoch: 0.8397\n","---- Validation ----\n","Validation loss: 86.7389\n","Validation acc: 0.7230\n","Time taken: 65.27s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 255.8387, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 225.8213, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 218.8719, Accuracy: 0.8386\n","Training loss (for one batch) at step 30: 241.3032, Accuracy: 0.8387\n","Training loss (for one batch) at step 40: 244.0343, Accuracy: 0.8415\n","Training loss (for one batch) at step 50: 256.6502, Accuracy: 0.8439\n","Training loss (for one batch) at step 60: 236.6000, Accuracy: 0.8451\n","Training loss (for one batch) at step 70: 241.3197, Accuracy: 0.8461\n","Training loss (for one batch) at step 80: 251.1613, Accuracy: 0.8435\n","Training loss (for one batch) at step 90: 244.2081, Accuracy: 0.8423\n","Training loss (for one batch) at step 100: 236.1856, Accuracy: 0.8434\n","Training loss (for one batch) at step 110: 223.7601, Accuracy: 0.8432\n","Training loss (for one batch) at step 120: 246.5681, Accuracy: 0.8431\n","Training loss (for one batch) at step 130: 231.0123, Accuracy: 0.8437\n","Training loss (for one batch) at step 140: 250.5249, Accuracy: 0.8416\n","---- Training ----\n","Training loss: 224.3437\n","Training acc over epoch: 0.8407\n","---- Validation ----\n","Validation loss: 74.3685\n","Validation acc: 0.7410\n","Time taken: 51.54s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 241.6153, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 253.2788, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 225.0560, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 227.9296, Accuracy: 0.8439\n","Training loss (for one batch) at step 40: 249.8547, Accuracy: 0.8427\n","Training loss (for one batch) at step 50: 223.9567, Accuracy: 0.8496\n","Training loss (for one batch) at step 60: 234.1541, Accuracy: 0.8498\n","Training loss (for one batch) at step 70: 241.9895, Accuracy: 0.8480\n","Training loss (for one batch) at step 80: 244.4040, Accuracy: 0.8448\n","Training loss (for one batch) at step 90: 239.4972, Accuracy: 0.8452\n","Training loss (for one batch) at step 100: 244.7682, Accuracy: 0.8441\n","Training loss (for one batch) at step 110: 250.7487, Accuracy: 0.8435\n","Training loss (for one batch) at step 120: 234.4897, Accuracy: 0.8438\n","Training loss (for one batch) at step 130: 243.3691, Accuracy: 0.8431\n","Training loss (for one batch) at step 140: 228.3394, Accuracy: 0.8443\n","---- Training ----\n","Training loss: 217.6007\n","Training acc over epoch: 0.8438\n","---- Validation ----\n","Validation loss: 79.2367\n","Validation acc: 0.7281\n","Time taken: 63.30s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 259.1945, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 223.3891, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 230.8128, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 231.3328, Accuracy: 0.8490\n","Training loss (for one batch) at step 40: 240.7964, Accuracy: 0.8473\n","Training loss (for one batch) at step 50: 229.8090, Accuracy: 0.8506\n","Training loss (for one batch) at step 60: 233.2526, Accuracy: 0.8497\n","Training loss (for one batch) at step 70: 236.0879, Accuracy: 0.8506\n","Training loss (for one batch) at step 80: 241.9864, Accuracy: 0.8510\n","Training loss (for one batch) at step 90: 236.8143, Accuracy: 0.8484\n","Training loss (for one batch) at step 100: 247.7609, Accuracy: 0.8485\n","Training loss (for one batch) at step 110: 226.1624, Accuracy: 0.8487\n","Training loss (for one batch) at step 120: 242.7240, Accuracy: 0.8496\n","Training loss (for one batch) at step 130: 246.0476, Accuracy: 0.8488\n","Training loss (for one batch) at step 140: 236.3339, Accuracy: 0.8482\n","---- Training ----\n","Training loss: 225.1215\n","Training acc over epoch: 0.8481\n","---- Validation ----\n","Validation loss: 75.7910\n","Validation acc: 0.7286\n","Time taken: 53.81s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 244.4957, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 234.6986, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 238.7920, Accuracy: 0.8452\n","Training loss (for one batch) at step 30: 245.8981, Accuracy: 0.8455\n","Training loss (for one batch) at step 40: 257.8392, Accuracy: 0.8459\n","Training loss (for one batch) at step 50: 247.9574, Accuracy: 0.8490\n","Training loss (for one batch) at step 60: 254.8295, Accuracy: 0.8505\n","Training loss (for one batch) at step 70: 232.8447, Accuracy: 0.8479\n","Training loss (for one batch) at step 80: 237.8924, Accuracy: 0.8427\n","Training loss (for one batch) at step 90: 240.3538, Accuracy: 0.8413\n","Training loss (for one batch) at step 100: 229.9748, Accuracy: 0.8424\n","Training loss (for one batch) at step 110: 227.2185, Accuracy: 0.8427\n","Training loss (for one batch) at step 120: 209.5623, Accuracy: 0.8431\n","Training loss (for one batch) at step 130: 220.3897, Accuracy: 0.8426\n","Training loss (for one batch) at step 140: 227.3054, Accuracy: 0.8421\n","---- Training ----\n","Training loss: 203.9045\n","Training acc over epoch: 0.8416\n","---- Validation ----\n","Validation loss: 69.1030\n","Validation acc: 0.7227\n","Time taken: 60.09s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 213.5802, Accuracy: 0.9200\n","Training loss (for one batch) at step 10: 235.1485, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 251.9877, Accuracy: 0.8538\n","Training loss (for one batch) at step 30: 232.8600, Accuracy: 0.8510\n","Training loss (for one batch) at step 40: 228.4192, Accuracy: 0.8510\n","Training loss (for one batch) at step 50: 208.7157, Accuracy: 0.8575\n","Training loss (for one batch) at step 60: 220.2924, Accuracy: 0.8582\n","Training loss (for one batch) at step 70: 243.8316, Accuracy: 0.8537\n","Training loss (for one batch) at step 80: 243.9522, Accuracy: 0.8507\n","Training loss (for one batch) at step 90: 230.8679, Accuracy: 0.8498\n","Training loss (for one batch) at step 100: 246.1116, Accuracy: 0.8501\n","Training loss (for one batch) at step 110: 234.1390, Accuracy: 0.8493\n","Training loss (for one batch) at step 120: 246.8664, Accuracy: 0.8498\n","Training loss (for one batch) at step 130: 263.2541, Accuracy: 0.8500\n","Training loss (for one batch) at step 140: 239.6235, Accuracy: 0.8507\n","---- Training ----\n","Training loss: 213.3511\n","Training acc over epoch: 0.8503\n","---- Validation ----\n","Validation loss: 70.8767\n","Validation acc: 0.7289\n","Time taken: 54.89s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 255.6301, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 228.9266, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 227.9070, Accuracy: 0.8538\n","Training loss (for one batch) at step 30: 231.9559, Accuracy: 0.8500\n","Training loss (for one batch) at step 40: 226.0088, Accuracy: 0.8510\n","Training loss (for one batch) at step 50: 256.7722, Accuracy: 0.8527\n","Training loss (for one batch) at step 60: 214.6650, Accuracy: 0.8552\n","Training loss (for one batch) at step 70: 237.6623, Accuracy: 0.8535\n","Training loss (for one batch) at step 80: 231.9537, Accuracy: 0.8517\n","Training loss (for one batch) at step 90: 230.2535, Accuracy: 0.8512\n","Training loss (for one batch) at step 100: 245.0045, Accuracy: 0.8488\n","Training loss (for one batch) at step 110: 237.9336, Accuracy: 0.8498\n","Training loss (for one batch) at step 120: 222.8438, Accuracy: 0.8509\n","Training loss (for one batch) at step 130: 240.9932, Accuracy: 0.8492\n","Training loss (for one batch) at step 140: 230.7503, Accuracy: 0.8492\n","---- Training ----\n","Training loss: 196.4485\n","Training acc over epoch: 0.8500\n","---- Validation ----\n","Validation loss: 84.7091\n","Validation acc: 0.7316\n","Time taken: 59.51s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 216.3004, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 246.1683, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 217.2094, Accuracy: 0.8524\n","Training loss (for one batch) at step 30: 246.5513, Accuracy: 0.8568\n","Training loss (for one batch) at step 40: 242.6228, Accuracy: 0.8532\n","Training loss (for one batch) at step 50: 218.4184, Accuracy: 0.8553\n","Training loss (for one batch) at step 60: 208.4032, Accuracy: 0.8564\n","Training loss (for one batch) at step 70: 224.3983, Accuracy: 0.8570\n","Training loss (for one batch) at step 80: 226.0243, Accuracy: 0.8540\n","Training loss (for one batch) at step 90: 240.9213, Accuracy: 0.8508\n","Training loss (for one batch) at step 100: 219.7956, Accuracy: 0.8511\n","Training loss (for one batch) at step 110: 218.1034, Accuracy: 0.8530\n","Training loss (for one batch) at step 120: 229.8796, Accuracy: 0.8515\n","Training loss (for one batch) at step 130: 218.8590, Accuracy: 0.8527\n","Training loss (for one batch) at step 140: 222.4816, Accuracy: 0.8513\n","---- Training ----\n","Training loss: 192.9897\n","Training acc over epoch: 0.8514\n","---- Validation ----\n","Validation loss: 70.8462\n","Validation acc: 0.7431\n","Time taken: 57.13s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 267.2434, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 218.1785, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 214.4615, Accuracy: 0.8638\n","Training loss (for one batch) at step 30: 224.0377, Accuracy: 0.8581\n","Training loss (for one batch) at step 40: 237.7624, Accuracy: 0.8568\n","Training loss (for one batch) at step 50: 228.3045, Accuracy: 0.8590\n","Training loss (for one batch) at step 60: 217.6089, Accuracy: 0.8570\n","Training loss (for one batch) at step 70: 212.1713, Accuracy: 0.8597\n","Training loss (for one batch) at step 80: 230.1659, Accuracy: 0.8573\n","Training loss (for one batch) at step 90: 254.7918, Accuracy: 0.8527\n","Training loss (for one batch) at step 100: 224.2519, Accuracy: 0.8527\n","Training loss (for one batch) at step 110: 233.6137, Accuracy: 0.8538\n","Training loss (for one batch) at step 120: 226.4637, Accuracy: 0.8555\n","Training loss (for one batch) at step 130: 221.4399, Accuracy: 0.8547\n","Training loss (for one batch) at step 140: 233.4846, Accuracy: 0.8533\n","---- Training ----\n","Training loss: 183.0642\n","Training acc over epoch: 0.8522\n","---- Validation ----\n","Validation loss: 70.7151\n","Validation acc: 0.7335\n","Time taken: 56.19s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 233.8235, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 212.6081, Accuracy: 0.8582\n","Training loss (for one batch) at step 20: 213.5287, Accuracy: 0.8533\n","Training loss (for one batch) at step 30: 227.9007, Accuracy: 0.8613\n","Training loss (for one batch) at step 40: 228.0869, Accuracy: 0.8590\n","Training loss (for one batch) at step 50: 220.6433, Accuracy: 0.8598\n","Training loss (for one batch) at step 60: 217.8183, Accuracy: 0.8620\n","Training loss (for one batch) at step 70: 243.0871, Accuracy: 0.8600\n","Training loss (for one batch) at step 80: 247.3833, Accuracy: 0.8557\n","Training loss (for one batch) at step 90: 251.6672, Accuracy: 0.8543\n","Training loss (for one batch) at step 100: 218.7553, Accuracy: 0.8524\n","Training loss (for one batch) at step 110: 220.2776, Accuracy: 0.8547\n","Training loss (for one batch) at step 120: 233.2729, Accuracy: 0.8550\n","Training loss (for one batch) at step 130: 231.0576, Accuracy: 0.8534\n","Training loss (for one batch) at step 140: 217.3413, Accuracy: 0.8533\n","---- Training ----\n","Training loss: 209.7606\n","Training acc over epoch: 0.8531\n","---- Validation ----\n","Validation loss: 85.5308\n","Validation acc: 0.7343\n","Time taken: 61.82s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 217.9160, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 219.3918, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 231.2528, Accuracy: 0.8562\n","Training loss (for one batch) at step 30: 202.6178, Accuracy: 0.8561\n","Training loss (for one batch) at step 40: 225.8084, Accuracy: 0.8566\n","Training loss (for one batch) at step 50: 213.6163, Accuracy: 0.8580\n","Training loss (for one batch) at step 60: 220.8907, Accuracy: 0.8574\n","Training loss (for one batch) at step 70: 222.5047, Accuracy: 0.8568\n","Training loss (for one batch) at step 80: 227.2559, Accuracy: 0.8560\n","Training loss (for one batch) at step 90: 223.6768, Accuracy: 0.8535\n","Training loss (for one batch) at step 100: 241.9527, Accuracy: 0.8538\n","Training loss (for one batch) at step 110: 223.0481, Accuracy: 0.8544\n","Training loss (for one batch) at step 120: 216.9584, Accuracy: 0.8535\n","Training loss (for one batch) at step 130: 241.9727, Accuracy: 0.8534\n","Training loss (for one batch) at step 140: 229.2938, Accuracy: 0.8535\n","---- Training ----\n","Training loss: 193.3904\n","Training acc over epoch: 0.8546\n","---- Validation ----\n","Validation loss: 66.6012\n","Validation acc: 0.7273\n","Time taken: 55.07s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 215.4482, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 227.6439, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 202.9946, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 224.3863, Accuracy: 0.8552\n","Training loss (for one batch) at step 40: 215.3178, Accuracy: 0.8593\n","Training loss (for one batch) at step 50: 227.8319, Accuracy: 0.8625\n","Training loss (for one batch) at step 60: 213.2877, Accuracy: 0.8616\n","Training loss (for one batch) at step 70: 213.3867, Accuracy: 0.8614\n","Training loss (for one batch) at step 80: 227.9424, Accuracy: 0.8588\n","Training loss (for one batch) at step 90: 232.0980, Accuracy: 0.8586\n","Training loss (for one batch) at step 100: 220.7150, Accuracy: 0.8580\n","Training loss (for one batch) at step 110: 195.0101, Accuracy: 0.8592\n","Training loss (for one batch) at step 120: 229.7917, Accuracy: 0.8588\n","Training loss (for one batch) at step 130: 243.2842, Accuracy: 0.8591\n","Training loss (for one batch) at step 140: 210.2522, Accuracy: 0.8584\n","---- Training ----\n","Training loss: 197.0641\n","Training acc over epoch: 0.8588\n","---- Validation ----\n","Validation loss: 65.6224\n","Validation acc: 0.7429\n","Time taken: 63.90s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 238.4746, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 230.3143, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 223.6493, Accuracy: 0.8495\n","Training loss (for one batch) at step 30: 222.8586, Accuracy: 0.8513\n","Training loss (for one batch) at step 40: 220.3348, Accuracy: 0.8563\n","Training loss (for one batch) at step 50: 228.5116, Accuracy: 0.8576\n","Training loss (for one batch) at step 60: 207.0388, Accuracy: 0.8595\n","Training loss (for one batch) at step 70: 241.3827, Accuracy: 0.8580\n","Training loss (for one batch) at step 80: 226.1390, Accuracy: 0.8557\n","Training loss (for one batch) at step 90: 214.9415, Accuracy: 0.8557\n","Training loss (for one batch) at step 100: 209.0433, Accuracy: 0.8556\n","Training loss (for one batch) at step 110: 221.9224, Accuracy: 0.8591\n","Training loss (for one batch) at step 120: 203.4293, Accuracy: 0.8579\n","Training loss (for one batch) at step 130: 210.0576, Accuracy: 0.8567\n","Training loss (for one batch) at step 140: 223.2287, Accuracy: 0.8570\n","---- Training ----\n","Training loss: 216.0514\n","Training acc over epoch: 0.8573\n","---- Validation ----\n","Validation loss: 75.0526\n","Validation acc: 0.7321\n","Time taken: 54.03s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 210.0832, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 213.5945, Accuracy: 0.8600\n","Training loss (for one batch) at step 20: 215.8032, Accuracy: 0.8643\n","Training loss (for one batch) at step 30: 222.8817, Accuracy: 0.8584\n","Training loss (for one batch) at step 40: 222.6540, Accuracy: 0.8590\n","Training loss (for one batch) at step 50: 212.5570, Accuracy: 0.8620\n","Training loss (for one batch) at step 60: 241.9197, Accuracy: 0.8641\n","Training loss (for one batch) at step 70: 242.6893, Accuracy: 0.8601\n","Training loss (for one batch) at step 80: 214.0489, Accuracy: 0.8596\n","Training loss (for one batch) at step 90: 215.5048, Accuracy: 0.8586\n","Training loss (for one batch) at step 100: 190.9990, Accuracy: 0.8588\n","Training loss (for one batch) at step 110: 227.5381, Accuracy: 0.8605\n","Training loss (for one batch) at step 120: 211.4626, Accuracy: 0.8589\n","Training loss (for one batch) at step 130: 225.6810, Accuracy: 0.8586\n","Training loss (for one batch) at step 140: 208.4209, Accuracy: 0.8585\n","---- Training ----\n","Training loss: 211.6571\n","Training acc over epoch: 0.8587\n","---- Validation ----\n","Validation loss: 75.7190\n","Validation acc: 0.7405\n","Time taken: 67.00s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 224.8729, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 207.7277, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 215.5733, Accuracy: 0.8624\n","Training loss (for one batch) at step 30: 207.2203, Accuracy: 0.8619\n","Training loss (for one batch) at step 40: 209.2862, Accuracy: 0.8641\n","Training loss (for one batch) at step 50: 207.7836, Accuracy: 0.8692\n","Training loss (for one batch) at step 60: 218.2404, Accuracy: 0.8661\n","Training loss (for one batch) at step 70: 207.7049, Accuracy: 0.8642\n","Training loss (for one batch) at step 80: 236.5039, Accuracy: 0.8621\n","Training loss (for one batch) at step 90: 208.1163, Accuracy: 0.8582\n","Training loss (for one batch) at step 100: 231.4270, Accuracy: 0.8556\n","Training loss (for one batch) at step 110: 196.9257, Accuracy: 0.8561\n","Training loss (for one batch) at step 120: 221.2243, Accuracy: 0.8567\n","Training loss (for one batch) at step 130: 206.7386, Accuracy: 0.8581\n","Training loss (for one batch) at step 140: 213.0825, Accuracy: 0.8574\n","---- Training ----\n","Training loss: 202.3738\n","Training acc over epoch: 0.8567\n","---- Validation ----\n","Validation loss: 81.5544\n","Validation acc: 0.7319\n","Time taken: 52.42s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 191.8417, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 215.4447, Accuracy: 0.8700\n","Training loss (for one batch) at step 20: 264.2191, Accuracy: 0.8714\n","Training loss (for one batch) at step 30: 229.9935, Accuracy: 0.8684\n","Training loss (for one batch) at step 40: 219.8963, Accuracy: 0.8651\n","Training loss (for one batch) at step 50: 211.9828, Accuracy: 0.8676\n","Training loss (for one batch) at step 60: 222.1944, Accuracy: 0.8670\n","Training loss (for one batch) at step 70: 201.8228, Accuracy: 0.8665\n","Training loss (for one batch) at step 80: 223.0892, Accuracy: 0.8635\n","Training loss (for one batch) at step 90: 195.3042, Accuracy: 0.8632\n","Training loss (for one batch) at step 100: 212.5520, Accuracy: 0.8624\n","Training loss (for one batch) at step 110: 220.4249, Accuracy: 0.8633\n","Training loss (for one batch) at step 120: 214.3669, Accuracy: 0.8631\n","Training loss (for one batch) at step 130: 240.6119, Accuracy: 0.8624\n","Training loss (for one batch) at step 140: 211.5039, Accuracy: 0.8625\n","---- Training ----\n","Training loss: 207.9323\n","Training acc over epoch: 0.8626\n","---- Validation ----\n","Validation loss: 48.7808\n","Validation acc: 0.7230\n","Time taken: 68.50s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 239.1552, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 215.0515, Accuracy: 0.8645\n","Training loss (for one batch) at step 20: 204.8672, Accuracy: 0.8681\n","Training loss (for one batch) at step 30: 210.7895, Accuracy: 0.8652\n","Training loss (for one batch) at step 40: 201.3899, Accuracy: 0.8688\n","Training loss (for one batch) at step 50: 204.3907, Accuracy: 0.8692\n","Training loss (for one batch) at step 60: 213.1714, Accuracy: 0.8669\n","Training loss (for one batch) at step 70: 200.3799, Accuracy: 0.8662\n","Training loss (for one batch) at step 80: 212.8331, Accuracy: 0.8642\n","Training loss (for one batch) at step 90: 205.2450, Accuracy: 0.8630\n","Training loss (for one batch) at step 100: 199.6923, Accuracy: 0.8632\n","Training loss (for one batch) at step 110: 227.0561, Accuracy: 0.8625\n","Training loss (for one batch) at step 120: 198.3493, Accuracy: 0.8626\n","Training loss (for one batch) at step 130: 209.1645, Accuracy: 0.8629\n","Training loss (for one batch) at step 140: 231.2700, Accuracy: 0.8618\n","---- Training ----\n","Training loss: 180.6710\n","Training acc over epoch: 0.8624\n","---- Validation ----\n","Validation loss: 84.7197\n","Validation acc: 0.7410\n","Time taken: 51.33s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 221.9289, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 187.0391, Accuracy: 0.8582\n","Training loss (for one batch) at step 20: 204.9850, Accuracy: 0.8629\n","Training loss (for one batch) at step 30: 204.6988, Accuracy: 0.8635\n","Training loss (for one batch) at step 40: 209.1958, Accuracy: 0.8649\n","Training loss (for one batch) at step 50: 222.0705, Accuracy: 0.8663\n","Training loss (for one batch) at step 60: 189.1868, Accuracy: 0.8667\n","Training loss (for one batch) at step 70: 211.6730, Accuracy: 0.8668\n","Training loss (for one batch) at step 80: 234.1201, Accuracy: 0.8643\n","Training loss (for one batch) at step 90: 225.8559, Accuracy: 0.8618\n","Training loss (for one batch) at step 100: 208.1099, Accuracy: 0.8621\n","Training loss (for one batch) at step 110: 192.4733, Accuracy: 0.8627\n","Training loss (for one batch) at step 120: 207.3810, Accuracy: 0.8622\n","Training loss (for one batch) at step 130: 231.5769, Accuracy: 0.8622\n","Training loss (for one batch) at step 140: 209.8936, Accuracy: 0.8623\n","---- Training ----\n","Training loss: 171.4940\n","Training acc over epoch: 0.8622\n","---- Validation ----\n","Validation loss: 77.5996\n","Validation acc: 0.7316\n","Time taken: 66.09s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 215.6532, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 196.9977, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 190.9654, Accuracy: 0.8643\n","Training loss (for one batch) at step 30: 208.2529, Accuracy: 0.8613\n","Training loss (for one batch) at step 40: 215.6306, Accuracy: 0.8620\n","Training loss (for one batch) at step 50: 208.1503, Accuracy: 0.8604\n","Training loss (for one batch) at step 60: 198.4570, Accuracy: 0.8575\n","Training loss (for one batch) at step 70: 217.2853, Accuracy: 0.8576\n","Training loss (for one batch) at step 80: 207.6673, Accuracy: 0.8569\n","Training loss (for one batch) at step 90: 208.2173, Accuracy: 0.8569\n","Training loss (for one batch) at step 100: 238.3291, Accuracy: 0.8555\n","Training loss (for one batch) at step 110: 198.5829, Accuracy: 0.8575\n","Training loss (for one batch) at step 120: 228.1394, Accuracy: 0.8591\n","Training loss (for one batch) at step 130: 231.0985, Accuracy: 0.8579\n","Training loss (for one batch) at step 140: 214.2993, Accuracy: 0.8578\n","---- Training ----\n","Training loss: 195.8482\n","Training acc over epoch: 0.8588\n","---- Validation ----\n","Validation loss: 70.9614\n","Validation acc: 0.7378\n","Time taken: 54.83s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 215.0208, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 211.5710, Accuracy: 0.8691\n","Training loss (for one batch) at step 20: 215.3608, Accuracy: 0.8652\n","Training loss (for one batch) at step 30: 235.3496, Accuracy: 0.8694\n","Training loss (for one batch) at step 40: 199.7101, Accuracy: 0.8680\n","Training loss (for one batch) at step 50: 203.6368, Accuracy: 0.8702\n","Training loss (for one batch) at step 60: 202.3418, Accuracy: 0.8648\n","Training loss (for one batch) at step 70: 227.0818, Accuracy: 0.8663\n","Training loss (for one batch) at step 80: 206.1741, Accuracy: 0.8651\n","Training loss (for one batch) at step 90: 201.0674, Accuracy: 0.8646\n","Training loss (for one batch) at step 100: 207.4842, Accuracy: 0.8646\n","Training loss (for one batch) at step 110: 225.7283, Accuracy: 0.8659\n","Training loss (for one batch) at step 120: 199.6247, Accuracy: 0.8657\n","Training loss (for one batch) at step 130: 218.7323, Accuracy: 0.8653\n","Training loss (for one batch) at step 140: 203.7116, Accuracy: 0.8640\n","---- Training ----\n","Training loss: 194.4820\n","Training acc over epoch: 0.8642\n","---- Validation ----\n","Validation loss: 70.2130\n","Validation acc: 0.7308\n","Time taken: 63.98s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 230.8803, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 197.1341, Accuracy: 0.8773\n","Training loss (for one batch) at step 20: 196.8264, Accuracy: 0.8771\n","Training loss (for one batch) at step 30: 205.3613, Accuracy: 0.8735\n","Training loss (for one batch) at step 40: 209.0168, Accuracy: 0.8761\n","Training loss (for one batch) at step 50: 220.6655, Accuracy: 0.8743\n","Training loss (for one batch) at step 60: 205.7396, Accuracy: 0.8716\n","Training loss (for one batch) at step 70: 211.4763, Accuracy: 0.8693\n","Training loss (for one batch) at step 80: 220.8356, Accuracy: 0.8674\n","Training loss (for one batch) at step 90: 209.3886, Accuracy: 0.8638\n","Training loss (for one batch) at step 100: 224.1730, Accuracy: 0.8638\n","Training loss (for one batch) at step 110: 198.9174, Accuracy: 0.8658\n","Training loss (for one batch) at step 120: 224.3681, Accuracy: 0.8648\n","Training loss (for one batch) at step 130: 220.3005, Accuracy: 0.8661\n","Training loss (for one batch) at step 140: 230.1022, Accuracy: 0.8649\n","---- Training ----\n","Training loss: 175.7946\n","Training acc over epoch: 0.8645\n","---- Validation ----\n","Validation loss: 51.7637\n","Validation acc: 0.7316\n","Time taken: 54.96s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 215.2122, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 190.4184, Accuracy: 0.8682\n","Training loss (for one batch) at step 20: 198.8093, Accuracy: 0.8695\n","Training loss (for one batch) at step 30: 206.8180, Accuracy: 0.8690\n","Training loss (for one batch) at step 40: 221.2284, Accuracy: 0.8698\n","Training loss (for one batch) at step 50: 224.2672, Accuracy: 0.8702\n","Training loss (for one batch) at step 60: 208.2581, Accuracy: 0.8723\n","Training loss (for one batch) at step 70: 208.7904, Accuracy: 0.8703\n","Training loss (for one batch) at step 80: 210.7225, Accuracy: 0.8693\n","Training loss (for one batch) at step 90: 200.7899, Accuracy: 0.8679\n","Training loss (for one batch) at step 100: 226.8988, Accuracy: 0.8659\n","Training loss (for one batch) at step 110: 198.1590, Accuracy: 0.8678\n","Training loss (for one batch) at step 120: 202.0061, Accuracy: 0.8683\n","Training loss (for one batch) at step 130: 206.7579, Accuracy: 0.8684\n","Training loss (for one batch) at step 140: 199.1331, Accuracy: 0.8680\n","---- Training ----\n","Training loss: 187.1591\n","Training acc over epoch: 0.8676\n","---- Validation ----\n","Validation loss: 81.6912\n","Validation acc: 0.7308\n","Time taken: 94.50s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 219.1730, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 208.4199, Accuracy: 0.8700\n","Training loss (for one batch) at step 20: 200.9400, Accuracy: 0.8786\n","Training loss (for one batch) at step 30: 214.1836, Accuracy: 0.8700\n","Training loss (for one batch) at step 40: 210.3602, Accuracy: 0.8744\n","Training loss (for one batch) at step 50: 207.3212, Accuracy: 0.8749\n","Training loss (for one batch) at step 60: 190.6501, Accuracy: 0.8748\n","Training loss (for one batch) at step 70: 209.0744, Accuracy: 0.8724\n","Training loss (for one batch) at step 80: 203.5255, Accuracy: 0.8690\n","Training loss (for one batch) at step 90: 212.0255, Accuracy: 0.8696\n","Training loss (for one batch) at step 100: 192.4191, Accuracy: 0.8690\n","Training loss (for one batch) at step 110: 203.2726, Accuracy: 0.8701\n","Training loss (for one batch) at step 120: 198.3244, Accuracy: 0.8698\n","Training loss (for one batch) at step 130: 206.4267, Accuracy: 0.8685\n","Training loss (for one batch) at step 140: 200.6184, Accuracy: 0.8671\n","---- Training ----\n","Training loss: 173.5077\n","Training acc over epoch: 0.8671\n","---- Validation ----\n","Validation loss: 88.4884\n","Validation acc: 0.7386\n","Time taken: 57.19s\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABpTUlEQVR4nO2dd3xUxfbAvyd1Q3qhhJoAoUoNRUCRqogKFkCwgfpsz97Lz6eI+p5dn115KlbAThFsFEEBqaGGEkKA0AmkQEif3x9zk2wgPbvZZJnv57Of3Tt3Zu6Zzc09O2fmnCNKKQwGg8FgAPBwtQAGg8FgqDsYpWAwGAyGIoxSMBgMBkMRRikYDAaDoQijFAwGg8FQhFEKBoPBYCjCKAWDoQqIyCARSXa1HAaDszBKwVBriEiSiAxztRwGg6FsjFIwGNwEEfFytQyG+o9RCgaXIyK+IvKGiOy3Xm+IiK91LkJE5opIqogcE5GlIuJhnXtURPaJSIaIbBORoWX0f4mIrBORdBHZKyKT7c5FiYgSkYkiskdEjorI/9md9xORaSJyXES2AL0rGMt/rWuki8gaETnf7pyniDwhIjstmdeISAvrXGcR+c0a4yERecIqnyYiz9n1UcJ8Zc2+HhWRDcBJEfESkcfsrrFFRK44TcZbRCTe7nxPEXlYRL47rd6bIvLf8sZrcEOUUuZlXrXyApKAYaWUTwFWAI2AhsAy4Fnr3H+A9wFv63U+IEB7YC/Q1KoXBbQp47qDgC7oH0FdgUPA5XbtFDAV8AO6AdlAR+v8C8BSIAxoAWwCkssZ43VAOOAFPAgcBGzWuYeBjZbsYl0rHAgEDlj1bdZxX6vNNOC508aSfNp3GmfJ5meVjQWaWuO9GjgJRNqd24dWbgK0BVoBkVa9EKueF3AYiHX1fWNetftyuQDmdfa8ylEKO4GRdscXAUnW5ynALKDtaW3aWg+tYYB3FeV4A3jd+lyoFJrbnV8JjLc+JwIj7M7dWp5SKOVax4Fu1udtwOhS6kwA1pXRvjJK4aYKZIgrvC7wC3BvGfXmA7dYny8Ftrj6njGv2n8Z85GhLtAU2G13vNsqA3gZSAB+FZFEEXkMQCmVANwHTAYOi8gMEWlKKYhIXxFZJCJHRCQNuB2IOK3aQbvPmUCAnWx7T5OtTETkIcs0kyYiqUCw3bVaoBXg6ZRVXlns5UNEbhCROMvklgqcUwkZAD5Fz3Sw3j+vgUyGeopRCoa6wH60CaOQllYZSqkMpdSDSqnWwCjggcK1A6XUV0qp86y2CnixjP6/AmYDLZRSwWhzlFRStgPoB6m9bKVirR88AowDQpVSIUCa3bX2Am1KaboXaF1GtyeBBnbHTUqpUxTqWERaoU1hdwHhlgybKiEDwI9AVxE5Bz1T+LKMegY3xigFQ23jLSI2u5cXMB14UkQaikgE8BTwBYCIXCoibUVE0A/YfKBARNqLyBBrQToLOAUUlHHNQOCYUipLRPoA11RB3q+Bx0UkVESaA3eXUzcQyAOOAF4i8hQQZHf+f8CzIhIjmq4iEg7MBSJF5D5r0T1QRPpabeKAkSISJiJN0LOj8vBHK4kjACJyI3qmYC/DQyISa8nQ1lIkKKWygG/RSnSlUmpPBdcyuCFGKRhqm3noB3jhazLwHLAa2IBeiF1rlQHEAL8DJ4DlwLtKqUWAL3oR+Cja9NMIeLyMa/4TmCIiGWiF83UV5H0GbTLaBfxK+SaVX4Cfge1WmyxKmnZes679K5AOfIReHM4AhgOXWWPZAQy22nwOrEevHfwKzCxPWKXUFuBV9Hd1CL3A/pfd+W+A59EP/gz07CDMrotPrTbGdHSWIkqZJDsGg0EjIi2BrUATpVS6q+Ux1D5mpmAwGACw/D8eAGYYhXD2YjwgDQYDIuKPNjftBka4WByDCzHmI4PBYDAUYcxHBoPBYCjCKAWDwWAwFGGUgsFgMBiKMErBYDAYDEUYpWAwGAyGIoxSMBgMBkMRRikYDAaDoQijFAwGg8FQhFEKBoPBYCjCKAWDwWAwFGGUgsFgMBiKMErBYDAYDEUYpWAwGAyGIoxSMBgMBkMR9TqfQkREhIqKiio6PnnyJP7+/q4TqBZw9zHWpfGtWbPmqFKqoSuufbbd2+4+PqhbYyzv3q7XSiEqKorVq1cXHS9evJhBgwa5TqBawN3HWJfGJyK7XXXts+3edvfxQd0aY3n3tjEfGQwGg6EIoxQMBoPBUITTlYKIeIrIOhGZax1Hi8jfIpIgIjNFxMcq97WOE6zzUc6WzWAwGAwlqY01hXuBeCDIOn4ReF0pNUNE3gduBt6z3o8rpdqKyHir3tW1IJ9Dyc3NJTk5maysLKf0HxwcTHx8vFP6rgu4Ynw2m43mzZvj7e1dq9c1GOoiTlUKItIcuAR4HnhARAQYAlxjVfkUmIxWCqOtzwDfAm+LiCillDNldDTJyckEBgYSFRWFHq5jycjIIDAw0OH91hVqe3xKKVJSUkhOTiY6OrrWrmsw1FWcPVN4A3gEKPwvDwdSlVJ51nEy0Mz63AzYC6CUyhORNKv+UfsOReRW4FaAxo0bs3jx4qJzJ06cKHHsCoKDgwkPD+fEiRNO6T8/P5+MjAyn9F0XcMX4fHx8SE1Ndfm9YzDUBZymFETkUuCwUmqNiAxyVL9KqQ+BDwF69eql7Ld41YUtX/Hx8QQFBVVcsZqYmYJzsNls9OjRo9avazDUNZw5UxgAjBKRkYANvabwXyBERLys2UJzYJ9Vfx/QAkgWES8gGEipzoV/3nSQ5OOZ/OP81jUdg8FgMNQLtuxPZ9G2w4Q28KFhoC+RwTbOaRZc5X6cphSUUo8DjwNYM4WHlFLXisg3wBhgBjARmGU1mW0dL7fOL6zuesLibYf5Pf6wUQoGg8HtycjK5bXftvPpsiQK7J6YbRsF8PsDF1S5P1d4ND8KzBCR54B1wEdW+UfA5yKSABwDxlf3As1D/Th6Ipus3Hxs3p41Frg+kZKSwtChQwE4ePAgnp6eNGyovdlXrlyJj49PmW1Xr17NZ599xptvvlnuNfr378+yZcscJvO0adNYvXo1b7/9tsP6NBjclcycPN5amMCeY5mkn8ol/kA6KSdzuK5vK+4dFkNufgFHMrLJzS+oVv+1ohSUUouBxdbnRKBPKXWygLGOuF7z0AYAJB8/RdtGAY7ost4QHh5OXFwcAJMnTyYgIICHHnqo6HxeXh5eXqX/2Xv16kWvXr0qvIYjFYLBYIA1u4/x3uKdeHt64O/rRYCvFzZvT/y8PenbOoxzW4cDkJ2Xz22fr+GvhKNEhfsT5OdNbKtQ/jmoLd1ahBT1FxnsV21Z6nXso7JoHqq/kL3HM12qFJ6Zs5kt+9Md2mdMhB/PXdW9Sm0mTZqEzWZj3bp1DBgwgPHjx3PvvfeSlZWFn58fn3zyCe3bt2fx4sW88sorzJ07l8mTJ7Nnzx4SExPZs2cP9913H/fccw8AAQEBRTu9Jk+eTEREBJs2bSI2NpYvvvgCEWHevHk88MAD+Pv7M2DAABITE5k7d26Fsu7evZt77rmHo0eP0rBhQz755BNatmzJN998wzPPPIOnpyfBwcEsWbKEzZs3c+ONN5KTk0NBQQHfffcdMTEx1flaDQaXkXD4BDd+sgofLw/C/H04kZXHiew8svIKyMnTv/Yn9GnBoyM68Nh3G1m64ygvjenKuF4tnCKPmyqF4pmCQZOcnMyyZcvw9PQkPT2dpUuX4uXlxe+//84TTzzBd999d0abrVu3smjRIjIyMmjfvj133HHHGQ5e69atY/PmzTRt2pQBAwbw119/0atXL2677TaWLFlCdHQ0EyZMqLScDz/8MBMnTmTixIl8/PHH3HPPPfz4449MmTKFX375hWbNmpGamgrA+++/z7333su1115LTk4O+fn5NfqODAZHMm/jAXYdPcnAmIZ0bhpEboHizx1HWb37GN1ahDAwpiGpmTncNE0rhB/+OYAWYQ1K9JGVm8/rv29n6pJEfli3j6zcAp66tJPTFAK4qVJoFOiLj6cHycczXSrH05d1dnif1d3DP3bsWDw99fpKWloaEydOZMeOHYgIubm5pba55JJL8PX1xdfXl0aNGnHo0CGaN29eok6fPn2Kyrp3705SUhIBAQG0bt26yBlswoQJfPjhh5WSc+XKlcyePRuA66+/nkceeQSAAQMGMGnSJMaNG8eVV14JQL9+/Xj++edJTk7myiuvNLMEQ50gL7+A536KZ9qyJABe/mUbEQG+pJ/KJif/76J6zUL8CPD14lB6FtNvPfcMhQBg8/bk8Ys7MqJzE6bM3cKFnZpw03nOdbJ0S6Xg4SE0C/UzMwU77OO4/+tf/2Lw4MH88MMPJCUllenb4evrW/TZ09OTvLy8atVxBO+//z5///03P/30E7GxsaxZs4ZrrrmGvn378tNPPzFy5Eg++OADhgwZ4pTrGwyV4WBaFg9/u56lO45y83nR3DawNUt3HGXpjiNkHDvMNYO706tVGH/tPMr0lXtYkZjCG1f3oGfL0HL77dEylB/+OaBWxuCWSgH0uoJRCqWTlpZGs2bakXzatGkO7799+/YkJiaSlJREVFQUM2fOrHTbvn37MmPGDK6//nq+/PJLzj//fAB27txJ37596du3L/Pnz2fv3r2kpaXRunVr7rnnHvbs2cOGDRucphREZATaz8YT+J9S6oXTzrdEh20Jseo8ppSaZwV2jAe2WVVXKKVud4qQhlpFKcWRjGy2Hswgbm8qC+IPsT45DW9P4aWrujKutzbxXBXbnKtim2vn2o6NARjZJZKRXSLJyy/Ay7NuBat2a6Xw6+ZDrhajTvLII48wceJEnnvuOS655BKH9+/n58e7777LiBEj8Pf3p3fv3pVu+/LLL3P33Xfz8ssvFy00g15r2LFjB0ophg4dSrdu3XjxxRf5/PPP8fb2pkmTJjzxxBMOHwvoSL/AO8BwdGiWVSIyWym1xa7ak8DXSqn3RKQTMA+Iss7tVEp1d4pwhlpBKcWeY5ks25lC/IF0th7MYPuhDFIzi02v3VuE8PBF7RnZJZLoiMplWKtrCgFA6lm8uRL06tVLlZWd6p1FCbz8yza2TLmIBj61p/vi4+Pp2LGj0/qvL2EuTpw4QUBAAEop7rzzTmJiYrj//vsrbOeq8ZX2dxORNUqpXiLSD5islLrIKn8cQCn1H7u6HwCJSqkXrfqvKqX6WzOFuUqpc6oiT3n3tjtS18Y3dUki36/bh7+PJ/6+Xuw8cqLI8hDo60W7JoG0axxIB7v3UP+yfYCgbo2x8N4u7ZxbzxQA9h0/RUzjuv8QdTemTp3Kp59+Sk5ODj169OC2225ztUg1oShYo0Uy0Pe0OpOBX0XkbsAfGGZ3LlpE1gHpwJNKqaWlXaSuB3t0Jq4a38GTBSxNzuOS1t408Jaishf+PEWkv4CPkHIcGtmEQR196BTuSaS/IJIDpEBOCtl7Yf3e8q8D9edv6MZKoXhbqlEKtc/9999/xszgk08+4b///W+JsgEDBvDOO+/UpmjOYgIwTSn1qjVT+FxEzgEOAC2VUikiEgv8KCKdlVJnOLDU9WCPzsQV41uVdIwXPltNamYu+Q3Cee+6nogIN01bhZ9PLj/cO4iGgb4Vd1RJ6svf0G2VQgs7BzZD3eDGG2/kxhtvdLUY1aEwWGMh9oEcC7kZGAGglFouIjYgQil1GMi2yteIyE6gHbAag8uYFbePh7/ZQPNQP8b1asGHSxL56M9dtGkUwMKth3liZAeHKoT6hNsqhYgAX3y8PMwOJIMjWAXEiEg0WhmMpzhRVCF7gKHANBHpiI4MfEREGgLHlFL5ItIaiAESa090gz2H07N47qd4Zq/fT5/oMD68PpZgP2/2pGTyn/lbaRToS3SEP5P6n70Jl9xWKXh4iLUt1cwUDDXDSvp0F/ALervpx0qpzSIyBVitlJoNPAhMFZH7AQVMUkopERkITBGRXKAAuF0pdcxFQzkrScvMZcuBdFYlHWPqkkSy8wu4b1gMdwxqg6+Xduh8aWxXRr31J0kpmXw8qRc+XnVvV1Bt4bZKAfS6gpkpGByBUmoeepupfdlTdp+3oHOInN7uO+DMGCIGp7P3WCYPfrOelbuKdfDAdg15ZlTnM7aMBtm8+eymvqzefYzB7RvVtqh1CjdXCn5s2pfmajEMBkMt89OGAzz2/QZQ8MDwdnRrEULHyEAaBdrKbNMyvAEtw88MNXG24dZzpOahfhw7mcPJbOeEXqiLDB48mF9++aVE2RtvvMEdd9xRav1BgwZRuB9+5MiRRcHm7Jk8eTKvvPJKudf98ccf2bKl2Jfrqaee4vfff6+i9GUzbdo07rrrLof1Z3BPjmRk88DMOO78ai1tGgbw0z3nc8/QGC5o17BchWAoxs2VwtkXLXXChAnMmDGjRNmMGTMqFal03rx5hISEVOu6pyuFKVOmMGzYsHJaGAyOIy+/gI//3MWQVxYzZ8N+7h7Slm9u72d++VcDtzYfFW5LTT6eSfsmLvBVmP8YHNzo0C59w9vDqNfKPD9mzBiefPJJcnJy8PHxISkpif379zN9+nQeeOABTp06xZgxY3jmmWfOaBsVFcXq1auJiIjg+eef59NPP6VRo0a0aNGC2NhYQDulffjhh+Tk5NC2bVs+//xz4uLimD17Nn/88QfPPfcc3333Hc8++yyXXnopY8aMYcGCBTz00EPk5eXRu3dv3nvvPXx9fYmKimLixInMmTOH3Nxcvvnmm6KYTOWRlJTETTfdZHIuGIr416zNTF+5h4HtGjL5sk60bnh2JddyJGam4GaEhYXRp08f5s+fD+hZwrhx43j++edZvXo1GzZs4I8//mDDhg1l9rFmzRpmzJhBXFwc8+bNY9WqVUXnrrzySlatWsX69evp2LEjH330Ef3792fUqFG8/PLLxMXF0aZNm6L6WVlZTJo0iZkzZ7Jx40by8vJ47733is5HRESwdu1a7rjjjgpNVIXcfffdTJw4kQ0bNnDttdcWJf8pzLmwfv36ovDbhTkX4uLiWL169Rmhvw31n+kr9zB95R5uu6A1n97Y2yiEGuLWM4WIAB98vTzYe8xF21IvfqHiOlUkOyOD8iOsFJuQRo8ezYwZM/joo4/4+uuv+fDDD8nLy+PAgQNs2bKFrl27ltp+6dKlXHHFFTRooJXqqFGjis5t2rSJJ598ktTUVE6cOMFFF11Urizbtm0jOjqadu3aATBx4kTeeecd7rvvPoCi3AixsbF8//33lfgGYPny5UV1Tc6Fs5t1e47z9KzNnB8TwSMXdUBEXC1SvcdpMwURsYnIShFZLyKbReQZq3yaiOwSkTjr1d0qFxF5U0QSRGSDiPR0gAy0CGvAblcpBRcxevRoFixYwNq1a8nMzCQsLIxXXnmFBQsWsGHDBi655BKysrKq1fekSZN4++232bhxI08//XS1+ymkMB+DI3IxvP/++zz33HPs3buX2NhYUlJSuOaaa5g9ezZ+fn6MHDmShQsX1ugaBtdyOD2Lu75ayw0fr+S2z1dzy2draBTky5vje+DpYRSCI3Cm+SgbGKKU6gZ0B0aIyLnWuYeVUt2tV5xVdjHa2zMGHRTsPRxAl2bBxO1NpT5Hg60qAQEBDB48mJtuuokJEyaQnp6Ov78/wcHBHDp0qMi0VBYDBw7kxx9/5NSpU2RkZDBnzpyicxkZGURGRpKbm8uXX35ZVB4YGFhqVrj27duTlJREQkICAJ9//jkXXHBBjcbXv3//osX00nIuTJkyhYYNG7J3714SExOLci6MHj26XLOZoW6z41AGV7y7jAXxh0k/lcvulEyahtj48PpeFUYoNVQep5mPlH4Kn7AOva1XeU/m0cBnVrsVIhIiIpFKqQM1kaNnq1B+WLeP5OOnSk13565MmDCBK664ghkzZtChQwd69OhBhw4daNGiBQMGlJ/BqWfPnlx99dV069aNRo0alciH8Oyzz9K3b18aNmxI3759ixTB+PHjueWWW3jzzTf59ttvi+rbbDY++eQTxo4dW7TQfPvtNcsx89Zbb3HjjTfWqZwLBsdzMC2LpJST5BcoDmdk8dSszdi8Pfnm9n6c0yzY1eK5L0opp73QIQHi0MrhRatsGjoL1QbgdcDXKp8LnGfXdgHQq7z+Y2NjlT2LFi1Sp7N5X5pq9ehc9cPa5DPOOYMtW7Y4tf/09HSn9u9qXDW+0v5u6BAWTv0fKetVmXvbnSgc38nsXDVz5R41/oPlKuqxuarVo8Wvoa8uVnuPnXStoDWgLv0Ny7u3nbrQrJTKB7qLSAjwgxVK+HHgIOCDDhP8KDClsn1WNeZ8gVLYPGH28k2EpO2oyXAqRXBwcKlmFEeRn5/v1P5djavGl5WVVS9i3bszv285xFOzNrE/LYvoCH/uHRpDn6gwvDw98PQQOkUG4efj6Wox3Z5a2X2klEoVkUXACKVU4b7DbBH5BHjIOq5MeOJqxZzvnfg3B0/kMGjQ+TUfTAXEx8c7NXNYfcm8Vl3ee+89PvjggxJltZFzwWaz0aNHD6dew1A6h9OzeGtdFmsOraZd4wCmjzuXc1uHmZ1ELsJpSsEKGZxrKQQ/dH7bFwvXCUT/xS8HNllNZgN3icgMdFarNFXD9YRCerYM5a2FOziRnUeAr/P1oFLK3NDV5LrrriszJIezUGfRJoS6xs+bDvL49xs4kZXPIyPa84/zWp/VEUrrAs58QkYCn1pJzz3QSc3nishCS2EIer2hcNVxHjASSAAyAYdlY4ltFUqBgrg9qZwXE+GobkvFZrORkpJCeHi4UQz1AKUUKSkp2GwmLk5tkpNXwL9+3MTM1Xs5p1kQ10R7cc2gtq4Wy4Bzdx9tAM6YjyulhpRRXwF3OkOW7i1DEIE1u487XSk0b96c5ORkjhw54pT+s7Ky3PoB5orx2Ww24+lciyileGqWVgh3DGrD/cPasezPJa4Wy2Dh1h7NhQTZvGnfOJA1e447/Vre3t5ERzsva9PixYvd2vbt7uMzwGfLdzNj1V7uHNyGhy/q4GpxDKdx1hjverYKZd3u4xQUGPuxweAqliUcZcrcLQzr2IgHh7d3tTiGUjhrlEJsy1AysvPYcfhExZUNBoNDSTuVy2u/beeWz1bTpqE/r1/dHQ8TlqJOclaYjwB6RYUCsHr3MdeE0TYYzlI+XZbEK79uIyMrjxGdm/CvyzoRaPN2tViGMjhrZgotwxoQ2sCbDXtNek5D1RGRESKyzQrY+Fgp51uKyCIRWWcFdBxpd+5xq902ESk/rKybMStuH0/P3kz3FiH8dM95vH99LM1C/FwtlqEczpqZgojQuWkwmw8YpWCoGta26nfQvjbJwCoRma2U2mJX7Un0tuv3RKQTeot1lPV5PNAZaAr8LiLtLG9/tyIzJ4/4Axn0aBGCh4ewaV8aj3y7gT5RYXw0sbfxP6gnnDVKAaBz0yA++SuJ3PwCvD3NDWqoNH2ABKVUIoDlYDkasFcKCgiyPgcD+63Po4EZSqlsYJeIJFj9La8NwWuTKXO2MGPVXqLCG3BN35ZM+yuJcH8f3r2up1EI9YizSil0ahpETn4BOw6doFPToIobGAyaZsBeu+NktNe9PZOBX0XkbsAfKExQ3QxYcVrbUnOOVjWuV13i6KkCvll9ii4RnpzKy+Lf87bi4wFP9LWxaXXF+q+uj88R1JcxnlVKoXNTHW530/40oxQMjmYCME0p9aqI9AM+twJAVprqxPWqKzz540Y8PPbywT8uoGmIH5v2aTNtZUNc1/XxOYL6MsazSilER/jTwMeTLfvTXS2KoX5RmWCNNwMjAJRSy0XEBkRUsm295mBaFl+vSmZMbAuaWovIJt9B/eWsMvR5eggdI4PYvN8sNhuqxCogRkSiRcQHvXA8+7Q6e4ChACLSEbABR6x640XEV0Si0ZkFV9aa5LXA+3/sJF8p/jmojatFMTiAs0opgF5s3rI/3Xg2GyqNUioPuAv4BYhH7zLaLCJTRGSUVe1B4BYRWQ9MByZZ+Uw2A1+jF6V/Bu50p51HhzOymL5yD1f0aHZWZTZ0Z84q8xFopfDZ8nx2H8skOsLf1eIY6glKqXnobab2ZU/Zfd4ClJrnVCn1PPC8UwV0ER//qXfz3TnYRDh1F87CmYK2dRoTksFQM9KzcvlyxW4u7hJpfmC5EWedUohpHICXh7DZLDYbDDXiyxV7yMjO444LzFqCO3HWKQVfL09iGgcWbZkzGAxVJys3n4/+3MX5MRFmp5GbcdYpBYBzrMVmk4bRYKge36/dx9ET2WaW4IaclUqhc9MgUk7msG5vKgviDzErbp9REAZDJcnOy+fDJTvp1jyYfm3CXS2OwcGcdbuPADpb090r311WVNYw0Jf+bZybqtNgqO+kncrlts9Xk5SSyUcTe5k85G7IWakUerYM5YmRHQjw9SY6wp8bp63k182HjFIwGMrhQNopJn28isSjJ/jv+O4M7djY1SIZnIDTzEciYhORlSKyXkQ2i8gzVnm0iPxtxZefaXmIYnl8zrTK/xaRKGfJ5ukh3DqwDdf0bUm/NuGcH9OQXzcfNCYkg6EMFm49xOi3/2Jf6imm3diH0d1LjelncAOcuaaQDQxRSnUDugMjRORc4EXgdaVUW+A4OmYM1vtxq/x1q16tcFHnJuxPy2Kj2ZFkMJQgLTOXB76O46Zpqwlt4MO3d/RjQFszo3ZnnKYULBf/woTI3tZLAUOAb63yT4HLrc+jrWOs80OllgyWwzo2wtND+GXzwdq4nMFQb7j501XMjtvPPUPaMufu8+jQxEQXdnecuqZgZaxaA7RFZ67aCaRasWSgZGz5opj1Sqk8EUkDwoGjp/XplJjz7UKEH1Ym0tu3biuG+hKTvbq4+/jqExuT01i9+zhPXdqJm86LdrU4hlrCqUrBCvzVXURCgB+ADg7o0ykx53f7JPH07M206NyLNg0DyM0vIL9AYfP2rKnIDqW+xGSvLu4+vvrEVyt3Y/P24KrY5q4WxVCL1IqfglIqFVgE9ANCRKRQGdnHli+KO2+dDwZSakM+gAs7650UP286yA/rkjnvxYVcM3VFBa0MBvckIyuXWXH7GdWtKcF+3rowfg4cT3KpXAbn48zdRw2tGQIi4odOeh6PVg5jrGoTgVnW59nWMdb5haoWtwNFBvvRrXkwr/22nftnricvX7F2TyoJhzNqSwSDoc7wY9x+MnPyubZvK12Q8DvMvA5+/ZdrBTM4HWfOFCKBRSKyAZ2k5Del1FzgUeABK4F5OPCRVf8jINwqfwB4zImylcq1fVvRLMSPl8d0Zd695+MhMDtuf8UNDQY3QinFlyt207lpEF2bB8OpVJh1tz65/RfIMrv03BmnrSkopTYAPUopTwT6lFKeBYx1ljyVYVzvFozrXZw5sV+bcGav38/9w9sZz03DWcO6valsPZjBv6/oou/7X/4PThyCka/AvIdgy2zoeb2rxTQ4ibMy9lFlGdWtKUkpmcZ/wXBWMXPlXvx9PBnVvameGcR9AefdB73/AWGtYePXrhbR4ESMUiiHEZ0j8fYUY0IynDXk5Rfw65aDDOvUmABfL1gwBRp2gAseBRHoMg52LYV08z/hrhilUA7BDby5oF1D5m44YHI6G84KVu46xvHMXC4+pwlkHIRDm6DbBPDy1RW6jgMUbPrOcRfNyyEoLb78OiYETa1hlEIFXNatKQfTs1iZdMzVohhciIiMEJFtVmyuMzZBiMjrIhJnvbaLSKrduXy7c7NrVfAqMn/TQfy8PbmgXSPYuUgXthlSXCG8DTTtCRscaEJa/TE91z0G238t/XxBPkwdAj/eCQUFjruuoVSMUqiA4Z0a4+ftyez1Zrp8tmJ55r8DXAx0AiaISCf7Okqp+5VS3ZVS3YG3gO/tTp8qPKeUGlVbcleVggLFL5sPMqh9Q/x8PGHnQmgQAY3PKVmx6zg4uAH2rXXMhTf/oN9/ewry8848v/1n2L9Wr20s/rdjrmkoE6MUKqCBjxfDOjVm/sYD5OabXylnKX2ABKVUolIqB5iBjtVVFhOA6bUimQNZt/c4hzOyGXFOE/2LPHERtBkMHqc9Js4ZA36hMO1SWP1x1Uw7+9dBzsni44yDsPdv0oLaw5F4iPvyzDZ/fwBBzaDHdbDkZYj7qnoDNFSKszKfQlW5rGskc9bv58+Eowxu38jV4hhqn6K4XBbJQN/SKopIKyAaWGhXbBOR1UAe8IJS6scy2jolrldlmb41Gy8Bn6PbWTXvV3qfPEJ8blMOlXJd326v0H7bm4TNvZ+UZV+y6ZzHUB7e5fbvlZtB/2UTOdR4MNs6aL+Hpvvm0Q7FuhY30WPvNGy/PM3K443I9/IDoMHJPfTZ9QeJ0dezN/ByuoRuJGTW3azbc5KMoBiHfwfOpL7E9TJKoRJc0L4hQTYv5qzfb5SCoSLGA99acb8KaaWU2icirYGFIrJRKbXz9IbOiutVGZRS/N+KRQxsH8bFw3rDX/8FoOPIO+gYFFl6owuvhD9fI3zhs1zQUqBtBfJtnQcqn8jDi4m8+lUIjYJPX4XwGIhoT/C5b8FHwzjfMw4GPa7bzL0fPH1pPeYZWvuHQ79e8FJrYgMOwaBbHDX8WqG+xPUy5qNK4OvlyYhzmvDr5kNk5eZX3MDgbhTF5bKwj9l1OuM5zXSklNpnvScCiynFqdPVbNqXzr7UU9p0BHo9oVEnKEshgDYr9bkVkMqtL+z+Czx9QDxh6atw8igk/QmdRuvtri16Q+crYMlL8PMTkLYP1s+ArmPB38oF7ReifSWObK3pkA1lYJRCJbmsW1NOZOexeNthV4tiqH1WATFW1kAf9IP/jF1EItIBCAWW25WFioiv9TkCGABsqRWpq8CHSxPx8fJgeMfGkJMJu5eX3HVUFrYgaNge9q2puO6e5dCsF/S8Qa8L/P0+qALoZLf2PuotiL0RVrwDb8VCbib0ua1kPw3bw5HtJcsyj+nZzbyHYca1sPC5iuWpKlnp8GoHWPF+5eov+jfMr/VoPTXGKIVK0q91OBEBPkW7kHLyCvg7MYV847/g9lj5P+4CfkEHdfxaKbVZRKaIiP1uovHAjNMCOXYEVovIenQwyBeUUnVKKSzbeZQ56/dz34BGhPoUwO5lkJ8NrQdXroNmsVoplLfgnH0C9sdBq/5w3v0gHnrROKQVNOlaXM83EC59DW76RZuXYi6CyK4l+2rYHo7thPzc4rLVH+ndS+tnwp4VeiZiH6NJKfjuFtgyi2qz7gvIOACL/6PjQZVHbhYsfwf+fg8O281qCgpg7WeQcajstnFf6e23LvLNMEqhknh5ejCySyQL4g8zfeUehr62mKs/XMHTszeZ3M5nAUqpeUqpdkqpNkqp562yp5RSs+3qTFZKPXZau2VKqS5KqW7W+0en9+1KcvMLeHrWZv4R9Df//HsIPN8YvrxKm3la9a9cJ816wskjkLa37DrJK0Hl6z6Dm0EPK3ZSp1HadHQ6Lc+FO1fANTPPPBfRHgry4Fhicdm+dRDeFh7fA2On6RnI7mXF54/u0OE5Fv2neg/bgnw9swmNhqxUWP52+fUTF0GOlXjSWp8B9O6q2XfDrHIe+ive09tvt80rWV4VubfN18qlGmM1SqEKjOrWlOy8Ah7/fiPBft5c0aMZX6zYw/+W7qp0Hyey8/hj+xGzNmGoE3y6LIkdh09wS6Nt4N8Ihj4N5z8Io98FnwaV66RZrH5PXl12nd3L9eyghRULc+BD0GoA9JxYdhsoXWE0bK/f7dcVDsRBZHf9uXlv8LJB4h/F5xN+t9rEly9nWWybD6m7Ydhk6HwlLH8XThwpu/6W2WALhl43a2WUuhev3HQ9m/ENhoTftP/F6WQc0j4gAL8/U+y3kZYM/+0Gv0+uWNbMYzD7Hq1cCqr+nDG7j6pAz5ah3D+sHTGNA7j4nCYopc1Iz8+Lp3moHxd3KXtRbvG2w8xYuZdF2w6TnVdgUhwaXEd+Hnh6cSQjm9d/286QduE0OroKYi6E8x+oen+NzwFPX21COufK0uvsXgaR3bR5CCCoKdw4r/S6FRFhbUUtXFc4cQTS90FTa/3e2wYt+sKuJcVtEn7XpqrMFFg7TS9qV4UV70FwS+hwqR7vllnw52sw4j/aJJR3Cnz8dd38XP0rv/1IbSpb+ykse4vWe5O0SevWRdqU9fNj2kTnbSu+zk5rJ/PAR/SC+/qvtF/IjGu0UvrzdWjZD9pdVLasvz6px3ndd+BZ9Ue8mSlUAQ8P4d5hMYzsEomI4OEhvDquG7GtQrlvZhwpJ7LPaKOU4p1FCUz6ZBVr9hxnfO8WRAbbWJFYa0nlDIZitv4EL7aCDV+zaNthTubk80QfQTJTIOr86vXp6a0f+PY7kJQqNl3kZUPyKj0zcAQ+/hDSsnimcCBOvzftXlwneiAc3qwVRu4pvfOpwyVaaW36Xi8aV5YD62H3n9D3Vv2QjWgL3a+BVf+D98+H/zSDF6Mh2Vps37VEm5g6joKQFtD1algzjcgDv8K5d+jv6uIXdRa75W+VvFbC73rGNuhxPeNZ9B/48Q44sAHGfgqNu+jjjDJyyScs0Caq8+47cy2mkhilUENs3p48M6oz2XkFLNpWcjqZX6CYPHszL/+yjcu7N+WvR4fwzOhzOK9tBKuSjpkge4baZc00nT0t5wSs/phVu44R0sCb1hnWwyy6mkoBtAnpQFyxuWPWXfDuudqWv2+tXriu7BpFZYhoD0e36c/71+l3+wXr1oP0e9JSSPoL8rKg7VBtrsrNrHxAv5yTsPgF8PYvXgcB/dBu0gUCGundUgGN4LubtLKJnw0+AcW7twbcC/k55PiEwiBryanNYOh4GSx9TZuGQJt6di7Ucnp4wLBnIGM/bPkRhv4LOl8OYz7Su8O+v1WbtP58A+Y/qs1ZO36DOfdBRDs906gmxnzkADo3DaJxkC+Lth5mjF2S8ylzNvPp8t3ccn40j1/cEQ8PbR/tEx3GN2uSSThygnaNA10ltuFsYsnLeptm2+H6F+TSV9nTYDu9WkXjkfSn3ukT0rL6/TeL1TttjmzVpou4L7Q/wv+GQdR5uk7Lfg4ZCqDXFZKW6gfp/ji9yGwLKj4f2R18AvWvdm8/vcbQaoB+b9RZ7wDqdWPZ/eflaLPPHy/BycMw6AntI1FIcDO4xc5pvdMo+ORi7Wy36w9tiis0CzVsD1e8z6bdGcT62v2/X/i8DgL4+zNw1VQ9jlPHoO0wfT5qgM5hIZ5w3gPFfV38Asy5V18HwLuBVnQACNz0c0mTVBUxSsEBiAhDOjRi7nodH8nb04PUzBymr9zL1b1a8H+XlIidRt9o7Yjz965jRikYnM9f/9UKoevVMPod/ct06at0T1tAeJ8HYMWf2tRRE5r11O97V8DK/2kFc+238PUNsHUuNOwIDcJqPpZCGnbQv/5Td+sZyumzEE8v/VDdtQQ8PLVC8NahM+h5A/z8KHx8sc4oh4Kr/le8YJ6fq3dg7Vqi2139BbQsNapJMS3PhQseKw7Y1+m077PbeDKOLy5ZFtoK+t8NS1/RToA7FwJScivwJa+eea2eEyG4OfgG6fUVW4h2BDy6TSuQlueWL2sFGPORgxjcvhEZ2XmsskJsz4rbT05+ARP7R51Rt0WYH02CbKzcZcJxG5zM6o/1jpfOV8Ll72n7f1g0qWHdGOW5jPODDunFz+iBNbtOWGsdJG/Rv/UOn4v+o3/V3vwrdB0PfW+ruI+qULgDKelPvchcuPPInuiB2p/h6PbiX98A3a7WC9GqQM+a8nJg+gRItbbU/vy4VgiX/Rcm/VSxQihk4EPQsr82NbUdXrk2590PAY31onPCb1q5Fnpvl4WIHk+LPvo7F4GAhnpG1qrmszEzU3AQA9pG4OPpwaKth+nfJoKvV+/lnGZBdGoadEZdEaF3dBgrd6WglDL5n2uROXPmcMkll+BxeuRPd2TzDzD3Ae0AduWH+hezxQr/IYw49jr5eyw/gOouMhcion9pJ/yuf+l2uESX24Lhyg9q1ndpRLTT74V5HewXmQuxV3T2SsEvVCurQg5vhY+Gw1fjoPu1sGqq/gUfO6lqMnl4ar+K9P3gG1C5Nr4BehvwrH/q4wserdo1nYDT/jNEpIWILBKRLSKyWUTutconi8g+u6QjI+3aPG4lMdkmIuXsuap7+Pt60bd1GAu3Hmbz/jQ2709nbGyLMuv3iQ7jUHo2e45lllnH4HhmzpxJTEwMjzzyCFu3unH8nPw8HT+oaQ8Y96meIdjx5YmeFOCBZ9zn2h5fXoyjytKyH3h46501zv6h4xcCAU30ugKUXGQupFFn8AvTW0kLt7GWRqMO+js6sg1+/T+tQIY9Uz25bEG6v6rQbYLekQQllZeLcObPpTzgQaVUJ+Bc4E67xCSv2yUdmQdgnRsPdAZGAO9ayU3qDUM7NGLnkZO8+ut2fDw9GN29aZl1+0Zr++rfxoRUq3zxxResW7eONm3aMGnSJPr168eHH35IRkaGq0VzLNt/1jtXBj5UbEu3OJGdx18HPdkbbNnQazpLKKTfXXD3mmLTjrMpvE54TMlF5kI8PGD4MzDs6YqVVJsh2rzWbgRc9VGJWZXT8fDQaz19bite13AhTlMKSqkDSqm11ucMdMyYZuU0GY2OG5OtlNoFJKCTm9QbhnRoDMDCrYe5sHNjQhr4lFm3bcMAQht4l7quUFCgjMezEwkKCmLMmDGMHz+eAwcO8MMPP9CzZ0/eeuutihvXF1Z/pBPTxJw54V635zgFCrI6WI5mNdmKao+3TS+e1haFSqE001EhPW+ALmMq11+3q7X5x36XUW3RpAuMfKl2lVEZ1MqagohEocMF/42OEnmXiNwArEbPJo6jFcYKu2bJlKJEXJ2IpCIi/YUDJxXtvY9VKEt0QAF/bNnH4sXHi8p2p+fzwfpsPD2EKf1tZ6w31IUxOhNnj++vv/7i559/Zt++fVx44YW8/vrrhIaGkpWVxaRJk+jSpYvTrl1rpOzUO1kGPVGqR+uqpON4CDQdOBEaNaj5ziNXUagUSltkNlQbpysFEQkAvgPuU0qli8h7wLOAst5fBW6qbH+uTERSGa5TCcxZv59/XnU+nh7lT1kTPBN57qd4VmU3oUeLUBKPnuCVv7cDQk5+AQ3b9eScZsEl2tSFMToTZ4/vk08+4fnnn2fgwDN323z55Zfu8d2u+URvTex5Q6mnV+06RsfIIAL9/au+mFqXaN5bj7PQD8LgEJyqFETEG60QvlRKfQ+glDpkd34qMNc6rEoikzrLnYPbcufgtpWqe1HnJny/dh/vLd5JoXPz8E6NeXREBy56Ywk/bzp4hlIw1IzJkycTGVm8qHrq1CkOHTpEVFQUQ4cOdaFkDiI3C9Z9qXf/lLJ4nJNXwLq9xxnfuwaOanWFyG7waFLp6wmGauM0pSDa7vEREK+Ues2uPFIpdcA6vALYZH2eDXwlIq8BTYEYYKWz5KsLtAhrwLx7zyczJ48t+9PJyi1gQNtwRIS+0WHM23SABy9sZ7asOpCxY8eybFlxSGVPT0/Gjh3LqlWrXCiVA9kyS3vF9r651NO/xx8iK7eAC9o1rGXBnIRRCA7HmTOFAcD1wEYRibPKngAmiEh3tPkoCbgNwEpa8jU6K1UecOdpeW7dlgY+XvSKKuntefE5TfjXrM3sOGxCYTiSvLw8fHyKNwD4+PiQk5PjQokczN6/tW9A9AWlnp6+cg+RwTYGuotSMDgcZ+4++lMpJUqprvbbT5VS11vJRroqpUbZzRpQSj1vJTFpr5Sa7yzZ6gMXdW6CCMzfWEY0REO1aNiwIbNnF2fSnDVrFhERES6UyMGcPKL375cyu9x7LJOlO44yrleLCte7DGcvZ4FbZ/2kUZCNXq1Cmb/pwBnnjp/M4V8/buJA2ikXSFa/ef/99/n3v/9Ny5YtadGiBS+++CIffOAEj1tXcfIo+Jc+C5i5ai8eAuN6l+1UaTAYpVCHGXFOJFsPZrDr6Mmisux8xc2fruLzFbuZFbffhdLVT9q0acOKFSvYsmUL8fHxLFu2jLZtK94YICIjLE/7BBE5Ixu7iLxu56W/XURS7c5NFJEd1quCVGM15OQR8D9z5pOXX8DXq/dyQbuGNAvxK6WhwaCp1JqCiPgDp5RSBSLSDugAzFdK5VbQ1FADRpzThGfnbuGz5Uk8OqIDXh7Ce3HZrD+aSZDNi5W7jnH7BW1cLWa946effmLz5s1kZWUVlT311FNl1rc8698BhqP9Z1aJyGyl1JbCOkqp++3q3432y0FEwoCngV7odbQ1VtvjOIOTR0qdKSzcepjDGdk818cNdh0ZnEplZwpLAJuINAN+RS8gT3OWUAZNsxA/BrVvyCd/JdHz2d8Y9fZfxB3JZ8qozlzarSmrdh0j3y5RT9LRk3y+PKlEmaEkt99+OzNnzuStt95CKcU333zD7t27K2rWB0hQSiUqpXKAGWgP/LKYAEy3Pl8E/KaUOmYpgt/QYVwcT16OzvhVilKYvnIPjQJ9GdKhkVMubXAfKqsURCmVCVwJvKuUGouOUWRwMlNv6MUXN/fl8h7NOJ6Zw+Vtvbm+XxR9o8PIyM4j/kBxWsEXf97Kv2Zt5sGv48jLL6j0Nf7YfoQhryxm71kQnG/ZsmV89tlnhIaG8vTTT7N8+XK2b99eUbNmwF6741K97QFEpBUQDRRmYKl02xqTaaV4Pc18lHT0JIu3H+Hq3i3w8jQWY0P5VHZLqohIP+BaoHADtOuDdJwFeHt6cF5MBOfF6H/0whAQfewC6p3TLJiT2Xks2naYqPAG/Bi3n+y8Al4Z242tBzNYt+c4/dtElBrGG2Dmqj0kHj3JXdPX8e3t/fB24weHzaYzUjVo0ID9+/cTHh7OgQNnLubXgPHAt9XZTl3TEC4BGYn0AjYlHeboyeK6X8Zn4wG0LtjH4sUOHavDcPfwLVB/xlhZpXAf8Djwg+VP0BpY5DSpDBUSGexHy7AGrNyVws3nRbNw62Gycgt44aqubN6fzrNzt/Dz5oNFudP7Rocx87YzE3Bk5eazeNsR2jcOZP3eVF75dRuPX9yxlkdTe1x22WWkpqby8MMP07NnT0SEW265paJmVfG2Hw/ceVrbQae1XVxawxqHcEnIhzVwTp9BRclW0rNyuXPhAkZ1b8YVI7qX396FuHv4Fqg/Y6yUUlBK/QH8ASAiHsBRpdQ9zhTMUDF9osNYEH+IggLFvI0HiAjwpXdUGOe2Dicy2Ebc3lR6tgxl+c6jfPH3HlIzc86I3Lp0x1Eyc/J58tKO/LzpIB/8kUj/NhFneLx+s3ovXZoH06FJ/fUgLSgoYOjQoYSEhHDVVVdx6aWXkpWVRXBwhaFEVgExIhKNfsiPB645vZKIdABCgeV2xb8A/xaRUOv4QvQPLMdz8qh+t1tT+HrVXk7m5HPTgGinXNLgflTKTiAiX4lIkLULaROwRUQedq5ohoroGx3G8cxc1iensmjbYUZ2aVLklDSySyRPjOzIiHOacEXP5uQXKBZuPXxGHz9vOkiQzYtzW4fzr0s70b5xIA/MjONwevHOnIVbD/Hwtxt4a0FCrY3NGXh4eHDnncU/4n19fSujEFBK5QF3oR/w8cDX1ox5iojYhxgdjw7/ruzaHkMHflxlvaZYZY7n5BH9bq0p5Bcopi1LondUKF2amxhahspRWeNxJ6VUOnA5MB+9kHa9s4QyVI6+0TqX6wvzt5KVW8DILqVnz+raLJhGgb78Hn+oRHlufgELth5iWMfGeHt6YPP25O1renAyJ48Hvl5PQYEiPSuXJ77X4alW7z6G3fOuXjJ06FC+++67Ko/D8sZvZ3ncP2+VPaWUmm1XZ7JS6gwfBqXUx0qpttbrkxoPoixOHtGZz2xaAfy25RDJx0+ZWYKhSlRWKXhbEU8vB2Zb/gn1++ngBrQI8yMy2Mbfu44VmY5Kw8NDGNqxMX9sO0J2XvH658pdx0jNzOXCzk2KymIaBzL5ss78mXCU95fs5D/z4jmckcWY2OYcSs8m+Xj99qL+4IMPGDt2LL6+vgQFBREYGEhQUP01iZWg0JvZCnExfeUemoX4MbxTYxcLZqhPVFYpfIAOXucPLLG23aWX28LgdESkaBeSvemoNC7s1JiTOfks35lSVPbzpoPYvD3OWD+4uncLLu0ayau/bmf6yr3cMrB10a/N1bvrd/rQjIwMCgoKyMnJIT09nYyMDNLT3eRWtvNmzs7L5+9dKQzv1NhsQzVUicouNL8JvGlXtFtEBjtHJENV6Nc6nFlx+7mkDNNRUb024TTw8eS3LYcY1L4RBQWKX7ccZFC7Rvj5lNxdLCL8+8oubEhOw9tTuH9YO7w9PQj09WJV0nGu6NHcKWNJz8ol4Xh+ia06jmbJkiWllpeWdKfeYefNvH5vGlm5BZzbOtzFQhnqG5UNcxGMdtUv/M/5A5gCpDlJLkMluSq2Oc1C/ehbwT+/zduTgTEN+T3+EA9f1J7/zNvKofRsRpzTpNT6QTZvfrrnvKK2AD1bhbI6yXkzhdd+3c60v7NI99/G/cOdk0fi5ZdfLvqclZXFypUriY2NZeHCheW0qiecPAoR7QBYvjMFETi3dekmRYOhLCo7r/wYyADGWa90wHkLZoZK4+3pwfkxlYuNP6xTYw6lZzPwpUV8uzaZWwe25tKuZc8wAm3eBNq8i457R4Wy/dAJ0jJ1yKuEwye4ZuoKDmdkldVFlViy4wg+nvDmwgQe+XYDuVXwyq4sc+bMKXr99ttvbNq0idDQ0Iob1nWUKmE+WrbzKJ0ig87YgmwwVERllUIbpdTTVuyXRKXUM0BrZwpmcDxDOjTC38eTVuH+zLpzAE+M7Fgle3NsK/2rc80ePVt4Yf5Wlu1McUjOh4NpWSQeOckVbX24d2gM36xJ5oGv19e434po3rw58fHxTr+O08k5CXmnwL8hWbn5rNuTSj9jOjJUg8p6NJ8SkfOUUn8CiMgAoH5vQzkLCfP3YdljQwmweVUryUr3FiF4eQirk44T0sCnaIvrwq2Hmdg/qty2Sime+GETl3WNpH/bM0M7L9upHa86hXswcXg7FPDmgh3c0K9VmbuqqsPdd99dZJYqKCggLi6Onj17Oqx/l1Hko9CQtbuPk5NfQP+2RikYqk5llcLtwGfW2gLAccC5ceENTiG4gXfFlcrAz8eTc5oFszrpOHF7Uwn392F4p8Z8v24fmTl5NPAp+3Y6lJ7N9JV7OJSeVapS+CshhdAG3rQI1DOXOy5ow4yVe3hx/la+ub0fIsKJ7Dyemb2ZG/pFVdsZq1evXkWfvby8mDBhAgMGDKhWX3UKO2/mZTtT8PQQhypTw9lDZXcfrQe6iUiQdZwuIvcBG5wom6EO0qtVKB/9tQul4KlLOxHTOIAZq/ayLCGFYeXshy+M5vpnwtEzFIhSimU7j9KvTTgekgFoBXTvsBj+74dNLNx6mPNjGnL752v4M+EowX7e1VYKY8aMwWaz4empF8/z8/PJzMykQYMG1eqvzmDnzbw8MYUuzYJLrAcZDJWlShuYlVLplmczwAPl1RWRFiKySES2iMhmEbnXKg8Tkd+sLFS/FcaEEc2bVmarDSLiBnN696NXVBhKQdNgG9f0bUmf6DAa+HiyaNuZITTs2WIphZy8Av7ccbTEuaSUTA6kZdGvTckZxLheLYiO8Oeln7fx6Hcb+DPhKIG+Xmw9mFFt+YcOHcqpU8WWz1OnTjFs2LBq91dnsJRCpncY6/em0q+NMR0ZqkdNvFoqMkrnAQ8qpToB5wJ3ikgn4DFggVIqBlhgHQNcDMRYr1uB92ogm8FJ9I0OI9jPm0cv7oDN2xNfL0/OaxvBoq2Hyw0dseVAOk2DbQT6erEgvqQC+StBK4kBpz3IvD09ePDCdmw7lMEP6/bx4PB2XNylCfEH0qsdbiMrK4uAgICi44CAADIz3SCPhKUUVh/xIK9AmUVmQ7WpiVIo979SKXVAKbXW+pyBDiTWDJ2x6lOr2qfo0BlY5Z8pzQogRETK98gy1Dqh/j7EPTWc0d2L88QM6dCI/WlZbDtU9i/4+APpdGkezAXtG7Jg62EK7LLDLdt5lMhgG9ER/me0G3lOJBd1bsxtA1tz15C2dIwMIuVkDkdOZFdLfn9/f9auXVt0vGbNGvz83CBn8cmj4BPIX3tO4u0p9Ipyg222BpdQ7pqCiGRQ+sNfgEr/J4lIFDpn7d9AY6VUYaaPg0ChIbqsDFV1MyvIWczpTmWDrRSPC7ceLjW0dmZOHruOnmRUt6ZEhfszd8MB1ien0qNlKAUFiuU7UxjcoVGpzmoeHsIH1xcvDhf2H38gg0aBtirL/sYbbzB27FiaNm2KUoqDBw8yc+bMKvdT57B8FFYkHqNb85ByF/0NhvIo985RSgXW9AIiEgB8B9xnLVDb969EpEp2gJpmp6rv1NUxtgry4Me/d9CJ5DPO7UzNRynIT9mDV4EnHgIf/7yKq9r5sDM1n+OZuYTnHmHx4sUVju9Ejr5dfvprHWp/9RyzPvjgA/bu1b8/WrRoQUZGRp38TqvEySPkN4hg0640br/AuBAZqo9Tf05YkVW/A75USn1vFR8SkUil1AHLPFRoYK5UdqsaZ6eq59TVMY7O3c5bC3ewNieSu4fGlEjpue/v3cAmxg3vT4uwBny+azk7MnPJbtiO/y5eT6DNi1tHDaRhoG+lxvf8mgXk+IUxaFCPM87NWb+fz1fs5tzoMAa2a6h9K+xkeeedd7j22muLFpePHz/O9OnT+ec//+mQ78FlnDzKcZ9I8guUiXdkqBFOC58oekrwERCvlHrN7tRsin0cJgKz7MpvsHYhnQuk2ZmZDHWc2wa25ooezXhzYQJj3ltG4pETRefiD6QTaPOieai2OA7v1JitBzO47fM1tAr3Z+7d59Ew0LfS1+rQJLDMHUjfrkkmbm8qby9KYMz7y3nk25K7pqdOnUpISEjRcWhoKFOnTq3CSOsoJ4+QnOOPl4cQ28qsJxiqjzNj6g5AJ+IZIiJx1msk8AIwXER2AMOsY4B5QCKQAEwF6vlPt7MLf18vXhvXnXev7UlSSiYTpq4gK1fnbog/kEHHJkFFawYXdW5CSANvJvWP4ts7+tEq/MwF5vLoGBlEwuETJXJDgPZ32LgvjSu6N2Pdvy7ksm5NmbfpQIl6+fn5JXYu5efnk5OTU91h1w0KCiDzKDtO2OjaPNisJxhqhNPuHiskRlnbVoeWUl9RMuG5oR4yskskoQ18mDB1BdNX7mFivyjiD6QzrlexZbBFWAPW/Wt4taOgdogMIq9AsfPwSTo1LV7Y3pd6imMnc+jSPJjgBt6M6taUOev3s25PapFJZcSIEVx99dXcdtttgF5fuPjii2sw4jrAqeOgCohPt9G3qzEdGWqGyb5hcDj92oTTNzqM9xbvZMfhE2Tm5NMxsuSehZqExe5k9bX1YMnkOBuTdST3rpa3c9/WYXh6SJEfBMCLL77IkCFDeP/993n//ffp0qVLCWe2eonlo3CkIJC+0Sa0haFmGKVgcAr3DovhcEY2T8/W+Z07Rjou5WVUuD8+Xh5FoTMK2bBPJwVq30QrjSCbN12bB/OnnVLIyM7nu702/MKasHLlShYuXEjHjh0rvKaIjBCRbZbH/Rl5mK064+w8+L+yK8+3M6HOLq1tjbCUwnEJppeJd2SoIcb4aHAK/VqH0yc6jBWJx/D0ENo1rvHu5iK8PD1o1zjgjMXmjclptG8SiK9XcSa589pG8M6iBNZu3Myc77/lvY8/IzXfRu+hIwFYtGhRhdcTEU/gHWA42n9mlYjMVkptsasTAzwODFBKHReRRnZdnFJKda/ueCvEUgphjZoS4Gv+pQ01w8wUDE5BRLhvaAwArSP8i7K3OYqOTYJKzBSUUmxITqVLs5AS9Qa0jaBAQa9uXViwYCFNx06myXUvcajFEMSj0jL1ARKsXCI5wAy0B749twDvKKWOW/KUHwzKgeScTAWgXasW5Vc0GCqBUQoGp9GvTTiXdInk4jJSftaEDpFBHD2Rw5EMHe5iz7FM0rPyitYTCunRMgQ/b0/GPfYG4h/Chg8foPH6aaQlrCUzO7eylyvL296edkA7EflLRFaIyAi7czYRWW2VX16FYVaK5CM66VG3aBMVxlBzzFzT4DREhHeudU6w287WrqO/Eo5yeY9mbLAWmbs0K6kUfL086R0dxv7UbjQe3Zve/Y9xZ3Qq9/37HVJTjnLHHXdwxRVXcOGFF9ZUJC90MMdBaMfLJSLSRSmVCrRSSu0TkdbAQhHZqJTaeXoH1fXWz9yxk9ZAxv5EFh/fX9NxuIS66qnvSOrLGI1SMNRLekeF0b5xIG/8vp1LukaycV8aPl4epa5dnNc2nH/P2wrAk5d05LrzW3M8sg8vzVlLq1ZHePHFFytSCpXxtk8G/lZK5QK7RGQ7WkmsUkrtA1BKJYrIYnQcsDOUQnW99X/Z9B0AI0dcBDXY1eVK6qqnviOpL2M05iNDvcTTQ3hkRHuSUjKZsWovG5JT6RgZhI/Xmbf0ACvTm7+PJ+N662f75T2a4WkLILD7CBYsWFDR5VYBMSISLSI+wHi0B749P6JnCYhIBNqclCgioSLia1c+ANiCAzmRkUG22OqtQjDULYxSMNRbhnRoRJ+oMP77+w427Uuna7PSs7F1bBJEizA/rju3FUFWNrIWYQ3oExXG92uTK8zNoJTKA+4CfkGHgP9aKbVZRKaIyCir2i9AiohsARYBDyulUoCOwGoRWW+Vv2C/a6mm5OUXkHXqBPmeVY8YazCUhjEfGeotIsKjF3fgqveWAZSZotPDQ1jwwCC8PEr+kr68RzOe+GEjG/el0bV5SLnXUkrNQ4disS97yu6zQmcjfOC0OsuALpUcUpVJSjmJr8pGebtBTghDncAoBUO9JrZVKBd1bswvmw+dschsT2lmpUu6RHIiO5dmIfX3gbrt4AlsZOPpW7X4UQZDWRilYKj3PDPqHHpHhdGhSdUc5IIbeHPrwDZOkqp22HYwne7k4GMzSsHgGMyagqHe0yTYxj/Ob12jeEr1la0HMwj1ycPDp4GrRTG4CUYpGAz1mO2HMgjxzgOzpmBwEEYpGAz1lMycPHYfyyTQIxe8zUzB4BiMUjAY6ik7Dp1AKfCTHDNTMDgMoxQMhnrKtkM6SqyvyjZKweAwjFIwGOop2w5mYPP2wDP/lDEfGRyGUQoGQz1l+6EMYhoFIrmnzEzB4DCMUjAY6ilbD2bQsbEfFJiFZoPjcJpSEJGPReSwiGyyK5ssIvvsUhOOtDv3uJXqcJuIXOQsuQwGd+DYSZ1LonNDH11gZgoGB+HMmcI0YEQp5a8rpbpbr3kAItIJHXmys9XmXSsFosFgKIXEIycAaBNq/ZsYpWBwEE5TCkqpJcCxSlYfDcxQSmUrpXYBCegUiAaDoRT2p2UB0NTfivDqZZSCwTG4IvbRXSJyA7AaeNDKadsMWGFXp7R0h0D1s1O5C+4+Rncfn6M4kHoKgMa2Al1gZgoGB1HbSuE94FlAWe+vAjdVpYPqZqdyF9x9jO4+PkdxIC2LQF8v/D1ydIFZaDY4iFrdfaSUOqSUyldKFQBTKTYRVSbdocFgsNiXeoqmIX6Qq2cMZqZgcBS1qhREJNLu8AqgcGfSbGC8iPiKSDQ6t+3K2pTNYKhPHEg7RWSIzU4pmJmCwTE4zXwkItPROWsjRCQZeBoYJCLd0eajJOA2ACu14dfo3LV5wJ1KqXxnyWYw1HcOpGbRpVkI5B7QBWamYHAQTlMKSqkJpRR/VE7954HnnSWPweAuZOXmk3Iyh2YlZgpGKRgcg/FoNhgqgYiMsBwrE0TksTLqjBORLSKyWUS+siufKCI7rNfEmspywNqOGhnsB7mZutCYjwwOwqTjNBgqwHKkfAcYjt4uvUpEZiulttjViQEeBwYopY6LSCOrPAxtOu2FNpuusdoer648hdtRI0NscNjMFAyOxcwUDIaK6QMkKKUSlVI5wAy0w6U9twDvFD7slVKHrfKLgN+UUsesc79Ruqd/pSlyXDMzBYMTMErBYKiYZsBeu+PSnCvbAe1E5C8RWSEiI6rQtkoUzhSaBFtrCuIJnt416dJgKMKYjwwGx+CF3ko9CO1ns0REulSlg8p666+OzybIB1b8tZQ2u7YT6eHDn3/84YgxuIyzwZO9vozRKAWDoWIq41yZDPytlMoFdonIdrSS2IdWFPZtF5d2kcp663+SuJJWDXMYNOg8yPgBjgfWey/ws8GTvb6M0ZiPDIaKWQXEiEi0iPigI/rOPq3Oj1gPfxGJQJuTEoFfgAtFJFREQoELrbJqcyDtFJHBNn2Qm2UWmQ0OxSgFg6EClFJ5wF3oh3k88LXlcDlFREZZ1X4BUkRkC7AIeFgplaKUOoaO87XKek2xyqrNgdQsHeIC9EKzWWQ2OBBjPjIYKoGV+2PeaWVP2X1WwAPW6/S2HwMfO0KO9KxcMrLzaBpSOFMwqTgNjsXMFAyGesSBVDvHNbCUgpkpGByHUQoGQz1if5rejlo8U8g0MwWDQzFKwWCoRxTOFIrXFE6Bt82FEhncDaMUDIZ6xP7UU3h6CI0C7WcKxnxkcBxGKRgM9Yj9aadoHOiLp4foArPQbHAwRikYDPWIA6lZRIbYKQGz0GxwMEYpGAz1iANpp4rXE5QyC80Gh2OUgsFQT1BKsT8ti6aF3sz5uaDyjVIwOBSjFAyGekJWbgHDOjaiW4sQXWDCZhucgPFoNhjqCX4+nrx7bWxxgUnFaXACTpspiMjHInJYRDbZlYWJyG9WWsLfrABhiOZNK9XhBhHp6Sy5DAa3wcwUDE7AmeajaZyZYeoxYIFSKgZYYB0DXIwOMxyDjif/nhPlMhjcAzNTMDgBpykFpdQS4PRokKOBT63PnwKX25V/pjQrgBARiXSWbAaDW1CkFMxMweA4anuhubFS6oD1+SDQ2Prs8JSFBoPbk2dmCgbH47KFZqWUEhFV1XaVTVnorrj7GN19fA7FmI8MTqC2lcIhEYlUSh2wzEOHrfLKpDsEKp+y0F1x9zG6+/gcipstNOfm5pKcnExWVparRXEKwcHBxMfH1+o1bTYbzZs3x9vbu9JtalspzAYmAi9Y77Psyu8SkRlAXyDNzsxkMBhKw81mCsnJyQQGBhIVFYWIuFoch5ORkUFgYGCtXU8pRUpKCsnJyURHR1e6nTO3pE4HlgPtRSRZRG5GK4PhIrIDGGYdg85olQgkAFOBfzpLLoPBbXCzmUJWVhbh4eFuqRBcgYgQHh5e5ZmX02YKSqkJZZwaWkpdBdzpLFkMBrfEzWYKgFEIDqY636d7hrkoKIC0ZFdLYajrnEqFeQ/DqeMVVhWRESKyzXKwfKyU85NE5IiIxFmvf9idy7crn+0w+QuVgpf7KAVXkpKSQvfu3enevTtNmjShWbNmRcc5OTnltl29ejX33HNPhdfo37+/o8R1Gu4Z5uLbG+HQJrhrNZhfHhVz8ihsnQs9J54935dSMPd+2DILul4NzXuVWVVEPIF3gOHo7dKrRGS2UmrLaVVnKqXuKqWLU0qp7o4SvYjcTPDwBk/3/DeubcLDw4mLiwNg8uTJBAQE8NBDDxWdz8vLw8ur9O+6V69e9OpV9j1UyLJlyxwiqzNxz5lCmyGQkgAH4lwtSf3gt6dhzr2w64/q95F9ApJXl32+oAC++wck/F79a9ijFCT+Afl51Wu/7gvY/D0MebJchWDRB0hQSiUqpXKAGWiHS9dicik4nUmTJnH77bfTt29fHnnkEVauXEm/fv3o0aMH/fv3Z9u2bYDeNXfppZcCWqHcdNNNDBo0iNatW/Pmm28W9RcQEFBUf9CgQYwZM4YOHTpw7bXXoq3oMG/ePDp06EBsbCz33HNPUb+1hXv+xOg0CuY9BBu+gaY9XC1N3eb4btgwQ39eMw1aD6peP3+8AMvehnvjIDTqzPPJq2DjN/pB1nZY9a5hz54V8NkoGPiwfrBXhSPbYP4jEH0BDLivMi1Kc67sW0q9q0RkILAduF8pVdjGJiKrgTzgBaXUj1UTuAzcOJfCM3M2s2V/ukP77NQ0iKcv61zldsnJySxbtgxPT0/S09NZunQpXl5e/P777zzxxBN89913Z7TZunUrixYtIiMjg/bt23PHHXecUWfdunVs3ryZpk2bMmDAAP766y969erFbbfdxpIlS4iOjmbChLKWZp2HeyoFv1CIuRA2fQcXPgsenq6WqO7y5+sgHtD5SoifAyeOQEDDqvVRkK8VMEo/+Ac+fGadLT/q96Slun5V/iYbvoGItiUV/NHt+n3pq/pv3aJP5frKz4Nvb9YP0ys+AA+HTZbnANOVUtkichs6jMsQ61wrpdQ+EWkNLBSRjUqpnad3UFXHzI7JSQTlwd9u4Ox34sQJgoODycjIACA3J5f8/HyHXiM3J7eo/4rIzs7G29ub3NxcLr30UjIz9U6vffv28cgjj7Bz505EhNxc3WdmZiZ5eXlkZGSQnZ3NsGHDyMnJwdfXl4iICHbu3EmTJk0AiurHxsYSHBzMyZMn6dy5M/Hx8YgIrVq1IiIigoyMDC6//HI++eSTSstdGllZWVVyCHVPpQDQZYy2kyctrf6vX3cnLVmbUXreAH1v0+aUuC/hvPv0+UwrdFWDsPL72bUEThwEb3/Y8DWc/1DJtYmCAtj8I/gEQlaaNus1iy2rt5LEfQU/3gEdLoXxXxaXH9+l7emBkfD9rXD7n+AbUHF/R+Lh0EYY9RYEVTq8VoXOlUqpFLvD/wEv2Z3bZ70nishioAdwhlKosmPmwalAuFs4+y1evBibzVa0j/+5q7q7VB5fX198fX3x9vYmIiKiSK4XX3yR4cOHM2fOHJKSkhg0aBCBgYE0aNAALy8vAgMD8fX1JSAgoKiNt7c3NpsNT0/9Q6iwfoMGDYrq2Gw2vL298ff3x9PTs6jcz8+vqN/qYrPZ6NGj8hYT91xTAGg3Qj+ENn7jaklKcioVPhwEOxe5WhL467+A0kqgYXtoNQDWfqof4ke2wbvnwn+7W7OActj4jf6uh/5L/4I/sL7k+eRVkLEfBlmbdhIruXaR9BfMtnZ0pCSUPHdsF4S0hCveh+NJ8Ov/Va7PI9oGTLOKFwXtWAXEiEi0iPgA49EOl0WcFsBxFBBvlYeKiK/1OQIYAJy+QF093Nh8VFdJS0ujWTMdlm3atGkO7799+/YkJiaSlJQEwMyZMx1+jYpwX6Xg7QcdL4MtsyE3S++wWfzimQ+s2mbz97B/HfzyhH74uoq0fbDmU+g2QT9cAWInwbFEWDUVpl2iF3MjYuD7f8C3N5W+dTP3lP6OO43Wu3g8vM9UxFt+BE9fPSNp1KniBe3cLL1oPfNavT7Rc6KWq8DOnHB8F4RFQ9QAGHCPXg/ZUondnofjQTwhvG3FdS2UUnnAXcAv6If910qpzSIyRURGWdXuEZHNIrIeuAeYZJV3BFZb5YvQawoOUgqnjFKoZR555BEef/xxevToQV5eNTc5lIOfnx/vvvsuI0aMIDY2lsDAQIKDgx1+nXJRStXbV2xsrLJn0aJFJY5VwgKlng5SasZ1Sj3fTH9+pYNSJ44qlzF1mFLPNtaybPy2ys0XLVqkVGqyUrPvVWrzLKXy8ytutO0XpQ5uKj4uKFDqizFajmO7istzTin1n5ZatpfbKXV4m1J5uUr98ZJSz4Qp9fFIpfLzSva98Ttdf+ciffzVBN22sF5+vv7Ovxqvj+c9qtSzjfS1Tid+rjr179ZKPR2s+3whSqmUnUqt+VQfpyQWy//vFkrNfVAf52Yr9cEgXWY/ntKYfo1Sb/Wq+DtTSgGrVV29t5VS6v3zlfpibKXGUtdZtGiR2rJli6vFcCrp6emVqpeRkaGUUqqgoEDdcccd6rXXXqvRdUv7Xsu7t913pgAQNRACGkP8bGh9AYydBplHtY26tF/pO37Xv4j3rysu2/M3fDJSb9ksdBY6HaW0/V1VEPT1aAIkr4QLHoGGHWHxCyV//VaCoLStMHUwrPkEvr5em3g2flt2g5VT4aux8PGI4nHFfQU7foVhk0vuFPK2Qb87ddmkn6BhO70HfuDDMOpt2P0n/PFSyf43fqPt+lHn6+OuY/X6wq4l+rjQdNT5Cn3c+gLIy9Lfgz25p+CnB8n3tGkz0xUfwu1LIaw1hMfoOoUmpMxjkJ2mZwoAXj4w9hP9+dubIK8cR6Mj27SpzB3IzTIzBTdk6tSpdO/enc6dO5OWlsZtt91Wq9d334Vm0A+0a7+FgjxoZmX4PHEE5j8My9/WZodCTh6FH26FzBS9a6nTaG0K2fQtNAiH3X/B/ji4+vNic0shy96C3/4FtmD9sO94KfS/+0x5NszQO326TYDwNvD1Dfqh2m18xWMpyIe1n9E97v8gpLleWD2yTe+++e5mvRjcZkjJNiun6q25MRfC4a3w+RVw1f/g58f1+kGfW8+8zsCH9et0J7buE7TZZ8lLEHUeRJ8PBzdp5dL39uLdRIVrOX++pk0+Cb9r01E7KwlfqwHafLNrCUQPLO5/1f8g4wDbu/+bHoNOi3hSaOpJSYCY4dp0BFphFBIaBaPf0t/pj3dA58u1MglvW+zclZetZep8ecXfd33A+Cm4Jffffz/333+/y67v3jMFgMiuxQoBoM8teq1hwTOw/Zfi8vmPQlY63PwbXPAoJCzQWzQHPgz3boAJM/QD5YMLYLedV+KhzbDwWf1LufOVevHv1ychcXFJOQoKYP0MaD1Y73rpcBk06aJnCzmZZcufmwWrP4a3e8Hc+0gL7gS3LNJtu4yBWxfrX+pLXyvZbs00rRDaXwJXfwkTZ+mH8xdXQUEujH679O2YImV7NY98BcLaaCX0wUB4f4BWnD2uL67j7WcpkCXw0wOwbR60vxhsQfq8LUj/PewXm7PStfxthpIWUso+cv8IrXCP7tDHxyylEHpa5MdOo2HAvVqRz7wO3u0L304qPp+SACofGnYofXz1DbPQbHAC7q8UTkdEm0IadYLp42HF+7Btvn6QDHxY73cf/ATcvxke3Kodo3wD9IPt1sV61vD5lXr3UF4O/HC7fmCNnQaXvaGVSkhL/Wvc3tt295+Qthe6X6OPPTxg6GT9q/fdc0sqqEKO79YP3rn3W9f4lPXdJpfcIurlC/3u0ltv91ommaM7YN4j0GaolsvLR/+qvmGW/vV88Uslf2VXFt8AbabJOQkIXPQfuHc9NDrtIXvxS/DILnhwm1aoV04teT76Ati3RisDgOXvwKljevdSaYhouVMspVA4UwhtdWbd4VPgsT1wy0LoOAp2/KYVK8CRrfrdbZSCWWg2OJ6zTykA+IXATT9D+5Hw86PwzSRo1BnOu79kndP354e3gRvn6/evrtbtDm6AS9/Qv2ZB2+UvfA4Ob4G104rbxk3XZpX2I4vLYobBxLngZYOvxsFX4/UsRCltmvnoQjh5RJvAblmkzR5SitNX7CTtsLf0NT0jmXWXluPyd7VCKKRRB7h7NfS8/sw+KkuTLvqhe9sf0O+fENj4zDoi+rsLbKIf3PYygF5XUPl6tvHtzVopdBpdvvd5eFtIsbb2H9sFgU3LfiDagrUfRI/r9PrF3r91+ZFt2nxXhZ1HdRalrJmCMR8ZHMvZqRQAfPxh3Ofa3ODpo80ppz+8SiOgIUycA407wbafoOt4vYZgT8dR2py08Hn9i/jribD+K23u8Tntnzj6fL0+MPRprRA+uRjeG6AXt8UDbvpF29HLC1TnG6Dt+tvnw7wHYe8KGPGCfig7g5p6iLcaAMOfhcad9QNb5cPgCkJVRLSF9H16lnIssXiRudzr9AcPL0i0fEIOx2uTk7etZvLXBfKyAWVmCgaHc/YqBdAmnOFT4NGkkusOFdEgTJtiRrwII18+87wIjPgPZKXC1CF6MfaCx+Ci50vvz8sHzn8AHoyHy97UD93g5nDzr9CoY+Vk6nOr9ihe/bGOLdSt9mOmVBoPT73IP/5LuH8TPL5P73QqD/vF5uO7zlxPKA3fQGjep9hR8Mi2yn+fdR03S7BTFxg8eDC//FLSjPvGG2+UGrcIYNCgQaxerYNAjhw5ktTU1DPqTJ48mVdeeaXc6/74449s2VLsuvLUU0/x++8OChxZDc5upVBIdX752oLh3NuLF1BPp0kXrXD63Ab3rIPBj+vZSXn4+EPsRL0V85/LIKRF+fXtaRCmt5P6hWlzVn0KgV2Z+EOF21IPbIAThyo3UwAd4uTAesg4BMd2utF2VPdLsONqJkyYwIwZM0qUzZgxo1JB6ebNm0dISEi1rnu6UpgyZQrDhjkgaGQ1MUrBmfS/G0a+5DwzzukMfgIe2FI1ZVJfKFwYLwy9XVml0GYwoLRfR0Geey0yg5kpOJAxY8bw008/FSXUSUpKYv/+/UyfPp1evXrRuXNnnn766VLbRkVFcfToUQCef/552rVrx3nnnVcUWht0WIzevXvTrVs3rrrqKjIzM1m2bBmzZ8/m4Ycfpnv37uzcuZNJkybx7bfa92jBggX06NGDLl26cNNNN5GdnV10vaeffpqePXvSpUsXtm7d6rDvwb39FM42RNz3l6NPAwhuUWwKqoz5CKBpT/ANglUf6WN3mSmkW/H4Kpp91lfmPwYHNzq2zyZd4OIXyjwdFhZGnz59mD9/PqNHj2bGjBmMGzeOJ554grCwMPLz8xk6dCgbNmyga9eupfaxZs0aZsyYQVxcHHl5efTs2ZPYWB388bLLLuPuu7X/0pNPPslHH33E3XffzahRo7j00ksZM2ZMib6ysrKYNGkSCxYsoF27dtxwww2899573HfffQBERESwdu1a3n33XV555RX+97//OeBLMjMFQ30ivK32ZIbKzxQ8vfSi/8nDgEBEBWsX9QGlYMnL0CBCb1QwOAx7E1Kh6ejrr7+mZ8+e9OjRg82bN5cw9ZzO0qVLueKKK2jQoAFBQUGMGjWq6Fx8fDznn38+Xbp04csvv2Tz5s3lyrJt2zaio6Np107fsxMnTmTJkiVF56+88koAYmNjiwLoOQKXzBREJAnIAPKBPKVULxEJA2YCUUASME4pVXHyXMPZQ3hbvZPIFqK34FaWNoP1TrHQKPeYSSUs0H4pF7+sF9PdkXJ+0TuT0aNHc//997N27VoyMzMJCwvjlVdeYdWqVYSGhjJp0iSysrKq1fcdd9zBrFmz6NatG9OmTatSjoPS8PX1BcDT09OhwflcOVMYrJTqrpQqjGH8GLBAKRUDLLCODYZiIqzF5srOEgopzKfhDusJBQXw+2St4GInuVgY9yMgIIDBgwdz0003MWHCBNLT0/H39yc4OJhDhw4xf/78ctsPHDiQH3/8kVOnTpGRkcGcOXOKzmVkZBAZGUlubi5fflmcGyQwMLDUJDrt27cnKSmJhAQd8+vzzz/nggsucNBIy6YumY9Go7NVYb1f7jpRDHWS8Db6vare2OFttWJod5HDRap1Nn2rkwQN+Vfl/GoMVWbChAmsX7+eCRMm0K1bN3r06EGHDh245pprGDBgQLlte/bsydVXX023bt24+OKL6d27d9G5J598kr59+zJgwAA6dCj+gTJ+/HhefvllevTowc6dxbmXbDYbn3zyCWPHjqVLly54eHhw++23O37ApyGqosiezrioyC7gOKCAD5RSH4pIqlIqxDovwPHC49Pa2qcsjLXfQnbixImixNjuiruPsbzx2U4d4ty/b2V3y7Hsan2d02UZPHjwGruZbK3Sq1cvVbgHHqzMa+f10zGwbCFw6x+OTCXqchYvXkzjxo3p2NFN/EhKISMjo0YZ1KpLfHz8Gd+riJR5b7tq99F5SuesbQT8JiIl9lMppZSIlKqtVFVTFroZ7j7GcsenFPjtotU5Y2gV4QahKqpKzkloca4OOOhGCsFQt3CJUlDFOWsPi8gPQB/gkIhEKqUOWKkND7tCNkMdRqQ4pefZSIMwuGpqxfUMhhpQ6z83RMRfRAILPwMXApvQOW8nWtUmArNqWzaDwWA423HFTKEx8INeNsAL+Eop9bOIrAK+FpGbgd3AOBfIZjAYXIhSCqlPIVrqONVZM671mYJSKlEp1c16dVZKPW+VpyilhiqlYpRSw5RSx2pbNoOhLERkhIhsE5EEETnDhiUik0TkiIjEWa9/2J2bKCI7rNfE09saNDabjZSUlGo9yAxnopQiJSUFm61qUYFNmAuDoQJExBN4BxgOJAOrRGS2Uup019aZSqm7TmsbBjwN9ELvtltjtTWOmafRvHlzkpOTOXLkiKtFcQpZWVlVfkDXFJvNRvPmzavUxigFg6Fi+gAJSqlEABGZgfarKTveQTEXAb8VznxF5DdgBDDdSbLWW7y9vYmOrqJjYj1i8eLF9OhRTiKpOoJRCgZDxTQD9todJwN9S6l3lYgMBLYD9yul9pbRtllpFznNB6dEGIQTJ07UOCxCXcbdxwf1Z4xGKRgMjmEOMF0plS0it6G98odUpYOz2QfH3ccH9WeMxgPGYKiYfYB9kormVlkR1kaJbOvwf0BsZdsaDHUJl4S5cBQicgS9fbWQCOCoi8SpLdx9jHVpfK2UUg1FxAttEhqKfqCvAq5RShXFPi50vLQ+XwE8qpQ611poXgMU5ntdC8RWtLvuLLy33X18ULfG2Eop1bC0E/XafHT6oERktati1dQW7j7Gujg+pVSeiNwF/AJ4Ah8rpTaLyBRgtVJqNnCPiIwC8oBjwCSr7TEReRatSACmVGa79dl2b7v7+KD+jLFezxROp7586TXB3cfo7uOrLu7+vbj7+KD+jNGsKRgMBoOhCHdTCh+6WoBawN3H6O7jqy7u/r24+/ignozRrcxHBoPBYKgZ7jZTMBgMBkMNcBulUFHAsvqGiLQQkUUiskVENovIvVZ5mIj8ZgVX+01EqpDBvu4hIp4isk5E5lrH0SLyt/V3nCkiZ3XOSXe7r8Hc23X93nYLpWAXsOxioBMwQUQ6uVaqGpMHPKiU6gScC9xpjekxYIFSKgZYYB3XZ+4F4u2OXwReV0q1RadsvdklUtUB3PS+BnNv1+l72y2UAnYBy5RSOUBhwLJ6i1LqgFJqrfU5A31zNUOP61Or2qfA5S4R0AGISHPgErQHcGFu7iHAt1aVej0+B+B29zWYe9uqUmfH5y5KodJBx+ojIhIF9AD+BhoXes4CB9FJi+orbwCPAAXWcTiQqpTKs47d6u9YDdz6vgZzb7tArgpxF6XgtohIAPAdcJ9SKt3+nNJbx+rl9jERuRQ4rJRa42pZDK7B3Nt1k3od5sIOtww6JiLe6H+aL5VS31vFhwrj7IhIJHDYdRLWiAHAKBEZCdiAIOC/QIiIeFm/qNzi71gD3PK+BnNvU4f/lu4yU1gFxFir+z7AeGC2i2WqEZYN8iMgXin1mt2p2UBhSseJwKzals0RKKUeV0o1V0pFof9eC5VS1wKLgDFWtXo7Pgfhdvc1mHvbqlZnx+cWSsHSvIUBy+KBr+0jWNZTBgDXA0Ps8v6OBF4AhovIDmCYdexOPAo8ICIJaDvsRy6Wx2W46X0N5t6u0/e28Wg2GAwGQxFuMVMwGAwGg2MwSsFgMBgMRRilYDAYDIYijFIwGAwGQxFGKRgMBoOhCKMU6iEikm+3lS/OkdEzRSRKRDY5qj+DoSqYe9v1uItH89nGKaVUd1cLYTA4AXNvuxgzU3AjRCRJRF4SkY0islJE2lrlUSKyUEQ2iMgCEWlplTcWkR9EZL316m915SkiU61Y97+KiJ/LBmUwYO7t2sQohfqJ32lT7KvtzqUppboAb6MjNQK8BXyqlOoKfAm8aZW/CfyhlOoG9AQKvWVjgHeUUp2BVOAqp47GYCjG3Nsuxng010NE5IRSKqCU8iRgiFIq0Qo4dlApFS4iR4FIpVSuVX5AKRUhIkeA5kqpbLs+ooDfrEQniMijgLdS6rlaGJrhLMfc267HzBTcD1XG56qQbfc5H7P2ZKgbmHu7FjBKwf242u59ufV5GTpaI8C1wFLr8wLgDijKJxtcW0IaDNXA3Nu1gNGS9RM/EYmzO/5ZKVW4dS9URDagfxFNsMruBj4RkYeBI8CNVvm9wIcicjP6V9MdwAEMBtdh7m0XY9YU3AjL7tpLKXXU1bIYDI7E3Nu1hzEfGQwGg6EIM1MwGAwGQxFmpmAwGAyGIoxSMBgMBkMRRikYDAaDoQijFAwGg8FQhFEKBoPBYCjCKAWDwWAwFPH/XzhWcInrmuUAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7504\n","Validation AUC: 0.7482\n","Validation Balanced_ACC: 0.4844\n","Validation MI: 0.1390\n","Validation Normalized MI: 0.2076\n","Validation Adjusted MI: 0.2076\n","Validation aUc_Sklearn: 0.8305\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 568.2831, Accuracy: 0.4900\n","Training loss (for one batch) at step 10: 437.3378, Accuracy: 0.5036\n","Training loss (for one batch) at step 20: 451.9300, Accuracy: 0.5438\n","Training loss (for one batch) at step 30: 486.5266, Accuracy: 0.5500\n","Training loss (for one batch) at step 40: 422.0882, Accuracy: 0.5534\n","Training loss (for one batch) at step 50: 466.7481, Accuracy: 0.5537\n","Training loss (for one batch) at step 60: 473.6014, Accuracy: 0.5564\n","Training loss (for one batch) at step 70: 416.8942, Accuracy: 0.5566\n","Training loss (for one batch) at step 80: 466.3800, Accuracy: 0.5563\n","Training loss (for one batch) at step 90: 472.3071, Accuracy: 0.5563\n","Training loss (for one batch) at step 100: 436.4700, Accuracy: 0.5597\n","Training loss (for one batch) at step 110: 406.7233, Accuracy: 0.5622\n","Training loss (for one batch) at step 120: 441.3499, Accuracy: 0.5639\n","Training loss (for one batch) at step 130: 458.7116, Accuracy: 0.5653\n","Training loss (for one batch) at step 140: 408.3489, Accuracy: 0.5642\n","---- Training ----\n","Training loss: 412.6354\n","Training acc over epoch: 0.5650\n","---- Validation ----\n","Validation loss: 111.9293\n","Validation acc: 0.5134\n","Time taken: 68.80s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 438.6027, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 412.2669, Accuracy: 0.6282\n","Training loss (for one batch) at step 20: 388.8326, Accuracy: 0.6171\n","Training loss (for one batch) at step 30: 438.9496, Accuracy: 0.6174\n","Training loss (for one batch) at step 40: 429.8932, Accuracy: 0.6178\n","Training loss (for one batch) at step 50: 406.5327, Accuracy: 0.6192\n","Training loss (for one batch) at step 60: 388.8469, Accuracy: 0.6185\n","Training loss (for one batch) at step 70: 400.0368, Accuracy: 0.6165\n","Training loss (for one batch) at step 80: 390.3627, Accuracy: 0.6175\n","Training loss (for one batch) at step 90: 415.1183, Accuracy: 0.6169\n","Training loss (for one batch) at step 100: 447.9932, Accuracy: 0.6175\n","Training loss (for one batch) at step 110: 377.0223, Accuracy: 0.6171\n","Training loss (for one batch) at step 120: 391.4781, Accuracy: 0.6158\n","Training loss (for one batch) at step 130: 407.4236, Accuracy: 0.6175\n","Training loss (for one batch) at step 140: 404.4418, Accuracy: 0.6172\n","---- Training ----\n","Training loss: 332.7355\n","Training acc over epoch: 0.6173\n","---- Validation ----\n","Validation loss: 116.7803\n","Validation acc: 0.5215\n","Time taken: 59.94s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 370.5181, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 383.8105, Accuracy: 0.6445\n","Training loss (for one batch) at step 20: 379.3936, Accuracy: 0.6414\n","Training loss (for one batch) at step 30: 357.8014, Accuracy: 0.6371\n","Training loss (for one batch) at step 40: 414.6072, Accuracy: 0.6439\n","Training loss (for one batch) at step 50: 414.7042, Accuracy: 0.6422\n","Training loss (for one batch) at step 60: 391.1946, Accuracy: 0.6387\n","Training loss (for one batch) at step 70: 405.6899, Accuracy: 0.6372\n","Training loss (for one batch) at step 80: 387.7918, Accuracy: 0.6375\n","Training loss (for one batch) at step 90: 381.6738, Accuracy: 0.6377\n","Training loss (for one batch) at step 100: 368.9249, Accuracy: 0.6350\n","Training loss (for one batch) at step 110: 357.1618, Accuracy: 0.6352\n","Training loss (for one batch) at step 120: 393.7811, Accuracy: 0.6361\n","Training loss (for one batch) at step 130: 403.5355, Accuracy: 0.6375\n","Training loss (for one batch) at step 140: 364.4939, Accuracy: 0.6384\n","---- Training ----\n","Training loss: 339.4365\n","Training acc over epoch: 0.6384\n","---- Validation ----\n","Validation loss: 72.5300\n","Validation acc: 0.6577\n","Time taken: 61.15s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 379.4445, Accuracy: 0.6400\n","Training loss (for one batch) at step 10: 372.8696, Accuracy: 0.6518\n","Training loss (for one batch) at step 20: 374.9841, Accuracy: 0.6519\n","Training loss (for one batch) at step 30: 347.1618, Accuracy: 0.6490\n","Training loss (for one batch) at step 40: 351.9590, Accuracy: 0.6551\n","Training loss (for one batch) at step 50: 358.9036, Accuracy: 0.6537\n","Training loss (for one batch) at step 60: 354.5307, Accuracy: 0.6513\n","Training loss (for one batch) at step 70: 336.0504, Accuracy: 0.6523\n","Training loss (for one batch) at step 80: 349.8038, Accuracy: 0.6494\n","Training loss (for one batch) at step 90: 353.6759, Accuracy: 0.6518\n","Training loss (for one batch) at step 100: 350.6976, Accuracy: 0.6525\n","Training loss (for one batch) at step 110: 364.6344, Accuracy: 0.6547\n","Training loss (for one batch) at step 120: 352.3576, Accuracy: 0.6553\n","Training loss (for one batch) at step 130: 349.2221, Accuracy: 0.6547\n","Training loss (for one batch) at step 140: 347.7408, Accuracy: 0.6541\n","---- Training ----\n","Training loss: 351.7236\n","Training acc over epoch: 0.6546\n","---- Validation ----\n","Validation loss: 68.7718\n","Validation acc: 0.6983\n","Time taken: 66.51s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 344.7408, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 364.4579, Accuracy: 0.6673\n","Training loss (for one batch) at step 20: 387.5877, Accuracy: 0.6681\n","Training loss (for one batch) at step 30: 386.8831, Accuracy: 0.6610\n","Training loss (for one batch) at step 40: 378.7969, Accuracy: 0.6556\n","Training loss (for one batch) at step 50: 369.3926, Accuracy: 0.6575\n","Training loss (for one batch) at step 60: 345.5716, Accuracy: 0.6598\n","Training loss (for one batch) at step 70: 338.2794, Accuracy: 0.6615\n","Training loss (for one batch) at step 80: 348.9991, Accuracy: 0.6625\n","Training loss (for one batch) at step 90: 353.6831, Accuracy: 0.6634\n","Training loss (for one batch) at step 100: 349.4561, Accuracy: 0.6627\n","Training loss (for one batch) at step 110: 375.4094, Accuracy: 0.6624\n","Training loss (for one batch) at step 120: 362.9272, Accuracy: 0.6609\n","Training loss (for one batch) at step 130: 357.0318, Accuracy: 0.6622\n","Training loss (for one batch) at step 140: 329.0805, Accuracy: 0.6644\n","---- Training ----\n","Training loss: 308.0832\n","Training acc over epoch: 0.6636\n","---- Validation ----\n","Validation loss: 75.3626\n","Validation acc: 0.7058\n","Time taken: 62.33s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 335.2616, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 346.1322, Accuracy: 0.6691\n","Training loss (for one batch) at step 20: 355.4135, Accuracy: 0.6771\n","Training loss (for one batch) at step 30: 351.8374, Accuracy: 0.6797\n","Training loss (for one batch) at step 40: 351.6768, Accuracy: 0.6741\n","Training loss (for one batch) at step 50: 356.8464, Accuracy: 0.6780\n","Training loss (for one batch) at step 60: 325.4394, Accuracy: 0.6805\n","Training loss (for one batch) at step 70: 350.4631, Accuracy: 0.6832\n","Training loss (for one batch) at step 80: 337.1670, Accuracy: 0.6804\n","Training loss (for one batch) at step 90: 316.0183, Accuracy: 0.6793\n","Training loss (for one batch) at step 100: 336.9574, Accuracy: 0.6781\n","Training loss (for one batch) at step 110: 328.0048, Accuracy: 0.6787\n","Training loss (for one batch) at step 120: 332.7192, Accuracy: 0.6779\n","Training loss (for one batch) at step 130: 345.3898, Accuracy: 0.6786\n","Training loss (for one batch) at step 140: 373.0555, Accuracy: 0.6795\n","---- Training ----\n","Training loss: 313.9550\n","Training acc over epoch: 0.6789\n","---- Validation ----\n","Validation loss: 79.0183\n","Validation acc: 0.6929\n","Time taken: 61.90s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 348.7469, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 344.4017, Accuracy: 0.6973\n","Training loss (for one batch) at step 20: 350.7155, Accuracy: 0.6924\n","Training loss (for one batch) at step 30: 335.3892, Accuracy: 0.6939\n","Training loss (for one batch) at step 40: 321.6350, Accuracy: 0.6951\n","Training loss (for one batch) at step 50: 332.8470, Accuracy: 0.6961\n","Training loss (for one batch) at step 60: 323.5509, Accuracy: 0.7005\n","Training loss (for one batch) at step 70: 350.9400, Accuracy: 0.7015\n","Training loss (for one batch) at step 80: 341.6899, Accuracy: 0.7002\n","Training loss (for one batch) at step 90: 320.9451, Accuracy: 0.7012\n","Training loss (for one batch) at step 100: 344.4136, Accuracy: 0.6985\n","Training loss (for one batch) at step 110: 343.0099, Accuracy: 0.7003\n","Training loss (for one batch) at step 120: 342.8688, Accuracy: 0.6997\n","Training loss (for one batch) at step 130: 321.8667, Accuracy: 0.7015\n","Training loss (for one batch) at step 140: 322.1480, Accuracy: 0.7021\n","---- Training ----\n","Training loss: 314.0279\n","Training acc over epoch: 0.7001\n","---- Validation ----\n","Validation loss: 75.6584\n","Validation acc: 0.7037\n","Time taken: 61.02s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 313.5968, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 322.5370, Accuracy: 0.7191\n","Training loss (for one batch) at step 20: 341.3511, Accuracy: 0.7205\n","Training loss (for one batch) at step 30: 335.2746, Accuracy: 0.7203\n","Training loss (for one batch) at step 40: 301.4094, Accuracy: 0.7195\n","Training loss (for one batch) at step 50: 323.3734, Accuracy: 0.7180\n","Training loss (for one batch) at step 60: 331.7534, Accuracy: 0.7144\n","Training loss (for one batch) at step 70: 355.3971, Accuracy: 0.7148\n","Training loss (for one batch) at step 80: 336.0733, Accuracy: 0.7119\n","Training loss (for one batch) at step 90: 319.7128, Accuracy: 0.7116\n","Training loss (for one batch) at step 100: 326.7942, Accuracy: 0.7129\n","Training loss (for one batch) at step 110: 329.0853, Accuracy: 0.7158\n","Training loss (for one batch) at step 120: 326.3042, Accuracy: 0.7138\n","Training loss (for one batch) at step 130: 305.1540, Accuracy: 0.7144\n","Training loss (for one batch) at step 140: 329.6453, Accuracy: 0.7143\n","---- Training ----\n","Training loss: 273.9512\n","Training acc over epoch: 0.7147\n","---- Validation ----\n","Validation loss: 72.1647\n","Validation acc: 0.7071\n","Time taken: 65.00s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 309.6161, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 313.6886, Accuracy: 0.7436\n","Training loss (for one batch) at step 20: 322.5263, Accuracy: 0.7362\n","Training loss (for one batch) at step 30: 329.0206, Accuracy: 0.7242\n","Training loss (for one batch) at step 40: 315.5564, Accuracy: 0.7276\n","Training loss (for one batch) at step 50: 311.4828, Accuracy: 0.7278\n","Training loss (for one batch) at step 60: 319.9177, Accuracy: 0.7270\n","Training loss (for one batch) at step 70: 317.6866, Accuracy: 0.7277\n","Training loss (for one batch) at step 80: 320.6369, Accuracy: 0.7228\n","Training loss (for one batch) at step 90: 327.1533, Accuracy: 0.7236\n","Training loss (for one batch) at step 100: 322.1693, Accuracy: 0.7230\n","Training loss (for one batch) at step 110: 328.1114, Accuracy: 0.7219\n","Training loss (for one batch) at step 120: 321.6311, Accuracy: 0.7224\n","Training loss (for one batch) at step 130: 297.9505, Accuracy: 0.7240\n","Training loss (for one batch) at step 140: 335.2967, Accuracy: 0.7254\n","---- Training ----\n","Training loss: 286.4736\n","Training acc over epoch: 0.7260\n","---- Validation ----\n","Validation loss: 62.7328\n","Validation acc: 0.7157\n","Time taken: 61.32s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 318.9900, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 302.2181, Accuracy: 0.7309\n","Training loss (for one batch) at step 20: 325.4204, Accuracy: 0.7357\n","Training loss (for one batch) at step 30: 309.2781, Accuracy: 0.7358\n","Training loss (for one batch) at step 40: 298.2429, Accuracy: 0.7307\n","Training loss (for one batch) at step 50: 302.3362, Accuracy: 0.7345\n","Training loss (for one batch) at step 60: 299.2465, Accuracy: 0.7364\n","Training loss (for one batch) at step 70: 321.8457, Accuracy: 0.7370\n","Training loss (for one batch) at step 80: 316.0764, Accuracy: 0.7367\n","Training loss (for one batch) at step 90: 341.8124, Accuracy: 0.7335\n","Training loss (for one batch) at step 100: 308.9229, Accuracy: 0.7327\n","Training loss (for one batch) at step 110: 303.6467, Accuracy: 0.7336\n","Training loss (for one batch) at step 120: 299.8018, Accuracy: 0.7350\n","Training loss (for one batch) at step 130: 300.6668, Accuracy: 0.7373\n","Training loss (for one batch) at step 140: 315.6631, Accuracy: 0.7362\n","---- Training ----\n","Training loss: 278.0719\n","Training acc over epoch: 0.7366\n","---- Validation ----\n","Validation loss: 61.5623\n","Validation acc: 0.7198\n","Time taken: 64.97s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 326.9460, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 320.6804, Accuracy: 0.7473\n","Training loss (for one batch) at step 20: 300.0578, Accuracy: 0.7443\n","Training loss (for one batch) at step 30: 314.2905, Accuracy: 0.7397\n","Training loss (for one batch) at step 40: 293.0572, Accuracy: 0.7407\n","Training loss (for one batch) at step 50: 323.0417, Accuracy: 0.7422\n","Training loss (for one batch) at step 60: 299.3143, Accuracy: 0.7448\n","Training loss (for one batch) at step 70: 303.9180, Accuracy: 0.7432\n","Training loss (for one batch) at step 80: 316.0914, Accuracy: 0.7430\n","Training loss (for one batch) at step 90: 321.6951, Accuracy: 0.7421\n","Training loss (for one batch) at step 100: 301.6747, Accuracy: 0.7414\n","Training loss (for one batch) at step 110: 309.5676, Accuracy: 0.7418\n","Training loss (for one batch) at step 120: 322.7063, Accuracy: 0.7419\n","Training loss (for one batch) at step 130: 298.5293, Accuracy: 0.7414\n","Training loss (for one batch) at step 140: 291.1007, Accuracy: 0.7416\n","---- Training ----\n","Training loss: 274.7017\n","Training acc over epoch: 0.7414\n","---- Validation ----\n","Validation loss: 80.6227\n","Validation acc: 0.7303\n","Time taken: 60.04s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 304.2397, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 293.8421, Accuracy: 0.7509\n","Training loss (for one batch) at step 20: 319.0310, Accuracy: 0.7605\n","Training loss (for one batch) at step 30: 312.1626, Accuracy: 0.7494\n","Training loss (for one batch) at step 40: 312.9362, Accuracy: 0.7483\n","Training loss (for one batch) at step 50: 297.4744, Accuracy: 0.7539\n","Training loss (for one batch) at step 60: 285.4249, Accuracy: 0.7523\n","Training loss (for one batch) at step 70: 311.0377, Accuracy: 0.7530\n","Training loss (for one batch) at step 80: 302.7659, Accuracy: 0.7509\n","Training loss (for one batch) at step 90: 289.6555, Accuracy: 0.7499\n","Training loss (for one batch) at step 100: 308.4319, Accuracy: 0.7509\n","Training loss (for one batch) at step 110: 292.1535, Accuracy: 0.7523\n","Training loss (for one batch) at step 120: 304.6355, Accuracy: 0.7506\n","Training loss (for one batch) at step 130: 320.2207, Accuracy: 0.7511\n","Training loss (for one batch) at step 140: 321.7360, Accuracy: 0.7532\n","---- Training ----\n","Training loss: 272.6035\n","Training acc over epoch: 0.7538\n","---- Validation ----\n","Validation loss: 65.0247\n","Validation acc: 0.7362\n","Time taken: 63.73s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 327.2354, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 288.0884, Accuracy: 0.7518\n","Training loss (for one batch) at step 20: 294.4939, Accuracy: 0.7643\n","Training loss (for one batch) at step 30: 301.4861, Accuracy: 0.7587\n","Training loss (for one batch) at step 40: 299.5453, Accuracy: 0.7571\n","Training loss (for one batch) at step 50: 308.1908, Accuracy: 0.7578\n","Training loss (for one batch) at step 60: 309.6224, Accuracy: 0.7590\n","Training loss (for one batch) at step 70: 313.6192, Accuracy: 0.7580\n","Training loss (for one batch) at step 80: 293.9702, Accuracy: 0.7593\n","Training loss (for one batch) at step 90: 316.3510, Accuracy: 0.7570\n","Training loss (for one batch) at step 100: 308.5866, Accuracy: 0.7583\n","Training loss (for one batch) at step 110: 292.3713, Accuracy: 0.7589\n","Training loss (for one batch) at step 120: 317.2153, Accuracy: 0.7588\n","Training loss (for one batch) at step 130: 302.3272, Accuracy: 0.7579\n","Training loss (for one batch) at step 140: 302.9681, Accuracy: 0.7591\n","---- Training ----\n","Training loss: 278.3014\n","Training acc over epoch: 0.7599\n","---- Validation ----\n","Validation loss: 74.6865\n","Validation acc: 0.7101\n","Time taken: 60.17s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 305.9536, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 292.5565, Accuracy: 0.7627\n","Training loss (for one batch) at step 20: 310.2082, Accuracy: 0.7733\n","Training loss (for one batch) at step 30: 291.7585, Accuracy: 0.7703\n","Training loss (for one batch) at step 40: 305.9544, Accuracy: 0.7698\n","Training loss (for one batch) at step 50: 279.9608, Accuracy: 0.7739\n","Training loss (for one batch) at step 60: 283.8403, Accuracy: 0.7725\n","Training loss (for one batch) at step 70: 294.2223, Accuracy: 0.7721\n","Training loss (for one batch) at step 80: 293.4728, Accuracy: 0.7736\n","Training loss (for one batch) at step 90: 292.2520, Accuracy: 0.7719\n","Training loss (for one batch) at step 100: 286.7873, Accuracy: 0.7711\n","Training loss (for one batch) at step 110: 290.5057, Accuracy: 0.7738\n","Training loss (for one batch) at step 120: 298.0457, Accuracy: 0.7723\n","Training loss (for one batch) at step 130: 290.2370, Accuracy: 0.7704\n","Training loss (for one batch) at step 140: 311.6062, Accuracy: 0.7718\n","---- Training ----\n","Training loss: 274.8362\n","Training acc over epoch: 0.7710\n","---- Validation ----\n","Validation loss: 75.4801\n","Validation acc: 0.7410\n","Time taken: 64.29s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 291.9652, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 294.9038, Accuracy: 0.7945\n","Training loss (for one batch) at step 20: 317.3183, Accuracy: 0.7829\n","Training loss (for one batch) at step 30: 302.1375, Accuracy: 0.7752\n","Training loss (for one batch) at step 40: 311.7945, Accuracy: 0.7761\n","Training loss (for one batch) at step 50: 289.2685, Accuracy: 0.7776\n","Training loss (for one batch) at step 60: 291.3695, Accuracy: 0.7733\n","Training loss (for one batch) at step 70: 296.4028, Accuracy: 0.7731\n","Training loss (for one batch) at step 80: 284.3185, Accuracy: 0.7760\n","Training loss (for one batch) at step 90: 299.1676, Accuracy: 0.7749\n","Training loss (for one batch) at step 100: 298.5912, Accuracy: 0.7729\n","Training loss (for one batch) at step 110: 303.7232, Accuracy: 0.7734\n","Training loss (for one batch) at step 120: 288.7953, Accuracy: 0.7727\n","Training loss (for one batch) at step 130: 307.7017, Accuracy: 0.7729\n","Training loss (for one batch) at step 140: 296.4705, Accuracy: 0.7743\n","---- Training ----\n","Training loss: 255.1895\n","Training acc over epoch: 0.7753\n","---- Validation ----\n","Validation loss: 70.6533\n","Validation acc: 0.7340\n","Time taken: 61.16s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 293.9965, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 294.9586, Accuracy: 0.7655\n","Training loss (for one batch) at step 20: 289.5933, Accuracy: 0.7752\n","Training loss (for one batch) at step 30: 282.5462, Accuracy: 0.7771\n","Training loss (for one batch) at step 40: 302.3198, Accuracy: 0.7702\n","Training loss (for one batch) at step 50: 278.3625, Accuracy: 0.7765\n","Training loss (for one batch) at step 60: 293.8387, Accuracy: 0.7785\n","Training loss (for one batch) at step 70: 297.6463, Accuracy: 0.7769\n","Training loss (for one batch) at step 80: 297.8519, Accuracy: 0.7781\n","Training loss (for one batch) at step 90: 304.5286, Accuracy: 0.7777\n","Training loss (for one batch) at step 100: 300.4453, Accuracy: 0.7790\n","Training loss (for one batch) at step 110: 281.3574, Accuracy: 0.7803\n","Training loss (for one batch) at step 120: 287.2178, Accuracy: 0.7799\n","Training loss (for one batch) at step 130: 289.8464, Accuracy: 0.7795\n","Training loss (for one batch) at step 140: 292.2887, Accuracy: 0.7811\n","---- Training ----\n","Training loss: 252.5204\n","Training acc over epoch: 0.7803\n","---- Validation ----\n","Validation loss: 69.4193\n","Validation acc: 0.7324\n","Time taken: 64.52s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 295.8695, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 286.6907, Accuracy: 0.8009\n","Training loss (for one batch) at step 20: 286.0630, Accuracy: 0.7948\n","Training loss (for one batch) at step 30: 299.8842, Accuracy: 0.7868\n","Training loss (for one batch) at step 40: 297.5775, Accuracy: 0.7861\n","Training loss (for one batch) at step 50: 274.2227, Accuracy: 0.7904\n","Training loss (for one batch) at step 60: 298.6975, Accuracy: 0.7890\n","Training loss (for one batch) at step 70: 278.7169, Accuracy: 0.7906\n","Training loss (for one batch) at step 80: 282.7876, Accuracy: 0.7904\n","Training loss (for one batch) at step 90: 279.3397, Accuracy: 0.7899\n","Training loss (for one batch) at step 100: 281.4591, Accuracy: 0.7869\n","Training loss (for one batch) at step 110: 285.3374, Accuracy: 0.7877\n","Training loss (for one batch) at step 120: 286.2715, Accuracy: 0.7865\n","Training loss (for one batch) at step 130: 296.9460, Accuracy: 0.7868\n","Training loss (for one batch) at step 140: 298.2442, Accuracy: 0.7862\n","---- Training ----\n","Training loss: 243.2220\n","Training acc over epoch: 0.7866\n","---- Validation ----\n","Validation loss: 69.1680\n","Validation acc: 0.7501\n","Time taken: 68.49s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 287.6788, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 300.5267, Accuracy: 0.7909\n","Training loss (for one batch) at step 20: 277.8903, Accuracy: 0.7876\n","Training loss (for one batch) at step 30: 282.7995, Accuracy: 0.7800\n","Training loss (for one batch) at step 40: 279.7767, Accuracy: 0.7834\n","Training loss (for one batch) at step 50: 278.8689, Accuracy: 0.7892\n","Training loss (for one batch) at step 60: 278.0653, Accuracy: 0.7903\n","Training loss (for one batch) at step 70: 286.2449, Accuracy: 0.7900\n","Training loss (for one batch) at step 80: 293.3292, Accuracy: 0.7891\n","Training loss (for one batch) at step 90: 264.5290, Accuracy: 0.7878\n","Training loss (for one batch) at step 100: 276.8055, Accuracy: 0.7860\n","Training loss (for one batch) at step 110: 287.2839, Accuracy: 0.7859\n","Training loss (for one batch) at step 120: 309.3788, Accuracy: 0.7856\n","Training loss (for one batch) at step 130: 290.3387, Accuracy: 0.7865\n","Training loss (for one batch) at step 140: 288.9032, Accuracy: 0.7864\n","---- Training ----\n","Training loss: 265.9966\n","Training acc over epoch: 0.7867\n","---- Validation ----\n","Validation loss: 67.6321\n","Validation acc: 0.7397\n","Time taken: 65.69s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 287.2849, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 279.0876, Accuracy: 0.7936\n","Training loss (for one batch) at step 20: 283.4956, Accuracy: 0.7910\n","Training loss (for one batch) at step 30: 282.6040, Accuracy: 0.7823\n","Training loss (for one batch) at step 40: 297.4592, Accuracy: 0.7846\n","Training loss (for one batch) at step 50: 256.6135, Accuracy: 0.7927\n","Training loss (for one batch) at step 60: 285.0305, Accuracy: 0.7933\n","Training loss (for one batch) at step 70: 257.3356, Accuracy: 0.7949\n","Training loss (for one batch) at step 80: 273.1933, Accuracy: 0.7951\n","Training loss (for one batch) at step 90: 292.5005, Accuracy: 0.7940\n","Training loss (for one batch) at step 100: 285.5302, Accuracy: 0.7932\n","Training loss (for one batch) at step 110: 287.1104, Accuracy: 0.7944\n","Training loss (for one batch) at step 120: 270.4535, Accuracy: 0.7943\n","Training loss (for one batch) at step 130: 288.0115, Accuracy: 0.7952\n","Training loss (for one batch) at step 140: 265.4819, Accuracy: 0.7957\n","---- Training ----\n","Training loss: 263.6748\n","Training acc over epoch: 0.7943\n","---- Validation ----\n","Validation loss: 71.4707\n","Validation acc: 0.7254\n","Time taken: 63.41s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 276.2089, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 266.6432, Accuracy: 0.7982\n","Training loss (for one batch) at step 20: 269.7543, Accuracy: 0.7990\n","Training loss (for one batch) at step 30: 287.0071, Accuracy: 0.7913\n","Training loss (for one batch) at step 40: 268.1562, Accuracy: 0.7961\n","Training loss (for one batch) at step 50: 283.4767, Accuracy: 0.7975\n","Training loss (for one batch) at step 60: 270.7737, Accuracy: 0.7934\n","Training loss (for one batch) at step 70: 280.0797, Accuracy: 0.7961\n","Training loss (for one batch) at step 80: 273.4070, Accuracy: 0.7931\n","Training loss (for one batch) at step 90: 281.4162, Accuracy: 0.7935\n","Training loss (for one batch) at step 100: 265.3513, Accuracy: 0.7934\n","Training loss (for one batch) at step 110: 285.8152, Accuracy: 0.7941\n","Training loss (for one batch) at step 120: 269.8726, Accuracy: 0.7954\n","Training loss (for one batch) at step 130: 295.2633, Accuracy: 0.7947\n","Training loss (for one batch) at step 140: 290.7611, Accuracy: 0.7940\n","---- Training ----\n","Training loss: 234.0087\n","Training acc over epoch: 0.7940\n","---- Validation ----\n","Validation loss: 68.8456\n","Validation acc: 0.7491\n","Time taken: 65.90s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 264.8388, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 263.9401, Accuracy: 0.8100\n","Training loss (for one batch) at step 20: 287.3592, Accuracy: 0.8052\n","Training loss (for one batch) at step 30: 288.9638, Accuracy: 0.8068\n","Training loss (for one batch) at step 40: 294.9315, Accuracy: 0.8007\n","Training loss (for one batch) at step 50: 270.0282, Accuracy: 0.7992\n","Training loss (for one batch) at step 60: 269.6413, Accuracy: 0.8007\n","Training loss (for one batch) at step 70: 270.5291, Accuracy: 0.7996\n","Training loss (for one batch) at step 80: 300.7979, Accuracy: 0.7956\n","Training loss (for one batch) at step 90: 280.7478, Accuracy: 0.7943\n","Training loss (for one batch) at step 100: 267.3016, Accuracy: 0.7956\n","Training loss (for one batch) at step 110: 262.2457, Accuracy: 0.7960\n","Training loss (for one batch) at step 120: 271.8864, Accuracy: 0.7983\n","Training loss (for one batch) at step 130: 279.3852, Accuracy: 0.7962\n","Training loss (for one batch) at step 140: 257.5609, Accuracy: 0.7972\n","---- Training ----\n","Training loss: 232.2364\n","Training acc over epoch: 0.7976\n","---- Validation ----\n","Validation loss: 63.3904\n","Validation acc: 0.7311\n","Time taken: 60.80s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 275.0459, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 266.6565, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 275.9676, Accuracy: 0.8095\n","Training loss (for one batch) at step 30: 275.9047, Accuracy: 0.8061\n","Training loss (for one batch) at step 40: 274.3126, Accuracy: 0.8041\n","Training loss (for one batch) at step 50: 259.8558, Accuracy: 0.8049\n","Training loss (for one batch) at step 60: 258.5053, Accuracy: 0.8105\n","Training loss (for one batch) at step 70: 264.7143, Accuracy: 0.8099\n","Training loss (for one batch) at step 80: 281.0883, Accuracy: 0.8072\n","Training loss (for one batch) at step 90: 256.6648, Accuracy: 0.8090\n","Training loss (for one batch) at step 100: 270.2168, Accuracy: 0.8075\n","Training loss (for one batch) at step 110: 250.5022, Accuracy: 0.8107\n","Training loss (for one batch) at step 120: 270.2244, Accuracy: 0.8088\n","Training loss (for one batch) at step 130: 265.8899, Accuracy: 0.8086\n","Training loss (for one batch) at step 140: 270.2143, Accuracy: 0.8083\n","---- Training ----\n","Training loss: 245.8899\n","Training acc over epoch: 0.8082\n","---- Validation ----\n","Validation loss: 65.7369\n","Validation acc: 0.7456\n","Time taken: 64.39s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 276.1351, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 291.4082, Accuracy: 0.7955\n","Training loss (for one batch) at step 20: 268.5733, Accuracy: 0.8090\n","Training loss (for one batch) at step 30: 254.4498, Accuracy: 0.8129\n","Training loss (for one batch) at step 40: 265.7195, Accuracy: 0.8102\n","Training loss (for one batch) at step 50: 266.6225, Accuracy: 0.8092\n","Training loss (for one batch) at step 60: 263.0423, Accuracy: 0.8105\n","Training loss (for one batch) at step 70: 262.4725, Accuracy: 0.8101\n","Training loss (for one batch) at step 80: 262.0826, Accuracy: 0.8059\n","Training loss (for one batch) at step 90: 261.9514, Accuracy: 0.8082\n","Training loss (for one batch) at step 100: 272.9232, Accuracy: 0.8061\n","Training loss (for one batch) at step 110: 261.0333, Accuracy: 0.8063\n","Training loss (for one batch) at step 120: 278.7687, Accuracy: 0.8080\n","Training loss (for one batch) at step 130: 263.6119, Accuracy: 0.8079\n","Training loss (for one batch) at step 140: 251.8516, Accuracy: 0.8079\n","---- Training ----\n","Training loss: 225.3245\n","Training acc over epoch: 0.8082\n","---- Validation ----\n","Validation loss: 86.2905\n","Validation acc: 0.7324\n","Time taken: 59.72s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 256.5095, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 272.0696, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 270.7391, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 269.6561, Accuracy: 0.8200\n","Training loss (for one batch) at step 40: 236.1044, Accuracy: 0.8166\n","Training loss (for one batch) at step 50: 260.8615, Accuracy: 0.8173\n","Training loss (for one batch) at step 60: 271.0296, Accuracy: 0.8166\n","Training loss (for one batch) at step 70: 253.4761, Accuracy: 0.8203\n","Training loss (for one batch) at step 80: 272.0312, Accuracy: 0.8153\n","Training loss (for one batch) at step 90: 292.8952, Accuracy: 0.8127\n","Training loss (for one batch) at step 100: 248.8977, Accuracy: 0.8121\n","Training loss (for one batch) at step 110: 267.0077, Accuracy: 0.8134\n","Training loss (for one batch) at step 120: 260.1814, Accuracy: 0.8131\n","Training loss (for one batch) at step 130: 271.7419, Accuracy: 0.8122\n","Training loss (for one batch) at step 140: 262.2242, Accuracy: 0.8125\n","---- Training ----\n","Training loss: 235.3381\n","Training acc over epoch: 0.8125\n","---- Validation ----\n","Validation loss: 72.8500\n","Validation acc: 0.7372\n","Time taken: 64.07s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 267.8811, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 247.8776, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 267.8331, Accuracy: 0.8133\n","Training loss (for one batch) at step 30: 261.3820, Accuracy: 0.8061\n","Training loss (for one batch) at step 40: 270.7435, Accuracy: 0.8115\n","Training loss (for one batch) at step 50: 251.7231, Accuracy: 0.8116\n","Training loss (for one batch) at step 60: 256.8279, Accuracy: 0.8072\n","Training loss (for one batch) at step 70: 245.6734, Accuracy: 0.8106\n","Training loss (for one batch) at step 80: 268.0728, Accuracy: 0.8102\n","Training loss (for one batch) at step 90: 287.5371, Accuracy: 0.8102\n","Training loss (for one batch) at step 100: 261.7558, Accuracy: 0.8102\n","Training loss (for one batch) at step 110: 266.9334, Accuracy: 0.8087\n","Training loss (for one batch) at step 120: 249.5676, Accuracy: 0.8102\n","Training loss (for one batch) at step 130: 251.9732, Accuracy: 0.8105\n","Training loss (for one batch) at step 140: 249.8629, Accuracy: 0.8098\n","---- Training ----\n","Training loss: 233.2699\n","Training acc over epoch: 0.8099\n","---- Validation ----\n","Validation loss: 76.3288\n","Validation acc: 0.7367\n","Time taken: 60.78s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 249.4137, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 253.2252, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 255.6759, Accuracy: 0.8224\n","Training loss (for one batch) at step 30: 242.6517, Accuracy: 0.8165\n","Training loss (for one batch) at step 40: 253.5451, Accuracy: 0.8210\n","Training loss (for one batch) at step 50: 248.8409, Accuracy: 0.8206\n","Training loss (for one batch) at step 60: 252.3577, Accuracy: 0.8197\n","Training loss (for one batch) at step 70: 276.0668, Accuracy: 0.8177\n","Training loss (for one batch) at step 80: 263.3936, Accuracy: 0.8159\n","Training loss (for one batch) at step 90: 242.4599, Accuracy: 0.8176\n","Training loss (for one batch) at step 100: 249.0356, Accuracy: 0.8172\n","Training loss (for one batch) at step 110: 259.4251, Accuracy: 0.8173\n","Training loss (for one batch) at step 120: 243.3459, Accuracy: 0.8175\n","Training loss (for one batch) at step 130: 290.0939, Accuracy: 0.8167\n","Training loss (for one batch) at step 140: 271.7534, Accuracy: 0.8184\n","---- Training ----\n","Training loss: 234.4030\n","Training acc over epoch: 0.8180\n","---- Validation ----\n","Validation loss: 83.1037\n","Validation acc: 0.7426\n","Time taken: 64.01s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 260.2676, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 245.9767, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 247.8090, Accuracy: 0.8233\n","Training loss (for one batch) at step 30: 270.2077, Accuracy: 0.8135\n","Training loss (for one batch) at step 40: 256.2837, Accuracy: 0.8163\n","Training loss (for one batch) at step 50: 249.5801, Accuracy: 0.8210\n","Training loss (for one batch) at step 60: 256.0130, Accuracy: 0.8200\n","Training loss (for one batch) at step 70: 244.1199, Accuracy: 0.8213\n","Training loss (for one batch) at step 80: 264.7918, Accuracy: 0.8183\n","Training loss (for one batch) at step 90: 269.7300, Accuracy: 0.8166\n","Training loss (for one batch) at step 100: 240.6131, Accuracy: 0.8177\n","Training loss (for one batch) at step 110: 243.9978, Accuracy: 0.8193\n","Training loss (for one batch) at step 120: 254.1115, Accuracy: 0.8183\n","Training loss (for one batch) at step 130: 273.2556, Accuracy: 0.8187\n","Training loss (for one batch) at step 140: 259.5561, Accuracy: 0.8187\n","---- Training ----\n","Training loss: 222.6881\n","Training acc over epoch: 0.8180\n","---- Validation ----\n","Validation loss: 74.0773\n","Validation acc: 0.7448\n","Time taken: 60.56s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 232.2290, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 261.5714, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 243.0491, Accuracy: 0.8248\n","Training loss (for one batch) at step 30: 251.9718, Accuracy: 0.8284\n","Training loss (for one batch) at step 40: 249.7420, Accuracy: 0.8271\n","Training loss (for one batch) at step 50: 238.1377, Accuracy: 0.8284\n","Training loss (for one batch) at step 60: 230.1080, Accuracy: 0.8289\n","Training loss (for one batch) at step 70: 252.6935, Accuracy: 0.8300\n","Training loss (for one batch) at step 80: 267.6059, Accuracy: 0.8259\n","Training loss (for one batch) at step 90: 237.7122, Accuracy: 0.8259\n","Training loss (for one batch) at step 100: 265.2425, Accuracy: 0.8252\n","Training loss (for one batch) at step 110: 238.5276, Accuracy: 0.8252\n","Training loss (for one batch) at step 120: 249.6782, Accuracy: 0.8255\n","Training loss (for one batch) at step 130: 272.7804, Accuracy: 0.8250\n","Training loss (for one batch) at step 140: 250.0237, Accuracy: 0.8245\n","---- Training ----\n","Training loss: 220.8620\n","Training acc over epoch: 0.8251\n","---- Validation ----\n","Validation loss: 69.8786\n","Validation acc: 0.7370\n","Time taken: 65.37s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 267.0614, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 231.5706, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 251.8730, Accuracy: 0.8248\n","Training loss (for one batch) at step 30: 263.0667, Accuracy: 0.8184\n","Training loss (for one batch) at step 40: 231.5031, Accuracy: 0.8266\n","Training loss (for one batch) at step 50: 245.4556, Accuracy: 0.8271\n","Training loss (for one batch) at step 60: 251.4777, Accuracy: 0.8257\n","Training loss (for one batch) at step 70: 264.3494, Accuracy: 0.8246\n","Training loss (for one batch) at step 80: 244.8515, Accuracy: 0.8247\n","Training loss (for one batch) at step 90: 227.7712, Accuracy: 0.8247\n","Training loss (for one batch) at step 100: 259.4113, Accuracy: 0.8233\n","Training loss (for one batch) at step 110: 238.0053, Accuracy: 0.8258\n","Training loss (for one batch) at step 120: 249.3116, Accuracy: 0.8261\n","Training loss (for one batch) at step 130: 262.4524, Accuracy: 0.8253\n","Training loss (for one batch) at step 140: 243.7264, Accuracy: 0.8235\n","---- Training ----\n","Training loss: 213.0100\n","Training acc over epoch: 0.8242\n","---- Validation ----\n","Validation loss: 72.2446\n","Validation acc: 0.7458\n","Time taken: 61.85s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 238.2764, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 239.8331, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 265.0829, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 246.6732, Accuracy: 0.8281\n","Training loss (for one batch) at step 40: 237.7912, Accuracy: 0.8288\n","Training loss (for one batch) at step 50: 256.3950, Accuracy: 0.8304\n","Training loss (for one batch) at step 60: 260.2420, Accuracy: 0.8321\n","Training loss (for one batch) at step 70: 257.2775, Accuracy: 0.8299\n","Training loss (for one batch) at step 80: 287.9333, Accuracy: 0.8256\n","Training loss (for one batch) at step 90: 240.2014, Accuracy: 0.8267\n","Training loss (for one batch) at step 100: 240.8687, Accuracy: 0.8263\n","Training loss (for one batch) at step 110: 255.1096, Accuracy: 0.8275\n","Training loss (for one batch) at step 120: 255.1806, Accuracy: 0.8279\n","Training loss (for one batch) at step 130: 272.5242, Accuracy: 0.8274\n","Training loss (for one batch) at step 140: 251.8438, Accuracy: 0.8293\n","---- Training ----\n","Training loss: 225.0919\n","Training acc over epoch: 0.8287\n","---- Validation ----\n","Validation loss: 79.6905\n","Validation acc: 0.7289\n","Time taken: 64.75s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 247.9711, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 259.7964, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 244.8900, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 254.7878, Accuracy: 0.8277\n","Training loss (for one batch) at step 40: 215.8607, Accuracy: 0.8285\n","Training loss (for one batch) at step 50: 225.9349, Accuracy: 0.8345\n","Training loss (for one batch) at step 60: 248.0441, Accuracy: 0.8339\n","Training loss (for one batch) at step 70: 246.8478, Accuracy: 0.8318\n","Training loss (for one batch) at step 80: 244.3359, Accuracy: 0.8304\n","Training loss (for one batch) at step 90: 250.8904, Accuracy: 0.8297\n","Training loss (for one batch) at step 100: 247.1734, Accuracy: 0.8290\n","Training loss (for one batch) at step 110: 267.8675, Accuracy: 0.8288\n","Training loss (for one batch) at step 120: 249.0680, Accuracy: 0.8289\n","Training loss (for one batch) at step 130: 265.7591, Accuracy: 0.8283\n","Training loss (for one batch) at step 140: 241.6664, Accuracy: 0.8278\n","---- Training ----\n","Training loss: 211.0540\n","Training acc over epoch: 0.8275\n","---- Validation ----\n","Validation loss: 63.9111\n","Validation acc: 0.7421\n","Time taken: 60.18s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 233.4685, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 228.6099, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 243.1700, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 263.4500, Accuracy: 0.8329\n","Training loss (for one batch) at step 40: 246.0653, Accuracy: 0.8354\n","Training loss (for one batch) at step 50: 235.3599, Accuracy: 0.8392\n","Training loss (for one batch) at step 60: 213.6123, Accuracy: 0.8364\n","Training loss (for one batch) at step 70: 262.0391, Accuracy: 0.8376\n","Training loss (for one batch) at step 80: 235.3920, Accuracy: 0.8375\n","Training loss (for one batch) at step 90: 249.2869, Accuracy: 0.8354\n","Training loss (for one batch) at step 100: 255.4146, Accuracy: 0.8357\n","Training loss (for one batch) at step 110: 222.9192, Accuracy: 0.8350\n","Training loss (for one batch) at step 120: 241.1500, Accuracy: 0.8342\n","Training loss (for one batch) at step 130: 265.1850, Accuracy: 0.8338\n","Training loss (for one batch) at step 140: 256.8575, Accuracy: 0.8333\n","---- Training ----\n","Training loss: 210.4998\n","Training acc over epoch: 0.8336\n","---- Validation ----\n","Validation loss: 65.5111\n","Validation acc: 0.7413\n","Time taken: 65.43s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 250.3142, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 222.0178, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 246.6547, Accuracy: 0.8243\n","Training loss (for one batch) at step 30: 237.3751, Accuracy: 0.8297\n","Training loss (for one batch) at step 40: 237.4019, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 218.1908, Accuracy: 0.8365\n","Training loss (for one batch) at step 60: 224.8291, Accuracy: 0.8372\n","Training loss (for one batch) at step 70: 261.4745, Accuracy: 0.8335\n","Training loss (for one batch) at step 80: 249.2448, Accuracy: 0.8302\n","Training loss (for one batch) at step 90: 232.7803, Accuracy: 0.8319\n","Training loss (for one batch) at step 100: 241.0771, Accuracy: 0.8318\n","Training loss (for one batch) at step 110: 224.0091, Accuracy: 0.8326\n","Training loss (for one batch) at step 120: 240.4555, Accuracy: 0.8325\n","Training loss (for one batch) at step 130: 262.9789, Accuracy: 0.8317\n","Training loss (for one batch) at step 140: 237.9560, Accuracy: 0.8300\n","---- Training ----\n","Training loss: 223.2001\n","Training acc over epoch: 0.8296\n","---- Validation ----\n","Validation loss: 80.8375\n","Validation acc: 0.7448\n","Time taken: 62.10s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 236.3316, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 217.8042, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 246.2785, Accuracy: 0.8357\n","Training loss (for one batch) at step 30: 243.9414, Accuracy: 0.8303\n","Training loss (for one batch) at step 40: 222.4774, Accuracy: 0.8305\n","Training loss (for one batch) at step 50: 227.3203, Accuracy: 0.8343\n","Training loss (for one batch) at step 60: 231.0095, Accuracy: 0.8366\n","Training loss (for one batch) at step 70: 247.9220, Accuracy: 0.8355\n","Training loss (for one batch) at step 80: 236.7035, Accuracy: 0.8337\n","Training loss (for one batch) at step 90: 250.3729, Accuracy: 0.8349\n","Training loss (for one batch) at step 100: 225.0669, Accuracy: 0.8344\n","Training loss (for one batch) at step 110: 246.6193, Accuracy: 0.8363\n","Training loss (for one batch) at step 120: 240.5588, Accuracy: 0.8339\n","Training loss (for one batch) at step 130: 247.9467, Accuracy: 0.8331\n","Training loss (for one batch) at step 140: 243.9002, Accuracy: 0.8318\n","---- Training ----\n","Training loss: 209.8524\n","Training acc over epoch: 0.8328\n","---- Validation ----\n","Validation loss: 76.5350\n","Validation acc: 0.7294\n","Time taken: 66.55s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 234.2189, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 248.5501, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 231.7302, Accuracy: 0.8486\n","Training loss (for one batch) at step 30: 255.7598, Accuracy: 0.8426\n","Training loss (for one batch) at step 40: 227.9252, Accuracy: 0.8434\n","Training loss (for one batch) at step 50: 221.3380, Accuracy: 0.8441\n","Training loss (for one batch) at step 60: 229.0824, Accuracy: 0.8420\n","Training loss (for one batch) at step 70: 210.9901, Accuracy: 0.8401\n","Training loss (for one batch) at step 80: 252.5154, Accuracy: 0.8373\n","Training loss (for one batch) at step 90: 247.1678, Accuracy: 0.8359\n","Training loss (for one batch) at step 100: 229.2041, Accuracy: 0.8360\n","Training loss (for one batch) at step 110: 218.3767, Accuracy: 0.8359\n","Training loss (for one batch) at step 120: 235.7198, Accuracy: 0.8360\n","Training loss (for one batch) at step 130: 217.2781, Accuracy: 0.8360\n","Training loss (for one batch) at step 140: 231.0072, Accuracy: 0.8357\n","---- Training ----\n","Training loss: 214.5541\n","Training acc over epoch: 0.8354\n","---- Validation ----\n","Validation loss: 81.2397\n","Validation acc: 0.7348\n","Time taken: 61.80s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 238.7279, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 235.9412, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 231.8674, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 222.4182, Accuracy: 0.8394\n","Training loss (for one batch) at step 40: 226.7190, Accuracy: 0.8393\n","Training loss (for one batch) at step 50: 239.5313, Accuracy: 0.8408\n","Training loss (for one batch) at step 60: 251.8678, Accuracy: 0.8403\n","Training loss (for one batch) at step 70: 218.2096, Accuracy: 0.8399\n","Training loss (for one batch) at step 80: 246.0926, Accuracy: 0.8396\n","Training loss (for one batch) at step 90: 238.2421, Accuracy: 0.8378\n","Training loss (for one batch) at step 100: 231.9322, Accuracy: 0.8342\n","Training loss (for one batch) at step 110: 239.9175, Accuracy: 0.8359\n","Training loss (for one batch) at step 120: 233.6303, Accuracy: 0.8355\n","Training loss (for one batch) at step 130: 246.1391, Accuracy: 0.8343\n","Training loss (for one batch) at step 140: 235.0736, Accuracy: 0.8357\n","---- Training ----\n","Training loss: 211.4016\n","Training acc over epoch: 0.8352\n","---- Validation ----\n","Validation loss: 76.6281\n","Validation acc: 0.7308\n","Time taken: 65.35s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 238.6932, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 218.2681, Accuracy: 0.8500\n","Training loss (for one batch) at step 20: 227.9955, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 255.4380, Accuracy: 0.8400\n","Training loss (for one batch) at step 40: 237.3891, Accuracy: 0.8432\n","Training loss (for one batch) at step 50: 219.0266, Accuracy: 0.8465\n","Training loss (for one batch) at step 60: 227.9399, Accuracy: 0.8479\n","Training loss (for one batch) at step 70: 229.6174, Accuracy: 0.8437\n","Training loss (for one batch) at step 80: 234.7866, Accuracy: 0.8388\n","Training loss (for one batch) at step 90: 245.9583, Accuracy: 0.8392\n","Training loss (for one batch) at step 100: 230.3555, Accuracy: 0.8377\n","Training loss (for one batch) at step 110: 231.9246, Accuracy: 0.8375\n","Training loss (for one batch) at step 120: 226.8226, Accuracy: 0.8384\n","Training loss (for one batch) at step 130: 244.9249, Accuracy: 0.8385\n","Training loss (for one batch) at step 140: 228.1391, Accuracy: 0.8378\n","---- Training ----\n","Training loss: 213.8731\n","Training acc over epoch: 0.8383\n","---- Validation ----\n","Validation loss: 65.4396\n","Validation acc: 0.7332\n","Time taken: 65.13s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 214.7086, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 204.4968, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 220.8909, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 232.6674, Accuracy: 0.8387\n","Training loss (for one batch) at step 40: 221.8589, Accuracy: 0.8422\n","Training loss (for one batch) at step 50: 214.9378, Accuracy: 0.8427\n","Training loss (for one batch) at step 60: 243.7677, Accuracy: 0.8411\n","Training loss (for one batch) at step 70: 241.7416, Accuracy: 0.8373\n","Training loss (for one batch) at step 80: 225.1516, Accuracy: 0.8360\n","Training loss (for one batch) at step 90: 229.0391, Accuracy: 0.8358\n","Training loss (for one batch) at step 100: 229.2784, Accuracy: 0.8362\n","Training loss (for one batch) at step 110: 229.3720, Accuracy: 0.8377\n","Training loss (for one batch) at step 120: 215.9642, Accuracy: 0.8377\n","Training loss (for one batch) at step 130: 239.4437, Accuracy: 0.8379\n","Training loss (for one batch) at step 140: 234.9407, Accuracy: 0.8377\n","---- Training ----\n","Training loss: 205.1173\n","Training acc over epoch: 0.8370\n","---- Validation ----\n","Validation loss: 68.3316\n","Validation acc: 0.7364\n","Time taken: 66.56s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 213.8399, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 231.6600, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 231.5735, Accuracy: 0.8490\n","Training loss (for one batch) at step 30: 230.3202, Accuracy: 0.8397\n","Training loss (for one batch) at step 40: 216.5244, Accuracy: 0.8415\n","Training loss (for one batch) at step 50: 241.8613, Accuracy: 0.8433\n","Training loss (for one batch) at step 60: 235.0100, Accuracy: 0.8464\n","Training loss (for one batch) at step 70: 240.9852, Accuracy: 0.8477\n","Training loss (for one batch) at step 80: 211.2136, Accuracy: 0.8452\n","Training loss (for one batch) at step 90: 223.6532, Accuracy: 0.8419\n","Training loss (for one batch) at step 100: 228.4670, Accuracy: 0.8418\n","Training loss (for one batch) at step 110: 235.2991, Accuracy: 0.8431\n","Training loss (for one batch) at step 120: 229.2585, Accuracy: 0.8431\n","Training loss (for one batch) at step 130: 221.5671, Accuracy: 0.8432\n","Training loss (for one batch) at step 140: 227.6562, Accuracy: 0.8422\n","---- Training ----\n","Training loss: 189.6470\n","Training acc over epoch: 0.8432\n","---- Validation ----\n","Validation loss: 64.1676\n","Validation acc: 0.7370\n","Time taken: 68.39s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 237.1278, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 205.4793, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 268.2793, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 235.5998, Accuracy: 0.8387\n","Training loss (for one batch) at step 40: 208.8513, Accuracy: 0.8420\n","Training loss (for one batch) at step 50: 230.6293, Accuracy: 0.8443\n","Training loss (for one batch) at step 60: 235.8383, Accuracy: 0.8443\n","Training loss (for one batch) at step 70: 239.6381, Accuracy: 0.8435\n","Training loss (for one batch) at step 80: 234.1430, Accuracy: 0.8443\n","Training loss (for one batch) at step 90: 220.4178, Accuracy: 0.8425\n","Training loss (for one batch) at step 100: 225.1412, Accuracy: 0.8433\n","Training loss (for one batch) at step 110: 223.0596, Accuracy: 0.8439\n","Training loss (for one batch) at step 120: 252.3037, Accuracy: 0.8436\n","Training loss (for one batch) at step 130: 243.3176, Accuracy: 0.8437\n","Training loss (for one batch) at step 140: 227.3838, Accuracy: 0.8435\n","---- Training ----\n","Training loss: 178.0078\n","Training acc over epoch: 0.8437\n","---- Validation ----\n","Validation loss: 88.5662\n","Validation acc: 0.7273\n","Time taken: 66.35s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 216.4188, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 214.0938, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 235.9726, Accuracy: 0.8457\n","Training loss (for one batch) at step 30: 227.4235, Accuracy: 0.8471\n","Training loss (for one batch) at step 40: 226.2378, Accuracy: 0.8502\n","Training loss (for one batch) at step 50: 190.1640, Accuracy: 0.8518\n","Training loss (for one batch) at step 60: 205.0281, Accuracy: 0.8502\n","Training loss (for one batch) at step 70: 227.6306, Accuracy: 0.8501\n","Training loss (for one batch) at step 80: 226.0949, Accuracy: 0.8462\n","Training loss (for one batch) at step 90: 216.7089, Accuracy: 0.8454\n","Training loss (for one batch) at step 100: 219.3318, Accuracy: 0.8446\n","Training loss (for one batch) at step 110: 219.0894, Accuracy: 0.8453\n","Training loss (for one batch) at step 120: 235.9011, Accuracy: 0.8457\n","Training loss (for one batch) at step 130: 213.5753, Accuracy: 0.8456\n","Training loss (for one batch) at step 140: 226.0894, Accuracy: 0.8440\n","---- Training ----\n","Training loss: 195.6663\n","Training acc over epoch: 0.8442\n","---- Validation ----\n","Validation loss: 76.6389\n","Validation acc: 0.7303\n","Time taken: 61.15s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 225.0316, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 216.7598, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 217.8878, Accuracy: 0.8543\n","Training loss (for one batch) at step 30: 213.2420, Accuracy: 0.8561\n","Training loss (for one batch) at step 40: 201.4889, Accuracy: 0.8546\n","Training loss (for one batch) at step 50: 201.1270, Accuracy: 0.8539\n","Training loss (for one batch) at step 60: 205.9330, Accuracy: 0.8523\n","Training loss (for one batch) at step 70: 231.7452, Accuracy: 0.8521\n","Training loss (for one batch) at step 80: 234.2701, Accuracy: 0.8473\n","Training loss (for one batch) at step 90: 218.1704, Accuracy: 0.8457\n","Training loss (for one batch) at step 100: 212.5427, Accuracy: 0.8444\n","Training loss (for one batch) at step 110: 204.7717, Accuracy: 0.8440\n","Training loss (for one batch) at step 120: 225.0644, Accuracy: 0.8450\n","Training loss (for one batch) at step 130: 222.9135, Accuracy: 0.8444\n","Training loss (for one batch) at step 140: 250.2830, Accuracy: 0.8429\n","---- Training ----\n","Training loss: 188.5053\n","Training acc over epoch: 0.8429\n","---- Validation ----\n","Validation loss: 67.1551\n","Validation acc: 0.7383\n","Time taken: 65.77s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 225.8636, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 216.1869, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 219.3552, Accuracy: 0.8457\n","Training loss (for one batch) at step 30: 225.4915, Accuracy: 0.8474\n","Training loss (for one batch) at step 40: 223.6529, Accuracy: 0.8490\n","Training loss (for one batch) at step 50: 215.7772, Accuracy: 0.8478\n","Training loss (for one batch) at step 60: 210.5129, Accuracy: 0.8469\n","Training loss (for one batch) at step 70: 239.4937, Accuracy: 0.8473\n","Training loss (for one batch) at step 80: 226.0515, Accuracy: 0.8456\n","Training loss (for one batch) at step 90: 209.4474, Accuracy: 0.8445\n","Training loss (for one batch) at step 100: 197.7493, Accuracy: 0.8435\n","Training loss (for one batch) at step 110: 211.2419, Accuracy: 0.8426\n","Training loss (for one batch) at step 120: 214.8913, Accuracy: 0.8431\n","Training loss (for one batch) at step 130: 236.1486, Accuracy: 0.8424\n","Training loss (for one batch) at step 140: 237.5836, Accuracy: 0.8432\n","---- Training ----\n","Training loss: 181.0783\n","Training acc over epoch: 0.8434\n","---- Validation ----\n","Validation loss: 80.9885\n","Validation acc: 0.7402\n","Time taken: 60.94s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 202.6954, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 216.0591, Accuracy: 0.8718\n","Training loss (for one batch) at step 20: 225.6759, Accuracy: 0.8562\n","Training loss (for one batch) at step 30: 213.2162, Accuracy: 0.8558\n","Training loss (for one batch) at step 40: 212.0256, Accuracy: 0.8546\n","Training loss (for one batch) at step 50: 206.8369, Accuracy: 0.8549\n","Training loss (for one batch) at step 60: 226.9923, Accuracy: 0.8541\n","Training loss (for one batch) at step 70: 204.6375, Accuracy: 0.8530\n","Training loss (for one batch) at step 80: 216.5882, Accuracy: 0.8506\n","Training loss (for one batch) at step 90: 216.0438, Accuracy: 0.8479\n","Training loss (for one batch) at step 100: 223.0962, Accuracy: 0.8457\n","Training loss (for one batch) at step 110: 233.1980, Accuracy: 0.8461\n","Training loss (for one batch) at step 120: 227.0358, Accuracy: 0.8461\n","Training loss (for one batch) at step 130: 219.4743, Accuracy: 0.8469\n","Training loss (for one batch) at step 140: 245.4401, Accuracy: 0.8459\n","---- Training ----\n","Training loss: 199.1525\n","Training acc over epoch: 0.8458\n","---- Validation ----\n","Validation loss: 89.1501\n","Validation acc: 0.7327\n","Time taken: 67.79s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 229.6684, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 217.3118, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 213.0234, Accuracy: 0.8471\n","Training loss (for one batch) at step 30: 201.2134, Accuracy: 0.8510\n","Training loss (for one batch) at step 40: 225.7282, Accuracy: 0.8488\n","Training loss (for one batch) at step 50: 208.7262, Accuracy: 0.8461\n","Training loss (for one batch) at step 60: 222.6118, Accuracy: 0.8456\n","Training loss (for one batch) at step 70: 245.3731, Accuracy: 0.8435\n","Training loss (for one batch) at step 80: 217.2943, Accuracy: 0.8422\n","Training loss (for one batch) at step 90: 228.1328, Accuracy: 0.8423\n","Training loss (for one batch) at step 100: 225.1113, Accuracy: 0.8430\n","Training loss (for one batch) at step 110: 205.0457, Accuracy: 0.8435\n","Training loss (for one batch) at step 120: 199.2538, Accuracy: 0.8432\n","Training loss (for one batch) at step 130: 219.1492, Accuracy: 0.8434\n","Training loss (for one batch) at step 140: 215.4514, Accuracy: 0.8431\n","---- Training ----\n","Training loss: 187.3772\n","Training acc over epoch: 0.8438\n","---- Validation ----\n","Validation loss: 81.6574\n","Validation acc: 0.7346\n","Time taken: 61.85s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 203.3833, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 219.9881, Accuracy: 0.8618\n","Training loss (for one batch) at step 20: 194.4039, Accuracy: 0.8581\n","Training loss (for one batch) at step 30: 220.7786, Accuracy: 0.8568\n","Training loss (for one batch) at step 40: 208.8696, Accuracy: 0.8559\n","Training loss (for one batch) at step 50: 210.0050, Accuracy: 0.8547\n","Training loss (for one batch) at step 60: 202.9584, Accuracy: 0.8520\n","Training loss (for one batch) at step 70: 234.5377, Accuracy: 0.8524\n","Training loss (for one batch) at step 80: 231.1420, Accuracy: 0.8506\n","Training loss (for one batch) at step 90: 214.6229, Accuracy: 0.8487\n","Training loss (for one batch) at step 100: 217.6947, Accuracy: 0.8489\n","Training loss (for one batch) at step 110: 202.5582, Accuracy: 0.8490\n","Training loss (for one batch) at step 120: 214.1706, Accuracy: 0.8498\n","Training loss (for one batch) at step 130: 224.6547, Accuracy: 0.8495\n","Training loss (for one batch) at step 140: 212.0076, Accuracy: 0.8497\n","---- Training ----\n","Training loss: 183.5596\n","Training acc over epoch: 0.8488\n","---- Validation ----\n","Validation loss: 65.4504\n","Validation acc: 0.7294\n","Time taken: 66.87s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 228.8866, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 207.2851, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 205.6905, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 216.9939, Accuracy: 0.8458\n","Training loss (for one batch) at step 40: 215.1180, Accuracy: 0.8405\n","Training loss (for one batch) at step 50: 233.5157, Accuracy: 0.8418\n","Training loss (for one batch) at step 60: 193.3800, Accuracy: 0.8446\n","Training loss (for one batch) at step 70: 197.5421, Accuracy: 0.8446\n","Training loss (for one batch) at step 80: 201.9869, Accuracy: 0.8458\n","Training loss (for one batch) at step 90: 223.5165, Accuracy: 0.8478\n","Training loss (for one batch) at step 100: 219.3352, Accuracy: 0.8468\n","Training loss (for one batch) at step 110: 217.6826, Accuracy: 0.8470\n","Training loss (for one batch) at step 120: 217.2001, Accuracy: 0.8458\n","Training loss (for one batch) at step 130: 212.4535, Accuracy: 0.8465\n","Training loss (for one batch) at step 140: 207.2098, Accuracy: 0.8472\n","---- Training ----\n","Training loss: 193.4420\n","Training acc over epoch: 0.8466\n","---- Validation ----\n","Validation loss: 73.7934\n","Validation acc: 0.7329\n","Time taken: 62.83s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 228.5602, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 191.1613, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 207.2621, Accuracy: 0.8538\n","Training loss (for one batch) at step 30: 216.3276, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 202.8960, Accuracy: 0.8459\n","Training loss (for one batch) at step 50: 222.4717, Accuracy: 0.8467\n","Training loss (for one batch) at step 60: 200.9142, Accuracy: 0.8470\n","Training loss (for one batch) at step 70: 215.5580, Accuracy: 0.8466\n","Training loss (for one batch) at step 80: 224.5522, Accuracy: 0.8464\n","Training loss (for one batch) at step 90: 220.8380, Accuracy: 0.8440\n","Training loss (for one batch) at step 100: 211.4236, Accuracy: 0.8419\n","Training loss (for one batch) at step 110: 201.1813, Accuracy: 0.8438\n","Training loss (for one batch) at step 120: 211.5011, Accuracy: 0.8439\n","Training loss (for one batch) at step 130: 201.7614, Accuracy: 0.8450\n","Training loss (for one batch) at step 140: 204.2637, Accuracy: 0.8460\n","---- Training ----\n","Training loss: 191.6983\n","Training acc over epoch: 0.8453\n","---- Validation ----\n","Validation loss: 67.1076\n","Validation acc: 0.7372\n","Time taken: 68.00s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 191.9689, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 211.0682, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 179.6260, Accuracy: 0.8419\n","Training loss (for one batch) at step 30: 201.9257, Accuracy: 0.8477\n","Training loss (for one batch) at step 40: 210.9674, Accuracy: 0.8478\n","Training loss (for one batch) at step 50: 214.6008, Accuracy: 0.8508\n","Training loss (for one batch) at step 60: 209.1919, Accuracy: 0.8515\n","Training loss (for one batch) at step 70: 236.3939, Accuracy: 0.8468\n","Training loss (for one batch) at step 80: 208.3466, Accuracy: 0.8473\n","Training loss (for one batch) at step 90: 227.0635, Accuracy: 0.8444\n","Training loss (for one batch) at step 100: 184.3079, Accuracy: 0.8451\n","Training loss (for one batch) at step 110: 222.1685, Accuracy: 0.8447\n","Training loss (for one batch) at step 120: 200.5127, Accuracy: 0.8456\n","Training loss (for one batch) at step 130: 222.7606, Accuracy: 0.8447\n","Training loss (for one batch) at step 140: 231.4540, Accuracy: 0.8463\n","---- Training ----\n","Training loss: 185.7916\n","Training acc over epoch: 0.8458\n","---- Validation ----\n","Validation loss: 60.5733\n","Validation acc: 0.7332\n","Time taken: 63.38s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 205.8401, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 207.2703, Accuracy: 0.8645\n","Training loss (for one batch) at step 20: 210.0096, Accuracy: 0.8590\n","Training loss (for one batch) at step 30: 195.4416, Accuracy: 0.8606\n","Training loss (for one batch) at step 40: 210.9266, Accuracy: 0.8585\n","Training loss (for one batch) at step 50: 189.7214, Accuracy: 0.8608\n","Training loss (for one batch) at step 60: 196.2239, Accuracy: 0.8605\n","Training loss (for one batch) at step 70: 227.3105, Accuracy: 0.8558\n","Training loss (for one batch) at step 80: 218.6985, Accuracy: 0.8547\n","Training loss (for one batch) at step 90: 217.8864, Accuracy: 0.8532\n","Training loss (for one batch) at step 100: 220.0170, Accuracy: 0.8532\n","Training loss (for one batch) at step 110: 195.9427, Accuracy: 0.8528\n","Training loss (for one batch) at step 120: 191.4595, Accuracy: 0.8535\n","Training loss (for one batch) at step 130: 212.8763, Accuracy: 0.8527\n","Training loss (for one batch) at step 140: 230.2480, Accuracy: 0.8519\n","---- Training ----\n","Training loss: 174.7856\n","Training acc over epoch: 0.8526\n","---- Validation ----\n","Validation loss: 84.9808\n","Validation acc: 0.7311\n","Time taken: 65.71s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7326\n","Validation AUC: 0.7294\n","Validation Balanced_ACC: 0.4802\n","Validation MI: 0.1378\n","Validation Normalized MI: 0.2061\n","Validation Adjusted MI: 0.2061\n","Validation aUc_Sklearn: 0.8307\n","\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2023-02-15 00:54:50.466304: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 1 of 1024\n","2023-02-15 00:54:53.994200: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["Training loss (for one batch) at step 0: 545.6800, Accuracy: 0.5100\n","Training loss (for one batch) at step 10: 495.1459, Accuracy: 0.5127\n","Training loss (for one batch) at step 20: 490.8329, Accuracy: 0.5248\n","Training loss (for one batch) at step 30: 425.7359, Accuracy: 0.5358\n","Training loss (for one batch) at step 40: 438.1086, Accuracy: 0.5522\n","Training loss (for one batch) at step 50: 437.8628, Accuracy: 0.5557\n","Training loss (for one batch) at step 60: 432.2560, Accuracy: 0.5548\n","Training loss (for one batch) at step 70: 464.4137, Accuracy: 0.5606\n","Training loss (for one batch) at step 80: 417.0397, Accuracy: 0.5611\n","Training loss (for one batch) at step 90: 430.1098, Accuracy: 0.5642\n","Training loss (for one batch) at step 100: 430.7260, Accuracy: 0.5689\n","Training loss (for one batch) at step 110: 410.6523, Accuracy: 0.5713\n","Training loss (for one batch) at step 120: 439.1637, Accuracy: 0.5726\n","Training loss (for one batch) at step 130: 417.6356, Accuracy: 0.5734\n","Training loss (for one batch) at step 140: 450.7852, Accuracy: 0.5729\n","---- Training ----\n","Training loss: 393.9187\n","Training acc over epoch: 0.5727\n","---- Validation ----\n","Validation loss: 85.3938\n","Validation acc: 0.5134\n","Time taken: 80.13s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 407.4026, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 361.6945, Accuracy: 0.6200\n","Training loss (for one batch) at step 20: 424.7666, Accuracy: 0.6100\n","Training loss (for one batch) at step 30: 444.8634, Accuracy: 0.6042\n","Training loss (for one batch) at step 40: 393.1862, Accuracy: 0.6000\n","Training loss (for one batch) at step 50: 391.3019, Accuracy: 0.5990\n","Training loss (for one batch) at step 60: 424.5691, Accuracy: 0.5989\n","Training loss (for one batch) at step 70: 389.5775, Accuracy: 0.5979\n","Training loss (for one batch) at step 80: 360.7109, Accuracy: 0.6037\n","Training loss (for one batch) at step 90: 367.6332, Accuracy: 0.6057\n","Training loss (for one batch) at step 100: 379.7974, Accuracy: 0.6047\n","Training loss (for one batch) at step 110: 390.2852, Accuracy: 0.6052\n","Training loss (for one batch) at step 120: 379.6125, Accuracy: 0.6050\n","Training loss (for one batch) at step 130: 391.9070, Accuracy: 0.6064\n","Training loss (for one batch) at step 140: 383.6197, Accuracy: 0.6074\n","---- Training ----\n","Training loss: 322.8352\n","Training acc over epoch: 0.6075\n","---- Validation ----\n","Validation loss: 80.8852\n","Validation acc: 0.5355\n","Time taken: 58.11s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 377.7250, Accuracy: 0.6100\n","Training loss (for one batch) at step 10: 364.0365, Accuracy: 0.6291\n","Training loss (for one batch) at step 20: 370.7310, Accuracy: 0.6314\n","Training loss (for one batch) at step 30: 385.7524, Accuracy: 0.6313\n","Training loss (for one batch) at step 40: 373.0836, Accuracy: 0.6249\n","Training loss (for one batch) at step 50: 359.8702, Accuracy: 0.6239\n","Training loss (for one batch) at step 60: 367.8431, Accuracy: 0.6266\n","Training loss (for one batch) at step 70: 372.2193, Accuracy: 0.6263\n","Training loss (for one batch) at step 80: 367.2703, Accuracy: 0.6280\n","Training loss (for one batch) at step 90: 355.3396, Accuracy: 0.6292\n","Training loss (for one batch) at step 100: 349.9782, Accuracy: 0.6321\n","Training loss (for one batch) at step 110: 344.6563, Accuracy: 0.6338\n","Training loss (for one batch) at step 120: 373.5445, Accuracy: 0.6346\n","Training loss (for one batch) at step 130: 375.1917, Accuracy: 0.6341\n","Training loss (for one batch) at step 140: 355.6011, Accuracy: 0.6342\n","---- Training ----\n","Training loss: 309.4636\n","Training acc over epoch: 0.6351\n","---- Validation ----\n","Validation loss: 73.6118\n","Validation acc: 0.6644\n","Time taken: 70.40s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 358.9247, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 391.4939, Accuracy: 0.6555\n","Training loss (for one batch) at step 20: 351.8127, Accuracy: 0.6452\n","Training loss (for one batch) at step 30: 335.7517, Accuracy: 0.6510\n","Training loss (for one batch) at step 40: 354.4075, Accuracy: 0.6495\n","Training loss (for one batch) at step 50: 364.5615, Accuracy: 0.6533\n","Training loss (for one batch) at step 60: 349.4557, Accuracy: 0.6507\n","Training loss (for one batch) at step 70: 345.6068, Accuracy: 0.6545\n","Training loss (for one batch) at step 80: 350.7102, Accuracy: 0.6505\n","Training loss (for one batch) at step 90: 379.4396, Accuracy: 0.6497\n","Training loss (for one batch) at step 100: 341.4798, Accuracy: 0.6505\n","Training loss (for one batch) at step 110: 353.7067, Accuracy: 0.6526\n","Training loss (for one batch) at step 120: 338.0478, Accuracy: 0.6545\n","Training loss (for one batch) at step 130: 363.7738, Accuracy: 0.6540\n","Training loss (for one batch) at step 140: 339.6879, Accuracy: 0.6543\n","---- Training ----\n","Training loss: 295.2355\n","Training acc over epoch: 0.6537\n","---- Validation ----\n","Validation loss: 72.7792\n","Validation acc: 0.6851\n","Time taken: 41.02s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 345.4147, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 331.6015, Accuracy: 0.6600\n","Training loss (for one batch) at step 20: 351.4102, Accuracy: 0.6595\n","Training loss (for one batch) at step 30: 349.5045, Accuracy: 0.6632\n","Training loss (for one batch) at step 40: 343.8345, Accuracy: 0.6646\n","Training loss (for one batch) at step 50: 331.9045, Accuracy: 0.6696\n","Training loss (for one batch) at step 60: 340.4880, Accuracy: 0.6695\n","Training loss (for one batch) at step 70: 364.7793, Accuracy: 0.6673\n","Training loss (for one batch) at step 80: 353.3133, Accuracy: 0.6657\n","Training loss (for one batch) at step 90: 366.5410, Accuracy: 0.6663\n","Training loss (for one batch) at step 100: 342.2521, Accuracy: 0.6650\n","Training loss (for one batch) at step 110: 340.5629, Accuracy: 0.6651\n","Training loss (for one batch) at step 120: 363.6970, Accuracy: 0.6672\n","Training loss (for one batch) at step 130: 336.9555, Accuracy: 0.6679\n","Training loss (for one batch) at step 140: 341.2458, Accuracy: 0.6669\n","---- Training ----\n","Training loss: 287.5524\n","Training acc over epoch: 0.6682\n","---- Validation ----\n","Validation loss: 62.8962\n","Validation acc: 0.6940\n","Time taken: 68.05s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 333.6786, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 342.5051, Accuracy: 0.6645\n","Training loss (for one batch) at step 20: 331.6709, Accuracy: 0.6819\n","Training loss (for one batch) at step 30: 324.5829, Accuracy: 0.6816\n","Training loss (for one batch) at step 40: 357.9179, Accuracy: 0.6827\n","Training loss (for one batch) at step 50: 337.0055, Accuracy: 0.6837\n","Training loss (for one batch) at step 60: 316.3197, Accuracy: 0.6846\n","Training loss (for one batch) at step 70: 324.5354, Accuracy: 0.6849\n","Training loss (for one batch) at step 80: 330.8062, Accuracy: 0.6822\n","Training loss (for one batch) at step 90: 306.9734, Accuracy: 0.6824\n","Training loss (for one batch) at step 100: 330.3593, Accuracy: 0.6828\n","Training loss (for one batch) at step 110: 323.9038, Accuracy: 0.6821\n","Training loss (for one batch) at step 120: 333.3981, Accuracy: 0.6826\n","Training loss (for one batch) at step 130: 305.9286, Accuracy: 0.6836\n","Training loss (for one batch) at step 140: 350.6210, Accuracy: 0.6835\n","---- Training ----\n","Training loss: 295.3501\n","Training acc over epoch: 0.6842\n","---- Validation ----\n","Validation loss: 71.8306\n","Validation acc: 0.6937\n","Time taken: 40.72s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 350.2249, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 328.0069, Accuracy: 0.6964\n","Training loss (for one batch) at step 20: 334.0849, Accuracy: 0.6933\n","Training loss (for one batch) at step 30: 345.8398, Accuracy: 0.6948\n","Training loss (for one batch) at step 40: 319.3948, Accuracy: 0.6980\n","Training loss (for one batch) at step 50: 325.6580, Accuracy: 0.7014\n","Training loss (for one batch) at step 60: 327.7035, Accuracy: 0.7036\n","Training loss (for one batch) at step 70: 334.6507, Accuracy: 0.6999\n","Training loss (for one batch) at step 80: 319.2107, Accuracy: 0.6986\n","Training loss (for one batch) at step 90: 338.7266, Accuracy: 0.6985\n","Training loss (for one batch) at step 100: 324.2195, Accuracy: 0.6979\n","Training loss (for one batch) at step 110: 312.8528, Accuracy: 0.7004\n","Training loss (for one batch) at step 120: 340.3146, Accuracy: 0.7011\n","Training loss (for one batch) at step 130: 317.3104, Accuracy: 0.6988\n","Training loss (for one batch) at step 140: 323.9902, Accuracy: 0.6987\n","---- Training ----\n","Training loss: 281.3472\n","Training acc over epoch: 0.6991\n","---- Validation ----\n","Validation loss: 78.8091\n","Validation acc: 0.7071\n","Time taken: 67.51s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 327.6902, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 326.8561, Accuracy: 0.7045\n","Training loss (for one batch) at step 20: 335.8393, Accuracy: 0.7038\n","Training loss (for one batch) at step 30: 317.1183, Accuracy: 0.7061\n","Training loss (for one batch) at step 40: 305.7310, Accuracy: 0.7068\n","Training loss (for one batch) at step 50: 323.1814, Accuracy: 0.7075\n","Training loss (for one batch) at step 60: 345.1830, Accuracy: 0.7098\n","Training loss (for one batch) at step 70: 336.6928, Accuracy: 0.7108\n","Training loss (for one batch) at step 80: 294.5559, Accuracy: 0.7114\n","Training loss (for one batch) at step 90: 320.8440, Accuracy: 0.7100\n","Training loss (for one batch) at step 100: 300.9401, Accuracy: 0.7077\n","Training loss (for one batch) at step 110: 310.1031, Accuracy: 0.7108\n","Training loss (for one batch) at step 120: 310.9427, Accuracy: 0.7119\n","Training loss (for one batch) at step 130: 292.9605, Accuracy: 0.7106\n","Training loss (for one batch) at step 140: 325.5179, Accuracy: 0.7104\n","---- Training ----\n","Training loss: 272.8610\n","Training acc over epoch: 0.7123\n","---- Validation ----\n","Validation loss: 67.2095\n","Validation acc: 0.7246\n","Time taken: 39.73s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 307.7834, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 320.1678, Accuracy: 0.7409\n","Training loss (for one batch) at step 20: 340.8282, Accuracy: 0.7329\n","Training loss (for one batch) at step 30: 311.2838, Accuracy: 0.7310\n","Training loss (for one batch) at step 40: 315.8815, Accuracy: 0.7324\n","Training loss (for one batch) at step 50: 336.0710, Accuracy: 0.7331\n","Training loss (for one batch) at step 60: 329.4042, Accuracy: 0.7344\n","Training loss (for one batch) at step 70: 317.3655, Accuracy: 0.7301\n","Training loss (for one batch) at step 80: 310.3604, Accuracy: 0.7277\n","Training loss (for one batch) at step 90: 313.7139, Accuracy: 0.7267\n","Training loss (for one batch) at step 100: 305.7078, Accuracy: 0.7263\n","Training loss (for one batch) at step 110: 315.9340, Accuracy: 0.7285\n","Training loss (for one batch) at step 120: 309.2935, Accuracy: 0.7294\n","Training loss (for one batch) at step 130: 317.5342, Accuracy: 0.7292\n","Training loss (for one batch) at step 140: 292.7810, Accuracy: 0.7278\n","---- Training ----\n","Training loss: 299.0878\n","Training acc over epoch: 0.7276\n","---- Validation ----\n","Validation loss: 70.1739\n","Validation acc: 0.7053\n","Time taken: 68.22s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 316.2713, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 292.0122, Accuracy: 0.7355\n","Training loss (for one batch) at step 20: 302.4611, Accuracy: 0.7329\n","Training loss (for one batch) at step 30: 321.5370, Accuracy: 0.7371\n","Training loss (for one batch) at step 40: 313.6048, Accuracy: 0.7349\n","Training loss (for one batch) at step 50: 316.6800, Accuracy: 0.7400\n","Training loss (for one batch) at step 60: 308.0285, Accuracy: 0.7398\n","Training loss (for one batch) at step 70: 312.4781, Accuracy: 0.7385\n","Training loss (for one batch) at step 80: 312.4885, Accuracy: 0.7380\n","Training loss (for one batch) at step 90: 310.7767, Accuracy: 0.7341\n","Training loss (for one batch) at step 100: 309.3721, Accuracy: 0.7337\n","Training loss (for one batch) at step 110: 307.0711, Accuracy: 0.7332\n","Training loss (for one batch) at step 120: 322.7055, Accuracy: 0.7352\n","Training loss (for one batch) at step 130: 318.4422, Accuracy: 0.7346\n","Training loss (for one batch) at step 140: 318.7543, Accuracy: 0.7360\n","---- Training ----\n","Training loss: 278.0220\n","Training acc over epoch: 0.7368\n","---- Validation ----\n","Validation loss: 65.0744\n","Validation acc: 0.7214\n","Time taken: 39.97s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 311.4355, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 298.1284, Accuracy: 0.7291\n","Training loss (for one batch) at step 20: 303.1657, Accuracy: 0.7438\n","Training loss (for one batch) at step 30: 297.2698, Accuracy: 0.7397\n","Training loss (for one batch) at step 40: 325.3689, Accuracy: 0.7400\n","Training loss (for one batch) at step 50: 298.9141, Accuracy: 0.7435\n","Training loss (for one batch) at step 60: 289.5235, Accuracy: 0.7474\n","Training loss (for one batch) at step 70: 313.0559, Accuracy: 0.7459\n","Training loss (for one batch) at step 80: 313.6139, Accuracy: 0.7441\n","Training loss (for one batch) at step 90: 296.2527, Accuracy: 0.7447\n","Training loss (for one batch) at step 100: 295.1881, Accuracy: 0.7439\n","Training loss (for one batch) at step 110: 296.0001, Accuracy: 0.7438\n","Training loss (for one batch) at step 120: 313.2403, Accuracy: 0.7434\n","Training loss (for one batch) at step 130: 296.1858, Accuracy: 0.7454\n","Training loss (for one batch) at step 140: 305.0052, Accuracy: 0.7449\n","---- Training ----\n","Training loss: 255.2052\n","Training acc over epoch: 0.7458\n","---- Validation ----\n","Validation loss: 68.8803\n","Validation acc: 0.7286\n","Time taken: 66.28s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 303.8528, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 284.4423, Accuracy: 0.7600\n","Training loss (for one batch) at step 20: 291.6891, Accuracy: 0.7600\n","Training loss (for one batch) at step 30: 292.7007, Accuracy: 0.7603\n","Training loss (for one batch) at step 40: 317.7006, Accuracy: 0.7607\n","Training loss (for one batch) at step 50: 312.8318, Accuracy: 0.7624\n","Training loss (for one batch) at step 60: 294.3421, Accuracy: 0.7651\n","Training loss (for one batch) at step 70: 304.1695, Accuracy: 0.7638\n","Training loss (for one batch) at step 80: 305.7187, Accuracy: 0.7622\n","Training loss (for one batch) at step 90: 300.9535, Accuracy: 0.7597\n","Training loss (for one batch) at step 100: 302.1191, Accuracy: 0.7573\n","Training loss (for one batch) at step 110: 293.2072, Accuracy: 0.7578\n","Training loss (for one batch) at step 120: 303.5265, Accuracy: 0.7569\n","Training loss (for one batch) at step 130: 304.8642, Accuracy: 0.7579\n","Training loss (for one batch) at step 140: 301.4506, Accuracy: 0.7571\n","---- Training ----\n","Training loss: 273.7491\n","Training acc over epoch: 0.7581\n","---- Validation ----\n","Validation loss: 62.9857\n","Validation acc: 0.7303\n","Time taken: 38.79s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 313.0536, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 283.7522, Accuracy: 0.7682\n","Training loss (for one batch) at step 20: 296.0261, Accuracy: 0.7667\n","Training loss (for one batch) at step 30: 301.6374, Accuracy: 0.7690\n","Training loss (for one batch) at step 40: 306.0946, Accuracy: 0.7663\n","Training loss (for one batch) at step 50: 297.3725, Accuracy: 0.7663\n","Training loss (for one batch) at step 60: 301.3681, Accuracy: 0.7680\n","Training loss (for one batch) at step 70: 299.6974, Accuracy: 0.7659\n","Training loss (for one batch) at step 80: 280.9861, Accuracy: 0.7658\n","Training loss (for one batch) at step 90: 288.2669, Accuracy: 0.7671\n","Training loss (for one batch) at step 100: 301.1797, Accuracy: 0.7651\n","Training loss (for one batch) at step 110: 289.5865, Accuracy: 0.7665\n","Training loss (for one batch) at step 120: 293.1295, Accuracy: 0.7655\n","Training loss (for one batch) at step 130: 295.6617, Accuracy: 0.7651\n","Training loss (for one batch) at step 140: 312.6779, Accuracy: 0.7648\n","---- Training ----\n","Training loss: 265.8235\n","Training acc over epoch: 0.7648\n","---- Validation ----\n","Validation loss: 78.2470\n","Validation acc: 0.7292\n","Time taken: 67.38s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 294.2739, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 294.1396, Accuracy: 0.7682\n","Training loss (for one batch) at step 20: 297.5699, Accuracy: 0.7652\n","Training loss (for one batch) at step 30: 299.1764, Accuracy: 0.7587\n","Training loss (for one batch) at step 40: 284.9442, Accuracy: 0.7615\n","Training loss (for one batch) at step 50: 307.8511, Accuracy: 0.7659\n","Training loss (for one batch) at step 60: 292.0417, Accuracy: 0.7703\n","Training loss (for one batch) at step 70: 288.8527, Accuracy: 0.7711\n","Training loss (for one batch) at step 80: 291.9001, Accuracy: 0.7701\n","Training loss (for one batch) at step 90: 303.5839, Accuracy: 0.7680\n","Training loss (for one batch) at step 100: 277.9055, Accuracy: 0.7695\n","Training loss (for one batch) at step 110: 297.5024, Accuracy: 0.7702\n","Training loss (for one batch) at step 120: 290.7953, Accuracy: 0.7702\n","Training loss (for one batch) at step 130: 274.9261, Accuracy: 0.7692\n","Training loss (for one batch) at step 140: 272.5548, Accuracy: 0.7693\n","---- Training ----\n","Training loss: 253.3904\n","Training acc over epoch: 0.7693\n","---- Validation ----\n","Validation loss: 68.7857\n","Validation acc: 0.7321\n","Time taken: 39.12s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 287.0439, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 278.1053, Accuracy: 0.8000\n","Training loss (for one batch) at step 20: 294.4882, Accuracy: 0.7900\n","Training loss (for one batch) at step 30: 300.0937, Accuracy: 0.7845\n","Training loss (for one batch) at step 40: 278.7210, Accuracy: 0.7844\n","Training loss (for one batch) at step 50: 272.2222, Accuracy: 0.7910\n","Training loss (for one batch) at step 60: 296.9243, Accuracy: 0.7889\n","Training loss (for one batch) at step 70: 305.9151, Accuracy: 0.7852\n","Training loss (for one batch) at step 80: 278.8784, Accuracy: 0.7812\n","Training loss (for one batch) at step 90: 296.2625, Accuracy: 0.7795\n","Training loss (for one batch) at step 100: 286.6433, Accuracy: 0.7796\n","Training loss (for one batch) at step 110: 290.6607, Accuracy: 0.7797\n","Training loss (for one batch) at step 120: 289.5623, Accuracy: 0.7788\n","Training loss (for one batch) at step 130: 283.5416, Accuracy: 0.7779\n","Training loss (for one batch) at step 140: 283.1549, Accuracy: 0.7788\n","---- Training ----\n","Training loss: 266.6304\n","Training acc over epoch: 0.7774\n","---- Validation ----\n","Validation loss: 73.6558\n","Validation acc: 0.7423\n","Time taken: 66.32s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 271.9902, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 269.7357, Accuracy: 0.7745\n","Training loss (for one batch) at step 20: 282.8263, Accuracy: 0.7795\n","Training loss (for one batch) at step 30: 298.6555, Accuracy: 0.7761\n","Training loss (for one batch) at step 40: 280.9085, Accuracy: 0.7778\n","Training loss (for one batch) at step 50: 288.6775, Accuracy: 0.7855\n","Training loss (for one batch) at step 60: 275.0435, Accuracy: 0.7867\n","Training loss (for one batch) at step 70: 286.2972, Accuracy: 0.7849\n","Training loss (for one batch) at step 80: 280.3688, Accuracy: 0.7860\n","Training loss (for one batch) at step 90: 273.1516, Accuracy: 0.7844\n","Training loss (for one batch) at step 100: 290.1310, Accuracy: 0.7821\n","Training loss (for one batch) at step 110: 264.9464, Accuracy: 0.7820\n","Training loss (for one batch) at step 120: 295.4944, Accuracy: 0.7813\n","Training loss (for one batch) at step 130: 286.2273, Accuracy: 0.7796\n","Training loss (for one batch) at step 140: 297.2076, Accuracy: 0.7797\n","---- Training ----\n","Training loss: 259.1566\n","Training acc over epoch: 0.7787\n","---- Validation ----\n","Validation loss: 80.6519\n","Validation acc: 0.7364\n","Time taken: 38.93s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 293.9340, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 285.1624, Accuracy: 0.7800\n","Training loss (for one batch) at step 20: 286.4086, Accuracy: 0.7862\n","Training loss (for one batch) at step 30: 276.6572, Accuracy: 0.7942\n","Training loss (for one batch) at step 40: 278.9475, Accuracy: 0.7932\n","Training loss (for one batch) at step 50: 281.2241, Accuracy: 0.7986\n","Training loss (for one batch) at step 60: 292.4484, Accuracy: 0.7962\n","Training loss (for one batch) at step 70: 282.9411, Accuracy: 0.7945\n","Training loss (for one batch) at step 80: 287.3175, Accuracy: 0.7922\n","Training loss (for one batch) at step 90: 299.9920, Accuracy: 0.7909\n","Training loss (for one batch) at step 100: 289.0371, Accuracy: 0.7898\n","Training loss (for one batch) at step 110: 272.8687, Accuracy: 0.7903\n","Training loss (for one batch) at step 120: 282.2369, Accuracy: 0.7911\n","Training loss (for one batch) at step 130: 269.1110, Accuracy: 0.7907\n","Training loss (for one batch) at step 140: 301.0891, Accuracy: 0.7901\n","---- Training ----\n","Training loss: 242.8848\n","Training acc over epoch: 0.7902\n","---- Validation ----\n","Validation loss: 70.5960\n","Validation acc: 0.7472\n","Time taken: 65.75s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 277.0214, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 282.9412, Accuracy: 0.8136\n","Training loss (for one batch) at step 20: 271.3755, Accuracy: 0.7905\n","Training loss (for one batch) at step 30: 282.5807, Accuracy: 0.7890\n","Training loss (for one batch) at step 40: 285.6729, Accuracy: 0.7907\n","Training loss (for one batch) at step 50: 287.7717, Accuracy: 0.7927\n","Training loss (for one batch) at step 60: 283.2824, Accuracy: 0.7959\n","Training loss (for one batch) at step 70: 302.6453, Accuracy: 0.7954\n","Training loss (for one batch) at step 80: 277.1131, Accuracy: 0.7938\n","Training loss (for one batch) at step 90: 272.5903, Accuracy: 0.7919\n","Training loss (for one batch) at step 100: 294.7510, Accuracy: 0.7920\n","Training loss (for one batch) at step 110: 275.6088, Accuracy: 0.7915\n","Training loss (for one batch) at step 120: 288.3119, Accuracy: 0.7923\n","Training loss (for one batch) at step 130: 283.3275, Accuracy: 0.7929\n","Training loss (for one batch) at step 140: 278.0891, Accuracy: 0.7924\n","---- Training ----\n","Training loss: 258.0831\n","Training acc over epoch: 0.7915\n","---- Validation ----\n","Validation loss: 67.1297\n","Validation acc: 0.7163\n","Time taken: 38.01s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 267.0449, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 274.1760, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 260.7248, Accuracy: 0.7962\n","Training loss (for one batch) at step 30: 279.9407, Accuracy: 0.7987\n","Training loss (for one batch) at step 40: 281.8289, Accuracy: 0.7941\n","Training loss (for one batch) at step 50: 264.4958, Accuracy: 0.7996\n","Training loss (for one batch) at step 60: 258.0450, Accuracy: 0.7985\n","Training loss (for one batch) at step 70: 274.3603, Accuracy: 0.7979\n","Training loss (for one batch) at step 80: 277.2342, Accuracy: 0.7957\n","Training loss (for one batch) at step 90: 287.3586, Accuracy: 0.7932\n","Training loss (for one batch) at step 100: 269.6772, Accuracy: 0.7934\n","Training loss (for one batch) at step 110: 278.3929, Accuracy: 0.7946\n","Training loss (for one batch) at step 120: 257.8979, Accuracy: 0.7965\n","Training loss (for one batch) at step 130: 272.9823, Accuracy: 0.7952\n","Training loss (for one batch) at step 140: 282.2632, Accuracy: 0.7954\n","---- Training ----\n","Training loss: 269.7241\n","Training acc over epoch: 0.7953\n","---- Validation ----\n","Validation loss: 74.4474\n","Validation acc: 0.7292\n","Time taken: 66.02s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 281.8826, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 274.4663, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 268.7200, Accuracy: 0.8062\n","Training loss (for one batch) at step 30: 290.0397, Accuracy: 0.7965\n","Training loss (for one batch) at step 40: 255.9625, Accuracy: 0.7980\n","Training loss (for one batch) at step 50: 258.1797, Accuracy: 0.8075\n","Training loss (for one batch) at step 60: 281.1497, Accuracy: 0.8064\n","Training loss (for one batch) at step 70: 281.7207, Accuracy: 0.8072\n","Training loss (for one batch) at step 80: 262.9015, Accuracy: 0.8022\n","Training loss (for one batch) at step 90: 273.4463, Accuracy: 0.8014\n","Training loss (for one batch) at step 100: 270.0117, Accuracy: 0.7982\n","Training loss (for one batch) at step 110: 244.3165, Accuracy: 0.8010\n","Training loss (for one batch) at step 120: 270.0508, Accuracy: 0.7996\n","Training loss (for one batch) at step 130: 268.8502, Accuracy: 0.7988\n","Training loss (for one batch) at step 140: 260.0322, Accuracy: 0.7992\n","---- Training ----\n","Training loss: 269.8491\n","Training acc over epoch: 0.8003\n","---- Validation ----\n","Validation loss: 72.2253\n","Validation acc: 0.7166\n","Time taken: 39.84s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 283.3231, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 265.2091, Accuracy: 0.8118\n","Training loss (for one batch) at step 20: 262.2683, Accuracy: 0.8024\n","Training loss (for one batch) at step 30: 286.8758, Accuracy: 0.8055\n","Training loss (for one batch) at step 40: 262.9738, Accuracy: 0.8061\n","Training loss (for one batch) at step 50: 272.9333, Accuracy: 0.8080\n","Training loss (for one batch) at step 60: 272.6455, Accuracy: 0.8098\n","Training loss (for one batch) at step 70: 275.4010, Accuracy: 0.8077\n","Training loss (for one batch) at step 80: 261.3798, Accuracy: 0.8037\n","Training loss (for one batch) at step 90: 260.1746, Accuracy: 0.8040\n","Training loss (for one batch) at step 100: 284.5849, Accuracy: 0.8023\n","Training loss (for one batch) at step 110: 270.2447, Accuracy: 0.8016\n","Training loss (for one batch) at step 120: 283.0817, Accuracy: 0.8021\n","Training loss (for one batch) at step 130: 276.7613, Accuracy: 0.8011\n","Training loss (for one batch) at step 140: 271.3142, Accuracy: 0.8013\n","---- Training ----\n","Training loss: 228.9207\n","Training acc over epoch: 0.8018\n","---- Validation ----\n","Validation loss: 70.2356\n","Validation acc: 0.7496\n","Time taken: 66.29s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 261.5767, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 264.8340, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 284.0477, Accuracy: 0.8052\n","Training loss (for one batch) at step 30: 265.1070, Accuracy: 0.8048\n","Training loss (for one batch) at step 40: 266.2586, Accuracy: 0.8090\n","Training loss (for one batch) at step 50: 257.8621, Accuracy: 0.8092\n","Training loss (for one batch) at step 60: 259.6110, Accuracy: 0.8118\n","Training loss (for one batch) at step 70: 263.3839, Accuracy: 0.8085\n","Training loss (for one batch) at step 80: 270.4365, Accuracy: 0.8054\n","Training loss (for one batch) at step 90: 267.5217, Accuracy: 0.8042\n","Training loss (for one batch) at step 100: 262.6905, Accuracy: 0.8029\n","Training loss (for one batch) at step 110: 253.4150, Accuracy: 0.8039\n","Training loss (for one batch) at step 120: 276.2479, Accuracy: 0.8050\n","Training loss (for one batch) at step 130: 268.2697, Accuracy: 0.8044\n","Training loss (for one batch) at step 140: 265.4790, Accuracy: 0.8029\n","---- Training ----\n","Training loss: 245.3509\n","Training acc over epoch: 0.8025\n","---- Validation ----\n","Validation loss: 74.2644\n","Validation acc: 0.7466\n","Time taken: 38.38s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 252.2912, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 270.3866, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 265.6100, Accuracy: 0.8186\n","Training loss (for one batch) at step 30: 277.3905, Accuracy: 0.8158\n","Training loss (for one batch) at step 40: 239.8378, Accuracy: 0.8185\n","Training loss (for one batch) at step 50: 256.0900, Accuracy: 0.8200\n","Training loss (for one batch) at step 60: 252.8295, Accuracy: 0.8164\n","Training loss (for one batch) at step 70: 260.9091, Accuracy: 0.8155\n","Training loss (for one batch) at step 80: 262.5147, Accuracy: 0.8125\n","Training loss (for one batch) at step 90: 261.9024, Accuracy: 0.8127\n","Training loss (for one batch) at step 100: 268.8061, Accuracy: 0.8125\n","Training loss (for one batch) at step 110: 236.9369, Accuracy: 0.8129\n","Training loss (for one batch) at step 120: 272.2038, Accuracy: 0.8129\n","Training loss (for one batch) at step 130: 248.0572, Accuracy: 0.8128\n","Training loss (for one batch) at step 140: 262.9789, Accuracy: 0.8121\n","---- Training ----\n","Training loss: 221.2986\n","Training acc over epoch: 0.8123\n","---- Validation ----\n","Validation loss: 64.7940\n","Validation acc: 0.7354\n","Time taken: 65.56s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 261.0020, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 263.5709, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 258.6952, Accuracy: 0.8024\n","Training loss (for one batch) at step 30: 273.9492, Accuracy: 0.8052\n","Training loss (for one batch) at step 40: 255.9412, Accuracy: 0.8134\n","Training loss (for one batch) at step 50: 251.2284, Accuracy: 0.8127\n","Training loss (for one batch) at step 60: 256.5804, Accuracy: 0.8098\n","Training loss (for one batch) at step 70: 265.2065, Accuracy: 0.8099\n","Training loss (for one batch) at step 80: 307.5951, Accuracy: 0.8059\n","Training loss (for one batch) at step 90: 254.5491, Accuracy: 0.8027\n","Training loss (for one batch) at step 100: 265.7367, Accuracy: 0.8005\n","Training loss (for one batch) at step 110: 232.5560, Accuracy: 0.8006\n","Training loss (for one batch) at step 120: 259.8309, Accuracy: 0.8012\n","Training loss (for one batch) at step 130: 285.8835, Accuracy: 0.8030\n","Training loss (for one batch) at step 140: 286.5533, Accuracy: 0.8046\n","---- Training ----\n","Training loss: 225.5977\n","Training acc over epoch: 0.8053\n","---- Validation ----\n","Validation loss: 79.5885\n","Validation acc: 0.7230\n","Time taken: 37.99s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 253.1805, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 260.0168, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 259.2551, Accuracy: 0.8129\n","Training loss (for one batch) at step 30: 266.1500, Accuracy: 0.8103\n","Training loss (for one batch) at step 40: 248.7327, Accuracy: 0.8129\n","Training loss (for one batch) at step 50: 269.4868, Accuracy: 0.8161\n","Training loss (for one batch) at step 60: 244.5789, Accuracy: 0.8177\n","Training loss (for one batch) at step 70: 264.4471, Accuracy: 0.8159\n","Training loss (for one batch) at step 80: 254.6012, Accuracy: 0.8151\n","Training loss (for one batch) at step 90: 266.1863, Accuracy: 0.8122\n","Training loss (for one batch) at step 100: 265.5896, Accuracy: 0.8114\n","Training loss (for one batch) at step 110: 274.1886, Accuracy: 0.8105\n","Training loss (for one batch) at step 120: 246.1082, Accuracy: 0.8121\n","Training loss (for one batch) at step 130: 258.8216, Accuracy: 0.8113\n","Training loss (for one batch) at step 140: 265.9856, Accuracy: 0.8104\n","---- Training ----\n","Training loss: 228.0304\n","Training acc over epoch: 0.8108\n","---- Validation ----\n","Validation loss: 77.5830\n","Validation acc: 0.7233\n","Time taken: 65.46s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 260.5574, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 259.3604, Accuracy: 0.8100\n","Training loss (for one batch) at step 20: 242.0190, Accuracy: 0.8090\n","Training loss (for one batch) at step 30: 228.5586, Accuracy: 0.8171\n","Training loss (for one batch) at step 40: 242.7536, Accuracy: 0.8159\n","Training loss (for one batch) at step 50: 247.6724, Accuracy: 0.8210\n","Training loss (for one batch) at step 60: 248.3274, Accuracy: 0.8249\n","Training loss (for one batch) at step 70: 272.1266, Accuracy: 0.8224\n","Training loss (for one batch) at step 80: 263.2000, Accuracy: 0.8180\n","Training loss (for one batch) at step 90: 258.9083, Accuracy: 0.8173\n","Training loss (for one batch) at step 100: 258.8387, Accuracy: 0.8163\n","Training loss (for one batch) at step 110: 242.9895, Accuracy: 0.8145\n","Training loss (for one batch) at step 120: 273.8111, Accuracy: 0.8146\n","Training loss (for one batch) at step 130: 234.3223, Accuracy: 0.8140\n","Training loss (for one batch) at step 140: 267.3054, Accuracy: 0.8140\n","---- Training ----\n","Training loss: 239.2564\n","Training acc over epoch: 0.8135\n","---- Validation ----\n","Validation loss: 72.5420\n","Validation acc: 0.7214\n","Time taken: 38.26s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 252.9211, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 250.2838, Accuracy: 0.8109\n","Training loss (for one batch) at step 20: 255.2143, Accuracy: 0.8090\n","Training loss (for one batch) at step 30: 258.8029, Accuracy: 0.8106\n","Training loss (for one batch) at step 40: 231.0898, Accuracy: 0.8139\n","Training loss (for one batch) at step 50: 261.2003, Accuracy: 0.8165\n","Training loss (for one batch) at step 60: 253.1717, Accuracy: 0.8159\n","Training loss (for one batch) at step 70: 242.5367, Accuracy: 0.8162\n","Training loss (for one batch) at step 80: 256.9031, Accuracy: 0.8146\n","Training loss (for one batch) at step 90: 267.7472, Accuracy: 0.8135\n","Training loss (for one batch) at step 100: 264.5642, Accuracy: 0.8116\n","Training loss (for one batch) at step 110: 247.3413, Accuracy: 0.8132\n","Training loss (for one batch) at step 120: 266.5620, Accuracy: 0.8141\n","Training loss (for one batch) at step 130: 279.6115, Accuracy: 0.8153\n","Training loss (for one batch) at step 140: 226.5630, Accuracy: 0.8141\n","---- Training ----\n","Training loss: 226.3137\n","Training acc over epoch: 0.8135\n","---- Validation ----\n","Validation loss: 72.9198\n","Validation acc: 0.7206\n","Time taken: 65.04s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 275.8741, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 228.7854, Accuracy: 0.8155\n","Training loss (for one batch) at step 20: 251.8837, Accuracy: 0.8267\n","Training loss (for one batch) at step 30: 251.2052, Accuracy: 0.8245\n","Training loss (for one batch) at step 40: 250.4408, Accuracy: 0.8259\n","Training loss (for one batch) at step 50: 235.0696, Accuracy: 0.8267\n","Training loss (for one batch) at step 60: 251.1914, Accuracy: 0.8266\n","Training loss (for one batch) at step 70: 254.8408, Accuracy: 0.8249\n","Training loss (for one batch) at step 80: 242.4602, Accuracy: 0.8247\n","Training loss (for one batch) at step 90: 248.1003, Accuracy: 0.8237\n","Training loss (for one batch) at step 100: 257.4386, Accuracy: 0.8211\n","Training loss (for one batch) at step 110: 244.1203, Accuracy: 0.8192\n","Training loss (for one batch) at step 120: 247.9332, Accuracy: 0.8199\n","Training loss (for one batch) at step 130: 244.9213, Accuracy: 0.8196\n","Training loss (for one batch) at step 140: 256.4597, Accuracy: 0.8177\n","---- Training ----\n","Training loss: 204.4540\n","Training acc over epoch: 0.8175\n","---- Validation ----\n","Validation loss: 54.5762\n","Validation acc: 0.7380\n","Time taken: 37.56s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 263.3540, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 259.2111, Accuracy: 0.8136\n","Training loss (for one batch) at step 20: 246.8516, Accuracy: 0.8205\n","Training loss (for one batch) at step 30: 238.2427, Accuracy: 0.8190\n","Training loss (for one batch) at step 40: 216.3518, Accuracy: 0.8241\n","Training loss (for one batch) at step 50: 232.5271, Accuracy: 0.8275\n","Training loss (for one batch) at step 60: 257.6609, Accuracy: 0.8266\n","Training loss (for one batch) at step 70: 271.8972, Accuracy: 0.8232\n","Training loss (for one batch) at step 80: 242.0723, Accuracy: 0.8200\n","Training loss (for one batch) at step 90: 261.6023, Accuracy: 0.8181\n","Training loss (for one batch) at step 100: 244.6490, Accuracy: 0.8198\n","Training loss (for one batch) at step 110: 249.1104, Accuracy: 0.8188\n","Training loss (for one batch) at step 120: 231.2841, Accuracy: 0.8204\n","Training loss (for one batch) at step 130: 233.8869, Accuracy: 0.8173\n","Training loss (for one batch) at step 140: 244.7898, Accuracy: 0.8178\n","---- Training ----\n","Training loss: 225.4135\n","Training acc over epoch: 0.8180\n","---- Validation ----\n","Validation loss: 69.9166\n","Validation acc: 0.7364\n","Time taken: 65.86s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 240.2009, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 232.1888, Accuracy: 0.8300\n","Training loss (for one batch) at step 20: 256.5484, Accuracy: 0.8262\n","Training loss (for one batch) at step 30: 233.2800, Accuracy: 0.8226\n","Training loss (for one batch) at step 40: 245.3730, Accuracy: 0.8234\n","Training loss (for one batch) at step 50: 249.1418, Accuracy: 0.8261\n","Training loss (for one batch) at step 60: 231.9691, Accuracy: 0.8264\n","Training loss (for one batch) at step 70: 247.3479, Accuracy: 0.8234\n","Training loss (for one batch) at step 80: 251.1865, Accuracy: 0.8228\n","Training loss (for one batch) at step 90: 241.9819, Accuracy: 0.8235\n","Training loss (for one batch) at step 100: 233.8342, Accuracy: 0.8239\n","Training loss (for one batch) at step 110: 242.0074, Accuracy: 0.8239\n","Training loss (for one batch) at step 120: 220.5725, Accuracy: 0.8236\n","Training loss (for one batch) at step 130: 239.0746, Accuracy: 0.8226\n","Training loss (for one batch) at step 140: 240.2853, Accuracy: 0.8220\n","---- Training ----\n","Training loss: 216.5283\n","Training acc over epoch: 0.8231\n","---- Validation ----\n","Validation loss: 62.2217\n","Validation acc: 0.7335\n","Time taken: 38.02s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 241.6787, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 248.3027, Accuracy: 0.7973\n","Training loss (for one batch) at step 20: 234.7922, Accuracy: 0.8071\n","Training loss (for one batch) at step 30: 233.5747, Accuracy: 0.8187\n","Training loss (for one batch) at step 40: 230.8037, Accuracy: 0.8222\n","Training loss (for one batch) at step 50: 222.7518, Accuracy: 0.8237\n","Training loss (for one batch) at step 60: 231.8712, Accuracy: 0.8264\n","Training loss (for one batch) at step 70: 234.8821, Accuracy: 0.8254\n","Training loss (for one batch) at step 80: 218.3129, Accuracy: 0.8251\n","Training loss (for one batch) at step 90: 234.8781, Accuracy: 0.8244\n","Training loss (for one batch) at step 100: 227.4222, Accuracy: 0.8244\n","Training loss (for one batch) at step 110: 248.7650, Accuracy: 0.8238\n","Training loss (for one batch) at step 120: 260.3617, Accuracy: 0.8250\n","Training loss (for one batch) at step 130: 246.1893, Accuracy: 0.8244\n","Training loss (for one batch) at step 140: 228.9409, Accuracy: 0.8236\n","---- Training ----\n","Training loss: 244.2156\n","Training acc over epoch: 0.8225\n","---- Validation ----\n","Validation loss: 70.0685\n","Validation acc: 0.7300\n","Time taken: 64.26s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 243.0386, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 251.9852, Accuracy: 0.8209\n","Training loss (for one batch) at step 20: 257.1714, Accuracy: 0.8171\n","Training loss (for one batch) at step 30: 241.6427, Accuracy: 0.8171\n","Training loss (for one batch) at step 40: 239.5426, Accuracy: 0.8254\n","Training loss (for one batch) at step 50: 244.6678, Accuracy: 0.8243\n","Training loss (for one batch) at step 60: 229.5812, Accuracy: 0.8244\n","Training loss (for one batch) at step 70: 239.7380, Accuracy: 0.8245\n","Training loss (for one batch) at step 80: 247.2630, Accuracy: 0.8233\n","Training loss (for one batch) at step 90: 251.6795, Accuracy: 0.8225\n","Training loss (for one batch) at step 100: 243.9653, Accuracy: 0.8208\n","Training loss (for one batch) at step 110: 229.6485, Accuracy: 0.8215\n","Training loss (for one batch) at step 120: 252.0766, Accuracy: 0.8223\n","Training loss (for one batch) at step 130: 227.1138, Accuracy: 0.8201\n","Training loss (for one batch) at step 140: 229.0114, Accuracy: 0.8191\n","---- Training ----\n","Training loss: 224.5929\n","Training acc over epoch: 0.8197\n","---- Validation ----\n","Validation loss: 69.2726\n","Validation acc: 0.7211\n","Time taken: 37.62s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 271.6505, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 220.2006, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 245.9800, Accuracy: 0.8295\n","Training loss (for one batch) at step 30: 255.8607, Accuracy: 0.8290\n","Training loss (for one batch) at step 40: 240.1856, Accuracy: 0.8268\n","Training loss (for one batch) at step 50: 217.3540, Accuracy: 0.8314\n","Training loss (for one batch) at step 60: 232.1200, Accuracy: 0.8298\n","Training loss (for one batch) at step 70: 238.8280, Accuracy: 0.8270\n","Training loss (for one batch) at step 80: 234.9357, Accuracy: 0.8241\n","Training loss (for one batch) at step 90: 258.4650, Accuracy: 0.8246\n","Training loss (for one batch) at step 100: 249.7270, Accuracy: 0.8234\n","Training loss (for one batch) at step 110: 250.2388, Accuracy: 0.8226\n","Training loss (for one batch) at step 120: 228.7269, Accuracy: 0.8225\n","Training loss (for one batch) at step 130: 256.3141, Accuracy: 0.8225\n","Training loss (for one batch) at step 140: 224.9754, Accuracy: 0.8227\n","---- Training ----\n","Training loss: 223.0587\n","Training acc over epoch: 0.8223\n","---- Validation ----\n","Validation loss: 73.4559\n","Validation acc: 0.7217\n","Time taken: 65.59s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 220.2015, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 229.7063, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 235.6014, Accuracy: 0.8424\n","Training loss (for one batch) at step 30: 229.0674, Accuracy: 0.8365\n","Training loss (for one batch) at step 40: 239.4333, Accuracy: 0.8373\n","Training loss (for one batch) at step 50: 230.2215, Accuracy: 0.8394\n","Training loss (for one batch) at step 60: 231.3838, Accuracy: 0.8400\n","Training loss (for one batch) at step 70: 238.2717, Accuracy: 0.8386\n","Training loss (for one batch) at step 80: 246.0764, Accuracy: 0.8341\n","Training loss (for one batch) at step 90: 247.5864, Accuracy: 0.8334\n","Training loss (for one batch) at step 100: 233.3765, Accuracy: 0.8319\n","Training loss (for one batch) at step 110: 232.3233, Accuracy: 0.8328\n","Training loss (for one batch) at step 120: 245.4573, Accuracy: 0.8296\n","Training loss (for one batch) at step 130: 237.8051, Accuracy: 0.8289\n","Training loss (for one batch) at step 140: 237.6152, Accuracy: 0.8290\n","---- Training ----\n","Training loss: 229.0773\n","Training acc over epoch: 0.8287\n","---- Validation ----\n","Validation loss: 75.4221\n","Validation acc: 0.7225\n","Time taken: 38.13s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 248.8514, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 227.8739, Accuracy: 0.8282\n","Training loss (for one batch) at step 20: 251.3698, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 217.5492, Accuracy: 0.8348\n","Training loss (for one batch) at step 40: 233.7143, Accuracy: 0.8295\n","Training loss (for one batch) at step 50: 234.8620, Accuracy: 0.8308\n","Training loss (for one batch) at step 60: 246.6546, Accuracy: 0.8289\n","Training loss (for one batch) at step 70: 231.1816, Accuracy: 0.8300\n","Training loss (for one batch) at step 80: 243.9612, Accuracy: 0.8263\n","Training loss (for one batch) at step 90: 231.9786, Accuracy: 0.8273\n","Training loss (for one batch) at step 100: 229.2979, Accuracy: 0.8265\n","Training loss (for one batch) at step 110: 251.5372, Accuracy: 0.8267\n","Training loss (for one batch) at step 120: 225.8591, Accuracy: 0.8276\n","Training loss (for one batch) at step 130: 242.9096, Accuracy: 0.8262\n","Training loss (for one batch) at step 140: 233.1262, Accuracy: 0.8273\n","---- Training ----\n","Training loss: 196.5769\n","Training acc over epoch: 0.8265\n","---- Validation ----\n","Validation loss: 67.8755\n","Validation acc: 0.7429\n","Time taken: 72.57s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 251.6011, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 240.7859, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 228.1844, Accuracy: 0.8348\n","Training loss (for one batch) at step 30: 238.0390, Accuracy: 0.8277\n","Training loss (for one batch) at step 40: 219.0575, Accuracy: 0.8320\n","Training loss (for one batch) at step 50: 233.7171, Accuracy: 0.8341\n","Training loss (for one batch) at step 60: 219.2300, Accuracy: 0.8339\n","Training loss (for one batch) at step 70: 251.2744, Accuracy: 0.8296\n","Training loss (for one batch) at step 80: 233.7988, Accuracy: 0.8302\n","Training loss (for one batch) at step 90: 221.3503, Accuracy: 0.8278\n","Training loss (for one batch) at step 100: 220.4608, Accuracy: 0.8268\n","Training loss (for one batch) at step 110: 244.2804, Accuracy: 0.8273\n","Training loss (for one batch) at step 120: 213.3488, Accuracy: 0.8276\n","Training loss (for one batch) at step 130: 236.7100, Accuracy: 0.8267\n","Training loss (for one batch) at step 140: 229.8438, Accuracy: 0.8251\n","---- Training ----\n","Training loss: 208.8496\n","Training acc over epoch: 0.8257\n","---- Validation ----\n","Validation loss: 70.2737\n","Validation acc: 0.7125\n","Time taken: 38.47s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 228.1042, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 229.1110, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 230.0180, Accuracy: 0.8210\n","Training loss (for one batch) at step 30: 246.5198, Accuracy: 0.8261\n","Training loss (for one batch) at step 40: 221.1021, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 222.1232, Accuracy: 0.8324\n","Training loss (for one batch) at step 60: 219.4864, Accuracy: 0.8326\n","Training loss (for one batch) at step 70: 218.5452, Accuracy: 0.8311\n","Training loss (for one batch) at step 80: 234.2761, Accuracy: 0.8311\n","Training loss (for one batch) at step 90: 240.7597, Accuracy: 0.8291\n","Training loss (for one batch) at step 100: 242.9129, Accuracy: 0.8281\n","Training loss (for one batch) at step 110: 248.8243, Accuracy: 0.8270\n","Training loss (for one batch) at step 120: 225.5729, Accuracy: 0.8266\n","Training loss (for one batch) at step 130: 222.3100, Accuracy: 0.8266\n","Training loss (for one batch) at step 140: 240.8463, Accuracy: 0.8245\n","---- Training ----\n","Training loss: 192.1903\n","Training acc over epoch: 0.8245\n","---- Validation ----\n","Validation loss: 55.7181\n","Validation acc: 0.7208\n","Time taken: 65.86s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 235.8002, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 244.8454, Accuracy: 0.8464\n","Training loss (for one batch) at step 20: 213.9529, Accuracy: 0.8386\n","Training loss (for one batch) at step 30: 227.9485, Accuracy: 0.8297\n","Training loss (for one batch) at step 40: 221.9188, Accuracy: 0.8305\n","Training loss (for one batch) at step 50: 207.3791, Accuracy: 0.8312\n","Training loss (for one batch) at step 60: 226.3200, Accuracy: 0.8339\n","Training loss (for one batch) at step 70: 234.2954, Accuracy: 0.8301\n","Training loss (for one batch) at step 80: 246.6668, Accuracy: 0.8268\n","Training loss (for one batch) at step 90: 251.1544, Accuracy: 0.8268\n","Training loss (for one batch) at step 100: 232.6071, Accuracy: 0.8276\n","Training loss (for one batch) at step 110: 226.9445, Accuracy: 0.8266\n","Training loss (for one batch) at step 120: 234.8217, Accuracy: 0.8274\n","Training loss (for one batch) at step 130: 234.0620, Accuracy: 0.8269\n","Training loss (for one batch) at step 140: 225.7990, Accuracy: 0.8266\n","---- Training ----\n","Training loss: 193.7419\n","Training acc over epoch: 0.8263\n","---- Validation ----\n","Validation loss: 59.9010\n","Validation acc: 0.7233\n","Time taken: 38.45s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 229.3847, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 240.2244, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 216.0325, Accuracy: 0.8343\n","Training loss (for one batch) at step 30: 229.5385, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 206.5859, Accuracy: 0.8332\n","Training loss (for one batch) at step 50: 244.8557, Accuracy: 0.8380\n","Training loss (for one batch) at step 60: 212.8445, Accuracy: 0.8354\n","Training loss (for one batch) at step 70: 220.3538, Accuracy: 0.8349\n","Training loss (for one batch) at step 80: 219.2851, Accuracy: 0.8321\n","Training loss (for one batch) at step 90: 219.6088, Accuracy: 0.8310\n","Training loss (for one batch) at step 100: 208.5105, Accuracy: 0.8307\n","Training loss (for one batch) at step 110: 241.8223, Accuracy: 0.8301\n","Training loss (for one batch) at step 120: 227.5181, Accuracy: 0.8314\n","Training loss (for one batch) at step 130: 232.9738, Accuracy: 0.8319\n","Training loss (for one batch) at step 140: 231.8808, Accuracy: 0.8323\n","---- Training ----\n","Training loss: 197.7151\n","Training acc over epoch: 0.8326\n","---- Validation ----\n","Validation loss: 86.0767\n","Validation acc: 0.7163\n","Time taken: 95.50s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 261.9899, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 213.6380, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 242.8512, Accuracy: 0.8271\n","Training loss (for one batch) at step 30: 227.1693, Accuracy: 0.8277\n","Training loss (for one batch) at step 40: 241.1911, Accuracy: 0.8354\n","Training loss (for one batch) at step 50: 230.3850, Accuracy: 0.8353\n","Training loss (for one batch) at step 60: 205.4429, Accuracy: 0.8374\n","Training loss (for one batch) at step 70: 212.5689, Accuracy: 0.8390\n","Training loss (for one batch) at step 80: 231.4029, Accuracy: 0.8340\n","Training loss (for one batch) at step 90: 217.5745, Accuracy: 0.8336\n","Training loss (for one batch) at step 100: 225.2627, Accuracy: 0.8318\n","Training loss (for one batch) at step 110: 222.2124, Accuracy: 0.8329\n","Training loss (for one batch) at step 120: 242.0108, Accuracy: 0.8333\n","Training loss (for one batch) at step 130: 227.8949, Accuracy: 0.8335\n","Training loss (for one batch) at step 140: 242.5297, Accuracy: 0.8318\n","---- Training ----\n","Training loss: 199.7805\n","Training acc over epoch: 0.8324\n","---- Validation ----\n","Validation loss: 77.9836\n","Validation acc: 0.7166\n","Time taken: 37.42s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 213.9440, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 203.8948, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 199.8266, Accuracy: 0.8438\n","Training loss (for one batch) at step 30: 200.7892, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 208.9452, Accuracy: 0.8354\n","Training loss (for one batch) at step 50: 227.5830, Accuracy: 0.8375\n","Training loss (for one batch) at step 60: 215.2776, Accuracy: 0.8410\n","Training loss (for one batch) at step 70: 218.1238, Accuracy: 0.8393\n","Training loss (for one batch) at step 80: 224.6337, Accuracy: 0.8353\n","Training loss (for one batch) at step 90: 218.9991, Accuracy: 0.8326\n","Training loss (for one batch) at step 100: 216.6648, Accuracy: 0.8323\n","Training loss (for one batch) at step 110: 218.1716, Accuracy: 0.8345\n","Training loss (for one batch) at step 120: 212.0941, Accuracy: 0.8342\n","Training loss (for one batch) at step 130: 228.5353, Accuracy: 0.8332\n","Training loss (for one batch) at step 140: 233.0268, Accuracy: 0.8320\n","---- Training ----\n","Training loss: 183.2200\n","Training acc over epoch: 0.8320\n","---- Validation ----\n","Validation loss: 72.4891\n","Validation acc: 0.7222\n","Time taken: 66.00s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 212.2791, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 217.7918, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 222.9600, Accuracy: 0.8300\n","Training loss (for one batch) at step 30: 212.4073, Accuracy: 0.8358\n","Training loss (for one batch) at step 40: 209.3708, Accuracy: 0.8388\n","Training loss (for one batch) at step 50: 233.0493, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 228.9935, Accuracy: 0.8377\n","Training loss (for one batch) at step 70: 237.9861, Accuracy: 0.8359\n","Training loss (for one batch) at step 80: 218.7483, Accuracy: 0.8386\n","Training loss (for one batch) at step 90: 248.5565, Accuracy: 0.8334\n","Training loss (for one batch) at step 100: 227.8262, Accuracy: 0.8339\n","Training loss (for one batch) at step 110: 215.5889, Accuracy: 0.8346\n","Training loss (for one batch) at step 120: 205.8310, Accuracy: 0.8355\n","Training loss (for one batch) at step 130: 215.7945, Accuracy: 0.8350\n","Training loss (for one batch) at step 140: 235.8431, Accuracy: 0.8338\n","---- Training ----\n","Training loss: 197.8561\n","Training acc over epoch: 0.8336\n","---- Validation ----\n","Validation loss: 60.8140\n","Validation acc: 0.7184\n","Time taken: 37.70s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 214.6485, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 181.9791, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 224.0612, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 215.2913, Accuracy: 0.8368\n","Training loss (for one batch) at step 40: 222.3994, Accuracy: 0.8366\n","Training loss (for one batch) at step 50: 240.0242, Accuracy: 0.8388\n","Training loss (for one batch) at step 60: 211.2804, Accuracy: 0.8418\n","Training loss (for one batch) at step 70: 225.1783, Accuracy: 0.8415\n","Training loss (for one batch) at step 80: 224.0579, Accuracy: 0.8405\n","Training loss (for one batch) at step 90: 205.6766, Accuracy: 0.8401\n","Training loss (for one batch) at step 100: 225.3220, Accuracy: 0.8372\n","Training loss (for one batch) at step 110: 216.5259, Accuracy: 0.8369\n","Training loss (for one batch) at step 120: 197.8819, Accuracy: 0.8383\n","Training loss (for one batch) at step 130: 235.7797, Accuracy: 0.8370\n","Training loss (for one batch) at step 140: 233.7490, Accuracy: 0.8360\n","---- Training ----\n","Training loss: 200.7546\n","Training acc over epoch: 0.8361\n","---- Validation ----\n","Validation loss: 82.5835\n","Validation acc: 0.7168\n","Time taken: 65.14s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 229.3561, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 198.8737, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 217.4108, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 218.5291, Accuracy: 0.8403\n","Training loss (for one batch) at step 40: 232.2681, Accuracy: 0.8376\n","Training loss (for one batch) at step 50: 226.4752, Accuracy: 0.8378\n","Training loss (for one batch) at step 60: 209.1878, Accuracy: 0.8392\n","Training loss (for one batch) at step 70: 225.9359, Accuracy: 0.8359\n","Training loss (for one batch) at step 80: 209.7132, Accuracy: 0.8331\n","Training loss (for one batch) at step 90: 222.9254, Accuracy: 0.8331\n","Training loss (for one batch) at step 100: 203.8576, Accuracy: 0.8331\n","Training loss (for one batch) at step 110: 206.8454, Accuracy: 0.8332\n","Training loss (for one batch) at step 120: 227.8678, Accuracy: 0.8341\n","Training loss (for one batch) at step 130: 213.7478, Accuracy: 0.8331\n","Training loss (for one batch) at step 140: 228.0531, Accuracy: 0.8328\n","---- Training ----\n","Training loss: 189.8096\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 69.9581\n","Validation acc: 0.7332\n","Time taken: 38.10s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 200.8908, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 219.6393, Accuracy: 0.8445\n","Training loss (for one batch) at step 20: 207.8801, Accuracy: 0.8352\n","Training loss (for one batch) at step 30: 246.4021, Accuracy: 0.8284\n","Training loss (for one batch) at step 40: 209.6073, Accuracy: 0.8349\n","Training loss (for one batch) at step 50: 199.8738, Accuracy: 0.8406\n","Training loss (for one batch) at step 60: 228.0004, Accuracy: 0.8387\n","Training loss (for one batch) at step 70: 249.1757, Accuracy: 0.8386\n","Training loss (for one batch) at step 80: 224.6043, Accuracy: 0.8363\n","Training loss (for one batch) at step 90: 227.6601, Accuracy: 0.8351\n","Training loss (for one batch) at step 100: 213.1256, Accuracy: 0.8359\n","Training loss (for one batch) at step 110: 232.2686, Accuracy: 0.8362\n","Training loss (for one batch) at step 120: 223.9907, Accuracy: 0.8379\n","Training loss (for one batch) at step 130: 247.7912, Accuracy: 0.8376\n","Training loss (for one batch) at step 140: 246.0294, Accuracy: 0.8362\n","---- Training ----\n","Training loss: 187.7875\n","Training acc over epoch: 0.8366\n","---- Validation ----\n","Validation loss: 70.7350\n","Validation acc: 0.7184\n","Time taken: 65.56s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 217.7732, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 234.4266, Accuracy: 0.8482\n","Training loss (for one batch) at step 20: 203.2027, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 216.2579, Accuracy: 0.8400\n","Training loss (for one batch) at step 40: 207.5538, Accuracy: 0.8417\n","Training loss (for one batch) at step 50: 213.3472, Accuracy: 0.8425\n","Training loss (for one batch) at step 60: 215.3906, Accuracy: 0.8361\n","Training loss (for one batch) at step 70: 197.4723, Accuracy: 0.8377\n","Training loss (for one batch) at step 80: 210.1010, Accuracy: 0.8359\n","Training loss (for one batch) at step 90: 195.2778, Accuracy: 0.8360\n","Training loss (for one batch) at step 100: 222.4199, Accuracy: 0.8350\n","Training loss (for one batch) at step 110: 206.8688, Accuracy: 0.8364\n","Training loss (for one batch) at step 120: 211.1022, Accuracy: 0.8363\n","Training loss (for one batch) at step 130: 221.0536, Accuracy: 0.8362\n","Training loss (for one batch) at step 140: 212.9427, Accuracy: 0.8353\n","---- Training ----\n","Training loss: 191.5314\n","Training acc over epoch: 0.8352\n","---- Validation ----\n","Validation loss: 77.9508\n","Validation acc: 0.7195\n","Time taken: 37.59s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 223.6536, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 210.7723, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 213.7711, Accuracy: 0.8305\n","Training loss (for one batch) at step 30: 212.7658, Accuracy: 0.8377\n","Training loss (for one batch) at step 40: 241.1566, Accuracy: 0.8412\n","Training loss (for one batch) at step 50: 213.4596, Accuracy: 0.8488\n","Training loss (for one batch) at step 60: 209.3451, Accuracy: 0.8480\n","Training loss (for one batch) at step 70: 231.4615, Accuracy: 0.8437\n","Training loss (for one batch) at step 80: 219.8414, Accuracy: 0.8438\n","Training loss (for one batch) at step 90: 216.0857, Accuracy: 0.8416\n","Training loss (for one batch) at step 100: 211.8239, Accuracy: 0.8401\n","Training loss (for one batch) at step 110: 217.0179, Accuracy: 0.8408\n","Training loss (for one batch) at step 120: 220.0503, Accuracy: 0.8409\n","Training loss (for one batch) at step 130: 247.5967, Accuracy: 0.8407\n","Training loss (for one batch) at step 140: 211.8790, Accuracy: 0.8401\n","---- Training ----\n","Training loss: 170.4977\n","Training acc over epoch: 0.8393\n","---- Validation ----\n","Validation loss: 87.0815\n","Validation acc: 0.7243\n","Time taken: 74.55s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 233.3850, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 216.5984, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 205.7735, Accuracy: 0.8348\n","Training loss (for one batch) at step 30: 196.3538, Accuracy: 0.8368\n","Training loss (for one batch) at step 40: 225.3056, Accuracy: 0.8383\n","Training loss (for one batch) at step 50: 196.2516, Accuracy: 0.8418\n","Training loss (for one batch) at step 60: 218.9918, Accuracy: 0.8418\n","Training loss (for one batch) at step 70: 233.2673, Accuracy: 0.8394\n","Training loss (for one batch) at step 80: 255.6149, Accuracy: 0.8381\n","Training loss (for one batch) at step 90: 200.5958, Accuracy: 0.8381\n","Training loss (for one batch) at step 100: 216.1486, Accuracy: 0.8366\n","Training loss (for one batch) at step 110: 228.9607, Accuracy: 0.8368\n","Training loss (for one batch) at step 120: 253.8981, Accuracy: 0.8372\n","Training loss (for one batch) at step 130: 208.7144, Accuracy: 0.8373\n","Training loss (for one batch) at step 140: 209.7704, Accuracy: 0.8379\n","---- Training ----\n","Training loss: 192.3657\n","Training acc over epoch: 0.8382\n","---- Validation ----\n","Validation loss: 80.3164\n","Validation acc: 0.7184\n","Time taken: 40.68s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 217.6216, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 216.5425, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 237.0836, Accuracy: 0.8371\n","Training loss (for one batch) at step 30: 206.3041, Accuracy: 0.8410\n","Training loss (for one batch) at step 40: 204.0766, Accuracy: 0.8417\n","Training loss (for one batch) at step 50: 232.2241, Accuracy: 0.8424\n","Training loss (for one batch) at step 60: 217.6690, Accuracy: 0.8397\n","Training loss (for one batch) at step 70: 220.7417, Accuracy: 0.8397\n","Training loss (for one batch) at step 80: 199.8788, Accuracy: 0.8381\n","Training loss (for one batch) at step 90: 205.5216, Accuracy: 0.8364\n","Training loss (for one batch) at step 100: 207.1142, Accuracy: 0.8365\n","Training loss (for one batch) at step 110: 205.1105, Accuracy: 0.8393\n","Training loss (for one batch) at step 120: 217.7876, Accuracy: 0.8388\n","Training loss (for one batch) at step 130: 190.2369, Accuracy: 0.8390\n","Training loss (for one batch) at step 140: 216.8800, Accuracy: 0.8393\n","---- Training ----\n","Training loss: 198.1443\n","Training acc over epoch: 0.8385\n","---- Validation ----\n","Validation loss: 78.2435\n","Validation acc: 0.7200\n","Time taken: 63.97s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 230.1934, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 209.6478, Accuracy: 0.8291\n","Training loss (for one batch) at step 20: 213.9764, Accuracy: 0.8395\n","Training loss (for one batch) at step 30: 226.4637, Accuracy: 0.8345\n","Training loss (for one batch) at step 40: 190.1437, Accuracy: 0.8412\n","Training loss (for one batch) at step 50: 217.8707, Accuracy: 0.8443\n","Training loss (for one batch) at step 60: 220.8602, Accuracy: 0.8457\n","Training loss (for one batch) at step 70: 215.5857, Accuracy: 0.8424\n","Training loss (for one batch) at step 80: 199.4958, Accuracy: 0.8412\n","Training loss (for one batch) at step 90: 211.4374, Accuracy: 0.8405\n","Training loss (for one batch) at step 100: 196.8961, Accuracy: 0.8394\n","Training loss (for one batch) at step 110: 210.9171, Accuracy: 0.8386\n","Training loss (for one batch) at step 120: 227.3339, Accuracy: 0.8394\n","Training loss (for one batch) at step 130: 212.0144, Accuracy: 0.8392\n","Training loss (for one batch) at step 140: 240.9035, Accuracy: 0.8392\n","---- Training ----\n","Training loss: 181.9597\n","Training acc over epoch: 0.8384\n","---- Validation ----\n","Validation loss: 59.4744\n","Validation acc: 0.7214\n","Time taken: 38.05s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7324\n","Validation AUC: 0.7293\n","Validation Balanced_ACC: 0.4774\n","Validation MI: 0.1368\n","Validation Normalized MI: 0.2050\n","Validation Adjusted MI: 0.2050\n","Validation aUc_Sklearn: 0.8299\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 479.5241, Accuracy: 0.5300\n","Training loss (for one batch) at step 10: 434.6303, Accuracy: 0.5500\n","Training loss (for one batch) at step 20: 480.0556, Accuracy: 0.5414\n","Training loss (for one batch) at step 30: 459.9586, Accuracy: 0.5371\n","Training loss (for one batch) at step 40: 437.3063, Accuracy: 0.5468\n","Training loss (for one batch) at step 50: 441.2097, Accuracy: 0.5506\n","Training loss (for one batch) at step 60: 437.8273, Accuracy: 0.5552\n","Training loss (for one batch) at step 70: 433.0073, Accuracy: 0.5603\n","Training loss (for one batch) at step 80: 409.3933, Accuracy: 0.5602\n","Training loss (for one batch) at step 90: 456.9695, Accuracy: 0.5609\n","Training loss (for one batch) at step 100: 397.3320, Accuracy: 0.5623\n","Training loss (for one batch) at step 110: 399.2796, Accuracy: 0.5634\n","Training loss (for one batch) at step 120: 425.2460, Accuracy: 0.5653\n","Training loss (for one batch) at step 130: 417.5290, Accuracy: 0.5678\n","Training loss (for one batch) at step 140: 421.9589, Accuracy: 0.5709\n","---- Training ----\n","Training loss: 339.3156\n","Training acc over epoch: 0.5713\n","---- Validation ----\n","Validation loss: 90.4750\n","Validation acc: 0.5134\n","Time taken: 75.59s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 395.2241, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 394.3415, Accuracy: 0.6445\n","Training loss (for one batch) at step 20: 391.3694, Accuracy: 0.6343\n","Training loss (for one batch) at step 30: 392.6755, Accuracy: 0.6239\n","Training loss (for one batch) at step 40: 366.5583, Accuracy: 0.6251\n","Training loss (for one batch) at step 50: 397.9012, Accuracy: 0.6169\n","Training loss (for one batch) at step 60: 401.4820, Accuracy: 0.6169\n","Training loss (for one batch) at step 70: 393.2722, Accuracy: 0.6154\n","Training loss (for one batch) at step 80: 382.2695, Accuracy: 0.6163\n","Training loss (for one batch) at step 90: 385.4666, Accuracy: 0.6156\n","Training loss (for one batch) at step 100: 393.0071, Accuracy: 0.6166\n","Training loss (for one batch) at step 110: 373.5232, Accuracy: 0.6183\n","Training loss (for one batch) at step 120: 442.0537, Accuracy: 0.6172\n","Training loss (for one batch) at step 130: 357.0536, Accuracy: 0.6172\n","Training loss (for one batch) at step 140: 363.0621, Accuracy: 0.6188\n","---- Training ----\n","Training loss: 321.2428\n","Training acc over epoch: 0.6196\n","---- Validation ----\n","Validation loss: 80.1559\n","Validation acc: 0.5247\n","Time taken: 48.99s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 355.7010, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 381.1049, Accuracy: 0.6491\n","Training loss (for one batch) at step 20: 367.4984, Accuracy: 0.6300\n","Training loss (for one batch) at step 30: 382.7675, Accuracy: 0.6319\n","Training loss (for one batch) at step 40: 359.8742, Accuracy: 0.6339\n","Training loss (for one batch) at step 50: 360.8224, Accuracy: 0.6300\n","Training loss (for one batch) at step 60: 383.7451, Accuracy: 0.6318\n","Training loss (for one batch) at step 70: 360.4893, Accuracy: 0.6303\n","Training loss (for one batch) at step 80: 382.1013, Accuracy: 0.6291\n","Training loss (for one batch) at step 90: 338.6798, Accuracy: 0.6301\n","Training loss (for one batch) at step 100: 363.4007, Accuracy: 0.6290\n","Training loss (for one batch) at step 110: 386.4888, Accuracy: 0.6300\n","Training loss (for one batch) at step 120: 366.4424, Accuracy: 0.6302\n","Training loss (for one batch) at step 130: 377.8067, Accuracy: 0.6327\n","Training loss (for one batch) at step 140: 354.8051, Accuracy: 0.6338\n","---- Training ----\n","Training loss: 331.3201\n","Training acc over epoch: 0.6327\n","---- Validation ----\n","Validation loss: 71.6832\n","Validation acc: 0.6690\n","Time taken: 65.55s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 359.6548, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 350.7328, Accuracy: 0.6564\n","Training loss (for one batch) at step 20: 360.8133, Accuracy: 0.6510\n","Training loss (for one batch) at step 30: 343.5828, Accuracy: 0.6587\n","Training loss (for one batch) at step 40: 363.3199, Accuracy: 0.6612\n","Training loss (for one batch) at step 50: 353.9315, Accuracy: 0.6592\n","Training loss (for one batch) at step 60: 357.2854, Accuracy: 0.6561\n","Training loss (for one batch) at step 70: 368.5715, Accuracy: 0.6577\n","Training loss (for one batch) at step 80: 377.2346, Accuracy: 0.6549\n","Training loss (for one batch) at step 90: 359.4851, Accuracy: 0.6524\n","Training loss (for one batch) at step 100: 352.9202, Accuracy: 0.6531\n","Training loss (for one batch) at step 110: 344.2189, Accuracy: 0.6514\n","Training loss (for one batch) at step 120: 340.2103, Accuracy: 0.6521\n","Training loss (for one batch) at step 130: 348.5594, Accuracy: 0.6524\n","Training loss (for one batch) at step 140: 340.0830, Accuracy: 0.6542\n","---- Training ----\n","Training loss: 310.6653\n","Training acc over epoch: 0.6555\n","---- Validation ----\n","Validation loss: 74.3464\n","Validation acc: 0.7133\n","Time taken: 39.16s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 351.3768, Accuracy: 0.6200\n","Training loss (for one batch) at step 10: 353.0665, Accuracy: 0.6636\n","Training loss (for one batch) at step 20: 354.0257, Accuracy: 0.6633\n","Training loss (for one batch) at step 30: 340.7885, Accuracy: 0.6616\n","Training loss (for one batch) at step 40: 336.6227, Accuracy: 0.6690\n","Training loss (for one batch) at step 50: 344.3452, Accuracy: 0.6669\n","Training loss (for one batch) at step 60: 342.9716, Accuracy: 0.6669\n","Training loss (for one batch) at step 70: 337.4590, Accuracy: 0.6700\n","Training loss (for one batch) at step 80: 350.5383, Accuracy: 0.6704\n","Training loss (for one batch) at step 90: 381.6825, Accuracy: 0.6695\n","Training loss (for one batch) at step 100: 315.9998, Accuracy: 0.6703\n","Training loss (for one batch) at step 110: 345.2491, Accuracy: 0.6732\n","Training loss (for one batch) at step 120: 334.2036, Accuracy: 0.6764\n","Training loss (for one batch) at step 130: 361.2713, Accuracy: 0.6763\n","Training loss (for one batch) at step 140: 347.9839, Accuracy: 0.6776\n","---- Training ----\n","Training loss: 308.9143\n","Training acc over epoch: 0.6781\n","---- Validation ----\n","Validation loss: 72.1825\n","Validation acc: 0.7023\n","Time taken: 65.45s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 349.2518, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 345.1181, Accuracy: 0.6882\n","Training loss (for one batch) at step 20: 339.7554, Accuracy: 0.6924\n","Training loss (for one batch) at step 30: 332.8319, Accuracy: 0.6929\n","Training loss (for one batch) at step 40: 337.7595, Accuracy: 0.6871\n","Training loss (for one batch) at step 50: 318.6205, Accuracy: 0.6920\n","Training loss (for one batch) at step 60: 329.6430, Accuracy: 0.6930\n","Training loss (for one batch) at step 70: 316.1043, Accuracy: 0.6900\n","Training loss (for one batch) at step 80: 338.8696, Accuracy: 0.6888\n","Training loss (for one batch) at step 90: 326.2845, Accuracy: 0.6897\n","Training loss (for one batch) at step 100: 319.5118, Accuracy: 0.6880\n","Training loss (for one batch) at step 110: 309.0623, Accuracy: 0.6910\n","Training loss (for one batch) at step 120: 362.3560, Accuracy: 0.6928\n","Training loss (for one batch) at step 130: 326.4955, Accuracy: 0.6944\n","Training loss (for one batch) at step 140: 327.5291, Accuracy: 0.6945\n","---- Training ----\n","Training loss: 309.4334\n","Training acc over epoch: 0.6939\n","---- Validation ----\n","Validation loss: 77.0379\n","Validation acc: 0.6814\n","Time taken: 38.38s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 314.7722, Accuracy: 0.6300\n","Training loss (for one batch) at step 10: 338.0643, Accuracy: 0.7155\n","Training loss (for one batch) at step 20: 329.1381, Accuracy: 0.7114\n","Training loss (for one batch) at step 30: 339.6018, Accuracy: 0.7145\n","Training loss (for one batch) at step 40: 309.0722, Accuracy: 0.7159\n","Training loss (for one batch) at step 50: 330.9476, Accuracy: 0.7175\n","Training loss (for one batch) at step 60: 327.5219, Accuracy: 0.7218\n","Training loss (for one batch) at step 70: 317.3719, Accuracy: 0.7159\n","Training loss (for one batch) at step 80: 315.6838, Accuracy: 0.7137\n","Training loss (for one batch) at step 90: 342.1706, Accuracy: 0.7136\n","Training loss (for one batch) at step 100: 316.2815, Accuracy: 0.7111\n","Training loss (for one batch) at step 110: 321.2736, Accuracy: 0.7090\n","Training loss (for one batch) at step 120: 315.9786, Accuracy: 0.7086\n","Training loss (for one batch) at step 130: 322.0745, Accuracy: 0.7102\n","Training loss (for one batch) at step 140: 315.4114, Accuracy: 0.7099\n","---- Training ----\n","Training loss: 294.9938\n","Training acc over epoch: 0.7089\n","---- Validation ----\n","Validation loss: 76.7858\n","Validation acc: 0.7163\n","Time taken: 66.39s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 334.0974, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 322.8423, Accuracy: 0.7373\n","Training loss (for one batch) at step 20: 331.6446, Accuracy: 0.7267\n","Training loss (for one batch) at step 30: 333.5007, Accuracy: 0.7229\n","Training loss (for one batch) at step 40: 317.0521, Accuracy: 0.7205\n","Training loss (for one batch) at step 50: 314.1695, Accuracy: 0.7190\n","Training loss (for one batch) at step 60: 297.0352, Accuracy: 0.7208\n","Training loss (for one batch) at step 70: 325.3018, Accuracy: 0.7234\n","Training loss (for one batch) at step 80: 328.4239, Accuracy: 0.7189\n","Training loss (for one batch) at step 90: 331.9845, Accuracy: 0.7180\n","Training loss (for one batch) at step 100: 324.1481, Accuracy: 0.7178\n","Training loss (for one batch) at step 110: 322.5584, Accuracy: 0.7200\n","Training loss (for one batch) at step 120: 297.7184, Accuracy: 0.7198\n","Training loss (for one batch) at step 130: 316.6651, Accuracy: 0.7201\n","Training loss (for one batch) at step 140: 328.7845, Accuracy: 0.7211\n","---- Training ----\n","Training loss: 273.9669\n","Training acc over epoch: 0.7219\n","---- Validation ----\n","Validation loss: 71.8118\n","Validation acc: 0.7359\n","Time taken: 38.33s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 308.8978, Accuracy: 0.6800\n","Training loss (for one batch) at step 10: 300.7010, Accuracy: 0.7464\n","Training loss (for one batch) at step 20: 307.9345, Accuracy: 0.7219\n","Training loss (for one batch) at step 30: 304.0897, Accuracy: 0.7248\n","Training loss (for one batch) at step 40: 300.8628, Accuracy: 0.7251\n","Training loss (for one batch) at step 50: 300.6904, Accuracy: 0.7298\n","Training loss (for one batch) at step 60: 333.6637, Accuracy: 0.7313\n","Training loss (for one batch) at step 70: 347.8326, Accuracy: 0.7297\n","Training loss (for one batch) at step 80: 307.9893, Accuracy: 0.7283\n","Training loss (for one batch) at step 90: 318.0943, Accuracy: 0.7307\n","Training loss (for one batch) at step 100: 318.7148, Accuracy: 0.7312\n","Training loss (for one batch) at step 110: 310.1903, Accuracy: 0.7339\n","Training loss (for one batch) at step 120: 328.8819, Accuracy: 0.7359\n","Training loss (for one batch) at step 130: 316.3365, Accuracy: 0.7353\n","Training loss (for one batch) at step 140: 301.1498, Accuracy: 0.7350\n","---- Training ----\n","Training loss: 285.0716\n","Training acc over epoch: 0.7349\n","---- Validation ----\n","Validation loss: 66.1246\n","Validation acc: 0.7176\n","Time taken: 65.71s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 300.6933, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 292.2977, Accuracy: 0.7382\n","Training loss (for one batch) at step 20: 311.1510, Accuracy: 0.7443\n","Training loss (for one batch) at step 30: 339.4004, Accuracy: 0.7371\n","Training loss (for one batch) at step 40: 307.5127, Accuracy: 0.7412\n","Training loss (for one batch) at step 50: 289.1755, Accuracy: 0.7473\n","Training loss (for one batch) at step 60: 311.5857, Accuracy: 0.7449\n","Training loss (for one batch) at step 70: 292.3828, Accuracy: 0.7445\n","Training loss (for one batch) at step 80: 318.7902, Accuracy: 0.7421\n","Training loss (for one batch) at step 90: 307.0590, Accuracy: 0.7423\n","Training loss (for one batch) at step 100: 321.7906, Accuracy: 0.7422\n","Training loss (for one batch) at step 110: 298.1156, Accuracy: 0.7444\n","Training loss (for one batch) at step 120: 307.2987, Accuracy: 0.7456\n","Training loss (for one batch) at step 130: 313.9139, Accuracy: 0.7471\n","Training loss (for one batch) at step 140: 297.6818, Accuracy: 0.7460\n","---- Training ----\n","Training loss: 268.8992\n","Training acc over epoch: 0.7460\n","---- Validation ----\n","Validation loss: 64.5709\n","Validation acc: 0.7380\n","Time taken: 39.95s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 301.4560, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 310.3856, Accuracy: 0.7527\n","Training loss (for one batch) at step 20: 313.4003, Accuracy: 0.7538\n","Training loss (for one batch) at step 30: 292.6399, Accuracy: 0.7513\n","Training loss (for one batch) at step 40: 304.9426, Accuracy: 0.7546\n","Training loss (for one batch) at step 50: 298.1487, Accuracy: 0.7582\n","Training loss (for one batch) at step 60: 290.6568, Accuracy: 0.7631\n","Training loss (for one batch) at step 70: 322.3645, Accuracy: 0.7617\n","Training loss (for one batch) at step 80: 298.8371, Accuracy: 0.7616\n","Training loss (for one batch) at step 90: 267.7661, Accuracy: 0.7601\n","Training loss (for one batch) at step 100: 294.8772, Accuracy: 0.7576\n","Training loss (for one batch) at step 110: 297.3646, Accuracy: 0.7577\n","Training loss (for one batch) at step 120: 298.3638, Accuracy: 0.7598\n","Training loss (for one batch) at step 130: 306.0370, Accuracy: 0.7589\n","Training loss (for one batch) at step 140: 302.5164, Accuracy: 0.7594\n","---- Training ----\n","Training loss: 269.8598\n","Training acc over epoch: 0.7599\n","---- Validation ----\n","Validation loss: 75.6907\n","Validation acc: 0.7230\n","Time taken: 64.81s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 299.8494, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 299.5659, Accuracy: 0.7455\n","Training loss (for one batch) at step 20: 286.4368, Accuracy: 0.7524\n","Training loss (for one batch) at step 30: 309.2848, Accuracy: 0.7587\n","Training loss (for one batch) at step 40: 305.0037, Accuracy: 0.7627\n","Training loss (for one batch) at step 50: 284.1733, Accuracy: 0.7643\n","Training loss (for one batch) at step 60: 286.8339, Accuracy: 0.7646\n","Training loss (for one batch) at step 70: 305.7822, Accuracy: 0.7648\n","Training loss (for one batch) at step 80: 301.5305, Accuracy: 0.7653\n","Training loss (for one batch) at step 90: 293.5418, Accuracy: 0.7658\n","Training loss (for one batch) at step 100: 308.7319, Accuracy: 0.7669\n","Training loss (for one batch) at step 110: 286.5334, Accuracy: 0.7658\n","Training loss (for one batch) at step 120: 294.0993, Accuracy: 0.7663\n","Training loss (for one batch) at step 130: 280.4850, Accuracy: 0.7656\n","Training loss (for one batch) at step 140: 304.8282, Accuracy: 0.7654\n","---- Training ----\n","Training loss: 276.5668\n","Training acc over epoch: 0.7659\n","---- Validation ----\n","Validation loss: 67.2533\n","Validation acc: 0.7254\n","Time taken: 37.87s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 286.7213, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 280.2058, Accuracy: 0.7727\n","Training loss (for one batch) at step 20: 281.2866, Accuracy: 0.7762\n","Training loss (for one batch) at step 30: 296.3166, Accuracy: 0.7794\n","Training loss (for one batch) at step 40: 290.6591, Accuracy: 0.7856\n","Training loss (for one batch) at step 50: 311.8596, Accuracy: 0.7814\n","Training loss (for one batch) at step 60: 276.2718, Accuracy: 0.7843\n","Training loss (for one batch) at step 70: 308.3509, Accuracy: 0.7793\n","Training loss (for one batch) at step 80: 293.8778, Accuracy: 0.7783\n","Training loss (for one batch) at step 90: 282.3287, Accuracy: 0.7744\n","Training loss (for one batch) at step 100: 302.3368, Accuracy: 0.7717\n","Training loss (for one batch) at step 110: 268.1348, Accuracy: 0.7724\n","Training loss (for one batch) at step 120: 307.6303, Accuracy: 0.7737\n","Training loss (for one batch) at step 130: 293.3424, Accuracy: 0.7727\n","Training loss (for one batch) at step 140: 286.4856, Accuracy: 0.7732\n","---- Training ----\n","Training loss: 256.0646\n","Training acc over epoch: 0.7740\n","---- Validation ----\n","Validation loss: 75.0658\n","Validation acc: 0.7182\n","Time taken: 65.20s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 289.9854, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 281.6703, Accuracy: 0.7864\n","Training loss (for one batch) at step 20: 286.9897, Accuracy: 0.7800\n","Training loss (for one batch) at step 30: 280.8076, Accuracy: 0.7784\n","Training loss (for one batch) at step 40: 298.1939, Accuracy: 0.7788\n","Training loss (for one batch) at step 50: 297.9860, Accuracy: 0.7847\n","Training loss (for one batch) at step 60: 288.4882, Accuracy: 0.7838\n","Training loss (for one batch) at step 70: 288.8973, Accuracy: 0.7837\n","Training loss (for one batch) at step 80: 288.4696, Accuracy: 0.7816\n","Training loss (for one batch) at step 90: 296.7395, Accuracy: 0.7829\n","Training loss (for one batch) at step 100: 277.1353, Accuracy: 0.7803\n","Training loss (for one batch) at step 110: 283.6693, Accuracy: 0.7816\n","Training loss (for one batch) at step 120: 282.2724, Accuracy: 0.7818\n","Training loss (for one batch) at step 130: 275.2750, Accuracy: 0.7821\n","Training loss (for one batch) at step 140: 278.1713, Accuracy: 0.7820\n","---- Training ----\n","Training loss: 254.8592\n","Training acc over epoch: 0.7818\n","---- Validation ----\n","Validation loss: 74.8755\n","Validation acc: 0.7431\n","Time taken: 39.00s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 279.8448, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 293.5523, Accuracy: 0.7845\n","Training loss (for one batch) at step 20: 286.2355, Accuracy: 0.7819\n","Training loss (for one batch) at step 30: 271.8284, Accuracy: 0.7861\n","Training loss (for one batch) at step 40: 275.5151, Accuracy: 0.7841\n","Training loss (for one batch) at step 50: 281.7759, Accuracy: 0.7847\n","Training loss (for one batch) at step 60: 289.5174, Accuracy: 0.7844\n","Training loss (for one batch) at step 70: 278.7155, Accuracy: 0.7831\n","Training loss (for one batch) at step 80: 290.5847, Accuracy: 0.7801\n","Training loss (for one batch) at step 90: 303.0349, Accuracy: 0.7823\n","Training loss (for one batch) at step 100: 289.9084, Accuracy: 0.7825\n","Training loss (for one batch) at step 110: 289.0851, Accuracy: 0.7811\n","Training loss (for one batch) at step 120: 296.3590, Accuracy: 0.7824\n","Training loss (for one batch) at step 130: 277.2641, Accuracy: 0.7834\n","Training loss (for one batch) at step 140: 307.4809, Accuracy: 0.7833\n","---- Training ----\n","Training loss: 253.9147\n","Training acc over epoch: 0.7835\n","---- Validation ----\n","Validation loss: 64.2057\n","Validation acc: 0.7397\n","Time taken: 66.00s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 282.5075, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 276.2860, Accuracy: 0.7964\n","Training loss (for one batch) at step 20: 289.4795, Accuracy: 0.7810\n","Training loss (for one batch) at step 30: 301.5453, Accuracy: 0.7887\n","Training loss (for one batch) at step 40: 289.0535, Accuracy: 0.7834\n","Training loss (for one batch) at step 50: 274.3402, Accuracy: 0.7839\n","Training loss (for one batch) at step 60: 283.3886, Accuracy: 0.7836\n","Training loss (for one batch) at step 70: 270.7652, Accuracy: 0.7851\n","Training loss (for one batch) at step 80: 278.5645, Accuracy: 0.7853\n","Training loss (for one batch) at step 90: 288.3759, Accuracy: 0.7820\n","Training loss (for one batch) at step 100: 287.1304, Accuracy: 0.7815\n","Training loss (for one batch) at step 110: 264.7650, Accuracy: 0.7827\n","Training loss (for one batch) at step 120: 283.5528, Accuracy: 0.7841\n","Training loss (for one batch) at step 130: 271.7293, Accuracy: 0.7849\n","Training loss (for one batch) at step 140: 287.8220, Accuracy: 0.7850\n","---- Training ----\n","Training loss: 252.3809\n","Training acc over epoch: 0.7859\n","---- Validation ----\n","Validation loss: 76.6500\n","Validation acc: 0.7523\n","Time taken: 38.30s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 279.6506, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 277.5917, Accuracy: 0.7964\n","Training loss (for one batch) at step 20: 291.1006, Accuracy: 0.8005\n","Training loss (for one batch) at step 30: 277.0858, Accuracy: 0.7948\n","Training loss (for one batch) at step 40: 263.8018, Accuracy: 0.7939\n","Training loss (for one batch) at step 50: 280.2572, Accuracy: 0.7978\n","Training loss (for one batch) at step 60: 269.4338, Accuracy: 0.7979\n","Training loss (for one batch) at step 70: 290.9586, Accuracy: 0.7999\n","Training loss (for one batch) at step 80: 286.7905, Accuracy: 0.7962\n","Training loss (for one batch) at step 90: 289.6342, Accuracy: 0.7960\n","Training loss (for one batch) at step 100: 256.5775, Accuracy: 0.7953\n","Training loss (for one batch) at step 110: 277.3252, Accuracy: 0.7961\n","Training loss (for one batch) at step 120: 269.9976, Accuracy: 0.7959\n","Training loss (for one batch) at step 130: 265.6883, Accuracy: 0.7965\n","Training loss (for one batch) at step 140: 273.1998, Accuracy: 0.7963\n","---- Training ----\n","Training loss: 246.7365\n","Training acc over epoch: 0.7960\n","---- Validation ----\n","Validation loss: 71.3381\n","Validation acc: 0.7327\n","Time taken: 67.18s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 274.3946, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 278.1289, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 280.4697, Accuracy: 0.8052\n","Training loss (for one batch) at step 30: 281.5846, Accuracy: 0.8100\n","Training loss (for one batch) at step 40: 255.4583, Accuracy: 0.8071\n","Training loss (for one batch) at step 50: 269.6871, Accuracy: 0.8053\n","Training loss (for one batch) at step 60: 269.4048, Accuracy: 0.8041\n","Training loss (for one batch) at step 70: 285.0975, Accuracy: 0.8004\n","Training loss (for one batch) at step 80: 285.1865, Accuracy: 0.7984\n","Training loss (for one batch) at step 90: 283.6025, Accuracy: 0.7960\n","Training loss (for one batch) at step 100: 273.6462, Accuracy: 0.7955\n","Training loss (for one batch) at step 110: 276.3793, Accuracy: 0.7970\n","Training loss (for one batch) at step 120: 281.1371, Accuracy: 0.7974\n","Training loss (for one batch) at step 130: 285.2191, Accuracy: 0.7975\n","Training loss (for one batch) at step 140: 271.5698, Accuracy: 0.7984\n","---- Training ----\n","Training loss: 234.5247\n","Training acc over epoch: 0.7975\n","---- Validation ----\n","Validation loss: 71.2114\n","Validation acc: 0.7380\n","Time taken: 39.28s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 276.9429, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 276.7552, Accuracy: 0.8018\n","Training loss (for one batch) at step 20: 294.2938, Accuracy: 0.8067\n","Training loss (for one batch) at step 30: 264.8023, Accuracy: 0.8116\n","Training loss (for one batch) at step 40: 289.8555, Accuracy: 0.8098\n","Training loss (for one batch) at step 50: 280.9545, Accuracy: 0.8125\n","Training loss (for one batch) at step 60: 267.7056, Accuracy: 0.8116\n","Training loss (for one batch) at step 70: 277.8397, Accuracy: 0.8100\n","Training loss (for one batch) at step 80: 286.8100, Accuracy: 0.8042\n","Training loss (for one batch) at step 90: 251.4415, Accuracy: 0.8042\n","Training loss (for one batch) at step 100: 268.6334, Accuracy: 0.8048\n","Training loss (for one batch) at step 110: 278.9490, Accuracy: 0.8036\n","Training loss (for one batch) at step 120: 274.5276, Accuracy: 0.8034\n","Training loss (for one batch) at step 130: 269.3804, Accuracy: 0.8034\n","Training loss (for one batch) at step 140: 293.4306, Accuracy: 0.8023\n","---- Training ----\n","Training loss: 247.7811\n","Training acc over epoch: 0.8031\n","---- Validation ----\n","Validation loss: 71.8373\n","Validation acc: 0.7281\n","Time taken: 67.82s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 272.2863, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 263.7847, Accuracy: 0.8182\n","Training loss (for one batch) at step 20: 280.6638, Accuracy: 0.8081\n","Training loss (for one batch) at step 30: 269.1390, Accuracy: 0.8113\n","Training loss (for one batch) at step 40: 252.1497, Accuracy: 0.8120\n","Training loss (for one batch) at step 50: 267.2648, Accuracy: 0.8129\n","Training loss (for one batch) at step 60: 266.2668, Accuracy: 0.8079\n","Training loss (for one batch) at step 70: 268.8604, Accuracy: 0.8055\n","Training loss (for one batch) at step 80: 272.5202, Accuracy: 0.8046\n","Training loss (for one batch) at step 90: 268.9320, Accuracy: 0.8049\n","Training loss (for one batch) at step 100: 265.1130, Accuracy: 0.8023\n","Training loss (for one batch) at step 110: 270.3014, Accuracy: 0.8028\n","Training loss (for one batch) at step 120: 276.8309, Accuracy: 0.8033\n","Training loss (for one batch) at step 130: 284.6234, Accuracy: 0.8034\n","Training loss (for one batch) at step 140: 280.2619, Accuracy: 0.8052\n","---- Training ----\n","Training loss: 231.6023\n","Training acc over epoch: 0.8049\n","---- Validation ----\n","Validation loss: 69.1793\n","Validation acc: 0.7405\n","Time taken: 39.30s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 268.7421, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 279.8432, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 260.8879, Accuracy: 0.8110\n","Training loss (for one batch) at step 30: 266.0927, Accuracy: 0.8139\n","Training loss (for one batch) at step 40: 279.5359, Accuracy: 0.8146\n","Training loss (for one batch) at step 50: 264.3742, Accuracy: 0.8169\n","Training loss (for one batch) at step 60: 264.5847, Accuracy: 0.8172\n","Training loss (for one batch) at step 70: 271.3310, Accuracy: 0.8135\n","Training loss (for one batch) at step 80: 279.0677, Accuracy: 0.8077\n","Training loss (for one batch) at step 90: 289.4846, Accuracy: 0.8086\n","Training loss (for one batch) at step 100: 283.0888, Accuracy: 0.8064\n","Training loss (for one batch) at step 110: 255.7741, Accuracy: 0.8073\n","Training loss (for one batch) at step 120: 251.3377, Accuracy: 0.8063\n","Training loss (for one batch) at step 130: 269.0388, Accuracy: 0.8066\n","Training loss (for one batch) at step 140: 273.2766, Accuracy: 0.8072\n","---- Training ----\n","Training loss: 249.3883\n","Training acc over epoch: 0.8062\n","---- Validation ----\n","Validation loss: 68.2650\n","Validation acc: 0.7423\n","Time taken: 69.16s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 262.3608, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 267.2453, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 275.9139, Accuracy: 0.8276\n","Training loss (for one batch) at step 30: 267.5163, Accuracy: 0.8223\n","Training loss (for one batch) at step 40: 252.0900, Accuracy: 0.8239\n","Training loss (for one batch) at step 50: 276.4173, Accuracy: 0.8235\n","Training loss (for one batch) at step 60: 279.0793, Accuracy: 0.8225\n","Training loss (for one batch) at step 70: 271.0175, Accuracy: 0.8211\n","Training loss (for one batch) at step 80: 289.7311, Accuracy: 0.8173\n","Training loss (for one batch) at step 90: 267.0374, Accuracy: 0.8148\n","Training loss (for one batch) at step 100: 271.7969, Accuracy: 0.8125\n","Training loss (for one batch) at step 110: 260.9313, Accuracy: 0.8110\n","Training loss (for one batch) at step 120: 261.1982, Accuracy: 0.8116\n","Training loss (for one batch) at step 130: 265.5856, Accuracy: 0.8099\n","Training loss (for one batch) at step 140: 269.0215, Accuracy: 0.8089\n","---- Training ----\n","Training loss: 245.0160\n","Training acc over epoch: 0.8093\n","---- Validation ----\n","Validation loss: 64.2289\n","Validation acc: 0.7421\n","Time taken: 40.34s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 273.0718, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 244.1673, Accuracy: 0.8073\n","Training loss (for one batch) at step 20: 259.3272, Accuracy: 0.8124\n","Training loss (for one batch) at step 30: 253.3538, Accuracy: 0.8113\n","Training loss (for one batch) at step 40: 267.5478, Accuracy: 0.8129\n","Training loss (for one batch) at step 50: 243.8898, Accuracy: 0.8198\n","Training loss (for one batch) at step 60: 262.6335, Accuracy: 0.8238\n","Training loss (for one batch) at step 70: 258.3515, Accuracy: 0.8215\n","Training loss (for one batch) at step 80: 265.3261, Accuracy: 0.8190\n","Training loss (for one batch) at step 90: 257.6531, Accuracy: 0.8192\n","Training loss (for one batch) at step 100: 263.3476, Accuracy: 0.8191\n","Training loss (for one batch) at step 110: 246.4431, Accuracy: 0.8176\n","Training loss (for one batch) at step 120: 274.0035, Accuracy: 0.8176\n","Training loss (for one batch) at step 130: 265.0739, Accuracy: 0.8163\n","Training loss (for one batch) at step 140: 274.4476, Accuracy: 0.8178\n","---- Training ----\n","Training loss: 220.1254\n","Training acc over epoch: 0.8167\n","---- Validation ----\n","Validation loss: 66.7004\n","Validation acc: 0.7286\n","Time taken: 67.41s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 257.4083, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 275.4130, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 271.4077, Accuracy: 0.8148\n","Training loss (for one batch) at step 30: 261.8566, Accuracy: 0.8265\n","Training loss (for one batch) at step 40: 241.5290, Accuracy: 0.8178\n","Training loss (for one batch) at step 50: 263.5068, Accuracy: 0.8208\n","Training loss (for one batch) at step 60: 241.3083, Accuracy: 0.8213\n","Training loss (for one batch) at step 70: 255.6885, Accuracy: 0.8177\n","Training loss (for one batch) at step 80: 262.2799, Accuracy: 0.8163\n","Training loss (for one batch) at step 90: 265.9784, Accuracy: 0.8155\n","Training loss (for one batch) at step 100: 263.2055, Accuracy: 0.8149\n","Training loss (for one batch) at step 110: 262.9856, Accuracy: 0.8157\n","Training loss (for one batch) at step 120: 254.1056, Accuracy: 0.8175\n","Training loss (for one batch) at step 130: 274.9526, Accuracy: 0.8164\n","Training loss (for one batch) at step 140: 266.5182, Accuracy: 0.8160\n","---- Training ----\n","Training loss: 233.3312\n","Training acc over epoch: 0.8145\n","---- Validation ----\n","Validation loss: 63.3822\n","Validation acc: 0.7340\n","Time taken: 39.84s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 254.2055, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 247.4862, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 255.9895, Accuracy: 0.8219\n","Training loss (for one batch) at step 30: 260.7684, Accuracy: 0.8171\n","Training loss (for one batch) at step 40: 267.2823, Accuracy: 0.8185\n","Training loss (for one batch) at step 50: 242.2910, Accuracy: 0.8218\n","Training loss (for one batch) at step 60: 249.2315, Accuracy: 0.8189\n","Training loss (for one batch) at step 70: 258.3653, Accuracy: 0.8190\n","Training loss (for one batch) at step 80: 249.1047, Accuracy: 0.8142\n","Training loss (for one batch) at step 90: 249.5768, Accuracy: 0.8133\n","Training loss (for one batch) at step 100: 254.9669, Accuracy: 0.8129\n","Training loss (for one batch) at step 110: 261.9439, Accuracy: 0.8123\n","Training loss (for one batch) at step 120: 251.5510, Accuracy: 0.8139\n","Training loss (for one batch) at step 130: 259.7151, Accuracy: 0.8135\n","Training loss (for one batch) at step 140: 244.7859, Accuracy: 0.8135\n","---- Training ----\n","Training loss: 244.8899\n","Training acc over epoch: 0.8131\n","---- Validation ----\n","Validation loss: 67.6783\n","Validation acc: 0.7402\n","Time taken: 66.52s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 271.7541, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 250.2131, Accuracy: 0.8100\n","Training loss (for one batch) at step 20: 269.1364, Accuracy: 0.8152\n","Training loss (for one batch) at step 30: 250.2654, Accuracy: 0.8177\n","Training loss (for one batch) at step 40: 255.4646, Accuracy: 0.8215\n","Training loss (for one batch) at step 50: 239.5324, Accuracy: 0.8278\n","Training loss (for one batch) at step 60: 238.1224, Accuracy: 0.8277\n","Training loss (for one batch) at step 70: 272.1417, Accuracy: 0.8256\n","Training loss (for one batch) at step 80: 285.5933, Accuracy: 0.8230\n","Training loss (for one batch) at step 90: 264.5500, Accuracy: 0.8211\n","Training loss (for one batch) at step 100: 251.5467, Accuracy: 0.8206\n","Training loss (for one batch) at step 110: 273.7039, Accuracy: 0.8205\n","Training loss (for one batch) at step 120: 267.1697, Accuracy: 0.8201\n","Training loss (for one batch) at step 130: 252.5623, Accuracy: 0.8205\n","Training loss (for one batch) at step 140: 243.4520, Accuracy: 0.8207\n","---- Training ----\n","Training loss: 226.5033\n","Training acc over epoch: 0.8202\n","---- Validation ----\n","Validation loss: 77.5648\n","Validation acc: 0.7082\n","Time taken: 38.66s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 257.2159, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 252.5316, Accuracy: 0.8245\n","Training loss (for one batch) at step 20: 230.7280, Accuracy: 0.8233\n","Training loss (for one batch) at step 30: 248.6595, Accuracy: 0.8252\n","Training loss (for one batch) at step 40: 238.3183, Accuracy: 0.8212\n","Training loss (for one batch) at step 50: 242.4891, Accuracy: 0.8247\n","Training loss (for one batch) at step 60: 245.5096, Accuracy: 0.8254\n","Training loss (for one batch) at step 70: 254.9247, Accuracy: 0.8245\n","Training loss (for one batch) at step 80: 237.3269, Accuracy: 0.8217\n","Training loss (for one batch) at step 90: 257.7325, Accuracy: 0.8202\n","Training loss (for one batch) at step 100: 253.9294, Accuracy: 0.8179\n","Training loss (for one batch) at step 110: 230.6475, Accuracy: 0.8197\n","Training loss (for one batch) at step 120: 252.7300, Accuracy: 0.8196\n","Training loss (for one batch) at step 130: 251.4202, Accuracy: 0.8191\n","Training loss (for one batch) at step 140: 238.5717, Accuracy: 0.8190\n","---- Training ----\n","Training loss: 210.5622\n","Training acc over epoch: 0.8195\n","---- Validation ----\n","Validation loss: 68.6347\n","Validation acc: 0.7286\n","Time taken: 66.17s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 251.4485, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 262.4686, Accuracy: 0.8309\n","Training loss (for one batch) at step 20: 242.3026, Accuracy: 0.8224\n","Training loss (for one batch) at step 30: 255.3805, Accuracy: 0.8229\n","Training loss (for one batch) at step 40: 237.1309, Accuracy: 0.8278\n","Training loss (for one batch) at step 50: 238.7290, Accuracy: 0.8308\n","Training loss (for one batch) at step 60: 257.7961, Accuracy: 0.8303\n","Training loss (for one batch) at step 70: 245.1685, Accuracy: 0.8301\n","Training loss (for one batch) at step 80: 232.4911, Accuracy: 0.8275\n","Training loss (for one batch) at step 90: 246.3766, Accuracy: 0.8257\n","Training loss (for one batch) at step 100: 232.2862, Accuracy: 0.8247\n","Training loss (for one batch) at step 110: 267.6193, Accuracy: 0.8241\n","Training loss (for one batch) at step 120: 249.8596, Accuracy: 0.8239\n","Training loss (for one batch) at step 130: 244.6400, Accuracy: 0.8234\n","Training loss (for one batch) at step 140: 246.4631, Accuracy: 0.8247\n","---- Training ----\n","Training loss: 233.5717\n","Training acc over epoch: 0.8246\n","---- Validation ----\n","Validation loss: 77.0562\n","Validation acc: 0.7278\n","Time taken: 37.80s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 241.8055, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 236.7795, Accuracy: 0.8391\n","Training loss (for one batch) at step 20: 250.2951, Accuracy: 0.8281\n","Training loss (for one batch) at step 30: 246.6147, Accuracy: 0.8352\n","Training loss (for one batch) at step 40: 229.5624, Accuracy: 0.8327\n","Training loss (for one batch) at step 50: 242.7495, Accuracy: 0.8345\n","Training loss (for one batch) at step 60: 228.4476, Accuracy: 0.8367\n","Training loss (for one batch) at step 70: 250.2468, Accuracy: 0.8342\n","Training loss (for one batch) at step 80: 222.4829, Accuracy: 0.8322\n","Training loss (for one batch) at step 90: 253.5771, Accuracy: 0.8300\n","Training loss (for one batch) at step 100: 237.4852, Accuracy: 0.8299\n","Training loss (for one batch) at step 110: 251.9977, Accuracy: 0.8305\n","Training loss (for one batch) at step 120: 247.5957, Accuracy: 0.8291\n","Training loss (for one batch) at step 130: 254.8130, Accuracy: 0.8282\n","Training loss (for one batch) at step 140: 255.3269, Accuracy: 0.8285\n","---- Training ----\n","Training loss: 225.3828\n","Training acc over epoch: 0.8291\n","---- Validation ----\n","Validation loss: 77.9171\n","Validation acc: 0.7225\n","Time taken: 66.16s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 248.6280, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 237.9588, Accuracy: 0.8409\n","Training loss (for one batch) at step 20: 240.9394, Accuracy: 0.8300\n","Training loss (for one batch) at step 30: 233.1646, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 243.2694, Accuracy: 0.8293\n","Training loss (for one batch) at step 50: 234.6088, Accuracy: 0.8304\n","Training loss (for one batch) at step 60: 249.5234, Accuracy: 0.8290\n","Training loss (for one batch) at step 70: 270.0999, Accuracy: 0.8259\n","Training loss (for one batch) at step 80: 237.4460, Accuracy: 0.8265\n","Training loss (for one batch) at step 90: 242.5996, Accuracy: 0.8255\n","Training loss (for one batch) at step 100: 232.5282, Accuracy: 0.8251\n","Training loss (for one batch) at step 110: 227.0333, Accuracy: 0.8250\n","Training loss (for one batch) at step 120: 238.8944, Accuracy: 0.8267\n","Training loss (for one batch) at step 130: 238.5324, Accuracy: 0.8266\n","Training loss (for one batch) at step 140: 244.7831, Accuracy: 0.8257\n","---- Training ----\n","Training loss: 210.1142\n","Training acc over epoch: 0.8262\n","---- Validation ----\n","Validation loss: 69.6281\n","Validation acc: 0.7340\n","Time taken: 38.25s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 233.6135, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 233.8873, Accuracy: 0.8173\n","Training loss (for one batch) at step 20: 240.2188, Accuracy: 0.8238\n","Training loss (for one batch) at step 30: 240.7806, Accuracy: 0.8265\n","Training loss (for one batch) at step 40: 223.9757, Accuracy: 0.8283\n","Training loss (for one batch) at step 50: 230.0146, Accuracy: 0.8327\n","Training loss (for one batch) at step 60: 219.8729, Accuracy: 0.8344\n","Training loss (for one batch) at step 70: 224.4239, Accuracy: 0.8339\n","Training loss (for one batch) at step 80: 244.8968, Accuracy: 0.8340\n","Training loss (for one batch) at step 90: 259.6616, Accuracy: 0.8308\n","Training loss (for one batch) at step 100: 246.4970, Accuracy: 0.8285\n","Training loss (for one batch) at step 110: 247.7748, Accuracy: 0.8295\n","Training loss (for one batch) at step 120: 240.6470, Accuracy: 0.8318\n","Training loss (for one batch) at step 130: 262.2714, Accuracy: 0.8318\n","Training loss (for one batch) at step 140: 246.1143, Accuracy: 0.8319\n","---- Training ----\n","Training loss: 207.9803\n","Training acc over epoch: 0.8336\n","---- Validation ----\n","Validation loss: 67.8286\n","Validation acc: 0.7276\n","Time taken: 66.41s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 241.2563, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 240.9076, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 254.9875, Accuracy: 0.8195\n","Training loss (for one batch) at step 30: 246.0640, Accuracy: 0.8255\n","Training loss (for one batch) at step 40: 252.9467, Accuracy: 0.8283\n","Training loss (for one batch) at step 50: 242.9528, Accuracy: 0.8343\n","Training loss (for one batch) at step 60: 239.5927, Accuracy: 0.8351\n","Training loss (for one batch) at step 70: 235.7014, Accuracy: 0.8338\n","Training loss (for one batch) at step 80: 256.6302, Accuracy: 0.8314\n","Training loss (for one batch) at step 90: 256.1144, Accuracy: 0.8301\n","Training loss (for one batch) at step 100: 229.5471, Accuracy: 0.8302\n","Training loss (for one batch) at step 110: 230.6715, Accuracy: 0.8305\n","Training loss (for one batch) at step 120: 237.2350, Accuracy: 0.8318\n","Training loss (for one batch) at step 130: 257.2697, Accuracy: 0.8324\n","Training loss (for one batch) at step 140: 230.1773, Accuracy: 0.8326\n","---- Training ----\n","Training loss: 192.6903\n","Training acc over epoch: 0.8319\n","---- Validation ----\n","Validation loss: 63.3008\n","Validation acc: 0.7225\n","Time taken: 39.03s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 232.2381, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 239.3753, Accuracy: 0.8382\n","Training loss (for one batch) at step 20: 238.6921, Accuracy: 0.8419\n","Training loss (for one batch) at step 30: 241.6314, Accuracy: 0.8390\n","Training loss (for one batch) at step 40: 242.8974, Accuracy: 0.8390\n","Training loss (for one batch) at step 50: 242.6385, Accuracy: 0.8412\n","Training loss (for one batch) at step 60: 245.8264, Accuracy: 0.8411\n","Training loss (for one batch) at step 70: 221.6444, Accuracy: 0.8399\n","Training loss (for one batch) at step 80: 241.2882, Accuracy: 0.8375\n","Training loss (for one batch) at step 90: 232.6875, Accuracy: 0.8352\n","Training loss (for one batch) at step 100: 238.3613, Accuracy: 0.8343\n","Training loss (for one batch) at step 110: 248.7412, Accuracy: 0.8366\n","Training loss (for one batch) at step 120: 234.3875, Accuracy: 0.8347\n","Training loss (for one batch) at step 130: 261.5870, Accuracy: 0.8340\n","Training loss (for one batch) at step 140: 238.9021, Accuracy: 0.8324\n","---- Training ----\n","Training loss: 235.2799\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 75.8381\n","Validation acc: 0.7485\n","Time taken: 73.74s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 248.4104, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 253.4173, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 247.0567, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 238.4016, Accuracy: 0.8335\n","Training loss (for one batch) at step 40: 216.2316, Accuracy: 0.8341\n","Training loss (for one batch) at step 50: 224.9815, Accuracy: 0.8396\n","Training loss (for one batch) at step 60: 243.2229, Accuracy: 0.8402\n","Training loss (for one batch) at step 70: 227.6909, Accuracy: 0.8377\n","Training loss (for one batch) at step 80: 237.3974, Accuracy: 0.8373\n","Training loss (for one batch) at step 90: 244.4578, Accuracy: 0.8374\n","Training loss (for one batch) at step 100: 234.5686, Accuracy: 0.8346\n","Training loss (for one batch) at step 110: 227.9779, Accuracy: 0.8366\n","Training loss (for one batch) at step 120: 244.4337, Accuracy: 0.8367\n","Training loss (for one batch) at step 130: 224.9476, Accuracy: 0.8362\n","Training loss (for one batch) at step 140: 255.3190, Accuracy: 0.8370\n","---- Training ----\n","Training loss: 211.1508\n","Training acc over epoch: 0.8365\n","---- Validation ----\n","Validation loss: 77.4379\n","Validation acc: 0.7190\n","Time taken: 38.40s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 233.1902, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 246.9863, Accuracy: 0.8400\n","Training loss (for one batch) at step 20: 251.7082, Accuracy: 0.8333\n","Training loss (for one batch) at step 30: 228.3527, Accuracy: 0.8313\n","Training loss (for one batch) at step 40: 221.5476, Accuracy: 0.8310\n","Training loss (for one batch) at step 50: 226.1902, Accuracy: 0.8351\n","Training loss (for one batch) at step 60: 225.6232, Accuracy: 0.8354\n","Training loss (for one batch) at step 70: 212.3603, Accuracy: 0.8345\n","Training loss (for one batch) at step 80: 232.3126, Accuracy: 0.8311\n","Training loss (for one batch) at step 90: 222.8756, Accuracy: 0.8319\n","Training loss (for one batch) at step 100: 234.7067, Accuracy: 0.8310\n","Training loss (for one batch) at step 110: 228.3782, Accuracy: 0.8316\n","Training loss (for one batch) at step 120: 223.0344, Accuracy: 0.8330\n","Training loss (for one batch) at step 130: 236.8021, Accuracy: 0.8321\n","Training loss (for one batch) at step 140: 270.8794, Accuracy: 0.8331\n","---- Training ----\n","Training loss: 213.0676\n","Training acc over epoch: 0.8322\n","---- Validation ----\n","Validation loss: 56.4675\n","Validation acc: 0.7238\n","Time taken: 66.45s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 247.4802, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 218.9325, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 218.0782, Accuracy: 0.8295\n","Training loss (for one batch) at step 30: 210.6562, Accuracy: 0.8342\n","Training loss (for one batch) at step 40: 220.0275, Accuracy: 0.8434\n","Training loss (for one batch) at step 50: 223.3390, Accuracy: 0.8449\n","Training loss (for one batch) at step 60: 234.4108, Accuracy: 0.8462\n","Training loss (for one batch) at step 70: 211.9288, Accuracy: 0.8446\n","Training loss (for one batch) at step 80: 239.6106, Accuracy: 0.8401\n","Training loss (for one batch) at step 90: 238.7744, Accuracy: 0.8377\n","Training loss (for one batch) at step 100: 226.8386, Accuracy: 0.8374\n","Training loss (for one batch) at step 110: 222.4343, Accuracy: 0.8390\n","Training loss (for one batch) at step 120: 235.5725, Accuracy: 0.8394\n","Training loss (for one batch) at step 130: 228.8778, Accuracy: 0.8392\n","Training loss (for one batch) at step 140: 225.0631, Accuracy: 0.8394\n","---- Training ----\n","Training loss: 214.2887\n","Training acc over epoch: 0.8395\n","---- Validation ----\n","Validation loss: 71.4977\n","Validation acc: 0.7286\n","Time taken: 38.68s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 224.3214, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 222.0542, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 215.8426, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 237.9241, Accuracy: 0.8413\n","Training loss (for one batch) at step 40: 202.2120, Accuracy: 0.8429\n","Training loss (for one batch) at step 50: 263.9170, Accuracy: 0.8410\n","Training loss (for one batch) at step 60: 220.6350, Accuracy: 0.8402\n","Training loss (for one batch) at step 70: 214.9335, Accuracy: 0.8408\n","Training loss (for one batch) at step 80: 228.2008, Accuracy: 0.8401\n","Training loss (for one batch) at step 90: 220.2791, Accuracy: 0.8385\n","Training loss (for one batch) at step 100: 232.5062, Accuracy: 0.8364\n","Training loss (for one batch) at step 110: 236.0719, Accuracy: 0.8369\n","Training loss (for one batch) at step 120: 226.4164, Accuracy: 0.8387\n","Training loss (for one batch) at step 130: 240.0429, Accuracy: 0.8377\n","Training loss (for one batch) at step 140: 234.6554, Accuracy: 0.8390\n","---- Training ----\n","Training loss: 197.9826\n","Training acc over epoch: 0.8385\n","---- Validation ----\n","Validation loss: 63.7251\n","Validation acc: 0.7276\n","Time taken: 71.50s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 238.2913, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 224.3347, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 203.8954, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 222.8010, Accuracy: 0.8445\n","Training loss (for one batch) at step 40: 223.6740, Accuracy: 0.8451\n","Training loss (for one batch) at step 50: 243.3969, Accuracy: 0.8473\n","Training loss (for one batch) at step 60: 243.6061, Accuracy: 0.8464\n","Training loss (for one batch) at step 70: 215.6344, Accuracy: 0.8459\n","Training loss (for one batch) at step 80: 225.6990, Accuracy: 0.8425\n","Training loss (for one batch) at step 90: 245.5683, Accuracy: 0.8423\n","Training loss (for one batch) at step 100: 225.5854, Accuracy: 0.8419\n","Training loss (for one batch) at step 110: 217.6298, Accuracy: 0.8434\n","Training loss (for one batch) at step 120: 227.2699, Accuracy: 0.8435\n","Training loss (for one batch) at step 130: 235.5796, Accuracy: 0.8440\n","Training loss (for one batch) at step 140: 209.1396, Accuracy: 0.8429\n","---- Training ----\n","Training loss: 203.7095\n","Training acc over epoch: 0.8431\n","---- Validation ----\n","Validation loss: 61.8124\n","Validation acc: 0.7329\n","Time taken: 39.98s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 215.1196, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 198.2802, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 225.3797, Accuracy: 0.8252\n","Training loss (for one batch) at step 30: 217.7483, Accuracy: 0.8342\n","Training loss (for one batch) at step 40: 239.9542, Accuracy: 0.8383\n","Training loss (for one batch) at step 50: 210.3000, Accuracy: 0.8427\n","Training loss (for one batch) at step 60: 233.6455, Accuracy: 0.8431\n","Training loss (for one batch) at step 70: 236.0225, Accuracy: 0.8414\n","Training loss (for one batch) at step 80: 212.6491, Accuracy: 0.8396\n","Training loss (for one batch) at step 90: 229.1385, Accuracy: 0.8368\n","Training loss (for one batch) at step 100: 225.1716, Accuracy: 0.8358\n","Training loss (for one batch) at step 110: 220.5824, Accuracy: 0.8377\n","Training loss (for one batch) at step 120: 235.9718, Accuracy: 0.8381\n","Training loss (for one batch) at step 130: 222.7420, Accuracy: 0.8369\n","Training loss (for one batch) at step 140: 239.5012, Accuracy: 0.8384\n","---- Training ----\n","Training loss: 220.2077\n","Training acc over epoch: 0.8377\n","---- Validation ----\n","Validation loss: 79.4969\n","Validation acc: 0.7329\n","Time taken: 70.09s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 216.5461, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 217.5700, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 236.8207, Accuracy: 0.8514\n","Training loss (for one batch) at step 30: 213.5869, Accuracy: 0.8474\n","Training loss (for one batch) at step 40: 221.4973, Accuracy: 0.8515\n","Training loss (for one batch) at step 50: 224.2252, Accuracy: 0.8547\n","Training loss (for one batch) at step 60: 225.5640, Accuracy: 0.8548\n","Training loss (for one batch) at step 70: 224.0919, Accuracy: 0.8521\n","Training loss (for one batch) at step 80: 234.3618, Accuracy: 0.8501\n","Training loss (for one batch) at step 90: 223.9925, Accuracy: 0.8493\n","Training loss (for one batch) at step 100: 220.8312, Accuracy: 0.8503\n","Training loss (for one batch) at step 110: 212.5044, Accuracy: 0.8485\n","Training loss (for one batch) at step 120: 234.4184, Accuracy: 0.8492\n","Training loss (for one batch) at step 130: 205.7584, Accuracy: 0.8490\n","Training loss (for one batch) at step 140: 249.1141, Accuracy: 0.8462\n","---- Training ----\n","Training loss: 203.4588\n","Training acc over epoch: 0.8459\n","---- Validation ----\n","Validation loss: 68.3646\n","Validation acc: 0.7273\n","Time taken: 40.03s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 207.0736, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 214.0502, Accuracy: 0.8591\n","Training loss (for one batch) at step 20: 210.8700, Accuracy: 0.8614\n","Training loss (for one batch) at step 30: 235.9331, Accuracy: 0.8535\n","Training loss (for one batch) at step 40: 207.5699, Accuracy: 0.8517\n","Training loss (for one batch) at step 50: 238.5863, Accuracy: 0.8508\n","Training loss (for one batch) at step 60: 243.9941, Accuracy: 0.8503\n","Training loss (for one batch) at step 70: 211.1517, Accuracy: 0.8458\n","Training loss (for one batch) at step 80: 240.7458, Accuracy: 0.8423\n","Training loss (for one batch) at step 90: 222.4530, Accuracy: 0.8431\n","Training loss (for one batch) at step 100: 237.1585, Accuracy: 0.8437\n","Training loss (for one batch) at step 110: 216.8531, Accuracy: 0.8438\n","Training loss (for one batch) at step 120: 210.6289, Accuracy: 0.8437\n","Training loss (for one batch) at step 130: 213.6298, Accuracy: 0.8440\n","Training loss (for one batch) at step 140: 238.6382, Accuracy: 0.8440\n","---- Training ----\n","Training loss: 200.5159\n","Training acc over epoch: 0.8430\n","---- Validation ----\n","Validation loss: 84.7053\n","Validation acc: 0.7319\n","Time taken: 69.85s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 207.8313, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 236.1079, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 204.2724, Accuracy: 0.8581\n","Training loss (for one batch) at step 30: 212.2942, Accuracy: 0.8558\n","Training loss (for one batch) at step 40: 211.1664, Accuracy: 0.8541\n","Training loss (for one batch) at step 50: 216.6557, Accuracy: 0.8531\n","Training loss (for one batch) at step 60: 225.1491, Accuracy: 0.8525\n","Training loss (for one batch) at step 70: 225.2661, Accuracy: 0.8542\n","Training loss (for one batch) at step 80: 220.9398, Accuracy: 0.8517\n","Training loss (for one batch) at step 90: 238.8253, Accuracy: 0.8504\n","Training loss (for one batch) at step 100: 244.8823, Accuracy: 0.8493\n","Training loss (for one batch) at step 110: 207.8640, Accuracy: 0.8487\n","Training loss (for one batch) at step 120: 211.6888, Accuracy: 0.8492\n","Training loss (for one batch) at step 130: 224.4673, Accuracy: 0.8482\n","Training loss (for one batch) at step 140: 228.4979, Accuracy: 0.8483\n","---- Training ----\n","Training loss: 179.6018\n","Training acc over epoch: 0.8483\n","---- Validation ----\n","Validation loss: 74.0037\n","Validation acc: 0.7155\n","Time taken: 40.68s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 221.7879, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 221.4762, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 217.2875, Accuracy: 0.8457\n","Training loss (for one batch) at step 30: 245.0501, Accuracy: 0.8487\n","Training loss (for one batch) at step 40: 213.3032, Accuracy: 0.8522\n","Training loss (for one batch) at step 50: 202.1278, Accuracy: 0.8549\n","Training loss (for one batch) at step 60: 218.2595, Accuracy: 0.8526\n","Training loss (for one batch) at step 70: 220.5493, Accuracy: 0.8487\n","Training loss (for one batch) at step 80: 231.2080, Accuracy: 0.8480\n","Training loss (for one batch) at step 90: 225.4845, Accuracy: 0.8464\n","Training loss (for one batch) at step 100: 197.8558, Accuracy: 0.8458\n","Training loss (for one batch) at step 110: 236.8451, Accuracy: 0.8467\n","Training loss (for one batch) at step 120: 220.1480, Accuracy: 0.8467\n","Training loss (for one batch) at step 130: 211.5138, Accuracy: 0.8469\n","Training loss (for one batch) at step 140: 231.1666, Accuracy: 0.8464\n","---- Training ----\n","Training loss: 201.4454\n","Training acc over epoch: 0.8470\n","---- Validation ----\n","Validation loss: 81.4464\n","Validation acc: 0.7437\n","Time taken: 71.35s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 194.5206, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 224.5829, Accuracy: 0.8491\n","Training loss (for one batch) at step 20: 215.9561, Accuracy: 0.8443\n","Training loss (for one batch) at step 30: 198.9930, Accuracy: 0.8390\n","Training loss (for one batch) at step 40: 197.3947, Accuracy: 0.8422\n","Training loss (for one batch) at step 50: 229.8982, Accuracy: 0.8445\n","Training loss (for one batch) at step 60: 186.8010, Accuracy: 0.8462\n","Training loss (for one batch) at step 70: 199.8136, Accuracy: 0.8432\n","Training loss (for one batch) at step 80: 212.4547, Accuracy: 0.8441\n","Training loss (for one batch) at step 90: 216.2263, Accuracy: 0.8429\n","Training loss (for one batch) at step 100: 205.6213, Accuracy: 0.8432\n","Training loss (for one batch) at step 110: 224.1265, Accuracy: 0.8440\n","Training loss (for one batch) at step 120: 214.5001, Accuracy: 0.8452\n","Training loss (for one batch) at step 130: 220.8449, Accuracy: 0.8446\n","Training loss (for one batch) at step 140: 223.0911, Accuracy: 0.8441\n","---- Training ----\n","Training loss: 184.6183\n","Training acc over epoch: 0.8448\n","---- Validation ----\n","Validation loss: 77.2103\n","Validation acc: 0.7356\n","Time taken: 41.75s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 214.0957, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 240.9085, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 212.6217, Accuracy: 0.8476\n","Training loss (for one batch) at step 30: 236.5129, Accuracy: 0.8477\n","Training loss (for one batch) at step 40: 199.8845, Accuracy: 0.8520\n","Training loss (for one batch) at step 50: 212.4296, Accuracy: 0.8518\n","Training loss (for one batch) at step 60: 226.4954, Accuracy: 0.8538\n","Training loss (for one batch) at step 70: 219.4652, Accuracy: 0.8524\n","Training loss (for one batch) at step 80: 251.5585, Accuracy: 0.8510\n","Training loss (for one batch) at step 90: 228.5986, Accuracy: 0.8498\n","Training loss (for one batch) at step 100: 237.5534, Accuracy: 0.8472\n","Training loss (for one batch) at step 110: 202.6739, Accuracy: 0.8486\n","Training loss (for one batch) at step 120: 222.9687, Accuracy: 0.8499\n","Training loss (for one batch) at step 130: 188.5314, Accuracy: 0.8494\n","Training loss (for one batch) at step 140: 221.6092, Accuracy: 0.8491\n","---- Training ----\n","Training loss: 195.2994\n","Training acc over epoch: 0.8499\n","---- Validation ----\n","Validation loss: 90.1100\n","Validation acc: 0.7351\n","Time taken: 67.99s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 219.2766, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 212.6325, Accuracy: 0.8500\n","Training loss (for one batch) at step 20: 204.4203, Accuracy: 0.8514\n","Training loss (for one batch) at step 30: 213.6050, Accuracy: 0.8487\n","Training loss (for one batch) at step 40: 209.1707, Accuracy: 0.8532\n","Training loss (for one batch) at step 50: 206.0803, Accuracy: 0.8561\n","Training loss (for one batch) at step 60: 213.8869, Accuracy: 0.8561\n","Training loss (for one batch) at step 70: 188.3012, Accuracy: 0.8569\n","Training loss (for one batch) at step 80: 217.0327, Accuracy: 0.8538\n","Training loss (for one batch) at step 90: 228.1745, Accuracy: 0.8531\n","Training loss (for one batch) at step 100: 207.0130, Accuracy: 0.8513\n","Training loss (for one batch) at step 110: 233.9702, Accuracy: 0.8523\n","Training loss (for one batch) at step 120: 217.2225, Accuracy: 0.8525\n","Training loss (for one batch) at step 130: 226.7958, Accuracy: 0.8525\n","Training loss (for one batch) at step 140: 205.3326, Accuracy: 0.8514\n","---- Training ----\n","Training loss: 193.7800\n","Training acc over epoch: 0.8518\n","---- Validation ----\n","Validation loss: 84.7421\n","Validation acc: 0.7372\n","Time taken: 39.09s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 204.7727, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 194.8137, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 196.2810, Accuracy: 0.8462\n","Training loss (for one batch) at step 30: 201.8774, Accuracy: 0.8465\n","Training loss (for one batch) at step 40: 216.2102, Accuracy: 0.8488\n","Training loss (for one batch) at step 50: 209.0035, Accuracy: 0.8563\n","Training loss (for one batch) at step 60: 217.0860, Accuracy: 0.8539\n","Training loss (for one batch) at step 70: 240.4558, Accuracy: 0.8537\n","Training loss (for one batch) at step 80: 224.0364, Accuracy: 0.8491\n","Training loss (for one batch) at step 90: 235.5498, Accuracy: 0.8498\n","Training loss (for one batch) at step 100: 204.9197, Accuracy: 0.8494\n","Training loss (for one batch) at step 110: 206.5943, Accuracy: 0.8513\n","Training loss (for one batch) at step 120: 235.6870, Accuracy: 0.8507\n","Training loss (for one batch) at step 130: 219.3824, Accuracy: 0.8505\n","Training loss (for one batch) at step 140: 206.5710, Accuracy: 0.8505\n","---- Training ----\n","Training loss: 186.8335\n","Training acc over epoch: 0.8504\n","---- Validation ----\n","Validation loss: 68.8416\n","Validation acc: 0.7327\n","Time taken: 69.10s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 197.0962, Accuracy: 0.8900\n","Training loss (for one batch) at step 10: 214.1809, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 215.9879, Accuracy: 0.8486\n","Training loss (for one batch) at step 30: 193.4881, Accuracy: 0.8465\n","Training loss (for one batch) at step 40: 194.3926, Accuracy: 0.8488\n","Training loss (for one batch) at step 50: 211.4341, Accuracy: 0.8545\n","Training loss (for one batch) at step 60: 206.2711, Accuracy: 0.8564\n","Training loss (for one batch) at step 70: 226.2395, Accuracy: 0.8559\n","Training loss (for one batch) at step 80: 221.5688, Accuracy: 0.8532\n","Training loss (for one batch) at step 90: 202.2805, Accuracy: 0.8534\n","Training loss (for one batch) at step 100: 219.2630, Accuracy: 0.8532\n","Training loss (for one batch) at step 110: 200.3749, Accuracy: 0.8528\n","Training loss (for one batch) at step 120: 200.5491, Accuracy: 0.8535\n","Training loss (for one batch) at step 130: 208.0553, Accuracy: 0.8535\n","Training loss (for one batch) at step 140: 204.2602, Accuracy: 0.8529\n","---- Training ----\n","Training loss: 169.6255\n","Training acc over epoch: 0.8528\n","---- Validation ----\n","Validation loss: 84.4762\n","Validation acc: 0.7337\n","Time taken: 40.12s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 199.8466, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 205.3529, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 214.1979, Accuracy: 0.8481\n","Training loss (for one batch) at step 30: 206.1032, Accuracy: 0.8513\n","Training loss (for one batch) at step 40: 201.5154, Accuracy: 0.8551\n","Training loss (for one batch) at step 50: 200.6290, Accuracy: 0.8571\n","Training loss (for one batch) at step 60: 206.0937, Accuracy: 0.8569\n","Training loss (for one batch) at step 70: 198.7331, Accuracy: 0.8563\n","Training loss (for one batch) at step 80: 203.3989, Accuracy: 0.8517\n","Training loss (for one batch) at step 90: 223.7517, Accuracy: 0.8507\n","Training loss (for one batch) at step 100: 214.3686, Accuracy: 0.8515\n","Training loss (for one batch) at step 110: 202.7460, Accuracy: 0.8518\n","Training loss (for one batch) at step 120: 197.4067, Accuracy: 0.8515\n","Training loss (for one batch) at step 130: 218.1138, Accuracy: 0.8525\n","Training loss (for one batch) at step 140: 197.6913, Accuracy: 0.8524\n","---- Training ----\n","Training loss: 183.0899\n","Training acc over epoch: 0.8518\n","---- Validation ----\n","Validation loss: 80.1335\n","Validation acc: 0.7394\n","Time taken: 67.78s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 202.8529, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 243.1760, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 209.5426, Accuracy: 0.8557\n","Training loss (for one batch) at step 30: 198.4198, Accuracy: 0.8516\n","Training loss (for one batch) at step 40: 225.9464, Accuracy: 0.8559\n","Training loss (for one batch) at step 50: 184.5410, Accuracy: 0.8582\n","Training loss (for one batch) at step 60: 198.5051, Accuracy: 0.8551\n","Training loss (for one batch) at step 70: 199.0852, Accuracy: 0.8530\n","Training loss (for one batch) at step 80: 204.0543, Accuracy: 0.8525\n","Training loss (for one batch) at step 90: 217.9881, Accuracy: 0.8527\n","Training loss (for one batch) at step 100: 215.2215, Accuracy: 0.8511\n","Training loss (for one batch) at step 110: 191.7576, Accuracy: 0.8526\n","Training loss (for one batch) at step 120: 224.1674, Accuracy: 0.8517\n","Training loss (for one batch) at step 130: 208.4098, Accuracy: 0.8518\n","Training loss (for one batch) at step 140: 199.1145, Accuracy: 0.8521\n","---- Training ----\n","Training loss: 181.0873\n","Training acc over epoch: 0.8523\n","---- Validation ----\n","Validation loss: 126.0566\n","Validation acc: 0.7294\n","Time taken: 39.32s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7405\n","Validation AUC: 0.7375\n","Validation Balanced_ACC: 0.4771\n","Validation MI: 0.1371\n","Validation Normalized MI: 0.2055\n","Validation Adjusted MI: 0.2055\n","Validation aUc_Sklearn: 0.8306\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 527.5986, Accuracy: 0.4500\n","Training loss (for one batch) at step 10: 484.1193, Accuracy: 0.5245\n","Training loss (for one batch) at step 20: 423.7532, Accuracy: 0.5390\n","Training loss (for one batch) at step 30: 473.1334, Accuracy: 0.5374\n","Training loss (for one batch) at step 40: 439.4325, Accuracy: 0.5417\n","Training loss (for one batch) at step 50: 413.2783, Accuracy: 0.5516\n","Training loss (for one batch) at step 60: 461.4584, Accuracy: 0.5533\n","Training loss (for one batch) at step 70: 454.9706, Accuracy: 0.5532\n","Training loss (for one batch) at step 80: 437.4577, Accuracy: 0.5530\n","Training loss (for one batch) at step 90: 438.3748, Accuracy: 0.5577\n","Training loss (for one batch) at step 100: 424.0384, Accuracy: 0.5617\n","Training loss (for one batch) at step 110: 457.6732, Accuracy: 0.5630\n","Training loss (for one batch) at step 120: 480.1002, Accuracy: 0.5647\n","Training loss (for one batch) at step 130: 398.5197, Accuracy: 0.5636\n","Training loss (for one batch) at step 140: 432.7971, Accuracy: 0.5642\n","---- Training ----\n","Training loss: 375.6224\n","Training acc over epoch: 0.5666\n","---- Validation ----\n","Validation loss: 91.1115\n","Validation acc: 0.5134\n","Time taken: 73.22s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 413.8096, Accuracy: 0.5700\n","Training loss (for one batch) at step 10: 422.1463, Accuracy: 0.6336\n","Training loss (for one batch) at step 20: 382.1375, Accuracy: 0.6271\n","Training loss (for one batch) at step 30: 451.0680, Accuracy: 0.6145\n","Training loss (for one batch) at step 40: 395.3322, Accuracy: 0.6122\n","Training loss (for one batch) at step 50: 374.7920, Accuracy: 0.6143\n","Training loss (for one batch) at step 60: 407.3326, Accuracy: 0.6125\n","Training loss (for one batch) at step 70: 404.7450, Accuracy: 0.6128\n","Training loss (for one batch) at step 80: 422.5473, Accuracy: 0.6096\n","Training loss (for one batch) at step 90: 401.6553, Accuracy: 0.6096\n","Training loss (for one batch) at step 100: 403.7165, Accuracy: 0.6102\n","Training loss (for one batch) at step 110: 383.1733, Accuracy: 0.6107\n","Training loss (for one batch) at step 120: 365.2353, Accuracy: 0.6144\n","Training loss (for one batch) at step 130: 405.7834, Accuracy: 0.6135\n","Training loss (for one batch) at step 140: 386.5142, Accuracy: 0.6152\n","---- Training ----\n","Training loss: 329.8106\n","Training acc over epoch: 0.6157\n","---- Validation ----\n","Validation loss: 86.8742\n","Validation acc: 0.5419\n","Time taken: 54.71s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 352.3314, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 399.2194, Accuracy: 0.6418\n","Training loss (for one batch) at step 20: 391.8743, Accuracy: 0.6443\n","Training loss (for one batch) at step 30: 349.3879, Accuracy: 0.6435\n","Training loss (for one batch) at step 40: 372.9807, Accuracy: 0.6415\n","Training loss (for one batch) at step 50: 383.5710, Accuracy: 0.6355\n","Training loss (for one batch) at step 60: 359.5850, Accuracy: 0.6367\n","Training loss (for one batch) at step 70: 368.7337, Accuracy: 0.6369\n","Training loss (for one batch) at step 80: 366.2454, Accuracy: 0.6401\n","Training loss (for one batch) at step 90: 374.5175, Accuracy: 0.6407\n","Training loss (for one batch) at step 100: 368.7094, Accuracy: 0.6396\n","Training loss (for one batch) at step 110: 346.9746, Accuracy: 0.6403\n","Training loss (for one batch) at step 120: 355.5563, Accuracy: 0.6407\n","Training loss (for one batch) at step 130: 353.6960, Accuracy: 0.6397\n","Training loss (for one batch) at step 140: 367.8237, Accuracy: 0.6401\n","---- Training ----\n","Training loss: 312.4849\n","Training acc over epoch: 0.6398\n","---- Validation ----\n","Validation loss: 72.9293\n","Validation acc: 0.6883\n","Time taken: 69.75s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 364.5711, Accuracy: 0.6500\n","Training loss (for one batch) at step 10: 325.1856, Accuracy: 0.6600\n","Training loss (for one batch) at step 20: 369.5432, Accuracy: 0.6438\n","Training loss (for one batch) at step 30: 364.5819, Accuracy: 0.6439\n","Training loss (for one batch) at step 40: 362.9421, Accuracy: 0.6434\n","Training loss (for one batch) at step 50: 373.7325, Accuracy: 0.6459\n","Training loss (for one batch) at step 60: 373.2194, Accuracy: 0.6466\n","Training loss (for one batch) at step 70: 373.3829, Accuracy: 0.6438\n","Training loss (for one batch) at step 80: 354.2503, Accuracy: 0.6463\n","Training loss (for one batch) at step 90: 350.3513, Accuracy: 0.6446\n","Training loss (for one batch) at step 100: 348.6281, Accuracy: 0.6455\n","Training loss (for one batch) at step 110: 349.3692, Accuracy: 0.6452\n","Training loss (for one batch) at step 120: 350.9062, Accuracy: 0.6464\n","Training loss (for one batch) at step 130: 360.9332, Accuracy: 0.6481\n","Training loss (for one batch) at step 140: 360.2079, Accuracy: 0.6495\n","---- Training ----\n","Training loss: 291.6394\n","Training acc over epoch: 0.6500\n","---- Validation ----\n","Validation loss: 71.8143\n","Validation acc: 0.7045\n","Time taken: 42.81s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 337.0139, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 342.7183, Accuracy: 0.6955\n","Training loss (for one batch) at step 20: 344.1118, Accuracy: 0.6733\n","Training loss (for one batch) at step 30: 393.5463, Accuracy: 0.6787\n","Training loss (for one batch) at step 40: 347.4206, Accuracy: 0.6700\n","Training loss (for one batch) at step 50: 345.5345, Accuracy: 0.6678\n","Training loss (for one batch) at step 60: 366.5325, Accuracy: 0.6689\n","Training loss (for one batch) at step 70: 357.7226, Accuracy: 0.6679\n","Training loss (for one batch) at step 80: 345.2705, Accuracy: 0.6693\n","Training loss (for one batch) at step 90: 338.4989, Accuracy: 0.6704\n","Training loss (for one batch) at step 100: 351.0471, Accuracy: 0.6714\n","Training loss (for one batch) at step 110: 350.8172, Accuracy: 0.6715\n","Training loss (for one batch) at step 120: 353.2338, Accuracy: 0.6725\n","Training loss (for one batch) at step 130: 355.8357, Accuracy: 0.6730\n","Training loss (for one batch) at step 140: 347.5988, Accuracy: 0.6713\n","---- Training ----\n","Training loss: 295.2686\n","Training acc over epoch: 0.6722\n","---- Validation ----\n","Validation loss: 68.5381\n","Validation acc: 0.7058\n","Time taken: 69.90s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 343.3817, Accuracy: 0.7000\n","Training loss (for one batch) at step 10: 348.3071, Accuracy: 0.6764\n","Training loss (for one batch) at step 20: 320.7846, Accuracy: 0.6929\n","Training loss (for one batch) at step 30: 307.7726, Accuracy: 0.6958\n","Training loss (for one batch) at step 40: 335.4081, Accuracy: 0.6915\n","Training loss (for one batch) at step 50: 325.5349, Accuracy: 0.6931\n","Training loss (for one batch) at step 60: 341.6328, Accuracy: 0.6867\n","Training loss (for one batch) at step 70: 339.9951, Accuracy: 0.6866\n","Training loss (for one batch) at step 80: 367.3934, Accuracy: 0.6879\n","Training loss (for one batch) at step 90: 318.5256, Accuracy: 0.6852\n","Training loss (for one batch) at step 100: 336.7431, Accuracy: 0.6858\n","Training loss (for one batch) at step 110: 340.6738, Accuracy: 0.6884\n","Training loss (for one batch) at step 120: 321.7924, Accuracy: 0.6887\n","Training loss (for one batch) at step 130: 323.8076, Accuracy: 0.6900\n","Training loss (for one batch) at step 140: 345.3731, Accuracy: 0.6877\n","---- Training ----\n","Training loss: 295.0337\n","Training acc over epoch: 0.6879\n","---- Validation ----\n","Validation loss: 71.8220\n","Validation acc: 0.6948\n","Time taken: 41.04s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 340.8214, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 305.7826, Accuracy: 0.7045\n","Training loss (for one batch) at step 20: 327.1538, Accuracy: 0.7038\n","Training loss (for one batch) at step 30: 323.5538, Accuracy: 0.6968\n","Training loss (for one batch) at step 40: 313.0959, Accuracy: 0.6929\n","Training loss (for one batch) at step 50: 308.3360, Accuracy: 0.6959\n","Training loss (for one batch) at step 60: 305.5701, Accuracy: 0.7020\n","Training loss (for one batch) at step 70: 324.3964, Accuracy: 0.6997\n","Training loss (for one batch) at step 80: 325.6848, Accuracy: 0.7001\n","Training loss (for one batch) at step 90: 354.5569, Accuracy: 0.6992\n","Training loss (for one batch) at step 100: 309.4525, Accuracy: 0.7020\n","Training loss (for one batch) at step 110: 329.3031, Accuracy: 0.7034\n","Training loss (for one batch) at step 120: 329.6373, Accuracy: 0.7027\n","Training loss (for one batch) at step 130: 335.3600, Accuracy: 0.7027\n","Training loss (for one batch) at step 140: 344.4106, Accuracy: 0.7011\n","---- Training ----\n","Training loss: 266.7270\n","Training acc over epoch: 0.7029\n","---- Validation ----\n","Validation loss: 66.3468\n","Validation acc: 0.7243\n","Time taken: 70.81s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 320.9370, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 311.2009, Accuracy: 0.7327\n","Training loss (for one batch) at step 20: 315.4370, Accuracy: 0.7290\n","Training loss (for one batch) at step 30: 311.0593, Accuracy: 0.7200\n","Training loss (for one batch) at step 40: 328.2438, Accuracy: 0.7163\n","Training loss (for one batch) at step 50: 327.8079, Accuracy: 0.7229\n","Training loss (for one batch) at step 60: 322.7364, Accuracy: 0.7231\n","Training loss (for one batch) at step 70: 317.3809, Accuracy: 0.7249\n","Training loss (for one batch) at step 80: 347.7578, Accuracy: 0.7228\n","Training loss (for one batch) at step 90: 318.2994, Accuracy: 0.7212\n","Training loss (for one batch) at step 100: 309.1743, Accuracy: 0.7188\n","Training loss (for one batch) at step 110: 309.0551, Accuracy: 0.7209\n","Training loss (for one batch) at step 120: 315.9899, Accuracy: 0.7217\n","Training loss (for one batch) at step 130: 299.7163, Accuracy: 0.7217\n","Training loss (for one batch) at step 140: 323.9458, Accuracy: 0.7212\n","---- Training ----\n","Training loss: 299.3060\n","Training acc over epoch: 0.7205\n","---- Validation ----\n","Validation loss: 68.6832\n","Validation acc: 0.6985\n","Time taken: 41.78s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 308.3130, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 309.3829, Accuracy: 0.7245\n","Training loss (for one batch) at step 20: 309.8175, Accuracy: 0.7300\n","Training loss (for one batch) at step 30: 332.4000, Accuracy: 0.7300\n","Training loss (for one batch) at step 40: 316.0762, Accuracy: 0.7349\n","Training loss (for one batch) at step 50: 312.5413, Accuracy: 0.7327\n","Training loss (for one batch) at step 60: 316.2780, Accuracy: 0.7321\n","Training loss (for one batch) at step 70: 330.6068, Accuracy: 0.7330\n","Training loss (for one batch) at step 80: 303.6725, Accuracy: 0.7315\n","Training loss (for one batch) at step 90: 308.1479, Accuracy: 0.7303\n","Training loss (for one batch) at step 100: 316.3442, Accuracy: 0.7291\n","Training loss (for one batch) at step 110: 290.3474, Accuracy: 0.7309\n","Training loss (for one batch) at step 120: 311.6064, Accuracy: 0.7305\n","Training loss (for one batch) at step 130: 340.3927, Accuracy: 0.7287\n","Training loss (for one batch) at step 140: 314.1768, Accuracy: 0.7272\n","---- Training ----\n","Training loss: 286.2704\n","Training acc over epoch: 0.7274\n","---- Validation ----\n","Validation loss: 68.6967\n","Validation acc: 0.7184\n","Time taken: 70.11s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 311.5945, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 307.1524, Accuracy: 0.7364\n","Training loss (for one batch) at step 20: 304.2565, Accuracy: 0.7424\n","Training loss (for one batch) at step 30: 327.4934, Accuracy: 0.7303\n","Training loss (for one batch) at step 40: 299.0128, Accuracy: 0.7383\n","Training loss (for one batch) at step 50: 296.2714, Accuracy: 0.7416\n","Training loss (for one batch) at step 60: 307.7940, Accuracy: 0.7449\n","Training loss (for one batch) at step 70: 324.5955, Accuracy: 0.7432\n","Training loss (for one batch) at step 80: 300.6064, Accuracy: 0.7422\n","Training loss (for one batch) at step 90: 311.1146, Accuracy: 0.7404\n","Training loss (for one batch) at step 100: 323.5187, Accuracy: 0.7400\n","Training loss (for one batch) at step 110: 309.1363, Accuracy: 0.7444\n","Training loss (for one batch) at step 120: 324.5754, Accuracy: 0.7433\n","Training loss (for one batch) at step 130: 294.1886, Accuracy: 0.7443\n","Training loss (for one batch) at step 140: 317.5658, Accuracy: 0.7418\n","---- Training ----\n","Training loss: 284.1860\n","Training acc over epoch: 0.7416\n","---- Validation ----\n","Validation loss: 68.1358\n","Validation acc: 0.7219\n","Time taken: 40.62s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 310.2429, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 300.2978, Accuracy: 0.7345\n","Training loss (for one batch) at step 20: 308.7468, Accuracy: 0.7495\n","Training loss (for one batch) at step 30: 294.1781, Accuracy: 0.7513\n","Training loss (for one batch) at step 40: 302.7307, Accuracy: 0.7539\n","Training loss (for one batch) at step 50: 293.5435, Accuracy: 0.7551\n","Training loss (for one batch) at step 60: 312.3758, Accuracy: 0.7531\n","Training loss (for one batch) at step 70: 322.9708, Accuracy: 0.7515\n","Training loss (for one batch) at step 80: 304.9420, Accuracy: 0.7499\n","Training loss (for one batch) at step 90: 293.7973, Accuracy: 0.7468\n","Training loss (for one batch) at step 100: 296.7136, Accuracy: 0.7474\n","Training loss (for one batch) at step 110: 301.3406, Accuracy: 0.7470\n","Training loss (for one batch) at step 120: 297.8398, Accuracy: 0.7482\n","Training loss (for one batch) at step 130: 302.2362, Accuracy: 0.7482\n","Training loss (for one batch) at step 140: 292.7247, Accuracy: 0.7496\n","---- Training ----\n","Training loss: 268.6658\n","Training acc over epoch: 0.7500\n","---- Validation ----\n","Validation loss: 68.7989\n","Validation acc: 0.7136\n","Time taken: 70.19s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 287.5923, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 288.5273, Accuracy: 0.7527\n","Training loss (for one batch) at step 20: 305.5519, Accuracy: 0.7524\n","Training loss (for one batch) at step 30: 303.8906, Accuracy: 0.7542\n","Training loss (for one batch) at step 40: 296.3648, Accuracy: 0.7505\n","Training loss (for one batch) at step 50: 299.0033, Accuracy: 0.7525\n","Training loss (for one batch) at step 60: 281.5224, Accuracy: 0.7552\n","Training loss (for one batch) at step 70: 287.0531, Accuracy: 0.7561\n","Training loss (for one batch) at step 80: 296.0748, Accuracy: 0.7562\n","Training loss (for one batch) at step 90: 295.1410, Accuracy: 0.7520\n","Training loss (for one batch) at step 100: 302.4777, Accuracy: 0.7530\n","Training loss (for one batch) at step 110: 306.0706, Accuracy: 0.7561\n","Training loss (for one batch) at step 120: 302.4145, Accuracy: 0.7572\n","Training loss (for one batch) at step 130: 305.3720, Accuracy: 0.7569\n","Training loss (for one batch) at step 140: 305.5745, Accuracy: 0.7562\n","---- Training ----\n","Training loss: 266.9718\n","Training acc over epoch: 0.7559\n","---- Validation ----\n","Validation loss: 78.2004\n","Validation acc: 0.7246\n","Time taken: 39.85s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 293.1306, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 302.3249, Accuracy: 0.7855\n","Training loss (for one batch) at step 20: 300.7356, Accuracy: 0.7776\n","Training loss (for one batch) at step 30: 292.7833, Accuracy: 0.7671\n","Training loss (for one batch) at step 40: 279.1132, Accuracy: 0.7654\n","Training loss (for one batch) at step 50: 292.5120, Accuracy: 0.7665\n","Training loss (for one batch) at step 60: 267.4562, Accuracy: 0.7682\n","Training loss (for one batch) at step 70: 302.8366, Accuracy: 0.7642\n","Training loss (for one batch) at step 80: 307.7257, Accuracy: 0.7623\n","Training loss (for one batch) at step 90: 289.1540, Accuracy: 0.7612\n","Training loss (for one batch) at step 100: 289.1783, Accuracy: 0.7598\n","Training loss (for one batch) at step 110: 276.9674, Accuracy: 0.7635\n","Training loss (for one batch) at step 120: 288.2111, Accuracy: 0.7645\n","Training loss (for one batch) at step 130: 281.3755, Accuracy: 0.7636\n","Training loss (for one batch) at step 140: 299.9367, Accuracy: 0.7632\n","---- Training ----\n","Training loss: 255.3710\n","Training acc over epoch: 0.7648\n","---- Validation ----\n","Validation loss: 71.0651\n","Validation acc: 0.7144\n","Time taken: 68.70s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 296.2023, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 286.3375, Accuracy: 0.7727\n","Training loss (for one batch) at step 20: 287.4993, Accuracy: 0.7757\n","Training loss (for one batch) at step 30: 304.1086, Accuracy: 0.7726\n","Training loss (for one batch) at step 40: 292.0949, Accuracy: 0.7722\n","Training loss (for one batch) at step 50: 312.6662, Accuracy: 0.7747\n","Training loss (for one batch) at step 60: 332.0870, Accuracy: 0.7785\n","Training loss (for one batch) at step 70: 310.1657, Accuracy: 0.7751\n","Training loss (for one batch) at step 80: 290.9586, Accuracy: 0.7741\n","Training loss (for one batch) at step 90: 289.1524, Accuracy: 0.7743\n","Training loss (for one batch) at step 100: 296.8352, Accuracy: 0.7736\n","Training loss (for one batch) at step 110: 288.9477, Accuracy: 0.7740\n","Training loss (for one batch) at step 120: 272.5976, Accuracy: 0.7734\n","Training loss (for one batch) at step 130: 286.6409, Accuracy: 0.7753\n","Training loss (for one batch) at step 140: 289.9462, Accuracy: 0.7751\n","---- Training ----\n","Training loss: 267.0271\n","Training acc over epoch: 0.7744\n","---- Validation ----\n","Validation loss: 66.8267\n","Validation acc: 0.7200\n","Time taken: 40.01s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 274.4041, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 281.1799, Accuracy: 0.7891\n","Training loss (for one batch) at step 20: 284.5640, Accuracy: 0.7800\n","Training loss (for one batch) at step 30: 294.5078, Accuracy: 0.7755\n","Training loss (for one batch) at step 40: 271.8104, Accuracy: 0.7810\n","Training loss (for one batch) at step 50: 271.3116, Accuracy: 0.7814\n","Training loss (for one batch) at step 60: 280.5667, Accuracy: 0.7848\n","Training loss (for one batch) at step 70: 285.3317, Accuracy: 0.7831\n","Training loss (for one batch) at step 80: 288.6895, Accuracy: 0.7806\n","Training loss (for one batch) at step 90: 278.3506, Accuracy: 0.7800\n","Training loss (for one batch) at step 100: 281.6333, Accuracy: 0.7789\n","Training loss (for one batch) at step 110: 273.0492, Accuracy: 0.7787\n","Training loss (for one batch) at step 120: 281.7909, Accuracy: 0.7792\n","Training loss (for one batch) at step 130: 285.3177, Accuracy: 0.7799\n","Training loss (for one batch) at step 140: 278.3694, Accuracy: 0.7800\n","---- Training ----\n","Training loss: 251.5452\n","Training acc over epoch: 0.7786\n","---- Validation ----\n","Validation loss: 63.7223\n","Validation acc: 0.7117\n","Time taken: 67.39s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 282.8299, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 282.6632, Accuracy: 0.7955\n","Training loss (for one batch) at step 20: 270.8885, Accuracy: 0.7952\n","Training loss (for one batch) at step 30: 270.3952, Accuracy: 0.7881\n","Training loss (for one batch) at step 40: 278.5165, Accuracy: 0.7824\n","Training loss (for one batch) at step 50: 281.3590, Accuracy: 0.7816\n","Training loss (for one batch) at step 60: 276.5955, Accuracy: 0.7834\n","Training loss (for one batch) at step 70: 268.8085, Accuracy: 0.7855\n","Training loss (for one batch) at step 80: 298.5565, Accuracy: 0.7827\n","Training loss (for one batch) at step 90: 283.5504, Accuracy: 0.7825\n","Training loss (for one batch) at step 100: 275.0671, Accuracy: 0.7821\n","Training loss (for one batch) at step 110: 307.2551, Accuracy: 0.7803\n","Training loss (for one batch) at step 120: 278.6587, Accuracy: 0.7806\n","Training loss (for one batch) at step 130: 264.2073, Accuracy: 0.7812\n","Training loss (for one batch) at step 140: 284.8057, Accuracy: 0.7811\n","---- Training ----\n","Training loss: 263.4333\n","Training acc over epoch: 0.7808\n","---- Validation ----\n","Validation loss: 69.0696\n","Validation acc: 0.7243\n","Time taken: 40.04s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 276.6978, Accuracy: 0.7700\n","Training loss (for one batch) at step 10: 274.0174, Accuracy: 0.8027\n","Training loss (for one batch) at step 20: 291.4106, Accuracy: 0.7995\n","Training loss (for one batch) at step 30: 291.3621, Accuracy: 0.7942\n","Training loss (for one batch) at step 40: 268.0268, Accuracy: 0.7978\n","Training loss (for one batch) at step 50: 294.2104, Accuracy: 0.7976\n","Training loss (for one batch) at step 60: 266.9556, Accuracy: 0.7962\n","Training loss (for one batch) at step 70: 261.6482, Accuracy: 0.7961\n","Training loss (for one batch) at step 80: 274.3265, Accuracy: 0.7941\n","Training loss (for one batch) at step 90: 296.7287, Accuracy: 0.7929\n","Training loss (for one batch) at step 100: 264.4135, Accuracy: 0.7897\n","Training loss (for one batch) at step 110: 286.2061, Accuracy: 0.7897\n","Training loss (for one batch) at step 120: 268.6156, Accuracy: 0.7893\n","Training loss (for one batch) at step 130: 272.5456, Accuracy: 0.7899\n","Training loss (for one batch) at step 140: 279.2499, Accuracy: 0.7891\n","---- Training ----\n","Training loss: 248.6221\n","Training acc over epoch: 0.7884\n","---- Validation ----\n","Validation loss: 65.3632\n","Validation acc: 0.7351\n","Time taken: 67.92s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 293.9531, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 260.4293, Accuracy: 0.8136\n","Training loss (for one batch) at step 20: 302.4777, Accuracy: 0.8033\n","Training loss (for one batch) at step 30: 278.2523, Accuracy: 0.8016\n","Training loss (for one batch) at step 40: 265.1810, Accuracy: 0.7983\n","Training loss (for one batch) at step 50: 276.9482, Accuracy: 0.8018\n","Training loss (for one batch) at step 60: 285.3032, Accuracy: 0.7998\n","Training loss (for one batch) at step 70: 290.5832, Accuracy: 0.8010\n","Training loss (for one batch) at step 80: 273.2991, Accuracy: 0.7999\n","Training loss (for one batch) at step 90: 281.3829, Accuracy: 0.7990\n","Training loss (for one batch) at step 100: 284.4566, Accuracy: 0.7980\n","Training loss (for one batch) at step 110: 265.6779, Accuracy: 0.7982\n","Training loss (for one batch) at step 120: 289.3460, Accuracy: 0.7983\n","Training loss (for one batch) at step 130: 295.4084, Accuracy: 0.7972\n","Training loss (for one batch) at step 140: 284.2663, Accuracy: 0.7961\n","---- Training ----\n","Training loss: 268.2704\n","Training acc over epoch: 0.7957\n","---- Validation ----\n","Validation loss: 65.8764\n","Validation acc: 0.7050\n","Time taken: 39.67s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 284.8246, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 271.8633, Accuracy: 0.8191\n","Training loss (for one batch) at step 20: 275.5013, Accuracy: 0.8043\n","Training loss (for one batch) at step 30: 260.5297, Accuracy: 0.7977\n","Training loss (for one batch) at step 40: 260.0592, Accuracy: 0.7988\n","Training loss (for one batch) at step 50: 258.6255, Accuracy: 0.8051\n","Training loss (for one batch) at step 60: 257.3095, Accuracy: 0.8044\n","Training loss (for one batch) at step 70: 272.2793, Accuracy: 0.8035\n","Training loss (for one batch) at step 80: 269.2575, Accuracy: 0.7999\n","Training loss (for one batch) at step 90: 271.0782, Accuracy: 0.7979\n","Training loss (for one batch) at step 100: 280.7691, Accuracy: 0.7980\n","Training loss (for one batch) at step 110: 279.1541, Accuracy: 0.7986\n","Training loss (for one batch) at step 120: 278.8455, Accuracy: 0.7979\n","Training loss (for one batch) at step 130: 274.0843, Accuracy: 0.7979\n","Training loss (for one batch) at step 140: 268.4203, Accuracy: 0.7978\n","---- Training ----\n","Training loss: 248.5131\n","Training acc over epoch: 0.7965\n","---- Validation ----\n","Validation loss: 55.4152\n","Validation acc: 0.7203\n","Time taken: 68.64s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 257.9449, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 260.1976, Accuracy: 0.8064\n","Training loss (for one batch) at step 20: 261.0378, Accuracy: 0.8076\n","Training loss (for one batch) at step 30: 289.5254, Accuracy: 0.8071\n","Training loss (for one batch) at step 40: 254.1850, Accuracy: 0.8044\n","Training loss (for one batch) at step 50: 281.1477, Accuracy: 0.8057\n","Training loss (for one batch) at step 60: 249.8896, Accuracy: 0.8044\n","Training loss (for one batch) at step 70: 270.9515, Accuracy: 0.8027\n","Training loss (for one batch) at step 80: 261.9622, Accuracy: 0.8038\n","Training loss (for one batch) at step 90: 263.8286, Accuracy: 0.8045\n","Training loss (for one batch) at step 100: 256.3716, Accuracy: 0.8048\n","Training loss (for one batch) at step 110: 266.3513, Accuracy: 0.8030\n","Training loss (for one batch) at step 120: 273.1258, Accuracy: 0.8012\n","Training loss (for one batch) at step 130: 286.5981, Accuracy: 0.8012\n","Training loss (for one batch) at step 140: 261.0540, Accuracy: 0.8005\n","---- Training ----\n","Training loss: 230.6163\n","Training acc over epoch: 0.8000\n","---- Validation ----\n","Validation loss: 64.9526\n","Validation acc: 0.7440\n","Time taken: 41.48s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 267.9152, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 254.0600, Accuracy: 0.8300\n","Training loss (for one batch) at step 20: 261.5470, Accuracy: 0.8143\n","Training loss (for one batch) at step 30: 276.0139, Accuracy: 0.8135\n","Training loss (for one batch) at step 40: 262.6774, Accuracy: 0.8156\n","Training loss (for one batch) at step 50: 247.3437, Accuracy: 0.8171\n","Training loss (for one batch) at step 60: 259.3389, Accuracy: 0.8166\n","Training loss (for one batch) at step 70: 264.9327, Accuracy: 0.8176\n","Training loss (for one batch) at step 80: 273.5218, Accuracy: 0.8130\n","Training loss (for one batch) at step 90: 271.5909, Accuracy: 0.8109\n","Training loss (for one batch) at step 100: 266.0771, Accuracy: 0.8087\n","Training loss (for one batch) at step 110: 274.3528, Accuracy: 0.8113\n","Training loss (for one batch) at step 120: 260.2671, Accuracy: 0.8098\n","Training loss (for one batch) at step 130: 251.9205, Accuracy: 0.8089\n","Training loss (for one batch) at step 140: 271.0856, Accuracy: 0.8074\n","---- Training ----\n","Training loss: 230.5191\n","Training acc over epoch: 0.8085\n","---- Validation ----\n","Validation loss: 74.2728\n","Validation acc: 0.7397\n","Time taken: 69.62s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 253.1247, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 277.1951, Accuracy: 0.7973\n","Training loss (for one batch) at step 20: 267.5648, Accuracy: 0.8014\n","Training loss (for one batch) at step 30: 262.8856, Accuracy: 0.8032\n","Training loss (for one batch) at step 40: 267.0617, Accuracy: 0.8029\n","Training loss (for one batch) at step 50: 285.0754, Accuracy: 0.8041\n","Training loss (for one batch) at step 60: 262.1369, Accuracy: 0.8075\n","Training loss (for one batch) at step 70: 257.0067, Accuracy: 0.8044\n","Training loss (for one batch) at step 80: 287.7650, Accuracy: 0.8042\n","Training loss (for one batch) at step 90: 287.9579, Accuracy: 0.8033\n","Training loss (for one batch) at step 100: 266.3832, Accuracy: 0.8025\n","Training loss (for one batch) at step 110: 241.1022, Accuracy: 0.8051\n","Training loss (for one batch) at step 120: 272.0801, Accuracy: 0.8068\n","Training loss (for one batch) at step 130: 280.6678, Accuracy: 0.8050\n","Training loss (for one batch) at step 140: 274.8775, Accuracy: 0.8043\n","---- Training ----\n","Training loss: 227.7609\n","Training acc over epoch: 0.8047\n","---- Validation ----\n","Validation loss: 78.8511\n","Validation acc: 0.7270\n","Time taken: 40.34s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 272.7597, Accuracy: 0.7300\n","Training loss (for one batch) at step 10: 249.4550, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 248.4739, Accuracy: 0.8148\n","Training loss (for one batch) at step 30: 259.5974, Accuracy: 0.8148\n","Training loss (for one batch) at step 40: 240.2643, Accuracy: 0.8154\n","Training loss (for one batch) at step 50: 276.4696, Accuracy: 0.8178\n","Training loss (for one batch) at step 60: 273.6829, Accuracy: 0.8159\n","Training loss (for one batch) at step 70: 248.0798, Accuracy: 0.8159\n","Training loss (for one batch) at step 80: 243.1398, Accuracy: 0.8135\n","Training loss (for one batch) at step 90: 271.6026, Accuracy: 0.8103\n","Training loss (for one batch) at step 100: 261.9376, Accuracy: 0.8099\n","Training loss (for one batch) at step 110: 250.8972, Accuracy: 0.8095\n","Training loss (for one batch) at step 120: 244.6315, Accuracy: 0.8087\n","Training loss (for one batch) at step 130: 259.9177, Accuracy: 0.8085\n","Training loss (for one batch) at step 140: 263.2397, Accuracy: 0.8103\n","---- Training ----\n","Training loss: 223.7578\n","Training acc over epoch: 0.8090\n","---- Validation ----\n","Validation loss: 75.1391\n","Validation acc: 0.7023\n","Time taken: 68.94s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 257.3048, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 262.6836, Accuracy: 0.8009\n","Training loss (for one batch) at step 20: 241.6714, Accuracy: 0.8124\n","Training loss (for one batch) at step 30: 252.3996, Accuracy: 0.8194\n","Training loss (for one batch) at step 40: 258.4375, Accuracy: 0.8117\n","Training loss (for one batch) at step 50: 253.2057, Accuracy: 0.8208\n","Training loss (for one batch) at step 60: 244.6396, Accuracy: 0.8211\n","Training loss (for one batch) at step 70: 259.3844, Accuracy: 0.8200\n","Training loss (for one batch) at step 80: 263.0248, Accuracy: 0.8174\n","Training loss (for one batch) at step 90: 244.5002, Accuracy: 0.8164\n","Training loss (for one batch) at step 100: 242.4540, Accuracy: 0.8135\n","Training loss (for one batch) at step 110: 256.4812, Accuracy: 0.8144\n","Training loss (for one batch) at step 120: 247.5332, Accuracy: 0.8141\n","Training loss (for one batch) at step 130: 252.2279, Accuracy: 0.8145\n","Training loss (for one batch) at step 140: 250.0751, Accuracy: 0.8133\n","---- Training ----\n","Training loss: 253.3919\n","Training acc over epoch: 0.8123\n","---- Validation ----\n","Validation loss: 71.9518\n","Validation acc: 0.7303\n","Time taken: 39.49s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 245.2087, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 267.4346, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 251.3935, Accuracy: 0.8210\n","Training loss (for one batch) at step 30: 252.2466, Accuracy: 0.8106\n","Training loss (for one batch) at step 40: 252.9010, Accuracy: 0.8085\n","Training loss (for one batch) at step 50: 232.7100, Accuracy: 0.8114\n","Training loss (for one batch) at step 60: 268.0819, Accuracy: 0.8143\n","Training loss (for one batch) at step 70: 282.3296, Accuracy: 0.8128\n","Training loss (for one batch) at step 80: 252.0375, Accuracy: 0.8138\n","Training loss (for one batch) at step 90: 266.4183, Accuracy: 0.8127\n","Training loss (for one batch) at step 100: 244.3384, Accuracy: 0.8115\n","Training loss (for one batch) at step 110: 246.0055, Accuracy: 0.8122\n","Training loss (for one batch) at step 120: 268.5213, Accuracy: 0.8127\n","Training loss (for one batch) at step 130: 259.4031, Accuracy: 0.8114\n","Training loss (for one batch) at step 140: 257.0443, Accuracy: 0.8101\n","---- Training ----\n","Training loss: 226.5488\n","Training acc over epoch: 0.8102\n","---- Validation ----\n","Validation loss: 71.7860\n","Validation acc: 0.7324\n","Time taken: 67.82s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 262.8203, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 257.3925, Accuracy: 0.8218\n","Training loss (for one batch) at step 20: 257.8772, Accuracy: 0.8157\n","Training loss (for one batch) at step 30: 259.9486, Accuracy: 0.8145\n","Training loss (for one batch) at step 40: 244.5385, Accuracy: 0.8161\n","Training loss (for one batch) at step 50: 237.1455, Accuracy: 0.8239\n","Training loss (for one batch) at step 60: 248.1620, Accuracy: 0.8262\n","Training loss (for one batch) at step 70: 258.5505, Accuracy: 0.8214\n","Training loss (for one batch) at step 80: 250.6287, Accuracy: 0.8190\n","Training loss (for one batch) at step 90: 266.9042, Accuracy: 0.8195\n","Training loss (for one batch) at step 100: 227.0710, Accuracy: 0.8206\n","Training loss (for one batch) at step 110: 249.6210, Accuracy: 0.8199\n","Training loss (for one batch) at step 120: 249.4041, Accuracy: 0.8193\n","Training loss (for one batch) at step 130: 233.6432, Accuracy: 0.8187\n","Training loss (for one batch) at step 140: 240.1343, Accuracy: 0.8178\n","---- Training ----\n","Training loss: 238.7665\n","Training acc over epoch: 0.8173\n","---- Validation ----\n","Validation loss: 80.8421\n","Validation acc: 0.7243\n","Time taken: 39.57s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 263.9147, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 248.9690, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 236.7310, Accuracy: 0.8057\n","Training loss (for one batch) at step 30: 267.7122, Accuracy: 0.8135\n","Training loss (for one batch) at step 40: 242.1663, Accuracy: 0.8149\n","Training loss (for one batch) at step 50: 257.6321, Accuracy: 0.8188\n","Training loss (for one batch) at step 60: 262.6769, Accuracy: 0.8205\n","Training loss (for one batch) at step 70: 249.0263, Accuracy: 0.8177\n","Training loss (for one batch) at step 80: 245.6560, Accuracy: 0.8147\n","Training loss (for one batch) at step 90: 249.2642, Accuracy: 0.8142\n","Training loss (for one batch) at step 100: 250.1915, Accuracy: 0.8135\n","Training loss (for one batch) at step 110: 247.5913, Accuracy: 0.8159\n","Training loss (for one batch) at step 120: 243.0607, Accuracy: 0.8152\n","Training loss (for one batch) at step 130: 253.2670, Accuracy: 0.8141\n","Training loss (for one batch) at step 140: 248.5217, Accuracy: 0.8152\n","---- Training ----\n","Training loss: 230.1614\n","Training acc over epoch: 0.8143\n","---- Validation ----\n","Validation loss: 83.7253\n","Validation acc: 0.7337\n","Time taken: 67.79s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 242.9598, Accuracy: 0.8800\n","Training loss (for one batch) at step 10: 247.8664, Accuracy: 0.8182\n","Training loss (for one batch) at step 20: 266.8396, Accuracy: 0.8205\n","Training loss (for one batch) at step 30: 268.3075, Accuracy: 0.8152\n","Training loss (for one batch) at step 40: 238.9866, Accuracy: 0.8149\n","Training loss (for one batch) at step 50: 249.5738, Accuracy: 0.8175\n","Training loss (for one batch) at step 60: 250.1463, Accuracy: 0.8211\n","Training loss (for one batch) at step 70: 260.3709, Accuracy: 0.8185\n","Training loss (for one batch) at step 80: 241.2599, Accuracy: 0.8225\n","Training loss (for one batch) at step 90: 246.5519, Accuracy: 0.8192\n","Training loss (for one batch) at step 100: 223.7112, Accuracy: 0.8182\n","Training loss (for one batch) at step 110: 244.1425, Accuracy: 0.8186\n","Training loss (for one batch) at step 120: 250.3738, Accuracy: 0.8179\n","Training loss (for one batch) at step 130: 251.2357, Accuracy: 0.8176\n","Training loss (for one batch) at step 140: 230.5758, Accuracy: 0.8165\n","---- Training ----\n","Training loss: 214.3449\n","Training acc over epoch: 0.8163\n","---- Validation ----\n","Validation loss: 59.5852\n","Validation acc: 0.7241\n","Time taken: 39.51s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 237.0660, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 245.4707, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 242.7267, Accuracy: 0.8381\n","Training loss (for one batch) at step 30: 245.9972, Accuracy: 0.8281\n","Training loss (for one batch) at step 40: 245.9184, Accuracy: 0.8263\n","Training loss (for one batch) at step 50: 220.9484, Accuracy: 0.8255\n","Training loss (for one batch) at step 60: 248.2107, Accuracy: 0.8254\n","Training loss (for one batch) at step 70: 251.8611, Accuracy: 0.8246\n","Training loss (for one batch) at step 80: 239.7196, Accuracy: 0.8216\n","Training loss (for one batch) at step 90: 269.4475, Accuracy: 0.8216\n","Training loss (for one batch) at step 100: 256.1593, Accuracy: 0.8198\n","Training loss (for one batch) at step 110: 245.2618, Accuracy: 0.8204\n","Training loss (for one batch) at step 120: 248.5625, Accuracy: 0.8217\n","Training loss (for one batch) at step 130: 253.1875, Accuracy: 0.8224\n","Training loss (for one batch) at step 140: 240.0161, Accuracy: 0.8216\n","---- Training ----\n","Training loss: 225.6399\n","Training acc over epoch: 0.8217\n","---- Validation ----\n","Validation loss: 70.6175\n","Validation acc: 0.7225\n","Time taken: 68.55s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 240.8630, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 235.8821, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 231.8177, Accuracy: 0.8305\n","Training loss (for one batch) at step 30: 223.3994, Accuracy: 0.8290\n","Training loss (for one batch) at step 40: 241.3397, Accuracy: 0.8261\n","Training loss (for one batch) at step 50: 223.1221, Accuracy: 0.8288\n","Training loss (for one batch) at step 60: 265.8589, Accuracy: 0.8293\n","Training loss (for one batch) at step 70: 225.0162, Accuracy: 0.8311\n","Training loss (for one batch) at step 80: 240.6938, Accuracy: 0.8296\n","Training loss (for one batch) at step 90: 239.2405, Accuracy: 0.8287\n","Training loss (for one batch) at step 100: 239.6542, Accuracy: 0.8273\n","Training loss (for one batch) at step 110: 238.0170, Accuracy: 0.8279\n","Training loss (for one batch) at step 120: 248.8421, Accuracy: 0.8271\n","Training loss (for one batch) at step 130: 246.5535, Accuracy: 0.8254\n","Training loss (for one batch) at step 140: 250.7069, Accuracy: 0.8265\n","---- Training ----\n","Training loss: 219.0284\n","Training acc over epoch: 0.8263\n","---- Validation ----\n","Validation loss: 77.5206\n","Validation acc: 0.7286\n","Time taken: 41.22s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 226.5276, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 229.6468, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 238.3939, Accuracy: 0.8286\n","Training loss (for one batch) at step 30: 257.4417, Accuracy: 0.8235\n","Training loss (for one batch) at step 40: 228.6163, Accuracy: 0.8207\n","Training loss (for one batch) at step 50: 249.1708, Accuracy: 0.8251\n","Training loss (for one batch) at step 60: 250.3281, Accuracy: 0.8257\n","Training loss (for one batch) at step 70: 254.4079, Accuracy: 0.8270\n","Training loss (for one batch) at step 80: 227.8084, Accuracy: 0.8253\n","Training loss (for one batch) at step 90: 234.0721, Accuracy: 0.8254\n","Training loss (for one batch) at step 100: 238.3733, Accuracy: 0.8225\n","Training loss (for one batch) at step 110: 242.7036, Accuracy: 0.8243\n","Training loss (for one batch) at step 120: 238.0730, Accuracy: 0.8234\n","Training loss (for one batch) at step 130: 239.5786, Accuracy: 0.8220\n","Training loss (for one batch) at step 140: 224.7513, Accuracy: 0.8224\n","---- Training ----\n","Training loss: 215.7556\n","Training acc over epoch: 0.8233\n","---- Validation ----\n","Validation loss: 71.5662\n","Validation acc: 0.7300\n","Time taken: 70.37s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 235.6551, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 238.6401, Accuracy: 0.8509\n","Training loss (for one batch) at step 20: 216.5951, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 229.7914, Accuracy: 0.8371\n","Training loss (for one batch) at step 40: 225.5388, Accuracy: 0.8363\n","Training loss (for one batch) at step 50: 238.1542, Accuracy: 0.8382\n","Training loss (for one batch) at step 60: 243.2029, Accuracy: 0.8362\n","Training loss (for one batch) at step 70: 255.1176, Accuracy: 0.8334\n","Training loss (for one batch) at step 80: 244.8720, Accuracy: 0.8331\n","Training loss (for one batch) at step 90: 247.1379, Accuracy: 0.8302\n","Training loss (for one batch) at step 100: 213.0667, Accuracy: 0.8274\n","Training loss (for one batch) at step 110: 231.0137, Accuracy: 0.8275\n","Training loss (for one batch) at step 120: 244.9926, Accuracy: 0.8288\n","Training loss (for one batch) at step 130: 248.2804, Accuracy: 0.8283\n","Training loss (for one batch) at step 140: 245.8166, Accuracy: 0.8280\n","---- Training ----\n","Training loss: 229.2257\n","Training acc over epoch: 0.8274\n","---- Validation ----\n","Validation loss: 76.1638\n","Validation acc: 0.7104\n","Time taken: 39.44s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 236.0183, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 253.8174, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 229.4721, Accuracy: 0.8338\n","Training loss (for one batch) at step 30: 239.5814, Accuracy: 0.8306\n","Training loss (for one batch) at step 40: 212.8347, Accuracy: 0.8288\n","Training loss (for one batch) at step 50: 245.4743, Accuracy: 0.8341\n","Training loss (for one batch) at step 60: 238.6210, Accuracy: 0.8321\n","Training loss (for one batch) at step 70: 244.3634, Accuracy: 0.8310\n","Training loss (for one batch) at step 80: 238.9213, Accuracy: 0.8305\n","Training loss (for one batch) at step 90: 218.5621, Accuracy: 0.8297\n","Training loss (for one batch) at step 100: 221.9011, Accuracy: 0.8298\n","Training loss (for one batch) at step 110: 255.0074, Accuracy: 0.8310\n","Training loss (for one batch) at step 120: 246.5009, Accuracy: 0.8303\n","Training loss (for one batch) at step 130: 258.9625, Accuracy: 0.8285\n","Training loss (for one batch) at step 140: 219.8892, Accuracy: 0.8279\n","---- Training ----\n","Training loss: 217.1170\n","Training acc over epoch: 0.8283\n","---- Validation ----\n","Validation loss: 66.0604\n","Validation acc: 0.7254\n","Time taken: 68.67s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 239.2077, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 225.8753, Accuracy: 0.8264\n","Training loss (for one batch) at step 20: 232.7441, Accuracy: 0.8181\n","Training loss (for one batch) at step 30: 218.0241, Accuracy: 0.8242\n","Training loss (for one batch) at step 40: 201.7208, Accuracy: 0.8261\n","Training loss (for one batch) at step 50: 223.0511, Accuracy: 0.8324\n","Training loss (for one batch) at step 60: 223.9432, Accuracy: 0.8300\n","Training loss (for one batch) at step 70: 235.0882, Accuracy: 0.8293\n","Training loss (for one batch) at step 80: 223.1269, Accuracy: 0.8281\n","Training loss (for one batch) at step 90: 227.8282, Accuracy: 0.8263\n","Training loss (for one batch) at step 100: 229.0715, Accuracy: 0.8251\n","Training loss (for one batch) at step 110: 226.9343, Accuracy: 0.8261\n","Training loss (for one batch) at step 120: 247.7040, Accuracy: 0.8256\n","Training loss (for one batch) at step 130: 239.1024, Accuracy: 0.8251\n","Training loss (for one batch) at step 140: 217.4137, Accuracy: 0.8263\n","---- Training ----\n","Training loss: 225.1393\n","Training acc over epoch: 0.8262\n","---- Validation ----\n","Validation loss: 80.4782\n","Validation acc: 0.7211\n","Time taken: 39.64s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 222.8628, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 227.8701, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 253.4336, Accuracy: 0.8376\n","Training loss (for one batch) at step 30: 229.9568, Accuracy: 0.8468\n","Training loss (for one batch) at step 40: 233.7424, Accuracy: 0.8415\n","Training loss (for one batch) at step 50: 222.1446, Accuracy: 0.8382\n","Training loss (for one batch) at step 60: 233.4369, Accuracy: 0.8416\n","Training loss (for one batch) at step 70: 237.5229, Accuracy: 0.8400\n","Training loss (for one batch) at step 80: 232.7879, Accuracy: 0.8364\n","Training loss (for one batch) at step 90: 223.6380, Accuracy: 0.8348\n","Training loss (for one batch) at step 100: 241.2095, Accuracy: 0.8346\n","Training loss (for one batch) at step 110: 239.6607, Accuracy: 0.8337\n","Training loss (for one batch) at step 120: 253.2920, Accuracy: 0.8329\n","Training loss (for one batch) at step 130: 229.1096, Accuracy: 0.8324\n","Training loss (for one batch) at step 140: 244.7189, Accuracy: 0.8318\n","---- Training ----\n","Training loss: 222.2115\n","Training acc over epoch: 0.8325\n","---- Validation ----\n","Validation loss: 60.3246\n","Validation acc: 0.7254\n","Time taken: 67.82s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 229.1195, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 245.0390, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 225.3183, Accuracy: 0.8367\n","Training loss (for one batch) at step 30: 233.7484, Accuracy: 0.8361\n","Training loss (for one batch) at step 40: 224.6992, Accuracy: 0.8407\n","Training loss (for one batch) at step 50: 221.2496, Accuracy: 0.8443\n","Training loss (for one batch) at step 60: 232.3968, Accuracy: 0.8433\n","Training loss (for one batch) at step 70: 224.8880, Accuracy: 0.8437\n","Training loss (for one batch) at step 80: 239.7034, Accuracy: 0.8394\n","Training loss (for one batch) at step 90: 212.1902, Accuracy: 0.8373\n","Training loss (for one batch) at step 100: 221.4440, Accuracy: 0.8360\n","Training loss (for one batch) at step 110: 229.4701, Accuracy: 0.8356\n","Training loss (for one batch) at step 120: 213.8596, Accuracy: 0.8351\n","Training loss (for one batch) at step 130: 242.9181, Accuracy: 0.8354\n","Training loss (for one batch) at step 140: 207.2268, Accuracy: 0.8352\n","---- Training ----\n","Training loss: 225.0655\n","Training acc over epoch: 0.8346\n","---- Validation ----\n","Validation loss: 91.1490\n","Validation acc: 0.7260\n","Time taken: 41.42s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 235.7008, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 230.7741, Accuracy: 0.8345\n","Training loss (for one batch) at step 20: 223.9419, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 224.5347, Accuracy: 0.8406\n","Training loss (for one batch) at step 40: 230.9295, Accuracy: 0.8422\n","Training loss (for one batch) at step 50: 226.3443, Accuracy: 0.8398\n","Training loss (for one batch) at step 60: 229.7600, Accuracy: 0.8385\n","Training loss (for one batch) at step 70: 246.8531, Accuracy: 0.8344\n","Training loss (for one batch) at step 80: 224.3175, Accuracy: 0.8354\n","Training loss (for one batch) at step 90: 233.3235, Accuracy: 0.8324\n","Training loss (for one batch) at step 100: 212.0814, Accuracy: 0.8318\n","Training loss (for one batch) at step 110: 228.0109, Accuracy: 0.8311\n","Training loss (for one batch) at step 120: 238.6880, Accuracy: 0.8310\n","Training loss (for one batch) at step 130: 222.6603, Accuracy: 0.8317\n","Training loss (for one batch) at step 140: 225.4574, Accuracy: 0.8306\n","---- Training ----\n","Training loss: 197.5582\n","Training acc over epoch: 0.8309\n","---- Validation ----\n","Validation loss: 83.5725\n","Validation acc: 0.7082\n","Time taken: 69.35s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 221.4831, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 233.2910, Accuracy: 0.8336\n","Training loss (for one batch) at step 20: 217.4336, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 231.5486, Accuracy: 0.8294\n","Training loss (for one batch) at step 40: 227.9975, Accuracy: 0.8307\n","Training loss (for one batch) at step 50: 217.0598, Accuracy: 0.8343\n","Training loss (for one batch) at step 60: 224.3783, Accuracy: 0.8369\n","Training loss (for one batch) at step 70: 234.3911, Accuracy: 0.8352\n","Training loss (for one batch) at step 80: 228.3164, Accuracy: 0.8343\n","Training loss (for one batch) at step 90: 248.6913, Accuracy: 0.8331\n","Training loss (for one batch) at step 100: 211.7279, Accuracy: 0.8343\n","Training loss (for one batch) at step 110: 234.5641, Accuracy: 0.8332\n","Training loss (for one batch) at step 120: 205.3940, Accuracy: 0.8337\n","Training loss (for one batch) at step 130: 231.4433, Accuracy: 0.8318\n","Training loss (for one batch) at step 140: 216.6727, Accuracy: 0.8325\n","---- Training ----\n","Training loss: 226.7897\n","Training acc over epoch: 0.8328\n","---- Validation ----\n","Validation loss: 61.6835\n","Validation acc: 0.7300\n","Time taken: 39.96s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 232.8424, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 207.6014, Accuracy: 0.8473\n","Training loss (for one batch) at step 20: 240.2044, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 225.2753, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 208.2381, Accuracy: 0.8351\n","Training loss (for one batch) at step 50: 225.3697, Accuracy: 0.8347\n","Training loss (for one batch) at step 60: 224.4839, Accuracy: 0.8366\n","Training loss (for one batch) at step 70: 214.2183, Accuracy: 0.8385\n","Training loss (for one batch) at step 80: 235.1060, Accuracy: 0.8391\n","Training loss (for one batch) at step 90: 212.5414, Accuracy: 0.8359\n","Training loss (for one batch) at step 100: 212.0553, Accuracy: 0.8359\n","Training loss (for one batch) at step 110: 209.2366, Accuracy: 0.8375\n","Training loss (for one batch) at step 120: 214.8327, Accuracy: 0.8356\n","Training loss (for one batch) at step 130: 222.3927, Accuracy: 0.8356\n","Training loss (for one batch) at step 140: 232.0658, Accuracy: 0.8349\n","---- Training ----\n","Training loss: 212.5442\n","Training acc over epoch: 0.8352\n","---- Validation ----\n","Validation loss: 83.5780\n","Validation acc: 0.7311\n","Time taken: 66.64s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 242.4544, Accuracy: 0.7600\n","Training loss (for one batch) at step 10: 212.1332, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 221.3975, Accuracy: 0.8429\n","Training loss (for one batch) at step 30: 225.3596, Accuracy: 0.8390\n","Training loss (for one batch) at step 40: 215.4514, Accuracy: 0.8373\n","Training loss (for one batch) at step 50: 218.8609, Accuracy: 0.8380\n","Training loss (for one batch) at step 60: 196.1662, Accuracy: 0.8370\n","Training loss (for one batch) at step 70: 243.7510, Accuracy: 0.8365\n","Training loss (for one batch) at step 80: 216.1343, Accuracy: 0.8365\n","Training loss (for one batch) at step 90: 246.3656, Accuracy: 0.8371\n","Training loss (for one batch) at step 100: 218.1694, Accuracy: 0.8349\n","Training loss (for one batch) at step 110: 207.9781, Accuracy: 0.8377\n","Training loss (for one batch) at step 120: 232.6457, Accuracy: 0.8364\n","Training loss (for one batch) at step 130: 230.9736, Accuracy: 0.8355\n","Training loss (for one batch) at step 140: 244.2299, Accuracy: 0.8357\n","---- Training ----\n","Training loss: 195.0882\n","Training acc over epoch: 0.8361\n","---- Validation ----\n","Validation loss: 68.8239\n","Validation acc: 0.7190\n","Time taken: 38.96s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 251.9922, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 228.0255, Accuracy: 0.8255\n","Training loss (for one batch) at step 20: 221.6367, Accuracy: 0.8329\n","Training loss (for one batch) at step 30: 246.8746, Accuracy: 0.8384\n","Training loss (for one batch) at step 40: 211.6280, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 218.8036, Accuracy: 0.8367\n","Training loss (for one batch) at step 60: 231.2731, Accuracy: 0.8380\n","Training loss (for one batch) at step 70: 230.3606, Accuracy: 0.8359\n","Training loss (for one batch) at step 80: 219.1460, Accuracy: 0.8354\n","Training loss (for one batch) at step 90: 237.6003, Accuracy: 0.8336\n","Training loss (for one batch) at step 100: 204.3558, Accuracy: 0.8338\n","Training loss (for one batch) at step 110: 235.5454, Accuracy: 0.8347\n","Training loss (for one batch) at step 120: 233.1591, Accuracy: 0.8349\n","Training loss (for one batch) at step 130: 213.6061, Accuracy: 0.8353\n","Training loss (for one batch) at step 140: 214.1243, Accuracy: 0.8348\n","---- Training ----\n","Training loss: 199.8629\n","Training acc over epoch: 0.8352\n","---- Validation ----\n","Validation loss: 80.6648\n","Validation acc: 0.6977\n","Time taken: 66.30s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 239.5077, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 208.6214, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 222.0068, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 211.4985, Accuracy: 0.8348\n","Training loss (for one batch) at step 40: 208.8649, Accuracy: 0.8383\n","Training loss (for one batch) at step 50: 216.1010, Accuracy: 0.8400\n","Training loss (for one batch) at step 60: 222.7691, Accuracy: 0.8421\n","Training loss (for one batch) at step 70: 229.5697, Accuracy: 0.8428\n","Training loss (for one batch) at step 80: 224.2507, Accuracy: 0.8399\n","Training loss (for one batch) at step 90: 222.4402, Accuracy: 0.8389\n","Training loss (for one batch) at step 100: 219.7448, Accuracy: 0.8378\n","Training loss (for one batch) at step 110: 210.3742, Accuracy: 0.8389\n","Training loss (for one batch) at step 120: 213.9673, Accuracy: 0.8391\n","Training loss (for one batch) at step 130: 222.9016, Accuracy: 0.8378\n","Training loss (for one batch) at step 140: 231.4823, Accuracy: 0.8370\n","---- Training ----\n","Training loss: 194.4597\n","Training acc over epoch: 0.8366\n","---- Validation ----\n","Validation loss: 83.3201\n","Validation acc: 0.7195\n","Time taken: 38.77s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 227.1496, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 235.9235, Accuracy: 0.8145\n","Training loss (for one batch) at step 20: 211.7898, Accuracy: 0.8400\n","Training loss (for one batch) at step 30: 230.5993, Accuracy: 0.8452\n","Training loss (for one batch) at step 40: 187.0107, Accuracy: 0.8441\n","Training loss (for one batch) at step 50: 227.6437, Accuracy: 0.8457\n","Training loss (for one batch) at step 60: 228.1958, Accuracy: 0.8444\n","Training loss (for one batch) at step 70: 196.7518, Accuracy: 0.8441\n","Training loss (for one batch) at step 80: 211.7545, Accuracy: 0.8430\n","Training loss (for one batch) at step 90: 228.6042, Accuracy: 0.8400\n","Training loss (for one batch) at step 100: 203.0460, Accuracy: 0.8399\n","Training loss (for one batch) at step 110: 225.6506, Accuracy: 0.8409\n","Training loss (for one batch) at step 120: 208.2786, Accuracy: 0.8404\n","Training loss (for one batch) at step 130: 219.2914, Accuracy: 0.8384\n","Training loss (for one batch) at step 140: 213.9928, Accuracy: 0.8394\n","---- Training ----\n","Training loss: 216.3493\n","Training acc over epoch: 0.8398\n","---- Validation ----\n","Validation loss: 70.2902\n","Validation acc: 0.7211\n","Time taken: 65.73s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 204.2107, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 217.1594, Accuracy: 0.8327\n","Training loss (for one batch) at step 20: 217.0646, Accuracy: 0.8362\n","Training loss (for one batch) at step 30: 200.9380, Accuracy: 0.8355\n","Training loss (for one batch) at step 40: 215.5766, Accuracy: 0.8337\n","Training loss (for one batch) at step 50: 222.0875, Accuracy: 0.8343\n","Training loss (for one batch) at step 60: 219.3408, Accuracy: 0.8356\n","Training loss (for one batch) at step 70: 225.2516, Accuracy: 0.8362\n","Training loss (for one batch) at step 80: 215.6136, Accuracy: 0.8374\n","Training loss (for one batch) at step 90: 224.7710, Accuracy: 0.8367\n","Training loss (for one batch) at step 100: 211.5945, Accuracy: 0.8362\n","Training loss (for one batch) at step 110: 202.5294, Accuracy: 0.8380\n","Training loss (for one batch) at step 120: 213.5864, Accuracy: 0.8386\n","Training loss (for one batch) at step 130: 207.4355, Accuracy: 0.8374\n","Training loss (for one batch) at step 140: 236.6324, Accuracy: 0.8376\n","---- Training ----\n","Training loss: 207.1648\n","Training acc over epoch: 0.8389\n","---- Validation ----\n","Validation loss: 89.5880\n","Validation acc: 0.7233\n","Time taken: 38.74s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 227.7313, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 224.0572, Accuracy: 0.8427\n","Training loss (for one batch) at step 20: 238.5672, Accuracy: 0.8414\n","Training loss (for one batch) at step 30: 211.0170, Accuracy: 0.8397\n","Training loss (for one batch) at step 40: 197.7054, Accuracy: 0.8429\n","Training loss (for one batch) at step 50: 203.5685, Accuracy: 0.8441\n","Training loss (for one batch) at step 60: 214.0670, Accuracy: 0.8430\n","Training loss (for one batch) at step 70: 238.4037, Accuracy: 0.8408\n","Training loss (for one batch) at step 80: 203.5839, Accuracy: 0.8398\n","Training loss (for one batch) at step 90: 203.3805, Accuracy: 0.8392\n","Training loss (for one batch) at step 100: 209.8988, Accuracy: 0.8400\n","Training loss (for one batch) at step 110: 223.6774, Accuracy: 0.8405\n","Training loss (for one batch) at step 120: 196.0912, Accuracy: 0.8415\n","Training loss (for one batch) at step 130: 219.5452, Accuracy: 0.8411\n","Training loss (for one batch) at step 140: 230.2804, Accuracy: 0.8409\n","---- Training ----\n","Training loss: 186.0357\n","Training acc over epoch: 0.8404\n","---- Validation ----\n","Validation loss: 80.6919\n","Validation acc: 0.7227\n","Time taken: 64.74s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 238.4560, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 194.8253, Accuracy: 0.8318\n","Training loss (for one batch) at step 20: 219.9620, Accuracy: 0.8381\n","Training loss (for one batch) at step 30: 215.7497, Accuracy: 0.8368\n","Training loss (for one batch) at step 40: 212.7747, Accuracy: 0.8412\n","Training loss (for one batch) at step 50: 198.8821, Accuracy: 0.8445\n","Training loss (for one batch) at step 60: 236.3775, Accuracy: 0.8433\n","Training loss (for one batch) at step 70: 221.9170, Accuracy: 0.8428\n","Training loss (for one batch) at step 80: 213.0508, Accuracy: 0.8419\n","Training loss (for one batch) at step 90: 197.8893, Accuracy: 0.8401\n","Training loss (for one batch) at step 100: 236.7733, Accuracy: 0.8394\n","Training loss (for one batch) at step 110: 222.2791, Accuracy: 0.8410\n","Training loss (for one batch) at step 120: 218.5991, Accuracy: 0.8412\n","Training loss (for one batch) at step 130: 224.9725, Accuracy: 0.8408\n","Training loss (for one batch) at step 140: 215.9731, Accuracy: 0.8409\n","---- Training ----\n","Training loss: 191.4384\n","Training acc over epoch: 0.8406\n","---- Validation ----\n","Validation loss: 97.7488\n","Validation acc: 0.7093\n","Time taken: 39.65s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 208.7464, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 210.0813, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 221.9965, Accuracy: 0.8571\n","Training loss (for one batch) at step 30: 230.0991, Accuracy: 0.8552\n","Training loss (for one batch) at step 40: 204.7511, Accuracy: 0.8515\n","Training loss (for one batch) at step 50: 218.2825, Accuracy: 0.8502\n","Training loss (for one batch) at step 60: 200.8929, Accuracy: 0.8516\n","Training loss (for one batch) at step 70: 206.2544, Accuracy: 0.8499\n","Training loss (for one batch) at step 80: 225.0881, Accuracy: 0.8469\n","Training loss (for one batch) at step 90: 202.8847, Accuracy: 0.8449\n","Training loss (for one batch) at step 100: 211.7589, Accuracy: 0.8445\n","Training loss (for one batch) at step 110: 221.0608, Accuracy: 0.8442\n","Training loss (for one batch) at step 120: 200.0377, Accuracy: 0.8441\n","Training loss (for one batch) at step 130: 210.6541, Accuracy: 0.8440\n","Training loss (for one batch) at step 140: 210.0822, Accuracy: 0.8430\n","---- Training ----\n","Training loss: 194.9838\n","Training acc over epoch: 0.8432\n","---- Validation ----\n","Validation loss: 80.0137\n","Validation acc: 0.7327\n","Time taken: 69.23s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 197.1196, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 218.8996, Accuracy: 0.8527\n","Training loss (for one batch) at step 20: 198.7946, Accuracy: 0.8533\n","Training loss (for one batch) at step 30: 225.0060, Accuracy: 0.8516\n","Training loss (for one batch) at step 40: 194.3371, Accuracy: 0.8495\n","Training loss (for one batch) at step 50: 188.4386, Accuracy: 0.8522\n","Training loss (for one batch) at step 60: 206.9781, Accuracy: 0.8511\n","Training loss (for one batch) at step 70: 199.8394, Accuracy: 0.8500\n","Training loss (for one batch) at step 80: 217.7742, Accuracy: 0.8436\n","Training loss (for one batch) at step 90: 215.6571, Accuracy: 0.8431\n","Training loss (for one batch) at step 100: 210.4976, Accuracy: 0.8419\n","Training loss (for one batch) at step 110: 212.9773, Accuracy: 0.8405\n","Training loss (for one batch) at step 120: 220.7786, Accuracy: 0.8416\n","Training loss (for one batch) at step 130: 225.8599, Accuracy: 0.8400\n","Training loss (for one batch) at step 140: 213.2460, Accuracy: 0.8414\n","---- Training ----\n","Training loss: 186.6153\n","Training acc over epoch: 0.8409\n","---- Validation ----\n","Validation loss: 85.3479\n","Validation acc: 0.7276\n","Time taken: 39.92s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 203.1366, Accuracy: 0.9200\n","Training loss (for one batch) at step 10: 185.1559, Accuracy: 0.8600\n","Training loss (for one batch) at step 20: 218.7847, Accuracy: 0.8576\n","Training loss (for one batch) at step 30: 191.1471, Accuracy: 0.8539\n","Training loss (for one batch) at step 40: 215.8734, Accuracy: 0.8488\n","Training loss (for one batch) at step 50: 203.3598, Accuracy: 0.8496\n","Training loss (for one batch) at step 60: 206.9249, Accuracy: 0.8485\n","Training loss (for one batch) at step 70: 207.5836, Accuracy: 0.8492\n","Training loss (for one batch) at step 80: 206.9852, Accuracy: 0.8470\n","Training loss (for one batch) at step 90: 227.6345, Accuracy: 0.8455\n","Training loss (for one batch) at step 100: 225.8455, Accuracy: 0.8462\n","Training loss (for one batch) at step 110: 193.3656, Accuracy: 0.8459\n","Training loss (for one batch) at step 120: 212.8346, Accuracy: 0.8462\n","Training loss (for one batch) at step 130: 202.9728, Accuracy: 0.8460\n","Training loss (for one batch) at step 140: 237.0291, Accuracy: 0.8449\n","---- Training ----\n","Training loss: 190.6838\n","Training acc over epoch: 0.8448\n","---- Validation ----\n","Validation loss: 86.4745\n","Validation acc: 0.7128\n","Time taken: 67.08s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 212.2415, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 215.1803, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 222.5047, Accuracy: 0.8562\n","Training loss (for one batch) at step 30: 205.4164, Accuracy: 0.8471\n","Training loss (for one batch) at step 40: 195.6361, Accuracy: 0.8502\n","Training loss (for one batch) at step 50: 184.7876, Accuracy: 0.8504\n","Training loss (for one batch) at step 60: 211.4153, Accuracy: 0.8502\n","Training loss (for one batch) at step 70: 203.3895, Accuracy: 0.8490\n","Training loss (for one batch) at step 80: 208.5665, Accuracy: 0.8458\n","Training loss (for one batch) at step 90: 209.2171, Accuracy: 0.8455\n","Training loss (for one batch) at step 100: 169.9461, Accuracy: 0.8443\n","Training loss (for one batch) at step 110: 215.6253, Accuracy: 0.8439\n","Training loss (for one batch) at step 120: 209.8707, Accuracy: 0.8425\n","Training loss (for one batch) at step 130: 213.9637, Accuracy: 0.8440\n","Training loss (for one batch) at step 140: 206.6464, Accuracy: 0.8435\n","---- Training ----\n","Training loss: 184.4137\n","Training acc over epoch: 0.8425\n","---- Validation ----\n","Validation loss: 88.4317\n","Validation acc: 0.7343\n","Time taken: 38.73s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7451\n","Validation AUC: 0.7429\n","Validation Balanced_ACC: 0.4780\n","Validation MI: 0.1371\n","Validation Normalized MI: 0.2052\n","Validation Adjusted MI: 0.2052\n","Validation aUc_Sklearn: 0.8301\n","\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 508.5974, Accuracy: 0.4800\n","Training loss (for one batch) at step 10: 458.0078, Accuracy: 0.5473\n","Training loss (for one batch) at step 20: 448.5780, Accuracy: 0.5438\n","Training loss (for one batch) at step 30: 462.5913, Accuracy: 0.5481\n","Training loss (for one batch) at step 40: 442.1822, Accuracy: 0.5461\n","Training loss (for one batch) at step 50: 417.6051, Accuracy: 0.5561\n","Training loss (for one batch) at step 60: 399.7358, Accuracy: 0.5559\n","Training loss (for one batch) at step 70: 449.2058, Accuracy: 0.5603\n","Training loss (for one batch) at step 80: 450.9482, Accuracy: 0.5606\n","Training loss (for one batch) at step 90: 445.9540, Accuracy: 0.5627\n","Training loss (for one batch) at step 100: 433.6956, Accuracy: 0.5602\n","Training loss (for one batch) at step 110: 419.5416, Accuracy: 0.5618\n","Training loss (for one batch) at step 120: 427.3777, Accuracy: 0.5631\n","Training loss (for one batch) at step 130: 440.2532, Accuracy: 0.5645\n","Training loss (for one batch) at step 140: 413.0059, Accuracy: 0.5667\n","---- Training ----\n","Training loss: 346.2086\n","Training acc over epoch: 0.5678\n","---- Validation ----\n","Validation loss: 73.1438\n","Validation acc: 0.5134\n","Time taken: 68.20s\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 404.1805, Accuracy: 0.5800\n","Training loss (for one batch) at step 10: 382.2370, Accuracy: 0.5891\n","Training loss (for one batch) at step 20: 377.0359, Accuracy: 0.5967\n","Training loss (for one batch) at step 30: 399.3176, Accuracy: 0.5913\n","Training loss (for one batch) at step 40: 370.0696, Accuracy: 0.5966\n","Training loss (for one batch) at step 50: 387.0901, Accuracy: 0.5861\n","Training loss (for one batch) at step 60: 380.5152, Accuracy: 0.5875\n","Training loss (for one batch) at step 70: 378.6922, Accuracy: 0.5872\n","Training loss (for one batch) at step 80: 393.3930, Accuracy: 0.5901\n","Training loss (for one batch) at step 90: 377.2006, Accuracy: 0.5922\n","Training loss (for one batch) at step 100: 396.8155, Accuracy: 0.5935\n","Training loss (for one batch) at step 110: 346.6873, Accuracy: 0.5940\n","Training loss (for one batch) at step 120: 394.1331, Accuracy: 0.5931\n","Training loss (for one batch) at step 130: 351.9615, Accuracy: 0.5918\n","Training loss (for one batch) at step 140: 377.4893, Accuracy: 0.5926\n","---- Training ----\n","Training loss: 320.4898\n","Training acc over epoch: 0.5939\n","---- Validation ----\n","Validation loss: 84.0435\n","Validation acc: 0.5247\n","Time taken: 51.47s\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 399.1810, Accuracy: 0.5500\n","Training loss (for one batch) at step 10: 367.5387, Accuracy: 0.5918\n","Training loss (for one batch) at step 20: 351.4949, Accuracy: 0.6071\n","Training loss (for one batch) at step 30: 357.1950, Accuracy: 0.6071\n","Training loss (for one batch) at step 40: 360.3572, Accuracy: 0.6054\n","Training loss (for one batch) at step 50: 378.9421, Accuracy: 0.6018\n","Training loss (for one batch) at step 60: 360.5316, Accuracy: 0.6064\n","Training loss (for one batch) at step 70: 357.5767, Accuracy: 0.6035\n","Training loss (for one batch) at step 80: 360.2577, Accuracy: 0.6091\n","Training loss (for one batch) at step 90: 367.6597, Accuracy: 0.6087\n","Training loss (for one batch) at step 100: 338.8252, Accuracy: 0.6089\n","Training loss (for one batch) at step 110: 339.9271, Accuracy: 0.6092\n","Training loss (for one batch) at step 120: 346.8394, Accuracy: 0.6112\n","Training loss (for one batch) at step 130: 378.6564, Accuracy: 0.6139\n","Training loss (for one batch) at step 140: 381.2691, Accuracy: 0.6144\n","---- Training ----\n","Training loss: 308.0762\n","Training acc over epoch: 0.6147\n","---- Validation ----\n","Validation loss: 72.1242\n","Validation acc: 0.6609\n","Time taken: 65.82s\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 360.2675, Accuracy: 0.5900\n","Training loss (for one batch) at step 10: 360.1122, Accuracy: 0.6245\n","Training loss (for one batch) at step 20: 355.1179, Accuracy: 0.6367\n","Training loss (for one batch) at step 30: 339.0730, Accuracy: 0.6265\n","Training loss (for one batch) at step 40: 347.0356, Accuracy: 0.6244\n","Training loss (for one batch) at step 50: 345.8120, Accuracy: 0.6263\n","Training loss (for one batch) at step 60: 352.2596, Accuracy: 0.6254\n","Training loss (for one batch) at step 70: 364.5292, Accuracy: 0.6215\n","Training loss (for one batch) at step 80: 348.7098, Accuracy: 0.6248\n","Training loss (for one batch) at step 90: 359.7964, Accuracy: 0.6270\n","Training loss (for one batch) at step 100: 346.9525, Accuracy: 0.6274\n","Training loss (for one batch) at step 110: 335.0567, Accuracy: 0.6300\n","Training loss (for one batch) at step 120: 345.9951, Accuracy: 0.6304\n","Training loss (for one batch) at step 130: 349.5189, Accuracy: 0.6303\n","Training loss (for one batch) at step 140: 336.6990, Accuracy: 0.6325\n","---- Training ----\n","Training loss: 306.4244\n","Training acc over epoch: 0.6320\n","---- Validation ----\n","Validation loss: 68.0483\n","Validation acc: 0.6738\n","Time taken: 37.45s\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 332.3388, Accuracy: 0.7200\n","Training loss (for one batch) at step 10: 341.0671, Accuracy: 0.6691\n","Training loss (for one batch) at step 20: 353.7315, Accuracy: 0.6486\n","Training loss (for one batch) at step 30: 348.4402, Accuracy: 0.6526\n","Training loss (for one batch) at step 40: 325.0941, Accuracy: 0.6527\n","Training loss (for one batch) at step 50: 356.5078, Accuracy: 0.6545\n","Training loss (for one batch) at step 60: 325.4660, Accuracy: 0.6539\n","Training loss (for one batch) at step 70: 335.8635, Accuracy: 0.6528\n","Training loss (for one batch) at step 80: 345.9576, Accuracy: 0.6512\n","Training loss (for one batch) at step 90: 363.9437, Accuracy: 0.6523\n","Training loss (for one batch) at step 100: 330.3947, Accuracy: 0.6522\n","Training loss (for one batch) at step 110: 338.1832, Accuracy: 0.6521\n","Training loss (for one batch) at step 120: 339.5884, Accuracy: 0.6521\n","Training loss (for one batch) at step 130: 332.8400, Accuracy: 0.6550\n","Training loss (for one batch) at step 140: 336.9701, Accuracy: 0.6530\n","---- Training ----\n","Training loss: 284.4721\n","Training acc over epoch: 0.6543\n","---- Validation ----\n","Validation loss: 73.5025\n","Validation acc: 0.6754\n","Time taken: 65.55s\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 333.8199, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 346.2613, Accuracy: 0.6855\n","Training loss (for one batch) at step 20: 334.9705, Accuracy: 0.6852\n","Training loss (for one batch) at step 30: 347.4201, Accuracy: 0.6774\n","Training loss (for one batch) at step 40: 330.2390, Accuracy: 0.6724\n","Training loss (for one batch) at step 50: 328.3431, Accuracy: 0.6733\n","Training loss (for one batch) at step 60: 338.9945, Accuracy: 0.6746\n","Training loss (for one batch) at step 70: 322.7267, Accuracy: 0.6735\n","Training loss (for one batch) at step 80: 350.3091, Accuracy: 0.6752\n","Training loss (for one batch) at step 90: 330.6779, Accuracy: 0.6752\n","Training loss (for one batch) at step 100: 338.9464, Accuracy: 0.6739\n","Training loss (for one batch) at step 110: 320.3706, Accuracy: 0.6739\n","Training loss (for one batch) at step 120: 328.9919, Accuracy: 0.6736\n","Training loss (for one batch) at step 130: 363.3353, Accuracy: 0.6741\n","Training loss (for one batch) at step 140: 327.6748, Accuracy: 0.6749\n","---- Training ----\n","Training loss: 305.5929\n","Training acc over epoch: 0.6756\n","---- Validation ----\n","Validation loss: 67.2395\n","Validation acc: 0.6703\n","Time taken: 37.26s\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 343.1735, Accuracy: 0.6600\n","Training loss (for one batch) at step 10: 325.7560, Accuracy: 0.6691\n","Training loss (for one batch) at step 20: 335.8406, Accuracy: 0.6729\n","Training loss (for one batch) at step 30: 333.3301, Accuracy: 0.6800\n","Training loss (for one batch) at step 40: 343.4000, Accuracy: 0.6788\n","Training loss (for one batch) at step 50: 315.4317, Accuracy: 0.6818\n","Training loss (for one batch) at step 60: 324.9974, Accuracy: 0.6857\n","Training loss (for one batch) at step 70: 327.0681, Accuracy: 0.6870\n","Training loss (for one batch) at step 80: 324.9272, Accuracy: 0.6863\n","Training loss (for one batch) at step 90: 323.9642, Accuracy: 0.6856\n","Training loss (for one batch) at step 100: 320.3303, Accuracy: 0.6866\n","Training loss (for one batch) at step 110: 314.5504, Accuracy: 0.6882\n","Training loss (for one batch) at step 120: 325.6480, Accuracy: 0.6890\n","Training loss (for one batch) at step 130: 318.8661, Accuracy: 0.6894\n","Training loss (for one batch) at step 140: 342.5833, Accuracy: 0.6894\n","---- Training ----\n","Training loss: 299.2988\n","Training acc over epoch: 0.6893\n","---- Validation ----\n","Validation loss: 76.6859\n","Validation acc: 0.6875\n","Time taken: 63.98s\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 320.1844, Accuracy: 0.6900\n","Training loss (for one batch) at step 10: 314.7481, Accuracy: 0.6955\n","Training loss (for one batch) at step 20: 325.0437, Accuracy: 0.6952\n","Training loss (for one batch) at step 30: 324.3101, Accuracy: 0.6974\n","Training loss (for one batch) at step 40: 326.5236, Accuracy: 0.7000\n","Training loss (for one batch) at step 50: 323.1355, Accuracy: 0.6990\n","Training loss (for one batch) at step 60: 317.6761, Accuracy: 0.7016\n","Training loss (for one batch) at step 70: 304.0023, Accuracy: 0.6990\n","Training loss (for one batch) at step 80: 330.1042, Accuracy: 0.6995\n","Training loss (for one batch) at step 90: 308.8157, Accuracy: 0.6991\n","Training loss (for one batch) at step 100: 334.6648, Accuracy: 0.6991\n","Training loss (for one batch) at step 110: 301.3532, Accuracy: 0.7010\n","Training loss (for one batch) at step 120: 311.9257, Accuracy: 0.7020\n","Training loss (for one batch) at step 130: 313.4055, Accuracy: 0.7019\n","Training loss (for one batch) at step 140: 319.5402, Accuracy: 0.7030\n","---- Training ----\n","Training loss: 281.0635\n","Training acc over epoch: 0.7038\n","---- Validation ----\n","Validation loss: 70.9094\n","Validation acc: 0.7123\n","Time taken: 37.31s\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 309.1336, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 319.8992, Accuracy: 0.7127\n","Training loss (for one batch) at step 20: 315.8604, Accuracy: 0.7157\n","Training loss (for one batch) at step 30: 322.7823, Accuracy: 0.7155\n","Training loss (for one batch) at step 40: 314.8830, Accuracy: 0.7110\n","Training loss (for one batch) at step 50: 316.9138, Accuracy: 0.7159\n","Training loss (for one batch) at step 60: 315.5333, Accuracy: 0.7187\n","Training loss (for one batch) at step 70: 312.9787, Accuracy: 0.7200\n","Training loss (for one batch) at step 80: 309.6868, Accuracy: 0.7184\n","Training loss (for one batch) at step 90: 329.1476, Accuracy: 0.7178\n","Training loss (for one batch) at step 100: 315.8623, Accuracy: 0.7177\n","Training loss (for one batch) at step 110: 322.8610, Accuracy: 0.7168\n","Training loss (for one batch) at step 120: 331.7591, Accuracy: 0.7166\n","Training loss (for one batch) at step 130: 312.1237, Accuracy: 0.7166\n","Training loss (for one batch) at step 140: 334.0428, Accuracy: 0.7172\n","---- Training ----\n","Training loss: 275.5959\n","Training acc over epoch: 0.7163\n","---- Validation ----\n","Validation loss: 74.7744\n","Validation acc: 0.7074\n","Time taken: 63.31s\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 314.8957, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 295.9340, Accuracy: 0.7345\n","Training loss (for one batch) at step 20: 312.0419, Accuracy: 0.7310\n","Training loss (for one batch) at step 30: 312.0032, Accuracy: 0.7248\n","Training loss (for one batch) at step 40: 306.9714, Accuracy: 0.7315\n","Training loss (for one batch) at step 50: 317.9958, Accuracy: 0.7306\n","Training loss (for one batch) at step 60: 317.4953, Accuracy: 0.7315\n","Training loss (for one batch) at step 70: 305.0045, Accuracy: 0.7325\n","Training loss (for one batch) at step 80: 314.2765, Accuracy: 0.7307\n","Training loss (for one batch) at step 90: 307.3655, Accuracy: 0.7315\n","Training loss (for one batch) at step 100: 307.3610, Accuracy: 0.7306\n","Training loss (for one batch) at step 110: 313.3464, Accuracy: 0.7321\n","Training loss (for one batch) at step 120: 308.6949, Accuracy: 0.7330\n","Training loss (for one batch) at step 130: 303.7930, Accuracy: 0.7324\n","Training loss (for one batch) at step 140: 296.3772, Accuracy: 0.7326\n","---- Training ----\n","Training loss: 278.9771\n","Training acc over epoch: 0.7319\n","---- Validation ----\n","Validation loss: 63.7425\n","Validation acc: 0.7131\n","Time taken: 37.63s\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 306.8549, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 303.9464, Accuracy: 0.7636\n","Training loss (for one batch) at step 20: 312.3066, Accuracy: 0.7567\n","Training loss (for one batch) at step 30: 312.0124, Accuracy: 0.7506\n","Training loss (for one batch) at step 40: 305.7898, Accuracy: 0.7541\n","Training loss (for one batch) at step 50: 307.4559, Accuracy: 0.7531\n","Training loss (for one batch) at step 60: 300.6809, Accuracy: 0.7508\n","Training loss (for one batch) at step 70: 294.0911, Accuracy: 0.7469\n","Training loss (for one batch) at step 80: 319.8887, Accuracy: 0.7448\n","Training loss (for one batch) at step 90: 321.5705, Accuracy: 0.7438\n","Training loss (for one batch) at step 100: 333.7896, Accuracy: 0.7413\n","Training loss (for one batch) at step 110: 326.5966, Accuracy: 0.7395\n","Training loss (for one batch) at step 120: 315.4378, Accuracy: 0.7394\n","Training loss (for one batch) at step 130: 300.6674, Accuracy: 0.7397\n","Training loss (for one batch) at step 140: 306.2756, Accuracy: 0.7399\n","---- Training ----\n","Training loss: 275.2092\n","Training acc over epoch: 0.7410\n","---- Validation ----\n","Validation loss: 68.4777\n","Validation acc: 0.7171\n","Time taken: 63.21s\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 284.5240, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 305.3553, Accuracy: 0.7564\n","Training loss (for one batch) at step 20: 295.9024, Accuracy: 0.7519\n","Training loss (for one batch) at step 30: 291.3435, Accuracy: 0.7535\n","Training loss (for one batch) at step 40: 299.9389, Accuracy: 0.7563\n","Training loss (for one batch) at step 50: 311.8002, Accuracy: 0.7555\n","Training loss (for one batch) at step 60: 316.4650, Accuracy: 0.7539\n","Training loss (for one batch) at step 70: 299.7022, Accuracy: 0.7535\n","Training loss (for one batch) at step 80: 312.1980, Accuracy: 0.7536\n","Training loss (for one batch) at step 90: 321.8228, Accuracy: 0.7535\n","Training loss (for one batch) at step 100: 287.9266, Accuracy: 0.7531\n","Training loss (for one batch) at step 110: 302.3047, Accuracy: 0.7522\n","Training loss (for one batch) at step 120: 281.2987, Accuracy: 0.7540\n","Training loss (for one batch) at step 130: 288.7980, Accuracy: 0.7527\n","Training loss (for one batch) at step 140: 308.8012, Accuracy: 0.7511\n","---- Training ----\n","Training loss: 275.6327\n","Training acc over epoch: 0.7509\n","---- Validation ----\n","Validation loss: 71.5102\n","Validation acc: 0.7200\n","Time taken: 37.20s\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 297.7991, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 289.0128, Accuracy: 0.7636\n","Training loss (for one batch) at step 20: 288.5938, Accuracy: 0.7633\n","Training loss (for one batch) at step 30: 305.1466, Accuracy: 0.7590\n","Training loss (for one batch) at step 40: 298.4105, Accuracy: 0.7600\n","Training loss (for one batch) at step 50: 304.1230, Accuracy: 0.7596\n","Training loss (for one batch) at step 60: 284.1893, Accuracy: 0.7620\n","Training loss (for one batch) at step 70: 287.9382, Accuracy: 0.7592\n","Training loss (for one batch) at step 80: 317.1934, Accuracy: 0.7574\n","Training loss (for one batch) at step 90: 298.5917, Accuracy: 0.7569\n","Training loss (for one batch) at step 100: 311.7328, Accuracy: 0.7562\n","Training loss (for one batch) at step 110: 283.5586, Accuracy: 0.7565\n","Training loss (for one batch) at step 120: 305.9326, Accuracy: 0.7548\n","Training loss (for one batch) at step 130: 321.1220, Accuracy: 0.7557\n","Training loss (for one batch) at step 140: 313.6051, Accuracy: 0.7563\n","---- Training ----\n","Training loss: 253.2909\n","Training acc over epoch: 0.7566\n","---- Validation ----\n","Validation loss: 69.5159\n","Validation acc: 0.7268\n","Time taken: 63.72s\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 316.8684, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 292.1217, Accuracy: 0.7709\n","Training loss (for one batch) at step 20: 307.6197, Accuracy: 0.7752\n","Training loss (for one batch) at step 30: 305.2005, Accuracy: 0.7681\n","Training loss (for one batch) at step 40: 300.3006, Accuracy: 0.7705\n","Training loss (for one batch) at step 50: 290.2699, Accuracy: 0.7741\n","Training loss (for one batch) at step 60: 286.2824, Accuracy: 0.7734\n","Training loss (for one batch) at step 70: 301.1277, Accuracy: 0.7720\n","Training loss (for one batch) at step 80: 312.2248, Accuracy: 0.7710\n","Training loss (for one batch) at step 90: 315.1287, Accuracy: 0.7704\n","Training loss (for one batch) at step 100: 290.1288, Accuracy: 0.7692\n","Training loss (for one batch) at step 110: 292.6099, Accuracy: 0.7689\n","Training loss (for one batch) at step 120: 301.6969, Accuracy: 0.7707\n","Training loss (for one batch) at step 130: 290.4244, Accuracy: 0.7697\n","Training loss (for one batch) at step 140: 281.0597, Accuracy: 0.7681\n","---- Training ----\n","Training loss: 260.8023\n","Training acc over epoch: 0.7683\n","---- Validation ----\n","Validation loss: 79.8110\n","Validation acc: 0.7286\n","Time taken: 37.25s\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 287.8112, Accuracy: 0.8000\n","Training loss (for one batch) at step 10: 288.2426, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 292.5754, Accuracy: 0.7829\n","Training loss (for one batch) at step 30: 312.2665, Accuracy: 0.7810\n","Training loss (for one batch) at step 40: 308.0047, Accuracy: 0.7763\n","Training loss (for one batch) at step 50: 287.4537, Accuracy: 0.7731\n","Training loss (for one batch) at step 60: 281.3705, Accuracy: 0.7764\n","Training loss (for one batch) at step 70: 299.7886, Accuracy: 0.7751\n","Training loss (for one batch) at step 80: 308.2660, Accuracy: 0.7733\n","Training loss (for one batch) at step 90: 286.6970, Accuracy: 0.7710\n","Training loss (for one batch) at step 100: 284.2503, Accuracy: 0.7702\n","Training loss (for one batch) at step 110: 290.3051, Accuracy: 0.7722\n","Training loss (for one batch) at step 120: 303.9724, Accuracy: 0.7717\n","Training loss (for one batch) at step 130: 276.2774, Accuracy: 0.7712\n","Training loss (for one batch) at step 140: 291.7871, Accuracy: 0.7713\n","---- Training ----\n","Training loss: 261.9626\n","Training acc over epoch: 0.7700\n","---- Validation ----\n","Validation loss: 71.8812\n","Validation acc: 0.7289\n","Time taken: 65.26s\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 287.7042, Accuracy: 0.7500\n","Training loss (for one batch) at step 10: 283.0758, Accuracy: 0.7809\n","Training loss (for one batch) at step 20: 303.7711, Accuracy: 0.7781\n","Training loss (for one batch) at step 30: 296.5357, Accuracy: 0.7800\n","Training loss (for one batch) at step 40: 276.4526, Accuracy: 0.7793\n","Training loss (for one batch) at step 50: 285.5413, Accuracy: 0.7757\n","Training loss (for one batch) at step 60: 293.6508, Accuracy: 0.7780\n","Training loss (for one batch) at step 70: 277.4861, Accuracy: 0.7813\n","Training loss (for one batch) at step 80: 295.0909, Accuracy: 0.7786\n","Training loss (for one batch) at step 90: 277.5001, Accuracy: 0.7771\n","Training loss (for one batch) at step 100: 279.5539, Accuracy: 0.7763\n","Training loss (for one batch) at step 110: 290.8910, Accuracy: 0.7779\n","Training loss (for one batch) at step 120: 297.6659, Accuracy: 0.7778\n","Training loss (for one batch) at step 130: 287.6613, Accuracy: 0.7775\n","Training loss (for one batch) at step 140: 307.6964, Accuracy: 0.7779\n","---- Training ----\n","Training loss: 254.6772\n","Training acc over epoch: 0.7772\n","---- Validation ----\n","Validation loss: 69.2148\n","Validation acc: 0.7203\n","Time taken: 38.95s\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 294.9160, Accuracy: 0.7100\n","Training loss (for one batch) at step 10: 272.7084, Accuracy: 0.7809\n","Training loss (for one batch) at step 20: 275.8794, Accuracy: 0.7914\n","Training loss (for one batch) at step 30: 296.7771, Accuracy: 0.7919\n","Training loss (for one batch) at step 40: 280.2924, Accuracy: 0.7915\n","Training loss (for one batch) at step 50: 306.4625, Accuracy: 0.7876\n","Training loss (for one batch) at step 60: 311.4976, Accuracy: 0.7898\n","Training loss (for one batch) at step 70: 269.2623, Accuracy: 0.7904\n","Training loss (for one batch) at step 80: 296.5634, Accuracy: 0.7878\n","Training loss (for one batch) at step 90: 306.0323, Accuracy: 0.7892\n","Training loss (for one batch) at step 100: 305.9054, Accuracy: 0.7853\n","Training loss (for one batch) at step 110: 292.7782, Accuracy: 0.7850\n","Training loss (for one batch) at step 120: 281.2682, Accuracy: 0.7859\n","Training loss (for one batch) at step 130: 291.4432, Accuracy: 0.7859\n","Training loss (for one batch) at step 140: 279.6985, Accuracy: 0.7847\n","---- Training ----\n","Training loss: 259.8427\n","Training acc over epoch: 0.7846\n","---- Validation ----\n","Validation loss: 67.0372\n","Validation acc: 0.7348\n","Time taken: 72.62s\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 281.1983, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 272.8742, Accuracy: 0.8091\n","Training loss (for one batch) at step 20: 268.1824, Accuracy: 0.8038\n","Training loss (for one batch) at step 30: 278.9404, Accuracy: 0.7974\n","Training loss (for one batch) at step 40: 275.6928, Accuracy: 0.7934\n","Training loss (for one batch) at step 50: 279.3399, Accuracy: 0.7965\n","Training loss (for one batch) at step 60: 280.3119, Accuracy: 0.7967\n","Training loss (for one batch) at step 70: 269.3581, Accuracy: 0.7946\n","Training loss (for one batch) at step 80: 288.1784, Accuracy: 0.7915\n","Training loss (for one batch) at step 90: 269.9775, Accuracy: 0.7908\n","Training loss (for one batch) at step 100: 281.1439, Accuracy: 0.7895\n","Training loss (for one batch) at step 110: 269.7388, Accuracy: 0.7923\n","Training loss (for one batch) at step 120: 291.3633, Accuracy: 0.7908\n","Training loss (for one batch) at step 130: 271.1154, Accuracy: 0.7906\n","Training loss (for one batch) at step 140: 268.1231, Accuracy: 0.7883\n","---- Training ----\n","Training loss: 253.1129\n","Training acc over epoch: 0.7889\n","---- Validation ----\n","Validation loss: 66.7540\n","Validation acc: 0.7273\n","Time taken: 37.52s\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 274.9939, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 266.5839, Accuracy: 0.8145\n","Training loss (for one batch) at step 20: 264.9141, Accuracy: 0.8010\n","Training loss (for one batch) at step 30: 275.9818, Accuracy: 0.8006\n","Training loss (for one batch) at step 40: 265.4191, Accuracy: 0.7973\n","Training loss (for one batch) at step 50: 277.9290, Accuracy: 0.7976\n","Training loss (for one batch) at step 60: 288.5861, Accuracy: 0.7954\n","Training loss (for one batch) at step 70: 290.2316, Accuracy: 0.7930\n","Training loss (for one batch) at step 80: 277.1662, Accuracy: 0.7893\n","Training loss (for one batch) at step 90: 274.7190, Accuracy: 0.7907\n","Training loss (for one batch) at step 100: 283.0499, Accuracy: 0.7920\n","Training loss (for one batch) at step 110: 268.4845, Accuracy: 0.7919\n","Training loss (for one batch) at step 120: 286.5542, Accuracy: 0.7925\n","Training loss (for one batch) at step 130: 268.5126, Accuracy: 0.7935\n","Training loss (for one batch) at step 140: 284.2941, Accuracy: 0.7923\n","---- Training ----\n","Training loss: 263.3982\n","Training acc over epoch: 0.7914\n","---- Validation ----\n","Validation loss: 73.8680\n","Validation acc: 0.7090\n","Time taken: 97.48s\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 272.6887, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 283.7895, Accuracy: 0.7845\n","Training loss (for one batch) at step 20: 283.6638, Accuracy: 0.8014\n","Training loss (for one batch) at step 30: 286.4651, Accuracy: 0.8010\n","Training loss (for one batch) at step 40: 268.7259, Accuracy: 0.8012\n","Training loss (for one batch) at step 50: 288.4514, Accuracy: 0.8016\n","Training loss (for one batch) at step 60: 281.6421, Accuracy: 0.8010\n","Training loss (for one batch) at step 70: 275.3656, Accuracy: 0.7986\n","Training loss (for one batch) at step 80: 260.4134, Accuracy: 0.7993\n","Training loss (for one batch) at step 90: 283.1617, Accuracy: 0.7976\n","Training loss (for one batch) at step 100: 267.3992, Accuracy: 0.7985\n","Training loss (for one batch) at step 110: 265.6535, Accuracy: 0.7988\n","Training loss (for one batch) at step 120: 267.9982, Accuracy: 0.7996\n","Training loss (for one batch) at step 130: 274.6024, Accuracy: 0.7982\n","Training loss (for one batch) at step 140: 274.4560, Accuracy: 0.7979\n","---- Training ----\n","Training loss: 250.8210\n","Training acc over epoch: 0.7986\n","---- Validation ----\n","Validation loss: 77.5652\n","Validation acc: 0.7294\n","Time taken: 38.54s\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 285.4881, Accuracy: 0.8200\n","Training loss (for one batch) at step 10: 273.3094, Accuracy: 0.8100\n","Training loss (for one batch) at step 20: 265.6511, Accuracy: 0.8133\n","Training loss (for one batch) at step 30: 274.4017, Accuracy: 0.8065\n","Training loss (for one batch) at step 40: 267.3605, Accuracy: 0.8073\n","Training loss (for one batch) at step 50: 250.6604, Accuracy: 0.8086\n","Training loss (for one batch) at step 60: 264.2548, Accuracy: 0.8098\n","Training loss (for one batch) at step 70: 292.1863, Accuracy: 0.8117\n","Training loss (for one batch) at step 80: 285.2086, Accuracy: 0.8069\n","Training loss (for one batch) at step 90: 287.3350, Accuracy: 0.8069\n","Training loss (for one batch) at step 100: 279.5231, Accuracy: 0.8064\n","Training loss (for one batch) at step 110: 265.5845, Accuracy: 0.8086\n","Training loss (for one batch) at step 120: 283.3965, Accuracy: 0.8076\n","Training loss (for one batch) at step 130: 261.0379, Accuracy: 0.8065\n","Training loss (for one batch) at step 140: 278.5376, Accuracy: 0.8063\n","---- Training ----\n","Training loss: 237.2046\n","Training acc over epoch: 0.8049\n","---- Validation ----\n","Validation loss: 60.6623\n","Validation acc: 0.7292\n","Time taken: 65.08s\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 266.2986, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 262.8398, Accuracy: 0.7964\n","Training loss (for one batch) at step 20: 263.0704, Accuracy: 0.8019\n","Training loss (for one batch) at step 30: 281.2963, Accuracy: 0.8026\n","Training loss (for one batch) at step 40: 265.4263, Accuracy: 0.8061\n","Training loss (for one batch) at step 50: 257.4875, Accuracy: 0.8110\n","Training loss (for one batch) at step 60: 259.3760, Accuracy: 0.8110\n","Training loss (for one batch) at step 70: 276.1196, Accuracy: 0.8083\n","Training loss (for one batch) at step 80: 260.8427, Accuracy: 0.8074\n","Training loss (for one batch) at step 90: 267.3523, Accuracy: 0.8073\n","Training loss (for one batch) at step 100: 274.2722, Accuracy: 0.8073\n","Training loss (for one batch) at step 110: 260.6438, Accuracy: 0.8075\n","Training loss (for one batch) at step 120: 278.0892, Accuracy: 0.8073\n","Training loss (for one batch) at step 130: 272.5726, Accuracy: 0.8069\n","Training loss (for one batch) at step 140: 252.9618, Accuracy: 0.8077\n","---- Training ----\n","Training loss: 233.6352\n","Training acc over epoch: 0.8068\n","---- Validation ----\n","Validation loss: 60.8059\n","Validation acc: 0.7303\n","Time taken: 38.91s\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 268.2427, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 253.6900, Accuracy: 0.8082\n","Training loss (for one batch) at step 20: 273.1879, Accuracy: 0.8086\n","Training loss (for one batch) at step 30: 267.2325, Accuracy: 0.8042\n","Training loss (for one batch) at step 40: 272.8430, Accuracy: 0.8032\n","Training loss (for one batch) at step 50: 253.9477, Accuracy: 0.8082\n","Training loss (for one batch) at step 60: 273.7468, Accuracy: 0.8098\n","Training loss (for one batch) at step 70: 264.7573, Accuracy: 0.8114\n","Training loss (for one batch) at step 80: 258.3544, Accuracy: 0.8130\n","Training loss (for one batch) at step 90: 261.5009, Accuracy: 0.8126\n","Training loss (for one batch) at step 100: 260.4083, Accuracy: 0.8108\n","Training loss (for one batch) at step 110: 279.3535, Accuracy: 0.8109\n","Training loss (for one batch) at step 120: 288.3007, Accuracy: 0.8097\n","Training loss (for one batch) at step 130: 259.0465, Accuracy: 0.8102\n","Training loss (for one batch) at step 140: 269.2532, Accuracy: 0.8095\n","---- Training ----\n","Training loss: 230.9660\n","Training acc over epoch: 0.8091\n","---- Validation ----\n","Validation loss: 59.1527\n","Validation acc: 0.7270\n","Time taken: 65.09s\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 248.9862, Accuracy: 0.7900\n","Training loss (for one batch) at step 10: 255.4626, Accuracy: 0.8127\n","Training loss (for one batch) at step 20: 258.1023, Accuracy: 0.8138\n","Training loss (for one batch) at step 30: 245.6452, Accuracy: 0.8219\n","Training loss (for one batch) at step 40: 245.3950, Accuracy: 0.8227\n","Training loss (for one batch) at step 50: 259.8107, Accuracy: 0.8243\n","Training loss (for one batch) at step 60: 251.9704, Accuracy: 0.8218\n","Training loss (for one batch) at step 70: 251.1315, Accuracy: 0.8187\n","Training loss (for one batch) at step 80: 265.2372, Accuracy: 0.8169\n","Training loss (for one batch) at step 90: 269.7393, Accuracy: 0.8166\n","Training loss (for one batch) at step 100: 270.7150, Accuracy: 0.8157\n","Training loss (for one batch) at step 110: 245.3944, Accuracy: 0.8162\n","Training loss (for one batch) at step 120: 258.1553, Accuracy: 0.8147\n","Training loss (for one batch) at step 130: 249.0710, Accuracy: 0.8131\n","Training loss (for one batch) at step 140: 287.2775, Accuracy: 0.8131\n","---- Training ----\n","Training loss: 230.6401\n","Training acc over epoch: 0.8119\n","---- Validation ----\n","Validation loss: 71.3853\n","Validation acc: 0.7348\n","Time taken: 37.27s\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 280.7761, Accuracy: 0.7400\n","Training loss (for one batch) at step 10: 247.2088, Accuracy: 0.8118\n","Training loss (for one batch) at step 20: 258.5042, Accuracy: 0.8190\n","Training loss (for one batch) at step 30: 255.4095, Accuracy: 0.8213\n","Training loss (for one batch) at step 40: 254.1044, Accuracy: 0.8198\n","Training loss (for one batch) at step 50: 256.7287, Accuracy: 0.8220\n","Training loss (for one batch) at step 60: 239.2006, Accuracy: 0.8248\n","Training loss (for one batch) at step 70: 255.1565, Accuracy: 0.8214\n","Training loss (for one batch) at step 80: 268.6976, Accuracy: 0.8196\n","Training loss (for one batch) at step 90: 267.7452, Accuracy: 0.8207\n","Training loss (for one batch) at step 100: 242.0513, Accuracy: 0.8187\n","Training loss (for one batch) at step 110: 258.2068, Accuracy: 0.8193\n","Training loss (for one batch) at step 120: 259.0406, Accuracy: 0.8165\n","Training loss (for one batch) at step 130: 259.2622, Accuracy: 0.8170\n","Training loss (for one batch) at step 140: 253.7758, Accuracy: 0.8154\n","---- Training ----\n","Training loss: 216.2381\n","Training acc over epoch: 0.8168\n","---- Validation ----\n","Validation loss: 69.9500\n","Validation acc: 0.7337\n","Time taken: 64.98s\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 263.5667, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 242.4959, Accuracy: 0.8236\n","Training loss (for one batch) at step 20: 266.2979, Accuracy: 0.8324\n","Training loss (for one batch) at step 30: 275.1202, Accuracy: 0.8281\n","Training loss (for one batch) at step 40: 286.8224, Accuracy: 0.8229\n","Training loss (for one batch) at step 50: 264.0530, Accuracy: 0.8214\n","Training loss (for one batch) at step 60: 229.2666, Accuracy: 0.8233\n","Training loss (for one batch) at step 70: 251.2237, Accuracy: 0.8228\n","Training loss (for one batch) at step 80: 283.0322, Accuracy: 0.8209\n","Training loss (for one batch) at step 90: 236.1496, Accuracy: 0.8215\n","Training loss (for one batch) at step 100: 265.8540, Accuracy: 0.8175\n","Training loss (for one batch) at step 110: 261.0361, Accuracy: 0.8185\n","Training loss (for one batch) at step 120: 248.9195, Accuracy: 0.8175\n","Training loss (for one batch) at step 130: 262.9921, Accuracy: 0.8182\n","Training loss (for one batch) at step 140: 252.1389, Accuracy: 0.8158\n","---- Training ----\n","Training loss: 225.3495\n","Training acc over epoch: 0.8159\n","---- Validation ----\n","Validation loss: 68.0859\n","Validation acc: 0.7386\n","Time taken: 37.04s\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 244.2747, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 269.4955, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 251.7158, Accuracy: 0.8233\n","Training loss (for one batch) at step 30: 253.7226, Accuracy: 0.8177\n","Training loss (for one batch) at step 40: 256.1872, Accuracy: 0.8190\n","Training loss (for one batch) at step 50: 239.9199, Accuracy: 0.8208\n","Training loss (for one batch) at step 60: 243.3136, Accuracy: 0.8205\n","Training loss (for one batch) at step 70: 250.4837, Accuracy: 0.8203\n","Training loss (for one batch) at step 80: 246.3107, Accuracy: 0.8204\n","Training loss (for one batch) at step 90: 273.5338, Accuracy: 0.8181\n","Training loss (for one batch) at step 100: 265.1309, Accuracy: 0.8182\n","Training loss (for one batch) at step 110: 258.0261, Accuracy: 0.8179\n","Training loss (for one batch) at step 120: 256.5783, Accuracy: 0.8200\n","Training loss (for one batch) at step 130: 269.6611, Accuracy: 0.8206\n","Training loss (for one batch) at step 140: 250.4053, Accuracy: 0.8213\n","---- Training ----\n","Training loss: 230.8903\n","Training acc over epoch: 0.8210\n","---- Validation ----\n","Validation loss: 69.6143\n","Validation acc: 0.7378\n","Time taken: 64.62s\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 268.1575, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 243.6683, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 259.9017, Accuracy: 0.8310\n","Training loss (for one batch) at step 30: 262.0081, Accuracy: 0.8258\n","Training loss (for one batch) at step 40: 240.2090, Accuracy: 0.8249\n","Training loss (for one batch) at step 50: 250.9597, Accuracy: 0.8259\n","Training loss (for one batch) at step 60: 239.2737, Accuracy: 0.8264\n","Training loss (for one batch) at step 70: 255.2901, Accuracy: 0.8269\n","Training loss (for one batch) at step 80: 250.7855, Accuracy: 0.8256\n","Training loss (for one batch) at step 90: 260.3322, Accuracy: 0.8242\n","Training loss (for one batch) at step 100: 251.3374, Accuracy: 0.8237\n","Training loss (for one batch) at step 110: 239.4255, Accuracy: 0.8251\n","Training loss (for one batch) at step 120: 254.1772, Accuracy: 0.8233\n","Training loss (for one batch) at step 130: 250.1361, Accuracy: 0.8244\n","Training loss (for one batch) at step 140: 271.4566, Accuracy: 0.8230\n","---- Training ----\n","Training loss: 234.3596\n","Training acc over epoch: 0.8226\n","---- Validation ----\n","Validation loss: 68.2509\n","Validation acc: 0.7397\n","Time taken: 38.04s\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 256.8065, Accuracy: 0.7800\n","Training loss (for one batch) at step 10: 259.0746, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 254.2482, Accuracy: 0.8390\n","Training loss (for one batch) at step 30: 237.0715, Accuracy: 0.8339\n","Training loss (for one batch) at step 40: 232.1272, Accuracy: 0.8327\n","Training loss (for one batch) at step 50: 264.7004, Accuracy: 0.8369\n","Training loss (for one batch) at step 60: 256.0864, Accuracy: 0.8370\n","Training loss (for one batch) at step 70: 255.6832, Accuracy: 0.8356\n","Training loss (for one batch) at step 80: 264.9968, Accuracy: 0.8319\n","Training loss (for one batch) at step 90: 239.4745, Accuracy: 0.8301\n","Training loss (for one batch) at step 100: 257.3871, Accuracy: 0.8294\n","Training loss (for one batch) at step 110: 235.6699, Accuracy: 0.8315\n","Training loss (for one batch) at step 120: 263.0173, Accuracy: 0.8307\n","Training loss (for one batch) at step 130: 253.0811, Accuracy: 0.8285\n","Training loss (for one batch) at step 140: 238.1869, Accuracy: 0.8269\n","---- Training ----\n","Training loss: 220.7025\n","Training acc over epoch: 0.8266\n","---- Validation ----\n","Validation loss: 60.2272\n","Validation acc: 0.7284\n","Time taken: 63.69s\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 239.6166, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 248.6262, Accuracy: 0.8227\n","Training loss (for one batch) at step 20: 273.5850, Accuracy: 0.8305\n","Training loss (for one batch) at step 30: 240.8706, Accuracy: 0.8371\n","Training loss (for one batch) at step 40: 236.1343, Accuracy: 0.8393\n","Training loss (for one batch) at step 50: 246.2553, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 251.3374, Accuracy: 0.8367\n","Training loss (for one batch) at step 70: 245.7694, Accuracy: 0.8345\n","Training loss (for one batch) at step 80: 291.0194, Accuracy: 0.8326\n","Training loss (for one batch) at step 90: 236.9663, Accuracy: 0.8305\n","Training loss (for one batch) at step 100: 240.1508, Accuracy: 0.8291\n","Training loss (for one batch) at step 110: 230.7787, Accuracy: 0.8299\n","Training loss (for one batch) at step 120: 220.4176, Accuracy: 0.8301\n","Training loss (for one batch) at step 130: 246.2157, Accuracy: 0.8292\n","Training loss (for one batch) at step 140: 235.0207, Accuracy: 0.8296\n","---- Training ----\n","Training loss: 237.4948\n","Training acc over epoch: 0.8289\n","---- Validation ----\n","Validation loss: 63.4127\n","Validation acc: 0.7359\n","Time taken: 37.58s\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 249.9998, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 256.5432, Accuracy: 0.8364\n","Training loss (for one batch) at step 20: 225.3118, Accuracy: 0.8290\n","Training loss (for one batch) at step 30: 247.8926, Accuracy: 0.8319\n","Training loss (for one batch) at step 40: 257.8928, Accuracy: 0.8285\n","Training loss (for one batch) at step 50: 235.7447, Accuracy: 0.8322\n","Training loss (for one batch) at step 60: 235.9714, Accuracy: 0.8285\n","Training loss (for one batch) at step 70: 246.7176, Accuracy: 0.8285\n","Training loss (for one batch) at step 80: 263.3189, Accuracy: 0.8274\n","Training loss (for one batch) at step 90: 266.1384, Accuracy: 0.8288\n","Training loss (for one batch) at step 100: 237.1652, Accuracy: 0.8278\n","Training loss (for one batch) at step 110: 252.4740, Accuracy: 0.8286\n","Training loss (for one batch) at step 120: 256.4757, Accuracy: 0.8282\n","Training loss (for one batch) at step 130: 244.4297, Accuracy: 0.8285\n","Training loss (for one batch) at step 140: 261.2341, Accuracy: 0.8283\n","---- Training ----\n","Training loss: 220.5580\n","Training acc over epoch: 0.8291\n","---- Validation ----\n","Validation loss: 75.0448\n","Validation acc: 0.7316\n","Time taken: 66.29s\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 251.4385, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 251.8913, Accuracy: 0.8518\n","Training loss (for one batch) at step 20: 253.3459, Accuracy: 0.8538\n","Training loss (for one batch) at step 30: 240.6779, Accuracy: 0.8510\n","Training loss (for one batch) at step 40: 241.1933, Accuracy: 0.8456\n","Training loss (for one batch) at step 50: 227.3037, Accuracy: 0.8424\n","Training loss (for one batch) at step 60: 253.6561, Accuracy: 0.8425\n","Training loss (for one batch) at step 70: 263.4375, Accuracy: 0.8406\n","Training loss (for one batch) at step 80: 233.6592, Accuracy: 0.8394\n","Training loss (for one batch) at step 90: 219.3743, Accuracy: 0.8376\n","Training loss (for one batch) at step 100: 242.1733, Accuracy: 0.8357\n","Training loss (for one batch) at step 110: 240.5328, Accuracy: 0.8348\n","Training loss (for one batch) at step 120: 249.4072, Accuracy: 0.8351\n","Training loss (for one batch) at step 130: 247.5589, Accuracy: 0.8340\n","Training loss (for one batch) at step 140: 246.7546, Accuracy: 0.8338\n","---- Training ----\n","Training loss: 206.1685\n","Training acc over epoch: 0.8342\n","---- Validation ----\n","Validation loss: 67.4582\n","Validation acc: 0.7391\n","Time taken: 37.34s\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 244.0874, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 249.9423, Accuracy: 0.8436\n","Training loss (for one batch) at step 20: 224.8503, Accuracy: 0.8448\n","Training loss (for one batch) at step 30: 271.1761, Accuracy: 0.8381\n","Training loss (for one batch) at step 40: 226.0677, Accuracy: 0.8388\n","Training loss (for one batch) at step 50: 238.1078, Accuracy: 0.8378\n","Training loss (for one batch) at step 60: 218.3685, Accuracy: 0.8415\n","Training loss (for one batch) at step 70: 243.2289, Accuracy: 0.8393\n","Training loss (for one batch) at step 80: 272.7744, Accuracy: 0.8396\n","Training loss (for one batch) at step 90: 246.1263, Accuracy: 0.8374\n","Training loss (for one batch) at step 100: 274.7321, Accuracy: 0.8365\n","Training loss (for one batch) at step 110: 238.6112, Accuracy: 0.8357\n","Training loss (for one batch) at step 120: 227.7910, Accuracy: 0.8351\n","Training loss (for one batch) at step 130: 248.2352, Accuracy: 0.8344\n","Training loss (for one batch) at step 140: 242.2143, Accuracy: 0.8343\n","---- Training ----\n","Training loss: 213.9095\n","Training acc over epoch: 0.8340\n","---- Validation ----\n","Validation loss: 70.6265\n","Validation acc: 0.7316\n","Time taken: 63.81s\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 252.0213, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 268.9356, Accuracy: 0.8273\n","Training loss (for one batch) at step 20: 237.1700, Accuracy: 0.8319\n","Training loss (for one batch) at step 30: 245.6171, Accuracy: 0.8323\n","Training loss (for one batch) at step 40: 247.8270, Accuracy: 0.8349\n","Training loss (for one batch) at step 50: 233.1107, Accuracy: 0.8392\n","Training loss (for one batch) at step 60: 247.4797, Accuracy: 0.8413\n","Training loss (for one batch) at step 70: 234.9050, Accuracy: 0.8411\n","Training loss (for one batch) at step 80: 239.3679, Accuracy: 0.8388\n","Training loss (for one batch) at step 90: 262.2308, Accuracy: 0.8351\n","Training loss (for one batch) at step 100: 235.6351, Accuracy: 0.8360\n","Training loss (for one batch) at step 110: 248.0833, Accuracy: 0.8376\n","Training loss (for one batch) at step 120: 240.7896, Accuracy: 0.8377\n","Training loss (for one batch) at step 130: 249.3737, Accuracy: 0.8367\n","Training loss (for one batch) at step 140: 242.9373, Accuracy: 0.8365\n","---- Training ----\n","Training loss: 200.1012\n","Training acc over epoch: 0.8367\n","---- Validation ----\n","Validation loss: 65.7357\n","Validation acc: 0.7340\n","Time taken: 37.16s\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 239.9920, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 231.5297, Accuracy: 0.8373\n","Training loss (for one batch) at step 20: 236.1277, Accuracy: 0.8348\n","Training loss (for one batch) at step 30: 247.3307, Accuracy: 0.8319\n","Training loss (for one batch) at step 40: 220.9794, Accuracy: 0.8368\n","Training loss (for one batch) at step 50: 236.2619, Accuracy: 0.8371\n","Training loss (for one batch) at step 60: 229.9386, Accuracy: 0.8393\n","Training loss (for one batch) at step 70: 254.0831, Accuracy: 0.8390\n","Training loss (for one batch) at step 80: 249.4035, Accuracy: 0.8402\n","Training loss (for one batch) at step 90: 239.7289, Accuracy: 0.8390\n","Training loss (for one batch) at step 100: 219.4154, Accuracy: 0.8385\n","Training loss (for one batch) at step 110: 230.9085, Accuracy: 0.8400\n","Training loss (for one batch) at step 120: 221.5601, Accuracy: 0.8402\n","Training loss (for one batch) at step 130: 217.7972, Accuracy: 0.8397\n","Training loss (for one batch) at step 140: 229.0081, Accuracy: 0.8384\n","---- Training ----\n","Training loss: 209.9108\n","Training acc over epoch: 0.8387\n","---- Validation ----\n","Validation loss: 76.8264\n","Validation acc: 0.7405\n","Time taken: 64.45s\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 242.5919, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 237.5313, Accuracy: 0.8355\n","Training loss (for one batch) at step 20: 228.6697, Accuracy: 0.8495\n","Training loss (for one batch) at step 30: 254.7920, Accuracy: 0.8500\n","Training loss (for one batch) at step 40: 222.7771, Accuracy: 0.8495\n","Training loss (for one batch) at step 50: 227.3997, Accuracy: 0.8494\n","Training loss (for one batch) at step 60: 234.4799, Accuracy: 0.8508\n","Training loss (for one batch) at step 70: 250.8777, Accuracy: 0.8451\n","Training loss (for one batch) at step 80: 229.2868, Accuracy: 0.8428\n","Training loss (for one batch) at step 90: 234.9481, Accuracy: 0.8437\n","Training loss (for one batch) at step 100: 232.2818, Accuracy: 0.8422\n","Training loss (for one batch) at step 110: 217.0236, Accuracy: 0.8419\n","Training loss (for one batch) at step 120: 241.6974, Accuracy: 0.8408\n","Training loss (for one batch) at step 130: 225.0129, Accuracy: 0.8398\n","Training loss (for one batch) at step 140: 252.2674, Accuracy: 0.8409\n","---- Training ----\n","Training loss: 206.1332\n","Training acc over epoch: 0.8405\n","---- Validation ----\n","Validation loss: 81.2987\n","Validation acc: 0.7262\n","Time taken: 37.71s\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 235.5174, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 230.6322, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 266.4501, Accuracy: 0.8467\n","Training loss (for one batch) at step 30: 217.2251, Accuracy: 0.8442\n","Training loss (for one batch) at step 40: 214.7453, Accuracy: 0.8427\n","Training loss (for one batch) at step 50: 244.0030, Accuracy: 0.8431\n","Training loss (for one batch) at step 60: 239.7386, Accuracy: 0.8454\n","Training loss (for one batch) at step 70: 243.2821, Accuracy: 0.8428\n","Training loss (for one batch) at step 80: 256.6152, Accuracy: 0.8417\n","Training loss (for one batch) at step 90: 229.0629, Accuracy: 0.8409\n","Training loss (for one batch) at step 100: 233.9327, Accuracy: 0.8378\n","Training loss (for one batch) at step 110: 222.1417, Accuracy: 0.8383\n","Training loss (for one batch) at step 120: 223.3936, Accuracy: 0.8368\n","Training loss (for one batch) at step 130: 217.7450, Accuracy: 0.8370\n","Training loss (for one batch) at step 140: 253.1354, Accuracy: 0.8363\n","---- Training ----\n","Training loss: 218.2092\n","Training acc over epoch: 0.8366\n","---- Validation ----\n","Validation loss: 70.4013\n","Validation acc: 0.7249\n","Time taken: 64.66s\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 238.1612, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 240.4977, Accuracy: 0.8491\n","Training loss (for one batch) at step 20: 226.4392, Accuracy: 0.8529\n","Training loss (for one batch) at step 30: 229.9782, Accuracy: 0.8439\n","Training loss (for one batch) at step 40: 219.1117, Accuracy: 0.8454\n","Training loss (for one batch) at step 50: 229.7378, Accuracy: 0.8457\n","Training loss (for one batch) at step 60: 248.6942, Accuracy: 0.8474\n","Training loss (for one batch) at step 70: 228.1802, Accuracy: 0.8487\n","Training loss (for one batch) at step 80: 238.2119, Accuracy: 0.8432\n","Training loss (for one batch) at step 90: 255.6680, Accuracy: 0.8413\n","Training loss (for one batch) at step 100: 218.1819, Accuracy: 0.8400\n","Training loss (for one batch) at step 110: 234.9074, Accuracy: 0.8397\n","Training loss (for one batch) at step 120: 234.5446, Accuracy: 0.8404\n","Training loss (for one batch) at step 130: 243.2114, Accuracy: 0.8398\n","Training loss (for one batch) at step 140: 237.8987, Accuracy: 0.8383\n","---- Training ----\n","Training loss: 191.9649\n","Training acc over epoch: 0.8379\n","---- Validation ----\n","Validation loss: 76.1656\n","Validation acc: 0.7316\n","Time taken: 38.09s\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 234.5698, Accuracy: 0.8100\n","Training loss (for one batch) at step 10: 246.7703, Accuracy: 0.8418\n","Training loss (for one batch) at step 20: 226.3742, Accuracy: 0.8405\n","Training loss (for one batch) at step 30: 226.5220, Accuracy: 0.8410\n","Training loss (for one batch) at step 40: 229.8373, Accuracy: 0.8410\n","Training loss (for one batch) at step 50: 238.0048, Accuracy: 0.8412\n","Training loss (for one batch) at step 60: 213.0829, Accuracy: 0.8430\n","Training loss (for one batch) at step 70: 230.9470, Accuracy: 0.8452\n","Training loss (for one batch) at step 80: 223.7115, Accuracy: 0.8436\n","Training loss (for one batch) at step 90: 227.6953, Accuracy: 0.8446\n","Training loss (for one batch) at step 100: 237.4434, Accuracy: 0.8436\n","Training loss (for one batch) at step 110: 227.3601, Accuracy: 0.8431\n","Training loss (for one batch) at step 120: 206.1754, Accuracy: 0.8432\n","Training loss (for one batch) at step 130: 220.3103, Accuracy: 0.8424\n","Training loss (for one batch) at step 140: 230.6531, Accuracy: 0.8408\n","---- Training ----\n","Training loss: 199.6105\n","Training acc over epoch: 0.8413\n","---- Validation ----\n","Validation loss: 64.4639\n","Validation acc: 0.7284\n","Time taken: 65.31s\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 237.1849, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 221.5655, Accuracy: 0.8573\n","Training loss (for one batch) at step 20: 229.8233, Accuracy: 0.8538\n","Training loss (for one batch) at step 30: 215.2856, Accuracy: 0.8542\n","Training loss (for one batch) at step 40: 233.7465, Accuracy: 0.8524\n","Training loss (for one batch) at step 50: 226.9208, Accuracy: 0.8559\n","Training loss (for one batch) at step 60: 231.8494, Accuracy: 0.8544\n","Training loss (for one batch) at step 70: 236.1653, Accuracy: 0.8545\n","Training loss (for one batch) at step 80: 230.4915, Accuracy: 0.8519\n","Training loss (for one batch) at step 90: 235.8813, Accuracy: 0.8485\n","Training loss (for one batch) at step 100: 232.1350, Accuracy: 0.8463\n","Training loss (for one batch) at step 110: 227.4958, Accuracy: 0.8460\n","Training loss (for one batch) at step 120: 219.5463, Accuracy: 0.8463\n","Training loss (for one batch) at step 130: 210.1389, Accuracy: 0.8458\n","Training loss (for one batch) at step 140: 225.8702, Accuracy: 0.8460\n","---- Training ----\n","Training loss: 184.7298\n","Training acc over epoch: 0.8458\n","---- Validation ----\n","Validation loss: 72.7286\n","Validation acc: 0.7246\n","Time taken: 38.61s\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 216.3292, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 204.0099, Accuracy: 0.8564\n","Training loss (for one batch) at step 20: 223.7343, Accuracy: 0.8510\n","Training loss (for one batch) at step 30: 215.5699, Accuracy: 0.8448\n","Training loss (for one batch) at step 40: 223.6602, Accuracy: 0.8456\n","Training loss (for one batch) at step 50: 220.5359, Accuracy: 0.8498\n","Training loss (for one batch) at step 60: 227.9573, Accuracy: 0.8490\n","Training loss (for one batch) at step 70: 231.0555, Accuracy: 0.8500\n","Training loss (for one batch) at step 80: 243.2740, Accuracy: 0.8504\n","Training loss (for one batch) at step 90: 226.2473, Accuracy: 0.8512\n","Training loss (for one batch) at step 100: 239.3641, Accuracy: 0.8499\n","Training loss (for one batch) at step 110: 246.7267, Accuracy: 0.8505\n","Training loss (for one batch) at step 120: 206.5442, Accuracy: 0.8497\n","Training loss (for one batch) at step 130: 222.5840, Accuracy: 0.8496\n","Training loss (for one batch) at step 140: 251.3899, Accuracy: 0.8486\n","---- Training ----\n","Training loss: 201.5881\n","Training acc over epoch: 0.8481\n","---- Validation ----\n","Validation loss: 73.3230\n","Validation acc: 0.7238\n","Time taken: 65.30s\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 227.7898, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 228.7859, Accuracy: 0.8545\n","Training loss (for one batch) at step 20: 219.9217, Accuracy: 0.8567\n","Training loss (for one batch) at step 30: 209.3973, Accuracy: 0.8577\n","Training loss (for one batch) at step 40: 208.9625, Accuracy: 0.8585\n","Training loss (for one batch) at step 50: 204.5882, Accuracy: 0.8592\n","Training loss (for one batch) at step 60: 229.8008, Accuracy: 0.8557\n","Training loss (for one batch) at step 70: 207.5428, Accuracy: 0.8577\n","Training loss (for one batch) at step 80: 230.2812, Accuracy: 0.8549\n","Training loss (for one batch) at step 90: 217.8126, Accuracy: 0.8543\n","Training loss (for one batch) at step 100: 223.2358, Accuracy: 0.8519\n","Training loss (for one batch) at step 110: 211.3388, Accuracy: 0.8500\n","Training loss (for one batch) at step 120: 226.7275, Accuracy: 0.8500\n","Training loss (for one batch) at step 130: 227.1644, Accuracy: 0.8492\n","Training loss (for one batch) at step 140: 224.5988, Accuracy: 0.8487\n","---- Training ----\n","Training loss: 195.1359\n","Training acc over epoch: 0.8483\n","---- Validation ----\n","Validation loss: 91.6706\n","Validation acc: 0.7423\n","Time taken: 38.84s\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 217.0396, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 241.3870, Accuracy: 0.8455\n","Training loss (for one batch) at step 20: 233.0230, Accuracy: 0.8514\n","Training loss (for one batch) at step 30: 213.6895, Accuracy: 0.8484\n","Training loss (for one batch) at step 40: 220.4002, Accuracy: 0.8500\n","Training loss (for one batch) at step 50: 220.8671, Accuracy: 0.8506\n","Training loss (for one batch) at step 60: 241.0061, Accuracy: 0.8485\n","Training loss (for one batch) at step 70: 221.8659, Accuracy: 0.8486\n","Training loss (for one batch) at step 80: 215.1025, Accuracy: 0.8478\n","Training loss (for one batch) at step 90: 193.4868, Accuracy: 0.8451\n","Training loss (for one batch) at step 100: 242.7956, Accuracy: 0.8444\n","Training loss (for one batch) at step 110: 215.4156, Accuracy: 0.8434\n","Training loss (for one batch) at step 120: 212.0618, Accuracy: 0.8443\n","Training loss (for one batch) at step 130: 228.4740, Accuracy: 0.8446\n","Training loss (for one batch) at step 140: 196.6378, Accuracy: 0.8452\n","---- Training ----\n","Training loss: 202.2497\n","Training acc over epoch: 0.8446\n","---- Validation ----\n","Validation loss: 62.3941\n","Validation acc: 0.7370\n","Time taken: 66.41s\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 224.0869, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 215.2218, Accuracy: 0.8409\n","Training loss (for one batch) at step 20: 211.4269, Accuracy: 0.8505\n","Training loss (for one batch) at step 30: 212.3453, Accuracy: 0.8442\n","Training loss (for one batch) at step 40: 215.4431, Accuracy: 0.8512\n","Training loss (for one batch) at step 50: 234.1839, Accuracy: 0.8488\n","Training loss (for one batch) at step 60: 224.4264, Accuracy: 0.8487\n","Training loss (for one batch) at step 70: 226.4505, Accuracy: 0.8496\n","Training loss (for one batch) at step 80: 226.6686, Accuracy: 0.8478\n","Training loss (for one batch) at step 90: 220.1757, Accuracy: 0.8486\n","Training loss (for one batch) at step 100: 210.6343, Accuracy: 0.8472\n","Training loss (for one batch) at step 110: 234.1867, Accuracy: 0.8475\n","Training loss (for one batch) at step 120: 218.1427, Accuracy: 0.8478\n","Training loss (for one batch) at step 130: 220.1093, Accuracy: 0.8482\n","Training loss (for one batch) at step 140: 227.0024, Accuracy: 0.8482\n","---- Training ----\n","Training loss: 179.8753\n","Training acc over epoch: 0.8475\n","---- Validation ----\n","Validation loss: 69.2404\n","Validation acc: 0.7171\n","Time taken: 39.09s\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 216.6525, Accuracy: 0.9000\n","Training loss (for one batch) at step 10: 230.2513, Accuracy: 0.8609\n","Training loss (for one batch) at step 20: 248.1977, Accuracy: 0.8543\n","Training loss (for one batch) at step 30: 210.0165, Accuracy: 0.8490\n","Training loss (for one batch) at step 40: 202.3168, Accuracy: 0.8505\n","Training loss (for one batch) at step 50: 199.5857, Accuracy: 0.8549\n","Training loss (for one batch) at step 60: 208.3279, Accuracy: 0.8551\n","Training loss (for one batch) at step 70: 225.5777, Accuracy: 0.8555\n","Training loss (for one batch) at step 80: 205.6580, Accuracy: 0.8538\n","Training loss (for one batch) at step 90: 226.4557, Accuracy: 0.8516\n","Training loss (for one batch) at step 100: 235.0610, Accuracy: 0.8496\n","Training loss (for one batch) at step 110: 234.9911, Accuracy: 0.8496\n","Training loss (for one batch) at step 120: 213.8809, Accuracy: 0.8503\n","Training loss (for one batch) at step 130: 229.6682, Accuracy: 0.8499\n","Training loss (for one batch) at step 140: 229.0847, Accuracy: 0.8493\n","---- Training ----\n","Training loss: 213.2135\n","Training acc over epoch: 0.8491\n","---- Validation ----\n","Validation loss: 85.4744\n","Validation acc: 0.7249\n","Time taken: 63.66s\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 222.7992, Accuracy: 0.8700\n","Training loss (for one batch) at step 10: 209.8335, Accuracy: 0.8600\n","Training loss (for one batch) at step 20: 219.3079, Accuracy: 0.8495\n","Training loss (for one batch) at step 30: 229.8299, Accuracy: 0.8552\n","Training loss (for one batch) at step 40: 224.5604, Accuracy: 0.8532\n","Training loss (for one batch) at step 50: 190.8823, Accuracy: 0.8563\n","Training loss (for one batch) at step 60: 208.4450, Accuracy: 0.8570\n","Training loss (for one batch) at step 70: 205.4574, Accuracy: 0.8527\n","Training loss (for one batch) at step 80: 238.4645, Accuracy: 0.8520\n","Training loss (for one batch) at step 90: 225.2913, Accuracy: 0.8479\n","Training loss (for one batch) at step 100: 213.0399, Accuracy: 0.8496\n","Training loss (for one batch) at step 110: 199.3031, Accuracy: 0.8495\n","Training loss (for one batch) at step 120: 243.4660, Accuracy: 0.8512\n","Training loss (for one batch) at step 130: 215.6532, Accuracy: 0.8498\n","Training loss (for one batch) at step 140: 232.8289, Accuracy: 0.8491\n","---- Training ----\n","Training loss: 185.4447\n","Training acc over epoch: 0.8505\n","---- Validation ----\n","Validation loss: 85.1821\n","Validation acc: 0.7450\n","Time taken: 36.82s\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 216.4352, Accuracy: 0.8600\n","Training loss (for one batch) at step 10: 199.4248, Accuracy: 0.8536\n","Training loss (for one batch) at step 20: 212.3192, Accuracy: 0.8543\n","Training loss (for one batch) at step 30: 237.6564, Accuracy: 0.8494\n","Training loss (for one batch) at step 40: 226.7646, Accuracy: 0.8505\n","Training loss (for one batch) at step 50: 219.4993, Accuracy: 0.8561\n","Training loss (for one batch) at step 60: 217.4336, Accuracy: 0.8559\n","Training loss (for one batch) at step 70: 201.6453, Accuracy: 0.8554\n","Training loss (for one batch) at step 80: 211.7825, Accuracy: 0.8560\n","Training loss (for one batch) at step 90: 227.1505, Accuracy: 0.8538\n","Training loss (for one batch) at step 100: 234.6304, Accuracy: 0.8528\n","Training loss (for one batch) at step 110: 223.3621, Accuracy: 0.8532\n","Training loss (for one batch) at step 120: 205.4325, Accuracy: 0.8539\n","Training loss (for one batch) at step 130: 204.2140, Accuracy: 0.8516\n","Training loss (for one batch) at step 140: 236.2521, Accuracy: 0.8522\n","---- Training ----\n","Training loss: 186.7998\n","Training acc over epoch: 0.8522\n","---- Validation ----\n","Validation loss: 73.4796\n","Validation acc: 0.7391\n","Time taken: 64.83s\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 203.1421, Accuracy: 0.8400\n","Training loss (for one batch) at step 10: 229.9133, Accuracy: 0.8491\n","Training loss (for one batch) at step 20: 234.2820, Accuracy: 0.8500\n","Training loss (for one batch) at step 30: 196.1465, Accuracy: 0.8513\n","Training loss (for one batch) at step 40: 228.6390, Accuracy: 0.8515\n","Training loss (for one batch) at step 50: 223.1656, Accuracy: 0.8533\n","Training loss (for one batch) at step 60: 217.5273, Accuracy: 0.8557\n","Training loss (for one batch) at step 70: 210.7529, Accuracy: 0.8548\n","Training loss (for one batch) at step 80: 191.5359, Accuracy: 0.8547\n","Training loss (for one batch) at step 90: 227.4669, Accuracy: 0.8518\n","Training loss (for one batch) at step 100: 211.4654, Accuracy: 0.8506\n","Training loss (for one batch) at step 110: 199.8591, Accuracy: 0.8514\n","Training loss (for one batch) at step 120: 225.0475, Accuracy: 0.8514\n","Training loss (for one batch) at step 130: 226.9212, Accuracy: 0.8512\n","Training loss (for one batch) at step 140: 213.8333, Accuracy: 0.8510\n","---- Training ----\n","Training loss: 179.8663\n","Training acc over epoch: 0.8505\n","---- Validation ----\n","Validation loss: 72.2260\n","Validation acc: 0.7254\n","Time taken: 36.92s\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 215.3543, Accuracy: 0.8300\n","Training loss (for one batch) at step 10: 243.1009, Accuracy: 0.8555\n","Training loss (for one batch) at step 20: 212.6778, Accuracy: 0.8519\n","Training loss (for one batch) at step 30: 183.0243, Accuracy: 0.8497\n","Training loss (for one batch) at step 40: 206.0371, Accuracy: 0.8546\n","Training loss (for one batch) at step 50: 220.6156, Accuracy: 0.8578\n","Training loss (for one batch) at step 60: 202.1973, Accuracy: 0.8595\n","Training loss (for one batch) at step 70: 207.4982, Accuracy: 0.8572\n","Training loss (for one batch) at step 80: 211.1456, Accuracy: 0.8563\n","Training loss (for one batch) at step 90: 204.6884, Accuracy: 0.8556\n","Training loss (for one batch) at step 100: 220.5500, Accuracy: 0.8546\n","Training loss (for one batch) at step 110: 203.2720, Accuracy: 0.8551\n","Training loss (for one batch) at step 120: 216.8195, Accuracy: 0.8560\n","Training loss (for one batch) at step 130: 215.0410, Accuracy: 0.8547\n","Training loss (for one batch) at step 140: 238.3763, Accuracy: 0.8531\n","---- Training ----\n","Training loss: 187.8261\n","Training acc over epoch: 0.8536\n","---- Validation ----\n","Validation loss: 75.8526\n","Validation acc: 0.7246\n","Time taken: 63.56s\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 227.0806, Accuracy: 0.8500\n","Training loss (for one batch) at step 10: 209.5961, Accuracy: 0.8591\n","Training loss (for one batch) at step 20: 214.4810, Accuracy: 0.8514\n","Training loss (for one batch) at step 30: 206.1188, Accuracy: 0.8539\n","Training loss (for one batch) at step 40: 200.9710, Accuracy: 0.8549\n","Training loss (for one batch) at step 50: 197.2371, Accuracy: 0.8567\n","Training loss (for one batch) at step 60: 215.7870, Accuracy: 0.8580\n","Training loss (for one batch) at step 70: 211.5255, Accuracy: 0.8563\n","Training loss (for one batch) at step 80: 238.5272, Accuracy: 0.8552\n","Training loss (for one batch) at step 90: 197.1934, Accuracy: 0.8522\n","Training loss (for one batch) at step 100: 220.6883, Accuracy: 0.8512\n","Training loss (for one batch) at step 110: 204.7271, Accuracy: 0.8545\n","Training loss (for one batch) at step 120: 210.4459, Accuracy: 0.8545\n","Training loss (for one batch) at step 130: 198.4456, Accuracy: 0.8540\n","Training loss (for one batch) at step 140: 208.7387, Accuracy: 0.8532\n","---- Training ----\n","Training loss: 205.0569\n","Training acc over epoch: 0.8534\n","---- Validation ----\n","Validation loss: 88.7453\n","Validation acc: 0.7311\n","Time taken: 36.91s\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["===== Q: 0.0001\n","Validation acc: 0.7384\n","Validation AUC: 0.7353\n","Validation Balanced_ACC: 0.4773\n","Validation MI: 0.1371\n","Validation Normalized MI: 0.2055\n","Validation Adjusted MI: 0.2055\n","Validation aUc_Sklearn: 0.8305\n"]}],"source":["from sklearn.metrics import classification_report, balanced_accuracy_score, roc_auc_score\n","from sklearn.metrics import normalized_mutual_info_score, mutual_info_score, adjusted_mutual_info_score\n","#model = create_model()\n","K=2\n","R=5\n","val_q = [0.0001]   #0.2, 0.4, 0.6, 0.8]\n","NUM_RUNS = 10\n","N_EPOCHS =50\n","ACC = np.zeros(NUM_RUNS)\n","AUC = np.zeros(NUM_RUNS)\n","AUCSK = np.zeros(NUM_RUNS)\n","MI = np.zeros(NUM_RUNS)\n","NMI = np.zeros(NUM_RUNS)\n","AMI = np.zeros(NUM_RUNS)\n","BACC = np.zeros(NUM_RUNS)\n","BACC1 = []\n","MI1 = []\n","NMI1 =[]\n","AMI1 = []\n","AUCSK1 = []\n","val_acc = np.zeros(NUM_RUNS)\n","for i in range(NUM_RUNS):\n","  MA = MultipleAnnotators_Classification(2, 5, val_q[0])\n","  model =  create_model()\n","  model = MA.fit(model, train_batches_MA, val_batches_MA, N_EPOCHS)\n","  #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n","  ACC[i] = MA.eval_model(test_batches_MA)\n","  print(\"===== Q: %.4f\" % (float(val_q[0]),))\n","  print(\"Validation acc: %.4f\" % (float(ACC[i]),))\n","\n","\n","    #AUC =======================\n","  val_AUC_metric = tf.keras.metrics.AUC( from_logits = True)\n","  for x_batch_val, y_batch_val in test_batches_MA:\n","      val_logits = model(x_batch_val.numpy(), training=False)\n","      # tf.print(y_batch_val)\n","      val_AUC_metric.update_state(y_batch_val, val_logits[:,:K].numpy().argmax(axis=1).astype('float'))   #val_logits[:,Y.shape[1]:].argmax(axis=1).astype('float'))\n","      AUCSK1.append(roc_auc_score(ook(y_batch_val.numpy().ravel()), val_logits[:,:K].numpy()))\n","      BACC1.append(balanced_accuracy_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True))\n","      MI1.append(mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","      NMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","      AMI1.append(normalized_mutual_info_score(y_batch_val.numpy().squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze()))\n","\n","  val_AUC = val_AUC_metric.result()\n","  val_AUC_metric.reset_states()\n","  val_AUC = val_AUC.numpy()\n","  print(\"Validation AUC: %.4f\" % (float(val_AUC),))\n","  AUC[i] = val_AUC\n","\n","  #===================================================\n","    \n","  # balanced. Accurcy\n","  BACC[i] = np.array(BACC1).mean() # balanced_accuracy_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze(), adjusted=True)\n","  print(\"Validation Balanced_ACC: %.4f\" % (float(BACC[i])))\n","\n","  #MI\n","  \n","  MI[i] =  np.array(MI1).mean()  #mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation MI: %.4f\" % (float(MI[i]),))\n","  NMI[i] =  np.array(NMI1).mean()   #normalized_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation Normalized MI: %.4f\" % (float(NMI[i]),))\n","  AMI[i]= np.array(AMI1).mean()  #adjusted_mutual_info_score(Y_true_test.squeeze(), val_logits[:,:K].numpy().argmax(axis=1).squeeze())\n","  print(\"Validation Adjusted MI: %.4f\" % (float(AMI[i]),))\n","  AUCSK[i] = np.array(AUCSK1).mean() \n","  print(\"Validation aUc_Sklearn: %.4f\" % (float(AUCSK[i]),))  \n","import pandas as pd\n","df = pd.DataFrame(ACC)\n","#df.to_csv('/content/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output"]},{"cell_type":"code","execution_count":19,"id":"9df0152b","metadata":{"execution":{"iopub.execute_input":"2023-02-15T03:55:53.274648Z","iopub.status.busy":"2023-02-15T03:55:53.27373Z","iopub.status.idle":"2023-02-15T03:55:53.27967Z","shell.execute_reply":"2023-02-15T03:55:53.278633Z"},"id":"_H_sb1cl1FC_","outputId":"59d957da-9223-4a01-e4d9-33933f7a2f4a","papermill":{"duration":0.426221,"end_time":"2023-02-15T03:55:53.281708","exception":false,"start_time":"2023-02-15T03:55:52.855487","status":"completed"},"tags":[]},"outputs":[],"source":["# classification_report_r= []\n","# model = create_model()\n","# K=2\n","# R=5\n","# NUM_RUNS = 10\n","# N_EPOCHS = 30\n","# val_acc = np.zeros(NUM_RUNS)\n","# for i in range(NUM_RUNS):\n","#   MA = MultipleAnnotators_Classification(K, R, 0.1)\n","#   model = create_model()\n","#   optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n","#   model.compile(optimizer=optimizer, loss= MA.loss())\n","#   history_model = model.fit(train_batches_MA, validation_data=val_batches_MA, epochs= N_EPOCHS, callbacks=callbacks, verbose=0)\n","#   #model = MA.fit(model, Data_train_MA, N_EPOCHS)\n","#   pred_2 = model.predict(X_test)\n","\n","#   lambda_R_ = pred_2[:, K:] #annotators reliability prediction N x R   \n","#   classification_report_r += [classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel(),output_dict=True)]\n","#   print(classification_report( pred_2[:,:K].argmax(axis=1),Y_true_test.ravel()))\n","#   #val_acc[i] = MA.eval_model(test_batches_MA)\n","#   #print(\"Validation acc: %.4f\" % (float(val_acc[i]),))\n","#   # Create the history figure\n","#   plt.figure(figsize=(16,9))\n","#   for i in  history_model.history:\n","#       plt.plot(history_model.history[i],label=i)\n","#   plt.title('Model history')\n","#   plt.legend()\n","#   plt.grid()\n","\n","# import pandas as pd\n","# df = pd.DataFrame(val_acc)\n","# #df.to_csimport pandas as pddf = pd.DataFrame(val_acc)#df.to_csv('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output​v('/kaggle/working/CatDogs_MA_InceptionV3.csv',index=False) # save to notebook output\n"]},{"cell_type":"code","execution_count":20,"id":"6c9baead","metadata":{"execution":{"iopub.execute_input":"2023-02-15T03:55:54.188645Z","iopub.status.busy":"2023-02-15T03:55:54.188272Z","iopub.status.idle":"2023-02-15T03:55:54.201302Z","shell.execute_reply":"2023-02-15T03:55:54.198523Z"},"id":"Mu0lyAUIGSTB","outputId":"cb82872d-c3ba-4d76-a28c-237eb266e78b","papermill":{"duration":0.433042,"end_time":"2023-02-15T03:55:54.204353","exception":false,"start_time":"2023-02-15T03:55:53.771311","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy:  74.15\n","Average std:  0.58\n","==============================================\n","Average AUC:  73.88\n","Average AUC std:  0.61\n","==============================================\n","Average AUC Sklearn:  82.99\n","Average AUC SK std:  0.3\n","==============================================\n","Average Balanced Accuracy:  48.24\n","Average std:  0.5499999999999999\n","==============================================\n","Average MI:  13.889999999999999\n","Average std:  0.22999999999999998\n","==============================================\n","Average Normalized MI:  20.79\n","Average std:  0.33999999999999997\n","==============================================\n","Average Ajdusted MI:  20.79\n","Average std:  0.33999999999999997\n"]}],"source":["print('Average Accuracy: ', np.round( ACC.mean(),4)*100) \n","print('Average std: ',np.round(np.std( ACC),4)*100)\n","print('==============================================')\n","print('Average AUC: ', np.round( AUC.mean(),4)*100) \n","print('Average AUC std: ',np.round(np.std( AUC),4)*100)\n","print('==============================================')\n","print('Average AUC Sklearn: ', np.round( AUCSK.mean(),4)*100) \n","print('Average AUC SK std: ',np.round(np.std( AUCSK),4)*100)\n","print('==============================================')\n","print('Average Balanced Accuracy: ', np.round( BACC.mean(),4)*100) \n","print('Average std: ',np.round(np.std( BACC),4)*100)\n","print('==============================================')\n","print('Average MI: ', np.round( MI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(MI),4)*100)\n","print('==============================================')\n","print('Average Normalized MI: ', np.round( NMI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(NMI),4)*100)\n","print('==============================================')\n","print('Average Ajdusted MI: ', np.round( AMI.mean(),4)*100) \n","print('Average std: ',np.round(np.std(AMI),4)*100)"]},{"cell_type":"code","execution_count":null,"id":"91b764ed","metadata":{"papermill":{"duration":0.437088,"end_time":"2023-02-15T03:55:55.05908","exception":false,"start_time":"2023-02-15T03:55:54.621992","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":21974.136544,"end_time":"2023-02-15T03:55:58.757915","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-02-14T21:49:44.621371","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}